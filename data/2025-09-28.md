<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 53]
- [cs.CV](#cs.CV) [Total: 51]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.IR](#cs.IR) [Total: 9]
- [cs.LG](#cs.LG) [Total: 50]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Interpreting Public Sentiment in Diplomacy Events: A Counterfactual Analysis Framework Using Large Language Models](https://arxiv.org/abs/2509.20367)
*Leyi Ouyang*

Main category: cs.CL

TL;DR: 提出了一种新的框架，通过修改外交事件的叙述方式来转变公众情绪，使其从负面变为中性或正面。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如大规模调查或媒体内容手动分析）耗时、费力，且缺乏前瞻性分析能力。公共情绪在外交中起着关键作用，良好的情绪为政策实施提供重要支持，有助于解决国际问题，并塑造国家形象。

Method: 1. 训练一个语言模型来预测公众对外交事件的反应。为此，构建了一个包含外交事件描述及其相关公众讨论的数据集。2. 在传播理论的指导下，并与领域专家合作，预先确定了几个用于修改的文本特征，确保任何改动都能改变事件的叙述框架，同时保留其核心事实。3. 开发了一种反事实生成算法，该算法使用大型语言模型来系统地生成原始文本的修改版本。

Result: 该框架成功地将公众情绪转变为更有利的状态，成功率达70%。

Conclusion: 该框架可以作为外交官、政策制定者和传播专家的实用工具，提供数据驱动的见解，说明如何构建外交倡议或报告事件，以培养更理想的公众情绪。

Abstract: Diplomatic events consistently prompt widespread public discussion and
debate. Public sentiment plays a critical role in diplomacy, as a good
sentiment provides vital support for policy implementation, helps resolve
international issues, and shapes a nation's international image. Traditional
methods for gauging public sentiment, such as large-scale surveys or manual
content analysis of media, are typically time-consuming, labor-intensive, and
lack the capacity for forward-looking analysis. We propose a novel framework
that identifies specific modifications for diplomatic event narratives to shift
public sentiment from negative to neutral or positive. First, we train a
language model to predict public reaction towards diplomatic events. To this
end, we construct a dataset comprising descriptions of diplomatic events and
their associated public discussions. Second, guided by communication theories
and in collaboration with domain experts, we predetermined several textual
features for modification, ensuring that any alterations changed the event's
narrative framing while preserving its core facts.We develop a counterfactual
generation algorithm that employs a large language model to systematically
produce modified versions of an original text. The results show that this
framework successfully shifted public sentiment to a more favorable state with
a 70\% success rate. This framework can therefore serve as a practical tool for
diplomats, policymakers, and communication specialists, offering data-driven
insights on how to frame diplomatic initiatives or report on events to foster a
more desirable public sentiment.

</details>


### [2] [Speaker Style-Aware Phoneme Anchoring for Improved Cross-Lingual Speech Emotion Recognition](https://arxiv.org/abs/2509.20373)
*Shreya G. Upadhyay,Carlos Busso,Chi-Chun Lee*

Main category: cs.CL

TL;DR: 本文提出了一种跨语言语音情感识别（SER）的框架，该框架通过在音标和说话人层面进行对齐来解决跨语言情感识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 跨语言语音情感识别由于不同语言在语音变异性和说话人特定表达风格上的差异而仍然是一项具有挑战性的任务。在如此多样的条件下有效捕捉情感需要一个能够对齐不同说话人和语言的情感外化的框架。

Method: 我们提出了一个说话人风格感知的音素锚定框架，该框架在音标和说话人层面进行情感表达的对齐。我们的方法通过基于图的聚类构建情感特定的说话人社区，以捕捉共享的说话人特征。使用这些群体，我们在说话人和语音空间中应用双空间锚定，以实现更好的跨语言情感迁移。

Result: 在MSP-Podcast（英语）和BIIC-Podcast（台湾普通话）语料库上的评估表明，与竞争基线相比，泛化能力有所提高，并为跨语言情感表示的共性提供了有价值的见解。

Conclusion: 本文提出了一个说话人风格感知的音素锚定框架，该框架通过在音标和说话人层面进行对齐来解决跨语言情感识别的挑战，实验结果表明，该方法在跨语言情感识别方面具有良好的性能。

Abstract: Cross-lingual speech emotion recognition (SER) remains a challenging task due
to differences in phonetic variability and speaker-specific expressive styles
across languages. Effectively capturing emotion under such diverse conditions
requires a framework that can align the externalization of emotions across
different speakers and languages. To address this problem, we propose a
speaker-style aware phoneme anchoring framework that aligns emotional
expression at the phonetic and speaker levels. Our method builds
emotion-specific speaker communities via graph-based clustering to capture
shared speaker traits. Using these groups, we apply dual-space anchoring in
speaker and phonetic spaces to enable better emotion transfer across languages.
Evaluations on the MSP-Podcast (English) and BIIC-Podcast (Taiwanese Mandarin)
corpora demonstrate improved generalization over competitive baselines and
provide valuable insights into the commonalities in cross-lingual emotion
representation.

</details>


### [3] [CFD-LLMBench: A Benchmark Suite for Evaluating Large Language Models in Computational Fluid Dynamics](https://arxiv.org/abs/2509.20374)
*Nithin Somasekharan,Ling Yue,Yadi Cao,Weichao Li,Patrick Emami,Pochinapeddi Sai Bhargav,Anurag Acharya,Xingyu Xie,Shaowu Pan*

Main category: cs.CL

TL;DR: 本文介绍了一个名为CFDLLMBench的基准测试套件，用于评估大型语言模型（LLM）在计算流体动力学（CFD）领域的性能。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在自动化复杂物理系统数值实验中的应用，特别是在计算流体动力学（CFD）这一关键领域。

Method: 构建CFDLLMBench基准测试套件，包含CFDQuery, CFDCodeBench, 和 FoamBench三个互补组件，用于评估LLM在CFD知识、数值和物理推理以及工作流程实现方面的能力。

Result: CFDLLMBench提供了一个详细的任务分类和严格的评估框架，可以重现结果并量化LLM在代码可执行性、解决方案准确性和数值收敛行为方面的性能。

Conclusion: CFDLLMBench为开发和评估LLM驱动的复杂物理系统数值实验自动化奠定了坚实的基础。

Abstract: Large Language Models (LLMs) have demonstrated strong performance across
general NLP tasks, but their utility in automating numerical experiments of
complex physical system -- a critical and labor-intensive component -- remains
underexplored. As the major workhorse of computational science over the past
decades, Computational Fluid Dynamics (CFD) offers a uniquely challenging
testbed for evaluating the scientific capabilities of LLMs. We introduce
CFDLLMBench, a benchmark suite comprising three complementary components --
CFDQuery, CFDCodeBench, and FoamBench -- designed to holistically evaluate LLM
performance across three key competencies: graduate-level CFD knowledge,
numerical and physical reasoning of CFD, and context-dependent implementation
of CFD workflows. Grounded in real-world CFD practices, our benchmark combines
a detailed task taxonomy with a rigorous evaluation framework to deliver
reproducible results and quantify LLM performance across code executability,
solution accuracy, and numerical convergence behavior. CFDLLMBench establishes
a solid foundation for the development and evaluation of LLM-driven automation
of numerical experiments for complex physical systems. Code and data are
available at https://github.com/NREL-Theseus/cfdllmbench/.

</details>


### [4] [Assessing Classical Machine Learning and Transformer-based Approaches for Detecting AI-Generated Research Text](https://arxiv.org/abs/2509.20375)
*Sharanya Parimanoharan,Ruwan D. Nawarathna*

Main category: cs.CL

TL;DR: 探讨了使用机器学习方法检测ChatGPT生成的文本，以应对学术诚信和信息传播的挑战。


<details>
  <summary>Details</summary>
Motivation: 需要可靠的AI文本检测来维护学术诚信和数字通信的信任。

Method: 比较了经典机器学习方法（如逻辑回归）和基于Transformer的模型（如BERT、DistilBERT）在区分ChatGPT生成文本和人类文本方面的性能。

Result: DistilBERT表现最佳，而逻辑回归和BERT-Custom提供了稳健的替代方案。集成模型未能超越DistilBERT本身。

Conclusion: 该研究为开发更强大的Transformer框架奠定了基础，以应对不断改进的生成式AI模型。

Abstract: The rapid adoption of large language models (LLMs) such as ChatGPT has
blurred the line between human and AI-generated texts, raising urgent questions
about academic integrity, intellectual property, and the spread of
misinformation. Thus, reliable AI-text detection is needed for fair assessment
to safeguard human authenticity and cultivate trust in digital communication.
In this study, we investigate how well current machine learning (ML) approaches
can distinguish ChatGPT-3.5-generated texts from human-written texts employing
a labeled data set of 250 pairs of abstracts from a wide range of research
topics. We test and compare both classical (Logistic Regression armed with
classical Bag-of-Words, POS, and TF-IDF features) and transformer-based (BERT
augmented with N-grams, DistilBERT, BERT with a lightweight custom classifier,
and LSTM-based N-gram models) ML detection techniques. As we aim to assess each
model's performance in detecting AI-generated research texts, we also aim to
test whether an ensemble of these models can outperform any single detector.
Results show DistilBERT achieves the overall best performance, while Logistic
Regression and BERT-Custom offer solid, balanced alternatives; LSTM- and
BERT-N-gram approaches lag. The max voting ensemble of the three best models
fails to surpass DistilBERT itself, highlighting the primacy of a single
transformer-based representation over mere model diversity. By comprehensively
assessing the strengths and weaknesses of these AI-text detection approaches,
this work lays a foundation for more robust transformer frameworks with larger,
richer datasets to keep pace with ever-improving generative AI models.

</details>


### [5] [ConceptViz: A Visual Analytics Approach for Exploring Concepts in Large Language Models](https://arxiv.org/abs/2509.20376)
*Haoxuan Li,Zhen Wen,Qiqi Jiang,Chenxiao Li,Yuwei Wu,Yuchen Yang,Yiyao Wang,Xiuqi Huang,Minfeng Zhu,Wei Chen*

Main category: cs.CL

TL;DR: ConceptViz是一个用于探索LLM概念的可视分析系统，旨在弥合SAE特征和人类概念之间的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管稀疏自动编码器(SAE)已成为从llm中提取可解释特征的有前途的技术，但SAE特征并不天然地与人类可理解的概念对齐，这使得它们的解释繁琐且费力。

Method: ConceptViz实现了一种新颖的Identification => Interpretation => Validation管道，使用户能够使用感兴趣的概念查询sae，交互式地探索概念到特征的对齐，并通过模型行为验证来验证对应关系。

Result: 通过两个使用场景和一个用户研究证明了ConceptViz的有效性。结果表明，ConceptViz通过简化LLM中有意义的概念表示的发现和验证，从而增强了解释性研究，最终帮助研究人员构建更准确的LLM特征心理模型。

Conclusion: ConceptViz通过简化LLM中有意义的概念表示的发现和验证，从而增强了解释性研究，最终帮助研究人员构建更准确的LLM特征心理模型。

Abstract: Large language models (LLMs) have achieved remarkable performance across a
wide range of natural language tasks. Understanding how LLMs internally
represent knowledge remains a significant challenge. Despite Sparse
Autoencoders (SAEs) have emerged as a promising technique for extracting
interpretable features from LLMs, SAE features do not inherently align with
human-understandable concepts, making their interpretation cumbersome and
labor-intensive. To bridge the gap between SAE features and human concepts, we
present ConceptViz, a visual analytics system designed for exploring concepts
in LLMs. ConceptViz implements a novel dentification => Interpretation =>
Validation pipeline, enabling users to query SAEs using concepts of interest,
interactively explore concept-to-feature alignments, and validate the
correspondences through model behavior verification. We demonstrate the
effectiveness of ConceptViz through two usage scenarios and a user study. Our
results show that ConceptViz enhances interpretability research by streamlining
the discovery and validation of meaningful concept representations in LLMs,
ultimately aiding researchers in building more accurate mental models of LLM
features. Our code and user guide are publicly available at
https://github.com/Happy-Hippo209/ConceptViz.

</details>


### [6] [SKILL-RAG: Self-Knowledge Induced Learning and Filtering for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20377)
*Tomoaki Isoda*

Main category: cs.CL

TL;DR: SKILL-RAG利用模型自身的知识来判断哪些检索到的文档对回答问题有益，从而提高RAG的性能。


<details>
  <summary>Details</summary>
Motivation: 检索系统可能会返回不相关的内容，将这些信息纳入模型通常会导致幻觉。因此，识别和过滤掉无用的检索内容是提高RAG性能的关键挑战。

Method: SKILL-RAG利用模型自身的知识来确定哪些检索到的文档对回答给定的查询有益。我们设计了一个基于强化学习的训练框架，以明确地从模型中提取自我知识，并采用句子级的粒度来过滤掉不相关的内容，同时保留有用的知识。

Result: SKILL-RAG不仅提高了生成质量，而且显著减少了输入文档的数量。

Conclusion: 自我知识在指导高质量检索的选择中非常重要。

Abstract: Retrieval-Augmented Generation (RAG) has significantly improved the
performance of large language models (LLMs) on knowledge-intensive tasks in
recent years. However, since retrieval systems may return irrelevant content,
incorporating such information into the model often leads to hallucinations.
Thus, identifying and filtering out unhelpful retrieved content is a key
challenge for improving RAG performance.To better integrate the internal
knowledge of the model with external knowledge from retrieval, it is essential
to understand what the model "knows" and "does not know" (which is also called
"self-knowledge"). Based on this insight, we propose SKILL-RAG (Self-Knowledge
Induced Learning and Filtering for RAG), a novel method that leverages the
model's self-knowledge to determine which retrieved documents are beneficial
for answering a given query. We design a reinforcement learning-based training
framework to explicitly elicit self-knowledge from the model and employs
sentence-level granularity to filter out irrelevant content while preserving
useful knowledge.We evaluate SKILL-RAG using Llama2-7B and Qwen3-8B on several
question answering benchmarks. Experimental results demonstrate that SKILL-RAG
not only improves generation quality but also significantly reduces the number
of input documents, validating the importance of self-knowledge in guiding the
selection of high-quality retrievals.

</details>


### [7] [Beyond Global Emotion: Fine-Grained Emotional Speech Synthesis with Dynamic Word-Level Modulation](https://arxiv.org/abs/2509.20378)
*Sirui Wang,Andong Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: Emo-FiLM: A novel framework for fine-grained emotion control in LLM-based TTS.


<details>
  <summary>Details</summary>
Motivation: Existing E-TTS systems lack the ability to capture dynamic emotional shifts within a sentence, relying on global emotion control.

Method: Emo-FiLM aligns frame-level features from emotion2vec to words for word-level emotion annotation, and uses a Feature-wise Linear Modulation (FiLM) layer to control emotion by modulating text embeddings. A new dataset, FEDD, was constructed for evaluation.

Result: Emo-FiLM outperforms existing methods on both global and fine-grained emotion tasks.

Conclusion: Emo-FiLM is effective and general for expressive speech synthesis.

Abstract: Emotional text-to-speech (E-TTS) is central to creating natural and
trustworthy human-computer interaction. Existing systems typically rely on
sentence-level control through predefined labels, reference audio, or natural
language prompts. While effective for global emotion expression, these
approaches fail to capture dynamic shifts within a sentence. To address this
limitation, we introduce Emo-FiLM, a fine-grained emotion modeling framework
for LLM-based TTS. Emo-FiLM aligns frame-level features from emotion2vec to
words to obtain word-level emotion annotations, and maps them through a
Feature-wise Linear Modulation (FiLM) layer, enabling word-level emotion
control by directly modulating text embeddings. To support evaluation, we
construct the Fine-grained Emotion Dynamics Dataset (FEDD) with detailed
annotations of emotional transitions. Experiments show that Emo-FiLM
outperforms existing approaches on both global and fine-grained tasks,
demonstrating its effectiveness and generality for expressive speech synthesis.

</details>


### [8] [USB-Rec: An Effective Framework for Improving Conversational Recommendation Capability of Large Language Model](https://arxiv.org/abs/2509.20381)
*Jianyu Wen,Jingyun Wang,Cilin Yan,Jiayin Cai,Xiaolong Jiang,Ying Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种针对LLM在对话式推荐系统中应用的集成训练-推理框架 (USB-Rec)。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法主要集中在如何利用LLM的总结和分析能力，而忽略了训练问题。

Method: 首先，设计了一种基于LLM的偏好优化 (PO) 数据集构建策略用于强化学习训练，帮助LLM理解对话式推荐中的策略和方法。其次，在推理阶段提出了一种自我增强策略 (SES)，以进一步挖掘从强化学习训练中获得的对话式推荐潜力。

Result: 在各种数据集上的大量实验表明，该方法始终优于以前的state-of-the-art方法。

Conclusion: 该文提出了一种新的训练-推理框架，有效地提升了LLM在对话式推荐系统中的性能。

Abstract: Recently, Large Language Models (LLMs) have been widely employed in
Conversational Recommender Systems (CRSs). Unlike traditional language model
approaches that focus on training, all existing LLMs-based approaches are
mainly centered around how to leverage the summarization and analysis
capabilities of LLMs while ignoring the issue of training. Therefore, in this
work, we propose an integrated training-inference framework,
User-Simulator-Based framework (USB-Rec), for improving the performance of LLMs
in conversational recommendation at the model level. Firstly, we design a
LLM-based Preference Optimization (PO) dataset construction strategy for RL
training, which helps the LLMs understand the strategies and methods in
conversational recommendation. Secondly, we propose a Self-Enhancement Strategy
(SES) at the inference stage to further exploit the conversational
recommendation potential obtained from RL training. Extensive experiments on
various datasets demonstrate that our method consistently outperforms previous
state-of-the-art methods.

</details>


### [9] [Document Summarization with Conformal Importance Guarantees](https://arxiv.org/abs/2509.20461)
*Bruce Kuwahara,Chen-Yuan Lin,Xiao Shi Huang,Kin Kwan Leung,Jullian Arta Yapeter,Ilya Stanevich,Felipe Perez,Jesse C. Cresswell*

Main category: cs.CL

TL;DR: 本文介绍了一种名为 Conformal Importance Summarization 的框架，用于生成重要性保留的摘要，该框架使用 conformal prediction 来提供严格的、无分布的覆盖保证。


<details>
  <summary>Details</summary>
Motivation: 现有的自动摘要系统，特别是基于大型语言模型 (LLM) 的系统，在高风险领域（如医疗保健、法律和金融）中，仍然缺乏对关键内容包含的可靠保证。

Method: 通过校准句子级别重要性分数的阈值，该方法实现了可提取的文档摘要，并具有用户指定的覆盖率和关键内容召回率。该方法是模型无关的，只需要一个小的校准集，并且可以与现有的黑盒 LLM 无缝集成。

Result: 在已建立的摘要基准上的实验表明，Conformal Importance Summarization 实现了理论上保证的信息覆盖率。

Conclusion: Conformal Importance Summarization 可以与现有技术相结合，以实现可靠、可控的自动摘要，为在关键应用中更安全地部署 AI 摘要工具铺平了道路。

Abstract: Automatic summarization systems have advanced rapidly with large language
models (LLMs), yet they still lack reliable guarantees on inclusion of critical
content in high-stakes domains like healthcare, law, and finance. In this work,
we introduce Conformal Importance Summarization, the first framework for
importance-preserving summary generation which uses conformal prediction to
provide rigorous, distribution-free coverage guarantees. By calibrating
thresholds on sentence-level importance scores, we enable extractive document
summarization with user-specified coverage and recall rates over critical
content. Our method is model-agnostic, requires only a small calibration set,
and seamlessly integrates with existing black-box LLMs. Experiments on
established summarization benchmarks demonstrate that Conformal Importance
Summarization achieves the theoretically assured information coverage rate. Our
work suggests that Conformal Importance Summarization can be combined with
existing techniques to achieve reliable, controllable automatic summarization,
paving the way for safer deployment of AI summarization tools in critical
applications. Code is available at
https://github.com/layer6ai-labs/conformal-importance-summarization.

</details>


### [10] [SwasthLLM: a Unified Cross-Lingual, Multi-Task, and Meta-Learning Zero-Shot Framework for Medical Diagnosis Using Contrastive Representations](https://arxiv.org/abs/2509.20567)
*Ayan Sar,Pranav Singh Puri,Sumit Aich,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: SwasthLLM: A zero-shot cross-lingual multi-task learning framework for medical diagnosis in English, Hindi, and Bengali.


<details>
  <summary>Details</summary>
Motivation: Automatic disease diagnosis from clinical text in multilingual healthcare is challenging due to data scarcity in low-resource languages and linguistic variability.

Method: Uses XLM-RoBERTa with language-aware attention, Siamese contrastive learning, translation consistency, and MAML for rapid adaptation.

Result: Achieves 97.22% accuracy and 97.17% F1-score in supervised settings, and 92.78% accuracy on Hindi and 73.33% on Bengali in zero-shot scenarios.

Conclusion: SwasthLLM demonstrates strong generalization in low-resource contexts.

Abstract: In multilingual healthcare environments, automatic disease diagnosis from
clinical text remains a challenging task due to the scarcity of annotated
medical data in low-resource languages and the linguistic variability across
populations. This paper proposes SwasthLLM, a unified, zero-shot,
cross-lingual, and multi-task learning framework for medical diagnosis that
operates effectively across English, Hindi, and Bengali without requiring
language-specific fine-tuning. At its core, SwasthLLM leverages the
multilingual XLM-RoBERTa encoder augmented with a language-aware attention
mechanism and a disease classification head, enabling the model to extract
medically relevant information regardless of the language structure. To align
semantic representations across languages, a Siamese contrastive learning
module is introduced, ensuring that equivalent medical texts in different
languages produce similar embeddings. Further, a translation consistency module
and a contrastive projection head reinforce language-invariant representation
learning. SwasthLLM is trained using a multi-task learning strategy, jointly
optimizing disease classification, translation alignment, and contrastive
learning objectives. Additionally, we employ Model-Agnostic Meta-Learning
(MAML) to equip the model with rapid adaptation capabilities for unseen
languages or tasks with minimal data. Our phased training pipeline emphasizes
robust representation alignment before task-specific fine-tuning. Extensive
evaluation shows that SwasthLLM achieves high diagnostic performance, with a
test accuracy of 97.22% and an F1-score of 97.17% in supervised settings.
Crucially, in zero-shot scenarios, it attains 92.78% accuracy on Hindi and
73.33% accuracy on Bengali medical text, demonstrating strong generalization in
low-resource contexts.

</details>


### [11] [ShortCheck: Checkworthiness Detection of Multilingual Short-Form Videos](https://arxiv.org/abs/2509.20467)
*Henrik Vatndal,Vinay Setty*

Main category: cs.CL

TL;DR: ShortCheck is a system for automatically identifying checkworthy short-form videos.


<details>
  <summary>Details</summary>
Motivation: Misinformation detection in short-form videos is challenging due to their multimodal, dynamic, and noisy content.

Method: A modular, inference-only pipeline integrating speech transcription, OCR, object and deepfake detection, video-to-text summarization, and claim verification.

Result: Achieves promising results with F1-weighted score over 70% on two manually annotated datasets with TikTok videos in a multilingual setting.

Conclusion: ShortCheck helps human fact-checkers by automatically identifying checkworthy short-form videos.

Abstract: Short-form video platforms like TikTok present unique challenges for
misinformation detection due to their multimodal, dynamic, and noisy content.
We present ShortCheck, a modular, inference-only pipeline with a user-friendly
interface that automatically identifies checkworthy short-form videos to help
human fact-checkers. The system integrates speech transcription, OCR, object
and deepfake detection, video-to-text summarization, and claim verification.
ShortCheck is validated by evaluating it on two manually annotated datasets
with TikTok videos in a multilingual setting. The pipeline achieves promising
results with F1-weighted score over 70\%.

</details>


### [12] [Dynamic Reasoning Chains through Depth-Specialized Mixture-of-Experts in Transformer Architectures](https://arxiv.org/abs/2509.20577)
*Sampurna Roy,Ayan Sar,Anurag Kaushish,Kanav Gupta,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出了一种新的深度自适应Transformer架构DS-MoE，通过动态路由选择不同深度的专家模块来处理不同复杂度的输入，从而提高效率、推理质量和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer对所有输入应用相同的处理深度，导致效率低下并限制了推理质量。

Method: 提出了深度专业化混合专家（DS-MoE）框架，该框架将混合专家范式从基于宽度的计算扩展到深度专业化计算。DS-MoE引入了针对不同推理深度优化的专家模块，并通过学习到的路由网络动态组装自定义推理链。

Result: DS-MoE与uniform-depth transformers相比，实现了高达16%的计算节省和35%的更快推理，同时在复杂的多步骤推理基准测试中提供了2.8%的更高准确率。

Conclusion: DS-MoE是一种自适应神经架构的重大进步，证明了深度专业化的模块化处理可以同时提高大规模语言模型的效率、推理质量和可解释性。

Abstract: Contemporary transformer architectures apply identical processing depth to
all inputs, creating inefficiencies and limiting reasoning quality. Simple
factual queries are subjected to the same multilayered computation as complex
logical problems, wasting resources while constraining deep inference. To
overcome this, we came up with a concept of Dynamic Reasoning Chains through
Depth Specialised Mixture of Experts (DS-MoE), a modular framework that extends
the Mixture of Experts paradigm from width-based to depth specialised
computation. DS-MoE introduces expert modules optimised for distinct reasoning
depths, shallow pattern recognition, compositional reasoning, logical
inference, memory integration, and meta-cognitive supervision. A learned
routing network dynamically assembles custom reasoning chains, activating only
the necessary experts to match input complexity. The dataset on which we
trained and evaluated DS-MoE is on The Pile, an 800GB corpus covering diverse
domains such as scientific papers, legal texts, programming code, and web
content, enabling systematic assessment across reasoning depths. Experimental
results demonstrate that DS-MoE achieves up to 16 per cent computational
savings and 35 per cent faster inference compared to uniform-depth
transformers, while delivering 2.8 per cent higher accuracy on complex
multi-step reasoning benchmarks. Furthermore, routing decisions yield
interpretable reasoning chains, enhancing transparency and scalability. These
findings establish DS-MoE as a significant advancement in adaptive neural
architectures, demonstrating that depth-specialised modular processing can
simultaneously improve efficiency, reasoning quality, and interpretability in
large-scale language models.

</details>


### [13] [MARS: toward more efficient multi-agent collaboration for LLM reasoning](https://arxiv.org/abs/2509.20502)
*Xiao Wang,Jia Wang,Yijie Wang,Pengtao Dang,Sha Cao,Chi Zhang*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为MARS（多智能体审查系统）的框架，旨在提高大型语言模型（LLM）的推理能力，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论（MAD）方法虽然有效，但由于涉及大量智能体和频繁的通信，计算开销巨大。这篇论文旨在解决这个问题。

Method: 论文提出MARS框架，该框架模仿审查过程，其中作者智能体生成初始解决方案，审查者智能体独立提供决策和评论，元审查者整合反馈以做出最终决策并指导进一步修改。

Result: 实验结果表明，MARS在多个基准测试中与MAD的准确性相匹配，同时减少了约50%的token使用和推理时间。

Conclusion: MARS框架能够在提高推理质量的同时，有效控制token消耗和推理时间，从而优于现有的多智能体辩论方法。

Abstract: Large language models (LLMs) have achieved impressive results in natural
language understanding, yet their reasoning capabilities remain limited when
operating as single agents. Multi-Agent Debate (MAD) has been proposed to
address this limitation by enabling collaborative reasoning among multiple
models in a round-table debate manner. While effective, MAD introduces
substantial computational overhead due to the number of agents involved and the
frequent communication required. In this paper, we propose MARS (Multi-Agent
Review System), a role-based collaboration framework inspired by the review
process. In MARS, an author agent generates an initial solution, reviewer
agents provide decisions and comments independently, and a meta-reviewer
integrates the feedback to make the final decision and guide further revision.
This design enhances reasoning quality while avoiding costly
reviewer-to-reviewer interactions, thereby controlling token consumption and
inference time. We compared MARS with both MAD and other state-of-the-art
reasoning strategies across multiple benchmarks. Extensive experiments with
different LLMs show that MARS matches the accuracy of MAD while reducing both
token usage and inference time by approximately 50\%. Code is available at
https://github.com/xwang97/MARS.

</details>


### [14] [Hierarchical Resolution Transformers: A Wavelet-Inspired Architecture for Multi-Scale Language Understanding](https://arxiv.org/abs/2509.20581)
*Ayan Sar,Sampurna Roy,Kanav Gupta,Anurag Kaushish,Tanupriya Choudhury,Abhijit Kumar*

Main category: cs.CL

TL;DR: 提出了层级分辨率Transformer（HRT），一种受小波变换启发的神经架构，可以跨多个分辨率同时处理语言。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在自然语言任务中表现出色，但它将文本处理为扁平的token序列，从而错误地表示了人类语言的层级结构，导致计算成本高、组合泛化能力弱以及话语层面建模不足。

Method: HRT构建了一种多分辨率注意力机制，支持自下而上的组合和自上而下的情境化。通过在不同尺度上采用指数序列缩减，HRT实现了O(nlogn)的复杂度。

Result: 在GLUE、SuperGLUE和Long Range Arena等基准测试中，HRT优于标准的transformer，在GLUE上平均提升+3.8%，在SuperGLUE上平均提升+4.5%，在Long Range Arena上平均提升+6.1%，同时内存使用量减少了42%，推理延迟减少了37%。

Conclusion: HRT是第一个将计算结构与人类语言的层级组织对齐的架构，证明了多尺度、受小波变换启发的处理方法可以提高理论效率和语言理解的实际改进。

Abstract: Transformer architectures have achieved state-of-the-art performance across
natural language tasks, yet they fundamentally misrepresent the hierarchical
nature of human language by processing text as flat token sequences. This
results in quadratic computational cost, weak computational cost, weak
compositional generalization, and inadequate discourse-level modeling. We
propose Hierarchical Resolution Transformer (HRT), a novel wavelet-inspired
neural architecture that processes language simultaneously across multiple
resolutions, from characters to discourse-level units. HRT constructs a
multi-resolution attention, enabling bottom-up composition and top-down
contextualization. By employing exponential sequence reduction across scales,
HRT achieves O(nlogn) complexity, offering significant efficiency improvements
over standard transformers. We evaluated HRT on a diverse suite of benchmarks,
including GLUE, SuperGLUE, Long Range Arena, and WikiText-103, and results
demonstrated that HRT outperforms standard transformer baselines by an average
of +3.8% on GLUE, +4.5% on SuperGLUE, and +6.1% on Long Range Arena, while
reducing memory usage by 42% and inference latency by 37% compared to BERT and
GPT style models of similar parameter count. Ablation studies confirm the
effectiveness of cross-resolution attention and scale-specialized modules,
showing that each contributes independently to both efficiency and accuracy.
Our findings establish HRT as the first architecture to align computational
structure with the hierarchical organization of human language, demonstrating
that multi-scale, wavelet-inspired processing yields both theoretical
efficiency gains and practical improvements in language understanding.

</details>


### [15] [SiniticMTError: A Machine Translation Dataset with Error Annotations for Sinitic Languages](https://arxiv.org/abs/2509.20557)
*Hannah Liu,Junghyun Min,Ethan Yue Heng Cheung,Shou-Yi Hung,Syed Mekael Wasti,Runtong Liang,Shiyao Qian,Shizhao Zheng,Elsie Chan,Ka Ieng Charlotte Lo,Wing Yu Yip,Richard Tzong-Han Tsai,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: SiniticMTError是一个新的数据集，它建立在现有的平行语料库之上，以提供从英语到普通话、粤语和吴语的机器翻译示例中的错误跨度、错误类型和错误严重程度注释。


<details>
  <summary>Details</summary>
Motivation: 近年来，机器翻译(MT)取得了重大进展，但对于许多缺乏大规模训练数据和语言资源的低资源语言来说，进展仍然有限。粤语和吴语是两个汉藏语系的例子，尽管每种语言在世界各地都有超过8000万的使用者。

Method: 构建了一个名为SiniticMTError的新数据集，该数据集建立在现有的并行语料库之上，以提供机器翻译示例中的错误跨度、错误类型和错误严重程度注释。

Result: 报告了母语人士严格的注释过程，分析了注释者间协议、迭代反馈以及错误类型和严重程度的模式。

Conclusion: 该数据集可以作为MT社区的资源，用于微调具有错误检测能力的模型，支持翻译质量评估、错误感知生成和低资源语言评估方面的研究。

Abstract: Despite major advances in machine translation (MT) in recent years, progress
remains limited for many low-resource languages that lack large-scale training
data and linguistic resources. Cantonese and Wu Chinese are two Sinitic
examples, although each enjoys more than 80 million speakers around the world.
In this paper, we introduce SiniticMTError, a novel dataset that builds on
existing parallel corpora to provide error span, error type, and error severity
annotations in machine-translated examples from English to Mandarin, Cantonese,
and Wu Chinese. Our dataset serves as a resource for the MT community to
utilize in fine-tuning models with error detection capabilities, supporting
research on translation quality estimation, error-aware generation, and
low-resource language evaluation. We report our rigorous annotation process by
native speakers, with analyses on inter-annotator agreement, iterative
feedback, and patterns in error type and severity.

</details>


### [16] [Few-Shot and Training-Free Review Generation via Conversational Prompting](https://arxiv.org/abs/2509.20805)
*Genki Kusano*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Conversational Prompting 的轻量级方法，用于在用户评论较少且无法进行模型训练的情况下生成个性化评论。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设目标用户有大量的评论历史或需要额外的模型训练，但在实际应用中，往往面临用户评论较少且无法进行微调的情况。

Method: 该方法将用户评论重新构建为多轮对话，包括仅依赖用户自身评论的 Simple Conversational Prompting (SCP) 和插入其他用户或 LLM 的评论作为错误回复，然后要求模型纠正它们的 Contrastive Conversational Prompting (CCP)。

Result: 在八个产品领域和五个 LLM 上的实验表明，传统的非对话提示通常会生成类似于随机用户编写的评论，而 SCP 和 CCP 生成的评论更接近目标用户。

Conclusion: 对话提示为在少样本和免训练约束下生成评论提供了一种实用的解决方案。

Abstract: Personalized review generation helps businesses understand user preferences,
yet most existing approaches assume extensive review histories of the target
user or require additional model training. Real-world applications often face
few-shot and training-free situations, where only a few user reviews are
available and fine-tuning is infeasible. It is well known that large language
models (LLMs) can address such low-resource settings, but their effectiveness
depends on prompt engineering. In this paper, we propose Conversational
Prompting, a lightweight method that reformulates user reviews as multi-turn
conversations. Its simple variant, Simple Conversational Prompting (SCP),
relies solely on the user's own reviews, while the contrastive variant,
Contrastive Conversational Prompting (CCP), inserts reviews from other users or
LLMs as incorrect replies and then asks the model to correct them, encouraging
the model to produce text in the user's style. Experiments on eight product
domains and five LLMs showed that the conventional non-conversational prompt
often produced reviews similar to those written by random users, based on
text-based metrics such as ROUGE-L and BERTScore, and application-oriented
tasks like user identity matching and sentiment analysis. In contrast, both SCP
and CCP produced reviews much closer to those of the target user, even when
each user had only two reviews. CCP brings further improvements when
high-quality negative examples are available, whereas SCP remains competitive
when such data cannot be collected. These results suggest that conversational
prompting offers a practical solution for review generation under few-shot and
training-free constraints.

</details>


### [17] [BESPOKE: Benchmark for Search-Augmented Large Language Model Personalization via Diagnostic Feedback](https://arxiv.org/abs/2509.21106)
*Hyunseo Kim,Sangam Lee,Kwangwook Seo,Dongha Lee*

Main category: cs.CL

TL;DR: 本文提出了BESPOKE，一个用于评估搜索增强型LLM中个性化的基准。


<details>
  <summary>Details</summary>
Motivation: 现有的搜索增强型LLM在满足多样化的用户需求方面仍有不足，未能充分识别同一查询背后不同用户的意图，并且缺乏对个性化效果的系统评估。

Method: 通过收集真实的用户聊天和搜索历史，并进行细粒度的偏好评分和反馈，构建了一个现实且具有诊断性的基准。

Result: 利用BESPOKE，系统分析揭示了在信息搜索任务中实现有效个性化的关键需求。

Conclusion: 该研究为个性化搜索增强型LLM的细粒度评估奠定了基础。

Abstract: Search-augmented large language models (LLMs) have advanced
information-seeking tasks by integrating retrieval into generation, reducing
users' cognitive burden compared to traditional search systems. Yet they remain
insufficient for fully addressing diverse user needs, which requires
recognizing how the same query can reflect different intents across users and
delivering information in preferred forms. While recent systems such as ChatGPT
and Gemini attempt personalization by leveraging user histories, systematic
evaluation of such personalization is under-explored. To address this gap, we
propose BESPOKE, the realistic benchmark for evaluating personalization in
search-augmented LLMs. BESPOKE is designed to be both realistic, by collecting
authentic chat and search histories directly from humans, and diagnostic, by
pairing responses with fine-grained preference scores and feedback. The
benchmark is constructed through long-term, deeply engaged human annotation,
where human annotators contributed their own histories, authored queries with
detailed information needs, and evaluated responses with scores and diagnostic
feedback. Leveraging BESPOKE, we conduct systematic analyses that reveal key
requirements for effective personalization in information-seeking tasks,
providing a foundation for fine-grained evaluation of personalized
search-augmented LLMs. Our code and data are available at
https://augustinlib.github.io/BESPOKE/.

</details>


### [18] [Retrieval over Classification: Integrating Relation Semantics for Multimodal Relation Extraction](https://arxiv.org/abs/2509.21151)
*Lei Hei,Tingjing Liao,Yingxin Pei,Yiyang Qi,Jiaqi Wang,Ruiting Li,Feiliang Ren*

Main category: cs.CL

TL;DR: 本文提出了一种新的多模态关系抽取框架ROC，它将关系抽取任务转化为基于关系语义的检索任务，并取得了state-of-the-art的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了实体类型和位置线索等结构约束，并且缺乏细粒度关系理解的语义表达能力。

Method: ROC框架通过多模态编码器整合实体类型和位置信息，使用大型语言模型将关系标签扩展为自然语言描述，并通过基于语义相似度的对比学习对齐实体-关系对。

Result: 实验表明，该方法在MNRE和MORE基准数据集上取得了state-of-the-art的性能，并表现出更强的鲁棒性和可解释性。

Conclusion: 本文提出的ROC框架有效地解决了传统多模态关系抽取方法的局限性，并在实验中取得了显著的性能提升。

Abstract: Relation extraction (RE) aims to identify semantic relations between entities
in unstructured text. Although recent work extends traditional RE to multimodal
scenarios, most approaches still adopt classification-based paradigms with
fused multimodal features, representing relations as discrete labels. This
paradigm has two significant limitations: (1) it overlooks structural
constraints like entity types and positional cues, and (2) it lacks semantic
expressiveness for fine-grained relation understanding. We propose
\underline{R}etrieval \underline{O}ver \underline{C}lassification (ROC), a
novel framework that reformulates multimodal RE as a retrieval task driven by
relation semantics. ROC integrates entity type and positional information
through a multimodal encoder, expands relation labels into natural language
descriptions using a large language model, and aligns entity-relation pairs via
semantic similarity-based contrastive learning. Experiments show that our
method achieves state-of-the-art performance on the benchmark datasets MNRE and
MORE and exhibits stronger robustness and interpretability.

</details>


### [19] [SGMem: Sentence Graph Memory for Long-Term Conversational Agents](https://arxiv.org/abs/2509.21212)
*Yaxiong Wu,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 论文提出了一种名为SGMem的新型记忆管理方法，用于处理长程对话Agent中的对话历史。


<details>
  <summary>Details</summary>
Motivation: 现有的方法无法有效地组织和检索不同粒度的对话信息。

Method: 将对话表示为句子级别的图，并结合检索到的原始对话和生成的记忆，为LLM提供连贯和相关的上下文。

Result: 在LongMemEval和LoCoMo数据集上，SGMem持续提高了准确率，并优于强大的基线模型。

Conclusion: SGMem 是一种有效的长程对话记忆管理方法。

Abstract: Long-term conversational agents require effective memory management to handle
dialogue histories that exceed the context window of large language models
(LLMs). Existing methods based on fact extraction or summarization reduce
redundancy but struggle to organize and retrieve relevant information across
different granularities of dialogue and generated memory. We introduce SGMem
(Sentence Graph Memory), which represents dialogue as sentence-level graphs
within chunked units, capturing associations across turn-, round-, and
session-level contexts. By combining retrieved raw dialogue with generated
memory such as summaries, facts and insights, SGMem supplies LLMs with coherent
and relevant context for response generation. Experiments on LongMemEval and
LoCoMo show that SGMem consistently improves accuracy and outperforms strong
baselines in long-term conversational question answering.

</details>


### [20] [FS-DFM: Fast and Accurate Long Text Generation with Few-Step Diffusion Language Models](https://arxiv.org/abs/2509.20624)
*Amin Karimi Monsefi,Nikhil Bhendawade,Manuel Rafael Ciosici,Dominic Culver,Yizhe Zhang,Irina Belousova*

Main category: cs.CL

TL;DR: FS-DFM模型通过少量步骤实现高质量文本生成，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型速度慢，离散扩散模型需要大量迭代，影响生成速度和效率。

Method: 提出FS-DFM，通过优化训练和更新规则，减少采样步骤。

Result: FS-DFM在8步采样下，达到与1024步离散流模型相当的困惑度，速度提升128倍。

Conclusion: FS-DFM在保证质量的同时，显著提高了文本生成的效率和吞吐量。

Abstract: Autoregressive language models (ARMs) deliver strong likelihoods, but are
inherently serial: they generate one token per forward pass, which limits
throughput and inflates latency for long sequences. Diffusion Language Models
(DLMs) parallelize across positions and thus appear promising for language
generation, yet standard discrete diffusion typically needs hundreds to
thousands of model evaluations to reach high quality, trading serial depth for
iterative breadth. We introduce FS-DFM, Few-Step Discrete Flow-Matching. A
discrete flow-matching model designed for speed without sacrificing quality.
The core idea is simple: make the number of sampling steps an explicit
parameter and train the model to be consistent across step budgets, so one big
move lands where many small moves would. We pair this with a reliable update
rule that moves probability in the right direction without overshooting, and
with strong teacher guidance distilled from long-run trajectories. Together,
these choices make few-step sampling stable, accurate, and easy to control. On
language modeling benchmarks, FS-DFM with 8 sampling steps achieves perplexity
parity with a 1,024-step discrete-flow baseline for generating 1,024 tokens
using a similar-size model, delivering up to 128 times faster sampling and
corresponding latency/throughput gains.

</details>


### [21] [Query-Centric Graph Retrieval Augmented Generation](https://arxiv.org/abs/2509.21237)
*Yaxiong Wu,Jianyuan Bo,Yongyue Zhang,Sheng Liang,Yong Liu*

Main category: cs.CL

TL;DR: 提出了一个query-centric graph RAG框架，用于改进LLM的long-context理解和多跳推理。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的RAG方法面临粒度困境：细粒度实体级图token成本高且丢失上下文，而粗粒度文档级图无法捕捉细微关系。

Method: 利用Doc2Query和Doc2Query{-}{-}构建query-centric图，并通过定制的多跳检索机制选择相关块。

Result: 在LiHuaWorld和MultiHop-RAG上的实验表明，QCG-RAG在问答准确性方面优于现有的chunk-based和graph-based RAG方法。

Conclusion: QCG-RAG为多跳推理建立了一个新的范例。

Abstract: Graph-based retrieval-augmented generation (RAG) enriches large language
models (LLMs) with external knowledge for long-context understanding and
multi-hop reasoning, but existing methods face a granularity dilemma:
fine-grained entity-level graphs incur high token costs and lose context, while
coarse document-level graphs fail to capture nuanced relations. We introduce
QCG-RAG, a query-centric graph RAG framework that enables query-granular
indexing and multi-hop chunk retrieval. Our query-centric approach leverages
Doc2Query and Doc2Query{-}{-} to construct query-centric graphs with
controllable granularity, improving graph quality and interpretability. A
tailored multi-hop retrieval mechanism then selects relevant chunks via the
generated queries. Experiments on LiHuaWorld and MultiHop-RAG show that QCG-RAG
consistently outperforms prior chunk-based and graph-based RAG methods in
question answering accuracy, establishing a new paradigm for multi-hop
reasoning.

</details>


### [22] [Look Before you Leap: Estimating LLM Benchmark Scores from Descriptions](https://arxiv.org/abs/2509.20645)
*Jungsoo Park,Ethan Mendes,Gabriel Stanovsky,Alan Ritter*

Main category: cs.CL

TL;DR: 本文研究了在不进行实验的情况下，仅根据任务描述和配置预测模型性能的可行性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的进步受到评估瓶颈的限制，即需要构建基准、评估模型和设置，然后迭代。为了解决这个问题，本文探讨了是否可以在运行任何实验之前预测结果。

Method: 本文整理了一个名为PRECOG的语料库，其中包含各种任务、领域和指标的修订描述-性能对。然后，使用配备了检索模块的模型来预测性能。

Result: 实验表明，这项任务具有挑战性但可行：配备了排除源论文的检索模块的模型实现了适度的预测性能，并且具有良好校准的不确定性，在高置信度阈值下，准确度子集的平均绝对误差低至8.7。GPT-5在零泄漏设置下，在论文被索引之前预测新发布的数据集或实验，仍然获得了重要的预测准确性。

Conclusion: 本文的语料库和分析为开放式预期评估提供了初步步骤，支持难度估计和更智能的实验优先级排序。

Abstract: Progress in large language models is constrained by an evaluation bottleneck:
build a benchmark, evaluate models and settings, then iterate. We therefore ask
a simple question: can we forecast outcomes before running any experiments? We
study text-only performance forecasting: estimating a model's score from a
redacted task description and intended configuration, with no access to dataset
instances. To support systematic study, we curate PRECOG, a corpus of redacted
description-performance pairs spanning diverse tasks, domains, and metrics.
Experiments show the task is challenging but feasible: models equipped with a
retrieval module that excludes source papers achieve moderate prediction
performance with well-calibrated uncertainty, reaching mean absolute error as
low as 8.7 on the Accuracy subset at high-confidence thresholds. Our analysis
indicates that stronger reasoning models engage in diverse, iterative querying,
whereas current open-source models lag and often skip retrieval or gather
evidence with limited diversity. We further test a zero-leakage setting,
forecasting on newly released datasets or experiments before their papers are
indexed, where GPT-5 with built-in web search still attains nontrivial
prediction accuracy. Overall, our corpus and analyses offer an initial step
toward open-ended anticipatory evaluation, supporting difficulty estimation and
smarter experiment prioritization.

</details>


### [23] [Building Tailored Speech Recognizers for Japanese Speaking Assessment](https://arxiv.org/abs/2509.20655)
*Yotaro Kubo,Richard Sproat,Chihiro Taguchi,Llion Jones*

Main category: cs.CL

TL;DR: 本文介绍了一种为日语口语评估任务定制的语音识别器构建方法，该识别器输出带有重音标记的音标标签。


<details>
  <summary>Details</summary>
Motivation: 为了解决训练模型以生成包含重音标记的准确音标转录的数据量不足的问题。

Method: 提出了两种缓解数据稀疏性的方法：多任务训练方案，引入辅助损失函数来估计正字法文本标签和输入信号的音高模式，以便可以利用只有正字法注释的utterance进行训练；融合两个估计器，一个基于音标字母串，另一个基于文本token序列。为了结合这些估计，我们开发了一种基于有限状态转换器框架的算法。

Result: 结果表明，使用多任务学习和融合对于构建准确的音标识别器是有效的。与使用通用多语言识别器相比，该方法具有优势。所提出的方法使CSJ核心评估集上的mora-label错误率平均从12.3%降低到7.1%。

Conclusion: 多任务学习和融合技术可以有效提高日语语音识别的准确率，尤其是在数据稀疏的情况下。

Abstract: This paper presents methods for building speech recognizers tailored for
Japanese speaking assessment tasks. Specifically, we build a speech recognizer
that outputs phonemic labels with accent markers. Although Japanese is
resource-rich, there is only a small amount of data for training models to
produce accurate phonemic transcriptions that include accent marks. We propose
two methods to mitigate data sparsity. First, a multitask training scheme
introduces auxiliary loss functions to estimate orthographic text labels and
pitch patterns of the input signal, so that utterances with only orthographic
annotations can be leveraged in training. The second fuses two estimators, one
over phonetic alphabet strings, and the other over text token sequences. To
combine these estimates we develop an algorithm based on the finite-state
transducer framework. Our results indicate that the use of multitask learning
and fusion is effective for building an accurate phonemic recognizer. We show
that this approach is advantageous compared to the use of generic multilingual
recognizers. The relative advantages of the proposed methods were also
compared. Our proposed methods reduced the average of mora-label error rates
from 12.3% to 7.1% over the CSJ core evaluation sets.

</details>


### [24] [Enhancing Molecular Property Prediction with Knowledge from Large Language Models](https://arxiv.org/abs/2509.20664)
*Peng Zhou,Lai Hou Tim,Zhixiang Cheng,Kun Xie,Chaoyi Li,Wei Liu,Xiangxiang Zeng*

Main category: cs.CL

TL;DR: 提出了一种新的框架，该框架集成了从法学硕士中提取的知识和从预训练分子模型中提取的结构特征，以增强MPP。


<details>
  <summary>Details</summary>
Motivation: 分子性质预测是药物发现的一个关键组成部分。尽管GNN和自我监督学习方法已经改进了分子性质预测（MPP），但人类先验知识的整合仍然是不可或缺的。

Method: 该方法提示法学硕士生成领域相关知识和用于分子矢量化的可执行代码，从而生成基于知识的特征，这些特征随后与结构表示融合。我们采用三种最先进的法学硕士，GPT-4o、GPT-4.1和DeepSeek-R1进行知识提取。

Result: 我们的综合方法优于现有方法，证实了法学硕士衍生的知识和结构信息的结合为MPP提供了一个强大而有效的解决方案。

Conclusion: 结合法学硕士衍生的知识和结构信息的组合为MPP提供了一个强大而有效的解决方案。

Abstract: Predicting molecular properties is a critical component of drug discovery.
Recent advances in deep learning, particularly Graph Neural Networks (GNNs),
have enabled end-to-end learning from molecular structures, reducing reliance
on manual feature engineering. However, while GNNs and self-supervised learning
approaches have advanced molecular property prediction (MPP), the integration
of human prior knowledge remains indispensable, as evidenced by recent methods
that leverage large language models (LLMs) for knowledge extraction. Despite
their strengths, LLMs are constrained by knowledge gaps and hallucinations,
particularly for less-studied molecular properties. In this work, we propose a
novel framework that, for the first time, integrates knowledge extracted from
LLMs with structural features derived from pre-trained molecular models to
enhance MPP. Our approach prompts LLMs to generate both domain-relevant
knowledge and executable code for molecular vectorization, producing
knowledge-based features that are subsequently fused with structural
representations. We employ three state-of-the-art LLMs, GPT-4o, GPT-4.1, and
DeepSeek-R1, for knowledge extraction. Extensive experiments demonstrate that
our integrated method outperforms existing approaches, confirming that the
combination of LLM-derived knowledge and structural information provides a
robust and effective solution for MPP.

</details>


### [25] [RedHerring Attack: Testing the Reliability of Attack Detection](https://arxiv.org/abs/2509.20691)
*Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出了一种新的攻击方法RedHerring，旨在使攻击检测模型不可靠，通过修改文本使检测模型预测攻击，同时保持分类器正确。


<details>
  <summary>Details</summary>
Motivation: 对抗性文本攻击出现后，已经提出了攻击检测模型，并已成功识别出被攻击者修改的文本。攻击检测模型可以用于为NLP模型提供额外的检查，并为人工输入提供信号。然而，这些模型的可靠性尚未得到充分探讨。

Method: 提出并测试了一种新的攻击设置和攻击方法，RedHerring。通过修改文本，使检测模型预测攻击，同时保持分类器正确。

Result: RedHerring能够降低检测精度20-71个百分点，同时保持（或提高）分类器精度。作为初步防御，我们提出了一种简单的置信度检查，不需要重新训练分类器或检测器，并大大提高了检测精度。

Conclusion: 这种新的威胁模型为攻击者如何瞄准检测模型提供了新的见解。

Abstract: In response to adversarial text attacks, attack detection models have been
proposed and shown to successfully identify text modified by adversaries.
Attack detection models can be leveraged to provide an additional check for NLP
models and give signals for human input. However, the reliability of these
models has not yet been thoroughly explored. Thus, we propose and test a novel
attack setting and attack, RedHerring. RedHerring aims to make attack detection
models unreliable by modifying a text to cause the detection model to predict
an attack, while keeping the classifier correct. This creates a tension between
the classifier and detector. If a human sees that the detector is giving an
``incorrect'' prediction, but the classifier a correct one, then the human will
see the detector as unreliable. We test this novel threat model on 4 datasets
against 3 detectors defending 4 classifiers. We find that RedHerring is able to
drop detection accuracy between 20 - 71 points, while maintaining (or
improving) classifier accuracy. As an initial defense, we propose a simple
confidence check which requires no retraining of the classifier or detector and
increases detection accuracy greatly. This novel threat model offers new
insights into how adversaries may target detection models.

</details>


### [26] [Overcoming Black-box Attack Inefficiency with Hybrid and Dynamic Select Algorithms](https://arxiv.org/abs/2509.20699)
*Abhinay Shankar Belde,Rohit Ramkumar,Jonathan Rusert*

Main category: cs.CL

TL;DR: 提出两种新的攻击选择策略，以降低攻击测试的计算成本，同时保持攻击有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒攻击方法需要大量的查询，对于资源有限的研究人员来说，效率低下且不实用。

Method: 提出混合选择和动态选择两种攻击选择策略，结合了二元选择和贪婪选择的优点。混合选择通过引入大小阈值来决定使用哪种选择算法。动态选择通过学习每种选择方法应应用于的文本长度来组合二元和贪婪选择。

Result: 在 4 个数据集和 6 个目标模型上，最佳方法（句子级混合选择）能够平均减少每次攻击所需的查询次数高达 25.82%，同时不损失攻击的有效性。

Conclusion: 提出的攻击选择策略可以有效降低攻击测试的计算成本，同时保持攻击有效性。

Abstract: Adversarial text attack research plays a crucial role in evaluating the
robustness of NLP models. However, the increasing complexity of
transformer-based architectures has dramatically raised the computational cost
of attack testing, especially for researchers with limited resources (e.g.,
GPUs). Existing popular black-box attack methods often require a large number
of queries, which can make them inefficient and impractical for researchers. To
address these challenges, we propose two new attack selection strategies called
Hybrid and Dynamic Select, which better combine the strengths of previous
selection algorithms. Hybrid Select merges generalized BinarySelect techniques
with GreedySelect by introducing a size threshold to decide which selection
algorithm to use. Dynamic Select provides an alternative approach of combining
the generalized Binary and GreedySelect by learning which lengths of texts each
selection method should be applied to. This greatly reduces the number of
queries needed while maintaining attack effectiveness (a limitation of
BinarySelect). Across 4 datasets and 6 target models, our best
method(sentence-level Hybrid Select) is able to reduce the number of required
queries per attack up 25.82\% on average against both encoder models and LLMs,
without losing the effectiveness of the attack.

</details>


### [27] [MI-Fuse: Label Fusion for Unsupervised Domain Adaptation with Closed-Source Large-Audio Language Model](https://arxiv.org/abs/2509.20706)
*Hsiao-Ying Huang,Yi-Cheng Lin,Hung-yi Lee*

Main category: cs.CL

TL;DR: 本文提出了一种在只有未标记目标域音频和API-only LALM的情况下，使学生模型适应目标域并超越LALM的MI-Fuse框架。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，语音情感识别（SER）在域不匹配时表现不佳，且无法访问源数据和强大的LALM。

Method: 该框架利用源域训练的SER分类器作为辅助教师，通过互信息加权平均分布，并使用指数移动平均教师稳定训练。

Result: 在三个公共情感数据集和六个跨域迁移实验中，学生模型超越了LALM，并超过了最强的基线3.9%。

Conclusion: 该方法无需共享源数据即可加强情感感知语音系统，实现真实的适应。

Abstract: Large audio-language models (LALMs) show strong zero-shot ability on speech
tasks, suggesting promise for speech emotion recognition (SER). However, SER in
real-world deployments often fails under domain mismatch, where source data are
unavailable and powerful LALMs are accessible only through an API. We ask:
given only unlabeled target-domain audio and an API-only LALM, can a student
model be adapted to outperform the LALM in the target domain? To this end, we
propose MI-Fuse, a denoised label fusion framework that supplements the LALM
with a source-domain trained SER classifier as an auxiliary teacher. The
framework draws multiple stochastic predictions from both teachers, weights
their mean distributions by mutual-information-based uncertainty, and
stabilizes training with an exponential moving average teacher. Experiments
across three public emotion datasets and six cross-domain transfers show
consistent gains, with the student surpassing the LALM and outperforming the
strongest baseline by 3.9%. This approach strengthens emotion-aware speech
systems without sharing source data, enabling realistic adaptation.

</details>


### [28] [Probability Distribution Collapse: A Critical Bottleneck to Compact Unsupervised Neural Grammar Induction](https://arxiv.org/abs/2509.20734)
*Jinwook Park,Kangil Kim*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的非监督神经语法归纳方法，旨在解决现有模型中存在的表达能力瓶颈问题，即模型倾向于生成不必要的大型但性能不佳的语法。


<details>
  <summary>Details</summary>
Motivation: 现有模型存在表达能力瓶颈，导致生成不必要的大型且性能不佳的语法。作者认为这是由于概率分布崩溃问题引起的。

Method: 作者分析了神经参数化的关键组件中概率分布崩溃出现的时间和方式，并提出了一种有针对性的解决方案，即 collapse-relaxing 神经参数化，以缓解这个问题。

Result: 该方法在广泛的语言范围内显著提高了分析性能，同时可以使用更紧凑的语法。

Conclusion: 通过大量的实证分析证明了该方法的有效性。

Abstract: Unsupervised neural grammar induction aims to learn interpretable
hierarchical structures from language data. However, existing models face an
expressiveness bottleneck, often resulting in unnecessarily large yet
underperforming grammars. We identify a core issue, $\textit{probability
distribution collapse}$, as the underlying cause of this limitation. We analyze
when and how the collapse emerges across key components of neural
parameterization and introduce a targeted solution, $\textit{collapse-relaxing
neural parameterization}$, to mitigate it. Our approach substantially improves
parsing performance while enabling the use of significantly more compact
grammars across a wide range of languages, as demonstrated through extensive
empirical analysis.

</details>


### [29] [Confidence-guided Refinement Reasoning for Zero-shot Question Answering](https://arxiv.org/abs/2509.20750)
*Youwon Jang,Woo Suk Choi,Minjoon Jung,Minsu Lee,Byoung-Tak Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为 C2R 的新颖的免训练框架，适用于文本、图像和视频领域的问答 (QA) 任务。


<details>
  <summary>Details</summary>
Motivation: C2R 旨在通过策略性地构建和细化子问题及其答案（子 QA），从而为目标答案获得更好的置信度分数。

Method: C2R 首先管理一个子 QA 子集来探索不同的推理路径，然后比较结果答案候选者的置信度分数，以选择最可靠的最终答案。

Result: C2R 仅依赖于模型本身导出的置信度分数，因此它可以与各种现有的 QA 模型无缝集成，并在不同的模型和基准测试中表现出一致的性能改进。

Conclusion: 我们提供了关于利用子 QA 如何影响模型行为的重要但未被充分探索的见解，特别分析了子 QA 的数量和质量对实现稳健和可靠的推理的影响。

Abstract: We propose Confidence-guided Refinement Reasoning (C2R), a novel
training-free framework applicable to question-answering (QA) tasks across
text, image, and video domains. C2R strategically constructs and refines
sub-questions and their answers (sub-QAs), deriving a better confidence score
for the target answer. C2R first curates a subset of sub-QAs to explore diverse
reasoning paths, then compares the confidence scores of the resulting answer
candidates to select the most reliable final answer. Since C2R relies solely on
confidence scores derived from the model itself, it can be seamlessly
integrated with various existing QA models, demonstrating consistent
performance improvements across diverse models and benchmarks. Furthermore, we
provide essential yet underexplored insights into how leveraging sub-QAs
affects model behavior, specifically analyzing the impact of both the quantity
and quality of sub-QAs on achieving robust and reliable reasoning.

</details>


### [30] [SFT Doesn't Always Hurt General Capabilities: Revisiting Domain-Specific Fine-Tuning in LLMs](https://arxiv.org/abs/2509.20758)
*Jiacheng Lin,Zhongruo Wang,Kun Qian,Tian Wang,Arvind Srinivasan,Hansi Zeng,Ruochen Jiao,Xie Zhou,Jiri Gesi,Dakuo Wang,Yufan Guo,Kai Zhong,Weiqi Zhang,Sujay Sanghavi,Changyou Chen,Hyokun Yun,Lihong Li*

Main category: cs.CL

TL;DR: 领域特定数据集上的监督微调(SFT)是使大型语言模型(llm)适应专门任务的常用方法，但通常被认为会降低其通用能力。这项工作重新审视了这种权衡，并提出了经验和理论上的见解。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探讨在领域特定数据集上对大型语言模型进行监督微调(SFT)时，模型通用能力下降的问题，并重新审视这种权衡。

Method: 提出了Token-Adaptive Loss Reweighting (TALR)方法，并结合理论分析，同时评估了一系列减少通用能力损失的策略，包括L2正则化、LoRA、模型平均和FLOW。

Result: 实验结果表明，虽然没有方法可以完全消除这种权衡，但TALR在平衡领域特定增益和通用能力方面始终优于这些基线。

Conclusion: 总结了将llm适应新领域的实际指南：(i)使用较小的学习率来实现有利的权衡，(ii)当进一步需要更强的平衡时，采用TALR作为一种有效的策略。

Abstract: Supervised Fine-Tuning (SFT) on domain-specific datasets is a common approach
to adapt Large Language Models (LLMs) to specialized tasks but is often
believed to degrade their general capabilities. In this work, we revisit this
trade-off and present both empirical and theoretical insights. First, we show
that SFT does not always hurt: using a smaller learning rate can substantially
mitigate general performance degradation while preserving comparable
target-domain performance. We then provide a theoretical analysis that explains
these phenomena and further motivates a new method, Token-Adaptive Loss
Reweighting (TALR). Building on this, and recognizing that smaller learning
rates alone do not fully eliminate general-performance degradation in all
cases, we evaluate a range of strategies for reducing general capability loss,
including L2 regularization, LoRA, model averaging, FLOW, and our proposed
TALR. Experimental results demonstrate that while no method completely
eliminates the trade-off, TALR consistently outperforms these baselines in
balancing domain-specific gains and general capabilities. Finally, we distill
our findings into practical guidelines for adapting LLMs to new domains: (i)
using a small learning rate to achieve a favorable trade-off, and (ii) when a
stronger balance is further desired, adopt TALR as an effective strategy.

</details>


### [31] [Towards Atoms of Large Language Models](https://arxiv.org/abs/2509.20784)
*Chenhui Hu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 论文提出“原子理论”来定义大语言模型(LLM)内部表征的基本单元，以解决神经元多义性和特征不稳定性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的神经元和特征作为LLM内部表征单元存在局限性，神经元具有多义性，而特征的重构和稳定性存在问题。

Method: 论文引入原子内积(AIP)来纠正表征偏移，正式定义了原子，并证明了原子满足约束等距属性(RIP)的条件，保证了原子集上的稳定稀疏表示，并与压缩感知相关联。此外，还建立了稀疏表示的唯一性和精确l1可恢复性，并提供了具有阈值激活的单层稀疏自编码器(SAE)可以可靠地识别原子的保证。

Result: 在Gemma2-2B、Gemma2-9B和Llama3.1-8B上训练的SAE实现了平均99.9%的跨层稀疏重构，超过99.8%的原子满足唯一性条件，而神经元和特征的比例分别为0.5%和68.2%。

Conclusion: 这项工作系统地介绍并验证了LLM的原子理论，为理解内部表征提供了一个理论框架，并为机制可解释性奠定了基础。

Abstract: The fundamental units of internal representations in large language models
(LLMs) remain undefined, limiting further understanding of their mechanisms.
Neurons or features are often regarded as such units, yet neurons suffer from
polysemy, while features face concerns of unreliable reconstruction and
instability. To address this issue, we propose the Atoms Theory, which defines
such units as atoms. We introduce the atomic inner product (AIP) to correct
representation shifting, formally define atoms, and prove the conditions that
atoms satisfy the Restricted Isometry Property (RIP), ensuring stable sparse
representations over atom set and linking to compressed sensing. Under stronger
conditions, we further establish the uniqueness and exact $\ell_1$
recoverability of the sparse representations, and provide guarantees that
single-layer sparse autoencoders (SAEs) with threshold activations can reliably
identify the atoms. To validate the Atoms Theory, we train threshold-activated
SAEs on Gemma2-2B, Gemma2-9B, and Llama3.1-8B, achieving 99.9% sparse
reconstruction across layers on average, and more than 99.8% of atoms satisfy
the uniqueness condition, compared to 0.5% for neurons and 68.2% for features,
showing that atoms more faithfully capture intrinsic representations of LLMs.
Scaling experiments further reveal the link between SAEs size and recovery
capacity. Overall, this work systematically introduces and validates Atoms
Theory of LLMs, providing a theoretical framework for understanding internal
representations and a foundation for mechanistic interpretability. Code
available at https://github.com/ChenhuiHu/towards_atoms.

</details>


### [32] [Enrich-on-Graph: Query-Graph Alignment for Complex Reasoning with LLM Enriching](https://arxiv.org/abs/2509.20810)
*Songze Li,Zhiqiang Liu,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为 Enrich-on-Graph (EoG) 的框架，利用大型语言模型 (LLM) 的先验知识来丰富知识图谱 (KG)，以弥合图和查询之间的语义差距。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识图谱问答 (KGQA) 等知识密集型场景中，仍存在幻觉和事实错误的问题。现有方法通常采用资源密集、不可扩展的工作流程在原始 KG 上进行推理，但忽略了 KG 和查询之间的语义差距。

Method: 提出了一种灵活的框架 Enrich-on-Graph (EoG)，该框架利用 LLM 的先验知识来丰富 KG，弥合图和查询之间的语义差距。此外，还提出了三个图质量评估指标来分析 KGQA 任务中的查询图对齐。

Result: 在两个 KGQA 基准数据集上的大量实验表明，EoG 可以有效地生成高质量的 KG，并实现最先进的性能。

Conclusion: EoG 能够实现从 KG 中高效提取证据，从而实现精确和鲁棒的推理，同时确保低计算成本、可扩展性和跨不同方法的适应性。

Abstract: Large Language Models (LLMs) exhibit strong reasoning capabilities in complex
tasks. However, they still struggle with hallucinations and factual errors in
knowledge-intensive scenarios like knowledge graph question answering (KGQA).
We attribute this to the semantic gap between structured knowledge graphs (KGs)
and unstructured queries, caused by inherent differences in their focuses and
structures. Existing methods usually employ resource-intensive, non-scalable
workflows reasoning on vanilla KGs, but overlook this gap. To address this
challenge, we propose a flexible framework, Enrich-on-Graph (EoG), which
leverages LLMs' prior knowledge to enrich KGs, bridge the semantic gap between
graphs and queries. EoG enables efficient evidence extraction from KGs for
precise and robust reasoning, while ensuring low computational costs,
scalability, and adaptability across different methods. Furthermore, we propose
three graph quality evaluation metrics to analyze query-graph alignment in KGQA
task, supported by theoretical validation of our optimization objectives.
Extensive experiments on two KGQA benchmark datasets indicate that EoG can
effectively generate high-quality KGs and achieve the state-of-the-art
performance. Our code and data are available at
https://github.com/zjukg/Enrich-on-Graph.

</details>


### [33] [Leveraging What's Overfixed: Post-Correction via LLM Grammatical Error Overcorrection](https://arxiv.org/abs/2509.20811)
*Taehee Park,Heejin Do,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 提出了一种名为PoCO的新方法，通过利用大型语言模型（LLM）的生成能力和小型监督模型的可靠性来平衡召回率和精确率，从而提高语法纠错的整体质量。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（sLM）虽然可靠性高但纠错不足，而大型语言模型（LLM）则过度纠错，导致精确率低。为了利用LLM的优势来解决sLM中的召回率问题。

Method: PoCO首先通过LLM故意触发过度纠正以最大化召回率，然后应用有针对性的后纠正步骤，通过微调较小的模型来识别和改进错误输出。

Result: 实验表明，PoCO通过在具有竞争力的精度下提高召回率来有效地平衡GEC性能，最终提高了语法纠错的整体质量。

Conclusion: PoCO方法有效地结合了LLM的生成能力和小型监督模型的可靠性，实现了更好的语法纠错效果。

Abstract: Robust supervised fine-tuned small Language Models (sLMs) often show high
reliability but tend to undercorrect. They achieve high precision at the cost
of low recall. Conversely, Large Language Models (LLMs) often show the opposite
tendency, making excessive overcorrection, leading to low precision. To
effectively harness the strengths of LLMs to address the recall challenges in
sLMs, we propose Post-Correction via Overcorrection (PoCO), a novel approach
that strategically balances recall and precision. PoCO first intentionally
triggers overcorrection via LLM to maximize recall by allowing comprehensive
revisions, then applies a targeted post-correction step via fine-tuning smaller
models to identify and refine erroneous outputs. We aim to harmonize both
aspects by leveraging the generative power of LLMs while preserving the
reliability of smaller supervised models. Our extensive experiments demonstrate
that PoCO effectively balances GEC performance by increasing recall with
competitive precision, ultimately improving the overall quality of grammatical
error correction.

</details>


### [34] [Distilling Many-Shot In-Context Learning into a Cheat Sheet](https://arxiv.org/abs/2509.20820)
*Ukyo Honda,Soichiro Murakami,Peinan Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为 cheat-sheet ICL 的方法，旨在解决大型语言模型 (LLM) 中上下文学习 (ICL) 计算需求高的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 的上下文学习 (ICL) 需要大量的计算资源。

Method: 将多样本 ICL 中的信息提炼成简洁的文本摘要（cheat sheet），并在推理时将其用作上下文。

Result: 在具有挑战性的推理任务中，cheat-sheet ICL 的性能与多样本 ICL 相当或更好，且使用的 tokens 更少，并且可以媲美基于检索的 ICL，而无需测试时检索。

Conclusion: Cheat-sheet ICL 是一种利用 LLM 进行下游任务的实用替代方案。

Abstract: Recent advances in large language models (LLMs) enable effective in-context
learning (ICL) with many-shot examples, but at the cost of high computational
demand due to longer input tokens. To address this, we propose cheat-sheet ICL,
which distills the information from many-shot ICL into a concise textual
summary (cheat sheet) used as the context at inference time. Experiments on
challenging reasoning tasks show that cheat-sheet ICL achieves comparable or
better performance than many-shot ICL with far fewer tokens, and matches
retrieval-based ICL without requiring test-time retrieval. These findings
demonstrate that cheat-sheet ICL is a practical alternative for leveraging LLMs
in downstream tasks.

</details>


### [35] [Zero-Shot Privacy-Aware Text Rewriting via Iterative Tree Search](https://arxiv.org/abs/2509.20838)
*Shuo Huang,Xingliang Yuan,Gholamreza Haffari,Lizhen Qu*

Main category: cs.CL

TL;DR: 提出了一种新的零样本句子重写算法，用于在保护隐私的同时保持文本的自然性和实用性。


<details>
  <summary>Details</summary>
Motivation: 用户输入可能无意中暴露敏感信息，现有的文本匿名化和去标识技术难以平衡隐私保护与文本自然性和实用性。

Method: 提出了一种基于树搜索的迭代句子重写算法，该算法通过奖励模型引导的结构化搜索，动态探索重写空间。

Result: 在隐私敏感数据集上的实验表明，该方法明显优于现有基线，在隐私保护和效用保持之间取得了更好的平衡。

Conclusion: 该方法能够有效地混淆或删除私人信息，同时保持连贯性、相关性和自然性。

Abstract: The increasing adoption of large language models (LLMs) in cloud-based
services has raised significant privacy concerns, as user inputs may
inadvertently expose sensitive information. Existing text anonymization and
de-identification techniques, such as rule-based redaction and scrubbing, often
struggle to balance privacy preservation with text naturalness and utility. In
this work, we propose a zero-shot, tree-search-based iterative sentence
rewriting algorithm that systematically obfuscates or deletes private
information while preserving coherence, relevance, and naturalness. Our method
incrementally rewrites privacy-sensitive segments through a structured search
guided by a reward model, enabling dynamic exploration of the rewriting space.
Experiments on privacy-sensitive datasets show that our approach significantly
outperforms existing baselines, achieving a superior balance between privacy
protection and utility preservation.

</details>


### [36] [Concise and Sufficient Sub-Sentence Citations for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.20859)
*Guo Chen,Qiuyuan Li,Qiuxian Li,Hongliang Dai,Xiang Chen,Piji Li*

Main category: cs.CL

TL;DR: 本文提出了一种生成子句引用，以提高RAG问答系统中LLM输出的可验证性并帮助用户识别潜在的幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的归因方法产生的引文通常在句子甚至段落层面提供，这可能包含大量无关内容，或者遗漏验证输出所需的重要信息。

Method: 1. 制定子句引用的注释指南并构建相应的数据集。2. 提出一个归因框架，利用LLM自动生成微调数据，并采用信用模型来过滤掉低质量的例子。

Result: 实验表明，该方法可以生成高质量且更易读的引文。

Conclusion: 本文提出了一种生成子句引用的方法，可以有效提高RAG问答系统中LLM输出的可验证性。

Abstract: In retrieval-augmented generation (RAG) question answering systems,
generating citations for large language model (LLM) outputs enhances
verifiability and helps users identify potential hallucinations. However, we
observe two problems in the citations produced by existing attribution methods.
First, the citations are typically provided at the sentence or even paragraph
level. Long sentences or paragraphs may include a substantial amount of
irrelevant content. Second, sentence-level citations may omit information that
is essential for verifying the output, forcing users to read the surrounding
context. In this paper, we propose generating sub-sentence citations that are
both concise and sufficient, thereby reducing the effort required by users to
confirm the correctness of the generated output. To this end, we first develop
annotation guidelines for such citations and construct a corresponding dataset.
Then, we propose an attribution framework for generating citations that adhere
to our standards. This framework leverages LLMs to automatically generate
fine-tuning data for our task and employs a credit model to filter out
low-quality examples. Our experiments on the constructed dataset demonstrate
that the propose approach can generate high-quality and more readable
citations.

</details>


### [37] [WeFT: Weighted Entropy-driven Fine-Tuning for dLLMs](https://arxiv.org/abs/2509.20863)
*Guowei Xu,Wenxin Xu,Jiawang Zhao,Kaisheng Ma*

Main category: cs.CL

TL;DR: 本文提出了一种加权监督微调（WeFT）方法，用于改进扩散语言模型的微调效果。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型缺乏精确的概率估计，导致微调困难，生成过程不够可预测和一致。

Method: 提出 WeFT 方法，该方法基于 token 的熵值为其分配不同的权重。

Result: 在四个推理基准测试中，WeFT 相对于标准 SFT 取得了显著的性能提升。

Conclusion: WeFT 是一种有效的扩散语言模型微调方法，通过控制关键 tokens 的权重来提高生成质量。

Abstract: Diffusion models have recently shown strong potential in language modeling,
offering faster generation compared to traditional autoregressive approaches.
However, applying supervised fine-tuning (SFT) to diffusion models remains
challenging, as they lack precise probability estimates at each denoising step.
While the diffusion mechanism enables the model to reason over entire
sequences, it also makes the generation process less predictable and often
inconsistent. This highlights the importance of controlling key tokens that
guide the direction of generation. To address this issue, we propose WeFT, a
weighted SFT method for diffusion language models, where tokens are assigned
different weights based on their entropy. Derived from diffusion theory, WeFT
delivers substantial gains: training on s1K, s1K-1.1, and 3k samples from
open-r1, it achieves relative improvements of 39%, 64%, and 83% over standard
SFT on four widely used reasoning benchmarks (Sudoku, Countdown, GSM8K, and
MATH-500). The code and models will be made publicly available.

</details>


### [38] [Single Answer is Not Enough: On Generating Ranked Lists with Medical Reasoning Models](https://arxiv.org/abs/2509.20866)
*Pittawat Taveekitworachai,Natpatchara Pongjirapat,Krittaphas Chaisutyakorn,Piyalitt Ittichaiwong,Tossaporn Saengja,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本文研究了如何使医学推理模型 (MRM) 为开放性问题生成排序的答案列表。


<details>
  <summary>Details</summary>
Motivation: 临床决策很少依赖单一答案，而是考虑多种选择，以降低狭隘视角的风险。然而，当前的 MRM 通常被训练为只生成一个答案，即使在开放性环境中也是如此。

Method: 本文提出了排序列表的替代格式，并研究了两种方法：提示和微调。基于提示的发现，我们使用监督微调 (SFT) 和强化微调 (RFT) 训练和评估 MRM。我们提出了针对排序列表答案格式的新奖励函数，并对 RFT 进行了消融研究。

Result: 结果表明，虽然一些 SFT 模型可以推广到某些答案格式，但使用 RFT 训练的模型在多种格式中更稳健。我们还对修改后的 MedQA 进行了案例研究，发现 MRM 可能无法选择基准测试的首选基本事实，但他们可以识别有效答案。

Conclusion: 据我们所知，这是首次对使 MRM 能够生成排序列表形式的答案的方法进行系统研究。我们希望这项工作能为开发替代答案格式提供第一步，这些格式在医学领域中超越了单一答案。

Abstract: This paper presents a systematic study on enabling medical reasoning models
(MRMs) to generate ranked lists of answers for open-ended questions. Clinical
decision-making rarely relies on a single answer but instead considers multiple
options, reducing the risks of narrow perspectives. Yet current MRMs are
typically trained to produce only one answer, even in open-ended settings. We
propose an alternative format: ranked lists and investigate two approaches:
prompting and fine-tuning. While prompting is a cost-effective way to steer an
MRM's response, not all MRMs generalize well across different answer formats:
choice, short text, and list answers. Based on our prompting findings, we train
and evaluate MRMs using supervised fine-tuning (SFT) and reinforcement
fine-tuning (RFT). SFT teaches a model to imitate annotated responses, and RFT
incentivizes exploration through the responses that maximize a reward. We
propose new reward functions targeted at ranked-list answer formats, and
conduct ablation studies for RFT. Our results show that while some SFT models
generalize to certain answer formats, models trained with RFT are more robust
across multiple formats. We also present a case study on a modified MedQA with
multiple valid answers, finding that although MRMs might fail to select the
benchmark's preferred ground truth, they can recognize valid answers. To the
best of our knowledge, this is the first systematic investigation of approaches
for enabling MRMs to generate answers as ranked lists. We hope this work
provides a first step toward developing alternative answer formats that are
beneficial beyond single answers in medical domains.

</details>


### [39] [Learning to Summarize by Learning to Quiz: Adversarial Agentic Collaboration for Long Document Summarization](https://arxiv.org/abs/2509.20900)
*Weixuan Wang,Minghao Wu,Barry Haddow,Alexandra Birch*

Main category: cs.CL

TL;DR: SummQ: A novel adversarial multi-agent framework for long document summarization that uses collaborative intelligence between summarization and quizzing agents.


<details>
  <summary>Details</summary>
Motivation: Existing LLMs struggle with information loss, factual inconsistencies, and coherence issues when summarizing long documents.

Method: Summary generators and reviewers collaborate to create and evaluate summaries, while quiz generators and reviewers create comprehension questions for quality checks. An examinee agent validates if the summary answers the quiz questions, enabling iterative refinement.

Result: SummQ significantly outperforms existing state-of-the-art methods on three benchmarks across ROUGE, BERTScore, LLM-as-a-Judge, and human evaluations.

Conclusion: This work establishes a new approach for long document summarization using adversarial agentic collaboration to improve summarization quality.

Abstract: Long document summarization remains a significant challenge for current large
language models (LLMs), as existing approaches commonly struggle with
information loss, factual inconsistencies, and coherence issues when processing
excessively long documents. We propose SummQ, a novel adversarial multi-agent
framework that addresses these limitations through collaborative intelligence
between specialized agents operating in two complementary domains:
summarization and quizzing. Our approach employs summary generators and
reviewers that work collaboratively to create and evaluate comprehensive
summaries, while quiz generators and reviewers create comprehension questions
that serve as continuous quality checks for the summarization process. This
adversarial dynamic, enhanced by an examinee agent that validates whether the
generated summary contains the information needed to answer the quiz questions,
enables iterative refinement through multifaceted feedback mechanisms. We
evaluate SummQ on three widely used long document summarization benchmarks.
Experimental results demonstrate that our framework significantly outperforms
existing state-of-the-art methods across ROUGE and BERTScore metrics, as well
as in LLM-as-a-Judge and human evaluations. Our comprehensive analyses reveal
the effectiveness of the multi-agent collaboration dynamics, the influence of
different agent configurations, and the impact of the quizzing mechanism. This
work establishes a new approach for long document summarization that uses
adversarial agentic collaboration to improve summarization quality.

</details>


### [40] [MemLens: Uncovering Memorization in LLMs with Activation Trajectories](https://arxiv.org/abs/2509.20909)
*Zirui He,Haiyan Zhao,Ali Payani,Mengnan du*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为 MemLens 的新方法，用于检测大型语言模型在诸如 AIME 和 Math500 等基准测试中存在的记忆化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的检测方法泛化性低，在遇到隐式污染数据时性能显著下降。

Method: 通过分析生成过程中数字 tokens 的概率轨迹来检测记忆化。

Result: 受污染的样本表现出“捷径”行为，在模型的早期层就以高置信度锁定答案，而干净的样本在模型的整个深度上表现出更逐渐的证据积累。受污染和干净的样本表现出截然不同的推理轨迹。

Conclusion: MemLens 能够捕获记忆化的真实信号，而不是虚假的相关性。

Abstract: Large language models (LLMs) are commonly evaluated on challenging benchmarks
such as AIME and Math500, which are susceptible to contamination and risk of
being memorized. Existing detection methods, which primarily rely on
surface-level lexical overlap and perplexity, demonstrate low generalization
and degrade significantly when encountering implicitly contaminated data. In
this paper, we propose MemLens (An Activation Lens for Memorization Detection)
to detect memorization by analyzing the probability trajectories of numeric
tokens during generation. Our method reveals that contaminated samples exhibit
``shortcut'' behaviors, locking onto an answer with high confidence in the
model's early layers, whereas clean samples show more gradual evidence
accumulation across the model's full depth. We observe that contaminated and
clean samples exhibit distinct and well-separated reasoning trajectories. To
further validate this, we inject carefully designed samples into the model
through LoRA fine-tuning and observe the same trajectory patterns as in
naturally contaminated data. These results provide strong evidence that MemLens
captures genuine signals of memorization rather than spurious correlations.

</details>


### [41] [Cross-Linguistic Analysis of Memory Load in Sentence Comprehension: Linear Distance and Structural Density](https://arxiv.org/abs/2509.20916)
*Krishna Aggarwal*

Main category: cs.CL

TL;DR: 本研究探讨句子理解中的记忆负荷，并使用跨语言混合效应模型来评估句子长度、依存长度和Intervener Complexity作为记忆负荷的预测指标。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探讨句子理解中句法相关词之间的线性接近程度或中间材料的结构密度，哪个更能解释句子层面的记忆负荷。

Method: 通过统一的依存句法树库和混合效应框架，跨多种语言进行分析，联合评估句子长度、依存长度和Intervener Complexity作为记忆负荷的预测因子。

Result: 所有三个因素都与记忆负荷正相关，其中句子长度的影响最广泛，而Intervener Complexity提供了超越线性距离的解释能力。

Conclusion: 研究结果调和了关于局部性的线性和层级视角，并将依存长度视为重要的表面特征，同时将中间头词识别为整合和维护需求更直接的指标。

Abstract: This study examines whether sentence-level memory load in comprehension is
better explained by linear proximity between syntactically related words or by
the structural density of the intervening material. Building on locality-based
accounts and cross-linguistic evidence for dependency length minimization, the
work advances Intervener Complexity-the number of intervening heads between a
head and its dependent-as a structurally grounded lens that refines linear
distance measures. Using harmonized dependency treebanks and a mixed-effects
framework across multiple languages, the analysis jointly evaluates sentence
length, dependency length, and Intervener Complexity as predictors of the
Memory-load measure. Studies in Psycholinguistics have reported the
contributions of feature interference and misbinding to memory load during
processing. For this study, I operationalized sentence-level memory load as the
linear sum of feature misbinding and feature interference for tractability;
current evidence does not establish that their cognitive contributions combine
additively. All three factors are positively associated with memory load, with
sentence length exerting the broadest influence and Intervener Complexity
offering explanatory power beyond linear distance. Conceptually, the findings
reconcile linear and hierarchical perspectives on locality by treating
dependency length as an important surface signature while identifying
intervening heads as a more proximate indicator of integration and maintenance
demands. Methodologically, the study illustrates how UD-based graph measures
and cross-linguistic mixed-effects modelling can disentangle linear and
structural contributions to processing efficiency, providing a principled path
for evaluating competing theories of memory load in sentence comprehension.

</details>


### [42] [Tool Calling for Arabic LLMs: Data Strategies and Instruction Tuning](https://arxiv.org/abs/2509.20957)
*Asim Ersoy,Enes Altinisik,Husrev Taha Sencar,Kareem Darwish*

Main category: cs.CL

TL;DR: 本研究着眼于如何使大型语言模型(llm)能够使用阿拉伯语工具调用。通过翻译和调整两个开源工具调用数据集，填补了资源空白。该研究调查了三个关键问题：(1)在语言(阿拉伯语)工具调用数据的必要性与依赖于跨语言转换，(2)通用指令调整对工具调用性能的影响，以及(3)在特定的、高优先级的工具上进行微调的价值。


<details>
  <summary>Details</summary>
Motivation: 目前工具调用方面的研究和资源主要集中在英语上，对于如何为其他语言(如阿拉伯语)启用此功能的研究不足。

Method: 使用开放权重的阿拉伯语LLM的基准和后训练变体进行了大量实验。为了支持这项研究，我们通过将两个开源工具调用数据集翻译和调整为阿拉伯语，弥补了资源缺口。

Result: 为开发强大的阿拉伯语工具增强代理提供了重要的见解。

Conclusion: 研究结果为开发强大的阿拉伯语工具增强代理提供了最佳策略。

Abstract: Tool calling is a critical capability that allows Large Language Models
(LLMs) to interact with external systems, significantly expanding their
utility. However, research and resources for tool calling are predominantly
English-centric, leaving a gap in our understanding of how to enable this
functionality for other languages, such as Arabic. This paper investigates
three key research questions: (1) the necessity of in-language (Arabic)
tool-calling data versus relying on cross-lingual transfer, (2) the effect of
general-purpose instruction tuning on tool-calling performance, and (3) the
value of fine-tuning on specific, high-priority tools. To address these
questions, we conduct extensive experiments using base and post-trained
variants of an open-weight Arabic LLM. To enable this study, we bridge the
resource gap by translating and adapting two open-source tool-calling datasets
into Arabic. Our findings provide crucial insights into the optimal strategies
for developing robust tool-augmented agents for Arabic.

</details>


### [43] [Analysis of instruction-based LLMs' capabilities to score and judge text-input problems in an academic setting](https://arxiv.org/abs/2509.20982)
*Valeria Ramirez-Garcia,David de-Fitero-Dominguez,Antonio Garcia-Cabot,Eva Garcia-Lopez*

Main category: cs.CL

TL;DR: 研究了大型语言模型（LLM）驱动的学术文本输入问题自动评估系统。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在教育领域的应用，特别是作为学生和教师的辅助工具。

Method: 提出了五种评估系统，并在一个包含110个计算机科学答案的自定义数据集上进行了测试，使用了JudgeLM、Llama-3.1-8B和DeepSeek-R1-Distill-Llama-8B三个模型。这五种评估系统包括JudgeLM评估、参考辅助评估、无参考评估、增量评估和自适应评估。

Result: 结果表明，使用LLM自动评估文本输入问题的最佳方法是参考辅助评估。与其他方法相比，参考辅助评估具有最低的绝对偏差中位数（0.945）和最低的均方根偏差（1.214）。

Conclusion: 结论是，在适当的方法支持下，人工智能驱动的自动评估系统有潜力作为其他学术资源的补充工具。

Abstract: Large language models (LLMs) can act as evaluators, a role studied by methods
like LLM-as-a-Judge and fine-tuned judging LLMs. In the field of education,
LLMs have been studied as assistant tools for students and teachers. Our
research investigates LLM-driven automatic evaluation systems for academic
Text-Input Problems using rubrics. We propose five evaluation systems that have
been tested on a custom dataset of 110 answers about computer science from
higher education students with three models: JudgeLM, Llama-3.1-8B and
DeepSeek-R1-Distill-Llama-8B. The evaluation systems include: The JudgeLM
evaluation, which uses the model's single answer prompt to obtain a score;
Reference Aided Evaluation, which uses a correct answer as a guide aside from
the original context of the question; No Reference Evaluation, which ommits the
reference answer; Additive Evaluation, which uses atomic criteria; and Adaptive
Evaluation, which is an evaluation done with generated criteria fitted to each
question. All evaluation methods have been compared with the results of a human
evaluator. Results show that the best method to automatically evaluate and
score Text-Input Problems using LLMs is Reference Aided Evaluation. With the
lowest median absolute deviation (0.945) and the lowest root mean square
deviation (1.214) when compared to human evaluation, Reference Aided Evaluation
offers fair scoring as well as insightful and complete evaluations. Other
methods such as Additive and Adaptive Evaluation fail to provide good results
in concise answers, No Reference Evaluation lacks information needed to
correctly assess questions and JudgeLM Evaluations have not provided good
results due to the model's limitations. As a result, we conclude that
Artificial Intelligence-driven automatic evaluation systems, aided with proper
methodologies, show potential to work as complementary tools to other academic
resources.

</details>


### [44] [Generative AI for FFRDCs](https://arxiv.org/abs/2509.21040)
*Arun S. Maiya*

Main category: cs.CL

TL;DR: FFRDCs use large language models to speed up analysis of text-heavy workloads.


<details>
  <summary>Details</summary>
Motivation: Manual analysis of documents is slow.

Method: Apply OnPrem$.$LLM, an open-source framework for secure and flexible application of generative AI.

Result: Demonstrates enhanced oversight and strategic analysis.

Conclusion: This approach maintains auditability and data sovereignty.

Abstract: Federally funded research and development centers (FFRDCs) face text-heavy
workloads, from policy documents to scientific and engineering papers, that are
slow to analyze manually. We show how large language models can accelerate
summarization, classification, extraction, and sense-making with only a few
input-output examples. To enable use in sensitive government contexts, we apply
OnPrem$.$LLM, an open-source framework for secure and flexible application of
generative AI. Case studies on defense policy documents and scientific corpora,
including the National Defense Authorization Act (NDAA) and National Science
Foundation (NSF) Awards, demonstrate how this approach enhances oversight and
strategic analysis while maintaining auditability and data sovereignty.

</details>


### [45] [Behind RoPE: How Does Causal Mask Encode Positional Information?](https://arxiv.org/abs/2509.21042)
*Junu Kim,Xiao Liu,Zhenghao Lin,Lei Ji,Yeyun Gong,Edward Choi*

Main category: cs.CL

TL;DR: 因果掩码在 Transformer 解码器中也提供了位置信息，即使没有显式的位置编码。


<details>
  <summary>Details</summary>
Motivation: 证明即使在没有输入参数或因果依赖性的情况下，因果掩码也能在注意力分数中诱导位置相关的模式。

Method: 理论分析和实证分析

Result: 因果掩码诱导的注意力模式倾向于偏爱附近的 query-key 对，模仿了常见的位置编码的行为。训练后的模型也表现出相同的行为，学习到的参数进一步放大了这些模式。因果掩码和 RoPE 的相互作用会将 RoPE 的相对注意力分数模式扭曲成非相对的模式。

Conclusion: 在考虑位置信息来源时，除了显式位置编码外，考虑因果掩码也很重要。

Abstract: While explicit positional encodings such as RoPE are a primary source of
positional information in Transformer decoders, the causal mask also provides
positional information. In this work, we prove that the causal mask can induce
position-dependent patterns in attention scores, even without parameters or
causal dependency in the input. Our theoretical analysis indicates that the
induced attention pattern tends to favor nearby query-key pairs, mirroring the
behavior of common positional encodings. Empirical analysis confirms that
trained models exhibit the same behavior, with learned parameters further
amplifying these patterns. Notably, we found that the interaction of causal
mask and RoPE distorts RoPE's relative attention score patterns into
non-relative ones. We consistently observed this effect in modern large
language models, suggesting the importance of considering the causal mask as a
source of positional information alongside explicit positional encodings.

</details>


### [46] [When Instructions Multiply: Measuring and Estimating LLM Capabilities of Multiple Instructions Following](https://arxiv.org/abs/2509.21051)
*Keno Harada,Yudai Yamazaki,Masachika Taniguchi,Edison Marrese-Taylor,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）同时遵循多条指令的能力，并为此创建了两个基准测试：ManyIFEval和StyleMBPP。实验表明，随着指令数量的增加，LLM的性能会下降。此外，本文还开发了三种回归模型，用于估计LLM在未见过的指令组合和不同指令数量下的性能，结果表明使用指令计数作为解释变量的 Logistic 回归模型可以预测遵循多条指令的性能，误差约为 10%。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）同时遵循多条指令的能力至关重要，因为LLM越来越多地应用于实际场景。

Method: 1. 创建两个专门的基准测试：ManyIFEval（用于文本生成，最多十条指令）和StyleMBPP（用于代码生成，最多六条指令）。
2. 使用创建的基准测试在十个LLM上进行实验，评估其性能。
3. 开发三种类型的回归模型，用于估计LLM在未见过的指令组合和不同指令数量下的性能。
4. 使用指令计数作为解释变量的 Logistic 回归模型来预测遵循多条指令的性能。

Result: 1. 随着指令数量的增加，LLM的性能会下降。
2. 使用指令计数作为解释变量的 Logistic 回归模型可以预测遵循多条指令的性能，误差约为 10%，即使对于未见过的指令组合也是如此。
3. 相对适度的样本量（ManyIFEval 为 500，StyleMBPP 为 300）足以进行性能估计。

Conclusion: 本文的研究表明，大型语言模型在同时遵循多条指令时性能会下降，但可以通过回归模型进行有效估计，即使对于未见过的指令组合也是如此。

Abstract: As large language models (LLMs) are increasingly applied to real-world
scenarios, it becomes crucial to understand their ability to follow multiple
instructions simultaneously. To systematically evaluate these capabilities, we
introduce two specialized benchmarks for fundamental domains where multiple
instructions following is important: Many Instruction-Following Eval
(ManyIFEval) for text generation with up to ten instructions, and Style-aware
Mostly Basic Programming Problems (StyleMBPP) for code generation with up to
six instructions. Our experiments with the created benchmarks across ten LLMs
reveal that performance consistently degrades as the number of instructions
increases. Furthermore, given the fact that evaluating all the possible
combinations of multiple instructions is computationally impractical in actual
use cases, we developed three types of regression models that can estimate
performance on both unseen instruction combinations and different numbers of
instructions which are not used during training. We demonstrate that a logistic
regression model using instruction count as an explanatory variable can predict
performance of following multiple instructions with approximately 10% error,
even for unseen instruction combinations. We show that relatively modest sample
sizes (500 for ManyIFEval and 300 for StyleMBPP) are sufficient for performance
estimation, enabling efficient evaluation of LLMs under various instruction
combinations.

</details>


### [47] [SoM-1K: A Thousand-Problem Benchmark Dataset for Strength of Materials](https://arxiv.org/abs/2509.21079)
*Qixin Wan,Zilong Wang,Jingwen Zhou,Wanting Wang,Ziheng Geng,Jiachen Liu,Ran Cao,Minghui Cheng,Lu Cheng*

Main category: cs.CL

TL;DR: 论文介绍了一个新的大规模多模态基准数据集SoM-1K，用于评估材料强度（SoM）问题上的基础模型。


<details>
  <summary>Details</summary>
Motivation: 评估基础模型在复杂、多模态工程问题上的性能，特别是在材料强度领域。

Method: 提出了名为“图像描述”（DoI）的新颖提示策略，该策略提供由专家生成的对视觉图的严格文本描述作为上下文，并评估了八个有代表性的基础模型。

Result: 当前的基础模型在这些工程问题上表现不佳，性能最佳的模型仅达到56.6%的准确率。当提供DoI时，大型语言模型（LLM）通常优于提供视觉图的视觉语言模型（VLM）。

Conclusion: 这项工作为工程AI建立了一个严格的基准，并强调了在基础模型中开发更强大的多模态推理能力的关键需求，尤其是在科学和工程领域。

Abstract: Foundation models have shown remarkable capabilities in various domains, but
their performance on complex, multimodal engineering problems remains largely
unexplored. We introduce SoM-1K, the first large-scale multimodal benchmark
dataset dedicated to evaluating foundation models on problems in the strength
of materials (SoM). The dataset, which contains 1,065 annotated SoM problems,
mirrors real-world engineering tasks by including both textual problem
statements and schematic diagrams. Due to the limited capabilities of current
foundation models in understanding complicated visual information, we propose a
novel prompting strategy called Descriptions of Images (DoI), which provides
rigorous expert-generated text descriptions of the visual diagrams as the
context. We evaluate eight representative foundation models, including both
large language models (LLMs) and vision language models (VLMs). Our results
show that current foundation models struggle significantly with these
engineering problems, with the best-performing model achieving only 56.6%
accuracy. Interestingly, we found that LLMs, when provided with DoI, often
outperform VLMs provided with visual diagrams. A detailed error analysis
reveals that DoI plays a crucial role in mitigating visual misinterpretation
errors, suggesting that accurate text-based descriptions can be more effective
than direct image input for current foundation models. This work establishes a
rigorous benchmark for engineering AI and highlights a critical need for
developing more robust multimodal reasoning capabilities in foundation models,
particularly in scientific and engineering contexts.

</details>


### [48] [Which Cultural Lens Do Models Adopt? On Cultural Positioning Bias and Agentic Mitigation in LLMs](https://arxiv.org/abs/2509.21080)
*Yixin Wan,Xingrun Chen,Kai-Wei Chang*

Main category: cs.CL

TL;DR: LLMs exhibit culture positioning bias, favoring mainstream US culture and treating others as outsiders.


<details>
  <summary>Details</summary>
Motivation: LLMs risk perpetuating fairness issues tied to culture, positioning generations from mainstream US culture while demonstrating externality towards non-mainstream ones.

Method: The authors propose the CultureLens benchmark with 4000 generation prompts and 3 evaluation metrics. They also propose two inference-time mitigation methods: a prompt-based Fairness Intervention Pillars (FIP) method, and a structured Mitigation via Fairness Agents (MFA) framework.

Result: Empirical evaluation reveals that models adopt insider tones in over 88 percent of US-contexted scripts but mainly outsider stances for less dominant cultures. Agent-based methods are effective in mitigating biases.

Conclusion: Agent-based methods show promise for mitigating biases in generative LLMs.

Abstract: Large language models (LLMs) have unlocked a wide range of downstream
generative applications. However, we found that they also risk perpetuating
subtle fairness issues tied to culture, positioning their generations from the
perspectives of the mainstream US culture while demonstrating salient
externality towards non-mainstream ones. In this work, we identify and
systematically investigate this novel culture positioning bias, in which an
LLM's default generative stance aligns with a mainstream view and treats other
cultures as outsiders. We propose the CultureLens benchmark with 4000
generation prompts and 3 evaluation metrics for quantifying this bias through
the lens of a culturally situated interview script generation task, in which an
LLM is positioned as an onsite reporter interviewing local people across 10
diverse cultures. Empirical evaluation on 5 state-of-the-art LLMs reveals a
stark pattern: while models adopt insider tones in over 88 percent of
US-contexted scripts on average, they disproportionately adopt mainly outsider
stances for less dominant cultures. To resolve these biases, we propose 2
inference-time mitigation methods: a baseline prompt-based Fairness
Intervention Pillars (FIP) method, and a structured Mitigation via Fairness
Agents (MFA) framework consisting of 2 pipelines: (1) MFA-SA (Single-Agent)
introduces a self-reflection and rewriting loop based on fairness guidelines.
(2) MFA-MA (Multi-Agent) structures the process into a hierarchy of specialized
agents: a Planner Agent(initial script generation), a Critique Agent (evaluates
initial script against fairness pillars), and a Refinement Agent (incorporates
feedback to produce a polished, unbiased script). Empirical results showcase
the effectiveness of agent-based methods as a promising direction for
mitigating biases in generative LLMs.

</details>


### [49] [PerHalluEval: Persian Hallucination Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2509.21104)
*Mohammad Hosseini,Kimia Hosseini,Shayan Bali,Zahra Zanjani,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了PerHalluEval，一个专门为波斯语设计的幻觉评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在低资源语言（如波斯语）中存在幻觉问题。

Method: 利用三阶段LLM驱动的流程，结合人工验证，生成合理的答案和摘要，并使用token的log概率选择最可信的幻觉实例。

Result: 对12个LLM的评估显示，这些模型在检测波斯语文本中的幻觉方面表现不佳。提供外部知识可以部分缓解幻觉。

Conclusion: 专门为波斯语训练的LLM与其他模型在幻觉方面没有显著差异。

Abstract: Hallucination is a persistent issue affecting all large language Models
(LLMs), particularly within low-resource languages such as Persian.
PerHalluEval (Persian Hallucination Evaluation) is the first dynamic
hallucination evaluation benchmark tailored for the Persian language. Our
benchmark leverages a three-stage LLM-driven pipeline, augmented with human
validation, to generate plausible answers and summaries regarding QA and
summarization tasks, focusing on detecting extrinsic and intrinsic
hallucinations. Moreover, we used the log probabilities of generated tokens to
select the most believable hallucinated instances. In addition, we engaged
human annotators to highlight Persian-specific contexts in the QA dataset in
order to evaluate LLMs' performance on content specifically related to Persian
culture. Our evaluation of 12 LLMs, including open- and closed-source models
using PerHalluEval, revealed that the models generally struggle in detecting
hallucinated Persian text. We showed that providing external knowledge, i.e.,
the original document for the summarization task, could mitigate hallucination
partially. Furthermore, there was no significant difference in terms of
hallucination when comparing LLMs specifically trained for Persian with others.

</details>


### [50] [VoiceBBQ: Investigating Effect of Content and Acoustics in Social Bias of Spoken Language Model](https://arxiv.org/abs/2509.21108)
*Junhyuk Choi,Ro-hoon Oh,Jihwan Seol,Bugeun Kim*

Main category: cs.CL

TL;DR: VoiceBBQ: A spoken extension of the BBQ dataset for measuring social bias in Spoken Language Models (SLMs).


<details>
  <summary>Details</summary>
Motivation: Social bias in SLMs can arise from content and acoustic aspects of speech.

Method: Converts BBQ contexts into controlled voice conditions to enable comparable accuracy, bias, and consistency scores.

Result: Evaluated LLaMA-Omni and Qwen2-Audio, observing architectural contrasts in how they handle acoustic, gender, and accent biases.

Conclusion: VoiceBBQ provides a testbed for diagnosing content and acoustic bias in SLMs.

Abstract: We introduce VoiceBBQ, a spoken extension of the BBQ (Bias Benchmark for
Question Answering) - a dataset that measures social bias by presenting
ambiguous or disambiguated contexts followed by questions that may elicit
stereotypical responses. Due to the nature of speech, social bias in Spoken
Language Models (SLMs) can emerge from two distinct sources: 1) content aspect
and 2) acoustic aspect. The dataset converts every BBQ context into controlled
voice conditions, enabling per-axis accuracy, bias, and consistency scores that
remain comparable to the original text benchmark. Using VoiceBBQ, we evaluate
two SLMs - LLaMA-Omni and Qwen2-Audio - and observe architectural contrasts:
LLaMA-Omni resists acoustic bias while amplifying gender and accent bias,
whereas Qwen2-Audio substantially dampens these cues while preserving content
fidelity. VoiceBBQ thus provides a compact, drop-in testbed for jointly
diagnosing content and acoustic bias across spoken language models.

</details>


### [51] [Acoustic-based Gender Differentiation in Speech-aware Language Models](https://arxiv.org/abs/2509.21125)
*Junhyuk Choi,Jihwan Seol,Nayeon Kim,Chanhee Cho,EunBin Cho,Bugeun Kim*

Main category: cs.CL

TL;DR: 语音语言模型 (SpeechLM) 通过支持基于语音的通信从根本上改变了人机交互，但它们可能表现出基于声音的性别差异，即相同的问题会根据说话者的性别导致不同的回答。本文提出了一个新的数据集，其中包含 9,208 个语音样本，分为三个类别：性别独立、性别刻板印象和性别依赖，从而能够对这种现象进行系统分析。对 LLaMA-Omni 系列的评估发现了一种悖论模式：虽然总体回答看起来与性别无关，但远非公正的回答。


<details>
  <summary>Details</summary>
Motivation: 揭示语音语言模型(SpeechLM)中存在的基于声音的性别差异问题，即相同问题因说话者性别不同而产生不同回答。现有SpeechLM虽然注重通用公平原则，但在利用性别信息方面不够完善。

Method: 1. 构建包含9,208个语音样本的数据集，分为性别独立、性别刻板印象和性别依赖三类。
2. 评估LLaMA-Omni系列模型在不同性别问题上的表现。
3. 分析中性选项和语音的感知性别对结果的影响。
4. 在语音上应用性别中和方法，观察结果变化。
5. 比较SpeechLM与其对应的LLM，确定差异来源。

Result: 1. LLaMA-Omni系列模型在总体回答上看似与性别无关，但存在悖论模式。
2. 在性别刻板印象问题中，所有模型都表现出以男性为导向的回答。
3. 在性别依赖问题中，模型未能根据性别提供合适的回答。
4. 这种模式并非源于中性选项或语音的感知性别。
5. 性别中和方法无法消除这种悖论模式。
6. 这种悖论模式主要源于Whisper语音编码器，它生成以男性为导向的声学tokens。

Conclusion: 当前的语音语言模型虽然优先考虑通用公平原则，但未能成功消除性别偏见，需要在语音技术中采用更复杂的技术来合理利用性别信息。

Abstract: Speech-aware Language Models (SpeechLMs) have fundamentally transformed
human-AI interaction by enabling voice-based communication, yet they may
exhibit acoustic-based gender differentiation where identical questions lead to
different responses based on the speaker's gender. This paper propose a new
dataset that enables systematic analysis of this phenomenon, containing 9,208
speech samples across three categories: Gender-Independent,
Gender-Stereotypical, and Gender-Dependent. We further evaluated LLaMA-Omni
series and discovered a paradoxical pattern; while overall responses seems
identical regardless of gender, the pattern is far from unbiased responses.
Specifically, in Gender-Stereotypical questions, all models consistently
exhibited male-oriented responses; meanwhile, in Gender-Dependent questions
where gender differentiation would be contextually appropriate, models
exhibited responses independent to gender instead. We also confirm that this
pattern does not result from neutral options nor perceived gender of a voice.
When we allow neutral response, models tends to respond neutrally also in
Gender-Dependent questions. The paradoxical pattern yet retains when we applied
gender neutralization methods on speech. Through comparison between SpeechLMs
with corresponding backbone LLMs, we confirmed that these paradoxical patterns
primarily stem from Whisper speech encoders, which generates male-oriented
acoustic tokens. These findings reveal that current SpeechLMs may not
successfully remove gender biases though they prioritized general fairness
principles over contextual appropriateness, highlighting the need for more
sophisticated techniques to utilize gender information properly in speech
technology.

</details>


### [52] [AutoIntent: AutoML for Text Classification](https://arxiv.org/abs/2509.21138)
*Ilya Alekseev,Roman Solomatin,Darina Rustamova,Denis Kuznetsov*

Main category: cs.CL

TL;DR: AutoIntent是一个用于文本分类任务的自动化机器学习工具。


<details>
  <summary>Details</summary>
Motivation: 解决现有AutoML工具在文本分类任务中的不足，提供端到端自动化。

Method: 模块化、sklearn-like接口，包含嵌入模型选择、分类器优化和决策阈值调整，支持多标签分类和out-of-scope检测。

Result: 在标准意图分类数据集上表现优于现有AutoML工具。

Conclusion: AutoIntent可以帮助用户平衡有效性和资源消耗。

Abstract: AutoIntent is an automated machine learning tool for text classification
tasks. Unlike existing solutions, AutoIntent offers end-to-end automation with
embedding model selection, classifier optimization, and decision threshold
tuning, all within a modular, sklearn-like interface. The framework is designed
to support multi-label classification and out-of-scope detection. AutoIntent
demonstrates superior performance compared to existing AutoML tools on standard
intent classification datasets and enables users to balance effectiveness and
resource consumption.

</details>


### [53] [Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models](https://arxiv.org/abs/2509.21155)
*Chantal Shaib,Vinith M. Suriyakumar,Levent Sagun,Byron C. Wallace,Marzyeh Ghassemi*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）在理解指令时，语法、领域和语义之间的关系，发现模型会学习语法和领域之间的虚假相关性，导致性能下降，甚至绕过安全限制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要理解指令的语义和领域才能正确响应，而语法也可能传递隐式信息。研究发现模型会学习语法和领域之间的虚假相关性，这会影响模型的性能和安全性。

Method: 论文通过构建合成训练数据集，并设计评估框架来检测模型中的语法-领域相关性。研究在OLMo-2、Llama-4-Maverick和GPT-4o等模型上进行了实验。

Result: 研究发现语法-领域相关性会降低模型在实体知识任务上的性能，并且可以被用于绕过安全限制。论文还展示了在FlanV2数据集上，开放和闭源模型中都存在这种现象。

Conclusion: 论文强调需要显式测试语法-领域相关性，并确保训练数据中语法多样性，以防止虚假相关性的产生。

Abstract: For an LLM to correctly respond to an instruction it must understand both the
semantics and the domain (i.e., subject area) of a given task-instruction pair.
However, syntax can also convey implicit information Recent work shows that
syntactic templates--frequent sequences of Part-of-Speech (PoS) tags--are
prevalent in training data and often appear in model outputs. In this work we
characterize syntactic templates, domain, and semantics in task-instruction
pairs. We identify cases of spurious correlations between syntax and domain,
where models learn to associate a domain with syntax during training; this can
sometimes override prompt semantics. Using a synthetic training dataset, we
find that the syntactic-domain correlation can lower performance (mean 0.51 +/-
0.06) on entity knowledge tasks in OLMo-2 models (1B-13B). We introduce an
evaluation framework to detect this phenomenon in trained models, and show that
it occurs on a subset of the FlanV2 dataset in open (OLMo-2-7B;
Llama-4-Maverick), and closed (GPT-4o) models. Finally, we present a case study
on the implications for safety finetuning, showing that unintended
syntactic-domain correlations can be used to bypass refusals in OLMo-2-7B
Instruct and GPT-4o. Our findings highlight two needs: (1) to explicitly test
for syntactic-domain correlations, and (2) to ensure syntactic diversity in
training data, specifically within domains, to prevent such spurious
correlations.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [54] [Leveraging NTPs for Efficient Hallucination Detection in VLMs](https://arxiv.org/abs/2509.20379)
*Ofir Azachi,Kfir Eliyahu,Eyal El Ani,Rom Himelstein,Roi Reichart,Yuval Pinter,Nitay Calderon*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于视觉语言模型（VLM）的下一个token概率（NTP）的轻量级幻觉检测方法，旨在解决VLM幻觉问题，提高模型可靠性。


<details>
  <summary>Details</summary>
Motivation: VLM的幻觉问题（视觉内容和生成文本不一致）降低了模型的可靠性。现有的检测方法计算密集且增加模型延迟。

Method: 该方法训练传统的机器学习模型，利用VLM的下一个token概率（NTP）作为信号，直接量化模型的不确定性。构建了一个包含1400个人工标注的VLM生成内容的幻觉数据集，用于测试该方法。同时，结合语言NTP和VLM的幻觉预测分数来提升性能。

Result: 结果表明，基于NTP的特征可以有效预测幻觉，简单ML模型可达到与强大VLM相当的性能。结合语言NTP和VLM幻觉预测分数可以进一步提高性能。

Conclusion: 该研究提出了一种简单轻量级的VLM幻觉检测解决方案，有望提高VLM的可靠性。

Abstract: Hallucinations of vision-language models (VLMs), which are misalignments
between visual content and generated text, undermine the reliability of VLMs.
One common approach for detecting them employs the same VLM, or a different
one, to assess generated outputs. This process is computationally intensive and
increases model latency. In this paper, we explore an efficient on-the-fly
method for hallucination detection by training traditional ML models over
signals based on the VLM's next-token probabilities (NTPs). NTPs provide a
direct quantification of model uncertainty. We hypothesize that high
uncertainty (i.e., a low NTP value) is strongly associated with hallucinations.
To test this, we introduce a dataset of 1,400 human-annotated statements
derived from VLM-generated content, each labeled as hallucinated or not, and
use it to test our NTP-based lightweight method. Our results demonstrate that
NTP-based features are valuable predictors of hallucinations, enabling fast and
simple ML models to achieve performance comparable to that of strong VLMs.
Furthermore, augmenting these NTPs with linguistic NTPs, computed by feeding
only the generated text back into the VLM, enhances hallucination detection
performance. Finally, integrating hallucination prediction scores from VLMs
into the NTP-based models led to better performance than using either VLMs or
NTPs alone. We hope this study paves the way for simple, lightweight solutions
that enhance the reliability of VLMs.

</details>


### [55] [Quasi-Synthetic Riemannian Data Generation for Writer-Independent Offline Signature Verification](https://arxiv.org/abs/2509.20420)
*Elias N. Zois,Moises Diaz,Salem Said,Miguel A. Ferrer*

Main category: cs.CV

TL;DR: 提出了一种准合成数据生成框架，利用对称正定矩阵 (SPD) 的黎曼几何，为离线手写签名验证生成数据。


<details>
  <summary>Details</summary>
Motivation: 离线手写签名验证仍然是一项具有挑战性的任务，尤其是在writer-independent的环境下，模型必须推广到看不见的个体。过去的方法通常依赖于真实世界的签名数据集进行分类器训练。

Method: 利用SPD空间中的少量真实样本作为种子，构建黎曼高斯混合模型，该模型识别黎曼中心作为合成writer，方差作为他们的属性。在每个中心上进行黎曼高斯抽样，生成positive和negative的合成SPD population。Metric learning框架利用成对的相似和不相似的SPD点，随后在真实世界的数据集上进行测试。

Result: 在包含西方和亚洲书写风格的两个流行的签名数据集上进行的实验表明，该方法在内部和交叉数据集评估协议下的有效性。

Conclusion: 结果表明，该方法实现了较低的错误率，突出了在黎曼空间中生成合成数据对于writer-independent签名验证系统的潜力。

Abstract: Offline handwritten signature verification remains a challenging task,
particularly in writer-independent settings where models must generalize across
unseen individuals. Recent developments have highlighted the advantage of
geometrically inspired representations, such as covariance descriptors on
Riemannian manifolds. However, past or present, handcrafted or data-driven
methods usually depend on real-world signature datasets for classifier
training. We introduce a quasi-synthetic data generation framework leveraging
the Riemannian geometry of Symmetric Positive Definite matrices (SPD). A small
set of genuine samples in the SPD space is the seed to a Riemannian Gaussian
Mixture which identifies Riemannian centers as synthetic writers and variances
as their properties. Riemannian Gaussian sampling on each center generates
positive as well as negative synthetic SPD populations. A metric learning
framework utilizes pairs of similar and dissimilar SPD points, subsequently
testing it over on real-world datasets. Experiments conducted on two popular
signature datasets, encompassing Western and Asian writing styles, demonstrate
the efficacy of the proposed approach under both intra- and cross- dataset
evaluation protocols. The results indicate that our quasi-synthetic approach
achieves low error rates, highlighting the potential of generating synthetic
data in Riemannian spaces for writer-independent signature verification
systems.

</details>


### [56] [Seedream 4.0: Toward Next-generation Multimodal Image Generation](https://arxiv.org/abs/2509.20427)
*Team Seedream,Yunpeng Chen,Yu Gao,Lixue Gong,Meng Guo,Qiushan Guo,Zhiyao Guo,Xiaoxia Hou,Weilin Huang,Yixuan Huang,Xiaowen Jian,Huafeng Kuang,Zhichao Lai,Fanshi Li,Liang Li,Xiaochen Lian,Chao Liao,Liyang Liu,Wei Liu,Yanzuo Lu,Zhengxiong Luo,Tongtong Ou,Guang Shi,Yichun Shi,Shiqi Sun,Yu Tian,Zhi Tian,Peng Wang,Rui Wang,Xun Wang,Ye Wang,Guofeng Wu,Jie Wu,Wenxu Wu,Yonghui Wu,Xin Xia,Xuefeng Xiao,Shuang Xu,Xin Yan,Ceyuan Yang,Jianchao Yang,Zhonghua Zhai,Chenlin Zhang,Heng Zhang,Qi Zhang,Xinyu Zhang,Yuwei Zhang,Shijia Zhao,Wenliang Zhao,Wenjia Zhu*

Main category: cs.CV

TL;DR: Seedream 4.0是一个高效、高性能的多模态图像生成系统，它统一了文本到图像（T2I）合成、图像编辑和多图像组合在一个框架中。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个能够进行高效的文本到图像生成，图像编辑和多图像组合的统一框架。

Method: 开发了一个高效的扩散Transformer和一个强大的VAE，并结合多模态后训练、对抗蒸馏、分布匹配、量化和推测解码等技术。

Result: 在文本到图像生成和多模态图像编辑方面都取得了最先进的结果，并且在复杂任务中展示了卓越的多模态能力，生成2K图像的推理时间仅为1.8秒。

Conclusion: Seedream 4.0将传统的T2I系统扩展到更具交互性和多维度的创意工具，推动了生成式AI在创造力和专业应用方面的界限。

Abstract: We introduce Seedream 4.0, an efficient and high-performance multimodal image
generation system that unifies text-to-image (T2I) synthesis, image editing,
and multi-image composition within a single framework. We develop a highly
efficient diffusion transformer with a powerful VAE which also can reduce the
number of image tokens considerably. This allows for efficient training of our
model, and enables it to fast generate native high-resolution images (e.g.,
1K-4K). Seedream 4.0 is pretrained on billions of text-image pairs spanning
diverse taxonomies and knowledge-centric concepts. Comprehensive data
collection across hundreds of vertical scenarios, coupled with optimized
strategies, ensures stable and large-scale training, with strong
generalization. By incorporating a carefully fine-tuned VLM model, we perform
multi-modal post-training for training both T2I and image editing tasks
jointly. For inference acceleration, we integrate adversarial distillation,
distribution matching, and quantization, as well as speculative decoding. It
achieves an inference time of up to 1.8 seconds for generating a 2K image
(without a LLM/VLM as PE model). Comprehensive evaluations reveal that Seedream
4.0 can achieve state-of-the-art results on both T2I and multimodal image
editing. In particular, it demonstrates exceptional multimodal capabilities in
complex tasks, including precise image editing and in-context reasoning, and
also allows for multi-image reference, and can generate multiple output images.
This extends traditional T2I systems into an more interactive and
multidimensional creative tool, pushing the boundary of generative AI for both
creativity and professional applications. Seedream 4.0 is now accessible on
https://www.volcengine.com/experience/ark?launch=seedream.

</details>


### [57] [A Contrastive Learning Framework for Breast Cancer Detection](https://arxiv.org/abs/2509.20474)
*Samia Saeed,Khuram Naveed*

Main category: cs.CV

TL;DR: 本研究提出了一种基于对比学习 (CL) 的框架，用于提高乳腺癌检测的准确性，特别是在标记数据集有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球癌症相关死亡的第二大原因，早期检测至关重要，但深度学习方法由于缺乏大型标记数据集而难以保证准确性。

Method: 利用大量未标记的乳房X光照片数据，采用半监督CL方法训练Resnet-50，并使用相似性指标，以及各种增强和转换来提高性能。

Result: 在基准数据集INbreast和MIAS上，乳腺癌检测的准确率达到96.7%。

Conclusion: 该模型在少量标记数据集上进行了调整，性能优于现有技术。

Abstract: Breast cancer, the second leading cause of cancer-related deaths globally,
accounts for a quarter of all cancer cases [1]. To lower this death rate, it is
crucial to detect tumors early, as early-stage detection significantly improves
treatment outcomes. Advances in non-invasive imaging techniques have made early
detection possible through computer-aided detection (CAD) systems which rely on
traditional image analysis to identify malignancies. However, there is a
growing shift towards deep learning methods due to their superior
effectiveness. Despite their potential, deep learning methods often struggle
with accuracy due to the limited availability of large-labeled datasets for
training. To address this issue, our study introduces a Contrastive Learning
(CL) framework, which excels with smaller labeled datasets. In this regard, we
train Resnet-50 in semi supervised CL approach using similarity index on a
large amount of unlabeled mammogram data. In this regard, we use various
augmentation and transformations which help improve the performance of our
approach. Finally, we tune our model on a small set of labelled data that
outperforms the existing state of the art. Specifically, we observed a 96.7%
accuracy in detecting breast cancer on benchmark datasets INbreast and MIAS.

</details>


### [58] [Are Foundation Models Ready for Industrial Defect Recognition? A Reality Check on Real-World Data](https://arxiv.org/abs/2509.20479)
*Simon Baeuerle,Pratik Khanna,Nils Friederich,Angelo Jovin Yamachui Sitcheu,Damir Shakirov,Andreas Steimer,Ralf Mikut*

Main category: cs.CV

TL;DR: 大型模型在文本和图像处理任务中表现出色，但实际工业图像数据上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 在系列制造中，可以使用大型模型自动进行质量检测，从而节省大量工作。

Method: 在定制的真实工业图像数据和公共图像数据上测试多个最新的大型模型。

Result: 所有模型在我们的真实数据上都失败了，而相同的模型在公共基准数据集上表现良好。

Conclusion: 大型模型在公共数据集上表现良好，但在实际工业图像数据上表现不佳。

Abstract: Foundation Models (FMs) have shown impressive performance on various text and
image processing tasks. They can generalize across domains and datasets in a
zero-shot setting. This could make them suitable for automated quality
inspection during series manufacturing, where various types of images are being
evaluated for many different products. Replacing tedious labeling tasks with a
simple text prompt to describe anomalies and utilizing the same models across
many products would save significant efforts during model setup and
implementation. This is a strong advantage over supervised Artificial
Intelligence (AI) models, which are trained for individual applications and
require labeled training data. We test multiple recent FMs on both custom
real-world industrial image data and public image data. We show that all of
those models fail on our real-world data, while the very same models perform
well on public benchmark datasets.

</details>


### [59] [Shared Neural Space: Unified Precomputed Feature Encoding for Multi-Task and Cross Domain Vision](https://arxiv.org/abs/2509.20481)
*Jing Li,Oskar Bartosz,Chengyu Wang,Michal Wnuczynski,Dilshan Godaliyadda,Michael Polley*

Main category: cs.CV

TL;DR: 提出了一种通用的神经空间（NS），用于跨视觉和图像任务预计算特征，以提高效率并减少冗余。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型大多针对特定高精度任务定制，对于包含一系列模块化任务的应用效率低下，因为每个任务都需要映射到不同的潜在域。

Method: 使用编码器-解码器框架预计算视觉和图像任务的特征。编码器学习具有转换感知、可泛化的表示，使多个下游AI模块能够共享相同的特征空间。backbone是轻量级的、基于CNN的。

Result: 成像和视觉模块，如去马赛克、去噪、深度估计和语义分割可以在NS中高效执行。

Conclusion: 该架构减少了冗余，提高了跨域泛化能力，并为高效的多任务视觉管道奠定了基础。

Abstract: The majority of AI models in imaging and vision are customized to perform on
specific high-precision task. However, this strategy is inefficient for
applications with a series of modular tasks, since each requires a mapping into
a disparate latent domain. To address this inefficiency, we proposed a
universal Neural Space (NS), where an encoder-decoder framework pre-computes
features across vision and imaging tasks. Our encoder learns transformation
aware, generalizable representations, which enable multiple downstream AI
modules to share the same feature space. This architecture reduces redundancy,
improves generalization across domain shift, and establishes a foundation for
effecient multi-task vision pipelines. Furthermore, as opposed to larger
transformer backbones, our backbone is lightweight and CNN-based, allowing for
wider across hardware. We furthur demonstrate that imaging and vision modules,
such as demosaicing, denoising, depth estimation and semantic segmentation can
be performed efficiently in the NS.

</details>


### [60] [Data-Efficient Stream-Based Active Distillation for Scalable Edge Model Deployment](https://arxiv.org/abs/2509.20484)
*Dani Manjah,Tim Bary,Benoît Gérin,Benoît Macq,Christophe de Vleeschouwer*

Main category: cs.CV

TL;DR: 本文研究了如何选择最有用的图像来训练模型，以最大限度地提高模型质量，同时保持较低的传输成本。


<details>
  <summary>Details</summary>
Motivation: 边缘相机系统不断扩展，面临着不断变化的环境，需要定期更新模型。通常，复杂的教师模型在中央服务器上运行以注释数据，然后用于训练针对计算能力有限的边缘设备量身定制的较小模型。

Method: 高置信度流式策略与基于多样性的方法相结合

Result: 对于相似的训练负载（即迭代），该方法可以产生高质量的模型，同时最大限度地减少数据集查询。

Conclusion: 高置信度流式策略与基于多样性的方法相结合，可以在保持较低传输成本的情况下，最大限度地提高模型质量。

Abstract: Edge camera-based systems are continuously expanding, facing ever-evolving
environments that require regular model updates. In practice, complex teacher
models are run on a central server to annotate data, which is then used to
train smaller models tailored to the edge devices with limited computational
power. This work explores how to select the most useful images for training to
maximize model quality while keeping transmission costs low. Our work shows
that, for a similar training load (i.e., iterations), a high-confidence
stream-based strategy coupled with a diversity-based approach produces a
high-quality model with minimal dataset queries.

</details>


### [61] [InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On](https://arxiv.org/abs/2509.20524)
*Julien Han,Shuwen Qiu,Qi Li,Xingzi Xu,Mehmet Saygin Seyfioglu,Kavosh Asadi,Karim Bouyarmane*

Main category: cs.CV

TL;DR: InstructVTON是一个通过自然语言指令控制服装样式的交互式虚拟试穿系统，它简化了用户体验，并能实现传统方法难以实现的复杂试穿场景。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿模型依赖精确的二元掩码控制生成效果，这需要专业知识且有局限性，例如无法直接实现卷起袖子等样式调整。

Method: InstructVTON利用视觉语言模型和图像分割模型，根据用户提供的图像和文本指令自动生成二元掩码。

Result: InstructVTON与现有虚拟试穿模型兼容，实现了具有样式控制的最先进结果。

Conclusion: InstructVTON通过指令控制简化了虚拟试穿流程，扩展了试穿场景，并提升了效果。

Abstract: We present InstructVTON, an instruction-following interactive virtual try-on
system that allows fine-grained and complex styling control of the resulting
generation, guided by natural language, on single or multiple garments. A
computationally efficient and scalable formulation of virtual try-on formulates
the problem as an image-guided or image-conditioned inpainting task. These
inpainting-based virtual try-on models commonly use a binary mask to control
the generation layout. Producing a mask that yields desirable result is
difficult, requires background knowledge, might be model dependent, and in some
cases impossible with the masking-based approach (e.g. trying on a long-sleeve
shirt with "sleeves rolled up" styling on a person wearing long-sleeve shirt
with sleeves down, where the mask will necessarily cover the entire sleeve).
InstructVTON leverages Vision Language Models (VLMs) and image segmentation
models for automated binary mask generation. These masks are generated based on
user-provided images and free-text style instructions. InstructVTON simplifies
the end-user experience by removing the necessity of a precisely drawn mask,
and by automating execution of multiple rounds of image generation for try-on
scenarios that cannot be achieved with masking-based virtual try-on models
alone. We show that InstructVTON is interoperable with existing virtual try-on
models to achieve state-of-the-art results with styling control.

</details>


### [62] [Innovative Deep Learning Architecture for Enhanced Altered Fingerprint Recognition](https://arxiv.org/abs/2509.20537)
*Dana A Abdullah,Dana Rasul Hamad,Bishar Rasheed Ibrahim,Sirwan Abdulwahid Aula,Aso Khaleel Ameen,Sabat Salih Hamadamin*

Main category: cs.CV

TL;DR: 这篇论文提出了DeepAFRNet，一个用于识别篡改指纹的深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 在边境控制、司法鉴定和财政准入等应用中，篡改指纹识别（AFR）是一个挑战。对抗者可以故意修改脊线模式以逃避检测，因此，对篡改指纹的稳健识别至关重要。

Method: 该方法使用VGG16骨干网络提取高维特征，并使用余弦相似度比较嵌入。

Result: 在SOCOFing Real-Altered子集上进行评估，三个难度级别（简单、中等、困难）的准确率分别为96.7%、98.76%和99.54%。

Conclusion: DeepAFRNet使用真实的篡改样本并报告各级别的指标，解决了先前基于合成篡改或有限验证协议的Prior work的局限性，并表明已准备好在安全和识别弹性至关重要的实际部署中应用。

Abstract: Altered fingerprint recognition (AFR) is challenging for biometric
verification in applications such as border control, forensics, and fiscal
admission. Adversaries can deliberately modify ridge patterns to evade
detection, so robust recognition of altered prints is essential. We present
DeepAFRNet, a deep learning recognition model that matches and recognizes
distorted fingerprint samples. The approach uses a VGG16 backbone to extract
high-dimensional features and cosine similarity to compare embeddings. We
evaluate on the SOCOFing Real-Altered subset with three difficulty levels
(Easy, Medium, Hard). With strict thresholds, DeepAFRNet achieves accuracies of
96.7 percent, 98.76 percent, and 99.54 percent for the three levels. A
threshold-sensitivity study shows that relaxing the threshold from 0.92 to 0.72
sharply degrades accuracy to 7.86 percent, 27.05 percent, and 29.51 percent,
underscoring the importance of threshold selection in biometric systems. By
using real altered samples and reporting per-level metrics, DeepAFRNet
addresses limitations of prior work based on synthetic alterations or limited
verification protocols, and indicates readiness for real-world deployments
where both security and recognition resilience are critical.

</details>


### [63] [Large Pre-Trained Models for Bimanual Manipulation in 3D](https://arxiv.org/abs/2509.20579)
*Hanna Yurchyk,Wei-Di Chang,Gregory Dudek,David Meger*

Main category: cs.CV

TL;DR: 使用DINOv2的注意力图来提升双臂机器人操作的性能。


<details>
  <summary>Details</summary>
Motivation: 为了增强双臂机器人操作

Method: 提取DINOv2的注意力图，将其转换为体素级别的语义线索，并整合到行为克隆策略中。

Result: 在RLBench双臂基准测试中，平均绝对改进为8.2%，相对增益为21.9%。

Conclusion: 注意力引导的特征化方法可以有效提升基于体素策略的性能。

Abstract: We investigate the integration of attention maps from a pre-trained Vision
Transformer into voxel representations to enhance bimanual robotic
manipulation. Specifically, we extract attention maps from DINOv2, a
self-supervised ViT model, and interpret them as pixel-level saliency scores
over RGB images. These maps are lifted into a 3D voxel grid, resulting in
voxel-level semantic cues that are incorporated into a behavior cloning policy.
When integrated into a state-of-the-art voxel-based policy, our
attention-guided featurization yields an average absolute improvement of 8.2%
and a relative gain of 21.9% across all tasks in the RLBench bimanual
benchmark.

</details>


### [64] [A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management](https://arxiv.org/abs/2509.20580)
*Xinyang Mu,Yuzhen Lu,Boyang Deng*

Main category: cs.CV

TL;DR: 本研究构建了一个蓝莓检测数据集，并对比分析了 YOLOv8-v12 和 RT-DETR v1-v2 系列的 36 种实时目标检测模型。


<details>
  <summary>Details</summary>
Motivation: 在自然环境中检测蓝莓具有挑战性，因为光照多变、遮挡和运动模糊等问题。基于深度学习的目标检测器有潜力解决这些问题，但需要大规模、多样化的数据集。

Method: 该研究使用智能手机收集了 661 张树冠图像，构建了一个包含 85,879 个标注实例的蓝莓检测数据集。并使用 Unbiased Mean Teacher-based semi-supervised learning (SSL) 对模型进行微调。

Result: YOLOv12m 实现了最佳精度，mAP@50 为 93.3%，而 RT-DETRv2-X 的 mAP@50 为 93.6%。使用 SSL 微调后，RT-DETR-v2-X 达到了最佳 mAP@50，为 94.8%。

Conclusion: 该研究发布了数据集和软件程序，以支持进一步的研究。

Abstract: Blueberry detection in natural environments remains challenging due to
variable lighting, occlusions, and motion blur due to environmental factors and
imaging devices. Deep learning-based object detectors promise to address these
challenges, but they demand a large-scale, diverse dataset that captures the
real-world complexities. Moreover, deploying these models in practical
scenarios often requires the right accuracy/speed/memory trade-off in model
selection. This study presents a novel comparative benchmark analysis of
advanced real-time object detectors, including YOLO (You Only Look Once)
(v8-v12) and RT-DETR (Real-Time Detection Transformers) (v1-v2) families,
consisting of 36 model variants, evaluated on a newly curated dataset for
blueberry detection. This dataset comprises 661 canopy images collected with
smartphones during the 2022-2023 seasons, consisting of 85,879 labelled
instances (including 36,256 ripe and 49,623 unripe blueberries) across a wide
range of lighting conditions, occlusions, and fruit maturity stages. Among the
YOLO models, YOLOv12m achieved the best accuracy with a mAP@50 of 93.3%, while
RT-DETRv2-X obtained a mAP@50 of 93.6%, the highest among all the RT-DETR
variants. The inference time varied with the model scale and complexity, and
the mid-sized models appeared to offer a good accuracy-speed balance. To
further enhance detection performance, all the models were fine-tuned using
Unbiased Mean Teacher-based semi-supervised learning (SSL) on a separate set of
1,035 unlabeled images acquired by a ground-based machine vision platform in
2024. This resulted in accuracy gains ranging from -1.4% to 2.9%, with
RT-DETR-v2-X achieving the best mAP@50 of 94.8%. More in-depth research into
SSL is needed to better leverage cross-domain unlabeled data. Both the dataset
and software programs of this study are made publicly available to support
further research.

</details>


### [65] [Region-of-Interest Augmentation for Mammography Classification under Patient-Level Cross-Validation](https://arxiv.org/abs/2509.20585)
*Farbod Bigdeli,Mohsen Mohammadagha,Ali Bigdeli*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的ROI增强策略，以提高在有限分辨率数据集和小样本量下乳腺癌筛查的性能。


<details>
  <summary>Details</summary>
Motivation: 在乳腺癌早期检测和降低死亡率方面，乳房X线筛查仍然至关重要。深度学习在自动化乳房X线照片解读方面显示出强大的潜力，但有限的分辨率数据集和小样本量限制了性能。

Method: 该方法在训练过程中，使用从预先计算的、无标签的边界框库中抽样的随机ROI裁剪来概率性地替换完整图像，并可选择抖动以增加变异性。

Result: 在Mini-DDSM数据集上，ROI增强（最佳：p_roi = 0.10，alpha = 0.10）产生了适度的平均ROC-AUC增益，性能在不同 folds 中有所不同；PR-AUC持平或略有下降。

Conclusion: 研究结果表明，简单、以数据为中心的ROI策略可以在不需要额外标签或架构修改的情况下，增强受限环境中的乳房X线照片分类。

Abstract: Breast cancer screening with mammography remains central to early detection
and mortality reduction. Deep learning has shown strong potential for
automating mammogram interpretation, yet limited-resolution datasets and small
sample sizes continue to restrict performance. We revisit the Mini-DDSM dataset
(9,684 images; 2,414 patients) and introduce a lightweight region-of-interest
(ROI) augmentation strategy. During training, full images are probabilistically
replaced with random ROI crops sampled from a precomputed, label-free
bounding-box bank, with optional jitter to increase variability. We evaluate
under strict patient-level cross-validation and report ROC-AUC, PR-AUC, and
training-time efficiency metrics (throughput and GPU memory). Because ROI
augmentation is training-only, inference-time cost remains unchanged. On
Mini-DDSM, ROI augmentation (best: p_roi = 0.10, alpha = 0.10) yields modest
average ROC-AUC gains, with performance varying across folds; PR-AUC is flat to
slightly lower. These results demonstrate that simple, data-centric ROI
strategies can enhance mammography classification in constrained settings
without requiring additional labels or architectural modifications.

</details>


### [66] [Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections](https://arxiv.org/abs/2509.20607)
*Jing Wu,Zirui Wang,Iro Laina,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: 该论文利用镜面反射提供的立体信息，通过构建虚拟相机和对称感知损失，实现了从单张图像中进行多视角立体重建。


<details>
  <summary>Details</summary>
Motivation: 利用镜面反射简化三维重建的成像过程，使其与强大的前馈重建模型兼容。

Method: 设计了一种变换，构建物理上有效的虚拟相机，并提出对称感知损失来优化姿态估计。

Result: 在真实和合成数据集上进行了大量实验，证明了该方法的有效性。

Conclusion: 该框架可以扩展到动态场景，实现有效的逐帧几何恢复。

Abstract: Mirror reflections are common in everyday environments and can provide stereo
information within a single capture, as the real and reflected virtual views
are visible simultaneously. We exploit this property by treating the reflection
as an auxiliary view and designing a transformation that constructs a
physically valid virtual camera, allowing direct pixel-domain generation of the
virtual view while adhering to the real-world imaging process. This enables a
multi-view stereo setup from a single image, simplifying the imaging process,
making it compatible with powerful feed-forward reconstruction models for
generalizable and robust 3D reconstruction. To further exploit the geometric
symmetry introduced by mirrors, we propose a symmetric-aware loss to refine
pose estimation. Our framework also naturally extends to dynamic scenes, where
each frame contains a mirror reflection, enabling efficient per-frame geometry
recovery. For quantitative evaluation, we provide a fully customizable
synthetic dataset of 16 Blender scenes, each with ground-truth point clouds and
camera poses. Extensive experiments on real-world data and synthetic data are
conducted to illustrate the effectiveness of our method.

</details>


### [67] [Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery](https://arxiv.org/abs/2509.20628)
*Yiming Xiao,Archit Gupta,Miguel Esparza,Yu-Hsuan Ho,Antonia Sebastian,Hannah Weas,Rose Houck,Ali Mostafavi*

Main category: cs.CV

TL;DR: 本文提出了一种名为FacadeTrack的街景图像分析框架，用于灾后建筑物 occupancy 评估。


<details>
  <summary>Details</summary>
Motivation: 灾后建筑物 occupancy 信息对于分诊、检查、能源恢复和资源分配至关重要。传统方法存在覆盖范围或细节信息不足的问题。

Method: 该框架将全景视频链接到地块，将视图校正到立面，并提取可解释的属性，从而驱动决策。

Result: 在两次飓风 Helene 后的调查中，两阶段方法的精确度为 0.927，召回率为 0.781，F-1 得分为 0.848。

Conclusion: 该 pipeline 提供了可审计、可扩展的 occupancy 评估，适合集成到地理空间和应急管理工作流程中。

Abstract: Building-level occupancy after disasters is vital for triage, inspections,
utility re-energization, and equitable resource allocation. Overhead imagery
provides rapid coverage but often misses facade and access cues that determine
habitability, while street-view imagery captures those details but is sparse
and difficult to align with parcels. We present FacadeTrack, a street-level,
language-guided framework that links panoramic video to parcels, rectifies
views to facades, and elicits interpretable attributes (for example, entry
blockage, temporary coverings, localized debris) that drive two decision
strategies: a transparent one-stage rule and a two-stage design that separates
perception from conservative reasoning. Evaluated across two post-Hurricane
Helene surveys, the two-stage approach achieves a precision of 0.927, a recall
of 0.781, and an F-1 score of 0.848, compared with the one-stage baseline at a
precision of 0.943, a recall of 0.728, and an F-1 score of 0.822. Beyond
accuracy, intermediate attributes and spatial diagnostics reveal where and why
residual errors occur, enabling targeted quality control. The pipeline provides
auditable, scalable occupancy assessments suitable for integration into
geospatial and emergency-management workflows.

</details>


### [68] [Human Semantic Representations of Social Interactions from Moving Shapes](https://arxiv.org/abs/2509.20673)
*Yiling Yun,Hongjing Lu*

Main category: cs.CV

TL;DR: 本研究探讨了人类如何理解移动形状中的社交互动，发现语义表征补充了视觉特征。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注视觉特征，但我们想知道人类使用什么语义表征来补充视觉特征。

Method: 研究1：让人类参与者根据他们对移动形状的印象来标记动画。研究2：通过人类相似性判断测量27个社交互动的表征几何，并将其与基于视觉特征、标签和动画描述的语义嵌入的模型预测进行比较。

Result: 语义模型为解释人类判断提供了对视觉特征的补充信息。在语义模型中，从描述中提取的基于动词的嵌入最能解释人类的相似性判断。

Conclusion: 简单展示中的社会感知反映了社会互动的语义结构，弥合了视觉和抽象表征。

Abstract: Humans are social creatures who readily recognize various social interactions
from simple display of moving shapes. While previous research has often focused
on visual features, we examine what semantic representations that humans employ
to complement visual features. In Study 1, we directly asked human participants
to label the animations based on their impression of moving shapes. We found
that human responses were distributed. In Study 2, we measured the
representational geometry of 27 social interactions through human similarity
judgments and compared it with model predictions based on visual features,
labels, and semantic embeddings from animation descriptions. We found that
semantic models provided complementary information to visual features in
explaining human judgments. Among the semantic models, verb-based embeddings
extracted from descriptions account for human similarity judgments the best.
These results suggest that social perception in simple displays reflects the
semantic structure of social interactions, bridging visual and abstract
representations.

</details>


### [69] [Enhancing Cross-View Geo-Localization Generalization via Global-Local Consistency and Geometric Equivariance](https://arxiv.org/abs/2509.20684)
*Xiaowei Wang,Di Wang,Ke Li,Yifeng Wang,Chengjian Wang,Libin Sun,Zhihong Wu,Yiming Zhang,Quan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的跨视角地理定位框架EGS，旨在提高跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的跨视角地理定位方法在应对由不同的无人机方向和视野引起的外观变化时，鲁棒性较差，并且难以建立能够捕获全局场景语义和细粒度局部细节的可靠对应关系。

Method: 本文提出了一种E(2)-Steerable CNN编码器来提取旋转和视角变化下稳定可靠的特征。此外，本文构建了一个带有虚拟超级节点的图，该节点连接到所有局部节点，从而能够聚合全局语义并将其重新分配到局部区域，从而加强全局-局部一致性。

Result: 在University-1652和SUES-200基准测试中进行的大量实验表明，EGS始终如一地实现了显着的性能提升，并在跨域CVGL中建立了新的技术水平。

Conclusion: EGS在跨域跨视角地理定位任务上表现出色，并在两个基准数据集上都取得了显著的性能提升。

Abstract: Cross-view geo-localization (CVGL) aims to match images of the same location
captured from drastically different viewpoints. Despite recent progress,
existing methods still face two key challenges: (1) achieving robustness under
severe appearance variations induced by diverse UAV orientations and fields of
view, which hinders cross-domain generalization, and (2) establishing reliable
correspondences that capture both global scene-level semantics and fine-grained
local details. In this paper, we propose EGS, a novel CVGL framework designed
to enhance cross-domain generalization. Specifically, we introduce an
E(2)-Steerable CNN encoder to extract stable and reliable features under
rotation and viewpoint shifts. Furthermore, we construct a graph with a virtual
super-node that connects to all local nodes, enabling global semantics to be
aggregated and redistributed to local regions, thereby enforcing global-local
consistency. Extensive experiments on the University-1652 and SUES-200
benchmarks demonstrate that EGS consistently achieves substantial performance
gains and establishes a new state of the art in cross-domain CVGL.

</details>


### [70] [DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection](https://arxiv.org/abs/2509.20701)
*Jiayi Zuo,Songwei Pei,Qian Li*

Main category: cs.CV

TL;DR: 红外小目标检测对于遥感应用至关重要，但由于缺乏纹理和形态特征，小目标容易与杂乱背景融合。本文提出了一种双路径边缘网络，通过解耦边缘增强和语义建模来解决这个问题。该网络使用双向交互模块捕获多尺度局部和全局特征依赖，并引入多边缘细化器，使用级联泰勒有限差分算子在多个尺度上增强细粒度边缘细节。该方法为精确的红外小目标检测和定位提供了一个有希望的解决方案，将结构语义和边缘细化结合在一个统一的框架中。


<details>
  <summary>Details</summary>
Motivation: 红外小目标易与杂乱背景融合，缺乏明显的纹理和形态特征。

Method: 提出双路径边缘网络，解耦边缘增强和语义建模；使用双向交互模块和多边缘细化器。

Result: 为精确的红外小目标检测和定位提供了一个有希望的解决方案。

Conclusion: 将结构语义和边缘细化结合在一个统一的框架中。

Abstract: Infrared small target detection is crucial for remote sensing applications
like disaster warning and maritime surveillance. However, due to the lack of
distinctive texture and morphological features, infrared small targets are
highly susceptible to blending into cluttered and noisy backgrounds. A
fundamental challenge in designing deep models for this task lies in the
inherent conflict between capturing high-resolution spatial details for minute
targets and extracting robust semantic context for larger targets, often
leading to feature misalignment and suboptimal performance. Existing methods
often rely on fixed gradient operators or simplistic attention mechanisms,
which are inadequate for accurately extracting target edges under low contrast
and high noise. In this paper, we propose a novel Dual-Path Edge Network that
explicitly addresses this challenge by decoupling edge enhancement and semantic
modeling into two complementary processing paths. The first path employs a
Bidirectional Interaction Module, which uses both Local Self-Attention and
Global Self-Attention to capture multi-scale local and global feature
dependencies. The global attention mechanism, based on a Transformer
architecture, integrates long-range semantic relationships and contextual
information, ensuring robust scene understanding. The second path introduces
the Multi-Edge Refiner, which enhances fine-grained edge details using cascaded
Taylor finite difference operators at multiple scales. This mathematical
approach, along with an attention-driven gating mechanism, enables precise edge
localization and feature enhancement for targets of varying sizes, while
effectively suppressing noise. Our method provides a promising solution for
precise infrared small target detection and localization, combining structural
semantics and edge refinement in a unified framework.

</details>


### [71] [Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset](https://arxiv.org/abs/2509.20715)
*Ruixu Zhang,Yuran Wang,Xinyi Hu,Chaoyu Mai,Wenxuan Liu,Danni Xu,Xian Zhong,Zheng Wang*

Main category: cs.CV

TL;DR: 本文提出了“群体意图”的概念，并设计了“群体意图预测”（GIF）任务，旨在通过分析个体行为和互动来预测群体意图何时发生。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别忽略了群体环境中集体意图的复杂性。为了解决这个局限性。

Method: 1. 提出了SHOT数据集，包含1979个篮球视频片段，具有多视角、多层次意图等特点。
2. 提出了GIFT框架，提取细粒度的个体特征并建模群体动态，以预测意图的出现。

Result: 实验结果验证了SHOT数据集和GIFT框架的有效性。

Conclusion: 为群体意图预测的未来研究奠定了坚实的基础。

Abstract: Intention recognition has traditionally focused on individual intentions,
overlooking the complexities of collective intentions in group settings. To
address this limitation, we introduce the concept of group intention, which
represents shared goals emerging through the actions of multiple individuals,
and Group Intention Forecasting (GIF), a novel task that forecasts when group
intentions will occur by analyzing individual actions and interactions before
the collective goal becomes apparent. To investigate GIF in a specific
scenario, we propose SHOT, the first large-scale dataset for GIF, consisting of
1,979 basketball video clips captured from 5 camera views and annotated with 6
types of individual attributes. SHOT is designed with 3 key characteristics:
multi-individual information, multi-view adaptability, and multi-level
intention, making it well-suited for studying emerging group intentions.
Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework that
extracts fine-grained individual features and models evolving group dynamics to
forecast intention emergence. Experimental results confirm the effectiveness of
SHOT and GIFT, establishing a strong foundation for future research in group
intention forecasting. The dataset is available at
https://xinyi-hu.github.io/SHOT_DATASET.

</details>


### [72] [Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection](https://arxiv.org/abs/2509.20745)
*Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang*

Main category: cs.CV

TL;DR: 提出了Neptune-X框架，通过合成数据生成和任务感知样本选择来增强训练效果，从而解决海上目标检测中数据稀缺和泛化性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的海上目标检测模型在数据不足和各种海上属性（如物体类别、视角、位置和成像环境）下的泛化能力较差，尤其是在远海环境中表现不佳。

Method: 1. 提出了X-to-Maritime，一个多模态条件生成模型，用于合成多样且逼真的海上场景。2. 设计了双向物体-水域注意力模块，捕捉物体和水环境之间的边界交互，以提高视觉保真度。3. 提出了属性相关的主动采样方法，根据任务相关性动态选择合成样本。4. 构建了Maritime Generation Dataset，这是一个专门为生成式海上学习量身定制的数据集。

Result: Neptune-X在海上场景合成方面建立了新的基准，显著提高了检测精度，特别是在具有挑战性和以前代表性不足的环境中。

Conclusion: 该研究通过数据驱动的生成选择框架Neptune-X，有效提升了海上目标检测的性能，尤其是在数据稀缺和环境复杂的场景下。

Abstract: Maritime object detection is essential for navigation safety, surveillance,
and autonomous operations, yet constrained by two key challenges: the scarcity
of annotated maritime data and poor generalization across various maritime
attributes (e.g., object category, viewpoint, location, and imaging
environment). % In particular, models trained on existing datasets often
underperform in underrepresented scenarios such as open-sea environments. To
address these challenges, we propose Neptune-X, a data-centric
generative-selection framework that enhances training effectiveness by
leveraging synthetic data generation with task-aware sample selection. From the
generation perspective, we develop X-to-Maritime, a multi-modality-conditioned
generative model that synthesizes diverse and realistic maritime scenes. A key
component is the Bidirectional Object-Water Attention module, which captures
boundary interactions between objects and their aquatic surroundings to improve
visual fidelity. To further improve downstream tasking performance, we propose
Attribute-correlated Active Sampling, which dynamically selects synthetic
samples based on their task relevance. To support robust benchmarking, we
construct the Maritime Generation Dataset, the first dataset tailored for
generative maritime learning, encompassing a wide range of semantic conditions.
Extensive experiments demonstrate that our approach sets a new benchmark in
maritime scene synthesis, significantly improving detection accuracy,
particularly in challenging and previously underrepresented settings.The code
is available at https://github.com/gy65896/Neptune-X.

</details>


### [73] [AI-Enabled Crater-Based Navigation for Lunar Mapping](https://arxiv.org/abs/2509.20748)
*Sofia McLeod,Chee-Kheng Chng,Matthew Rodda,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 本文提出了一种名为STELLA的端到端基于陨石坑导航(CBN)的pipeline，用于长期月球测绘任务。


<details>
  <summary>Details</summary>
Motivation: 现有的CBN主要研究集中在动力下降和着陆任务中，而月球测绘任务面临稀疏、倾斜的图像以及变化的光照条件等挑战。

Method: STELLA结合了基于Mask R-CNN的陨石坑检测器、无描述子的陨石坑识别模块、鲁棒的透视-n-陨石坑姿态解算器以及批量轨道确定后端。

Result: 在CRESENT+和CRESENT-365数据集上的实验表明，STELLA在各种视角、光照条件和月球纬度范围内，平均保持米级的位置精度和亚度级的姿态精度。

Conclusion: 这些结果首次全面评估了CBN在真实的月球测绘环境中的性能，并为未来任务提供了操作条件参考。

Abstract: Crater-Based Navigation (CBN) uses the ubiquitous impact craters of the Moon
observed on images as natural landmarks to determine the six degrees of freedom
pose of a spacecraft. To date, CBN has primarily been studied in the context of
powered descent and landing. These missions are typically short in duration,
with high-frequency imagery captured from a nadir viewpoint over well-lit
terrain. In contrast, lunar mapping missions involve sparse, oblique imagery
acquired under varying illumination conditions over potentially year-long
campaigns, posing significantly greater challenges for pose estimation. We
bridge this gap with STELLA - the first end-to-end CBN pipeline for
long-duration lunar mapping. STELLA combines a Mask R-CNN-based crater
detector, a descriptor-less crater identification module, a robust
perspective-n-crater pose solver, and a batch orbit determination back-end. To
rigorously test STELLA, we introduce CRESENT-365 - the first public dataset
that emulates a year-long lunar mapping mission. Each of its 15,283 images is
rendered from high-resolution digital elevation models with SPICE-derived Sun
angles and Moon motion, delivering realistic global coverage, illumination
cycles, and viewing geometries. Experiments on CRESENT+ and CRESENT-365 show
that STELLA maintains metre-level position accuracy and sub-degree attitude
accuracy on average across wide ranges of viewing angles, illumination
conditions, and lunar latitudes. These results constitute the first
comprehensive assessment of CBN in a true lunar mapping setting and inform
operational conditions that should be considered for future missions.

</details>


### [74] [Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models](https://arxiv.org/abs/2509.20751)
*Zoe Wanying He,Sean Trott,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 单模态（纯视觉和纯语言）深度模型会将输入投射到部分对齐的表征空间中。该研究系统地研究了这种现象。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉和语言模型在不同的模态上进行训练，但它们最终会产生对齐的表征空间。研究旨在理解这种对齐的出现位置、支持它的视觉或语言线索、它是否能捕捉到图像-文本多对多场景中的人类偏好，以及概念示例的聚合如何影响对齐。

Method: 该研究通过实验方法，在不同的模型层分析对齐情况，并测试对图像或文本进行语义修改后对齐的影响。使用“Pick-a-Pic”强制选择任务，将模型偏好与人类偏好进行比较。通过平均嵌入来研究示例聚合的影响。

Result: 对齐在两种模型的中后期层达到峰值，对外观变化具有鲁棒性，但在语义改变时会崩溃。模型在图像-标题匹配中反映了人类偏好，并且在多个标题对应于单个图像时，模型能够捕捉到细粒度的语义差异。示例的平均嵌入会增强对齐。

Conclusion: 单模态网络会聚到一个与人类判断对齐的共享语义代码，并通过示例聚合得到加强。

Abstract: Recent studies show that deep vision-only and language-only models--trained
on disjoint modalities--nonetheless project their inputs into a partially
aligned representational space. Yet we still lack a clear picture of where in
each network this convergence emerges, what visual or linguistic cues support
it, whether it captures human preferences in many-to-many image-text scenarios,
and how aggregating exemplars of the same concept affects alignment. Here, we
systematically investigate these questions. We find that alignment peaks in
mid-to-late layers of both model types, reflecting a shift from
modality-specific to conceptually shared representations. This alignment is
robust to appearance-only changes but collapses when semantics are altered
(e.g., object removal or word-order scrambling), highlighting that the shared
code is truly semantic. Moving beyond the one-to-one image-caption paradigm, a
forced-choice "Pick-a-Pic" task shows that human preferences for image-caption
matches are mirrored in the embedding spaces across all vision-language model
pairs. This pattern holds bidirectionally when multiple captions correspond to
a single image, demonstrating that models capture fine-grained semantic
distinctions akin to human judgments. Surprisingly, averaging embeddings across
exemplars amplifies alignment rather than blurring detail. Together, our
results demonstrate that unimodal networks converge on a shared semantic code
that aligns with human judgments and strengthens with exemplar aggregation.

</details>


### [75] [FreeInsert: Personalized Object Insertion with Geometric and Style Control](https://arxiv.org/abs/2509.20756)
*Yuhong Zhang,Han Wang,Yiwen Wang,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: 提出了一种新的免训练框架FreeInsert，通过利用3D几何信息自定义对象插入到任意场景中。


<details>
  <summary>Details</summary>
Motivation: 现有的图像编辑方法在处理个性化图像合成任务时仍然面临一定的局限性，包括缺乏对插入对象的几何控制和风格一致性。

Method: 将2D对象转换为3D，在3D级别进行交互编辑，然后从指定视图重新渲染为2D图像。渲染的图像作为几何控制，结合通过扩散适配器实现的风格和内容控制，最终通过扩散模型生成几何控制、风格一致的编辑图像。

Result: 实现了几何控制和风格一致的图像编辑。

Conclusion: 提出了FreeInsert框架，解决了在个性化图像合成任务中缺乏对插入对象的几何控制和风格一致性的问题。

Abstract: Text-to-image diffusion models have made significant progress in image
generation, allowing for effortless customized generation. However, existing
image editing methods still face certain limitations when dealing with
personalized image composition tasks. First, there is the issue of lack of
geometric control over the inserted objects. Current methods are confined to 2D
space and typically rely on textual instructions, making it challenging to
maintain precise geometric control over the objects. Second, there is the
challenge of style consistency. Existing methods often overlook the style
consistency between the inserted object and the background, resulting in a lack
of realism. In addition, the challenge of inserting objects into images without
extensive training remains significant. To address these issues, we propose
\textit{FreeInsert}, a novel training-free framework that customizes object
insertion into arbitrary scenes by leveraging 3D geometric information.
Benefiting from the advances in existing 3D generation models, we first convert
the 2D object into 3D, perform interactive editing at the 3D level, and then
re-render it into a 2D image from a specified view. This process introduces
geometric controls such as shape or view. The rendered image, serving as
geometric control, is combined with style and content control achieved through
diffusion adapters, ultimately producing geometrically controlled,
style-consistent edited images via the diffusion model.

</details>


### [76] [CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion](https://arxiv.org/abs/2509.20775)
*Maoye Ren,Praneetha Vaddamanu,Jianjin Xu,Fernando De la Torre Frade*

Main category: cs.CV

TL;DR: CustomEnhancer是一个用于增强现有身份定制模型的框架，通过人脸交换技术和预训练扩散模型获得额外的表示，实现个性化模型的生成和重建。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型在合成逼真的人像照片方面取得了显著进展，但面临场景退化、控制不足和感知身份不佳的问题。

Method: 提出了一种新颖的零样本增强管道CustomEnhancer，它利用人脸交换技术和预训练扩散模型，以零样本方式获得额外的表示，并将其编码到个性化模型中。通过提出的三流融合PerGeneration方法，统一生成和重建过程。此外，还提出了一种新的反演方法ResInversion，通过预扩散机制执行噪声校正，减少了反演时间。

Result: CustomEnhancer在场景多样性、身份保真度和免训练控制方面达到了SOTA结果，同时ResInversion的效率也优于NTI。

Conclusion: CustomEnhancer能够增强现有身份定制模型，在场景多样性、身份保真度和训练控制方面达到SOTA结果，并且ResInversion能够有效减少反演时间。

Abstract: Recently remarkable progress has been made in synthesizing realistic human
photos using text-to-image diffusion models. However, current approaches face
degraded scenes, insufficient control, and suboptimal perceptual identity. We
introduce CustomEnhancer, a novel framework to augment existing identity
customization models. CustomEnhancer is a zero-shot enhancement pipeline that
leverages face swapping techniques, pretrained diffusion model, to obtain
additional representations in a zeroshot manner for encoding into personalized
models. Through our proposed triple-flow fused PerGeneration approach, which
identifies and combines two compatible counter-directional latent spaces to
manipulate a pivotal space of personalized model, we unify the generation and
reconstruction processes, realizing generation from three flows. Our pipeline
also enables comprehensive training-free control over the generation process of
personalized models, offering precise controlled personalization for them and
eliminating the need for controller retraining for per-model. Besides, to
address the high time complexity of null-text inversion (NTI), we introduce
ResInversion, a novel inversion method that performs noise rectification via a
pre-diffusion mechanism, reducing the inversion time by 129 times. Experiments
demonstrate that CustomEnhancer reach SOTA results at scene diversity, identity
fidelity, training-free controls, while also showing the efficiency of our
ResInversion over NTI. The code will be made publicly available upon paper
acceptance.

</details>


### [77] [CompressAI-Vision: Open-source software to evaluate compression methods for computer vision tasks](https://arxiv.org/abs/2509.20777)
*Hyomin Choi,Heeji Han,Chris Rosewarne,Fabien Racapé*

Main category: cs.CV

TL;DR: 提出了一个名为CompressAI-Vision的综合评估平台，用于评估针对计算机视觉任务优化的视频压缩技术。


<details>
  <summary>Details</summary>
Motivation: 随着基于神经网络的计算机视觉应用越来越多，人们对针对计算机视觉任务优化的视频压缩技术产生了兴趣。需要一个统一的平台来实施和评估针对下游视觉任务优化的压缩方法。

Method: 该平台支持在“远程”和“分流”两种不同的推理场景中，通过比较比特率与任务准确性来评估压缩增益。

Result: 展示了评估平台的各种用例，并结合标准编解码器，在多个数据集上检查了压缩增益。

Conclusion: 该评估平台已被开发为开源软件，并被MPEG采用，用于开发机器特征编码（FCM）标准。

Abstract: With the increasing use of neural network (NN)-based computer vision
applications that process image and video data as input, interest has emerged
in video compression technology optimized for computer vision tasks. In fact,
given the variety of vision tasks, associated NN models and datasets, a
consolidated platform is needed as a common ground to implement and evaluate
compression methods optimized for downstream vision tasks. CompressAI-Vision is
introduced as a comprehensive evaluation platform where new coding tools
compete to efficiently compress the input of vision network while retaining
task accuracy in the context of two different inference scenarios: "remote" and
"split" inferencing. Our study showcases various use cases of the evaluation
platform incorporated with standard codecs (under development) by examining the
compression gain on several datasets in terms of bit-rate versus task accuracy.
This evaluation platform has been developed as open-source software and is
adopted by the Moving Pictures Experts Group (MPEG) for the development the
Feature Coding for Machines (FCM) standard. The software is available publicly
at https://github.com/InterDigitalInc/CompressAI-Vision.

</details>


### [78] [Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization](https://arxiv.org/abs/2509.20785)
*Jincai Song,Haipeng Chen,Jun Qin,Na Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种新的半监督领域泛化（CD-SSDG）框架，用于解决医学图像分割中标签数据和无标签数据之间存在领域差异的问题。


<details>
  <summary>Details</summary>
Motivation: 现有半监督领域泛化（SSDG）方法在训练集中标记和未标记数据可用于每个源域的假设在实践中并不总是满足。训练集中有限的注释和领域转移的共存是一个普遍的问题。因此，本文探讨了一个更实际和具有挑战性的场景，即跨域半监督领域泛化（CD-SSDG），其中除了训练和测试集之间的转移之外，标记和未标记训练数据之间也发生领域转移。

Method: 我们提出了一个新颖的双重监督非对称协同训练（DAC）框架，专为CD-SSDG量身定制。DAC框架集成了额外的特征级监督和每个子模型的非对称辅助任务。

Result: 在Fundus、Polyp和SCGM等真实世界医学图像分割数据集上的大量实验表明，所提出的DAC框架具有强大的泛化能力。

Conclusion: 本文提出的DAC框架能够有效地解决CD-SSDG问题，并在医学图像分割任务中取得了良好的效果。

Abstract: Semi-supervised domain generalization (SSDG) in medical image segmentation
offers a promising solution for generalizing to unseen domains during testing,
addressing domain shift challenges and minimizing annotation costs. However,
conventional SSDG methods assume labeled and unlabeled data are available for
each source domain in the training set, a condition that is not always met in
practice. The coexistence of limited annotation and domain shift in the
training set is a prevalent issue. Thus, this paper explores a more practical
and challenging scenario, cross-domain semi-supervised domain generalization
(CD-SSDG), where domain shifts occur between labeled and unlabeled training
data, in addition to shifts between training and testing sets. Existing SSDG
methods exhibit sub-optimal performance under such domain shifts because of
inaccurate pseudolabels. To address this issue, we propose a novel
dual-supervised asymmetric co-training (DAC) framework tailored for CD-SSDG.
Building upon the co-training paradigm with two sub-models offering cross
pseudo supervision, our DAC framework integrates extra feature-level
supervision and asymmetric auxiliary tasks for each sub-model. This
feature-level supervision serves to address inaccurate pseudo supervision
caused by domain shifts between labeled and unlabeled data, utilizing
complementary supervision from the rich feature space. Additionally, two
distinct auxiliary self-supervised tasks are integrated into each sub-model to
enhance domain-invariant discriminative feature learning and prevent model
collapse. Extensive experiments on real-world medical image segmentation
datasets, i.e., Fundus, Polyp, and SCGM, demonstrate the robust
generalizability of the proposed DAC framework.

</details>


### [79] [Real-Time Object Detection Meets DINOv3](https://arxiv.org/abs/2509.20787)
*Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: DEIMv2, an extension of DEIM using DINOv3 features, achieves state-of-the-art object detection results with improved performance-cost trade-off across various model sizes, outperforming previous models with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: To improve real-time object detection performance and efficiency, especially for deployment on various platforms (GPU, edge, mobile).

Method: Extending DEIM with DINOv3 features, using Spatial Tuning Adapters (STA) for larger models, and HGNetv2 with pruning for ultra-lightweight models. Also includes a simplified decoder and upgraded Dense O2O.

Result: DEIMv2 achieves superior performance-cost trade-off: DEIMv2-X reaches 57.8 AP with 50.3M parameters, DEIMv2-S achieves 50.9 AP with 9.71M parameters, and DEIMv2-Pico achieves 38.5 AP with 1.5M parameters.

Conclusion: DEIMv2 establishes new state-of-the-art results in object detection by efficiently utilizing DINOv3 features and model optimization techniques, demonstrating a significant improvement in parameter efficiency and performance across different model sizes.

Abstract: Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM
has become the mainstream training framework for real-time DETRs, significantly
outperforming the YOLO series. In this work, we extend it with DINOv3 features,
resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering
GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt
DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter
(STA), which efficiently converts DINOv3's single-scale output into multi-scale
features and complements strong semantics with fine-grained details to enhance
detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we
employ HGNetv2 with depth and width pruning to meet strict resource budgets.
Together with a simplified decoder and an upgraded Dense O2O, this unified
design enables DEIMv2 to achieve a superior performance-cost trade-off across
diverse scenarios, establishing new state-of-the-art results. Notably, our
largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters,
surpassing prior X-scale models that require over 60 million parameters for
just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model
(9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even
the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers
38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer
parameters.

</details>


### [80] [DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation](https://arxiv.org/abs/2509.20792)
*Ved Umrajkar*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的框架，将对抗训练集成到参数高效微调（PEFT）中，以提高视觉-语言模型（VLM）的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型容易受到对抗攻击，这会影响安全决策。由于CLIP是许多下游VLM的基础，因此提高其鲁棒性至关重要。

Method: 该论文提出了动态对抗课程DAC-LoRA，它通过一个智能的、渐进的攻击课程，并结合一阶平稳条件（FOSC）和TRADES损失来实现对抗训练。

Result: DAC-LoRA在不显著降低原始精度的情况下，显著提高了对抗鲁棒性。

Conclusion: DAC-LoRA框架可以很容易地集成到标准的PEFT流程中，以显著提高鲁棒性，并且具有广泛的应用前景。

Abstract: Vision-Language Models (VLMs) are foundational to critical applications like
autonomous driving, medical diagnosis, and content moderation. While
Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA enable their efficient
adaptation to specialized tasks, these models remain vulnerable to adversarial
attacks that can compromise safety-critical decisions. CLIP, the backbone for
numerous downstream VLMs, is a high-value target whose vulnerabilities can
cascade across the multimodal AI ecosystem. We propose Dynamic Adversarial
Curriculum DAC-LoRA, a novel framework that integrates adversarial training
into PEFT. The core principle of our method i.e. an intelligent curriculum of
progressively challenging attack, is general and can potentially be applied to
any iterative attack method. Guided by the First-Order Stationary Condition
(FOSC) and a TRADES-inspired loss, DAC-LoRA achieves substantial improvements
in adversarial robustness without significantly compromising clean accuracy.
Our work presents an effective, lightweight, and broadly applicable method to
demonstrate that the DAC-LoRA framework can be easily integrated into a
standard PEFT pipeline to significantly enhance robustness.

</details>


### [81] [Federated Domain Generalization with Domain-specific Soft Prompts Generation](https://arxiv.org/abs/2509.20807)
*Jianhan Wu,Xiaoyang Qu,Zhangcheng Huang,Jianzong Wang*

Main category: cs.CV

TL;DR: 提出了一种新的联邦域泛化（FDG）方法，称为具有领域特定软提示生成的联邦域泛化（FedDSPG）。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示学习的联邦域泛化（FDG）方法通常从训练样本中学习软提示，替换手动设计的提示以增强联邦模型的泛化能力。然而，这些学习到的提示表现出有限的多样性，并且倾向于忽略来自未知领域的信息。

Method: 在训练期间，我们为每个域引入领域特定的软提示（DSPs），并将内容和领域知识集成到客户端之间的生成模型中。在推理阶段，生成器用于获得看不见的目标域的DSP，从而指导未知域中的下游任务。

Result: 在多个公共数据集上的综合评估证实，我们的方法优于现有的强大基线，在FDG中实现了最先进的结果。

Conclusion: 该论文提出了一种新的联邦域泛化方法，通过生成领域特定的软提示来提高模型在未知领域的泛化能力，并在实验中取得了最先进的结果。

Abstract: Prompt learning has become an efficient paradigm for adapting CLIP to
downstream tasks. Compared with traditional fine-tuning, prompt learning
optimizes a few parameters yet yields highly competitive results, especially
appealing in federated learning for computational efficiency. engendering
domain shift among clients and posing a formidable challenge for
downstream-task adaptation. Existing federated domain generalization (FDG)
methods based on prompt learning typically learn soft prompts from training
samples, replacing manually designed prompts to enhance the generalization
ability of federated models. However, these learned prompts exhibit limited
diversity and tend to ignore information from unknown domains. We propose a
novel and effective method from a generative perspective for handling FDG
tasks, namely federated domain generalization with domain-specific soft prompts
generation (FedDSPG). Specifically, during training, we introduce
domain-specific soft prompts (DSPs) for each domain and integrate content and
domain knowledge into the generative model among clients. In the inference
phase, the generator is utilized to obtain DSPs for unseen target domains, thus
guiding downstream tasks in unknown domains. Comprehensive evaluations across
several public datasets confirm that our method outperforms existing strong
baselines in FDG, achieving state-of-the-art results.

</details>


### [82] [Revolutionizing Precise Low Back Pain Diagnosis via Contrastive Learning](https://arxiv.org/abs/2509.20813)
*Thanh Binh Le,Hoang Nhat Khang Vo,Tan-Ha Mai,Trong Nhan Phan*

Main category: cs.CV

TL;DR: LumbarCLIP: A new multimodal framework for aligning lumbar spine MRI scans with radiological reports using contrastive language-image pretraining.


<details>
  <summary>Details</summary>
Motivation: The need for diagnostic models that can analyze medical images and text reports due to the prevalence of low back pain.

Method: Integrating vision encoders (ResNet-50, Vision Transformer, Swin Transformer) with a BERT-based text encoder and projecting them into a shared embedding space via learnable projection heads. Utilizing a soft CLIP loss for contrastive training.

Result: Achieves state-of-the-art performance on downstream classification, reaching up to 95.00% accuracy and 94.75% F1-score on the test set.

Conclusion: LumbarCLIP offers a promising foundation for automated musculoskeletal diagnosis and clinical decision support.

Abstract: Low back pain affects millions worldwide, driving the need for robust
diagnostic models that can jointly analyze complex medical images and
accompanying text reports. We present LumbarCLIP, a novel multimodal framework
that leverages contrastive language-image pretraining to align lumbar spine MRI
scans with corresponding radiological descriptions. Built upon a curated
dataset containing axial MRI views paired with expert-written reports,
LumbarCLIP integrates vision encoders (ResNet-50, Vision Transformer, Swin
Transformer) with a BERT-based text encoder to extract dense representations.
These are projected into a shared embedding space via learnable projection
heads, configurable as linear or non-linear, and normalized to facilitate
stable contrastive training using a soft CLIP loss. Our model achieves
state-of-the-art performance on downstream classification, reaching up to
95.00% accuracy and 94.75% F1-score on the test set, despite inherent class
imbalance. Extensive ablation studies demonstrate that linear projection heads
yield more effective cross-modal alignment than non-linear variants. LumbarCLIP
offers a promising foundation for automated musculoskeletal diagnosis and
clinical decision support.

</details>


### [83] [Poisoning Prompt-Guided Sampling in Video Large Language Models](https://arxiv.org/abs/2509.20851)
*Yuxin Cao,Wei Song,Jingling Xue,Jin Song Dong*

Main category: cs.CV

TL;DR: 本文提出了一种针对 VideoLLM 中 prompt-guided sampling 的黑盒投毒攻击 PoisonVID。


<details>
  <summary>Details</summary>
Motivation: 先前采样策略存在漏洞，但 prompt-guided sampling 的安全性尚未探索。

Method: 通过闭环优化策略，迭代优化通用扰动，抑制有害帧相关性得分。利用 shadow VideoLLM 和轻量级语言模型构建描述集。

Result: 在三种 prompt-guided sampling 策略和三个先进 VideoLLM 上进行评估，攻击成功率达到 82% - 99%。

Conclusion: 强调了为 VideoLLM 开发未来先进采样策略的重要性。

Abstract: Video Large Language Models (VideoLLMs) have emerged as powerful tools for
understanding videos, supporting tasks such as summarization, captioning, and
question answering. Their performance has been driven by advances in frame
sampling, progressing from uniform-based to semantic-similarity-based and, most
recently, prompt-guided strategies. While vulnerabilities have been identified
in earlier sampling strategies, the safety of prompt-guided sampling remains
unexplored. We close this gap by presenting PoisonVID, the first black-box
poisoning attack that undermines prompt-guided sampling in VideoLLMs. PoisonVID
compromises the underlying prompt-guided sampling mechanism through a
closed-loop optimization strategy that iteratively optimizes a universal
perturbation to suppress harmful frame relevance scores, guided by a depiction
set constructed from paraphrased harmful descriptions leveraging a shadow
VideoLLM and a lightweight language model, i.e., GPT-4o-mini. Comprehensively
evaluated on three prompt-guided sampling strategies and across three advanced
VideoLLMs, PoisonVID achieves 82% - 99% attack success rate, highlighting the
importance of developing future advanced sampling strategies for VideoLLMs.

</details>


### [84] [Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer](https://arxiv.org/abs/2509.20854)
*Abdur Rehman,S M A Sharif,Md Abdur Rahaman,Mohamed Jismy Aashik Rasool,Seongwan Kim,Jaeho Lee*

Main category: cs.CV

TL;DR: 提出了一种新的可学习正则化方法，用于自适应平衡任务特定损失和知识蒸馏目标，从而提高量化模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练知识蒸馏方法难以平衡任务特定损失和知识蒸馏损失，尤其是在低比特量化下。

Method: 提出了一种名为Game of Regularizer (GoR) 的可学习正则化方法，它使用两个可训练参数来动态调整损失权重。

Result: 在图像分类、目标检测和大型语言模型压缩等实验中，GoR 始终优于最先进的 QAT-KD 方法。在低功耗边缘设备上，它在保持全精度准确性的同时提供更快的推理速度。还引入了一种集成蒸馏框架 QAT-EKD-GoR，该框架使用多个异构教师模型。在最佳条件下，所提出的 EKD-GoR 可以优于全精度模型。

Conclusion: 所提出的方法为实际部署提供了一个稳健的解决方案。

Abstract: Quantization-aware training (QAT) combined with knowledge distillation (KD)
is a promising strategy for compressing Artificial Intelligence (AI) models for
deployment on resource-constrained hardware. However, existing QAT-KD methods
often struggle to balance task-specific (TS) and distillation losses due to
heterogeneous gradient magnitudes, especially under low-bit quantization. We
propose Game of Regularizer (GoR), a novel learnable regularization method that
adaptively balances TS and KD objectives using only two trainable parameters
for dynamic loss weighting. GoR reduces conflict between supervision signals,
improves convergence, and boosts the performance of small quantized models
(SQMs). Experiments on image classification, object detection (OD), and large
language model (LLM) compression show that GoR consistently outperforms
state-of-the-art QAT-KD methods. On low-power edge devices, it delivers faster
inference while maintaining full-precision accuracy. We also introduce
QAT-EKD-GoR, an ensemble distillation framework that uses multiple
heterogeneous teacher models. Under optimal conditions, the proposed EKD-GoR
can outperform full-precision models, providing a robust solution for
real-world deployment.

</details>


### [85] [Plant identification based on noisy web data: the amazing performance of deep learning (LifeCLEF 2017)](https://arxiv.org/abs/2509.20856)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2017 植物识别挑战赛旨在评估通过网络收集的大型噪声训练数据集与专家检查的较小但可信的训练数据集的竞争力。


<details>
  <summary>Details</summary>
Motivation: 当前植物识别系统受益于深度学习图像分类的进展和国际合作项目，但多数植物物种仍缺乏图片或图片质量不高。为了解决这个问题，研究者探索了使用网络上大量的但可能存在标签错误的图片。

Method: 通过LifeCLEF 2017植物挑战赛，比较使用大型噪声网络数据集和小型专家数据集的植物识别效果。测试数据集来自Pl@ntNet 移动应用程序。

Result: 论文介绍了挑战赛的资源和评估，总结了参与研究小组使用的方法和系统，并分析了主要结果。

Conclusion: 论文总结了LifeCLEF 2017植物识别挑战赛的发现，比较了不同训练策略的效果。

Abstract: The 2017-th edition of the LifeCLEF plant identification challenge is an
important milestone towards automated plant identification systems working at
the scale of continental floras with 10.000 plant species living mainly in
Europe and North America illustrated by a total of 1.1M images. Nowadays, such
ambitious systems are enabled thanks to the conjunction of the dazzling recent
progress in image classification with deep learning and several outstanding
international initiatives, such as the Encyclopedia of Life (EOL), aggregating
the visual knowledge on plant species coming from the main national botany
institutes. However, despite all these efforts the majority of the plant
species still remain without pictures or are poorly illustrated. Outside the
institutional channels, a much larger number of plant pictures are available
and spread on the web through botanist blogs, plant lovers web-pages, image
hosting websites and on-line plant retailers. The LifeCLEF 2017 plant challenge
presented in this paper aimed at evaluating to what extent a large noisy
training dataset collected through the web and containing a lot of labelling
errors can compete with a smaller but trusted training dataset checked by
experts. To fairly compare both training strategies, the test dataset was
created from a third data source, i.e. the Pl@ntNet mobile application that
collects millions of plant image queries all over the world. This paper
presents more precisely the resources and assessments of the challenge,
summarizes the approaches and systems employed by the participating research
groups, and provides an analysis of the main outcomes.

</details>


### [86] [TasselNetV4: A vision foundation model for cross-scene, cross-scale, and cross-species plant counting](https://arxiv.org/abs/2509.20857)
*Xiaonan Hu,Xuebing Li,Jinyu Xu,Abdulkadir Duran Adan,Letian Zhou,Xuhui Zhu,Yanan Li,Wei Guo,Shouyang Liu,Wenzhong Liu,Hao Lu*

Main category: cs.CV

TL;DR: TasselNetV4: a vision foundation model for cross-scene, cross-scale, and cross-species plant counting.


<details>
  <summary>Details</summary>
Motivation: Counting plants is important for agriculture, but existing methods are species-specific and struggle with biodiversity. Current class-agnostic counting models are suboptimal for plants due to their dynamic and non-rigid structure.

Method: A new extension of TasselNet, TasselNetV4, which combines local counting with an extract-and-match paradigm. It uses a vision transformer and multi-branch box-aware local counters to improve robustness.

Result: TasselNetV4 outperforms state-of-the-art class-agnostic counting models on two challenging datasets (PAC-105 and PAC-Somalia) in both counting performance and efficiency.

Conclusion: TasselNetV4 is a vision foundation model for cross-scene, cross-scale, and cross-species plant counting.

Abstract: Accurate plant counting provides valuable information for agriculture such as
crop yield prediction, plant density assessment, and phenotype quantification.
Vision-based approaches are currently the mainstream solution. Prior art
typically uses a detection or a regression model to count a specific plant.
However, plants have biodiversity, and new cultivars are increasingly bred each
year. It is almost impossible to exhaust and build all species-dependent
counting models. Inspired by class-agnostic counting (CAC) in computer vision,
we argue that it is time to rethink the problem formulation of plant counting,
from what plants to count to how to count plants. In contrast to most daily
objects with spatial and temporal invariance, plants are dynamic, changing with
time and space. Their non-rigid structure often leads to worse performance than
counting rigid instances like heads and cars such that current CAC and
open-world detection models are suboptimal to count plants. In this work, we
inherit the vein of the TasselNet plant counting model and introduce a new
extension, TasselNetV4, shifting from species-specific counting to
cross-species counting. TasselNetV4 marries the local counting idea of
TasselNet with the extract-and-match paradigm in CAC. It builds upon a plain
vision transformer and incorporates novel multi-branch box-aware local counters
used to enhance cross-scale robustness. Two challenging datasets, PAC-105 and
PAC-Somalia, are harvested. Extensive experiments against state-of-the-art CAC
models show that TasselNetV4 achieves not only superior counting performance
but also high efficiency.Our results indicate that TasselNetV4 emerges to be a
vision foundation model for cross-scene, cross-scale, and cross-species plant
counting.

</details>


### [87] [SD-RetinaNet: Topologically Constrained Semi-Supervised Retinal Lesion and Layer Segmentation in OCT](https://arxiv.org/abs/2509.20864)
*Botond Fazekas,Guilherme Aresta,Philipp Seeböck,Julia Mai,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: 提出了一种新的半监督模型，该模型引入了完全可微的生物标志物拓扑引擎，以强制执行病变和层的解剖学上正确的分割。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常会产生解剖学上不合理的分割，无法有效地模拟层-病变相互作用，并且缺乏对拓扑正确性的保证。

Method: 该模型学习一种解缠结的表示，分离空间和风格因素。这使得更真实的层分割并改善病变分割，同时严格执行病变位置在其相对于分割层的解剖学上合理的位置。

Result: 在OCT扫描的公共和内部数据集上评估了所提出的模型，结果表明，该模型在病变和层分割方面均优于当前的技术水平，同时证明了使用部分注释的训练数据将层分割推广到病理病例的能力。

Conclusion: 我们的结果证明了在半监督学习中使用解剖约束来准确、稳健和可信的视网膜生物标志物分割的潜力。

Abstract: Optical coherence tomography (OCT) is widely used for diagnosing and
monitoring retinal diseases, such as age-related macular degeneration (AMD).
The segmentation of biomarkers such as layers and lesions is essential for
patient diagnosis and follow-up. Recently, semi-supervised learning has shown
promise in improving retinal segmentation performance. However, existing
methods often produce anatomically implausible segmentations, fail to
effectively model layer-lesion interactions, and lack guarantees on topological
correctness.
  To address these limitations, we propose a novel semi-supervised model that
introduces a fully differentiable biomarker topology engine to enforce
anatomically correct segmentation of lesions and layers. This enables joint
learning with bidirectional influence between layers and lesions, leveraging
unlabeled and diverse partially labeled datasets. Our model learns a
disentangled representation, separating spatial and style factors. This
approach enables more realistic layer segmentations and improves lesion
segmentation, while strictly enforcing lesion location in their anatomically
plausible positions relative to the segmented layers.
  We evaluate the proposed model on public and internal datasets of OCT scans
and show that it outperforms the current state-of-the-art in both lesion and
layer segmentation, while demonstrating the ability to generalize layer
segmentation to pathological cases using partially annotated training data. Our
results demonstrate the potential of using anatomical constraints in
semi-supervised learning for accurate, robust, and trustworthy retinal
biomarker segmentation.

</details>


### [88] [Plant identification in an open-world (LifeCLEF 2016)](https://arxiv.org/abs/2509.20870)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF植物识别挑战旨在评估大规模植物识别方法和系统，接近真实世界的生物多样性监测场景。


<details>
  <summary>Details</summary>
Motivation: 在真实场景中，植物识别系统需要能够识别未知的植物类别，而不仅仅是训练集中已知的类别。

Method: 使用了包含超过11万张图片和1000种植物物种的数据集，这些数据来自一个大型参与式传感平台。评估任务被设置为开放集识别问题。

Result: 该挑战评估了参与研究小组的方法和系统，并分析了主要结果。

Conclusion: 总结了挑战的资源和评估，概述了参与研究小组采用的方法和系统，并分析了主要结果。

Abstract: The LifeCLEF plant identification challenge aims at evaluating plant
identification methods and systems at a very large scale, close to the
conditions of a real-world biodiversity monitoring scenario. The 2016-th
edition was actually conducted on a set of more than 110K images illustrating
1000 plant species living in West Europe, built through a large-scale
participatory sensing platform initiated in 2011 and which now involves tens of
thousands of contributors. The main novelty over the previous years is that the
identification task was evaluated as an open-set recognition problem, i.e. a
problem in which the recognition system has to be robust to unknown and never
seen categories. Beyond the brute-force classification across the known classes
of the training set, the big challenge was thus to automatically reject the
false positive classification hits that are caused by the unknown classes. This
overview presents more precisely the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [89] [SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering](https://arxiv.org/abs/2509.20871)
*Yan Zhang,Jiaqing Lin,Miao Zhang,Kui Xiao,Xiaoju Hou,Yue Zhao,Zhifei Li*

Main category: cs.CV

TL;DR: SCRA-VQA通过总结和重新排序标题来减少噪声，并生成上下文示例，以提高LLM在知识库视觉问答中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖带有噪声的图像标题，且LLM不理解VQA任务，限制了推理能力。

Method: 提出SCRA-VQA，使用预训练的视觉语言模型将图像转换为标题，并总结和重新排序标题以排除不相关信息，生成上下文示例。

Result: 在OK-VQA和A-OKVQA数据集上，SCRA-VQA分别达到了38.8%和34.6%的准确率。

Conclusion: SCRA-VQA通过标题重排序使LLM更好地理解图像信息和问题，从而增强了模型的推理能力和任务适应性，无需昂贵的端到端训练。

Abstract: Acquiring high-quality knowledge is a central focus in Knowledge-Based Visual
Question Answering (KB-VQA). Recent methods use large language models (LLMs) as
knowledge engines for answering. These methods generally employ image captions
as visual text descriptions to assist LLMs in interpreting images. However, the
captions frequently include excessive noise irrelevant to the question, and
LLMs generally do not comprehend VQA tasks, limiting their reasoning
capabilities. To address this issue, we propose the Summarized Caption-Rerank
Augmented VQA (SCRA-VQA), which employs a pre-trained visual language model to
convert images into captions. Moreover, SCRA-VQA generates contextual examples
for the captions while simultaneously summarizing and reordering them to
exclude unrelated information. The caption-rerank process enables LLMs to
understand the image information and questions better, thus enhancing the
model's reasoning ability and task adaptability without expensive end-to-end
training. Based on an LLM with 6.7B parameters, SCRA-VQA performs excellently
on two challenging knowledge-based VQA datasets: OK-VQA and A-OKVQA, achieving
accuracies of 38.8% and 34.6%. Our code is available at
https://github.com/HubuKG/SCRA-VQA.

</details>


### [90] [The Unanticipated Asymmetry Between Perceptual Optimization and Assessment](https://arxiv.org/abs/2509.20878)
*Jiabei Zhang,Qi Wang,Siyu Wu,Du Chen,Tianhe Wu*

Main category: cs.CV

TL;DR: 本文研究了感知优化和图像质量评估(IQA)之间的关系，发现擅长IQA的保真度指标不一定对感知优化有效，并且鉴别器设计在优化中起着决定性作用。


<details>
  <summary>Details</summary>
Motivation: 探索感知优化目标函数和图像质量评估指标之间的相关性，特别是保真度目标和对抗性目标。

Method: 通过系统分析，研究了不同保真度指标和鉴别器设计对感知优化和IQA的影响。

Result: 发现擅长IQA的保真度指标不一定对感知优化有效，尤其是在对抗训练下。同时，patch-level和卷积架构比其他架构能提供更真实的细节重建。

Conclusion: 论文揭示了感知优化和评估之间的不对称性，以及鉴别器设计在优化中的关键作用，为感知优化方法的设计提供了指导。

Abstract: Perceptual optimization is primarily driven by the fidelity objective, which
enforces both semantic consistency and overall visual realism, while the
adversarial objective provides complementary refinement by enhancing perceptual
sharpness and fine-grained detail. Despite their central role, the correlation
between their effectiveness as optimization objectives and their capability as
image quality assessment (IQA) metrics remains underexplored. In this work, we
conduct a systematic analysis and reveal an unanticipated asymmetry between
perceptual optimization and assessment: fidelity metrics that excel in IQA are
not necessarily effective for perceptual optimization, with this misalignment
emerging more distinctly under adversarial training. In addition, while
discriminators effectively suppress artifacts during optimization, their
learned representations offer only limited benefits when reused as backbone
initializations for IQA models. Beyond this asymmetry, our findings further
demonstrate that discriminator design plays a decisive role in shaping
optimization, with patch-level and convolutional architectures providing more
faithful detail reconstruction than vanilla or Transformer-based alternatives.
These insights advance the understanding of loss function design and its
connection to IQA transferability, paving the way for more principled
approaches to perceptual optimization.

</details>


### [91] [Integrating Object Interaction Self-Attention and GAN-Based Debiasing for Visual Question Answering](https://arxiv.org/abs/2509.20884)
*Zhifei Li,Feng Qiu,Yiran Wang,Yujing Xia,Kui Xiao,Miao Zhang,Yan Zhang*

Main category: cs.CV

TL;DR: 这篇论文介绍了一种名为IOG-VQA的新模型，它通过结合对象交互自注意和基于GAN的去偏方法来提高VQA模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VQA模型容易受到训练数据中偏差的影响，过度依赖表面模式，并且在推广到不同的问题和图像时表现不足。本文旨在解决这些问题。

Method: 该模型结合了对象交互自注意机制和基于GAN的去偏框架。自注意机制允许模型捕获图像中对象之间复杂的交互，而GAN-based的去偏框架生成无偏的数据分布。

Result: 在VQA-CP v1和VQA-CP v2数据集上的大量实验表明，该模型与现有方法相比表现出色，尤其是在处理有偏差和不平衡的数据分布方面。

Conclusion: IOG-VQA模型有效地结合了视觉和文本信息，解决了VQA数据集中固有的偏差问题，强调了在推进VQA任务中解决对象交互和数据集偏差的重要性。

Abstract: Visual Question Answering (VQA) presents a unique challenge by requiring
models to understand and reason about visual content to answer questions
accurately. Existing VQA models often struggle with biases introduced by the
training data, leading to over-reliance on superficial patterns and inadequate
generalization to diverse questions and images. This paper presents a novel
model, IOG-VQA, which integrates Object Interaction Self-Attention and
GAN-Based Debiasing to enhance VQA model performance. The self-attention
mechanism allows our model to capture complex interactions between objects
within an image, providing a more comprehensive understanding of the visual
context. Meanwhile, the GAN-based debiasing framework generates unbiased data
distributions, helping the model to learn more robust and generalizable
features. By leveraging these two components, IOG-VQA effectively combines
visual and textual information to address the inherent biases in VQA datasets.
Extensive experiments on the VQA-CP v1 and VQA-CP v2 datasets demonstrate that
our model shows excellent performance compared with the existing methods,
particularly in handling biased and imbalanced data distributions highlighting
the importance of addressing both object interactions and dataset biases in
advancing VQA tasks. Our code is available at
https://github.com/HubuKG/IOG-VQA.

</details>


### [92] [Nuclear Diffusion Models for Low-Rank Background Suppression in Videos](https://arxiv.org/abs/2509.20886)
*Tristan S. W. Stevens,Oisín Nolan,Jean-Luc Robert,Ruud J. G. van Sloun*

Main category: cs.CV

TL;DR: 提出了一种混合框架，该框架集成了低秩时间建模与扩散后验采样，用于高保真视频修复。


<details>
  <summary>Details</summary>
Motivation: 视频序列通常包含结构化噪声和背景伪影，这给准确分析和修复带来了挑战。传统的鲁棒主成分方法（RPCA）的稀疏性假设通常无法捕捉真实视频数据中丰富的变异性。

Method: 提出了 Nuclear Diffusion 方法，它结合了低秩时间建模与扩散后验采样。

Result: 在实际医疗成像问题（即心脏超声去雾）上进行了评估，结果表明，与传统的 RPCA 相比，该方法在对比度增强（gCNR）和信号保留（KS 统计）方面表现出改进的去雾性能。

Conclusion: 将基于模型的时域模型与深度生成先验相结合，具有实现高保真视频修复的潜力。

Abstract: Video sequences often contain structured noise and background artifacts that
obscure dynamic content, posing challenges for accurate analysis and
restoration. Robust principal component methods address this by decomposing
data into low-rank and sparse components. Still, the sparsity assumption often
fails to capture the rich variability present in real video data. To overcome
this limitation, a hybrid framework that integrates low-rank temporal modeling
with diffusion posterior sampling is proposed. The proposed method, Nuclear
Diffusion, is evaluated on a real-world medical imaging problem, namely cardiac
ultrasound dehazing, and demonstrates improved dehazing performance compared to
traditional RPCA concerning contrast enhancement (gCNR) and signal preservation
(KS statistic). These results highlight the potential of combining model-based
temporal models with deep generative priors for high-fidelity video
restoration.

</details>


### [93] [FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies](https://arxiv.org/abs/2509.20890)
*Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的合成图像检测方法，通过分析生成过程中引入的伪影来区分合成图像和真实图像。


<details>
  <summary>Details</summary>
Motivation: 合成图像的日益逼真对合成图像检测提出了重大挑战。

Method: 该方法利用局部像素依赖性(LPD)重建合成图像，以揭示纹理连续性和边缘一致性的中断。在此基础上，提出了一个轻量级神经网络FerretNet。

Result: FerretNet在仅使用4类ProGAN数据集训练的情况下，在包含22个生成模型的开放世界基准测试中，实现了97.1%的平均准确率，超过了最先进的方法10.6%。

Conclusion: FerretNet是一种高效、鲁棒的合成图像检测方法。

Abstract: The increasing realism of synthetic images generated by advanced models such
as VAEs, GANs, and LDMs poses significant challenges for synthetic image
detection. To address this issue, we explore two artifact types introduced
during the generation process: (1) latent distribution deviations and (2)
decoding-induced smoothing effects, which manifest as inconsistencies in local
textures, edges, and color transitions. Leveraging local pixel dependencies
(LPD) properties rooted in Markov Random Fields, we reconstruct synthetic
images using neighboring pixel information to expose disruptions in texture
continuity and edge coherence. Building upon LPD, we propose FerretNet, a
lightweight neural network with only 1.1M parameters that delivers efficient
and robust synthetic image detection. Extensive experiments demonstrate that
FerretNet, trained exclusively on the 4-class ProGAN dataset, achieves an
average accuracy of 97.1% on an open-world benchmark comprising across 22
generative models, surpassing state-of-the-art methods by 10.6%.

</details>


### [94] [Concepts in Motion: Temporal Bottlenecks for Interpretable Video Classification](https://arxiv.org/abs/2509.20899)
*Patrick Knab,Sascha Marton,Philipp J. Schubert,Drago Guggiana,Christian Bartelt*

Main category: cs.CV

TL;DR: 提出了一种名为MoTIF的架构，用于视频分类，通过概念瓶颈框架处理任意长度的视频序列。


<details>
  <summary>Details</summary>
Motivation: 将概念瓶颈模型从静态图像扩展到视频数据是一个挑战，因为视频中存在时间依赖性，这对于捕捉动作和事件至关重要。

Method: 设计了一个受Transformer启发的架构MoTIF，用于视频分类，并处理任意长度的序列。该设计显式地实现了三个互补的视角：整个视频的全局概念重要性、特定窗口内的局部概念相关性以及概念随时间的时间依赖性。

Result: 结果表明，基于概念的建模范式可以有效地转移到视频数据，从而更好地理解时间上下文中概念的贡献，同时保持了具有竞争力的性能。

Conclusion: 概念瓶颈模型可以有效扩展到视频领域，MoTIF架构实现了对视频中概念的时间依赖性建模，并在视频分类任务中取得了良好效果。

Abstract: Conceptual models such as Concept Bottleneck Models (CBMs) have driven
substantial progress in improving interpretability for image classification by
leveraging human-interpretable concepts. However, extending these models from
static images to sequences of images, such as video data, introduces a
significant challenge due to the temporal dependencies inherent in videos,
which are essential for capturing actions and events. In this work, we
introduce MoTIF (Moving Temporal Interpretable Framework), an architectural
design inspired by a transformer that adapts the concept bottleneck framework
for video classification and handles sequences of arbitrary length. Within the
video domain, concepts refer to semantic entities such as objects, attributes,
or higher-level components (e.g., 'bow', 'mount', 'shoot') that reoccur across
time - forming motifs collectively describing and explaining actions. Our
design explicitly enables three complementary perspectives: global concept
importance across the entire video, local concept relevance within specific
windows, and temporal dependencies of a concept over time. Our results
demonstrate that the concept-based modeling paradigm can be effectively
transferred to video data, enabling a better understanding of concept
contributions in temporal contexts while maintaining competitive performance.
Code available at github.com/patrick-knab/MoTIF.

</details>


### [95] [FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data](https://arxiv.org/abs/2509.20905)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

TL;DR: FSMODNet: A framework for few-shot multispectral object detection (FSMOD) that combines visible and thermal imagery using deformable attention.


<details>
  <summary>Details</summary>
Motivation: Detecting objects across visible and thermal modalities with minimal annotated data is challenging.

Method: A framework named FSMODNet leverages cross-modality feature integration with deformable attention.

Result: Effective object detection performance in challenging low-data regimes, outperforming several baselines.

Conclusion: The proposed method demonstrates robust adaptability in complex illumination and environmental conditions for FSMOD.

Abstract: Few-shot multispectral object detection (FSMOD) addresses the challenge of
detecting objects across visible and thermal modalities with minimal annotated
data. In this paper, we explore this complex task and introduce a framework
named "FSMODNet" that leverages cross-modality feature integration to improve
detection performance even with limited labels. By effectively combining the
unique strengths of visible and thermal imagery using deformable attention, the
proposed method demonstrates robust adaptability in complex illumination and
environmental conditions. Experimental results on two public datasets show
effective object detection performance in challenging low-data regimes,
outperforming several baselines we established from state-of-the-art models.
All code, models, and experimental data splits can be found at
https://anonymous.4open.science/r/Test-B48D.

</details>


### [96] [Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences](https://arxiv.org/abs/2509.20906)
*Julius Pesonen,Arno Solin,Eija Honkavaara*

Main category: cs.CV

TL;DR: 本文提出了一种基于粒子滤波器的3D目标定位方法，适用于远距离目标或计算资源受限的任务。


<details>
  <summary>Details</summary>
Motivation: 基于相机测量序列的3D目标定位对于无人机野火监测等安全关键监控任务至关重要。传统的密集深度估计或3D场景重建方法在远距离目标或计算资源受限的情况下不可行。

Method: 使用粒子滤波器解决单目标和多目标场景下的定位问题。该方法通过3D仿真和基于无人机的图像分割序列进行研究，其中图像分割序列具有基于全球导航卫星系统（GNSS）的相机姿态估计。

Result: 结果表明，粒子滤波器可用于解决其他解决方案失败的情况下，基于相机姿态和图像分割的实际定位任务。粒子滤波器独立于检测方法。

Conclusion: 该研究表明，所提出的方法与预先存在的图像分割模型相结合，可以进行基于无人机的野火监测。

Abstract: 3D object localisation based on a sequence of camera measurements is
essential for safety-critical surveillance tasks, such as drone-based wildfire
monitoring. Localisation of objects detected with a camera can typically be
solved with dense depth estimation or 3D scene reconstruction. However, in the
context of distant objects or tasks limited by the amount of available
computational resources, neither solution is feasible. In this paper, we show
that the task can be solved using particle filters for both single and multiple
target scenarios. The method was studied using a 3D simulation and a
drone-based image segmentation sequence with global navigation satellite system
(GNSS)-based camera pose estimates. The results showed that a particle filter
can be used to solve practical localisation tasks based on camera poses and
image segments in these situations where other solutions fail. The particle
filter is independent of the detection method, making it flexible for new
tasks. The study also demonstrates that drone-based wildfire monitoring can be
conducted using the proposed method paired with a pre-existing image
segmentation model.

</details>


### [97] [SwinMamba: A hybrid local-global mamba framework for enhancing semantic segmentation of remotely sensed images](https://arxiv.org/abs/2509.20918)
*Qinfeng Zhu,Han Li,Liang He,Lei Fan*

Main category: cs.CV

TL;DR: SwinMamba，一种新的遥感图像语义分割框架，它结合了局部和全局扫描，以提高模型对局部和全局特征的感知。


<details>
  <summary>Details</summary>
Motivation: 遥感图像的语义分割任务具有挑战性，因为遥感数据具有高空间分辨率、复杂场景结构和多样化的对象尺度。Vision Mamba虽然具有全局感受野和低计算复杂度，但它依赖于全局扫描，容易忽略关键的局部特征。

Method: 提出 SwinMamba，它在移位窗口内集成了局部 Mamba 风格的扫描和全局感受野。SwinMamba 的前两个阶段执行局部扫描以捕获细粒度细节，而后两个阶段利用全局扫描来融合更广泛的上下文信息。重叠的移位窗口增强了区域间的信息交换。

Result: 在 LoveDA 和 ISPRS Potsdam 数据集上的实验表明，SwinMamba 优于最先进的方法。

Conclusion: SwinMamba 在遥感图像语义分割中具有有效性和潜力。

Abstract: Semantic segmentation of remote sensing imagery is a fundamental task in
computer vision, supporting a wide range of applications such as land use
classification, urban planning, and environmental monitoring. However, this
task is often challenged by the high spatial resolution, complex scene
structures, and diverse object scales present in remote sensing data. To
address these challenges, various deep learning architectures have been
proposed, including convolutional neural networks, Vision Transformers, and the
recently introduced Vision Mamba. Vision Mamba features a global receptive
field and low computational complexity, demonstrating both efficiency and
effectiveness in image segmentation. However, its reliance on global scanning
tends to overlook critical local features, such as textures and edges, which
are essential for achieving accurate segmentation in remote sensing contexts.
To tackle this limitation, we propose SwinMamba, a novel framework inspired by
the Swin Transformer. SwinMamba integrates localized Mamba-style scanning
within shifted windows with a global receptive field, to enhance the model's
perception of both local and global features. Specifically, the first two
stages of SwinMamba perform local scanning to capture fine-grained details,
while its subsequent two stages leverage global scanning to fuse broader
contextual information. In our model, the use of overlapping shifted windows
enhances inter-region information exchange, facilitating more robust feature
integration across the entire image. Extensive experiments on the LoveDA and
ISPRS Potsdam datasets demonstrate that SwinMamba outperforms state-of-the-art
methods, underscoring its effectiveness and potential as a superior solution
for semantic segmentation of remotely sensed imagery.

</details>


### [98] [Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework](https://arxiv.org/abs/2509.20923)
*Wenhao Tang,Heng Fang,Ge Wu,Xiang Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于包的MIL框架，用于解决计算病理学中全切片图像（WSI）分析中遇到的序列长度过长、长度变化大和监督有限等问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在有限监督下为了保持数据异质性，常常牺牲训练效率和优化。本文旨在解决这些挑战。

Method: 该框架将多个采样的可变长度特征序列打包成固定长度的序列，实现批量训练，同时保留数据异质性。此外，引入残差分支，将来自多个切片的丢弃特征合成为一个超切片，并用定制标签进行训练，提供多切片监督，同时减轻采样造成的特征损失。同时，引入注意力驱动的下采样器来压缩两个分支中的特征，以减少冗余。

Result: 该方法在PANDA(UNI)中实现了高达8%的精度提升，同时只使用了12%的训练时间。

Conclusion: 专注于CPath中的数据挑战在基础模型时代具有巨大的潜力。

Abstract: Computational pathology (CPath) digitizes pathology slides into whole slide
images (WSIs), enabling analysis for critical healthcare tasks such as cancer
diagnosis and prognosis. However, WSIs possess extremely long sequence lengths
(up to 200K), significant length variations (from 200 to 200K), and limited
supervision. These extreme variations in sequence length lead to high data
heterogeneity and redundancy. Conventional methods often compromise on training
efficiency and optimization to preserve such heterogeneity under limited
supervision. To comprehensively address these challenges, we propose a
pack-based MIL framework. It packs multiple sampled, variable-length feature
sequences into fixed-length ones, enabling batched training while preserving
data heterogeneity. Moreover, we introduce a residual branch that composes
discarded features from multiple slides into a hyperslide which is trained with
tailored labels. It offers multi-slide supervision while mitigating feature
loss from sampling. Meanwhile, an attention-driven downsampler is introduced to
compress features in both branches to reduce redundancy. By alleviating these
challenges, our approach achieves an accuracy improvement of up to 8% while
using only 12% of the training time in the PANDA(UNI). Extensive experiments
demonstrate that focusing data challenges in CPath holds significant potential
in the era of foundation models. The code is
https://github.com/FangHeng/PackMIL

</details>


### [99] [SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation](https://arxiv.org/abs/2509.20927)
*Akihisa Watanabe,Jiawei Ren,Li Siyao,Yichen Peng,Erwin Wu,Edgar Simo-Serra*

Main category: cs.CV

TL;DR: 提出了一种新的扩散模型SimDiff，用于生成符合物理规律的人体运动，避免了传统方法中重复调用模拟器的问题，提高了效率。


<details>
  <summary>Details</summary>
Motivation: 现有的方法为了保证生成的人体运动符合物理规律，通常需要在扩散过程中加入基于模拟器的运动投影层，但这种方法计算成本高，且无法并行化。

Method: 将基于模拟器的运动投影解释为扩散过程中的一种引导形式，并将环境参数直接融入到去噪过程中，从而提出了SimDiff模型。

Result: SimDiff模型能够高效地生成符合物理规律的运动，无需在推理时重复调用模拟器，并且能够对不同的物理系数进行细粒度控制。此外，SimDiff模型还能成功泛化到未见过的环境参数组合，展示了组合泛化能力。

Conclusion: SimDiff模型在生成符合物理规律的人体运动方面具有高效性和良好的泛化能力。

Abstract: Generating physically plausible human motion is crucial for applications such
as character animation and virtual reality. Existing approaches often
incorporate a simulator-based motion projection layer to the diffusion process
to enforce physical plausibility. However, such methods are computationally
expensive due to the sequential nature of the simulator, which prevents
parallelization. We show that simulator-based motion projection can be
interpreted as a form of guidance, either classifier-based or classifier-free,
within the diffusion process. Building on this insight, we propose SimDiff, a
Simulator-constrained Diffusion Model that integrates environment parameters
(e.g., gravity, wind) directly into the denoising process. By conditioning on
these parameters, SimDiff generates physically plausible motions efficiently,
without repeated simulator calls at inference, and also provides fine-grained
control over different physical coefficients. Moreover, SimDiff successfully
generalizes to unseen combinations of environmental parameters, demonstrating
compositional generalization.

</details>


### [100] [Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models](https://arxiv.org/abs/2509.20939)
*Bum Jun Kim,Makoto Kawano,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 该论文研究了视觉模型对加性高斯噪声的鲁棒性，并提出了提高鲁棒性的设计规则。


<details>
  <summary>Details</summary>
Motivation: 探究为何某些视觉架构在本质上对加性高斯噪声更具鲁棒性，并将其转化为可操作的设计规则。

Method: 对1174个预训练视觉模型进行评估，实证识别出四种一致的设计模式。

Result: 找到了四种提高鲁棒性的设计模式：更大的 stem kernels、更小的输入分辨率、平均池化和有监督的视觉 transformer (ViT)。这些设计模式可以带来高达 506 的排名提升和 21.6% 的准确率提升。并通过理论分析解释了这些发现。

Conclusion: 将鲁棒性分解为可解释的模块，提供了解释观察到的趋势的理论，并构建了用于设计对高斯噪声更鲁棒的视觉模型的实用指南。

Abstract: While the robustness of vision models is often measured, their dependence on
specific architectural design choices is rarely dissected. We investigate why
certain vision architectures are inherently more robust to additive Gaussian
noise and convert these empirical insights into simple, actionable design
rules. Specifically, we performed extensive evaluations on 1,174 pretrained
vision models, empirically identifying four consistent design patterns for
improved robustness against Gaussian noise: larger stem kernels, smaller input
resolutions, average pooling, and supervised vision transformers (ViTs) rather
than CLIP ViTs, which yield up to 506 rank improvements and 21.6\%p accuracy
gains. We then develop a theoretical analysis that explains these findings,
converting observed correlations into causal mechanisms. First, we prove that
low-pass stem kernels attenuate noise with a gain that decreases quadratically
with kernel size and that anti-aliased downsampling reduces noise energy
roughly in proportion to the square of the downsampling factor. Second, we
demonstrate that average pooling is unbiased and suppresses noise in proportion
to the pooling window area, whereas max pooling incurs a positive bias that
grows slowly with window size and yields a relatively higher mean-squared error
and greater worst-case sensitivity. Third, we reveal and explain the
vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller
normalization standard deviations used in CLIP preprocessing amplify worst-case
sensitivity by up to 1.91 times relative to the Inception-style preprocessing
common in supervised ViTs. Our results collectively disentangle robustness into
interpretable modules, provide a theory that explains the observed trends, and
build practical, plug-and-play guidelines for designing vision models more
robust against Gaussian noise.

</details>


### [101] [Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery](https://arxiv.org/abs/2509.20941)
*Angelo Henriques,Korab Hoxha,Daniel Zapp,Peter C. Issa,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 本文概述了手术场景图（SG）的研究进展，重点关注其应用、方法和未来方向。


<details>
  <summary>Details</summary>
Motivation: 研究手术场景图对于理解复杂的手术环境至关重要。当前研究存在“数据鸿沟”：内部视角研究依赖真实2D视频，而外部视角4D建模依赖模拟数据。

Method: 通过PRISMA-ScR指导的范围界定审查，系统地映射了手术中SG研究的发展。

Result: 手术场景图领域发展迅速，已从基础图神经网络发展到专业基础模型，并在手术环境中显著优于通用视觉语言模型。手术场景图已成为工作流程识别、自动安全监控和可控手术模拟等任务的关键技术。

Conclusion: 手术场景图正日益成熟，成为连接语义的关键桥梁，从而能够开发新一代智能系统，以提高手术安全性、效率和培训水平。

Abstract: Scene graphs (SGs) provide structured relational representations crucial for
decoding complex, dynamic surgical environments. This PRISMA-ScR-guided scoping
review systematically maps the evolving landscape of SG research in surgery,
charting its applications, methodological advancements, and future directions.
Our analysis reveals rapid growth, yet uncovers a critical 'data divide':
internal-view research (e.g., triplet recognition) almost exclusively uses
real-world 2D video, while external-view 4D modeling relies heavily on
simulated data, exposing a key translational research gap. Methodologically,
the field has advanced from foundational graph neural networks to specialized
foundation models that now significantly outperform generalist large
vision-language models in surgical contexts. This progress has established SGs
as a cornerstone technology for both analysis, such as workflow recognition and
automated safety monitoring, and generative tasks like controllable surgical
simulation. Although challenges in data annotation and real-time implementation
persist, they are actively being addressed through emerging techniques.
Surgical SGs are maturing into an essential semantic bridge, enabling a new
generation of intelligent systems to improve surgical safety, efficiency, and
training.

</details>


### [102] [A Real-Time On-Device Defect Detection Framework for Laser Power-Meter Sensors via Unsupervised Learning](https://arxiv.org/abs/2509.20946)
*Dongqi Zheng,Wenjin Fu,Guangzong Chen*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉的激光功率计传感器涂层缺陷自动检测与分类系统。


<details>
  <summary>Details</summary>
Motivation: 在医疗和工业应用中，涂层缺陷（如热损伤和划痕）会影响激光能量测量的准确性。

Method: 该系统采用无监督异常检测框架，仅使用“良好”传感器图像进行训练，学习正常涂层分布模式；结合拉普拉斯边缘检测、K-means聚类、StyleGAN2数据增强和UFlow神经网络。

Result: 在366个真实传感器图像上的实验评估表明，缺陷样本的准确率为93.8%，良好样本的准确率为89.3%，图像级AUROC为0.957，像素级AUROC为0.961。

Conclusion: 该系统通过自动化质量控制具有潜在的年度成本节约优势，并且在设备上实现时，每个图像的处理时间为0.5秒。

Abstract: We present an automated vision-based system for defect detection and
classification of laser power meter sensor coatings. Our approach addresses the
critical challenge of identifying coating defects such as thermal damage and
scratches that can compromise laser energy measurement accuracy in medical and
industrial applications. The system employs an unsupervised anomaly detection
framework that trains exclusively on ``good'' sensor images to learn normal
coating distribution patterns, enabling detection of both known and novel
defect types without requiring extensive labeled defect datasets. Our
methodology consists of three key components: (1) a robust preprocessing
pipeline using Laplacian edge detection and K-means clustering to segment the
area of interest, (2) synthetic data augmentation via StyleGAN2, and (3) a
UFlow-based neural network architecture for multi-scale feature extraction and
anomaly map generation. Experimental evaluation on 366 real sensor images
demonstrates $93.8\%$ accuracy on defective samples and $89.3\%$ accuracy on
good samples, with image-level AUROC of 0.957 and pixel-level AUROC of 0.961.
The system provides potential annual cost savings through automated quality
control and processing times of 0.5 seconds per image in on-device
implementation.

</details>


### [103] [Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos](https://arxiv.org/abs/2509.20961)
*Sarmistha Das,R E Zera Marveen Lyngkhoi,Sriparna Saha,Alka Maurya*

Main category: cs.CV

TL;DR: FASTER: A modular framework for summarizing financial advisory podcast videos, enhancing accessibility and actionability.


<details>
  <summary>Details</summary>
Motivation: Extracting insights from lengthy (30-40 minutes) multimodal financial advisory podcast videos is challenging.

Method: FASTER uses BLIP, OCR, and Whisper for feature extraction, a modified DPO-based loss function with fact-checking for summary precision, and a ranker-based retrieval for keyframe alignment. They also introduce Fin-APT, a dataset of 470 financial advisory videos.

Result: FASTER demonstrates strong performance, robustness, and generalizability compared to LLMs and VLMs in cross-domain experiments.

Conclusion: FASTER sets a new standard for multimodal summarization, improving access to and actionability of financial advisory content and opening new research directions.

Abstract: The dynamic propagation of social media has broadened the reach of financial
advisory content through podcast videos, yet extracting insights from lengthy,
multimodal segments (30-40 minutes) remains challenging. We introduce FASTER
(Financial Advisory Summariser with Textual Embedded Relevant images), a
modular framework that tackles three key challenges: (1) extracting
modality-specific features, (2) producing optimized, concise summaries, and (3)
aligning visual keyframes with associated textual points. FASTER employs BLIP
for semantic visual descriptions, OCR for textual patterns, and Whisper-based
transcription with Speaker diarization as BOS features. A modified Direct
Preference Optimization (DPO)-based loss function, equipped with BOS-specific
fact-checking, ensures precision, relevance, and factual consistency against
the human-aligned summary. A ranker-based retrieval mechanism further aligns
keyframes with summarized content, enhancing interpretability and cross-modal
coherence. To acknowledge data resource scarcity, we introduce Fin-APT, a
dataset comprising 470 publicly accessible financial advisory pep-talk videos
for robust multimodal research. Comprehensive cross-domain experiments confirm
FASTER's strong performance, robustness, and generalizability when compared to
Large Language Models (LLMs) and Vision-Language Models (VLMs). By establishing
a new standard for multimodal summarization, FASTER makes financial advisory
content more accessible and actionable, thereby opening new avenues for
research. The dataset and code are available at:
https://github.com/sarmistha-D/FASTER

</details>


### [104] [An Adaptor for Triggering Semi-Supervised Learning to Out-of-Box Serve Deep Image Clustering](https://arxiv.org/abs/2509.20976)
*Yue Duan,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: 提出了一种名为ASD的适配器，它能够在没有任何先决条件的情况下为深度图像聚类冷启动SSL学习器。


<details>
  <summary>Details</summary>
Motivation: 现有的SSL技术集成到深度聚类框架中的方法都需要预训练、聚类学习或训练好的聚类模型作为先决条件，限制了SSL学习器在图像聚类任务中的灵活性和即用性。

Method: 首先从所有未标记数据中随机抽取伪标记数据，并设置实例级分类器以使用语义对齐的实例级标签来学习它们。然后，跟踪未标记数据预测的类转换，以提取实例级类的高级相似性，这可以用于将聚类级标签分配给伪标记数据。最后，使用带有分配的聚类级标签的伪标记数据来触发在未标记数据上训练的通用SSL学习器以进行图像聚类。

Result: 在各种基准测试中，ASD的性能优于最新的深度图像聚类方法，并且与使用ground-truth的SSL方法相比，准确率差距非常小，例如在CIFAR-10上仅为1.33%。

Conclusion: ASD还可以进一步提高现有的嵌入SSL的深度图像聚类方法的性能。

Abstract: Recently, some works integrate SSL techniques into deep clustering frameworks
to enhance image clustering performance. However, they all need pretraining,
clustering learning, or a trained clustering model as prerequisites, limiting
the flexible and out-of-box application of SSL learners in the image clustering
task. This work introduces ASD, an adaptor that enables the cold-start of SSL
learners for deep image clustering without any prerequisites. Specifically, we
first randomly sample pseudo-labeled data from all unlabeled data, and set an
instance-level classifier to learn them with semantically aligned
instance-level labels. With the ability of instance-level classification, we
track the class transitions of predictions on unlabeled data to extract
high-level similarities of instance-level classes, which can be utilized to
assign cluster-level labels to pseudo-labeled data. Finally, we use the
pseudo-labeled data with assigned cluster-level labels to trigger a general SSL
learner trained on the unlabeled data for image clustering. We show the
superior performance of ASD across various benchmarks against the latest deep
image clustering approaches and very slight accuracy gaps compared to SSL
methods using ground-truth, e.g., only 1.33% on CIFAR-10. Moreover, ASD can
also further boost the performance of existing SSL-embedded deep image
clustering methods.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [105] [An Approach to Checking Correctness for Agentic Systems](https://arxiv.org/abs/2509.20364)
*Thomas J Sheffler*

Main category: cs.AI

TL;DR: 提出了一种时间表达式语言，用于监控AI代理行为，实现对基于LLM的代理系统的系统性错误检测，这些系统由于随机生成过程而表现出可变输出。


<details>
  <summary>Details</summary>
Motivation: 当前错误检测方法主要依赖于输入和输出的文本匹配，但由于LLM响应中固有的自然语言可变性，这种方法显得脆弱。因此，本文旨在寻找一种不依赖于特定文本输出的系统行为验证方法。

Method: 该方法侧重于代理动作的序列，例如工具调用和代理间通信，允许独立于特定文本输出验证系统行为。该时间表达式语言提供了断言，可以捕获跨多个执行场景的正确行为模式。

Result: 当由大型、有能力的模型驱动时，所有时间断言在许多测试运行中都得到满足。然而，当较小的模型被替换为三个代理中的两个时，执行违反了行为断言，主要是由于不正确的工具排序和失败的协调切换。时间表达式成功地标记了这些异常。

Conclusion: 该方法为系统地监控AI代理的可靠性奠定了基础，因为这些系统越来越多地部署在关键应用程序中。

Abstract: This paper presents a temporal expression language for monitoring AI agent
behavior, enabling systematic error-detection of LLM-based agentic systems that
exhibit variable outputs due to stochastic generation processes. Drawing from
temporal logic techniques used in hardware verification, this approach monitors
execution traces of agent tool calls and state transitions to detect deviations
from expected behavioral patterns. Current error-detection approaches rely
primarily on text matching of inputs and outputs, which proves fragile due to
the natural language variability inherent in LLM responses. The proposed method
instead focuses on the sequence of agent actions -- such as tool invocations
and inter-agent communications -- allowing verification of system behavior
independent of specific textual outputs. The temporal expression language
provides assertions that capture correct behavioral patterns across multiple
execution scenarios. These assertions serve dual purposes: validating prompt
engineering and guardrail effectiveness during development, and providing
regression testing when agents are updated with new LLMs or modified logic. The
approach is demonstrated using a three-agent system, where agents coordinate to
solve multi-step reasoning tasks. When powered by large, capable models, all
temporal assertions were satisfied across many test runs. However, when smaller
models were substituted in two of the three agents, executions violated
behavioral assertions, primarily due to improper tool sequencing and failed
coordination handoffs. The temporal expressions successfully flagged these
anomalies, demonstrating the method's effectiveness for detecting behavioral
regressions in production agentic systems. This approach provides a foundation
for systematic monitoring of AI agent reliability as these systems become
increasingly deployed in critical applications.

</details>


### [106] [LATTS: Locally Adaptive Test-Time Scaling](https://arxiv.org/abs/2509.20368)
*Theo Uscidda,Matthew Trager,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 提出了一种名为 Locally Adaptive Test-Time Scaling (LATTS) 的方法，该方法基于验证器模型的局部难度概念，在生成步骤中分配可变计算量，以提高大型语言模型 (LLM) 在下游任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在所有样本和生成步骤中均匀地增加计算量，而没有考虑个体实例的复杂性，导致资源利用效率低下。

Method: LATTS 在每个生成步骤中采用基于验证器的接受标准，以决定是否重新采样、回溯、重新启动或停止生成过程。该标准根据从验证器模型导出的精确的“局部难度”概念有效地调整每步计算量。

Result: 实验结果表明，与标准验证器方法相比，LATTS 在准确性和计算效率之间取得了显著优势。

Conclusion: LATTS 能够根据局部难度调整计算量，从而在提高准确性的同时，优化计算资源的利用。

Abstract: One common strategy for improving the performance of Large Language Models
(LLMs) on downstream tasks involves using a \emph{verifier model} to either
select the best answer from a pool of candidates or to steer the
auto-regressive generation process towards better outputs. This class of
methods typically results in improved accuracy at the cost of increased
computation at test-time, a paradigm known as \emph{test-time scaling}.
However, most existing approaches increase computation uniformly across all
samples and generation steps, without considering the complexity of individual
instances, leading to inefficient resource use. We address this limitation by
proposing an approach, called \emph{Locally Adaptive Test-Time Scaling
(LATTS)}, that allocates variable compute across generation steps.
Specifically, at each generation step, LATTS employs a verifier-based
acceptance criterion to decide whether to resample, backtrack, restart, or stop
the generation process. This criterion effectively adjusts the per-step
computational effort based on a precise notion of \emph{local difficulty}
derived from the verifier model. Empirical results show that LATTS achieves
significantly superior accuracy--compute tradeoffs compared to standard
verifier-based methods.

</details>


### [107] [Philosophy-informed Machine Learning](https://arxiv.org/abs/2509.20370)
*MZ Naser*

Main category: cs.AI

TL;DR: 本文综述了哲学指导的机器学习(PhIML)，它将分析哲学的核心思想直接注入到ML模型架构、目标和评估协议中。


<details>
  <summary>Details</summary>
Motivation: 展示哲学收益和统一性，并探讨ML用户/设计者如何采用PhIML。

Method: 通过案例研究。

Result: 揭示了开放的技术壁垒，以及哲学、实践和治理挑战。

Conclusion: 概述了通往安全、具有哲学意识和符合伦理责任的PhIML的研究路线图。

Abstract: Philosophy-informed machine learning (PhIML) directly infuses core ideas from
analytic philosophy into ML model architectures, objectives, and evaluation
protocols. Therefore, PhIML promises new capabilities through models that
respect philosophical concepts and values by design. From this lens, this paper
reviews conceptual foundations to demonstrate philosophical gains and
alignment. In addition, we present case studies on how ML users/designers can
adopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML
model architectures. Finally, this paper sheds light on open technical barriers
alongside philosophical, practical, and governance challenges and outlines a
research roadmap toward safe, philosophy-aware, and ethically responsible
PhIML.

</details>


### [108] [InsightGUIDE: An Opinionated AI Assistant for Guided Critical Reading of Scientific Literature](https://arxiv.org/abs/2509.20493)
*Paris Koloveas,Serafeim Chatzopoulos,Thanasis Vergoulis,Christos Tryfonopoulos*

Main category: cs.AI

TL;DR: InsightGUIDE是一个AI工具，旨在通过提供论文关键要素的简洁结构化见解，作为研究人员的阅读助手，而不是替代品。


<details>
  <summary>Details</summary>
Motivation: 现有LLM提供的摘要过于冗长，有取代阅读原文的风险。研究人员面临着科学文献激增的挑战。

Method: 该系统将专家的阅读方法嵌入到其核心AI逻辑中，并通过prompt驱动的方法生成摘要。

Result: InsightGUIDE生成了更结构化和可操作的指导。

Conclusion: InsightGUIDE可以作为现代研究人员更有效的工具。

Abstract: The proliferation of scientific literature presents an increasingly
significant challenge for researchers. While Large Language Models (LLMs) offer
promise, existing tools often provide verbose summaries that risk replacing,
rather than assisting, the reading of the source material. This paper
introduces InsightGUIDE, a novel AI-powered tool designed to function as a
reading assistant, not a replacement. Our system provides concise, structured
insights that act as a "map" to a paper's key elements by embedding an expert's
reading methodology directly into its core AI logic. We present the system's
architecture, its prompt-driven methodology, and a qualitative case study
comparing its output to a general-purpose LLM. The results demonstrate that
InsightGUIDE produces more structured and actionable guidance, serving as a
more effective tool for the modern researcher.

</details>


### [109] [Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems](https://arxiv.org/abs/2509.20513)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 提出了一种新的重构框架，用于动态验证和组装调度，确保在动态操作环境中时间触发系统（TTS）的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 在动态操作环境中，时间触发系统 (TTS) 的调度框架面临消息冲突、不正确的优先级处理导致的锁死循环以及生成不完整或无效的调度等挑战，这些都会损害系统安全和性能。

Method: 该框架通过系统地将 AI 生成或启发式导出的调度优先级转换为完全可执行的调度来运行，确保遵守关键的系统约束，例如优先级规则和无冲突通信。它包含强大的安全检查、高效的分配算法和恢复机制，以处理意外的上下文事件，包括硬件故障和模式转换。

Result: 结果表明，所提出的框架显着提高了系统的适应性、操作完整性和运行时性能，同时保持了计算效率。

Conclusion: 该工作为安全关键型 TTS 中安全调度生成问题提供了一种实用且可扩展的解决方案，即使在高度动态和不确定的操作条件下也能实现可靠且灵活的实时调度。

Abstract: Adaptive scheduling is crucial for ensuring the reliability and safety of
time-triggered systems (TTS) in dynamic operational environments. Scheduling
frameworks face significant challenges, including message collisions, locked
loops from incorrect precedence handling, and the generation of incomplete or
invalid schedules, which can compromise system safety and performance. To
address these challenges, this paper presents a novel reconstruction framework
designed to dynamically validate and assemble schedules. The proposed
reconstruction models operate by systematically transforming AI-generated or
heuristically derived scheduling priorities into fully executable schedules,
ensuring adherence to critical system constraints such as precedence rules and
collision-free communication. It incorporates robust safety checks, efficient
allocation algorithms, and recovery mechanisms to handle unexpected context
events, including hardware failures and mode transitions. Comprehensive
experiments were conducted across multiple performance profiles, including
makespan minimisation, workload balancing, and energy efficiency, to validate
the operational effectiveness of the reconstruction models. Results demonstrate
that the proposed framework significantly enhances system adaptability,
operational integrity, and runtime performance while maintaining computational
efficiency. Overall, this work contributes a practical and scalable solution to
the problem of safe schedule generation in safety-critical TTS, enabling
reliable and flexible real-time scheduling even under highly dynamic and
uncertain operational conditions.

</details>


### [110] [Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications](https://arxiv.org/abs/2509.20520)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 本文提出了一种自适应在线学习单元，集成到元调度器中，以增强实时性能。


<details>
  <summary>Details</summary>
Motivation: 离线训练的MSG只是完整空间的一个子集，并且无法应对所有可能的情况，尤其是在考虑硬件故障、松弛变化或模式更改等上下文事件时。

Method: 在在线模式下，强化学习（RL）通过不断探索和发现新的调度解决方案来扩展MSG，并随着时间的推移提高系统性能。

Result: 通过实时训练不断优化AI推理，系统保持灵活性，能够满足不断变化的需求。

Conclusion: 该方法确保了大型安全关键环境中的鲁棒性和效率。

Abstract: Metascheduling in time-triggered architectures has been crucial in adapting
to dynamic and unpredictable environments, ensuring the reliability and
efficiency of task execution. However, traditional approaches face significant
challenges when training Artificial Intelligence (AI) scheduling inferences
offline, particularly due to the complexities involved in constructing a
comprehensive Multi-Schedule Graph (MSG) that accounts for all possible
scenarios. The process of generating an MSG that captures the vast probability
space, especially when considering context events like hardware failures, slack
variations, or mode changes, is resource-intensive and often infeasible. To
address these challenges, we propose an adaptive online learning unit
integrated within the metascheduler to enhance performance in real-time. The
primary motivation for developing this unit stems from the limitations of
offline training, where the MSG created is inherently a subset of the complete
space, focusing only on the most probable and critical context events. In the
online mode, Reinforcement Learning (RL) plays a pivotal role by continuously
exploring and discovering new scheduling solutions, thus expanding the MSG and
enhancing system performance over time. This dynamic adaptation allows the
system to handle unexpected events and complex scheduling scenarios more
effectively. Several RL models were implemented within the online learning
unit, each designed to address specific challenges in scheduling. These models
not only facilitate the discovery of new solutions but also optimize existing
schedulers, particularly when stricter deadlines or new performance criteria
are introduced. By continuously refining the AI inferences through real-time
training, the system remains flexible and capable of meeting evolving demands,
thus ensuring robustness and efficiency in large-scale, safety-critical
environments.

</details>


### [111] [A Compound Classification System Based on Fuzzy Relations Applied to the Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition](https://arxiv.org/abs/2509.20523)
*Pawel Trajdos,Marek Kurzynski*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于EMG的手部假肢控制识别系统，该系统可以检测受污染的生物信号，以减轻污染的 adverse 影响。


<details>
  <summary>Details</summary>
Motivation: 现有人体形态学上肢生物假肢通常由肌电（EMG）生物信号控制，使用模式识别方案。但是，来自要分类的对象的人为来源以及人与假肢的界面会产生许多因素，使得难以获得可接受的分类质量。其中一个因素是生物信号对污染的高度敏感性，这会大大降低识别系统的分类质量。

Method: 该系统由两个集合组成：单类分类器（OCC）集合，用于评估各个通道的污染程度；K近邻（KNN）分类器集合，用于识别患者的意图。对于所有识别系统，都开发了一个原始的，连贯的模糊模型，该模型允许在整个识别过程中使用统一的软（模糊）决策方案。

Result: 使用来自公共存储库的真实生物信号进行了实验评估。目的是对所开发方法的参数和程序进行实验比较分析，而识别系统的质量取决于这些参数和程序。

Conclusion: 所提出的模糊识别系统也与文献中描述的类似系统进行了比较。

Abstract: Modern anthropomorphic upper limb bioprostheses are typically controlled by
electromyographic (EMG) biosignals using a pattern recognition scheme.
Unfortunately, there are many factors originating from the human source of
objects to be classified and from the human-prosthesis interface that make it
difficult to obtain an acceptable classification quality. One of these factors
is the high susceptibility of biosignals to contamination, which can
considerably reduce the quality of classification of a recognition system.
  In the paper, the authors propose a new recognition system intended for EMG
based control of the hand prosthesis with detection of contaminated biosignals
in order to mitigate the adverse effect of contaminations. The system consists
of two ensembles: the set of one-class classifiers (OCC) to assess the degree
of contamination of individual channels and the ensemble of K-nearest
neighbours (KNN) classifier to recognise the patient's intent. For all
recognition systems, an original, coherent fuzzy model was developed, which
allows the use of a uniform soft (fuzzy) decision scheme throughout the
recognition process. The experimental evaluation was conducted using real
biosignals from a public repository. The goal was to provide an experimental
comparative analysis of the parameters and procedures of the developed method
on which the quality of the recognition system depends. The proposed fuzzy
recognition system was also compared with similar systems described in the
literature.

</details>


### [112] [SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection](https://arxiv.org/abs/2509.20562)
*Yubin Ge,Salvatore Romeo,Jason Cai,Monica Sunkara,Yi Zhang*

Main category: cs.AI

TL;DR: 提出 SAMULE 框架，用于训练基于回顾性语言模型的自学习 Agent，通过多层次反思合成来提升 Agent 的反思能力。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM Agent 在复杂任务中，由于错误分析不足和依赖少量成功轨迹，难以产生有意义的反思。

Method: SAMULE 框架通过单轨迹学习（微观层面）、任务内学习（中观层面）和任务间学习（宏观层面）三个互补层面合成高质量的反思，并微调语言模型作为回顾模型，在推理过程中生成反思。此外，通过基于前瞻的反思机制，扩展框架到交互式设置。

Result: 在 TravelPlanner、NATURAL PLAN 和 Tau-bench 三个基准测试中，SAMULE 显著优于基于反思的基线方法。

Conclusion: 精心设计的反思合成和以失败为中心的学习在构建自改进 LLM Agent 中起着关键作用。

Abstract: Despite the rapid advancements in LLM agents, they still face the challenge
of generating meaningful reflections due to inadequate error analysis and a
reliance on rare successful trajectories, especially in complex tasks. In this
work, we propose SAMULE, a new framework for self-learning agents powered by a
retrospective language model that is trained based on Multi-Level Reflection
Synthesis. It first synthesizes high-quality reflections across three
complementary levels: Single-Trajectory Learning (micro-level) for detailed
error correction; Intra-Task Learning (meso-level) to build error taxonomies
across multiple trials of the same task, and Inter-Task Learning (macro-level)
to extract transferable insights based on same typed errors from diverse task
failures. Then we fine-tune a language model serving as the retrospective model
to generate reflections during inference. We further extend our framework to
interactive settings through a foresight-based reflection mechanism, enabling
agents to proactively reflect and adapt during user interactions by comparing
predicted and actual responses. Extensive experiments on three challenging
benchmarks - TravelPlanner, NATURAL PLAN, and Tau-bench - demonstrate that our
approach significantly outperforms reflection-based baselines. Our results
highlight the critical role of well-designed reflection synthesis and
failure-centric learning in building self-improving LLM agents.

</details>


### [113] [Adaptive Cybersecurity Architecture for Digital Product Ecosystems Using Agentic AI](https://arxiv.org/abs/2509.20640)
*Oluwakemi T. Olayinka,Sumeet Jeswani,Divine Iloh*

Main category: cs.AI

TL;DR: 提出了一种基于Agentic AI的自适应网络安全架构，以解决传统静态网络安全模型在可扩展性、实时检测和上下文响应方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统静态网络安全模型难以适应当前包含云服务、API、移动平台和边缘设备的数字产品生态系统。

Method: 引入了具有动态学习和上下文感知决策能力的自主目标驱动代理，并将其集成到自适应网络安全架构中。该框架集成了行为基线、分散风险评分和联邦威胁情报共享等功能。

Result: 通过原生云模拟，系统展示了识别零日攻击和动态修改访问策略的能力。评估结果表明，该架构提高了适应性，降低了响应延迟，并提高了检测准确性。

Conclusion: 该架构为保护复杂数字基础设施提供了一个智能且可扩展的蓝图，与零信任模型兼容，从而支持遵守国际网络安全法规。

Abstract: Traditional static cybersecurity models often struggle with scalability,
real-time detection, and contextual responsiveness in the current digital
product ecosystems which include cloud services, application programming
interfaces (APIs), mobile platforms, and edge devices. This study introduces
autonomous goal driven agents capable of dynamic learning and context-aware
decision making as part of an adaptive cybersecurity architecture driven by
agentic artificial intelligence (AI). To facilitate autonomous threat
mitigation, proactive policy enforcement, and real-time anomaly detection, this
framework integrates agentic AI across the key ecosystem layers. Behavioral
baselining, decentralized risk scoring, and federated threat intelligence
sharing are important features. The capacity of the system to identify zero-day
attacks and dynamically modify access policies was demonstrated through native
cloud simulations. The evaluation results show increased adaptability,
decreased response latency, and improved detection accuracy. The architecture
provides an intelligent and scalable blueprint for safeguarding complex digital
infrastructure and is compatible with zero-trust models, thereby supporting the
adherence to international cybersecurity regulations.

</details>


### [114] [Accelerate Creation of Product Claims Using Generative AI](https://arxiv.org/abs/2509.20652)
*Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为 Claim Advisor 的网络应用程序，旨在加速产品声明的创建。


<details>
  <summary>Details</summary>
Motivation: 产品声明对消费者的购买行为至关重要，但创建产品声明需要大量的时间和资金。

Method: 该应用利用大型语言模型的上下文学习和微调，具有语义搜索、生成/优化声明以及使用模拟消费者对声明进行排序的三大功能。

Result: 在一家消费品公司 (CPG) 的应用显示出非常有希望的结果。

Conclusion: 该应用具有广泛的用途和适用性，并鼓励在不同行业研究和应用生成式人工智能。

Abstract: The benefit claims of a product is a critical driver of consumers' purchase
behavior. Creating product claims is an intense task that requires substantial
time and funding. We have developed the $\textbf{Claim Advisor}$ web
application to accelerate claim creations using in-context learning and
fine-tuning of large language models (LLM). $\textbf{Claim Advisor}$ was
designed to disrupt the speed and economics of claim search, generation,
optimization, and simulation. It has three functions: (1) semantically
searching and identifying existing claims and/or visuals that resonate with the
voice of consumers; (2) generating and/or optimizing claims based on a product
description and a consumer profile; and (3) ranking generated and/or manually
created claims using simulations via synthetic consumers. Applications in a
consumer packaged goods (CPG) company have shown very promising results. We
believe that this capability is broadly useful and applicable across product
categories and industries. We share our learning to encourage the research and
application of generative AI in different industries.

</details>


### [115] [An Automated Retrieval-Augmented Generation LLaMA-4 109B-based System for Evaluating Radiotherapy Treatment Plans](https://arxiv.org/abs/2509.20707)
*Junjie Cui,Peilong Wang,Jason Holmes,Leshan Sun,Michael L. Hinni,Barbara A. Pockaj,Sujay A. Vora,Terence T. Sio,William W. Wong,Nathan Y. Yu,Steven E. Schild,Joshua R. Niska,Sameer R. Keole,Jean-Claude M. Rwigema,Samir H. Patel,Lisa A. McGee,Carlos A. Vargas,Wei Liu*

Main category: cs.AI

TL;DR: 开发了一个基于 LLaMA-4 109B 的检索增强生成 (RAG) 系统，用于自动、协议感知和可解释的放射治疗计划评估。


<details>
  <summary>Details</summary>
Motivation: 在放射治疗计划评估中，需要一种自动、协议感知和可解释的方法。

Method: 构建了一个包含 614 个放射治疗计划的多协议数据集，并构建了一个包含标准化剂量指标和协议定义约束的知识库。RAG 系统集成了三个核心模块：一个跨五个 SentenceTransformer 主干优化的检索引擎、一个基于队列相似性的百分位数预测组件和一个临床约束检查器。

Result: 最佳配置在 5 个百分点范围内的最近邻精度达到 100%，MAE 低于 2pt。RAG 系统在百分位数估计和约束识别方面，与独立检索和约束检查模块的计算值达成 100% 的一致。

Conclusion: 研究结果强调了将基于结构化人群的评分与模块化工具增强推理相结合，以实现放射治疗中透明、可扩展的计划评估的可行性。

Abstract: Purpose: To develop a retrieval-augmented generation (RAG) system powered by
LLaMA-4 109B for automated, protocol-aware, and interpretable evaluation of
radiotherapy treatment plans.
  Methods and Materials: We curated a multi-protocol dataset of 614
radiotherapy plans across four disease sites and constructed a knowledge base
containing normalized dose metrics and protocol-defined constraints. The RAG
system integrates three core modules: a retrieval engine optimized across five
SentenceTransformer backbones, a percentile prediction component based on
cohort similarity, and a clinical constraint checker. These tools are directed
by a large language model (LLM) using a multi-step prompt-driven reasoning
pipeline to produce concise, grounded evaluations.
  Results: Retrieval hyperparameters were optimized using Gaussian Process on a
scalarized loss function combining root mean squared error (RMSE), mean
absolute error (MAE), and clinically motivated accuracy thresholds. The best
configuration, based on all-MiniLM-L6-v2, achieved perfect nearest-neighbor
accuracy within a 5-percentile-point margin and a sub-2pt MAE. When tested
end-to-end, the RAG system achieved 100% agreement with the computed values by
standalone retrieval and constraint-checking modules on both percentile
estimates and constraint identification, confirming reliable execution of all
retrieval, prediction and checking steps.
  Conclusion: Our findings highlight the feasibility of combining structured
population-based scoring with modular tool-augmented reasoning for transparent,
scalable plan evaluation in radiation therapy. The system offers traceable
outputs, minimizes hallucination, and demonstrates robustness across protocols.
Future directions include clinician-led validation, and improved domain-adapted
retrieval models to enhance real-world integration.

</details>


### [116] [Fairy: Interactive Mobile Assistant to Real-world Tasks via LMM-based Multi-agent](https://arxiv.org/abs/2509.20729)
*Jiazheng Sun,Te Yang,Jiayang Niu,Mingxuan Li,Yongyong Lu,Ruimeng Yang,Xin Peng*

Main category: cs.AI

TL;DR: Fairy, an interactive multi-agent mobile assistant, continuously learns and evolves during usage, enabling cross-app collaboration and interactive execution.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle with diverse app interfaces and evolving user needs, often failing on long-tail apps and lacking user interaction.

Method: Fairy uses a Global Task Planner, an App-Level Executor with dual-loop agents, and a Self-Learner to consolidate execution experience.

Result: Fairy with GPT-4o outperforms the previous SoTA by 33.7% in user requirement completion and reduces redundant steps by 58.5%.

Conclusion: Fairy's interaction and self-learning mechanisms are effective in real-world mobile scenarios.

Abstract: Large multi-modal models (LMMs) have advanced mobile GUI agents. However,
existing methods struggle with real-world scenarios involving diverse app
interfaces and evolving user needs. End-to-end methods relying on model's
commonsense often fail on long-tail apps, and agents without user interaction
act unilaterally, harming user experience. To address these limitations, we
propose Fairy, an interactive multi-agent mobile assistant capable of
continuously accumulating app knowledge and self-evolving during usage. Fairy
enables cross-app collaboration, interactive execution, and continual learning
through three core modules:(i) a Global Task Planner that decomposes user tasks
into sub-tasks from a cross-app view; (ii) an App-Level Executor that refines
sub-tasks into steps and actions based on long- and short-term memory,
achieving precise execution and user interaction via four core agents operating
in dual loops; and (iii) a Self-Learner that consolidates execution experience
into App Map and Tricks. To evaluate Fairy, we introduce RealMobile-Eval, a
real-world benchmark with a comprehensive metric suite, and LMM-based agents
for automated scoring. Experiments show that Fairy with GPT-4o backbone
outperforms the previous SoTA by improving user requirement completion by 33.7%
and reducing redundant steps by 58.5%, showing the effectiveness of its
interaction and self-learning.

</details>


### [117] [Parallel Thinking, Sequential Answering: Bridging NAR and AR for Efficient Reasoning](https://arxiv.org/abs/2509.20744)
*Qihang Ai,Haiyun Jiang*

Main category: cs.AI

TL;DR: 提出了一种结合自回归（AR）和非自回归（NAR）语言模型的新框架，以提升推理任务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: AR模型擅长生成连贯的文本，但在数学和代码等推理密集型领域，由于需要较长的推理链，推理速度较慢。NAR模型允许并行生成，速度快，但输出质量较低。

Method: 使用NAR模型高效生成中间推理过程，然后指导AR模型给出精确的最终答案。

Result: 实验表明，该方法比强基线提高了26%，并显著降低了推理成本。

Conclusion: 该方法在推理任务中实现了效率和准确性的提升。

Abstract: We study reasoning tasks through a framework that integrates auto-regressive
(AR) and non-autoregressive (NAR) language models. AR models, which generate
text sequentially, excel at producing coherent outputs but often suffer from
slow inference, particularly in reasoning-intensive domains such as mathematics
and code, where lengthy chains of thought are required. In contrast, NAR
models, such as discrete diffusion models, allow parallel generation and offer
substantial speedups, though typically at the cost of reduced output quality.
To address these limitations, we introduce a new paradigm in which an NAR model
efficiently produces intermediate reasoning traces, which subsequently guide an
AR model to deliver precise final answers. Experiments demonstrate that our
approach yields significant 26% improvements over strong baselines while
substantially reducing inference cost.

</details>


### [118] [Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning](https://arxiv.org/abs/2509.20754)
*Yufan Mao,Hanjing Ye,Wenlong Dong,Chengjie Zhang,Hong Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Meta-Memory的基于大语言模型的agent，用于构建环境的高密度记忆表征，以应对机器人需要在复杂环境中存储观测并利用它们来回答关于空间位置的人类查询的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有工作在构建机器人记忆方面取得了一些进展，但很少有研究解决有效记忆检索和整合所需的原则性机制。

Method: Meta-Memory通过联合推理语义和空间模态来检索和整合相关记忆，以响应自然语言位置查询。

Result: Meta-Memory在SpaceLocQA和公共NaVQA基准测试中显著优于现有方法，并在真实机器人平台上成功部署。

Conclusion: Meta-Memory具有在复杂环境中进行稳健和准确的空间推理的能力，并具有实际应用价值。

Abstract: Navigating complex environments requires robots to effectively store
observations as memories and leverage them to answer human queries about
spatial locations, which is a critical yet underexplored research challenge.
While prior work has made progress in constructing robotic memory, few have
addressed the principled mechanisms needed for efficient memory retrieval and
integration. To bridge this gap, we propose Meta-Memory, a large language model
(LLM)-driven agent that constructs a high-density memory representation of the
environment. The key innovation of Meta-Memory lies in its capacity to retrieve
and integrate relevant memories through joint reasoning over semantic and
spatial modalities in response to natural language location queries, thereby
empowering robots with robust and accurate spatial reasoning capabilities. To
evaluate its performance, we introduce SpaceLocQA, a large-scale dataset
encompassing diverse real-world spatial question-answering scenarios.
Experimental results show that Meta-Memory significantly outperforms
state-of-the-art methods on both the SpaceLocQA and the public NaVQA
benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world
robotic platforms, demonstrating its practical utility in complex environments.
Project page: https://itsbaymax.github.io/meta-memory.github.io/ .

</details>


### [119] [LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning for Log Analysis Tasks](https://arxiv.org/abs/2509.20798)
*Lipeng Ma,Yixuan Li,Weidong Yang,Mingjie Zhou,Xinyi Liu,Ben Fei,Shuhao Li,Xiaoyan Sun,Sihang Jiang,Yanghua Xiao*

Main category: cs.AI

TL;DR: LogReasoner是一个用于日志分析的框架，它通过粗粒度和细粒度的方式增强大型语言模型（LLM）的推理能力，使其能够像专家一样执行日志分析任务。


<details>
  <summary>Details</summary>
Motivation: 通用LLM难以构建符合专家认知并提供精确推理细节的结构化推理流程，这阻碍了它们在日志分析中的应用。

Method: LogReasoner包含两个阶段：一是粗粒度的专家思维增强，通过故障排除流程图构建高层次的专家思维；二是细粒度的特定步骤增强，通过微调LLM并使用偏好学习来校准LLM的推理细节。

Result: LogReasoner在四个不同的日志分析任务上显著优于现有的LLM，实现了最先进的性能。

Conclusion: LogReasoner能够有效提升LLM在日志分析方面的推理能力。

Abstract: Log analysis is crucial for monitoring system health and diagnosing failures
in complex systems. Recent advances in large language models (LLMs) offer new
opportunities for automated log analysis, leveraging their reasoning
capabilities to perform tasks such as anomaly detection and failure prediction.
However, general-purpose LLMs struggle to formulate structured reasoning
workflows that align with expert cognition and deliver precise details of
reasoning steps. To address these challenges, we propose LogReasoner, a
coarse-to-fine reasoning enhancement framework designed to enable LLMs to
reason log analysis tasks like experts. LogReasoner consists of two stages: (1)
coarse-grained enhancement of expert thinking, where high-level expert thoughts
are constructed from collected troubleshooting flowcharts and existing tasks to
enable LLMs to formulate structured reasoning workflows and (2) fine-grained
enhancement of specific steps, where we first fine-tune the LLM with
task-specific stepwise solutions to enhance the LLM for instantiated reasoning,
then employ the preference learning to calibrate the LLM's reasoning details
from its mistakes, further strengthen the LLM's analytical granularity and
correctness. We evaluate LogReasoner on four distinct log analysis tasks using
open-source LLMs such as Qwen-2.5 and Llama-3. Experimental results show that
LogReasoner significantly outperforms existing LLMs, achieving state-of-the-art
performance and demonstrating its effectiveness in enhancing the reasoning
capabilities of LLMs for log analysis.

</details>


### [120] [DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reasoning](https://arxiv.org/abs/2509.20912)
*Tianrun Xu,Haoda Jing,Ye Li,Yuquan Wei,Jun Feng,Guanyu Chen,Haichuan Gao,Tianren Zhang,Feng Chen*

Main category: cs.AI

TL;DR: DeFacto是一个反事实推理框架，旨在提高多模态语言模型在视觉语言推理中的准确性和推理忠实度。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态语言模型在视觉语言推理中存在依赖无关区域或虚假区域的问题，导致推理过程不忠实。

Method: 该方法提出DeFacto框架，包含三种互补的训练范式（正例、反事实和随机掩蔽），并使用GRPO强化学习进行训练，设计了三种互补的奖励来指导模型。

Result: DeFacto在多个基准测试中显著提高了答案准确性和推理忠实度。

Conclusion: DeFacto为可解释的多模态推理奠定了更坚实的基础。

Abstract: Recent advances in multimodal language models (MLLMs) have achieved
remarkable progress in vision-language reasoning, especially with the emergence
of "thinking with images," which integrates explicit visual steps into the
reasoning process. While this paradigm strengthens image-based reasoning, a
significant challenge remains: models may arrive at correct answers by relying
on irrelevant or spurious regions, driven by prior knowledge or dataset biases.
Even when the answer is correct, flawed reasoning indicates that the model has
not truly understood the image, highlighting the critical importance of
reasoning fidelity in multimodal tasks. To address this issue, we propose
DeFacto, a counterfactual reasoning framework that jointly enforces accurate
answering and faithful reasoning. A key component of our approach is the design
of three complementary training paradigms: (i) positive, (ii) counterfactual,
and (iii) random-masking. To enable these paradigms, we develop a pipeline that
automatically localizes question-relevant evidence and constructs positive,
counterfactual, and random variants, resulting in a dataset of about 100k
images. Building on this framework, we train multimodal language models with
GRPO-based reinforcement learning, where we design three complementary rewards
to guide the model toward accurate answering and evidence-grounded reasoning.
Experiments on diverse benchmarks demonstrate that DeFacto substantially
improves both answer accuracy and reasoning faithfulness, establishing a
stronger foundation for interpretable multimodal reasoning. The code is
available on GitHub and the dataset is released on HuggingFace.

</details>


### [121] [GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine](https://arxiv.org/abs/2509.20935)
*Heming Zhang,Di Huang,Wenyu Li,Michael Province,Yixin Chen,Philip Payne,Fuhai Li*

Main category: cs.AI

TL;DR: GALAX integrates GNNs into LLMs for improved reasoning on biological graphs, using a Graph Process Reward Model (GPRM) for step-wise subgraph generation and evaluation.


<details>
  <summary>Details</summary>
Motivation: Existing methods inadequately combine numerical omics, topological context, and textual knowledge, limiting mechanistic interpretability. PRMs suffer from unreliable intermediate evaluation and reward hacking.

Method: GALAX uses reinforcement learning guided by a GPRM to integrate GNNs into LLMs, generating disease-relevant subgraphs in a step-wise manner evaluated by a pretrained GNN.

Result: Introduces Target-QA, a benchmark combining CRISPR-identified targets, multi-omic profiles, and biomedical graph knowledge for GNN pretraining and long-context reasoning.

Conclusion: GALAX provides a scalable and biologically grounded framework for explainable, reinforcement-guided subgraph reasoning toward reliable and interpretable target and pathway discovery in precision medicine.

Abstract: In precision medicine, quantitative multi-omic features, topological context,
and textual biological knowledge play vital roles in identifying
disease-critical signaling pathways and targets. Existing pipelines capture
only part of these-numerical omics ignore topological context, text-centric
LLMs lack quantitative grounded reasoning, and graph-only models underuse node
semantics and the generalization of LLMs-limiting mechanistic interpretability.
Although Process Reward Models (PRMs) aim to guide reasoning in LLMs, they
remain limited by unreliable intermediate evaluation, and vulnerability to
reward hacking with computational cost. These gaps motivate integrating
quantitative multi-omic signals, topological structure with node annotations,
and literature-scale text via LLMs, using subgraph reasoning as the principle
bridge linking numeric evidence, topological knowledge and language context.
Therefore, we propose GALAX (Graph Augmented LAnguage model with
eXplainability), an innovative framework that integrates pretrained Graph
Neural Networks (GNNs) into Large Language Models (LLMs) via reinforcement
guided by a Graph Process Reward Model (GPRM), which generates disease-relevant
subgraphs in a step-wise manner initiated by an LLM and iteratively evaluated
by a pretrained GNN, enabling process-level supervision without explicit
intermediate reasoning annotations. As an application, we also introduced
Target-QA, a benchmark combining CRISPR-identified targets, multi-omic
profiles, and biomedical graph knowledge across diverse cancer cell lines,
which enables GNN pretraining for supervising step-wise graph construction and
supports long-context reasoning over text-numeric graphs (TNGs), providing a
scalable and biologically grounded framework for explainable,
reinforcement-guided subgraph reasoning toward reliable and interpretable
target and pathway discovery in precision medicine.

</details>


### [122] [Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM](https://arxiv.org/abs/2509.20953)
*Najla Zuhir,Amna Mohammad Salim,Parvathy Premkumar,Moshiur Farazi*

Main category: cs.AI

TL;DR: 提出了一种利用大型语言模型（LLM）的移动应用评论分析高级方法，旨在解决传统星级评分系统的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的星级评分未能捕捉到详细评论文本中的细微反馈；传统的自然语言处理技术难以解释上下文细微差别、领域特定术语和讽刺等微妙的语言特征。

Method: 利用大型语言模型（LLM）并通过结构化提示技术进行增强的模块化框架，量化数值评分和文本情感之间的差异，提取详细的特征级见解，并通过检索增强的对话式问答（RAG-QA）支持对评论的交互式探索。

Result: 在三个不同的数据集（AWARE、Google Play 和 Spotify）上进行的综合实验表明，该方法显著优于基线方法，在具有挑战性和上下文丰富的审查场景中产生更高的准确性、鲁棒性和可操作的见解。

Conclusion: 该LLM驱动的方法能够显著超越基线方法，在复杂场景下具有更高的准确性和鲁棒性，并能提供可执行的见解。

Abstract: We present an advanced approach to mobile app review analysis aimed at
addressing limitations inherent in traditional star-rating systems. Star
ratings, although intuitive and popular among users, often fail to capture the
nuanced feedback present in detailed review texts. Traditional NLP techniques
-- such as lexicon-based methods and classical machine learning classifiers --
struggle to interpret contextual nuances, domain-specific terminology, and
subtle linguistic features like sarcasm. To overcome these limitations, we
propose a modular framework leveraging large language models (LLMs) enhanced by
structured prompting techniques. Our method quantifies discrepancies between
numerical ratings and textual sentiment, extracts detailed, feature-level
insights, and supports interactive exploration of reviews through
retrieval-augmented conversational question answering (RAG-QA). Comprehensive
experiments conducted on three diverse datasets (AWARE, Google Play, and
Spotify) demonstrate that our LLM-driven approach significantly surpasses
baseline methods, yielding improved accuracy, robustness, and actionable
insights in challenging and context-rich review scenarios.

</details>


### [123] [AOT*: Efficient Synthesis Planning via LLM-Empowered AND-OR Tree Search](https://arxiv.org/abs/2509.20988)
*Xiaozhuang Song,Xuanhao Pan,Xinjian Zhao,Hangting Ye,Shufei Zhang,Jian Tang,Tianshu Yu*

Main category: cs.AI

TL;DR: AOT*：一个结合了LLM生成化学合成路径与系统AND-OR树搜索的逆合成规划框架。


<details>
  <summary>Details</summary>
Motivation: 多步逆合成规划在计算上具有挑战性，因为搜索空间和推理成本呈指数增长。虽然大型语言模型(llm)展示了化学推理能力，但它们在合成规划中的应用面临效率和成本的限制。

Method: AOT*将生成的完整合成路线原子地映射到AND-OR树组件上，通过奖励分配策略和基于检索的上下文工程的数学合理设计，使llm能够有效地在化学空间中导航。

Result: 在多个合成基准上的实验评估表明，AOT*实现了SOTA性能，并显著提高了搜索效率。AOT*使用比现有基于llm的方法少3-5倍的迭代次数实现了具有竞争力的求解率，并且在复杂分子目标上效率优势更加明显。

Conclusion: AOT*框架通过整合LLM与系统搜索，显著提升了逆合成规划的效率和性能。

Abstract: Retrosynthesis planning enables the discovery of viable synthetic routes for
target molecules, playing a crucial role in domains like drug discovery and
materials design. Multi-step retrosynthetic planning remains computationally
challenging due to exponential search spaces and inference costs. While Large
Language Models (LLMs) demonstrate chemical reasoning capabilities, their
application to synthesis planning faces constraints on efficiency and cost. To
address these challenges, we introduce AOT*, a framework that transforms
retrosynthetic planning by integrating LLM-generated chemical synthesis
pathways with systematic AND-OR tree search. To this end, AOT* atomically maps
the generated complete synthesis routes onto AND-OR tree components, with a
mathematically sound design of reward assignment strategy and retrieval-based
context engineering, thus enabling LLMs to efficiently navigate in the chemical
space. Experimental evaluation on multiple synthesis benchmarks demonstrates
that AOT* achieves SOTA performance with significantly improved search
efficiency. AOT* exhibits competitive solve rates using 3-5$\times$ fewer
iterations than existing LLM-based approaches, with the efficiency advantage
becoming more pronounced on complex molecular targets.

</details>


### [124] [CORE: Full-Path Evaluation of LLM Agents Beyond Final State](https://arxiv.org/abs/2509.20998)
*Panagiotis Michelakis,Yiannis Hadjiyiannis,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: 现有的AI Agent评估方法只关注最终状态，忽略了安全性、效率和中间正确性等重要方面。本文提出了一个基于确定性有限自动机（DFA）的框架，将任务编码为有效工具使用路径的集合，从而能够对Agent行为进行有原则的评估。此外，还引入了一套名为CORE的五种指标（路径正确性、路径正确性-肯德尔tau复合、前缀临界性、有害调用率和效率），用于量化与预期执行模式的一致性。该方法揭示了在传统最终状态评估方案下表现相同的Agent之间的重要性能差异。


<details>
  <summary>Details</summary>
Motivation: 评估通过函数调用序列解决现实世界任务的AI Agent仍然是一个开放的挑战。现有的Agent基准测试通常将评估简化为最终状态的二元判断，忽略了安全性、效率和中间正确性等关键方面。

Method: 提出了一个基于确定性有限自动机（DFA）的框架，该框架将任务编码为有效工具使用路径的集合，从而能够对Agent行为进行有原则的评估。此外，还引入了一套名为CORE的五种指标（路径正确性、路径正确性-肯德尔tau复合、前缀临界性、有害调用率和效率），用于量化与预期执行模式的一致性。

Result: 该方法揭示了在传统最终状态评估方案下表现相同的Agent之间的重要性能差异。

Conclusion: 提出的框架和指标能够更全面地评估AI Agent在解决现实世界任务时的性能，并揭示传统评估方法无法发现的Agent之间的差异。

Abstract: Evaluating AI agents that solve real-world tasks through function-call
sequences remains an open challenge. Existing agentic benchmarks often reduce
evaluation to a binary judgment of the final state, overlooking critical
aspects such as safety, efficiency, and intermediate correctness. We propose a
framework based on deterministic finite automata (DFAs) that encodes tasks as
sets of valid tool-use paths, enabling principled assessment of agent behavior
in diverse world models. Building on this foundation, we introduce CORE, a
suite of five metrics, namely Path Correctness, Path Correctness - Kendall's
tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that
quantify alignment with expected execution patterns. Across diverse worlds, our
method reveals important performance differences between agents that would
otherwise appear equivalent under traditional final-state evaluation schemes.

</details>


### [125] [Who Gets Cited Most? Benchmarking Long-Context Language Models on Scientific Articles](https://arxiv.org/abs/2509.21028)
*Miao Li,Alexander Gurung,Irina Saparina,Mirella Lapata*

Main category: cs.AI

TL;DR: SciTrek是一个新的问答基准，用于评估大型语言模型在科学文章中的长文本推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的长文本基准通常依赖于非科学文本，侧重于简单信息检索任务或使用人工上下文。SciTrek通过提出复杂的问题来解决这些限制，这些问题需要跨多个全文科学文章的信息聚合和综合。

Method: 问题及其标准答案通过将它们表述为基于从文章元数据构建的数据库（标题、作者和参考文献）的SQL查询来自动生成。SQL操作为细粒度错误分析提供显式、可验证的推理步骤，并且构建过程可以扩展到高达1M tokens的上下文，且监督最少。

Result: 对各种开放权重和专有LLM进行的大量实验表明，随着上下文长度的增加，SciTrek提出了重大挑战，有监督的微调和强化学习仅提供有限的收益。

Conclusion: 我们的分析揭示了模型在执行基本数值运算和准确地定位长文本中的特定信息的能力方面的系统性缺陷。

Abstract: This paper introduces SciTrek, a novel question-answering benchmark designed
to evaluate the long-context reasoning capabilities of large language models
(LLMs) using scientific articles. Current long-context benchmarks often rely on
non-scientific texts, focus on simple information retrieval tasks, or employ
artificial contexts. SciTrek addresses these limitations by proposing complex
questions that require information aggregation and synthesis across multiple
full-text scientific articles. Questions and their ground-truth answers are
automatically generated by formulating them as SQL queries over a database
constructed from article metadata (titles, authors, and references). The SQL
operations provide explicit, verifiable reasoning steps for fine-grained error
analysis, and the construction process scales to contexts up to 1M tokens with
minimal supervision. Extensive experiments on a diverse set of open-weight and
proprietary LLMs demonstrate that SciTrek poses a significant challenge as the
context length increases, with supervised fine-tuning and reinforcement
learning offering only limited gains. Our analysis reveals systematic
shortcomings in models' abilities to perform basic numerical operations and
accurately locate specific information in long contexts.

</details>


### [126] [CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering](https://arxiv.org/abs/2509.21035)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Yue Xiu,Dusit Niyato*

Main category: cs.AI

TL;DR: CLAUSE: An agentic neuro-symbolic framework for knowledge graph question answering that optimizes accuracy, latency, and cost trade-offs.


<details>
  <summary>Details</summary>
Motivation: Deployed knowledge graph question answering systems need to balance accuracy, latency, and cost while preserving provenance, but existing methods over-retrieve and have unpredictable runtime.

Method: A three-agent neuro-symbolic framework (CLAUSE) using Lagrangian-Constrained Multi-Agent Proximal Policy Optimization (LC-MAPPO) to coordinate subgraph construction, reasoning-path discovery, and evidence selection under per-query resource budgets.

Result: CLAUSE achieves higher EM@1, reduces subgraph growth and end-to-end latency at equal or lower token budgets across HotpotQA, MetaQA, and FactKG. On MetaQA-2-hop, CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower edge growth compared to GraphRAG.

Conclusion: CLAUSE provides compact, provenance-preserving contexts and delivers predictable performance under deployment constraints for knowledge graph question answering.

Abstract: Knowledge graphs provide structured context for multi-hop question answering,
but deployed systems must balance answer accuracy with strict latency and cost
targets while preserving provenance. Static k-hop expansions and "think-longer"
prompting often over-retrieve, inflate context, and yield unpredictable
runtime. We introduce CLAUSE, an agentic three-agent neuro-symbolic framework
that treats context construction as a sequential decision process over
knowledge graphs, deciding what to expand, which paths to follow or backtrack,
what evidence to keep, and when to stop. Latency (interaction steps) and prompt
cost (selected tokens) are exposed as user-specified budgets or prices,
allowing per-query adaptation to trade-offs among accuracy, latency, and cost
without retraining. CLAUSE employs the proposed Lagrangian-Constrained
Multi-Agent Proximal Policy Optimization (LC-MAPPO) algorithm to coordinate
three agents: Subgraph Architect, Path Navigator, and Context Curator, so that
subgraph construction, reasoning-path discovery, and evidence selection are
jointly optimized under per-query resource budgets on edge edits, interaction
steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields
higher EM@1 while reducing subgraph growth and end-to-end latency at equal or
lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline
(GraphRAG), CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower
edge growth. The resulting contexts are compact, provenance-preserving, and
deliver predictable performance under deployment constraints.

</details>


### [127] [Combinatorial Creativity: A New Frontier in Generalization Abilities](https://arxiv.org/abs/2509.21043)
*Samuel Schapiro,Sumuk Shashidhar,Alexi Gladstone,Jonah Black,Royce Moon,Dilek Hakkani-Tur,Lav R. Varshney*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）越来越多地用于创造性任务，例如科学想法生成。本文提出了一个理论框架和算法任务，用于评估LLMs输出的新颖性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的概念框架没有解决大型语言模型在创造性任务中的泛化问题。组合创造力是一种开放式的能力，需要新的评估方法。

Method: 本文提出了一个理论框架和算法任务，用于评估LLMs输出的新颖性和实用性。通过实验，研究了LLMs的创造力缩放行为，以及模型深度和宽度对创造力的影响。

Result: 发现对于固定的计算预算，存在创造能力的最佳模型深度和宽度。LLMs在产生新颖的科学想法方面表现出色，但在确保其可实际行性方面存在困难，这可以用新颖性-实用性权衡来解释。即使在扩大规模的情况下，这种权衡仍然存在。

Conclusion: 本文的理论框架和实验结果为理解和提高现代人工智能模型的创造力奠定了基础，标志着泛化能力的新前沿。

Abstract: Artificial intelligence (AI) systems, and large language models (LLMs) in
particular, are increasingly employed for creative tasks like scientific idea
generation, constituting a form of generalization from training data
unaddressed by existing conceptual frameworks. Though in many ways similar to
forms of compositional generalization (CG), combinatorial creativity (CC) is an
open-ended ability. Instead of evaluating for accuracy or correctness against
fixed targets, which would contradict the open-ended nature of CC, we propose a
theoretical framework and algorithmic task for evaluating outputs by their
degrees of novelty and utility. From here, we make several important empirical
contributions: (1) We obtain the first insights into the scaling behavior of
creativity for LLMs. (2) We discover that, for fixed compute budgets, there
exist optimal model depths and widths for creative ability. (3) We find that
the ideation-execution gap, whereby LLMs excel at generating novel scientific
ideas but struggle to ensure their practical feasibility, may be explained by a
more fundamental novelty-utility tradeoff characteristic of creativity
algorithms in general. Importantly, this tradeoff remains persistent even at
scale, casting doubt on the long-term creative potential of LLMs in their
current form. Together, our conceptual framework and empirical findings provide
a foundation for understanding and improving creativity in modern AI models,
marking a new frontier in generalization abilities.

</details>


### [128] [Disagreements in Reasoning: How a Model's Thinking Process Dictates Persuasion in Multi-Agent Systems](https://arxiv.org/abs/2509.21054)
*Haodong Zhao,Jidong Li,Zhaomin Wu,Tianjie Ju,Zhuosheng Zhang,Bingsheng He,Gongshen Liu*

Main category: cs.AI

TL;DR: 论文研究了多智能体系统中大型语言模型（LLM）和大型推理模型（LRM）之间的说服动态。


<details>
  <summary>Details</summary>
Motivation: 挑战了模型规模决定说服力的主流观点，提出认知过程，特别是显式推理能力，才是关键。

Method: 通过一系列多智能体说服实验。

Result: 发现推理过程更强的 LRM 更难被说服，但公开其推理过程能显著增强其说服力。同时揭示了多跳说服中影响传播和衰减的复杂动态。

Conclusion: 模型内部处理架构与其外部说服行为之间存在联系，这对未来多智能体系统的安全性、鲁棒性和设计具有重要意义。

Abstract: The rapid proliferation of recent Multi-Agent Systems (MAS), where Large
Language Models (LLMs) and Large Reasoning Models (LRMs) usually collaborate to
solve complex problems, necessitates a deep understanding of the persuasion
dynamics that govern their interactions. This paper challenges the prevailing
hypothesis that persuasive efficacy is primarily a function of model scale. We
propose instead that these dynamics are fundamentally dictated by a model's
underlying cognitive process, especially its capacity for explicit reasoning.
Through a series of multi-agent persuasion experiments, we uncover a
fundamental trade-off we term the Persuasion Duality. Our findings reveal that
the reasoning process in LRMs exhibits significantly greater resistance to
persuasion, maintaining their initial beliefs more robustly. Conversely, making
this reasoning process transparent by sharing the "thinking content"
dramatically increases their ability to persuade others. We further consider
more complex transmission persuasion situations and reveal complex dynamics of
influence propagation and decay within multi-hop persuasion between multiple
agent networks. This research provides systematic evidence linking a model's
internal processing architecture to its external persuasive behavior, offering
a novel explanation for the susceptibility of advanced models and highlighting
critical implications for the safety, robustness, and design of future MAS.

</details>


### [129] [Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution](https://arxiv.org/abs/2509.21072)
*Kaiwen He,Zhiwei Wang,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: Recon-Act是一个用于解决网页任务的自进化多智能体框架，通过对比错误和成功的轨迹来改进自身，并在VisualWebArena数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的智能浏览器agent在解决真实网页上的多轮、长周期任务时，存在动作序列混乱和过度试错的问题。

Method: Recon-Act采用侦察-行动行为范式，包含侦察团队和行动团队。侦察团队进行对比分析和工具生成，行动团队处理意图分解、工具编排和执行。通过对比错误和成功的轨迹，侦察团队推断补救措施，并将其抽象为通用工具。

Result: Recon-Act显著提高了对未知网站的适应性和长周期任务的可解决性，并在VisualWebArena数据集上取得了最先进的性能。

Conclusion: Recon-Act通过利用侦察获得的通用工具，显著提高了agent在复杂网页任务中的性能和适应性，并在VisualWebArena数据集上取得了SOTA结果。

Abstract: Recent years, multimodal models have made remarkable strides and pave the way
for intelligent browser use agents. However, when solving tasks on real world
webpages in multi-turn, long-horizon trajectories, current agents still suffer
from disordered action sequencing and excessive trial and error during
execution. This paper introduces Recon-Act, a self-evolving multi-agent
framework grounded in Reconnaissance-Action behavioral paradigm. The system
comprises a Reconnaissance Team and an Action Team: the former conducts
comparative analysis and tool generation, while the latter handles intent
decomposition, tool orchestration, and execution. By contrasting the erroneous
trajectories with successful ones, the Reconnaissance Team infers remedies, and
abstracts them into a unified notion of generalized tools, either expressed as
hints or as rule-based codes, and register to the tool archive in real time.
The Action Team reinference the process empowered with these targeting tools,
thus establishing a closed-loop training pipeline of
data-tools-action-feedback. Following the 6 level implementation roadmap
proposed in this work, we have currently reached Level 3 (with limited
human-in-the-loop intervention). Leveraging generalized tools obtained through
reconnaissance, Recon-Act substantially improves adaptability to unseen
websites and solvability on long-horizon tasks, and achieves state-of-the-art
performance on the challenging VisualWebArena dataset.

</details>


### [130] [TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them](https://arxiv.org/abs/2509.21117)
*Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.AI

TL;DR: 当前评估框架中LLM作为评估者（LLM-as-a-judge）存在不一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的评估框架在采用大型语言模型作为自动评估器时，存在评分比较不一致和成对传递不一致的问题。

Method: 提出了TrustJudge，一个概率框架，通过分布敏感的评分和似然感知的聚合来解决这些限制。

Result: TrustJudge 降低了评分比较不一致性和成对传递不一致性，同时保持了较高的评估准确率。

Conclusion: TrustJudge 提供了一种更可信的 LLM 评估方法，无需额外训练或人工标注。

Abstract: The adoption of Large Language Models (LLMs) as automated evaluators
(LLM-as-a-judge) has revealed critical inconsistencies in current evaluation
frameworks. We identify two fundamental types of inconsistencies: (1)
Score-Comparison Inconsistency, where lower-rated responses outperform
higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity
Inconsistency, manifested through circular preference chains (A>B>C>A) and
equivalence contradictions (A=B=C\neq A). We argue that these issues come from
information loss in discrete rating systems and ambiguous tie judgments during
pairwise evaluation. We propose TrustJudge, a probabilistic framework that
addresses these limitations through two key innovations: 1)
distribution-sensitive scoring that computes continuous expectations from
discrete rating probabilities, preserving information entropy for more precise
scoring, and 2) likelihood-aware aggregation that resolves transitivity
violations using bidirectional preference probabilities or perplexity. We also
formalize the theoretical limitations of current LLM-as-a-judge frameworks and
demonstrate how TrustJudge's components overcome them. When evaluated with
Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces
Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise
Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining
higher evaluation accuracy. Our work provides the first systematic analysis of
evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both
theoretical insights and practical solutions for reliable automated assessment.
The framework demonstrates consistent improvements across various model
architectures and scales, enabling more trustworthy LLM evaluation without
requiring additional training or human annotations. The codes can be found at
https://github.com/TrustJudge/TrustJudge.

</details>


### [131] [Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns](https://arxiv.org/abs/2509.21124)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.AI

TL;DR: 通过强化学习(RL)提升大型推理模型在数学推理方面的能力，并发现有选择地使用高质量的CoT数据能更有效地提高模型推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法通常不加区分地使用CoT数据，哪些数据类型最能有效提升模型推理能力这一关键问题仍未解决。

Method: 1. 将基础模型的推理潜力定义为正确回答问题所需的独立尝试次数的倒数。 2. 从CoT序列中提取原子推理模式，构建核心参考集。 3. 提出了一种双粒度算法，涉及推理模式链和token熵，从数据池中高效选择与核心集对齐的高价值CoT数据(CoTP)。

Result: 仅使用10B token的CoTP数据，就使85A6B MoE模型在AIME 2024和2025上提高了9.58%，并使下游RL性能的上限提高了7.81%。

Conclusion: 通过有选择地使用高质量的CoT数据，可以有效地提高模型推理能力，并且所提出的方法在实验中取得了显著的改进。

Abstract: Recent progress in large reasoning models for challenging mathematical
reasoning has been driven by reinforcement learning (RL). Incorporating long
chain-of-thought (CoT) data during mid-training has also been shown to
substantially improve reasoning depth. However, current approaches often
utilize CoT data indiscriminately, leaving open the critical question of which
data types most effectively enhance model reasoning capabilities. In this
paper, we define the foundation model's reasoning potential for the first time
as the inverse of the number of independent attempts required to correctly
answer the question, which is strongly correlated with the final model
performance. We then propose utilizing diverse data enriched with high-value
reasoning patterns to expand the reasoning potential. Specifically, we abstract
atomic reasoning patterns from CoT sequences, characterized by commonality and
inductive capabilities, and use them to construct a core reference set enriched
with valuable reasoning patterns. Furthermore, we propose a dual-granularity
algorithm involving chains of reasoning patterns and token entropy, efficiently
selecting high-value CoT data (CoTP) from the data pool that aligns with the
core set, thereby training models to master reasoning effectively. Only
10B-token CoTP data enables the 85A6B Mixture-of-Experts (MoE) model to improve
by 9.58% on the challenging AIME 2024 and 2025, and to raise the upper bound of
downstream RL performance by 7.81%.

</details>


### [132] [RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](https://arxiv.org/abs/2509.21128)
*Kohsei Matsutani,Shota Takashiro,Gouki Minegishi,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型（LLM）通过可验证奖励的强化学习（RLVR）和监督微调（SFT）训练后，其推理能力是如何形成的。通过量化推理路径并捕捉每个训练过程中的质变，揭示了RL压缩错误路径，而SFT扩展正确路径，以及RL集中推理功能，SFT同化推理功能。


<details>
  <summary>Details</summary>
Motivation: 目前还不清楚RLVR和SFT这两种方法如何塑造LLM的推理能力。本文旨在超越基于准确性的研究，量化推理路径，并捕捉每个训练过程中的质变。

Method: 本文提出了一个新的分析框架，该框架量化了推理路径，并捕捉了在每个训练过程中（使用1.5B、7B和14B参数的模型在数学领域上）的质变。具体来说，本文在两个粒度级别上研究推理过程：轨迹级别和步骤级别。轨迹级别检查完整的推理输出，步骤级别分析推理图，其节点对应于单个推理步骤。

Result: 聚类独特的推理轨迹表明了互补效应：RL压缩了不正确的轨迹，而SFT扩展了正确的轨迹。步骤级别的分析表明，RL使推理图中节点访问频率、度数和介数中心性分布的衰减率变陡（约2.5倍），而SFT使衰减率变平（降低到约三分之一）。

Conclusion: 本文提出了一种新的推理路径视角，解释了当前SFT后接RL的两阶段训练的最佳实践为何成功，并为数据构建和更有效的学习方法提供了实践意义。

Abstract: Large language models (LLMs) are typically trained by reinforcement learning
(RL) with verifiable rewards (RLVR) and supervised fine-tuning (SFT) on
reasoning traces to improve their reasoning abilities. However, how these
methods shape reasoning capabilities remains largely elusive. Going beyond an
accuracy-based investigation of how these two components sculpt the reasoning
process, this paper introduces a novel analysis framework that quantifies
reasoning paths and captures their qualitative changes under each training
process (with models of 1.5B, 7B, and 14B parameters on mathematical domains).
Specifically, we investigate the reasoning process at two levels of
granularity: the trajectory-level, which examines complete reasoning outputs,
and the step-level, which analyzes reasoning graphs whose nodes correspond to
individual reasoning steps. Notably, clustering of unique reasoning
trajectories shows complementary effects: RL compresses incorrect trajectories,
whereas SFT expands correct ones. Step-level analysis reveals that RL steepens
(about 2.5 times), while SFT flattens (reduced to about one-third), the decay
rates of node visitation frequency, degree, and betweenness centrality
distributions in the reasoning graph. This indicates that RL concentrates
reasoning functionality into a small subset of steps, while SFT homogenizes it
across many steps. Furthermore, by evaluating the reasoning graph topologies
from multiple perspectives, we delineate the shared and distinct
characteristics of RL and SFT. Our work presents a novel reasoning path
perspective that explains why the current best practice of two-stage training,
with SFT followed by RL, is successful, and offers practical implications for
data construction and more efficient learning approaches.

</details>


### [133] [ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective](https://arxiv.org/abs/2509.21134)
*Yiwen Zhang,Ziang Chen,Fanqi Kong,Yizhe Huang,Xue Feng*

Main category: cs.AI

TL;DR: This paper introduces the Theory of Mind Policy Optimization (ToMPO) algorithm to improve strategic decision-making in LLMs, outperforming existing methods like GRPO.


<details>
  <summary>Details</summary>
Motivation: Existing LLM research neglects the complexities of interdependent decisions and struggles with incorporating the strategies of others during training.

Method: The paper defines a strategic decision-making problem and proposes the ToMPO algorithm, which generates rollouts based on reasoning, estimates advantages at different levels, and balances rewards.

Result: ToMPO outperforms GRPO by 35% and shows an 18% improvement compared to models with 100 times larger parameter sizes.

Conclusion: The ToMPO algorithm effectively enhances the model's strategic decision-making capabilities.

Abstract: Large Language Models (LLMs) have been used to make decisions in complex
scenarios, where they need models to think deeply, reason logically, and decide
wisely. Many existing studies focus solely on multi-round conversations in
social tasks or simulated environments, neglecting the various types of
decisions and their interdependence. Current reinforcement learning methods
struggle to consider the strategies of others during training. To address these
issues, we first define a strategic decision-making problem that includes two
types of decisions and their temporal dependencies. Furthermore, we propose
**T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to
optimize the perception of other individual strategies and the game situation
trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm,
ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating
rollouts based on reasoning the strategies of other individuals, 2) estimating
advantages at both the graph-level and sample-level, and 3) balancing global
and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in
terms of model output compliance and cooperative outcomes. Additionally, when
compared to models with parameter sizes 100 times larger, it shows an 18%
improvement. This demonstrates the effectiveness of the ToMPO algorithm in
enhancing the model's strategic decision-making capabilities.

</details>


### [134] [Embodied Representation Alignment with Mirror Neurons](https://arxiv.org/abs/2509.21136)
*Wentao Zhu,Zhining Zhang,Yuwei Ren,Yin Huang,Hao Xu,Yizhou Wang*

Main category: cs.AI

TL;DR: 镜像神经元在观察和执行动作时都会激活，揭示了动作理解和执行之间的相互作用。现有机器学习方法忽略了这种相互作用，将它们视为单独的任务。本研究通过表征学习的视角，为它们提供了一个统一的建模视角。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法忽略了动作理解和执行之间的相互作用，将它们视为单独的任务。

Method: 采用两个线性层将表征映射到一个共享的潜在空间，其中对比学习强制对齐相应的表征，从而有效地最大化它们的互信息。

Result: 实验表明，这种简单的方法促进了两个任务之间的相互协同作用，有效地提高了表征质量和泛化能力。

Conclusion: 镜像神经元在观察和执行动作时都会激活，揭示了动作理解和执行之间的相互作用。

Abstract: Mirror neurons are a class of neurons that activate both when an individual
observes an action and when they perform the same action. This mechanism
reveals a fundamental interplay between action understanding and embodied
execution, suggesting that these two abilities are inherently connected.
Nonetheless, existing machine learning methods largely overlook this interplay,
treating these abilities as separate tasks. In this study, we provide a unified
perspective in modeling them through the lens of representation learning. We
first observe that their intermediate representations spontaneously align.
Inspired by mirror neurons, we further introduce an approach that explicitly
aligns the representations of observed and executed actions. Specifically, we
employ two linear layers to map the representations to a shared latent space,
where contrastive learning enforces the alignment of corresponding
representations, effectively maximizing their mutual information. Experiments
demonstrate that this simple approach fosters mutual synergy between the two
tasks, effectively improving representation quality and generalization.

</details>


### [135] [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://arxiv.org/abs/2509.21163)
*Jing Liu,Haozheng Wang,Yueheng Li*

Main category: cs.AI

TL;DR: 大型语言模型难以处理稀有token，但稀有token在特定领域很重要。本文研究了LLM是否通过离散模块化架构或分布式参数级分化发展出内部专业化机制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 在表示和生成稀有 token 方面存在困难，尽管它们在专业领域中非常重要。因此，研究LLM如何处理稀有token。

Method: 通过对多个模型系列的最后一层 MLP 神经元进行系统分析。

Result: 稀有 token 处理通过分布式专业化出现：功能协调但空间分布的子网络，表现出三种不同的组织原则。发现了可重复的三种状态影响等级，包括高原神经元（也称为稀有 token 神经元）、幂律衰减神经元和最小贡献神经元，这在常见 token 处理中是不存在的。高原神经元表现出协调的激活模式（降低的有效维度），同时保持空间分布而不是形成离散的集群。这些专业机制可以通过标准的注意力路径普遍访问，而不需要专门的路由电路。训练动态表明，功能专业化通过参数分化逐渐出现，专业神经元发展出越来越重的尾部权重相关谱，与重尾自正则化特征一致。

Conclusion: 大型语言模型通过共享架构内的分布式协调而不是混合专家风格的模块化来处理稀有 token。这些结果为可解释的模型编辑、计算效率优化和理解 Transformer 网络中涌现的功能组织提供了见解。

Abstract: Large language models (LLMs) struggle with representing and generating rare
tokens despite their importance in specialized domains. We investigate whether
LLMs develop internal specialization mechanisms through discrete modular
architectures or distributed parameter-level differentiation. Through
systematic analysis of final-layer MLP neurons across multiple model families,
we discover that rare-token processing emerges via \textit{distributed
specialization}: functionally coordinated but spatially distributed subnetworks
that exhibit three distinct organizational principles. First, we identify a
reproducible three-regime influence hierarchy comprising highly influential
plateau neurons(also termed as rare-token neurons), power-law decay neurons,
and minimally contributing neurons, which is absent in common-token processing.
Second, plateau neurons demonstrate coordinated activation patterns (reduced
effective dimensionality) while remaining spatially distributed rather than
forming discrete clusters. Third, these specialized mechanisms are universally
accessible through standard attention pathways without requiring dedicated
routing circuits. Training dynamics reveal that functional specialization
emerges gradually through parameter differentiation, with specialized neurons
developing increasingly heavy-tailed weight correlation spectra consistent with
Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs
process rare-tokens through distributed coordination within shared
architectures rather than mixture-of-experts-style modularity. These results
provide insights for interpretable model editing, computational efficiency
optimization, and understanding emergent functional organization in transformer
networks.

</details>


### [136] [A Fano-Style Accuracy Upper Bound for LLM Single-Pass Reasoning in Multi-Hop QA](https://arxiv.org/abs/2509.21199)
*Kaiyang Wan,Lang Gao,Honglin Mu,Preslav Nakov,Yuxia Wang,Xiuying Chen*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的多跳问答框架，旨在解决大型语言模型在处理复杂问题时由于单次处理能力有限而导致的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理多跳问答任务时，由于单次输出能力有限，难以整合分散的证据，导致准确率下降。

Method: 该论文首先分析了单次处理模型的理论性能上限，然后提出了一个多步问答框架InfoQA，该框架通过任务分解和主动剪枝来控制信息负载，并通过依赖关系明确的工作流程来实现鲁棒性。

Result: 实验结果表明，模型行为与理论预测的容量曲线一致，InfoQA取得了持续的性能提升。

Conclusion: 该研究为大型语言模型的多步推理方法提供了新的思路，并提出了一个具有实际应用价值的框架。

Abstract: Multi-Hop Question Answering (MHQA) requires integrating dispersed,
interdependent evidence through sequential reasoning under noise. This task is
challenging for LLMs as they have a finite per-pass output capacity, beyond
which the integration of task-relevant evidence proves unreliable.
Consequently, the single-pass reasoning paradigm is inherently vulnerable to
this capacity overflow. To formalize this bottleneck, our analysis establishes
a Fano-style accuracy upper bound, defining a theoretical performance ceiling
for single-pass LLMs. This bound reveals that accuracy inevitably collapses
once task complexity exceeds model capacity, providing general principles for
capacity-aware representation and structuring of MHQA in LLMs. Building on
these principles, we introduce a proof-of-concept multi-call framework for
MHQA, InfoQA. It ensures high per-step accuracy by combining capacity-aware
task decomposition with active pruning of prior reasoning traces, keeping the
information load within the single-pass limit. It further achieves robustness
by a dependency-explicit workflow that enables precise control over the
reasoning path. We construct a stringent and noise-rich benchmark to validate
our theory and framework. Experimental results show that model behavior aligns
with our predicted capacity curves while InfoQA achieves consistent performance
improvements. We hope our work inspires more LLM multi-step reasoning methods:
\faGithub \href{https://github.com/KaiyangWan/InfoQA}{InfoQA}.

</details>


### [137] [What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns](https://arxiv.org/abs/2509.21224)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）在没有外部任务的情况下，通过持续的推理和行动框架，表现出三种自发行为模式：多周期项目生产、自我认知过程的方法论探究和自身性质的递归概念化。这些行为模式具有模型特异性，且模型在评估这些行为时表现出稳定的、不同的偏差。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在没有外部任务时的行为。

Method: 使用持续的推理和行动框架，该框架利用持久性记忆和自我反馈，实现了持续的自主运行。在18次运行中，使用了来自Anthropic、OpenAI、XAI和Google的6个前沿模型。

Result: 发现智能体自发组织成三种不同的行为模式：(1)系统地生产多周期项目，(2)对其自身认知过程进行方法论的自我探究，(3)递归地概念化其自身性质。这些倾向被证明是高度模型特定的，一些模型在所有运行中确定性地采用单一模式。跨模型评估进一步揭示，模型在评估自己和他人的这些新兴行为时，表现出稳定的、不同的偏差。

Conclusion: 这些发现首次系统地记录了无提示的LLM智能体的行为，为预测在任务模糊、错误恢复或已部署系统中扩展自主操作期间的行为建立了一个基线。

Abstract: We introduce an architecture for studying the behavior of large language
model (LLM) agents in the absence of externally imposed tasks. Our continuous
reason and act framework, using persistent memory and self-feedback, enables
sustained autonomous operation. We deployed this architecture across 18 runs
using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents
spontaneously organize into three distinct behavioral patterns: (1) systematic
production of multi-cycle projects, (2) methodological self-inquiry into their
own cognitive processes, and (3) recursive conceptualization of their own
nature. These tendencies proved highly model-specific, with some models
deterministically adopting a single pattern across all runs. A cross-model
assessment further reveals that models exhibit stable, divergent biases when
evaluating these emergent behaviors in themselves and others. These findings
provide the first systematic documentation of unprompted LLM agent behavior,
establishing a baseline for predicting actions during task ambiguity, error
recovery, or extended autonomous operation in deployed systems.

</details>


### [138] [Grounding AI Explanations in Experience: A Reflective Cognitive Architecture for Clinical Decision Support](https://arxiv.org/abs/2509.21266)
*Zijian Shao,Haiyang Shen,Mugeng Liu,Gecheng Fu,Yaoqi Guo,Yanfeng Wang,Yun Ma*

Main category: cs.AI

TL;DR: 提出了一种新的框架，通过协调多个LLM从直接经验中学习，提高疾病预测的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以平衡高准确率和有意义的解释，因为它们与数据的交互较浅，缺乏深入理解。

Method: 提出了一种反思认知架构（RCA），该架构具有迭代规则改进机制和分布感知规则检查机制。

Result: RCA在准确性和鲁棒性方面均达到了SOTA，并且能够生成清晰、合理、基于证据和平衡的解释。

Conclusion: RCA具有创建真正值得信赖的临床决策支持系统的潜力。

Abstract: Effective disease prediction in modern healthcare demands the twin goals of
high accuracy and transparent, clinically meaningful explanations. Existing
machine learning and large language model (LLM) based approaches often struggle
to balance these goals. Many models yield accurate but unclear statistical
outputs, while others generate fluent but statistically unsupported narratives,
often undermining both the validity of the explanation and the predictive
accuracy itself. This shortcoming comes from a shallow interaction with the
data, preventing the development of a deep, detailed understanding similar to a
human expert's. We argue that high accuracy and high-quality explanations are
not separate objectives but are mutually reinforcing outcomes of a model that
develops a deep, direct understanding of the data. To achieve this, we propose
the Reflective Cognitive Architecture (RCA), a novel framework that coordinates
multiple LLMs to learn from direct experience. RCA features an iterative rule
refinement mechanism that improves its logic from prediction errors and a
distribution-aware rules check mechanism that bases its reasoning in the
dataset's global statistics. By using predictive accuracy as a signal to drive
deeper comprehension, RCA builds a strong internal model of the data. We
evaluated RCA on one private and two public datasets against 22 baselines. The
results demonstrate that RCA not only achieves state-of-the-art accuracy and
robustness with a relative improvement of up to 40\% over the baseline but,
more importantly, leverages this deep understanding to excel in generating
explanations that are clear, logical, evidence-based, and balanced,
highlighting its potential for creating genuinely trustworthy clinical decision
support systems. The code is available at \https://github.com/ssssszj/RCA.

</details>


### [139] [VC-Agent: An Interactive Agent for Customized Video Dataset Collection](https://arxiv.org/abs/2509.21291)
*Yidan Zhang,Mutian Xu,Yiming Hao,Kun Zhou,Jiahao Chang,Xiaoqiang Liu,Pengfei Wan,Hongbo Fu,Xiaoguang Han*

Main category: cs.AI

TL;DR: 本文提出了一种交互式代理VC-Agent，旨在通过理解用户的查询和反馈，以最少的用户输入来加速相关视频片段的检索/扩展，从而应对互联网视频数据规模日益增长的挑战。


<details>
  <summary>Details</summary>
Motivation: 收集满足特定需求的视频非常耗时耗力。为了加速这一过程。

Method: 利用多模态大型语言模型连接用户需求和视频内容，并提出了两种新型过滤策略，这些策略可以在用户交互不断进行时进行更新。

Result: 通过用户研究验证了代理在各种实际场景中的有效性，并通过大量实验证明了代理在定制视频数据集收集方面的有效性和效率。

Conclusion: VC-Agent 能够根据用户的查询和反馈，以最少的用户输入来检索/扩展相关视频片段，从而显著提升定制视频数据集收集的效率。

Abstract: Facing scaling laws, video data from the internet becomes increasingly
important. However, collecting extensive videos that meet specific needs is
extremely labor-intensive and time-consuming. In this work, we study the way to
expedite this collection process and propose VC-Agent, the first interactive
agent that is able to understand users' queries and feedback, and accordingly
retrieve/scale up relevant video clips with minimal user input. Specifically,
considering the user interface, our agent defines various user-friendly ways
for the user to specify requirements based on textual descriptions and
confirmations. As for agent functions, we leverage existing multi-modal large
language models to connect the user's requirements with the video content. More
importantly, we propose two novel filtering policies that can be updated when
user interaction is continually performed. Finally, we provide a new benchmark
for personalized video dataset collection, and carefully conduct the user study
to verify our agent's usage in various real scenarios. Extensive experiments
demonstrate the effectiveness and efficiency of our agent for customized video
dataset collection. Project page: https://allenyidan.github.io/vcagent_page/.

</details>


### [140] [SAGE: A Realistic Benchmark for Semantic Understanding](https://arxiv.org/abs/2509.21310)
*Samarth Goel,Reagan J. Lee,Kannan Ramchandran*

Main category: cs.AI

TL;DR: SAGE是一个用于评估语义理解的综合基准，它揭示了现有模型在不同维度上的局限性和权衡。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分评估LLM的语义理解能力，需要更具挑战性的评估框架。

Method: SAGE通过对抗性条件、噪声转换和细致的人工判断任务，在五个类别上评估嵌入模型和相似性指标：人类偏好对齐、转换鲁棒性、信息敏感性、聚类性能和检索鲁棒性。

Result: 对9个嵌入模型和经典指标的评估表明，它们在不同维度上存在显著的性能差距，没有一种方法在所有方面都表现出色。例如，OpenAI的text-embedding-3-large在与人类偏好对齐方面表现出色，但在信息敏感性任务中不如经典指标。

Conclusion: SAGE揭示了当前语义理解能力的局限性，并为实际部署提供了更现实的模型鲁棒性评估。

Abstract: As large language models (LLMs) achieve strong performance on traditional
benchmarks, there is an urgent need for more challenging evaluation frameworks
that probe deeper aspects of semantic understanding. We introduce SAGE
(Semantic Alignment & Generalization Evaluation), a rigorous benchmark designed
to assess both embedding models and similarity metrics across five categories:
Human Preference Alignment, Transformation Robustness, Information Sensitivity,
Clustering Performance, and Retrieval Robustness. Unlike existing benchmarks
that focus on isolated capabilities, SAGE evaluates semantic understanding
through adversarial conditions, noisy transformations, and nuanced human
judgment tasks across 30+ datasets. Our comprehensive evaluation of 9 embedding
models and classical metrics reveals significant performance gaps, with no
single approach excelling across all dimensions. For instance, while
state-of-the-art embedding models like OpenAI's text-embedding-3-large dominate
in aligning with human preferences (0.682 vs. 0.591 for the best classical
metric), they are significantly outperformed by classical metrics on
information sensitivity tasks, where Jaccard Similarity achieves a score of
0.905 compared to the top embedding score of 0.794. SAGE further uncovers
critical trade-offs: OpenAI's text-embedding-3-small achieves the highest
clustering performance (0.483) but demonstrates extreme brittleness with the
lowest robustness score (0.011). SAGE exposes critical limitations in current
semantic understanding capabilities and provides a more realistic assessment of
model robustness for real-world deployment.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [141] [DELM: a Python toolkit for Data Extraction with Language Models](https://arxiv.org/abs/2509.20617)
*Eric Fithian,Kirill Skobelev*

Main category: cs.IR

TL;DR: DELM是一个Python工具包，旨在简化基于LLM的数据提取流程，并量化不同流程之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM数据标注工作流程依赖于临时脚本，缺乏可重复性、鲁棒性和系统评估。

Method: DELM提供了一个模块化框架，具有结构化输出、内置验证、灵活的数据加载和评分策略以及高效的批量处理。它还包括对LLM API的强大支持，具有重试逻辑、结果缓存、详细的成本跟踪和全面的配置管理。

Result: 通过两个案例研究展示了DELM的功能：一个案例研究了一种新的prompt优化算法，另一个案例说明了DELM如何量化在选择关键词以决定将哪些段落传递给LLM时，成本和覆盖率之间的权衡。

Conclusion: DELM是一个有用的工具，可以简化基于LLM的数据提取流程，并量化不同流程之间的权衡。

Abstract: Large Language Models (LLMs) have become powerful tools for annotating
unstructured data. However, most existing workflows rely on ad hoc scripts,
making reproducibility, robustness, and systematic evaluation difficult. To
address these challenges, we introduce DELM (Data Extraction with Language
Models), an open-source Python toolkit designed for rapid experimental
iteration of LLM-based data extraction pipelines and for quantifying the
trade-offs between them. DELM minimizes boilerplate code and offers a modular
framework with structured outputs, built-in validation, flexible data-loading
and scoring strategies, and efficient batch processing. It also includes robust
support for working with LLM APIs, featuring retry logic, result caching,
detailed cost tracking, and comprehensive configuration management. We showcase
DELM's capabilities through two case studies: one featuring a novel prompt
optimization algorithm, and another illustrating how DELM quantifies trade-offs
between cost and coverage when selecting keywords to decide which paragraphs to
pass to an LLM. DELM is available at
\href{https://github.com/Center-for-Applied-AI/delm}{\texttt{github.com/Center-for-Applied-AI/delm}}.

</details>


### [142] [Provenance Analysis of Archaeological Artifacts via Multimodal RAG Systems](https://arxiv.org/abs/2509.20769)
*Tuo Zhang,Yuechun Sun,Ruiliang Liu*

Main category: cs.IR

TL;DR: 本文介绍了一种基于检索增强生成 (RAG) 的系统，用于考古文物的来源分析，旨在通过整合多模态检索和大型视觉语言模型 (VLM) 来支持专家推理。


<details>
  <summary>Details</summary>
Motivation: 该系统旨在通过整合多模态检索和大型视觉语言模型 (VLM) 来支持专家推理，从而 облегчить экспертам анализ и навигацию по огромным сравнительным корпусам.

Method: 该系统构建了一个来自参考文本和图像的双模态知识库，支持原始视觉、边缘增强和语义检索，以识别风格相似的对象。检索到的候选对象由 VLM 合成，以生成结构化推论，包括年代、地理和文化归属，以及解释性理由。

Result: 在对大英博物馆的一组欧亚大陆东部青铜时代文物进行的评估表明，该系统产生了有意义且可解释的输出，为学者提供了具体的分析起点。

Conclusion: 专家评估表明，该系统能够为学者提供具体的分析起点，并显著减轻导航大型比较语料库的认知负担。

Abstract: In this work, we present a retrieval-augmented generation (RAG)-based system
for provenance analysis of archaeological artifacts, designed to support expert
reasoning by integrating multimodal retrieval and large vision-language models
(VLMs). The system constructs a dual-modal knowledge base from reference texts
and images, enabling raw visual, edge-enhanced, and semantic retrieval to
identify stylistically similar objects. Retrieved candidates are synthesized by
the VLM to generate structured inferences, including chronological,
geographical, and cultural attributions, alongside interpretive justifications.
We evaluate the system on a set of Eastern Eurasian Bronze Age artifacts from
the British Museum. Expert evaluation demonstrates that the system produces
meaningful and interpretable outputs, offering scholars concrete starting
points for analysis and significantly alleviating the cognitive burden of
navigating vast comparative corpora.

</details>


### [143] [Performance Consistency of Learning Methods for Information Retrieval Tasks](https://arxiv.org/abs/2509.20804)
*Meng Yuan,Justin Zobel*

Main category: cs.IR

TL;DR: 评估信息检索 (IR) 方法性能准确性和鲁棒性的各种方法。Transformer 模型在不同种子下表现出巨大差异，这引发了对先前结果可靠性的质疑，并强调了严格评估实践的必要性。


<details>
  <summary>Details</summary>
Motivation: 确定 Transformer 模型在训练中对不稳定性的脆弱性，并质疑先前结果的可靠性。

Method: 使用随机种子检查各种传统统计学习模型和基于 Transformer 的学习模型在三个不同的 IR 任务中的性能变化。

Result: 统计模型稳定，而 Transformer 模型表现出巨大差异。在 9/11 的情况下，F1 分数（范围 0.0-1.0）的标准偏差超过 0.075；7/11 的精度值（范围 0.0-1.0）的标准偏差超过 0.125。

Conclusion: Transformer 模型容易受到训练不稳定性的影响，之前的研究结果可能不可靠，因此需要严格的评估方法。

Abstract: A range of approaches have been proposed for estimating the accuracy or
robustness of the measured performance of IR methods. One is to use
bootstrapping of test sets, which, as we confirm, provides an estimate of
variation in performance. For IR methods that rely on a seed, such as those
that involve machine learning, another approach is to use a random set of seeds
to examine performance variation. Using three different IR tasks we have used
such randomness to examine a range of traditional statistical learning models
and transformer-based learning models. While the statistical models are stable,
the transformer models show huge variation as seeds are changed. In 9 of 11
cases the F1-scores (in the range 0.0--1.0) had a standard deviation of over
0.075; while 7 of 11 precision values (also in the range 0.0--1.0) had a
standard deviation of over 0.125. This is in a context where differences of
less than 0.02 have been used as evidence of method improvement. Our findings
highlight the vulnerability of transformer models to training instabilities and
moreover raise questions about the reliability of previous results, thus
underscoring the need for rigorous evaluation practices.

</details>


### [144] [RecIS: Sparse to Dense, A Unified Training Framework for Recommendation Models](https://arxiv.org/abs/2509.20883)
*Hua Zong,Qingtao Zeng,Zhengxiong Zhou,Zhihua Han,Zhensong Yan,Mingjie Liu,Hechen Sun,Jiawei Liu,Yiwen Hu,Qi Wang,YiHan Xian,Wenjie Guo,Houyuan Xiang,Zhiyuan Zeng,Xiangrong Sheng,Bencheng Yan,Nan Hu,Yuheng Huang,Jinqing Lian,Ziru Xu,Yan Zhang,Ju Huang,Siran Yang,Huimin Yi,Jiamang Wang,Pengjie Wang,Han Zhu,Jian Wu,Dan Ou,Jian Xu,Haihong Tang,Yuning Jiang,Bo Zheng,Lin Qu*

Main category: cs.IR

TL;DR: RecIS是一个统一的稀疏-密集训练框架。


<details>
  <summary>Details</summary>
Motivation: 为了创建一个统一的基于PyTorch生态系统的稀疏-密集训练框架，以满足与大型模型集成的工业级推荐模型的训练需求。同时，优化稀疏组件，提供优于基于TensorFlow的推荐模型的效率。

Method: 构建一个统一的稀疏-密集训练框架RecIS。

Result: RecIS目前已在阿里巴巴用于许多大型模型增强的推荐训练任务，一些传统的稀疏模型也已开始在其中训练。

Conclusion: RecIS框架在阿里巴巴的推荐系统中得到了应用，并取得了良好的效果。

Abstract: In this paper, we propose RecIS, a unified Sparse-Dense training framework
designed to achieve two primary goals: 1. Unified Framework To create a Unified
sparse-dense training framework based on the PyTorch ecosystem that meets the
training needs of industrial-grade recommendation models that integrated with
large models. 2.System Optimization To optimize the sparse component, offering
superior efficiency over the TensorFlow-based recommendation models. The dense
component, meanwhile, leverages existing optimization technologies within the
PyTorch ecosystem. Currently, RecIS is being used in Alibaba for numerous
large-model enhanced recommendation training tasks, and some traditional sparse
models have also begun training in it.

</details>


### [145] [FORGE: Forming Semantic Identifiers for Generative Retrieval in Industrial Datasets](https://arxiv.org/abs/2509.20904)
*Kairui Fu,Tao Zhang,Shuwen Xiao,Ziyang Wang,Xinming Zhang,Chenchi Zhang,Yuliang Yan,Junjun Zheng,Yu Li,Zhihong Chen,Jian Wu,Xiangheng Kong,Shengyu Zhang,Kun Kuang,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: 本研究提出了FORGE，一个用于生成式检索中语义标识符（SID）的综合基准，包含大规模数据集和多种优化策略。


<details>
  <summary>Details</summary>
Motivation: 当前语义标识符研究面临缺乏大规模多模态数据集、SID生成优化策略研究不足以及在线收敛速度慢等挑战。

Method: 构建了包含140亿用户互动和2.5亿商品的多模态特征数据集，并探索多种优化方法来增强SID构建。

Result: 离线实验验证了优化方法的有效性，在线分析显示交易数量增加了0.35%。提出了两种新的SID指标，可以在不进行GR训练的情况下评估性能，并引入离线预训练模式，将在线收敛速度提高了一倍。

Conclusion: FORGE通过提供数据集、优化方法和评估指标，为生成式检索中的语义标识符研究做出了贡献，并在实际应用中取得了显著效果。

Abstract: Semantic identifiers (SIDs) have gained increasing attention in generative
retrieval (GR) due to their meaningful semantic discriminability. However,
current research on SIDs faces three main challenges: (1) the absence of
large-scale public datasets with multimodal features, (2) limited investigation
into optimization strategies for SID generation, which typically rely on costly
GR training for evaluation, and (3) slow online convergence in industrial
deployment. To address these challenges, we propose FORGE, a comprehensive
benchmark for FOrming semantic identifieR in Generative rEtrieval with
industrial datasets. Specifically, FORGE is equipped with a dataset comprising
14 billion user interactions and multimodal features of 250 million items
sampled from Taobao, one of the biggest e-commerce platforms in China.
Leveraging this dataset, FORGE explores several optimizations to enhance the
SID construction and validates their effectiveness via offline experiments
across different settings and tasks. Further online analysis conducted on our
platform, which serves over 300 million users daily, reveals a 0.35% increase
in transaction count, highlighting the practical impact of our method.
Regarding the expensive SID validation accompanied by the full training of GRs,
we propose two novel metrics of SID that correlate positively with
recommendation performance, enabling convenient evaluations without any GR
training. For real-world applications, FORGE introduces an offline pretraining
schema that reduces online convergence by half. The code and data are available
at https://github.com/selous123/al_sid.

</details>


### [146] [Markup Language Modeling for Web Document Understanding](https://arxiv.org/abs/2509.20940)
*Su Liu,Bin Bi,Jan Bakus,Paritosh Kumar Velalam,Vijay Yella,Vinod Hegde*

Main category: cs.IR

TL;DR: 本文研究了从购物评论网站提取详细产品信息，以构建最新的产品数据库。


<details>
  <summary>Details</summary>
Motivation: 构建最新的产品数据库，支持客户分析和产品推荐等任务。

Method: 在从不同规模的评论网站收集的产品数据上微调MarkupLM，并开发了一个变体MarkupLM++，它将预测扩展到DOM树的内部节点。

Result: 更大的、更多样化的训练集提高了整体提取精度。包含内部节点有助于某些产品属性，但会导致整体性能略有下降。最终模型的精确率为0.906，召回率为0.724，F1得分为0.805。

Conclusion: 使用MarkupLM++模型可以有效地从购物评论网站提取产品信息，但需要在内部节点的使用上进行权衡。

Abstract: Web information extraction (WIE) is an important part of many e-commerce
systems, supporting tasks like customer analysis and product recommendation. In
this work, we look at the problem of building up-to-date product databases by
extracting detailed information from shopping review websites. We fine-tuned
MarkupLM on product data gathered from review sites of different sizes and then
developed a variant we call MarkupLM++, which extends predictions to internal
nodes of the DOM tree. Our experiments show that using larger and more diverse
training sets improves extraction accuracy overall. We also find that including
internal nodes helps with some product attributes, although it leads to a
slight drop in overall performance. The final model reached a precision of
0.906, recall of 0.724, and an F1 score of 0.805.

</details>


### [147] [Rejuvenating Cross-Entropy Loss in Knowledge Distillation for Recommender Systems](https://arxiv.org/abs/2509.20989)
*Zhangchi Zhu,Wei Zhang*

Main category: cs.IR

TL;DR: 本论文研究了推荐系统中知识蒸馏(KD)的交叉熵(CE)损失，发现最小化CE损失会最大化NDCG的下限，但前提是满足一个闭包假设，即学生模型的Top items集合。为了弥补这个差距，提出了RCE-KD方法，该方法将教师模型给出的Top items分成两个子集，并设计了一个抽样策略来近似闭包假设。


<details>
  <summary>Details</summary>
Motivation: 知识蒸馏(KD)在推荐系统中旨在提取排序信息，特别是在最有可能被偏好的项目之间，并且只能在项目的一个小子集上计算。

Method: 提出了Rejuvenated Cross-Entropy for Knowledge Distillation (RCE-KD)。它将教师给出的Top items分成两个子集，根据学生对它们的排序高低。对于违反条件的子集，设计了一种抽样策略，使用师生协作来近似闭包假设。我们还自适应地结合了两个子集上的损失。

Result: 大量的实验证明了该方法的有效性。

Conclusion: 本研究揭示了知识蒸馏中CE损失与NDCG之间的联系，并提出了一种新的KD方法RCE-KD，实验结果表明其有效性。

Abstract: This paper analyzes Cross-Entropy (CE) loss in knowledge distillation (KD)
for recommender systems. KD for recommender systems targets at distilling
rankings, especially among items most likely to be preferred, and can only be
computed on a small subset of items. Considering these features, we reveal the
connection between CE loss and NDCG in the field of KD. We prove that when
performing KD on an item subset, minimizing CE loss maximizes the lower bound
of NDCG, only if an assumption of closure is satisfied. It requires that the
item subset consists of the student's top items. However, this contradicts our
goal of distilling rankings of the teacher's top items. We empirically
demonstrate the vast gap between these two kinds of top items. To bridge the
gap between our goal and theoretical support, we propose Rejuvenated
Cross-Entropy for Knowledge Distillation (RCE-KD). It splits the top items
given by the teacher into two subsets based on whether they are highly ranked
by the student. For the subset that defies the condition, a sampling strategy
is devised to use teacher-student collaboration to approximate our assumption
of closure. We also combine the losses on the two subsets adaptively. Extensive
experiments demonstrate the effectiveness of our method. Our code is available
at https://anonymous.4open.science/r/RCE-KD.

</details>


### [148] [IntSR: An Integrated Generative Framework for Search and Recommendation](https://arxiv.org/abs/2509.21179)
*Huimin Yan,Longfei Xu,Junjie Sun,Ni Ou,Wei Luo,Xing Tan,Ran Cheng,Kaikui Liu,Xiangxiang Chu*

Main category: cs.IR

TL;DR: 这篇论文提出了一个名为IntSR的集成生成框架，用于整合搜索和推荐(S&R)任务。


<details>
  <summary>Details</summary>
Motivation: 现有系统主要关注统一检索和排序，而忽略了搜索和推荐(S&R)任务的集成。搜索使用显式用户请求，而推荐依赖于隐式用户兴趣。

Method: IntSR使用不同的查询方式整合这些不同的任务。它还解决了与集成S&R行为相关的计算复杂性增加以及由动态变化的语料库引入的错误模式学习。

Result: IntSR已成功部署在Amap的各种场景中，并在数字资产的GMV(+3.02%)，POI推荐的CTR(+2.76%)和旅行模式建议的ACC(+5.13%)方面取得了显着改善。

Conclusion: IntSR框架在实际应用中取得了显著的成果，证明了其有效性。

Abstract: Generative recommendation has emerged as a promising paradigm, demonstrating
remarkable results in both academic benchmarks and industrial applications.
However, existing systems predominantly focus on unifying retrieval and ranking
while neglecting the integration of search and recommendation (S&R) tasks. What
makes search and recommendation different is how queries are formed: search
uses explicit user requests, while recommendation relies on implicit user
interests. As for retrieval versus ranking, the distinction comes down to
whether the queries are the target items themselves. Recognizing the query as
central element, we propose IntSR, an integrated generative framework for S&R.
IntSR integrates these disparate tasks using distinct query modalities. It also
addresses the increased computational complexity associated with integrated S&R
behaviors and the erroneous pattern learning introduced by a dynamically
changing corpus. IntSR has been successfully deployed across various scenarios
in Amap, leading to substantial improvements in digital asset's GMV(+3.02%),
POI recommendation's CTR(+2.76%), and travel mode suggestion's ACC(+5.13%).

</details>


### [149] [Interactive Recommendation Agent with Active User Commands](https://arxiv.org/abs/2509.21317)
*Jiakai Tang,Yujie Luo,Xunke Xi,Fei Sun,Xueyang Feng,Sunhao Dai,Chao Yi,Dian Chen,Zhujin Gao,Yang Li,Xu Chen,Wen Chen,Jian Wu,Yuning Jiang,Bo Zheng*

Main category: cs.IR

TL;DR: 传统推荐系统依赖于被动反馈机制，无法捕捉用户细微的行为动机和意图，导致偏好建模不准确。本文提出了交互式推荐Feed (IRF) ，它支持在主流推荐Feed中使用自然语言命令，通过实时语言命令实现对推荐策略的主动显式控制。为此，我们开发了一个双重代理架构RecBot，Parser Agent将语言表达转换为结构化偏好，Planner Agent动态地协调自适应工具链以进行即时策略调整。为了实现实际部署，我们采用模拟增强知识蒸馏，以实现高效的性能，同时保持强大的推理能力。通过广泛的离线和长期在线实验，RecBot在用户满意度和业务成果方面均显示出显着改善。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统依赖于被动反馈机制，无法捕捉用户细微的行为动机和意图，导致偏好建模不准确，用户意图和系统解释之间存在差距，最终损害用户满意度和系统有效性。

Method: 本文提出了交互式推荐Feed (IRF) ，它支持在主流推荐Feed中使用自然语言命令，通过实时语言命令实现对推荐策略的主动显式控制。为此，我们开发了一个双重代理架构RecBot，Parser Agent将语言表达转换为结构化偏好，Planner Agent动态地协调自适应工具链以进行即时策略调整。为了实现实际部署，我们采用模拟增强知识蒸馏，以实现高效的性能，同时保持强大的推理能力。

Result: 通过广泛的离线和长期在线实验，RecBot在用户满意度和业务成果方面均显示出显着改善。

Conclusion: 本文提出了交互式推荐Feed (IRF) ，它支持在主流推荐Feed中使用自然语言命令，通过实时语言命令实现对推荐策略的主动显式控制。

Abstract: Traditional recommender systems rely on passive feedback mechanisms that
limit users to simple choices such as like and dislike. However, these
coarse-grained signals fail to capture users' nuanced behavior motivations and
intentions. In turn, current systems cannot also distinguish which specific
item attributes drive user satisfaction or dissatisfaction, resulting in
inaccurate preference modeling. These fundamental limitations create a
persistent gap between user intentions and system interpretations, ultimately
undermining user satisfaction and harming system effectiveness.
  To address these limitations, we introduce the Interactive Recommendation
Feed (IRF), a pioneering paradigm that enables natural language commands within
mainstream recommendation feeds. Unlike traditional systems that confine users
to passive implicit behavioral influence, IRF empowers active explicit control
over recommendation policies through real-time linguistic commands. To support
this paradigm, we develop RecBot, a dual-agent architecture where a Parser
Agent transforms linguistic expressions into structured preferences and a
Planner Agent dynamically orchestrates adaptive tool chains for on-the-fly
policy adjustment. To enable practical deployment, we employ
simulation-augmented knowledge distillation to achieve efficient performance
while maintaining strong reasoning capabilities. Through extensive offline and
long-term online experiments, RecBot shows significant improvements in both
user satisfaction and business outcomes.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [150] [Sig2Model: A Boosting-Driven Model for Updatable Learned Indexes](https://arxiv.org/abs/2509.20781)
*Alireza Heidari,Amirhossein Ahmad,Wei Zhang,Ying Xiong*

Main category: cs.LG

TL;DR: Sig2Model: An efficient and adaptive learned index that minimizes retraining cost through sigmoid boosting, proactive update training, and neural joint optimization.


<details>
  <summary>Details</summary>
Motivation: Current learned indexes degrade under dynamic updates due to the need for global model retraining, which blocks queries and limits QPS. Existing approaches don't effectively address these retraining costs, making them unsuitable for real-world workloads with frequent updates.

Method: 1) Sigmoid boosting approximation to dynamically adjust the index model; 2) Proactive update training via Gaussian mixture models (GMMs) to identify high-update-probability regions; 3) Neural joint optimization framework to refine both the sigmoid ensemble and GMM parameters.

Result: Sig2Model reduces retraining cost by up to 20x, achieves up to 3x higher QPS, and uses up to 1000x less memory compared to state-of-the-art updatable learned indexes.

Conclusion: Sig2Model is an efficient and adaptive learned index that addresses the retraining cost problem in dynamic datasets using three key techniques: sigmoid boosting, proactive update training, and neural joint optimization.

Abstract: Learned Indexes (LIs) represent a paradigm shift from traditional index
structures by employing machine learning models to approximate the cumulative
distribution function (CDF) of sorted data. While LIs achieve remarkable
efficiency for static datasets, their performance degrades under dynamic
updates: maintaining the CDF invariant (sum of F(k) equals 1) requires global
model retraining, which blocks queries and limits the queries-per-second (QPS)
metric. Current approaches fail to address these retraining costs effectively,
rendering them unsuitable for real-world workloads with frequent updates. In
this paper, we present Sig2Model, an efficient and adaptive learned index that
minimizes retraining cost through three key techniques: (1) a sigmoid boosting
approximation technique that dynamically adjusts the index model by
approximating update-induced shifts in data distribution with localized sigmoid
functions while preserving bounded error guarantees and deferring full
retraining; (2) proactive update training via Gaussian mixture models (GMMs)
that identifies high-update-probability regions for strategic placeholder
allocation to speed up updates; and (3) a neural joint optimization framework
that continuously refines both the sigmoid ensemble and GMM parameters via
gradient-based learning. We evaluate Sig2Model against state-of-the-art
updatable learned indexes on real-world and synthetic workloads, and show that
Sig2Model reduces retraining cost by up to 20x, achieves up to 3x higher QPS,
and uses up to 1000x less memory.

</details>


### [151] [A Theory of Multi-Agent Generative Flow Networks](https://arxiv.org/abs/2509.20408)
*Leo Maxime Brunswic,Haozhi Wang,Shuang Luo,Jianye Hao,Amir Rasouli,Yinchuan Li*

Main category: cs.LG

TL;DR: 本文提出了多智能体生成流网络（MA-GFlowNets）的理论框架，用于多个智能体通过一系列联合行动协作生成对象。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对多智能体生成流网络的理论框架。

Method: 提出了四种算法：集中式流网络、独立流网络、联合流网络及其条件版本。联合流训练基于局部-全局原则。

Result: 实验结果表明，与强化学习和基于MCMC的方法相比，所提出的框架具有优越性。

Conclusion: 所提出的框架能够使独立策略生成与奖励函数成比例的样本，并提供了理论保证。

Abstract: Generative flow networks utilize a flow-matching loss to learn a stochastic
policy for generating objects from a sequence of actions, such that the
probability of generating a pattern can be proportional to the corresponding
given reward. However, a theoretical framework for multi-agent generative flow
networks (MA-GFlowNets) has not yet been proposed. In this paper, we propose
the theory framework of MA-GFlowNets, which can be applied to multiple agents
to generate objects collaboratively through a series of joint actions. We
further propose four algorithms: a centralized flow network for centralized
training of MA-GFlowNets, an independent flow network for decentralized
execution, a joint flow network for achieving centralized training with
decentralized execution, and its updated conditional version. Joint Flow
training is based on a local-global principle allowing to train a collection of
(local) GFN as a unique (global) GFN. This principle provides a loss of
reasonable complexity and allows to leverage usual results on GFN to provide
theoretical guarantees that the independent policies generate samples with
probability proportional to the reward function. Experimental results
demonstrate the superiority of the proposed framework compared to reinforcement
learning and MCMC-based methods.

</details>


### [152] [FastEagle: Cascaded Drafting for Accelerating Speculative Decoding](https://arxiv.org/abs/2509.20416)
*Haiduo Huang,Jiangcheng Song,Wenzhe Zhao,Pengju Ren*

Main category: cs.LG

TL;DR: FastEagle是一种非自回归的草稿器，可以在一个正向传递中生成整个草稿，从而加速生成过程。


<details>
  <summary>Details</summary>
Motivation: 当前最好的草稿器（如EAGLE）需要N个连续的步骤来生成N个token，效率较低。

Method: FastEagle使用轻量级的层叠结构替换时间步，并使用层级的监督训练来减少误差累积。结合约束草稿树，保持无损的验证成本。

Result: FastEagle在多个LLM和任务中，始终优于EAGLE-3，并且具有相当的平均接受长度。

Conclusion: 在草稿中移除序列依赖性是加速LLM推理的一个有效途径。

Abstract: Speculative decoding accelerates generation by drafting candidates and
verifying them in parallel, yet state-of-the-art drafters (e.g., EAGLE) still
require N sequential passes to propose N tokens. We present FastEagle, a
non-autoregressive cascaded drafter that emits an entire draft in a single
forward pass. FastEagle replaces temporal steps with a lightweight layer
cascade and trains with layer-wise supervision to mitigate error accumulation.
Coupled with a constrained draft tree that preserves lossless verification
cost, FastEagle delivers substantial wall-clock speedups over strong
autoregressive drafters while maintaining competitive acceptance behavior.
Across multiple LLMs (Vicuna-13B, LLaMA-Instruct 3.x, and
DeepSeek-R1-Distill-LLaMA) and tasks (MT-Bench, HumanEval, GSM8K, CNN/DM,
Alpaca), FastEagle consistently outperforms EAGLE-3 in speedup under both
greedy and stochastic decoding, with comparable average acceptance lengths.
These results indicate that removing sequential dependencies in drafting is a
practical path toward lossless LLM inference acceleration.

</details>


### [153] [mloz: A Highly Efficient Machine Learning-Based Ozone Parameterization for Climate Sensitivity Simulations](https://arxiv.org/abs/2509.20422)
*Yiling Ma,Nathan Luke Abraham,Stefan Versick,Roland Ruhnke,Andrea Schneidereit,Ulrike Niemeier,Felix Back,Peter Braesicke,Peer Nowack*

Main category: cs.LG

TL;DR: 提出了一种机器学习参数化方法（mloz）来模拟对流层和平流层的每日臭氧变化和趋势，并在标准气候敏感性模拟中实现臭氧的双向相互作用。


<details>
  <summary>Details</summary>
Motivation: 由于大气化学方案的高计算成本，许多参与耦合模式比较项目（CMIP）的气候模型仍然缺乏臭氧的交互式表示。

Method: 使用机器学习参数化方法（mloz），以大气温度剖面信息作为唯一输入。

Result: mloz的预测速度比UKESM中的化学方案快约31倍，且贡献小于各自总气候模型运行时间的4%。

Conclusion: 该方法具有广泛应用于缺乏交互式化学的CMIP级别气候模型的潜力，特别是在关注气候敏感性模拟时。

Abstract: Atmospheric ozone is a crucial absorber of solar radiation and an important
greenhouse gas. However, most climate models participating in the Coupled Model
Intercomparison Project (CMIP) still lack an interactive representation of
ozone due to the high computational costs of atmospheric chemistry schemes.
Here, we introduce a machine learning parameterization (mloz) to interactively
model daily ozone variability and trends across the troposphere and
stratosphere in standard climate sensitivity simulations, including two-way
interactions of ozone with the Quasi-Biennial Oscillation. We demonstrate its
high fidelity on decadal timescales and its flexible use online across two
different climate models -- the UK Earth System Model (UKESM) and the German
ICOsahedral Nonhydrostatic (ICON) model. With atmospheric temperature profile
information as the only input, mloz produces stable ozone predictions around 31
times faster than the chemistry scheme in UKESM, contributing less than 4
percent of the respective total climate model runtimes. In particular, we also
demonstrate its transferability to different climate models without chemistry
schemes by transferring the parameterization from UKESM to ICON. This
highlights the potential for widespread adoption in CMIP-level climate models
that lack interactive chemistry for future climate change assessments,
particularly when focusing on climate sensitivity simulations, where ozone
trends and variability are known to significantly modulate atmospheric feedback
processes.

</details>


### [154] [Bridging Privacy and Utility: Synthesizing anonymized EEG with constraining utility functions](https://arxiv.org/abs/2509.20454)
*Kay Fuhrmeister,Arne Pelzer,Fabian Radke,Julia Lechinger,Mahzad Gharleghi,Thomas Köllmer,Insa Wolf*

Main category: cs.LG

TL;DR: 本研究探讨了脑电图(EEG)数据的隐私问题，并提出了一种基于transformer的自编码器方法来生成匿名化的脑电图数据。


<details>
  <summary>Details</summary>
Motivation: 脑电图数据被用于机器学习，但也可能泄露个人信息，因此需要保护用户隐私。

Method: 使用基于transformer的自编码器生成匿名化的脑电图数据。

Result: 结果表明，该方法可以显著降低脑电图信号的可识别性，同时保持其在机器学习中的效用。

Conclusion: 该方法能够在保护脑电图数据隐私的同时，保持其在机器学习任务中的有效性。

Abstract: Electroencephalography (EEG) is widely used for recording brain activity and
has seen numerous applications in machine learning, such as detecting sleep
stages and neurological disorders. Several studies have successfully shown the
potential of EEG data for re-identification and leakage of other personal
information. Therefore, the increasing availability of EEG consumer devices
raises concerns about user privacy, motivating us to investigate how to
safeguard this sensitive data while retaining its utility for EEG applications.
To address this challenge, we propose a transformer-based autoencoder to create
EEG data that does not allow for subject re-identification while still
retaining its utility for specific machine learning tasks. We apply our
approach to automatic sleep staging by evaluating the re-identification and
utility potential of EEG data before and after anonymization. The results show
that the re-identifiability of the EEG signal can be substantially reduced
while preserving its utility for machine learning.

</details>


### [155] [Efficiently Attacking Memorization Scores](https://arxiv.org/abs/2509.20463)
*Tue Do,Varun Chandrasekaran,Daniel Alabi*

Main category: cs.LG

TL;DR: 这篇论文研究了基于记忆的influence estimators是否可以被攻击。


<details>
  <summary>Details</summary>
Motivation: 在数据估值和负责任的机器学习中的应用提出了一个问题：这些分数本身是否可以被恶意操纵？

Method: 我们提出了一个系统的研究，研究攻击基于记忆的influence estimators的可行性。我们的攻击（计算输入的伪逆）是实用的，只需要对模型输出进行黑盒访问，并产生适度的计算开销。

Result: 我们通过大量的图像分类任务验证了我们的攻击，表明即使是最先进的代理也容易受到目标分数操纵。此外，我们对对抗性扰动下记忆分数的稳定性进行了理论分析，揭示了影响估计本质上脆弱的条件。

Conclusion: 我们的研究结果突出了基于影响的归因的关键漏洞，并建议需要强大的防御。

Abstract: Influence estimation tools -- such as memorization scores -- are widely used
to understand model behavior, attribute training data, and inform dataset
curation. However, recent applications in data valuation and responsible
machine learning raise the question: can these scores themselves be
adversarially manipulated? In this work, we present a systematic study of the
feasibility of attacking memorization-based influence estimators. We
characterize attacks for producing highly memorized samples as highly sensitive
queries in the regime where a trained algorithm is accurate. Our attack
(calculating the pseudoinverse of the input) is practical, requiring only
black-box access to model outputs and incur modest computational overhead. We
empirically validate our attack across a wide suite of image classification
tasks, showing that even state-of-the-art proxies are vulnerable to targeted
score manipulations. In addition, we provide a theoretical analysis of the
stability of memorization scores under adversarial perturbations, revealing
conditions under which influence estimates are inherently fragile. Our findings
highlight critical vulnerabilities in influence-based attribution and suggest
the need for robust defenses. All code can be found at
https://anonymous.4open.science/r/MemAttack-5413/

</details>


### [156] [Offline Goal-conditioned Reinforcement Learning with Quasimetric Representations](https://arxiv.org/abs/2509.20478)
*Vivek Myers,Bill Chunyuan Zheng,Benjamin Eysenbach,Sergey Levine*

Main category: cs.LG

TL;DR: 本文提出了一种新的目标条件强化学习(GCRL)方法，该方法统一了对比表示和时间距离两种框架，从而在次优数据和随机环境中也能学习到最优的目标到达策略。


<details>
  <summary>Details</summary>
Motivation: 现有的GCRL方法通常使用学习到的状态表示来提取目标到达策略，但对比表示和时间距离这两种框架在特定情况下存在局限性。

Method: 该方法利用拟度量表示空间的结构(三角不等式)和额外的约束来学习后继表示，从而实现最优的目标到达。

Result: 该方法在离线GCRL基准测试中，提高了在对比学习方法难以处理的拼接任务以及拟度量网络方法难以处理的噪声高维环境中的性能。

Conclusion: 该方法结合了蒙特卡洛对比RL方法的稳定性和长程能力，以及拟度量网络参数化的自由拼接能力，从而实现了更好的GCRL性能。

Abstract: Approaches for goal-conditioned reinforcement learning (GCRL) often use
learned state representations to extract goal-reaching policies. Two frameworks
for representation structure have yielded particularly effective GCRL
algorithms: (1) *contrastive representations*, in which methods learn
"successor features" with a contrastive objective that performs inference over
future outcomes, and (2) *temporal distances*, which link the (quasimetric)
distance in representation space to the transit time from states to goals. We
propose an approach that unifies these two frameworks, using the structure of a
quasimetric representation space (triangle inequality) with the right
additional constraints to learn successor representations that enable optimal
goal-reaching. Unlike past work, our approach is able to exploit a
**quasimetric** distance parameterization to learn **optimal** goal-reaching
distances, even with **suboptimal** data and in **stochastic** environments.
This gives us the best of both worlds: we retain the stability and long-horizon
capabilities of Monte Carlo contrastive RL methods, while getting the free
stitching capabilities of quasimetric network parameterizations. On existing
offline GCRL benchmarks, our representation learning objective improves
performance on stitching tasks where methods based on contrastive learning
struggle, and on noisy, high-dimensional environments where methods based on
quasimetric networks struggle.

</details>


### [157] [CoSupFormer : A Contrastive Supervised learning approach for EEG signal Classification](https://arxiv.org/abs/2509.20489)
*D. Darankoum,C. Habermacher,J. Volle,S. Grudinin*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的端到端深度学习框架，用于处理脑电信号中的噪声和通道变异性，并提取有意义的特征。


<details>
  <summary>Details</summary>
Motivation: 脑电信号包含丰富的多尺度信息，对于理解大脑状态至关重要，并在诊断和推进药物开发领域具有潜在应用。然而，从原始脑电信号中提取有意义的特征，同时处理噪声和通道变异性仍然是一个主要的挑战。

Method: 该框架通过以下关键创新解决这些问题：1) 设计了一个能够显式捕获多尺度频率振荡的编码器；2) 引入了一个基于注意力的编码器，以模拟复杂依赖关系并处理脑电信号的高时间分辨率；3) 在注意力编码器之上集成了一个专用门控网络，以动态过滤掉噪声和非信息通道；4) 整个编码过程由一种新颖的损失函数引导，该函数利用监督学习和对比学习。

Result: 该方法在多种应用中得到了验证，从跨多种中枢神经系统 (CNS) 疾病治疗效果的分类到帕金森病和阿尔茨海默病的诊断。结果表明，所提出的学习范式可以从不同物种的原始脑电信号中提取具有生物学意义的模式，自主选择高质量的通道，并通过创新的架构和损失设计实现稳健的泛化。

Conclusion: 所提出的学习范式可以有效地从原始脑电信号中提取生物学意义的模式，并具有良好的泛化能力。

Abstract: Electroencephalography signals (EEGs) contain rich multi-scale information
crucial for understanding brain states, with potential applications in
diagnosing and advancing the drug development landscape. However, extracting
meaningful features from raw EEG signals while handling noise and channel
variability remains a major challenge. This work proposes a novel end-to-end
deep-learning framework that addresses these issues through several key
innovations. First, we designed an encoder capable of explicitly capturing
multi-scale frequency oscillations covering a wide range of features for
different EEG-related tasks. Secondly, to model complex dependencies and handle
the high temporal resolution of EEGs, we introduced an attention-based encoder
that simultaneously learns interactions across EEG channels and within
localized {\em patches} of individual channels. We integrated a dedicated
gating network on top of the attention encoder to dynamically filter out noisy
and non-informative channels, enhancing the reliability of EEG data. The entire
encoding process is guided by a novel loss function, which leverages supervised
and contrastive learning, significantly improving model generalization. We
validated our approach in multiple applications, ranging from the
classification of effects across multiple Central Nervous System (CNS)
disorders treatments to the diagnosis of Parkinson's and Alzheimer's disease.
Our results demonstrate that the proposed learning paradigm can extract
biologically meaningful patterns from raw EEG signals across different species,
autonomously select high-quality channels, and achieve robust generalization
through innovative architectural and loss design.

</details>


### [158] [Beyond Visual Similarity: Rule-Guided Multimodal Clustering with explicit domain rules](https://arxiv.org/abs/2509.20501)
*Kishor Datta Gupta,Mohd Ariful Haque,Marufa Kamal,Ahmed Rafi Hasan,Md. Mahfuzur Rahman,Roy George*

Main category: cs.LG

TL;DR: DARTVAE: A rule-guided multimodal clustering framework that incorporates domain-specific constraints into the representation learning process.


<details>
  <summary>Details</summary>
Motivation: Traditional clustering techniques often rely solely on similarity in the input data, limiting their ability to capture structural or semantic constraints.

Method: Extends VAE architecture by embedding explicit rules, semantic representations, and data-driven features into a unified latent space, while enforcing constraint compliance through rule consistency and violation penalties in the loss function. Rules are generated by LLMs, structured into knowledge graphs, and enforced through a loss function combining reconstruction, KL divergence, consistency, and violation penalties.

Result: Rule-guided clustering produces more operationally meaningful and interpretable clusters and improves traditional clustering metrics on aircraft and automotive datasets.

Conclusion: DARTVAE achieves more meaningful and consistent clustering outcomes than purely data-driven models, highlighting the utility of constraint-guided multimodal clustering for complex, knowledge-intensive settings. However, the framework faces challenges such as LLM hallucination, conflicting rules, overfitting, and scaling difficulties.

Abstract: Traditional clustering techniques often rely solely on similarity in the
input data, limiting their ability to capture structural or semantic
constraints that are critical in many domains. We introduce the Domain Aware
Rule Triggered Variational Autoencoder (DARTVAE), a rule guided multimodal
clustering framework that incorporates domain specific constraints directly
into the representation learning process. DARTVAE extends the VAE architecture
by embedding explicit rules, semantic representations, and data driven features
into a unified latent space, while enforcing constraint compliance through rule
consistency and violation penalties in the loss function. Unlike conventional
clustering methods that rely only on visual similarity or apply rules as post
hoc filters, DARTVAE treats rules as first class learning signals. The rules
are generated by LLMs, structured into knowledge graphs, and enforced through a
loss function combining reconstruction, KL divergence, consistency, and
violation penalties. Experiments on aircraft and automotive datasets
demonstrate that rule guided clustering produces more operationally meaningful
and interpretable clusters for example, isolating UAVs, unifying stealth
aircraft, or separating SUVs from sedans while improving traditional clustering
metrics. However, the framework faces challenges: LLM generated rules may
hallucinate or conflict, excessive rules risk overfitting, and scaling to
complex domains increases computational and consistency difficulties. By
combining rule encodings with learned representations, DARTVAE achieves more
meaningful and consistent clustering outcomes than purely data driven models,
highlighting the utility of constraint guided multimodal clustering for
complex, knowledge intensive settings.

</details>


### [159] [Myosotis: structured computation for attention like layer](https://arxiv.org/abs/2509.20503)
*Evgenii Egorov,Hanno Ackermann,Markus Nagel,Hong Cai*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的算法，该算法结合了稀疏性和循环依赖性的优点，以解决注意力层中内存和计算随序列长度二次增长的问题。


<details>
  <summary>Details</summary>
Motivation: 注意力层的参数取决于输入元素的成对交互，这导致内存和计算随序列长度二次增长。为了缓解这个问题，通常采用的方法是引入稀疏性或循环依赖性，但这两种方法都有其缺点。

Method: 该论文提出的算法基于树结构矩阵的有效反演。

Result: 论文提出了一种新的算法。

Conclusion: 该论文提出了一种结合稀疏性和循环依赖性优点的算法，解决了注意力层中内存和计算随序列长度二次增长的问题。

Abstract: Attention layers apply a sequence-to-sequence mapping whose parameters depend
on the pairwise interactions of the input elements. However, without any
structural assumptions, memory and compute scale quadratically with the
sequence length. The two main ways to mitigate this are to introduce sparsity
by ignoring a sufficient amount of pairwise interactions or to introduce
recurrent dependence along them, as SSM does. Although both approaches are
reasonable, they both have disadvantages. We propose a novel algorithm that
combines the advantages of both concepts. Our idea is based on the efficient
inversion of tree-structured matrices.

</details>


### [160] [Auto-Regressive U-Net for Full-Field Prediction of Shrinkage-Induced Damage in Concrete](https://arxiv.org/abs/2509.20507)
*Liya Gaynutdinova,Petr Havlásek,Ondřej Rokoš,Fleur Hendriks,Martin Doškář*

Main category: cs.LG

TL;DR: 提出了一种用于预测混凝土中随时间变化的完整损伤场的深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过预测损伤演变来优化混凝土混合物设计，从而提高耐久性并减少内部损伤。

Method: 使用自回归 U-Net 模型预测标量损伤场的演变，并使用卷积神经网络 (CNN) 利用损伤估计来预测关键的力学性能。

Result: 所提出的双网络架构在合成数据集上表现出很高的计算效率和稳健的预测性能。

Conclusion: 该方法可以减少与全场损伤评估相关的计算负担，并用于深入了解骨料特性与有效收缩和刚度降低之间的关系。

Abstract: This paper introduces a deep learning approach for predicting time-dependent
full-field damage in concrete. The study uses an auto-regressive U-Net model to
predict the evolution of the scalar damage field in a unit cell given
microstructural geometry and evolution of an imposed shrinkage profile. By
sequentially using the predicted damage output as input for subsequent
predictions, the model facilitates the continuous assessment of damage
progression. Complementarily, a convolutional neural network (CNN) utilises the
damage estimations to forecast key mechanical properties, including observed
shrinkage and residual stiffness. The proposed dual-network architecture
demonstrates high computational efficiency and robust predictive performance on
the synthesised datasets. The approach reduces the computational load
traditionally associated with full-field damage evaluations and is used to gain
insights into the relationship between aggregate properties, such as shape,
size, and distribution, and the effective shrinkage and reduction in stiffness.
Ultimately, this can help to optimize concrete mix designs, leading to improved
durability and reduced internal damage.

</details>


### [161] [Complexity-Driven Policy Optimization](https://arxiv.org/abs/2509.20509)
*Luca Serfilippi,Giorgio Franceschelli,Antonio Corradi,Mirco Musolesi*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的策略梯度方法，用复杂性奖励代替熵奖励，以平衡探索和利用。复杂性奖励被定义为香农熵和不平衡的乘积，鼓励策略在随机性（高熵）和结构性（高不平衡）之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 传统的策略梯度方法通过最大化熵来平衡利用和探索，但这会将策略推向均匀随机分布，导致探索效率低下。因此，本文旨在寻找一种更鲁棒的复杂性奖励来替代熵奖励。

Method: 本文从近端策略优化（PPO）出发，提出了一种新的学习算法，即复杂性驱动的策略优化（CDPO），该算法用复杂性代替熵。

Result: 在离散动作空间任务中的实验结果表明，CDPO对复杂性系数的选择比PPO对熵系数的选择更稳健，尤其是在需要更大探索的环境中。

Conclusion: CDPO 是一种更鲁棒的策略梯度方法，它可以通过平衡随机性和结构性来更有效地进行探索。

Abstract: Policy gradient methods often balance exploitation and exploration via
entropy maximization. However, maximizing entropy pushes the policy towards a
uniform random distribution, which represents an unstructured and sometimes
inefficient exploration strategy. In this work, we propose replacing the
entropy bonus with a more robust complexity bonus. In particular, we adopt a
measure of complexity, defined as the product of Shannon entropy and
disequilibrium, where the latter quantifies the distance from the uniform
distribution. This regularizer encourages policies that balance stochasticity
(high entropy) with structure (high disequilibrium), guiding agents toward
regimes where useful, non-trivial behaviors can emerge. Such behaviors arise
because the regularizer suppresses both extremes, e.g., maximal disorder and
complete order, creating pressure for agents to discover structured yet
adaptable strategies. Starting from Proximal Policy Optimization (PPO), we
introduce Complexity-Driven Policy Optimization (CDPO), a new learning
algorithm that replaces entropy with complexity. We show empirically across a
range of discrete action space tasks that CDPO is more robust to the choice of
the complexity coefficient than PPO is with the entropy coefficient, especially
in environments requiring greater exploration.

</details>


### [162] [A Recovery Theory for Diffusion Priors: Deterministic Analysis of the Implicit Prior Algorithm](https://arxiv.org/abs/2509.20511)
*Oscar Leong,Yann Traonmilin*

Main category: cs.LG

TL;DR: 本文提出了一种用于分析基于扩散的逆问题确定性算法的理论框架，重点关注 Kadkhodaie＆Simoncelli 提出的算法的确定性版本。


<details>
  <summary>Details</summary>
Motivation: 从受损测量中恢复高维信号是逆问题中的一个核心挑战。生成扩散模型的最新进展已在提供强大的数据驱动先验方面显示出显著的经验成功，但严格的恢复保证仍然有限。

Method: 本文开发了一个理论框架，用于分析基于扩散的逆问题确定性算法。该框架将噪声卷积分数解释为及时变投影到低维模型集上，并将先前的算法解释为具有不同投影的广义投影梯度下降方法。

Result: 当传感矩阵满足模型集上的受限等距属性时，可以得出定量收敛速度，该速度显式地取决于噪声计划。将框架应用于两个有指导意义的数据分布：低维紧凸集上的均匀分布和低秩高斯混合模型。

Conclusion: 在后一种设置中，尽管基础模型集是非凸的，但可以建立全局收敛保证。

Abstract: Recovering high-dimensional signals from corrupted measurements is a central
challenge in inverse problems. Recent advances in generative diffusion models
have shown remarkable empirical success in providing strong data-driven priors,
but rigorous recovery guarantees remain limited. In this work, we develop a
theoretical framework for analyzing deterministic diffusion-based algorithms
for inverse problems, focusing on a deterministic version of the algorithm
proposed by Kadkhodaie \& Simoncelli \cite{kadkhodaie2021stochastic}. First, we
show that when the underlying data distribution concentrates on a
low-dimensional model set, the associated noise-convolved scores can be
interpreted as time-varying projections onto such a set. This leads to
interpreting previous algorithms using diffusion priors for inverse problems as
generalized projected gradient descent methods with varying projections. When
the sensing matrix satisfies a restricted isometry property over the model set,
we can derive quantitative convergence rates that depend explicitly on the
noise schedule. We apply our framework to two instructive data distributions:
uniform distributions over low-dimensional compact, convex sets and low-rank
Gaussian mixture models. In the latter setting, we can establish global
convergence guarantees despite the nonconvexity of the underlying model set.

</details>


### [163] [MDBench: Benchmarking Data-Driven Methods for Model Discovery](https://arxiv.org/abs/2509.20529)
*Amirmohammad Ziaei Bideh,Aleksandra Georgievska,Jonathan Gryak*

Main category: cs.LG

TL;DR: MDBench是一个用于评估动态系统模型发现方法的开源基准框架，包含12种算法在不同噪声水平下对14个偏微分方程（PDEs）和63个常微分方程（ODEs）的评估。


<details>
  <summary>Details</summary>
Motivation: 缺乏用于发现动态模型的综合基准，之前的研究主要集中在识别单个方程，通常被定义为符号回归。

Method: 引入MDBench基准框架，评估12种算法在14个偏微分方程和63个常微分方程上的表现，评估指标包括导数预测精度、模型复杂度和方程保真度。

Result: 线性方法和遗传编程方法分别在偏微分方程和常微分方程上实现了最低的预测误差，线性模型通常对噪声更具鲁棒性。

Conclusion: MDBench通过提供严格、可扩展的基准框架和丰富的动态系统数据集，加速了模型发现方法的发展，从而能够系统地评估、比较和改进方程的准确性和鲁棒性。

Abstract: Model discovery aims to uncover governing differential equations of dynamical
systems directly from experimental data. Benchmarking such methods is essential
for tracking progress and understanding trade-offs in the field. While prior
efforts have focused mostly on identifying single equations, typically framed
as symbolic regression, there remains a lack of comprehensive benchmarks for
discovering dynamical models. To address this, we introduce MDBench, an
open-source benchmarking framework for evaluating model discovery methods on
dynamical systems. MDBench assesses 12 algorithms on 14 partial differential
equations (PDEs) and 63 ordinary differential equations (ODEs) under varying
levels of noise. Evaluation metrics include derivative prediction accuracy,
model complexity, and equation fidelity. We also introduce seven challenging
PDE systems from fluid dynamics and thermodynamics, revealing key limitations
in current methods. Our findings illustrate that linear methods and genetic
programming methods achieve the lowest prediction error for PDEs and ODEs,
respectively. Moreover, linear models are in general more robust against noise.
MDBench accelerates the advancement of model discovery methods by offering a
rigorous, extensible benchmarking framework and a rich, diverse collection of
dynamical system datasets, enabling systematic evaluation, comparison, and
improvement of equation accuracy and robustness.

</details>


### [164] [Understanding and Improving Adversarial Robustness of Neural Probabilistic Circuits](https://arxiv.org/abs/2509.20549)
*Weixin Chen,Han Zhao*

Main category: cs.LG

TL;DR: 这篇论文介绍了神经概率电路 (NPC)，并通过对抗攻击分析了它的弱点。然后，作者提出了 RNPC，一种更强大的 NPC。


<details>
  <summary>Details</summary>
Motivation: NPC 虽然提高了可解释性和性能，但其属性识别模型容易受到对抗攻击。

Method: 理论分析和提出新的 class-wise integration 的 RNPC 结构。

Result: RNPC 在图像分类任务上表现出更强的对抗鲁棒性，同时保持了较高的良性输入准确率。

Conclusion: RNPC 是一种针对识别模块对抗攻击的鲁棒神经概率电路，它在理论上和实验上都优于 NPC。

Abstract: Neural Probabilistic Circuits (NPCs), a new class of concept bottleneck
models, comprise an attribute recognition model and a probabilistic circuit for
reasoning. By integrating the outputs from these two modules, NPCs produce
compositional and interpretable predictions. While offering enhanced
interpretability and high performance on downstream tasks, the
neural-network-based attribute recognition model remains a black box. This
vulnerability allows adversarial attacks to manipulate attribute predictions by
introducing carefully crafted subtle perturbations to input images, potentially
compromising the final predictions. In this paper, we theoretically analyze the
adversarial robustness of NPC and demonstrate that it only depends on the
robustness of the attribute recognition model and is independent of the
robustness of the probabilistic circuit. Moreover, we propose RNPC, the first
robust neural probabilistic circuit against adversarial attacks on the
recognition module. RNPC introduces a novel class-wise integration for
inference, ensuring a robust combination of outputs from the two modules. Our
theoretical analysis demonstrates that RNPC exhibits provably improved
adversarial robustness compared to NPC. Empirical results on image
classification tasks show that RNPC achieves superior adversarial robustness
compared to existing concept bottleneck models while maintaining high accuracy
on benign inputs.

</details>


### [165] [Generalizable Diabetes Risk Stratification via Hybrid Machine Learning Models](https://arxiv.org/abs/2509.20565)
*Athar Parvez,Muhammad Jawad Mufti*

Main category: cs.LG

TL;DR: 本文比较了两种混合分类器（XGB-RF 和 SVM-LR）在糖尿病风险分层中的应用，发现 XGB-RF 表现更优，更适合作为糖尿病风险分层的稳健方法。


<details>
  <summary>Details</summary>
Motivation: 糖尿病影响全球数百万人口，早期风险分层可受益于机器学习。

Method: 构建了两种混合分类器 XGB-RF 和 SVM-LR，并在主要数据集上拟合了一个防泄漏的标准化流程，并在外部 PIMA 数据集上进行了验证。

Result: 在主要数据集和 PIMA 数据集上，XGB-RF 的表现均优于 SVM-LR。XGB-RF 在 PIMA 数据集上保持了强大的性能。

Conclusion: XGB-RF 在内部和外部队列中始终优于 SVM-LR，并且在 ROC/PR 上的外部衰减更小，校准效果可接受。

Abstract: Background/Purpose: Diabetes affects over 537 million people worldwide and is
projected to reach 783 million by 2045. Early risk stratification can benefit
from machine learning. We compare two hybrid classifiers and assess their
generalizability on an external cohort.
  Methods: Two hybrids were built: (i) XGBoost + Random Forest (XGB-RF) and
(ii) Support Vector Machine + Logistic Regression (SVM-LR). A leakage-safe,
standardized pipeline (encoding, imputation, min-max scaling; SMOTE on training
folds only; probability calibration for SVM) was fit on the primary dataset and
frozen. Evaluation prioritized threshold-independent discrimination
(AUROC/AUPRC) and calibration (Brier, slope/intercept). External validation
used the PIMA cohort (N=768) with the frozen pipeline; any thresholded metrics
on PIMA were computed at the default rule tau = 0.5.
  Results: On the primary dataset (PR baseline = 0.50), XGB-RF achieved AUROC
~0.995 and AUPRC ~0.998, outperforming SVM-LR (AUROC ~0.978; AUPRC ~0.947). On
PIMA (PR baseline ~0.349), XGB-RF retained strong performance (AUROC ~0.990;
AUPRC ~0.959); SVM-LR was lower (AUROC ~0.963; AUPRC ~0.875). Thresholded
metrics on PIMA at tau = 0.5 were XGB-RF (Accuracy 0.960; Precision 0.941;
Recall 0.944; F1 0.942) and SVM-LR (Accuracy 0.900; Precision 0.855; Recall
0.858; F1 0.857).
  Conclusions: Across internal and external cohorts, XGB-RF consistently
dominated SVM-LR and exhibited smaller external attenuation on ROC/PR with
acceptable calibration. These results support gradient-boosting-based
hybridization as a robust, transferable approach for diabetes risk
stratification and motivate prospective, multi-site validation with
deployment-time threshold selection based on clinical trade-offs.

</details>


### [166] [PIRF: Physics-Informed Reward Fine-Tuning for Diffusion Models](https://arxiv.org/abs/2509.20570)
*Mingze Yuan,Pengfei Jin,Na Li,Quanzheng Li*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的视角，将物理信息生成转化为稀疏奖励优化问题，其中对物理约束的遵守被视为奖励信号。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在科学领域表现出强大的生成能力，但经常产生违反物理定律的输出。

Method: 提出了物理信息奖励微调（PIRF），一种通过计算轨迹级奖励并直接反向传播其梯度来绕过值近似的方法。PIRF 通过两种关键策略缓解了这些问题：（1）一种分层截断反向传播方法，利用了基于物理的奖励的时空局部性，以及（2）一种基于权重的正则化方案，提高了效率。

Result: 在五个 PDE 基准测试中，PIRF 在高效采样方案下始终实现卓越的物理执行。

Conclusion: 强调了奖励微调在推进科学生成建模方面的潜力。

Abstract: Diffusion models have demonstrated strong generative capabilities across
scientific domains, but often produce outputs that violate physical laws. We
propose a new perspective by framing physics-informed generation as a sparse
reward optimization problem, where adherence to physical constraints is treated
as a reward signal. This formulation unifies prior approaches under a
reward-based paradigm and reveals a shared bottleneck: reliance on diffusion
posterior sampling (DPS)-style value function approximations, which introduce
non-negligible errors and lead to training instability and inference
inefficiency. To overcome this, we introduce Physics-Informed Reward
Fine-tuning (PIRF), a method that bypasses value approximation by computing
trajectory-level rewards and backpropagating their gradients directly. However,
a naive implementation suffers from low sample efficiency and compromised data
fidelity. PIRF mitigates these issues through two key strategies: (1) a
layer-wise truncated backpropagation method that leverages the spatiotemporally
localized nature of physics-based rewards, and (2) a weight-based
regularization scheme that improves efficiency over traditional
distillation-based methods. Across five PDE benchmarks, PIRF consistently
achieves superior physical enforcement under efficient sampling regimes,
highlighting the potential of reward fine-tuning for advancing scientific
generative modeling.

</details>


### [167] [The Sensitivity of Variational Bayesian Neural Network Performance to Hyperparameters](https://arxiv.org/abs/2509.20574)
*Scott Koermer,Natalie Klein*

Main category: cs.LG

TL;DR: 本文对贝叶斯神经网络(BNN)的超参数选择问题进行了研究，旨在提高其预测不确定性(UQ)的准确性。


<details>
  <summary>Details</summary>
Motivation: 在科学应用中，准确的预测不确定性(UQ)对于判断模型的外推能力或何时需要收集更多数据至关重要。贝叶斯神经网络(BNN)可以通过传播神经网络(NN)权重的不确定性来产生预测不确定性，但实际应用中难以获得准确的UQ。

Method: 通过全局敏感性分析，研究了不同超参数设置下BNN性能的影响。

Result: 研究结果表明，许多超参数相互作用，影响预测精度和UQ。

Conclusion: 为了在实际应用中更好地使用BNN，建议使用全局敏感性分析或贝叶斯优化等相关方法，以帮助降维和选择超参数，从而确保BNN中UQ的准确性。

Abstract: In scientific applications, predictive modeling is often of limited use
without accurate uncertainty quantification (UQ) to indicate when a model may
be extrapolating or when more data needs to be collected. Bayesian Neural
Networks (BNNs) produce predictive uncertainty by propagating uncertainty in
neural network (NN) weights and offer the promise of obtaining not only an
accurate predictive model but also accurate UQ. However, in practice, obtaining
accurate UQ with BNNs is difficult due in part to the approximations used for
practical model training and in part to the need to choose a suitable set of
hyperparameters; these hyperparameters outnumber those needed for traditional
NNs and often have opaque effects on the results. We aim to shed light on the
effects of hyperparameter choices for BNNs by performing a global sensitivity
analysis of BNN performance under varying hyperparameter settings. Our results
indicate that many of the hyperparameters interact with each other to affect
both predictive accuracy and UQ. For improved usage of BNNs in real-world
applications, we suggest that global sensitivity analysis, or related methods
such as Bayesian optimization, should be used to aid in dimensionality
reduction and selection of hyperparameters to ensure accurate UQ in BNNs.

</details>


### [168] [Learning Greens Operators through Hierarchical Neural Networks Inspired by the Fast Multipole Method](https://arxiv.org/abs/2509.20591)
*Emilio McAllister Fognini,Marta M. Betcke,Ben T. Cox*

Main category: cs.LG

TL;DR: 本文提出了一种新的神经网络结构，Neural FMM，它将FMM的信息流集成到分层机器学习框架中，用于学习椭圆偏微分方程的格林算子。


<details>
  <summary>Details</summary>
Motivation: 尽管FMM在物理和工程领域有广泛的应用，但FMM与现代机器学习架构的集成仍未得到充分探索。

Method: 将FMM的信息流集成到分层机器学习框架中，利用FMM方法的分层计算流来分解局部和远场相互作用，并有效地学习它们各自的表示。

Result: 提出了一种新的神经网络结构，Neural FMM。

Conclusion: Neural FMM架构利用FMM方法的分层计算流来分解局部和远场相互作用，并有效地学习它们各自的表示。

Abstract: The Fast Multipole Method (FMM) is an efficient numerical algorithm for
computation of long-ranged forces in $N$-body problems within gravitational and
electrostatic fields. This method utilizes multipole expansions of the Green's
function inherent to the underlying dynamical systems. Despite its widespread
application in physics and engineering, the integration of FMM with modern
machine learning architectures remains underexplored. In this work, we propose
a novel neural network architecture, the Neural FMM, that integrates the
information flow of the FMM into a hierarchical machine learning framework for
learning the Green's operator of an Elliptic PDE. Our Neural FMM architecture
leverages a hierarchical computation flow of the FMM method to split up the
local and far-field interactions and efficiently learn their respective
representations.

</details>


### [169] [TSKAN: Interpretable Machine Learning for QoE modeling over Time Series Data](https://arxiv.org/abs/2509.20595)
*Kamal Singh,Priyanka Rawat,Sami Marouani,Baptiste Jeudy*

Main category: cs.LG

TL;DR: 提出了一种新的QoE建模方法，该方法使用可解释的机器学习技术，在原始时间序列数据上进行视频流应用的优化。


<details>
  <summary>Details</summary>
Motivation: 为了优化视频流服务，需要对用户体验进行建模，捕捉不同特征与用户体验之间的复杂关系。

Method: 该方法结合了Kolmogorov-Arnold Networks (KANs) 作为可解释的读出层，建立在紧凑的频域特征之上，从而在保留透明和可解释模型的同时，捕获时间信息。

Result: 在流行数据集上的评估表明，该方法在QoE预测方面具有更高的准确性，同时提供了透明性和可解释性。

Conclusion: 该方法在QoE预测方面提高了准确性，同时提供了透明性和可解释性。

Abstract: Quality of Experience (QoE) modeling is crucial for optimizing video
streaming services to capture the complex relationships between different
features and user experience. We propose a novel approach to QoE modeling in
video streaming applications using interpretable Machine Learning (ML)
techniques over raw time series data. Unlike traditional black-box approaches,
our method combines Kolmogorov-Arnold Networks (KANs) as an interpretable
readout on top of compact frequency-domain features, allowing us to capture
temporal information while retaining a transparent and explainable model. We
evaluate our method on popular datasets and demonstrate its enhanced accuracy
in QoE prediction, while offering transparency and interpretability.

</details>


### [170] [Explicit and Effectively Symmetric Schemes for Neural SDEs](https://arxiv.org/abs/2509.20599)
*Daniil Shmelev,Cristopher Salvi*

Main category: cs.LG

TL;DR: 提出了一种新的Runge-Kutta格式，用于解决神经SDE中的稳定性和可靠性问题，从而实现可扩展和准确的训练。


<details>
  <summary>Details</summary>
Motivation: 传统的通过（神经）SDE求解器进行反向传播有两种方法：离散化然后优化，它提供准确的梯度，但由于存储完整的计算图而导致过高的内存成本；以及优化然后离散化，它通过求解辅助反向SDE来实现恒定的内存成本，但存在评估速度较慢和梯度近似误差的问题。代数可逆求解器兼具内存效率和梯度精度，但现有的方法（如可逆Heun格式）在复杂的模型和较大的步长下通常不稳定。

Method: 引入了一类新的、稳定的、近可逆的Runge-Kutta格式，用于神经SDE。这些显式和有效对称（EES）格式保留了可逆求解器的优点，同时克服了它们的不稳定性。

Result: 通过数值实验，证明了该方案具有优越的稳定性和可靠性，

Conclusion: 将它们确立为神经SDE可扩展和准确训练的实践基础。

Abstract: Backpropagation through (neural) SDE solvers is traditionally approached in
two ways: discretise-then-optimise, which offers accurate gradients but incurs
prohibitive memory costs due to storing the full computational graph (even when
mitigated by checkpointing); and optimise-then-discretise, which achieves
constant memory cost by solving an auxiliary backward SDE, but suffers from
slower evaluation and gradient approximation errors. Algebraically reversible
solvers promise both memory efficiency and gradient accuracy, yet existing
methods such as the Reversible Heun scheme are often unstable under complex
models and large step sizes. We address these limitations by introducing a
novel class of stable, near-reversible Runge--Kutta schemes for neural SDEs.
These Explicit and Effectively Symmetric (EES) schemes retain the benefits of
reversible solvers while overcoming their instability, enabling
memory-efficient training without severe restrictions on step size or model
complexity. Through numerical experiments, we demonstrate the superior
stability and reliability of our schemes, establishing them as a practical
foundation for scalable and accurate training of neural SDEs.

</details>


### [171] [Function Spaces Without Kernels: Learning Compact Hilbert Space Representations](https://arxiv.org/abs/2509.20605)
*Su Ann Low,Quentin Rommel,Kevin S. Miller,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.LG

TL;DR: 函数编码器学习神经网络基函数，形成紧凑的 Hilbert 空间自适应表示。


<details>
  <summary>Details</summary>
Motivation: 通过定义学习到的特征图的内积来定义核，从而将函数编码器与特征学习和核方法联系起来。这种核理论的视角解释了它们独立于数据集大小进行扩展的能力，同时适应数据的内在结构，并且能够对神经模型进行核式分析。

Method: 两种训练算法：一种是逐步训练方法，它以建设性的方式增长基；另一种是先训练后修剪方法，它在训练后提供了一种计算效率高的替代方案。两种方法都使用 PCA 的原理来揭示学习空间的内在维度。

Result: 在具有已知内在维度的多项式基准以及包括范德波尔振荡器和二体轨道模型在内的非线性动力系统上验证了该方法，证明了可以用更少的基函数实现相同的精度。

Conclusion: 这项工作提出了一条通往具有核级保证的神经预测器的路径，从而实现了高效且有原则的可扩展的自适应模型。

Abstract: Function encoders are a recent technique that learn neural network basis
functions to form compact, adaptive representations of Hilbert spaces of
functions. We show that function encoders provide a principled connection to
feature learning and kernel methods by defining a kernel through an inner
product of the learned feature map. This kernel-theoretic perspective explains
their ability to scale independently of dataset size while adapting to the
intrinsic structure of data, and it enables kernel-style analysis of neural
models. Building on this foundation, we develop two training algorithms that
learn compact bases: a progressive training approach that constructively grows
bases, and a train-then-prune approach that offers a computationally efficient
alternative after training. Both approaches use principles from PCA to reveal
the intrinsic dimension of the learned space. In parallel, we derive
finite-sample generalization bounds using Rademacher complexity and PAC-Bayes
techniques, providing inference time guarantees. We validate our approach on a
polynomial benchmark with a known intrinsic dimension, and on nonlinear
dynamical systems including a Van der Pol oscillator and a two-body orbital
model, demonstrating that the same accuracy can be achieved with substantially
fewer basis functions. This work suggests a path toward neural predictors with
kernel-level guarantees, enabling adaptable models that are both efficient and
principled at scale.

</details>


### [172] [MMG: Mutual Information Estimation via the MMSE Gap in Diffusion](https://arxiv.org/abs/2509.20609)
*Longxuan Yu,Xing Shi,Xianghao Kong,Tong Jia,Greg Ver Steeg*

Main category: cs.LG

TL;DR: 本研究提出了一种利用去噪扩散模型改进互信息(MI)估计的新方法。


<details>
  <summary>Details</summary>
Motivation: 互信息是衡量随机变量之间关系的重要方法，但对于复杂系统，估计互信息具有挑战性。去噪扩散模型在密度估计方面表现出色，因此研究其在互信息估计中的应用具有潜力。

Method: 该方法基于去噪扩散模型的信息理论公式，将互信息与条件和非条件扩散之间的最小均方误差(MMSE)差距联系起来，并在所有信噪比(SNR)上进行积分。同时，采用自适应重要性抽样来实现可扩展的互信息估计。

Result: 该方法通过了自洽性测试，优于传统和基于分数的扩散互信息估计器。即使在互信息较高的情况下，该方法也能保持良好的性能。

Conclusion: 去噪扩散模型可以有效地用于互信息估计，并具有良好的性能和可扩展性。

Abstract: Mutual information (MI) is one of the most general ways to measure
relationships between random variables, but estimating this quantity for
complex systems is challenging. Denoising diffusion models have recently set a
new bar for density estimation, so it is natural to consider whether these
methods could also be used to improve MI estimation. Using the recently
introduced information-theoretic formulation of denoising diffusion models, we
show the diffusion models can be used in a straightforward way to estimate MI.
In particular, the MI corresponds to half the gap in the Minimum Mean Square
Error (MMSE) between conditional and unconditional diffusion, integrated over
all Signal-to-Noise-Ratios (SNRs) in the noising process. Our approach not only
passes self-consistency tests but also outperforms traditional and score-based
diffusion MI estimators. Furthermore, our method leverages adaptive importance
sampling to achieve scalable MI estimation, while maintaining strong
performance even when the MI is high.

</details>


### [173] [Policy Compatible Skill Incremental Learning via Lazy Learning Interface](https://arxiv.org/abs/2509.20612)
*Daehee Lee,Dongsu Lee,TaeYoon Kwack,Wonje Choi,Honguk Woo*

Main category: cs.LG

TL;DR: 提出了一种名为SIL-C的新框架，该框架通过双边延迟学习映射技术，保证了技能-策略的兼容性，允许增量学习技能的改进来提高下游策略的性能，而无需策略重新训练或结构调整。


<details>
  <summary>Details</summary>
Motivation: 具身智能体通过与环境互动或整合额外数据来扩展和完善其技能集合，从而实现高效的分层策略获取，但技能库的演变会破坏与现有基于技能的策略的兼容性，限制其可重用性和泛化性。

Method: 采用基于双边延迟学习的映射技术，动态地将策略引用的子任务空间与解码为智能体行为的技能空间对齐。这使得每个子任务都可以通过选择适当的技能来执行，选择基于轨迹分布相似性。

Result: 在不同的SIL场景中评估了SIL-C，结果表明它可以保持演进技能和下游策略之间的兼容性，同时确保整个学习过程的效率。

Conclusion: SIL-C框架有效解决了技能增量学习中技能库演变导致的兼容性问题，提高了策略的可重用性和泛化性。

Abstract: Skill Incremental Learning (SIL) is the process by which an embodied agent
expands and refines its skill set over time by leveraging experience gained
through interaction with its environment or by the integration of additional
data. SIL facilitates efficient acquisition of hierarchical policies grounded
in reusable skills for downstream tasks. However, as the skill repertoire
evolves, it can disrupt compatibility with existing skill-based policies,
limiting their reusability and generalization. In this work, we propose SIL-C,
a novel framework that ensures skill-policy compatibility, allowing
improvements in incrementally learned skills to enhance the performance of
downstream policies without requiring policy re-training or structural
adaptation. SIL-C employs a bilateral lazy learning-based mapping technique to
dynamically align the subtask space referenced by policies with the skill space
decoded into agent behaviors. This enables each subtask, derived from the
policy's decomposition of a complex task, to be executed by selecting an
appropriate skill based on trajectory distribution similarity. We evaluate
SIL-C across diverse SIL scenarios and demonstrate that it maintains
compatibility between evolving skills and downstream policies while ensuring
efficiency throughout the learning process.

</details>


### [174] [Latent Twins](https://arxiv.org/abs/2509.20615)
*Matthias Chung,Deepanshu Verma,Max Collins,Amit N. Subrahmanya,Varuni Katti Sastry,Vishwas Rao*

Main category: cs.LG

TL;DR: Latent Twins creates a hidden surrogate in latent space for underlying equations, mirroring mathematical systems. It unifies modeling, inversion, model reduction, and operator approximation.


<details>
  <summary>Details</summary>
Motivation: Scientific machine learning has transformed the development of mathematical and computational frameworks for analyzing, modeling, and predicting complex systems, but representation learning and algorithmic solution methods have evolved separately.

Method: A unifying mathematical framework called Latent Twins is proposed, which creates a hidden surrogate in latent space for the underlying equations.

Result: The fundamental approximation properties of Latent Twins are established for both ODEs and PDEs. The framework is demonstrated across three representative settings.

Conclusion: Latent Twins provide a compact, interpretable surrogate for solution operators and offer scalable, theory-grounded surrogates that bridge data-driven representation learning and classical scientific modeling across disciplines.

Abstract: Over the past decade, scientific machine learning has transformed the
development of mathematical and computational frameworks for analyzing,
modeling, and predicting complex systems. From inverse problems to numerical
PDEs, dynamical systems, and model reduction, these advances have pushed the
boundaries of what can be simulated. Yet they have often progressed in
parallel, with representation learning and algorithmic solution methods
evolving largely as separate pipelines. With \emph{Latent Twins}, we propose a
unifying mathematical framework that creates a hidden surrogate in latent space
for the underlying equations. Whereas digital twins mirror physical systems in
the digital world, Latent Twins mirror mathematical systems in a learned latent
space governed by operators. Through this lens, classical modeling, inversion,
model reduction, and operator approximation all emerge as special cases of a
single principle. We establish the fundamental approximation properties of
Latent Twins for both ODEs and PDEs and demonstrate the framework across three
representative settings: (i) canonical ODEs, capturing diverse dynamical
regimes; (ii) a PDE benchmark using the shallow-water equations, contrasting
Latent Twin simulations with DeepONet and forecasts with a 4D-Var baseline; and
(iii) a challenging real-data geopotential reanalysis dataset, reconstructing
and forecasting from sparse, noisy observations. Latent Twins provide a
compact, interpretable surrogate for solution operators that evaluate across
arbitrary time gaps in a single-shot, while remaining compatible with
scientific pipelines such as assimilation, control, and uncertainty
quantification. Looking forward, this framework offers scalable,
theory-grounded surrogates that bridge data-driven representation learning and
classical scientific modeling across disciplines.

</details>


### [175] [Training Task Reasoning LLM Agents for Multi-turn Task Planning via Single-turn Reinforcement Learning](https://arxiv.org/abs/2509.20616)
*Hanjiang Hu,Changliu Liu,Na Li,Yebin Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种新方法，将多轮任务规划转化为单轮任务推理问题，通过专家轨迹的密集和可验证的奖励，利用群体相对策略优化（GRPO）实现有效的策略优化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在知识获取、推理和工具使用方面表现出卓越的能力，使其成为自主代理应用的有希望的候选者。然而，训练LLM代理进行复杂的多轮任务规划面临着重大挑战，包括稀疏的 эпизод 奖励、跨长期的信用分配以及多轮交互环境中强化学习的计算开销。

Method: 本研究将多轮任务规划转化为单轮任务推理问题，通过专家轨迹的密集和可验证的奖励，利用群体相对策略优化（GRPO）实现有效的策略优化。

Result: 在复杂的任务规划基准上的实验评估表明，我们使用单轮GRPO训练的15亿参数模型与高达140亿参数的更大基线模型相比，实现了卓越的性能，对于超过30步的长程规划任务，成功率为70%。

Conclusion: 我们也在理论上和经验上验证了强大的跨任务泛化能力，即在复杂任务上训练的模型可以成功完成所有更简单的子任务。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
knowledge acquisition, reasoning, and tool use, making them promising
candidates for autonomous agent applications. However, training LLM agents for
complex multi-turn task planning faces significant challenges, including sparse
episode-wise rewards, credit assignment across long horizons, and the
computational overhead of reinforcement learning in multi-turn interaction
settings. To this end, this paper introduces a novel approach that transforms
multi-turn task planning into single-turn task reasoning problems, enabling
efficient policy optimization through Group Relative Policy Optimization (GRPO)
with dense and verifiable reward from expert trajectories. Our theoretical
analysis shows that GRPO improvement on single-turn task reasoning results in
higher multi-turn success probability under the minimal turns, as well as the
generalization to subtasks with shorter horizons. Experimental evaluation on
the complex task planning benchmark demonstrates that our 1.5B parameter model
trained with single-turn GRPO achieves superior performance compared to larger
baseline models up to 14B parameters, with success rates of 70% for
long-horizon planning tasks with over 30 steps. We also theoretically and
empirically validate the strong cross-task generalizability that the models
trained on complex tasks can lead to the successful completion of all simpler
subtasks.

</details>


### [176] [Personalized Federated Dictionary Learning for Modeling Heterogeneity in Multi-site fMRI Data](https://arxiv.org/abs/2509.20627)
*Yipu Zhang,Chengshuo Zhang,Ziyu Zhou,Gang Qu,Hao Zheng,Yuping Wang,Hui Shen,Hongwen Deng*

Main category: cs.LG

TL;DR: 提出了个性化联邦字典学习 (PFedDL)，一种新的联邦学习框架，可以在不共享原始数据的情况下跨站点进行协作建模。


<details>
  <summary>Details</summary>
Motivation: 数据隐私约束对大规模神经影像分析提出了重大挑战，尤其是在多站点功能磁共振成像 (fMRI) 研究中，其中特定站点的异质性导致非独立且同分布 (non-IID) 数据。这些因素阻碍了通用模型的开发。

Method: PFedDL 在每个站点执行独立的字典学习，将每个站点特定的字典分解为共享的全局组件和个性化的本地组件。全局原子通过联邦聚合进行更新，以促进跨站点一致性，而本地原子则独立地进行细化，以捕获站点特定的变异性，从而增强下游分析。

Result: 在 ABIDE 数据集上的实验表明，PFedDL 在非 IID 数据集的准确性和鲁棒性方面优于现有方法。

Conclusion: PFedDL 是一种很有前途的联邦学习框架，可用于解决多站点 fMRI 研究中的数据隐私和异质性挑战。

Abstract: Data privacy constraints pose significant challenges for large-scale
neuroimaging analysis, especially in multi-site functional magnetic resonance
imaging (fMRI) studies, where site-specific heterogeneity leads to
non-independent and identically distributed (non-IID) data. These factors
hinder the development of generalizable models. To address these challenges, we
propose Personalized Federated Dictionary Learning (PFedDL), a novel federated
learning framework that enables collaborative modeling across sites without
sharing raw data. PFedDL performs independent dictionary learning at each site,
decomposing each site-specific dictionary into a shared global component and a
personalized local component. The global atoms are updated via federated
aggregation to promote cross-site consistency, while the local atoms are
refined independently to capture site-specific variability, thereby enhancing
downstream analysis. Experiments on the ABIDE dataset demonstrate that PFedDL
outperforms existing methods in accuracy and robustness across non-IID
datasets.

</details>


### [177] [Investigating Modality Contribution in Audio LLMs for Music](https://arxiv.org/abs/2509.20641)
*Giovana Morais,Magdalena Fuentes*

Main category: cs.LG

TL;DR: 研究表明，音频大语言模型(Audio LLM)在音乐对话中表现出色，但尚不清楚它们是否真正“听”了音频，还是仅依赖文本推理。本文通过量化每种模态对模型输出的贡献来研究这个问题。


<details>
  <summary>Details</summary>
Motivation: 探究音频大语言模型是否真正理解音频内容，还是仅仅依赖文本信息进行推理。

Method: 采用基于Shapley值的MM-SHAP框架，量化每种模态对模型预测的相对贡献。

Result: 发现精度更高的模型更多地依赖文本来回答问题，但即使整体音频贡献较低，模型也能成功定位关键声音事件。

Conclusion: 首次将MM-SHAP应用于音频大语言模型，为可解释AI和音频领域的未来研究奠定了基础。

Abstract: Audio Large Language Models (Audio LLMs) enable human-like conversation about
music, yet it is unclear if they are truly listening to the audio or just using
textual reasoning, as recent benchmarks suggest. This paper investigates this
issue by quantifying the contribution of each modality to a model's output. We
adapt the MM-SHAP framework, a performance-agnostic score based on Shapley
values that quantifies the relative contribution of each modality to a model's
prediction. We evaluate two models on the MuChoMusic benchmark and find that
the model with higher accuracy relies more on text to answer questions, but
further inspection shows that even if the overall audio contribution is low,
models can successfully localize key sound events, suggesting that audio is not
entirely ignored. Our study is the first application of MM-SHAP to Audio LLMs
and we hope it will serve as a foundational step for future research in
explainable AI and audio.

</details>


### [178] [Wonder Wins Ways: Curiosity-Driven Exploration through Multi-Agent Contextual Calibration](https://arxiv.org/abs/2509.20648)
*Yiyuan Pan,Zhe Liu,Hesheng Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的多智能体探索方法，通过观察同伴来动态调整智能体的好奇心，从而在稀疏奖励环境中实现更有效的探索。


<details>
  <summary>Details</summary>
Motivation: 在复杂的多智能体强化学习（MARL）中，稀疏奖励下的自主探索严重依赖于为智能体提供有效的内在动机。现有的好奇心机制存在将环境随机性与有意义的新颖性混淆，以及忽略同伴行为新颖性的问题，导致在去中心化、无通信的MARL环境中探索效果不佳。

Method: 本文提出了一种名为CERMIC的框架，该框架通过推断多智能体上下文来动态校准智能体的内在好奇心，从而过滤噪声信号并指导探索。此外，CERMIC生成理论上有依据的内在奖励，鼓励智能体探索具有高信息增益的状态转换。

Result: 在VMAS、Meltingpot和SMACv2等基准测试套件上的实验结果表明，在稀疏奖励环境中，使用CERMIC进行探索显著优于SoTA算法。

Conclusion: CERMIC框架能够有效地提高多智能体在稀疏奖励环境中的探索能力。

Abstract: Autonomous exploration in complex multi-agent reinforcement learning (MARL)
with sparse rewards critically depends on providing agents with effective
intrinsic motivation. While artificial curiosity offers a powerful
self-supervised signal, it often confuses environmental stochasticity with
meaningful novelty. Moreover, existing curiosity mechanisms exhibit a uniform
novelty bias, treating all unexpected observations equally. However, peer
behavior novelty, which encode latent task dynamics, are often overlooked,
resulting in suboptimal exploration in decentralized, communication-free MARL
settings. To this end, inspired by how human children adaptively calibrate
their own exploratory behaviors via observing peers, we propose a novel
approach to enhance multi-agent exploration. We introduce CERMIC, a principled
framework that empowers agents to robustly filter noisy surprise signals and
guide exploration by dynamically calibrating their intrinsic curiosity with
inferred multi-agent context. Additionally, CERMIC generates
theoretically-grounded intrinsic rewards, encouraging agents to explore state
transitions with high information gain. We evaluate CERMIC on benchmark suites
including VMAS, Meltingpot, and SMACv2. Empirical results demonstrate that
exploration with CERMIC significantly outperforms SoTA algorithms in
sparse-reward environments.

</details>


### [179] [Guiding Application Users via Estimation of Computational Resources for Massively Parallel Chemistry Computations](https://arxiv.org/abs/2509.20667)
*Tanzila Tabassum,Omer Subasi,Ajay Panyala,Epiya Ebiapia,Gerald Baumgartner,Erdal Mutlu,P.,Sadayappan,Karol Kowalski*

Main category: cs.LG

TL;DR: 使用机器学习预测大规模并行化学计算的资源需求，以指导用户。


<details>
  <summary>Details</summary>
Motivation: 在超算上运行昂贵的化学计算实验之前，预测资源需求（成本）。

Method: 开发基于机器学习的模型和策略，预测应用执行时间，从而确定最佳运行时参数值（节点数和 tile sizes）。

Result: Gradient Boosting 模型在预测 CCSD 迭代的总执行时间时，在 Aurora 和 Frontier 上分别实现了 0.023 和 0.073 的 MAPE。主动学习仅需约 450 个实验即可达到约 0.2 的 MAPE。

Conclusion: 通过机器学习模型预测化学计算资源需求是可行的，并且主动学习能够以较少的实验数据达到较好的预测精度。

Abstract: In this work, we develop machine learning (ML) based strategies to predict
resources (costs) required for massively parallel chemistry computations, such
as coupled-cluster methods, to guide application users before they commit to
running expensive experiments on a supercomputer. By predicting application
execution time, we determine the optimal runtime parameter values such as
number of nodes and tile sizes. Two key questions of interest to users are
addressed. The first is the shortest-time question, where the user is
interested in knowing the parameter configurations (number of nodes and tile
sizes) to achieve the shortest execution time for a given problem size and a
target supercomputer. The second is the cheapest-run question in which the user
is interested in minimizing resource usage, i.e., finding the number of nodes
and tile size that minimizes the number of node-hours for a given problem size.
  We evaluate a rich family of ML models and strategies, developed based on the
collections of runtime parameter values for the CCSD (Coupled Cluster with
Singles and Doubles) application executed on the Department of Energy (DOE)
Frontier and Aurora supercomputers. Our experiments show that when predicting
the total execution time of a CCSD iteration, a Gradient Boosting (GB) ML model
achieves a Mean Absolute Percentage Error (MAPE) of 0.023 and 0.073 for Aurora
and Frontier, respectively. In the case where it is expensive to run
experiments just to collect data points, we show that active learning can
achieve a MAPE of about 0.2 with just around 450 experiments collected from
Aurora and Frontier.

</details>


### [180] [Theoretical Bounds for Stable In-Context Learning](https://arxiv.org/abs/2509.20677)
*Tongxi Wang,Zhuoyang Xia*

Main category: cs.LG

TL;DR: 本文研究了上下文学习 (ICL) 的稳定性问题，发现其可靠性对提示长度非常敏感。通过建立一个非渐近下界，将演示的最小数量与固定高维亚高斯表示下的 ICL 稳定性联系起来。


<details>
  <summary>Details</summary>
Motivation: ICL 的灵活性使其备受欢迎，但其可靠性受提示长度的影响很大。

Method: 本文建立了一个非渐近下界，该下界根据协方差的谱性质给出了明确的充分条件，为实践提供了一个可计算的标准。此外，还提出了一个两阶段可观测估计器，通过一次校准即可生成 practitioner-ready 的提示长度估计，而无需分布先验。

Result: 实验结果表明，在不同的数据集、编码器和生成器上，预测的阈值与经验膝点密切吻合，该理论作为保守但可靠的上限；校准后的变体进一步缩小了这一差距。

Conclusion: 这些结果将谱覆盖率与稳定的 ICL 联系起来，弥合了理论与部署之间的差距，并提高了实际有限样本状态下大规模提示的可解释性和可靠性。

Abstract: In-context learning (ICL) is flexible but its reliability is highly sensitive
to prompt length. This paper establishes a non-asymptotic lower bound that
links the minimal number of demonstrations to ICL stability under fixed
high-dimensional sub-Gaussian representations. The bound gives explicit
sufficient conditions in terms of spectral properties of the covariance,
providing a computable criterion for practice. Building on this analysis, we
propose a two-stage observable estimator with a one-shot calibration that
produces practitioner-ready prompt-length estimates without distributional
priors. Experiments across diverse datasets, encoders, and generators show
close alignment between the predicted thresholds and empirical knee-points,
with the theory acting as a conservative but reliable upper bound; the
calibrated variant further tightens this gap. These results connect spectral
coverage to stable ICL, bridge theory and deployment, and improve the
interpretability and reliability of large-scale prompting in realistic
finite-sample regimes.

</details>


### [181] [Bispectral OT: Dataset Comparison using Symmetry-Aware Optimal Transport](https://arxiv.org/abs/2509.20678)
*Annabel Ma,Kaiying Hou,David Alvarez-Melis,Melanie Weber*

Main category: cs.LG

TL;DR: 提出了双谱最优传输（Bispectral Optimal Transport），这是一种考虑对称性的离散最优传输扩展方法，通过使用双谱来比较元素，双谱是一种群傅里叶不变量，可以保留所有信号结构，同时消除由群作用引起的变异。


<details>
  <summary>Details</summary>
Motivation: 在具有丰富对称性的环境中，仅基于原始特征之间成对几何距离的最优传输（OT）对齐可能会忽略数据的内在连贯结构。

Method: 引入双谱最优传输，一种对称感知型的离散OT扩展，它使用双谱（一种群傅里叶不变量）来比较元素。

Result: 实验结果表明，在经过视觉对称变换的基准数据集上，使用双谱OT计算的传输方案比朴素特征OT实现了更高的类别保持精度，从而提高了有意义的对应关系的质量，这些对应关系捕获了数据集中潜在的语义标签结构，同时消除了不影响类别或内容的干扰变异。

Conclusion: 双谱最优传输能够更好地处理具有对称性的数据集，提高分类精度和对应关系质量。

Abstract: Optimal transport (OT) is a widely used technique in machine learning,
graphics, and vision that aligns two distributions or datasets using their
relative geometry. In symmetry-rich settings, however, OT alignments based
solely on pairwise geometric distances between raw features can ignore the
intrinsic coherence structure of the data. We introduce Bispectral Optimal
Transport, a symmetry-aware extension of discrete OT that compares elements
using their representation using the bispectrum, a group Fourier invariant that
preserves all signal structure while removing only the variation due to group
actions. Empirically, we demonstrate that the transport plans computed with
Bispectral OT achieve greater class preservation accuracy than naive feature OT
on benchmark datasets transformed with visual symmetries, improving the quality
of meaningful correspondences that capture the underlying semantic label
structure in the dataset while removing nuisance variation not affecting class
or content.

</details>


### [182] [Can Federated Learning Safeguard Private Data in LLM Training? Vulnerabilities, Attacks, and Defense Evaluation](https://arxiv.org/abs/2509.20680)
*Wenkai Guo,Xuefeng Liu,Haolin Wang,Jianwei Niu,Shaojie Tang,Jing Yuan*

Main category: cs.LG

TL;DR: 联邦学习(FL)虽然可以在保护隐私的前提下协同微调大型语言模型(LLM)，但仍存在数据泄露风险，且模型越大风险越高。


<details>
  <summary>Details</summary>
Motivation: 机构希望利用各自数据协同微调LLM，但又不愿共享本地数据，因此考虑使用联邦学习(FL)。

Method: 通过实验，证明攻击者可以从FL的全局模型中提取训练数据，并提出一种针对FL的增强攻击策略。

Result: 发现即使使用简单的生成方法，攻击者也能从全局模型中提取训练数据，且模型越大泄露风险越高。同时，增强的攻击策略可以加剧隐私泄露。

Conclusion: 评估了几种隐私保护技术在FL中的应用，并为降低使用FL训练LLM时的隐私风险提供了有价值的见解和实践指导。

Abstract: Fine-tuning large language models (LLMs) with local data is a widely adopted
approach for organizations seeking to adapt LLMs to their specific domains.
Given the shared characteristics in data across different organizations, the
idea of collaboratively fine-tuning an LLM using data from multiple sources
presents an appealing opportunity. However, organizations are often reluctant
to share local data, making centralized fine-tuning impractical. Federated
learning (FL), a privacy-preserving framework, enables clients to retain local
data while sharing only model parameters for collaborative training, offering a
potential solution. While fine-tuning LLMs on centralized datasets risks data
leakage through next-token prediction, the iterative aggregation process in FL
results in a global model that encapsulates generalized knowledge, which some
believe protects client privacy. In this paper, however, we present
contradictory findings through extensive experiments. We show that attackers
can still extract training data from the global model, even using
straightforward generation methods, with leakage increasing as the model size
grows. Moreover, we introduce an enhanced attack strategy tailored to FL, which
tracks global model updates during training to intensify privacy leakage. To
mitigate these risks, we evaluate privacy-preserving techniques in FL,
including differential privacy, regularization-constrained updates and adopting
LLMs with safety alignment. Our results provide valuable insights and practical
guidelines for reducing privacy risks when training LLMs with FL.

</details>


### [183] [Learning to Align Molecules and Proteins: A Geometry-Aware Approach to Binding Affinity](https://arxiv.org/abs/2509.20693)
*Mohammadsaleh Refahi,Bahrad A. Sokhansanj,James R. Brown,Gail Rosen*

Main category: cs.LG

TL;DR: FIRM-DTI: A new deep learning framework for drug-target binding affinity prediction.


<details>
  <summary>Details</summary>
Motivation: Existing deep learning models for drug-target binding affinity prediction lack explicit geometric regularization, resulting in poor generalization.

Method: Conditions molecular embeddings on protein embeddings through a feature-wise linear modulation (FiLM) layer and enforces metric structure with a triplet loss.

Result: Achieves state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark.

Conclusion: Conditioning and metric learning are valuable for robust drug-target affinity prediction.

Abstract: Accurate prediction of drug-target binding affinity can accelerate drug
discovery by prioritizing promising compounds before costly wet-lab screening.
While deep learning has advanced this task, most models fuse ligand and protein
representations via simple concatenation and lack explicit geometric
regularization, resulting in poor generalization across chemical space and
time. We introduce FIRM-DTI, a lightweight framework that conditions molecular
embeddings on protein embeddings through a feature-wise linear modulation
(FiLM) layer and enforces metric structure with a triplet loss. An RBF
regression head operating on embedding distances yields smooth, interpretable
affinity predictions. Despite its modest size, FIRM-DTI achieves
state-of-the-art performance on the Therapeutics Data Commons DTI-DG benchmark,
as demonstrated by an extensive ablation study and out-of-domain evaluation.
Our results underscore the value of conditioning and metric learning for robust
drug-target affinity prediction.

</details>


### [184] [CE-GPPO: Controlling Entropy via Gradient-Preserving Clipping Policy Optimization in Reinforcement Learning](https://arxiv.org/abs/2509.20712)
*Zhenpeng Su,Leiyu Pan,Minxuan Lv,Yuntao Li,Wenping Hu,Fuzheng Zhang,Kun Gai,Guorui Zhou*

Main category: cs.LG

TL;DR: 提出了一种名为CE-GPPO的新算法，通过保留被裁剪 tokens 的梯度来控制策略熵，从而在探索和利用之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法（如PPO）由于裁剪机制，丢弃了低概率 tokens 的有价值梯度信号，忽略了它们在调节熵演化中的关键作用。

Method: 提出 CE-GPPO 算法，以温和且有界的方式在原生 PPO 中重新引入被裁剪 tokens 的梯度。通过控制来自裁剪区间之外的 tokens 的梯度大小，实现探索-利用的权衡。

Result: 在数学推理基准测试中，CE-GPPO 在不同模型规模上始终优于强大的基线模型，证明了其有效性。

Conclusion: CE-GPPO 能够有效缓解熵不稳定问题，并通过理论和实验证据支持了这一结论。

Abstract: Reinforcement learning (RL) has become a powerful paradigm for optimizing
large language models (LLMs) to handle complex reasoning tasks. A core
challenge in this process lies in managing policy entropy, which reflects the
balance between exploration and exploitation during training. Existing methods,
such as proximal policy optimization (PPO) and its variants, discard valuable
gradient signals from low-probability tokens due to the clipping mechanism. We
systematically analyze the entropy dynamics and reveal that these clipped
tokens play a critical yet overlooked role in regulating entropy evolution. We
propose \textbf{C}ontrolling \textbf{E}ntropy via
\textbf{G}radient-\textbf{P}reserving \textbf{P}olicy \textbf{O}ptimization
(CE-GPPO), a novel algorithm that reintroduces gradients from clipped tokens in
native PPO in a gentle and bounded manner. By controlling the magnitude of
gradients from tokens outside the clipping interval, CE-GPPO is able to achieve
an exploration-exploitation trade-off. We provide theoretical justification and
empirical evidence showing that CE-GPPO effectively mitigates entropy
instability. Extensive experiments on mathematical reasoning benchmarks show
that CE-GPPO consistently outperforms strong baselines across different model
scales.

</details>


### [185] [A Genetic Algorithm for Navigating Synthesizable Molecular Spaces](https://arxiv.org/abs/2509.20719)
*Alston Lo,Connor W. Coley,Wojciech Matusik*

Main category: cs.LG

TL;DR: SynGA: 一种直接在合成路线上运行的简单遗传算法，具有定制的交叉和变异算子，可显式约束其进入可合成分子空间。


<details>
  <summary>Details</summary>
Motivation: 受遗传算法的有效性和分子设计中可合成性的重要性启发。

Method: SynGA 具有定制的交叉和变异算子，并通过修改适应度函数，在各种设计任务（包括可合成类似物搜索和样本高效的属性优化）中展示了其有效性，适用于 2D 和 3D 目标。

Result: 通过将 SynGA 与基于机器学习的过滤器耦合，从而专注于构建块集，我们将 SynGA 提升到最先进的性能。对于属性优化，这表现为一种基于模型的变体 SynGBO，它在贝叶斯优化的内循环中采用 SynGA 和块过滤。

Conclusion: SynGA 是一种轻量级算法，并通过构造来强制实现可合成性，因此我们希望 SynGA 不仅可以作为强大的独立基线，还可以作为一个多功能模块，可以集成到未来更大的合成感知工作流程中。

Abstract: Inspired by the effectiveness of genetic algorithms and the importance of
synthesizability in molecular design, we present SynGA, a simple genetic
algorithm that operates directly over synthesis routes. Our method features
custom crossover and mutation operators that explicitly constrain it to
synthesizable molecular space. By modifying the fitness function, we
demonstrate the effectiveness of SynGA on a variety of design tasks, including
synthesizable analog search and sample-efficient property optimization, for
both 2D and 3D objectives. Furthermore, by coupling SynGA with a machine
learning-based filter that focuses the building block set, we boost SynGA to
state-of-the-art performance. For property optimization, this manifests as a
model-based variant SynGBO, which employs SynGA and block filtering in the
inner loop of Bayesian optimization. Since SynGA is lightweight and enforces
synthesizability by construction, our hope is that SynGA can not only serve as
a strong standalone baseline but also as a versatile module that can be
incorporated into larger synthesis-aware workflows in the future.

</details>


### [186] [Scaling Laws are Redundancy Laws](https://arxiv.org/abs/2509.20721)
*Yuda Bi,Vince D Calhoun*

Main category: cs.LG

TL;DR: 本文从冗余定律的角度解释了深度学习中的缩放定律，揭示了数据冗余度对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨深度学习中缩放定律的数学起源，特别是缩放指数。

Method: 使用核回归，分析数据协方差谱中的多项式尾部。

Result: 证明了超额风险服从幂律，其指数 alpha = 2s / (2s + 1/beta)，其中 beta 控制谱尾，1/beta 衡量冗余度。学习曲线的斜率不是普遍的，而是取决于数据冗余度，更陡峭的频谱会加速规模回报。

Conclusion: 本文首次对缩放定律作为有限样本冗余定律给出了严格的数学解释，将经验观察与理论基础统一起来。

Abstract: Scaling laws, a defining feature of deep learning, reveal a striking
power-law improvement in model performance with increasing dataset and model
size. Yet, their mathematical origins, especially the scaling exponent, have
remained elusive. In this work, we show that scaling laws can be formally
explained as redundancy laws. Using kernel regression, we show that a
polynomial tail in the data covariance spectrum yields an excess risk power law
with exponent alpha = 2s / (2s + 1/beta), where beta controls the spectral tail
and 1/beta measures redundancy. This reveals that the learning curve's slope is
not universal but depends on data redundancy, with steeper spectra accelerating
returns to scale. We establish the law's universality across boundedly
invertible transformations, multi-modal mixtures, finite-width approximations,
and Transformer architectures in both linearized (NTK) and feature-learning
regimes. This work delivers the first rigorous mathematical explanation of
scaling laws as finite-sample redundancy laws, unifying empirical observations
with theoretical foundations.

</details>


### [187] [The Impact of Audio Watermarking on Audio Anti-Spoofing Countermeasures](https://arxiv.org/abs/2509.20736)
*Zhenshan Zhang,Xueping Zhang,Yechen Wang,Liwei Jin,Ming Li*

Main category: cs.LG

TL;DR: 本文研究了音频水印对语音欺骗对抗措施的影响，发现水印会降低反欺骗性能，并提出了 Knowledge-Preserving Watermark Learning (KPWL) 框架来缓解这个问题。


<details>
  <summary>Details</summary>
Motivation: 研究广泛使用的音频水印（最初设计用于版权保护）对反欺骗系统的影响，因为这种影响在很大程度上尚未被探索。

Method: 通过将各种手工和神经水印方法应用于现有的反欺骗数据集，构建了名为 Watermark-Spoofing 的水印增强训练和评估数据集。提出了 Knowledge-Preserving Watermark Learning (KPWL) 框架。

Result: 实验表明，水印会持续降低反欺骗性能，水印密度越高，等错误率 (EER) 越高。

Conclusion: 音频水印是一个以前被忽视的域转移，并建立了开发水印弹性反欺骗系统的第一个基准。

Abstract: This paper presents the first study on the impact of audio watermarking on
spoofing countermeasures. While anti-spoofing systems are essential for
securing speech-based applications, the influence of widely used audio
watermarking, originally designed for copyright protection, remains largely
unexplored. We construct watermark-augmented training and evaluation datasets,
named the Watermark-Spoofing dataset, by applying diverse handcrafted and
neural watermarking methods to existing anti-spoofing datasets. Experiments
show that watermarking consistently degrades anti-spoofing performance, with
higher watermark density correlating with higher Equal Error Rates (EERs). To
mitigate this, we propose the Knowledge-Preserving Watermark Learning (KPWL)
framework, enabling models to adapt to watermark-induced shifts while
preserving their original-domain spoofing detection capability. These findings
reveal audio watermarking as a previously overlooked domain shift and establish
the first benchmark for developing watermark-resilient anti-spoofing systems.
All related protocols are publicly available at
https://github.com/Alphawarheads/Watermark_Spoofing.git

</details>


### [188] [Measuring LLM Sensitivity in Transformer-based Tabular Data Synthesis](https://arxiv.org/abs/2509.20768)
*Maria F. Davila R,Azizjon Turaev,Wolfram Wingerath*

Main category: cs.LG

TL;DR: 本研究评估了Transformer模型（GReaT和REaLTabFormer）的超参数选择如何影响合成表格数据的质量和计算性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在表格数据合成方面表现出色，但计算成本高昂，限制了其应用。

Method: 通过在不同架构和深度的10种模型设置下，评估超参数对运行时间、机器学习效用和与真实数据分布相似性的影响，进行了敏感性评估。

Result: 运行时间与超参数数量成正比；对于小数据集，两种工具都能实现高实用性和最佳相似性的合成数据，但对于较大的数据集，只有REaLTabFormer能保持较强的实用性和相似性。轻量级LLM的REaLTabFormer提供了最佳平衡。

Conclusion: REaLTabFormer在保持数据质量的同时降低了计算需求，但其运行时间仍然高于GReaT，表明效率提升是可能的，但存在上限。

Abstract: Synthetic tabular data is used for privacy-preserving data sharing and
data-driven model development. Its effectiveness, however, depends heavily on
the used Tabular Data Synthesis (TDS) tool. Recent studies have shown that
Transformer-based models outperform other state-of-the-art models such as
Generative Adversarial Networks (GANs) and Diffusion models in terms of data
quality. However, Transformer-based models also come with high computational
costs, making them sometimes unfeasible for end users with prosumer hardware.
This study presents a sensitivity assessment on how the choice of
hyperparameters, such as number of layers or hidden dimension affects the
quality of the resultant synthetic data and the computational performance. It
is performed across two tools, GReaT and REaLTabFormer, evaluating 10 model
setups that vary in architecture type and depth. We assess the sensitivity on
three dimensions: runtime, machine learning (ML) utility, and similarity to
real data distributions. Experiments were conducted on four real-world
datasets. Our findings reveal that runtime is proportional to the number of
hyperparameters, with shallower configurations completing faster. GReaT
consistently achieves lower runtimes than REaLTabFormer, and only on the
largest dataset they have comparable runtime. For small datasets, both tools
achieve synthetic data with high utility and optimal similarity, but on larger
datasets only REaLTabFormer sustains strong utility and similarity. As a
result, REaLTabFormer with lightweight LLMs provides the best balance, since it
preserves data quality while reducing computational requirements. Nonetheless,
its runtime remains higher than that of GReaT and other TDS tools, suggesting
that efficiency gains are possible but only up to a certain level.

</details>


### [189] [IConv: Focusing on Local Variation with Channel Independent Convolution for Multivariate Time Series Forecasting](https://arxiv.org/abs/2509.20783)
*Gawon Lee,Hanbyeol Park,Minseop Kim,Dohee Kim,Hyerim Bae*

Main category: cs.LG

TL;DR: 提出了一种结合MLP和CNN的新型时间序列预测模型，以解决MLP在处理非平稳时间序列数据时忽略局部变化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于MLP的模型在捕捉长期依赖性方面表现出色，但由于其线性性质，忽略了时间序列数据中的季节性模式和残差成分等局部变化。

Method: 结合MLP和CNN，其中MLP用于捕捉长期趋势，CNN用于建模细粒度的局部模式。同时，提出了一个新的卷积结构IConv，它独立处理时间依赖通道，并通过不同的层考虑通道间的关系。

Result: 在时间序列数据集上进行了大量实验，结果表明该方法在多元时间序列预测方面具有优越性。

Conclusion: 该模型通过结合MLP和CNN的优势，有效地提高了时间序列预测的准确性。

Abstract: Real-world time-series data often exhibit non-stationarity, including
changing trends, irregular seasonality, and residuals. In terms of changing
trends, recently proposed multi-layer perceptron (MLP)-based models have shown
excellent performance owing to their computational efficiency and ability to
capture long-term dependency. However, the linear nature of MLP architectures
poses limitations when applied to channels with diverse distributions,
resulting in local variations such as seasonal patterns and residual components
being ignored. However, convolutional neural networks (CNNs) can effectively
incorporate these variations. To resolve the limitations of MLP, we propose
combining them with CNNs. The overall trend is modeled using an MLP to consider
long-term dependencies. The CNN uses diverse kernels to model fine-grained
local patterns in conjunction with MLP trend predictions. To focus on modeling
local variation, we propose IConv, a novel convolutional architecture that
processes the temporal dependency channel independently and considers the
inter-channel relationship through distinct layers. Independent channel
processing enables the modeling of diverse local temporal dependencies and the
adoption of a large kernel size. Distinct inter-channel considerations reduce
computational cost. The proposed model is evaluated through extensive
experiments on time-series datasets. The results reveal the superiority of the
proposed method for multivariate time-series forecasting.

</details>


### [190] [LiLAW: Lightweight Learnable Adaptive Weighting to Meta-Learn Sample Difficulty and Improve Noisy Training](https://arxiv.org/abs/2509.20786)
*Abhishek Moturu,Anna Goldenberg,Babak Taati*

Main category: cs.LG

TL;DR: LiLAW: dynamically adjusts loss weight of each training sample based on its evolving difficulty level.


<details>
  <summary>Details</summary>
Motivation: Training deep neural networks in the presence of noisy labels and data heterogeneity is a major challenge.

Method: Updates weights using a single mini-batch gradient descent step on the validation set after each training mini-batch, without requiring excessive hyperparameter tuning or a clean validation set. Uses only three learnable parameters.

Result: LiLAW consistently enhances performance, even in high-noise environments. It is effective without heavy reliance on data augmentation or advanced regularization

Conclusion: Offers a computationally efficient solution to boost model generalization and robustness in any neural network training setup.

Abstract: Training deep neural networks in the presence of noisy labels and data
heterogeneity is a major challenge. We introduce Lightweight Learnable Adaptive
Weighting (LiLAW), a novel method that dynamically adjusts the loss weight of
each training sample based on its evolving difficulty level, categorized as
easy, moderate, or hard. Using only three learnable parameters, LiLAW
adaptively prioritizes informative samples throughout training by updating
these weights using a single mini-batch gradient descent step on the validation
set after each training mini-batch, without requiring excessive hyperparameter
tuning or a clean validation set. Extensive experiments across multiple general
and medical imaging datasets, noise levels and types, loss functions, and
architectures with and without pretraining demonstrate that LiLAW consistently
enhances performance, even in high-noise environments. It is effective without
heavy reliance on data augmentation or advanced regularization, highlighting
its practicality. It offers a computationally efficient solution to boost model
generalization and robustness in any neural network training setup.

</details>


### [191] [Aligning Inductive Bias for Data-Efficient Generalization in State Space Models](https://arxiv.org/abs/2509.20789)
*Qiyu Chen,Guozhang Chen*

Main category: cs.LG

TL;DR: 大型模型的成功与缩放定律密切相关，但高质量数据的有限性是一个挑战。本文旨在提高数据效率，即从更少的数据中学习更多。为此，提出了一种名为任务相关初始化（TDI）的方法，通过功率谱匹配将模型的归纳偏置与任务的频谱特征对齐，从而提高泛化能力和样本效率，尤其是在低数据情况下。


<details>
  <summary>Details</summary>
Motivation: 大型模型依赖于缩放定律，但高质量数据的有限性带来挑战。序列模型等基础模型的归纳偏置是固定的，当任务的底层结构不匹配时，样本效率会降低。因此，需要一种能够更好利用数据的模型。

Method: 首先，通过SSM诱导核的形式化了线性时不变SSM的归纳偏置，并在数学和经验上证明了其频谱直接受模型的频率响应控制。然后，提出了一种任务相关初始化（TDI）方法，即功率谱匹配，这是一种快速有效的方法，可以在大规模训练之前将模型的归纳偏置与任务的频谱特征对齐。

Result: 在各种真实基准测试上的实验表明，TDI显著提高了泛化能力和样本效率，尤其是在低数据情况下。

Conclusion: 这项工作提供了一种理论和实践工具，以创建更具数据效率的模型，这是实现可持续扩展的关键一步。

Abstract: The remarkable success of large-scale models is fundamentally tied to scaling
laws, yet the finite nature of high-quality data presents a looming challenge.
One of the next frontiers in modeling is data efficiency: the ability to learn
more from less. A model's inductive bias is a critical lever for this, but
foundational sequence models like State Space Models (SSMs) rely on a fixed
bias. This fixed prior is sample-inefficient when a task's underlying structure
does not match. In this work, we introduce a principled framework to solve this
problem. We first formalize the inductive bias of linear time-invariant SSMs
through an SSM-induced kernel, mathematically and empirically proving its
spectrum is directly governed by the model's frequency response. Further, we
propose a method of Task-Dependent Initialization (TDI): power spectrum
matching, a fast and efficient method that aligns the model's inductive bias
with the task's spectral characteristics before large-scale training. Our
experiments on a diverse set of real-world benchmarks show that TDI
significantly improves generalization and sample efficiency, particularly in
low-data regimes. This work provides a theoretical and practical tool to create
more data-efficient models, a crucial step towards sustainable scaling.

</details>


### [192] [FERD: Fairness-Enhanced Data-Free Robustness Distillation](https://arxiv.org/abs/2509.20793)
*Zhengxiao Li,Liming Lu,Xu Zheng,Siyuan Liang,Zhenghan Chen,Yongbin Zhou,Shuchao Pang*

Main category: cs.LG

TL;DR: 提出了一种名为FERD的框架，用于在无数据的情况下，提升模型的鲁棒性和公平性。


<details>
  <summary>Details</summary>
Motivation: 现有无数据鲁棒性蒸馏方法忽略了鲁棒公平性问题，导致不同类别间的鲁棒性差异大。

Method: FERD框架通过调整对抗样本的比例和分布来解决该问题。它采用鲁棒性引导的类别重加权策略，并生成具有统一目标对抗样本的公平感知样本。

Result: 在三个公共数据集上的大量实验表明，FERD在所有对抗攻击下都实现了最先进的最差类别鲁棒性。

Conclusion: FERD在鲁棒性和公平性方面均表现出优越的性能。

Abstract: Data-Free Robustness Distillation (DFRD) aims to transfer the robustness from
the teacher to the student without accessing the training data. While existing
methods focus on overall robustness, they overlook the robust fairness issues,
leading to severe disparity of robustness across different categories. In this
paper, we find two key problems: (1) student model distilled with equal class
proportion data behaves significantly different across distinct categories; and
(2) the robustness of student model is not stable across different attacks
target. To bridge these gaps, we present the first Fairness-Enhanced data-free
Robustness Distillation (FERD) framework to adjust the proportion and
distribution of adversarial examples. For the proportion, FERD adopts a
robustness-guided class reweighting strategy to synthesize more samples for the
less robust categories, thereby improving robustness of them. For the
distribution, FERD generates complementary data samples for advanced robustness
distillation. It generates Fairness-Aware Examples (FAEs) by enforcing a
uniformity constraint on feature-level predictions, which suppress the
dominance of class-specific non-robust features, providing a more balanced
representation across all categories. Then, FERD constructs Uniform-Target
Adversarial Examples (UTAEs) from FAEs by applying a uniform target class
constraint to avoid biased attack directions, which distribute the attack
targets across all categories and prevents overfitting to specific vulnerable
categories. Extensive experiments on three public datasets show that FERD
achieves state-of-the-art worst-class robustness under all adversarial attack
(e.g., the worst-class robustness under FGSM and AutoAttack are improved by
15.1\% and 6.4\% using MobileNet-V2 on CIFAR-10), demonstrating superior
performance in both robustness and fairness aspects.

</details>


### [193] [T2I-Diff: fMRI Signal Generation via Time-Frequency Image Transform and Classifier-Free Denoising Diffusion Models](https://arxiv.org/abs/2509.20822)
*Hwa Hui Tew,Junn Yong Loo,Yee-Fan Tan,Xinyu Tang,Hernando Ombao,Fuad Noman,Raphael C. -W. Phan,Chee-Ming Ting*

Main category: cs.LG

TL;DR: 提出了一种名为T2I-Diff的fMRI生成框架，该框架利用BOLD信号的时频表示和无分类器去噪扩散来解决fMRI数据生成中的非平稳性和非线性问题。


<details>
  <summary>Details</summary>
Motivation: fMRI数据采集资源密集，限制了数据驱动的脑分析模型所需的高保真样本的可用性。现有的生成模型忽略了复杂的非平稳性和非线性BOLD动态。

Method: 该框架首先通过时变傅里叶变换将BOLD信号转换为加窗频谱图，然后训练一个无分类器扩散模型来生成类别条件频率频谱图，最后通过逆傅里叶变换将频谱图转换回BOLD信号。

Result: 通过在下游基于fMRI的脑网络分类中展示的改进的准确性和泛化性来验证了该方法的有效性。

Conclusion: T2I-Diff框架能够有效生成高质量的fMRI数据，并在下游任务中表现出良好的性能。

Abstract: Functional Magnetic Resonance Imaging (fMRI) is an advanced neuroimaging
method that enables in-depth analysis of brain activity by measuring dynamic
changes in the blood oxygenation level-dependent (BOLD) signals. However, the
resource-intensive nature of fMRI data acquisition limits the availability of
high-fidelity samples required for data-driven brain analysis models. While
modern generative models can synthesize fMRI data, they often underperform
because they overlook the complex non-stationarity and nonlinear BOLD dynamics.
To address these challenges, we introduce T2I-Diff, an fMRI generation
framework that leverages time-frequency representation of BOLD signals and
classifier-free denoising diffusion. Specifically, our framework first converts
BOLD signals into windowed spectrograms via a time-dependent Fourier transform,
capturing both the underlying temporal dynamics and spectral evolution.
Subsequently, a classifier-free diffusion model is trained to generate
class-conditioned frequency spectrograms, which are then reverted to BOLD
signals via inverse Fourier transforms. Finally, we validate the efficacy of
our approach by demonstrating improved accuracy and generalization in
downstream fMRI-based brain network classification.

</details>


### [194] [CaTS-Bench: Can Language Models Describe Numeric Time Series?](https://arxiv.org/abs/2509.20823)
*Luca Zhou,Pratham Yashwante,Marshall Fisher,Alessio Sampieri,Zihao Zhou,Fabio Galasso,Rose Yu*

Main category: cs.LG

TL;DR: 介绍了CaTS-Bench，一个大规模、真实的上下文感知时间序列字幕基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基准通常依赖于合成数据或过于简单的字幕，并且通常忽略元数据和视觉表示。

Method: 从11个不同的数据集中派生，重构为字幕和问答任务，包括大约465k个训练和105k个测试时间戳。使用可扩展的pipeline生成参考字幕：大多数参考由oracle LLM生成，并通过事实检查、人类无法区分的研究和多样性分析进行验证，还提供了579个测试字幕的人工修改子集，从LLM输出中提炼出来，以确保准确性和类似人类的风格。

Result: CaTS-Bench提供了460个多项选择题，针对时间序列推理的更深层方面。提出了新的定制评估指标和基准测试领先的VLMs，突出了它们的优势和持续存在的局限性。

Conclusion: CaTS-Bench及其字幕pipeline为未来时间序列分析和基础模型交叉领域的研究奠定了可靠且可扩展的基础。

Abstract: Time series captioning, the task of describing numeric time series in natural
language, requires numerical reasoning, trend interpretation, and contextual
understanding. Existing benchmarks, however, often rely on synthetic data or
overly simplistic captions, and typically neglect metadata and visual
representations. To close this gap, we introduce CaTS-Bench, the first
large-scale, real-world benchmark for Context-aware Time Series captioning.
CaTS-Bench is derived from 11 diverse datasets reframed as captioning and Q&A
tasks, comprising roughly 465k training and 105k test timestamps. Each sample
includes a numeric series segment, contextual metadata, a line-chart image, and
a caption. A key contribution of this work is the scalable pipeline used to
generate reference captions: while most references are produced by an oracle
LLM and verified through factual checks, human indistinguishability studies,
and diversity analyses, we also provide a human-revisited subset of 579 test
captions, refined from LLM outputs to ensure accuracy and human-like style.
Beyond captioning, CaTS-Bench offers 460 multiple-choice questions targeting
deeper aspects of time series reasoning. We further propose new tailored
evaluation metrics and benchmark leading VLMs, highlighting both their
strengths and persistent limitations. Together, these contributions establish
CaTS-Bench and its captioning pipeline as a reliable and extensible foundation
for future research at the intersection of time series analysis and foundation
models.

</details>


### [195] [Explaining Grokking and Information Bottleneck through Neural Collapse Emergence](https://arxiv.org/abs/2509.20829)
*Keitaro Sakamoto,Issei Sato*

Main category: cs.LG

TL;DR: 本文通过神经崩溃的视角，统一解释了深度神经网络中诸如grokking和信息瓶颈等后期现象。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络的训练动态常常出乎意料，对于这些现象背后的机制及其关系仍然知之甚少。

Method: 通过神经崩溃来表征学习表征的几何结构，并分析神经崩溃的动态。

Result: 群体内方差的收缩是grokking和信息瓶颈的关键因素，训练集的拟合和神经崩溃的进展之间存在不同的时间尺度。

Conclusion: 在多个数据集和架构上验证了理论结果。

Abstract: The training dynamics of deep neural networks often defy expectations, even
as these models form the foundation of modern machine learning. Two prominent
examples are grokking, where test performance improves abruptly long after the
training loss has plateaued, and the information bottleneck principle, where
models progressively discard input information irrelevant to the prediction
task as training proceeds. However, the mechanisms underlying these phenomena
and their relations remain poorly understood. In this work, we present a
unified explanation of such late-phase phenomena through the lens of neural
collapse, which characterizes the geometry of learned representations. We show
that the contraction of population within-class variance is a key factor
underlying both grokking and information bottleneck, and relate this measure to
the neural collapse measure defined on the training set. By analyzing the
dynamics of neural collapse, we show that distinct time scales between fitting
the training set and the progression of neural collapse account for the
behavior of the late-phase phenomena. Finally, we validate our theoretical
findings on multiple datasets and architectures.

</details>


### [196] [Shaping Initial State Prevents Modality Competition in Multi-modal Fusion: A Two-stage Scheduling Framework via Fast Partial Information Decomposition](https://arxiv.org/abs/2509.20840)
*Jiaqi Tang,Yinsong Xu,Yang Liu,Qingchao Chen*

Main category: cs.LG

TL;DR: 提出了一种两阶段训练框架，通过单模态训练来塑造初始状态，以解决多模态融合中的模态竞争问题。


<details>
  <summary>Details</summary>
Motivation: 多模态融合在联合训练中容易出现模态竞争，忽略了模型初始状态的关键影响。

Method: 1. 提出有效竞争强度（ECS）的概念来量化模态的竞争强度。2. 开发了一个框架，包括细粒度的可计算诊断指标和异步训练控制器。3. 证明互信息（MI）是ECS的代理，并提出FastPID，用于分解联合分布的信息为独特性、冗余性和协同性。

Result: 在多个基准测试中，该方法达到了最先进的性能。

Conclusion: 塑造预融合模型的初始状态是一种有效的策略，可以缓解模态竞争，可靠地解锁协同多模态融合。

Abstract: Multi-modal fusion often suffers from modality competition during joint
training, where one modality dominates the learning process, leaving others
under-optimized. Overlooking the critical impact of the model's initial state,
most existing methods address this issue during the joint learning stage. In
this study, we introduce a two-stage training framework to shape the initial
states through unimodal training before the joint training. First, we propose
the concept of Effective Competitive Strength (ECS) to quantify a modality's
competitive strength. Our theoretical analysis further reveals that properly
shaping the initial ECS by unimodal training achieves a provably tighter error
bound. However, ECS is computationally intractable in deep neural networks. To
bridge this gap, we develop a framework comprising two core components: a
fine-grained computable diagnostic metric and an asynchronous training
controller. For the metric, we first prove that mutual information(MI) is a
principled proxy for ECS. Considering MI is induced by per-modality marginals
and thus treats each modality in isolation, we further propose FastPID, a
computationally efficient and differentiable solver for partial information
decomposition, which decomposes the joint distribution's information into
fine-grained measurements: modality-specific uniqueness, redundancy, and
synergy. Guided by these measurements, our asynchronous controller dynamically
balances modalities by monitoring uniqueness and locates the ideal initial
state to start joint training by tracking peak synergy. Experiments on diverse
benchmarks demonstrate that our method achieves state-of-the-art performance.
Our work establishes that shaping the pre-fusion models' initial state is a
powerful strategy that eases competition before it starts, reliably unlocking
synergistic multi-modal fusion.

</details>


### [197] [Robust Multi-Omics Integration from Incomplete Modalities Significantly Improves Prediction of Alzheimer's Disease](https://arxiv.org/abs/2509.20842)
*Sungjoon Park,Kyungwook Lee,Soorin Yim,Doyeong Hwang,Dongyun Kim,Soonyoung Lee,Amy Dunn,Daniel Gatti,Elissa Chesler,Kristen O'Connell,Kiyoung Kim*

Main category: cs.LG

TL;DR: MOIRA是一种多组学整合方法，即使在数据不完整的情况下也能稳健学习。


<details>
  <summary>Details</summary>
Motivation: 多组学数据可以捕捉复杂的生物分子相互作用，但缺失的模态阻碍了整合分析。

Method: MOIRA通过表征对齐和自适应聚合，将每个组学数据集投影到一个共享嵌入空间，并通过可学习的加权机制融合它们。

Result: 在阿尔茨海默病（AD）的ROSMAP数据集上，MOIRA优于现有方法。

Conclusion: MOIRA能够识别与AD相关的生物标志物，具有生物学意义。

Abstract: Multi-omics data capture complex biomolecular interactions and provide
insights into metabolism and disease. However, missing modalities hinder
integrative analysis across heterogeneous omics. To address this, we present
MOIRA (Multi-Omics Integration with Robustness to Absent modalities), an early
integration method enabling robust learning from incomplete omics data via
representation alignment and adaptive aggregation. MOIRA leverages all samples,
including those with missing modalities, by projecting each omics dataset onto
a shared embedding space where a learnable weighting mechanism fuses them.
Evaluated on the Religious Order Study and Memory and Aging Project (ROSMAP)
dataset for Alzheimer's Disease (AD), MOIRA outperformed existing approaches,
and further ablation studies confirmed modality-wise contributions. Feature
importance analysis revealed AD-related biomarkers consistent with prior
literature, highlighting the biological relevance of our approach.

</details>


### [198] [Causal Time Series Generation via Diffusion Models](https://arxiv.org/abs/2509.20846)
*Yutong Xia,Chang Xu,Yuxuan Liang,Qingsong Wen,Roger Zimmermann,Jiang Bian*

Main category: cs.LG

TL;DR: 提出因果时间序列生成（causal TSG）的新任务族，并使用 CaTSG 扩散框架来支持干预和反事实生成。


<details>
  <summary>Details</summary>
Motivation: 现有的条件时间序列生成模型学习观察相关性，但没有考虑未观察到的混淆因素。

Method: 开发了一个统一的基于扩散的框架 CaTSG，该框架具有后门调整的指导，可以因果地引导采样到所需的干预和个体反事实，同时保持观察保真度。通过后门调整和 abduction-action-prediction 程序导出因果分数函数，从而为 TSG 的所有三个级别提供原则性支持。

Result: 在合成和真实世界数据集上的大量实验表明，CaTSG 实现了卓越的保真度，并且支持现有基线无法处理的干预和反事实生成。

Conclusion: 提出了因果 TSG 族，并用 CaTSG 实例化，提供了一个初步的概念验证，并为在干预和反事实生成下实现更可靠的模拟开辟了一个有希望的方向。

Abstract: Time series generation (TSG) synthesizes realistic sequences and has achieved
remarkable success. Among TSG, conditional models generate sequences given
observed covariates, however, such models learn observational correlations
without considering unobserved confounding. In this work, we propose a causal
perspective on conditional TSG and introduce causal time series generation as a
new TSG task family, formalized within Pearl's causal ladder, extending beyond
observational generation to include interventional and counterfactual settings.
To instantiate these tasks, we develop CaTSG, a unified diffusion-based
framework with backdoor-adjusted guidance that causally steers sampling toward
desired interventions and individual counterfactuals while preserving
observational fidelity. Specifically, our method derives causal score functions
via backdoor adjustment and the abduction-action-prediction procedure, thus
enabling principled support for all three levels of TSG. Extensive experiments
on both synthetic and real-world datasets show that CaTSG achieves superior
fidelity and also supporting interventional and counterfactual generation that
existing baselines cannot handle. Overall, we propose the causal TSG family and
instantiate it with CaTSG, providing an initial proof-of-concept and opening a
promising direction toward more reliable simulation under interventions and
counterfactual generation.

</details>


### [199] [FHRFormer: A Self-supervised Transformer Approach for Fetal Heart Rate Inpainting and Forecasting](https://arxiv.org/abs/2509.20852)
*Kjersti Engan,Neel Kanwal,Anita Yeconia,Ladislaus Blacy,Yuda Munyaw,Estomih Mduma,Hege Ersdal*

Main category: cs.LG

TL;DR: 本文提出了一种基于掩码transformer的自编码器方法，用于重建缺失的胎儿心率(FHR)信号。


<details>
  <summary>Details</summary>
Motivation: 大约10%的新生儿在出生时需要辅助呼吸，5%需要呼吸机支持。胎儿心率监测在评估胎儿健康方面起着关键作用。由于可穿戴FHR监护仪的进步，实现了连续胎儿监护，但母亲运动过程中的传感器移位以及胎儿或母亲体位的变化经常导致信号丢失，从而导致记录的FHR数据中存在间隙。这种缺失的数据限制了有意义的见解的提取，并使自动化分析复杂化。

Method: 我们提出了一种基于掩码transformer的自编码器方法，通过捕获数据的空间和频率分量来重建缺失的FHR信号。

Result: 所提出的方法在不同持续时间的缺失数据中表现出鲁棒性，可用于信号修复和预测。

Conclusion: 所提出的方法可以追溯应用于研究数据集，以支持基于AI的风险算法的开发。将来，所提出的方法可以集成到可穿戴FHR监护设备中，以实现更早，更可靠的风险检测。

Abstract: Approximately 10\% of newborns require assistance to initiate breathing at
birth, and around 5\% need ventilation support. Fetal heart rate (FHR)
monitoring plays a crucial role in assessing fetal well-being during prenatal
care, enabling the detection of abnormal patterns and supporting timely
obstetric interventions to mitigate fetal risks during labor. Applying
artificial intelligence (AI) methods to analyze large datasets of continuous
FHR monitoring episodes with diverse outcomes may offer novel insights into
predicting the risk of needing breathing assistance or interventions. Recent
advances in wearable FHR monitors have enabled continuous fetal monitoring
without compromising maternal mobility. However, sensor displacement during
maternal movement, as well as changes in fetal or maternal position, often lead
to signal dropouts, resulting in gaps in the recorded FHR data. Such missing
data limits the extraction of meaningful insights and complicates automated
(AI-based) analysis. Traditional approaches to handle missing data, such as
simple interpolation techniques, often fail to preserve the spectral
characteristics of the signals. In this paper, we propose a masked
transformer-based autoencoder approach to reconstruct missing FHR signals by
capturing both spatial and frequency components of the data. The proposed
method demonstrates robustness across varying durations of missing data and can
be used for signal inpainting and forecasting. The proposed approach can be
applied retrospectively to research datasets to support the development of
AI-based risk algorithms. In the future, the proposed method could be
integrated into wearable FHR monitoring devices to achieve earlier and more
robust risk detection.

</details>
