{"id": "2511.07436", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07436", "abs": "https://arxiv.org/abs/2511.07436", "authors": ["Liam Kearns"], "title": "Analysing Environmental Efficiency in AI for X-Ray Diagnosis", "comment": "17 pages, 8 figures", "summary": "The integration of AI tools into medical applications has aimed to improve the efficiency of diagnosis. The emergence of large language models (LLMs), such as ChatGPT and Claude, has expanded this integration even further. Because of LLM versatility and ease of use through APIs, these larger models are often utilised even though smaller, custom models can be used instead. In this paper, LLMs and small discriminative models are integrated into a Mendix application to detect Covid-19 in chest X-rays. These discriminative models are also used to provide knowledge bases for LLMs to improve accuracy. This provides a benchmark study of 14 different model configurations for comparison of accuracy and environmental impact. The findings indicated that while smaller models reduced the carbon footprint of the application, the output was biased towards a positive diagnosis and the output probabilities were lacking confidence. Meanwhile, restricting LLMs to only give probabilistic output caused poor performance in both accuracy and carbon footprint, demonstrating the risk of using LLMs as a universal AI solution. While using the smaller LLM GPT-4.1-Nano reduced the carbon footprint by 94.2% compared to the larger models, this was still disproportionate to the discriminative models; the most efficient solution was the Covid-Net model. Although it had a larger carbon footprint than other small models, its carbon footprint was 99.9% less than when using GPT-4.5-Preview, whilst achieving an accuracy of 95.5%, the highest of all models examined. This paper contributes to knowledge by comparing generative and discriminative models in Covid-19 detection as well as highlighting the environmental risk of using generative tools for classification tasks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u5c0f\u578b\u5224\u522b\u6a21\u578b\u5728\u68c0\u6d4b Covid-19 \u80f8\u90e8 X \u5149\u7247\u4e2d\u7684\u5e94\u7528\uff0c\u5e76\u6bd4\u8f83\u4e86\u5b83\u4eec\u7684\u51c6\u786e\u6027\u548c\u73af\u5883\u5f71\u54cd\u3002", "motivation": "\u5728\u533b\u5b66\u5e94\u7528\u4e2d\u96c6\u6210\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u65e8\u5728\u63d0\u9ad8\u8bca\u65ad\u6548\u7387\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u51fa\u73b0\u8fdb\u4e00\u6b65\u6269\u5c55\u4e86\u8fd9\u79cd\u96c6\u6210\u3002\u7531\u4e8e LLM \u7684\u591a\u529f\u80fd\u6027\u548c\u901a\u8fc7 API \u6613\u4e8e\u4f7f\u7528\uff0c\u8fd9\u4e9b\u66f4\u5927\u7684\u6a21\u578b\u7ecf\u5e38\u88ab\u4f7f\u7528\uff0c\u5373\u4f7f\u53ef\u4ee5\u4f7f\u7528\u66f4\u5c0f\u7684\u5b9a\u5236\u6a21\u578b\u3002", "method": "\u5c06 LLM \u548c\u5c0f\u578b\u5224\u522b\u6a21\u578b\u96c6\u6210\u5230 Mendix \u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u4ee5\u68c0\u6d4b\u80f8\u90e8 X \u5149\u7247\u4e2d\u7684 Covid-19\u3002\u8fd9\u4e9b\u5224\u522b\u6a21\u578b\u8fd8\u7528\u4e8e\u4e3a LLM \u63d0\u4f9b\u77e5\u8bc6\u5e93\uff0c\u4ee5\u63d0\u9ad8\u51c6\u786e\u6027\u3002\u5bf9 14 \u79cd\u4e0d\u540c\u7684\u6a21\u578b\u914d\u7f6e\u8fdb\u884c\u57fa\u51c6\u7814\u7a76\uff0c\u4ee5\u6bd4\u8f83\u51c6\u786e\u6027\u548c\u73af\u5883\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136\u8f83\u5c0f\u7684\u6a21\u578b\u964d\u4f4e\u4e86\u5e94\u7528\u7a0b\u5e8f\u7684\u78b3\u8db3\u8ff9\uff0c\u4f46\u8f93\u51fa\u7ed3\u679c\u504f\u5411\u4e8e\u9633\u6027\u8bca\u65ad\uff0c\u5e76\u4e14\u8f93\u51fa\u6982\u7387\u7f3a\u4e4f\u4fe1\u5fc3\u3002\u540c\u65f6\uff0c\u9650\u5236 LLM \u4ec5\u63d0\u4f9b\u6982\u7387\u8f93\u51fa\u4f1a\u5bfc\u81f4\u51c6\u786e\u6027\u548c\u78b3\u8db3\u8ff9\u65b9\u9762\u7684\u6027\u80fd\u4e0d\u4f73\uff0c\u8fd9\u8868\u660e\u4e86\u4f7f\u7528 LLM \u4f5c\u4e3a\u901a\u7528 AI \u89e3\u51b3\u65b9\u6848\u7684\u98ce\u9669\u3002\u867d\u7136\u4f7f\u7528\u8f83\u5c0f\u7684 LLM GPT-4.1-Nano \u5c06\u78b3\u8db3\u8ff9\u6bd4\u66f4\u5927\u7684\u6a21\u578b\u51cf\u5c11\u4e86 94.2%\uff0c\u4f46\u8fd9\u4e0e\u5224\u522b\u6a21\u578b\u76f8\u6bd4\u4ecd\u7136\u4e0d\u6210\u6bd4\u4f8b\uff1b\u6700\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u662f Covid-Net \u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u6bd4\u8f83 Covid-19 \u68c0\u6d4b\u4e2d\u7684\u751f\u6210\u6a21\u578b\u548c\u5224\u522b\u6a21\u578b\uff0c\u4ee5\u53ca\u5f3a\u8c03\u4f7f\u7528\u751f\u6210\u5de5\u5177\u8fdb\u884c\u5206\u7c7b\u4efb\u52a1\u7684\u73af\u5883\u98ce\u9669\uff0c\u4e3a\u77e5\u8bc6\u505a\u51fa\u4e86\u8d21\u732e\u3002"}}
{"id": "2511.07437", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07437", "abs": "https://arxiv.org/abs/2511.07437", "authors": ["Ravi Gupta", "Guneet Bhatia"], "title": "Agentic Educational Content Generation for African Languages on Edge Devices", "comment": null, "summary": "Addressing educational inequity in Sub-Saharan Africa, this research presents an autonomous agent-orchestrated framework for decentralized, culturally adaptive educational content generation on edge devices. The system leverages four specialized agents that work together to generate contextually appropriate educational content. Experimental validation on platforms including Raspberry Pi 4B and NVIDIA Jetson Nano demonstrates significant performance achievements. InkubaLM on Jetson Nano achieved a Time-To-First-Token (TTFT) of 129 ms, an average inter-token latency of 33 ms, and a throughput of 45.2 tokens per second while consuming 8.4 W. On Raspberry Pi 4B, InkubaLM also led with 326 ms TTFT and 15.9 tokens per second at 5.8 W power consumption. The framework consistently delivered high multilingual quality, averaging a BLEU score of 0.688, cultural relevance of 4.4/5, and fluency of 4.2/5 across tested African languages. Through potential partnerships with active community organizations including African Youth & Community Organization (AYCO) and Florida Africa Foundation, this research aims to establish a practical foundation for accessible, localized, and sustainable AI-driven education in resource-constrained environments. Keeping focus on long-term viability and cultural appropriateness, it contributes to United Nations SDGs 4, 9, and 10. Index Terms - Multi-Agent Systems, Edge AI Computing, Educational Technology, African Languages, Rural Education, Sustainable Development, UN SDG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u4e3b\u4ee3\u7406\u7f16\u6392\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u751f\u6210\u53bb\u4e2d\u5fc3\u5316\u7684\u3001\u6587\u5316\u81ea\u9002\u5e94\u7684\u6559\u80b2\u5185\u5bb9\uff0c\u65e8\u5728\u89e3\u51b3\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u7684\u6559\u80b2\u4e0d\u516c\u5e73\u95ee\u9898\u3002", "motivation": "\u89e3\u51b3\u6492\u54c8\u62c9\u4ee5\u5357\u975e\u6d32\u7684\u6559\u80b2\u4e0d\u516c\u5e73\u95ee\u9898\uff0c\u4e3a\u8d44\u6e90\u6709\u9650\u7684\u73af\u5883\u63d0\u4f9b\u53ef\u8bbf\u95ee\u3001\u672c\u5730\u5316\u548c\u53ef\u6301\u7eed\u7684AI\u9a71\u52a8\u6559\u80b2\u3002", "method": "\u5229\u7528\u56db\u4e2a\u4e13\u95e8\u7684\u4ee3\u7406\u534f\u540c\u5de5\u4f5c\uff0c\u751f\u6210\u7b26\u5408\u4e0a\u4e0b\u6587\u7684\u6559\u80b2\u5185\u5bb9\uff0c\u5e76\u5728Raspberry Pi 4B\u548cNVIDIA Jetson Nano\u7b49\u5e73\u53f0\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5728Jetson Nano\u4e0a\uff0cInkubaLM\u5b9e\u73b0\u4e86129\u6beb\u79d2\u7684\u9996\u4e2a\u4ee4\u724c\u65f6\u95f4\uff08TTFT\uff09\u300133\u6beb\u79d2\u7684\u5e73\u5747\u4ee4\u724c\u95f4\u5ef6\u8fdf\u548c\u6bcf\u79d245.2\u4e2a\u4ee4\u724c\u7684\u541e\u5410\u91cf\uff0c\u529f\u8017\u4e3a8.4W\u3002\u5728Raspberry Pi 4B\u4e0a\uff0cInkubaLM\u4e5f\u8868\u73b0\u51fa\u8272\uff0cTTFT\u4e3a326\u6beb\u79d2\uff0c\u6bcf\u79d215.9\u4e2a\u4ee4\u724c\uff0c\u529f\u8017\u4e3a5.8W\u3002\u8be5\u6846\u67b6\u5728\u591a\u79cd\u975e\u6d32\u8bed\u8a00\u4e2d\u59cb\u7ec8\u4fdd\u6301\u9ad8\u8d28\u91cf\uff0c\u5e73\u5747BLEU\u5206\u6570\u4e3a0.688\uff0c\u6587\u5316\u76f8\u5173\u6027\u4e3a4.4/5\uff0c\u6d41\u7545\u6027\u4e3a4.2/5\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u4e0e\u975e\u6d32\u9752\u5e74\u548c\u793e\u533a\u7ec4\u7ec7\uff08AYCO\uff09\u548c\u4f5b\u7f57\u91cc\u8fbe\u975e\u6d32\u57fa\u91d1\u4f1a\u7b49\u793e\u533a\u7ec4\u7ec7\u5408\u4f5c\uff0c\u65e8\u5728\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u8bbf\u95ee\u3001\u672c\u5730\u5316\u548c\u53ef\u6301\u7eed\u7684AI\u9a71\u52a8\u6559\u80b2\u5960\u5b9a\u5b9e\u8df5\u57fa\u7840\uff0c\u5e76\u4e3a\u8054\u5408\u56fd\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u68074\u30019\u548c10\u505a\u51fa\u8d21\u732e\u3002"}}
{"id": "2511.07483", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07483", "abs": "https://arxiv.org/abs/2511.07483", "authors": ["Qianxi He", "Qingyu Ren", "Shanzhe Lei", "Xuhong Wang", "Yingchun Wang"], "title": "Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u6a21\u578b\uff0c\u4ee5\u589e\u5f3a STEM \u63a8\u7406\u80fd\u529b\uff0c\u901a\u8fc7\u60e9\u7f5a\u4e0d\u6b63\u786e\u7684\u7b54\u6848\u548c\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u6b63\u786e\u7b54\u6848\uff0c\u4ece\u800c\u4fc3\u8fdb\u66f4\u5f3a\u5927\u548c\u903b\u8f91\u4e0a\u4e00\u81f4\u7684\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u8303\u5f0f\uff0c\u5373\u57fa\u4e8e\u89c4\u5219\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u5e38\u4f1a\u5bfc\u81f4\u4f4e\u8d28\u91cf\u7684\u63a8\u7406\u94fe\u6216\u63a8\u7406\u8fc7\u7a0b\u4e0e\u6700\u7ec8\u7b54\u6848\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\uff0c\u5c24\u5176\u662f\u5728\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u8f83\u5c0f\u7684\u60c5\u51b5\u4e0b\u3002\u7531\u4e8e\u7f3a\u4e4f\u77e5\u8bc6\uff0c\u6a21\u578b\u53ef\u80fd\u4f1a\u91c7\u7528\u4f4e\u8d28\u91cf\u7684\u63a8\u7406\u94fe\uff0c\u5076\u5c14\u4f1a\u968f\u673a\u4ea7\u751f\u6b63\u786e\u7684\u7b54\u6848\uff0c\u5e76\u6839\u636e\u5df2\u5efa\u7acb\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u5224\u65ad\u83b7\u5f97\u5956\u52b1\u3002\u8fd9\u9650\u5236\u4e86\u8d44\u6e90\u6709\u9650\u7684\u7ec4\u7ec7\u5bf9\u8f83\u5c0f\u89c4\u6a21\u7684\u6a21\u578b\u8fdb\u884c\u76f4\u63a5\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u4e0d\u4ec5\u60e9\u7f5a\u4e0d\u6b63\u786e\u7684\u7b54\u6848\uff0c\u8fd8\u60e9\u7f5a\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u6b63\u786e\u54cd\u5e94\uff0c\u4ece\u800c\u4fc3\u8fdb\u66f4\u5f3a\u5927\u548c\u903b\u8f91\u4e0a\u4e00\u81f4\u7684\u63a8\u7406\u3002", "result": "\u901a\u8fc7\u9759\u6001\u8bc4\u4f30\u3001Best-of-N \u63a8\u7406\u6d4b\u8bd5\u548c\u57fa\u4e8e PPO \u7684 RL \u8bad\u7ec3\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u5404\u79cd STEM \u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u5f00\u6e90\u5956\u52b1\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5956\u52b1\u6a21\u578b\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728 STEM \u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.07568", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07568", "abs": "https://arxiv.org/abs/2511.07568", "authors": ["Vincent Hsiao", "Mark Roberts", "Leslie Smith"], "title": "Procedural Knowledge Improves Agentic LLM Workflows", "comment": null, "summary": "Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning efficiency, little work evaluates its potential for improving LLM performance on agentic tasks that may require implicit planning. We formalize, implement, and evaluate an agentic LLM workflow that leverages procedural knowledge in the form of a hierarchical task network (HTN). Empirical results of our implementation show that hand-coded HTNs can dramatically improve LLM performance on agentic tasks, and using HTNs can boost a 20b or 70b parameter LLM to outperform a much larger 120b parameter LLM baseline. Furthermore, LLM-created HTNs improve overall performance, though less so. The results suggest that leveraging expertise--from humans, documents, or LLMs--to curate procedural knowledge will become another important tool for improving LLM workflows.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff08\u4ee5\u5206\u5c42\u4efb\u52a1\u7f51\u7edcHTN\u7684\u5f62\u5f0f\uff09\u5982\u4f55\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9700\u8981\u9690\u5f0f\u89c4\u5212\u7684\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u624b\u5de5\u7f16\u7801\u7684HTN\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u7684\u6027\u80fd\uff0c\u5e76\u4e14LLM\u521b\u5efa\u7684HTN\u4e5f\u80fd\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6267\u884c\u4ee3\u7406\u4efb\u52a1\u65f6\uff0c\u5982\u679c\u6ca1\u6709\u5927\u91cf\u7684\u5de5\u5177\u652f\u6301\u3001\u63d0\u793a\u5de5\u7a0b\u6216\u5fae\u8c03\uff0c\u901a\u5e38\u4f1a\u9047\u5230\u56f0\u96be\u3002", "method": "\u8be5\u7814\u7a76\u5f62\u5f0f\u5316\u3001\u5b9e\u65bd\u5e76\u8bc4\u4f30\u4e86\u4e00\u79cd\u5229\u7528\u7a0b\u5e8f\u6027\u77e5\u8bc6\uff08\u4ee5\u5206\u5c42\u4efb\u52a1\u7f51\u7edcHTN\u7684\u5f62\u5f0f\uff09\u7684\u4ee3\u7406LLM\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u624b\u5de5\u7f16\u7801\u7684HTN\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8LLM\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u4f7f\u7528HTN\u53ef\u4ee5\u4f7f20b\u621670b\u53c2\u6570\u7684LLM\u80dc\u8fc7\u66f4\u5927\u7684120b\u53c2\u6570\u7684LLM\u57fa\u7ebf\u3002\u6b64\u5916\uff0cLLM\u521b\u5efa\u7684HTN\u53ef\u4ee5\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\uff0c\u5c3d\u7ba1\u6548\u679c\u7a0d\u5dee\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u6765\u81ea\u4eba\u7c7b\u3001\u6587\u6863\u6216LLM\u7684\u4e13\u4e1a\u77e5\u8bc6\u6765\u7ba1\u7406\u7a0b\u5e8f\u6027\u77e5\u8bc6\u5c06\u6210\u4e3a\u63d0\u9ad8LLM\u5de5\u4f5c\u6d41\u7a0b\u7684\u53e6\u4e00\u4e2a\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2511.07573", "categories": ["cs.IR", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.07573", "abs": "https://arxiv.org/abs/2511.07573", "authors": ["Kamand Kalashi", "Babak Teimourpour"], "title": "A Hybrid Multimodal Deep Learning Framework for Intelligent Fashion Recommendation", "comment": "8 pages, 1 figure", "summary": "The rapid expansion of online fashion platforms has created an increasing demand for intelligent recommender systems capable of understanding both visual and textual cues. This paper proposes a hybrid multimodal deep learning framework for fashion recommendation that jointly addresses two key tasks: outfit compatibility prediction and complementary item retrieval. The model leverages the visual and textual encoders of the CLIP architecture to obtain joint latent representations of fashion items, which are then integrated into a unified feature vector and processed by a transformer encoder. For compatibility prediction, an \"outfit token\" is introduced to model the holistic relationships among items, achieving an AUC of 0.95 on the Polyvore dataset. For complementary item retrieval, a \"target item token\" representing the desired item description is used to retrieve compatible items, reaching an accuracy of 69.24% under the Fill-in-the-Blank (FITB) metric. The proposed approach demonstrates strong performance across both tasks, highlighting the effectiveness of multimodal learning for fashion recommendation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u65f6\u5c1a\u63a8\u8350\uff0c\u53ef\u4ee5\u540c\u65f6\u5904\u7406\u670d\u88c5\u642d\u914d\u9884\u6d4b\u548c\u4e92\u8865\u5546\u54c1\u68c0\u7d22\u3002", "motivation": "\u5728\u7ebf\u65f6\u5c1a\u5e73\u53f0\u7684\u5feb\u901f\u6269\u5f20\uff0c\u8d8a\u6765\u8d8a\u9700\u8981\u80fd\u591f\u7406\u89e3\u89c6\u89c9\u548c\u6587\u672c\u7ebf\u7d22\u7684\u667a\u80fd\u63a8\u8350\u7cfb\u7edf\u3002", "method": "\u5229\u7528CLIP\u67b6\u6784\u7684\u89c6\u89c9\u548c\u6587\u672c\u7f16\u7801\u5668\u6765\u83b7\u5f97\u65f6\u5c1a\u5546\u54c1\u7684\u8054\u5408\u6f5c\u5728\u8868\u793a\uff0c\u7136\u540e\u5c06\u5176\u6574\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u7684\u7279\u5f81\u5411\u91cf\u4e2d\uff0c\u5e76\u901a\u8fc7Transformer\u7f16\u7801\u5668\u8fdb\u884c\u5904\u7406\u3002\u5f15\u5165\u201c\u670d\u88c5token\u201d\u6765\u5efa\u6a21\u5546\u54c1\u4e4b\u95f4\u7684\u6574\u4f53\u5173\u7cfb\uff0c\u5e76\u4f7f\u7528\u4ee3\u8868\u6240\u9700\u5546\u54c1\u63cf\u8ff0\u7684\u201c\u76ee\u6807\u5546\u54c1token\u201d\u6765\u68c0\u7d22\u517c\u5bb9\u5546\u54c1\u3002", "result": "\u5728Polyvore\u6570\u636e\u96c6\u4e0a\uff0c\u642d\u914d\u9884\u6d4b\u7684AUC\u8fbe\u52300.95\u3002\u5728\u586b\u7a7a\uff08FITB\uff09\u6307\u6807\u4e0b\uff0c\u4e92\u8865\u5546\u54c1\u68c0\u7d22\u7684\u51c6\u786e\u7387\u8fbe\u523069.24%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e24\u9879\u4efb\u52a1\u4e2d\u90fd\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\uff0c\u7a81\u51fa\u4e86\u591a\u6a21\u6001\u5b66\u4e60\u5bf9\u65f6\u5c1a\u63a8\u8350\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.07663", "categories": ["cs.DB", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.07663", "abs": "https://arxiv.org/abs/2511.07663", "authors": ["Paritosh Aggarwal", "Bowei Chen", "Anupam Datta", "Benjamin Han", "Boxin Jiang", "Nitish Jindal", "Zihan Li", "Aaron Lin", "Pawel Liskowski", "Jay Tayade", "Dimitris Tsirogiannis", "Nathan Wiegand", "Weicheng Zhao"], "title": "Cortex AISQL: A Production SQL Engine for Unstructured Data", "comment": null, "summary": "Snowflake's Cortex AISQL is a production SQL engine that integrates native semantic operations directly into SQL. This integration allows users to write declarative queries that combine relational operations with semantic reasoning, enabling them to query both structured and unstructured data effortlessly. However, making semantic operations efficient at production scale poses fundamental challenges. Semantic operations are more expensive than traditional SQL operations, possess distinct latency and throughput characteristics, and their cost and selectivity are unknown during query compilation. Furthermore, existing query engines are not designed to optimize semantic operations. The AISQL query execution engine addresses these challenges through three novel techniques informed by production deployment data from Snowflake customers. First, AI-aware query optimization treats AI inference cost as a first-class optimization objective, reasoning about large language model (LLM) cost directly during query planning to achieve 2-8$\\times$ speedups. Second, adaptive model cascades reduce inference costs by routing most rows through a fast proxy model while escalating uncertain cases to a powerful oracle model, achieving 2-6$\\times$ speedups while maintaining 90-95% of oracle model quality. Third, semantic join query rewriting lowers the quadratic time complexity of join operations to linear through reformulation as multi-label classification tasks, achieving 15-70$\\times$ speedups with often improved prediction quality. AISQL is deployed in production at Snowflake, where it powers diverse customer workloads across analytics, search, and content understanding.", "AI": {"tldr": "Snowflake\u7684Cortex AISQL\u5c06\u8bed\u4e49\u64cd\u4f5c\u96c6\u6210\u5230SQL\u4e2d\uff0c\u5141\u8bb8\u7528\u6237\u67e5\u8be2\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u6570\u636e\u3002\u5b83\u901a\u8fc7AI\u611f\u77e5\u67e5\u8be2\u4f18\u5316\u3001\u81ea\u9002\u5e94\u6a21\u578b\u7ea7\u8054\u548c\u8bed\u4e49\u8fde\u63a5\u67e5\u8be2\u91cd\u5199\u7b49\u6280\u672f\uff0c\u4f18\u5316AI\u63a8\u7406\u6210\u672c\uff0c\u63d0\u9ad8\u67e5\u8be2\u6548\u7387\u548c\u9884\u6d4b\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u67e5\u8be2\u5f15\u64ce\u6ca1\u6709\u9488\u5bf9\u8bed\u4e49\u64cd\u4f5c\u8fdb\u884c\u4f18\u5316\uff0c\u800c\u8bed\u4e49\u64cd\u4f5c\u6bd4\u4f20\u7edfSQL\u64cd\u4f5c\u66f4\u6602\u8d35\uff0c\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u7279\u6027\u4e0d\u540c\uff0c\u5e76\u4e14\u5728\u67e5\u8be2\u7f16\u8bd1\u671f\u95f4\u6210\u672c\u548c\u9009\u62e9\u6027\u672a\u77e5\u3002", "method": "\u8be5\u5f15\u64ce\u91c7\u7528\u4e09\u79cd\u65b0\u6280\u672f\uff1aAI\u611f\u77e5\u67e5\u8be2\u4f18\u5316\uff08\u5c06AI\u63a8\u7406\u6210\u672c\u89c6\u4e3a\u9996\u8981\u4f18\u5316\u76ee\u6807\uff09\u3001\u81ea\u9002\u5e94\u6a21\u578b\u7ea7\u8054\uff08\u901a\u8fc7\u5feb\u901f\u4ee3\u7406\u6a21\u578b\u8def\u7531\u5927\u591a\u6570\u884c\uff0c\u5e76\u5c06\u4e0d\u786e\u5b9a\u60c5\u51b5\u5347\u7ea7\u5230\u5f3a\u5927\u7684oracle\u6a21\u578b\uff09\u548c\u8bed\u4e49\u8fde\u63a5\u67e5\u8be2\u91cd\u5199\uff08\u5c06\u8fde\u63a5\u64cd\u4f5c\u7684\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u964d\u4f4e\u5230\u7ebf\u6027\uff09\u3002", "result": "AI\u611f\u77e5\u67e5\u8be2\u4f18\u5316\u5b9e\u73b0\u4e862-8\u500d\u7684\u52a0\u901f\uff0c\u81ea\u9002\u5e94\u6a21\u578b\u7ea7\u8054\u5728\u4fdd\u630190-95%\u7684oracle\u6a21\u578b\u8d28\u91cf\u7684\u540c\u65f6\u5b9e\u73b0\u4e862-6\u500d\u7684\u52a0\u901f\uff0c\u8bed\u4e49\u8fde\u63a5\u67e5\u8be2\u91cd\u5199\u5b9e\u73b0\u4e8615-70\u500d\u7684\u52a0\u901f\uff0c\u5e76\u4e14\u901a\u5e38\u63d0\u9ad8\u4e86\u9884\u6d4b\u8d28\u91cf\u3002", "conclusion": "AISQL\u5df2\u5728Snowflake\u4e2d\u90e8\u7f72\uff0c\u4e3a\u5206\u6790\u3001\u641c\u7d22\u548c\u5185\u5bb9\u7406\u89e3\u7b49\u5404\u79cd\u5ba2\u6237\u5de5\u4f5c\u8d1f\u8f7d\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.07445", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.07445", "abs": "https://arxiv.org/abs/2511.07445", "authors": ["Claire Lin", "Bo-Han Feng", "Xuanjun Chen", "Te-Lun Yang", "Hung-yi Lee", "Jyh-Shing Roger Jang"], "title": "A Preliminary Study of RAG for Taiwanese Historical Archives", "comment": "Accepted by ROCLING 2025", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a promising approach for knowledge-intensive tasks. However, few studies have examined RAG for Taiwanese Historical Archives. In this paper, we present an initial study of a RAG pipeline applied to two historical Traditional Chinese datasets, Fort Zeelandia and the Taiwan Provincial Council Gazette, along with their corresponding open-ended query sets. We systematically investigate the effects of query characteristics and metadata integration strategies on retrieval quality, answer generation, and the performance of the overall system. The results show that early-stage metadata integration enhances both retrieval and answer accuracy while also revealing persistent challenges for RAG systems, including hallucinations during generation and difficulties in handling temporal or multi-hop historical queries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u5728\u53f0\u6e7e\u5386\u53f2\u6863\u6848\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u5173\u6ce8RAG\u5728\u53f0\u6e7e\u5386\u53f2\u6863\u6848\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u8be5\u7814\u7a76\u5c06RAG\u6d41\u7a0b\u5e94\u7528\u4e8e\u4e24\u4e2a\u7e41\u4f53\u4e2d\u6587\u5386\u53f2\u6570\u636e\u96c6\uff0c\u5e76\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u67e5\u8be2\u7279\u5f81\u548c\u5143\u6570\u636e\u96c6\u6210\u7b56\u7565\u5bf9\u68c0\u7d22\u8d28\u91cf\u3001\u7b54\u6848\u751f\u6210\u548c\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u65e9\u671f\u5143\u6570\u636e\u96c6\u6210\u63d0\u9ad8\u4e86\u68c0\u7d22\u548c\u7b54\u6848\u7684\u51c6\u786e\u6027\u3002", "conclusion": "RAG\u7cfb\u7edf\u4ecd\u7136\u5b58\u5728\u6311\u6218\uff0c\u5305\u62ec\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5e7b\u89c9\u4ee5\u53ca\u5904\u7406\u65f6\u95f4\u6216\u591a\u8df3\u5386\u53f2\u67e5\u8be2\u7684\u56f0\u96be\u3002"}}
