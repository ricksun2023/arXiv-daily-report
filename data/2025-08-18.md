<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 66]
- [cs.AI](#cs.AI) [Total: 11]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.IR](#cs.IR) [Total: 7]
- [cs.LG](#cs.LG) [Total: 59]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)
*Tomer Wolfson,Harsh Trivedi,Mor Geva,Yoav Goldberg,Dan Roth,Tushar Khot,Ashish Sabharwal,Reut Tsarfaty*

Main category: cs.CL

TL;DR: MoNaCo: a new benchmark for LLMs with 1,315 complex, real-world information-seeking questions that require significant reasoning. Current LLMs struggle on MoNaCo, highlighting the need for improved reasoning models.


<details>
  <summary>Details</summary>
Motivation: current LLM benchmarks rarely feature natural questions that are both information-seeking as well as genuinely time-consuming for humans

Method: developed a decomposed annotation pipeline to elicit and manually answer natural time-consuming questions at scale

Result: a benchmark of 1,315 natural and complex questions that require dozens, and at times hundreds, of intermediate steps to solve

Conclusion: Frontier LLMs evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and hallucinations. Our results underscore the need for reasoning models that better handle the complexity and sheer breadth of real-world information-seeking questions -- with MoNaCo providing an effective resource for tracking such progress.

Abstract: Large language models (LLMs) are emerging as a go-to tool for querying
information. However, current LLM benchmarks rarely feature natural questions
that are both information-seeking as well as genuinely time-consuming for
humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural
and complex questions that require dozens, and at times hundreds, of
intermediate steps to solve -- far more than any existing QA benchmark. To
build MoNaCo, we developed a decomposed annotation pipeline to elicit and
manually answer natural time-consuming questions at scale. Frontier LLMs
evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and
hallucinations. Our results underscore the need for reasoning models that
better handle the complexity and sheer breadth of real-world
information-seeking questions -- with MoNaCo providing an effective resource
for tracking such progress. The MONACO benchmark, codebase, prompts and models
predictions are publicly available at: https://tomerwolgithub.github.io/monaco

</details>


### [2] [A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation](https://arxiv.org/abs/2508.10904)
*Jie Lei,Ruofan Jia,J. Andrew Zhang,Hao Zhang*

Main category: cs.CL

TL;DR: A2HCoder是一种基于LLM的分层算法到HDL编码代理，旨在实现敏捷可靠的算法到硬件转换，通过分层框架增强鲁棒性和可解释性，并抑制LLM生成代码中常见的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 在无线通信系统中，超低延迟和功耗等严格要求大大增加了对高效算法到硬件部署的需求。然而，算法设计和硬件实现之间仍然存在持久且巨大的差距。由于MATLAB等高级编程语言与Verilog等硬件描述语言（HDL）在内存访问模式、数据处理方式和数据类型表示方面存在根本不匹配，因此弥合这一差距传统上需要广泛的领域专业知识和耗时的手动开发。

Method: A2HCoder：一种分层算法到HDL的编码代理，由大型语言模型（LLM）驱动，旨在实现敏捷可靠的算法到硬件转换。A2HCoder引入了一个分层框架，该框架增强了鲁棒性和可解释性，同时抑制了LLM生成代码中常见的幻觉问题。

Result: A2HCoder通过将复杂算法分解为模块化功能块，简化了代码生成并提高了代码一致性。在垂直维度上，A2HCoder执行逐步的细粒度转换，利用MATLAB和Vitis HLS等外部工具链进行调试和电路级综合。这种结构化过程显著减轻了幻觉并确保了硬件级正确性。

Conclusion: A2HCoder通过5G无线通信领域的实际部署案例验证，证明了其可行性、可靠性和部署效率。

Abstract: In wireless communication systems, stringent requirements such as ultra-low
latency and power consumption have significantly increased the demand for
efficient algorithm-to-hardware deployment. However, a persistent and
substantial gap remains between algorithm design and hardware implementation.
Bridging this gap traditionally requires extensive domain expertise and
time-consuming manual development, due to fundamental mismatches between
high-level programming languages like MATLAB and hardware description languages
(HDLs) such as Verilog-in terms of memory access patterns, data processing
manners, and datatype representations. To address this challenge, we propose
A2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large
language models (LLMs), designed to enable agile and reliable
algorithm-to-hardware translation. A2HCoder introduces a hierarchical framework
that enhances both robustness and interpretability while suppressing common
hallucination issues in LLM-generated code. In the horizontal dimension,
A2HCoder decomposes complex algorithms into modular functional blocks,
simplifying code generation and improving consistency. In the vertical
dimension, instead of relying on end-to-end generation, A2HCoder performs
step-by-step, fine-grained translation, leveraging external toolchains such as
MATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured
process significantly mitigates hallucinations and ensures hardware-level
correctness. We validate A2HCoder through a real-world deployment case in the
5G wireless communication domain, demonstrating its practicality, reliability,
and deployment efficiency.

</details>


### [3] [PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins](https://arxiv.org/abs/2508.10906)
*Sihan Chen,John P. Lalor,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: PersonaTwin, a multi-tier prompt conditioning framework, builds adaptive digital twins by integrating demographic, behavioral, and psychometric data. It improves simulation fidelity and fairness compared to standard LLMs.


<details>
  <summary>Details</summary>
Motivation: LLMs often fail to capture the multidimensional nuances of individual users.

Method: a multi-tier prompt conditioning framework that builds adaptive digital twins by integrating demographic, behavioral, and psychometric data

Result: PersonaTwin produces simulation fidelity on par with oracle settings; downstream models trained on persona-twins approximate models trained on individuals in terms of prediction and fairness metrics across both GPT-4o-based and Llama-based models.

Conclusion: LLM digital twin-based approaches have the potential to produce realistic and emotionally nuanced user simulations, offering a powerful tool for personalized digital user modeling and behavior analysis.

Abstract: While large language models (LLMs) afford new possibilities for user modeling
and approximation of human behaviors, they often fail to capture the
multidimensional nuances of individual users. In this work, we introduce
PersonaTwin, a multi-tier prompt conditioning framework that builds adaptive
digital twins by integrating demographic, behavioral, and psychometric data.
Using a comprehensive data set in the healthcare context of more than 8,500
individuals, we systematically benchmark PersonaTwin against standard LLM
outputs, and our rigorous evaluation unites state-of-the-art text similarity
metrics with dedicated demographic parity assessments, ensuring that generated
responses remain accurate and unbiased. Experimental results show that our
framework produces simulation fidelity on par with oracle settings. Moreover,
downstream models trained on persona-twins approximate models trained on
individuals in terms of prediction and fairness metrics across both
GPT-4o-based and Llama-based models. Together, these findings underscore the
potential for LLM digital twin-based approaches in producing realistic and
emotionally nuanced user simulations, offering a powerful tool for personalized
digital user modeling and behavior analysis.

</details>


### [4] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
*OpenAI,:,Sandhini Agarwal,Lama Ahmad,Jason Ai,Sam Altman,Andy Applebaum,Edwin Arbus,Rahul K. Arora,Yu Bai,Bowen Baker,Haiming Bao,Boaz Barak,Ally Bennett,Tyler Bertao,Nivedita Brett,Eugene Brevdo,Greg Brockman,Sebastien Bubeck,Che Chang,Kai Chen,Mark Chen,Enoch Cheung,Aidan Clark,Dan Cook,Marat Dukhan,Casey Dvorak,Kevin Fives,Vlad Fomenko,Timur Garipov,Kristian Georgiev,Mia Glaese,Tarun Gogineni,Adam Goucher,Lukas Gross,Katia Gil Guzman,John Hallman,Jackie Hehir,Johannes Heidecke,Alec Helyar,Haitang Hu,Romain Huet,Jacob Huh,Saachi Jain,Zach Johnson,Chris Koch,Irina Kofman,Dominik Kundel,Jason Kwon,Volodymyr Kyrylov,Elaine Ya Le,Guillaume Leclerc,James Park Lennon,Scott Lessans,Mario Lezcano-Casado,Yuanzhi Li,Zhuohan Li,Ji Lin,Jordan Liss,Lily,Liu,Jiancheng Liu,Kevin Lu,Chris Lu,Zoran Martinovic,Lindsay McCallum,Josh McGrath,Scott McKinney,Aidan McLaughlin,Song Mei,Steve Mostovoy,Tong Mu,Gideon Myles,Alexander Neitz,Alex Nichol,Jakub Pachocki,Alex Paino,Dana Palmie,Ashley Pantuliano,Giambattista Parascandolo,Jongsoo Park,Leher Pathak,Carolina Paz,Ludovic Peran,Dmitry Pimenov,Michelle Pokrass,Elizabeth Proehl,Huida Qiu,Gaby Raila,Filippo Raso,Hongyu Ren,Kimmy Richardson,David Robinson,Bob Rotsted,Hadi Salman,Suvansh Sanjeev,Max Schwarzer,D. Sculley,Harshit Sikchi,Kendal Simon,Karan Singhal,Yang Song,Dane Stuckey,Zhiqing Sun,Philippe Tillet,Sam Toizer,Foivos Tsimpourlas,Nikhil Vyas,Eric Wallace,Xin Wang,Miles Wang,Olivia Watkins,Kevin Weil,Amy Wendling,Kevin Whinnery,Cedric Whitney,Hannah Wong,Lin Yang,Yu Yang,Michihiro Yasunaga,Kristen Ying,Wojciech Zaremba,Wenting Zhan,Cyril Zhang,Brian Zhang,Eddie Zhang,Shengjia Zhao*

Main category: cs.CL

TL;DR: gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models that push the frontier of accuracy and inference cost.


<details>
  <summary>Details</summary>
Motivation: push the frontier of accuracy and inference cost

Method: The models use an efficient mixture-of-expert transformer architecture and are trained using large-scale distillation and reinforcement learning.

Result: achieve strong results on benchmarks ranging from mathematics, coding, and safety

Conclusion: Both models achieve strong results on benchmarks ranging from mathematics, coding, and safety.

Abstract: We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models
that push the frontier of accuracy and inference cost. The models use an
efficient mixture-of-expert transformer architecture and are trained using
large-scale distillation and reinforcement learning. We optimize the models to
have strong agentic capabilities (deep research browsing, python tool use, and
support for developer-provided functions), all while using a rendered chat
format that enables clear instruction following and role delineation. Both
models achieve strong results on benchmarks ranging from mathematics, coding,
and safety. We release the model weights, inference implementations, tool
environments, and tokenizers under an Apache 2.0 license to enable broad use
and further research.

</details>


### [5] [Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News](https://arxiv.org/abs/2508.10927)
*Jiaxin Pei,Soumya Vadlamannati,Liang-Kang Huang,Daniel Preotiuc-Pietro,Xinyu Hua*

Main category: cs.CL

TL;DR: extract company risk factors from news articles


<details>
  <summary>Details</summary>
Motivation: identifying risks associated with a company is important to investors and the well-being of the overall financial market

Method: build a computational framework to automatically extract company risk factors from news articles, sample and annotate 744 news articles and benchmark various machine learning models, analyze over 277K Bloomberg news articles

Result: zero-shot and few-shot prompting state-of-the-art LLMs (e.g. LLaMA-2) can only achieve moderate to low performances in identifying risk factors, fine-tuned pre-trained language models are performing better on most of the risk factors

Conclusion: identifying risk factors from news could provide extensive insight into the operations of companies and industries

Abstract: Identifying risks associated with a company is important to investors and the
well-being of the overall financial market. In this study, we build a
computational framework to automatically extract company risk factors from news
articles. Our newly proposed schema comprises seven distinct aspects, such as
supply chain, regulations, and competitions. We sample and annotate 744 news
articles and benchmark various machine learning models. While large language
models have achieved huge progress in various types of NLP tasks, our
experiment shows that zero-shot and few-shot prompting state-of-the-art LLMs
(e.g. LLaMA-2) can only achieve moderate to low performances in identifying
risk factors. And fine-tuned pre-trained language models are performing better
on most of the risk factors. Using this model, we analyze over 277K Bloomberg
news articles and demonstrate that identifying risk factors from news could
provide extensive insight into the operations of companies and industries.

</details>


### [6] [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)
*Nasim Shirvani-Mahdavi,Chengkai Li*

Main category: cs.CL

TL;DR: Rule2Text利用llm为挖掘的逻辑规则生成自然语言解释，从而提高KG的可访问性和可用性。


<details>
  <summary>Details</summary>
Motivation: 知识图可以通过规则挖掘来增强;然而，由于其固有的复杂性和单个知识图的特殊标签约定，由此产生的逻辑规则通常难以让人理解。

Method: 利用大型语言模型(llm)为挖掘的逻辑规则生成自然语言解释的综合框架Rule2Text。

Result: 对多个数据集(包括Freebase变体(FB- cvt-rev, FB+CVT-REV和FB15k-237)以及ogbl-biokg数据集)进行了广泛的实验，并使用AMIE 3.5.1挖掘规则。系统地评估了各种提示策略(包括zero-shot、few-shot、可变类型合并和思维链推理)中的几个llm。

Conclusion: 使用微调后的Zephyr模型，解释质量显著提高，尤其是在特定领域的数据集中。

Abstract: Knowledge graphs (KGs) can be enhanced through rule mining; however, the
resulting logical rules are often difficult for humans to interpret due to
their inherent complexity and the idiosyncratic labeling conventions of
individual KGs. This work presents Rule2Text, a comprehensive framework that
leverages large language models (LLMs) to generate natural language
explanations for mined logical rules, thereby improving KG accessibility and
usability. We conduct extensive experiments using multiple datasets, including
Freebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the
ogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically
evaluate several LLMs across a comprehensive range of prompting strategies,
including zero-shot, few-shot, variable type incorporation, and
Chain-of-Thought reasoning. To systematically assess models' performance, we
conduct a human evaluation of generated explanations on correctness and
clarity. To address evaluation scalability, we develop and validate an
LLM-as-a-judge framework that demonstrates strong agreement with human
evaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,
and human-in-the-loop feedback, we construct high-quality ground truth
datasets, which we use to fine-tune the open-source Zephyr model. Our results
demonstrate significant improvements in explanation quality after fine-tuning,
with particularly strong gains in the domain-specific dataset. Additionally, we
integrate a type inference module to support KGs lacking explicit type
information. All code and data are publicly available at
https://github.com/idirlab/KGRule2NL.

</details>


### [7] [Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling](https://arxiv.org/abs/2508.10995)
*Tejomay Kishor Padole,Suyash P Awate,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: This paper proposes a verifier-based inference-time scaling method for Masked Diffusion Language Models (MDMs) that improves generation quality, making them a better alternative to autoregressive models for text-style transfer.


<details>
  <summary>Details</summary>
Motivation: Masked diffusion language models (MDMs) have recently gained traction as a viable generative framework for natural language due to its scalability and ease of training, establishing itself as the state-of-the-art non-autoregressive generator for discrete data. Diffusion models, in general, have shown excellent ability to improve the generation quality by leveraging inference-time scaling.

Method: a verifier-based inference-time scaling method that aids in finding a better candidate generation during the denoising process of the MDM; a simple soft-value-based verifier setup for MDMs using off-the-shelf pre-trained embedding models

Result: MDMs as a better alternative to autoregressive language models; significant gains in generation quality even when used on top of typical classifier-free guidance setups

Conclusion: MDMs are a better alternative to autoregressive language models for text-style transfer tasks. A simple soft-value-based verifier setup for MDMs leads to significant gains in generation quality.

Abstract: Masked diffusion language models (MDMs) have recently gained traction as a
viable generative framework for natural language. This can be attributed to its
scalability and ease of training compared to other diffusion model paradigms
for discrete data, establishing itself as the state-of-the-art
non-autoregressive generator for discrete data. Diffusion models, in general,
have shown excellent ability to improve the generation quality by leveraging
inference-time scaling either by increasing the number of denoising steps or by
using external verifiers on top of the outputs of each step to guide the
generation. In this work, we propose a verifier-based inference-time scaling
method that aids in finding a better candidate generation during the denoising
process of the MDM. Our experiments demonstrate the application of MDMs for
standard text-style transfer tasks and establish MDMs as a better alternative
to autoregressive language models. Additionally, we show that a simple
soft-value-based verifier setup for MDMs using off-the-shelf pre-trained
embedding models leads to significant gains in generation quality even when
used on top of typical classifier-free guidance setups in the existing
literature.

</details>


### [8] [SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth](https://arxiv.org/abs/2508.11009)
*Wenpeng Xing,Lanyi Wei,Haixiao Hu,Rongchang Li,Mohan Li,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: 这篇论文介绍了一个新的评估套件 SproutBench，用于评估 LLM 在儿童使用时的安全风险，发现现有 LLM 存在大量安全漏洞，并为儿童人工智能设计提供了实用指南。


<details>
  <summary>Details</summary>
Motivation: 针对儿童和青少年的人工智能应用程序中大型语言模型 (LLM) 的迅速普及，需要从根本上重新评估当前的 AI 安全框架，这些框架主要针对成人用户，而忽略了未成年人独特的发育脆弱性。

Method: 我们引入了 SproutBench，这是一个创新的评估套件，包含 1,283 个基于发展原理的对抗性提示，旨在探测情感依赖、侵犯隐私和模仿危险行为等风险。

Result: 我们发现了大量的安全漏洞，并通过强大的跨维度关联（例如，安全和风险预防之间）和交互性与年龄适当性之间显着的反比关系证实了这些漏洞。

Conclusion: 通过对 47 个不同 LLM 的严格实证评估，我们发现了大量的安全漏洞，并通过强大的跨维度关联（例如，安全和风险预防之间）和交互性与年龄适当性之间显着的反比关系证实了这些漏洞。这些见解为推进以儿童为中心的人工智能设计和部署提供了实用的指导。

Abstract: The rapid proliferation of large language models (LLMs) in applications
targeting children and adolescents necessitates a fundamental reassessment of
prevailing AI safety frameworks, which are largely tailored to adult users and
neglect the distinct developmental vulnerabilities of minors. This paper
highlights key deficiencies in existing LLM safety benchmarks, including their
inadequate coverage of age-specific cognitive, emotional, and social risks
spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence
(13--18). To bridge these gaps, we introduce SproutBench, an innovative
evaluation suite comprising 1,283 developmentally grounded adversarial prompts
designed to probe risks such as emotional dependency, privacy violations, and
imitation of hazardous behaviors. Through rigorous empirical evaluation of 47
diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by
robust inter-dimensional correlations (e.g., between Safety and Risk
Prevention) and a notable inverse relationship between Interactivity and Age
Appropriateness. These insights yield practical guidelines for advancing
child-centric AI design and deployment.

</details>


### [9] [Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics](https://arxiv.org/abs/2508.11017)
*Carter Blum,Katja Filipova,Ann Yuan,Asma Ghandeharioun,Julian Zimmert,Fred Zhang,Jessica Hoffmann,Tal Linzen,Martin Wattenberg,Lucas Dixon,Mor Geva*

Main category: cs.CL

TL;DR: This paper studies cross-lingual knowledge transfer in LLMs using synthetic datasets. It finds that unification of representations across languages is essential for transfer and proposes methods to modulate transfer by manipulating data distribution and tokenization.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with cross-lingual knowledge transfer: they hallucinate when asked in one language about facts expressed in a different language during training.

Method: training small Transformer models from scratch on synthetic multilingual datasets

Result: a model develops either separate or unified representations of the same facts across languages, and show that unification is essential for cross-lingual transfer. We also show that the degree of unification depends on mutual information between facts and training data language, and on how easy it is to extract that language.

Conclusion: This work shows how controlled settings can shed light on pre-training dynamics and suggests new directions for improving cross-lingual transfer in LLMs.

Abstract: Large language models (LLMs) struggle with cross-lingual knowledge transfer:
they hallucinate when asked in one language about facts expressed in a
different language during training. This work introduces a controlled setting
to study the causes and dynamics of this phenomenon by training small
Transformer models from scratch on synthetic multilingual datasets. We identify
a learning phase wherein a model develops either separate or unified
representations of the same facts across languages, and show that unification
is essential for cross-lingual transfer. We also show that the degree of
unification depends on mutual information between facts and training data
language, and on how easy it is to extract that language. Based on these
insights, we develop methods to modulate the level of cross-lingual transfer by
manipulating data distribution and tokenization, and we introduce metrics and
visualizations to formally characterize their effects on unification. Our work
shows how controlled settings can shed light on pre-training dynamics and
suggests new directions for improving cross-lingual transfer in LLMs.

</details>


### [10] [Hell or High Water: Evaluating Agentic Recovery from External Failures](https://arxiv.org/abs/2508.11027)
*Andrew Wang,Sophia Hager,Adi Asija,Daniel Khashabi,Nicholas Andrews*

Main category: cs.CL

TL;DR: 语言模型智能体在环境反馈中难以制定备用计划，即使搜索空间受限也是如此。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型智能体被应用于日益复杂的现实世界问题，它们将被期望在大型搜索空间中制定计划。如果这些计划由于超出其控制的原因而失败，那么语言智能体在寻找实现其目标的其他方法方面的表现如何？

Method: 我们设计了一个专门的智能体规划基准来研究这个问题。每个规划问题都通过函数调用的组合来解决。智能体从四千多个可能性中搜索相关函数，并观察环境反馈，形式为函数输出或错误消息。

Result: 语言智能体难以制定和执行备用计划以响应环境反馈。虽然最先进的模型通常能够识别在正确的上下文中使用哪个正确的函数，但它们难以适应环境的反馈，并且常常无法采取替代行动，即使搜索空间是人为限制的。

Conclusion: 语言模型智能体在应对环境反馈时，难以制定和执行备用计划。即使在搜索空间受限的情况下，它们也难以适应环境反馈，并且常常无法采取替代行动。

Abstract: As language model agents are applied to real world problems of increasing
complexity, they will be expected to formulate plans across large search
spaces. If those plans fail for reasons beyond their control, how well do
language agents search for alternative ways to achieve their goals? We devise a
specialized agentic planning benchmark to study this question. Each planning
problem is solved via combinations of function calls. The agent searches for
relevant functions from a set of over four thousand possibilities, and observes
environmental feedback in the form of function outputs or error messages. Our
benchmark confronts the agent with external failures in its workflow, such as
functions that suddenly become unavailable. At the same time, even with the
introduction of these failures, we guarantee that the task remains solvable.
Ideally, an agent's performance on the planning task should not be affected by
the presence of external failures. Overall, we find that language agents
struggle to formulate and execute backup plans in response to environment
feedback. While state-of-the-art models are often able to identify the correct
function to use in the right context, they struggle to adapt to feedback from
the environment and often fail to pursue alternate courses of action, even when
the search space is artificially restricted. We provide a systematic analysis
of the failures of both open-source and commercial models, examining the
effects of search space size, as well as the benefits of scaling model size in
our setting. Our analysis identifies key challenges for current generative
models as well as promising directions for future work.

</details>


### [11] [SGSimEval: A Comprehensive Multifaceted and Similarity-Enhanced Benchmark for Automatic Survey Generation Systems](https://arxiv.org/abs/2508.11310)
*Beichen Guo,Zhiyuan Wen,Yu Yang,Peng Gao,Ruosong Yang,Jiaxing Shen*

Main category: cs.CL

TL;DR: This paper introduces SGSimEval, a new benchmark for evaluating automatic survey generation systems, addressing limitations in existing methods. The results show that current systems excel in outline generation but need improvement in content and reference generation.


<details>
  <summary>Details</summary>
Motivation: existing evaluation methods suffer from several limitations, including biased metrics, a lack of human preference, and an over-reliance on LLMs-as-judges. To address these challenges, we propose

Method: SGSimEval, a comprehensive benchmark for Survey Generation with Similarity-Enhanced Evaluation that evaluates automatic survey generation systems by integrating assessments of the outline, content, and references, and also combines LLM-based scoring with quantitative metrics to provide a multifaceted evaluation framework. In SGSimEval, we also introduce human preference metrics that emphasize both inherent quality and similarity to humans.

Result: current ASG systems demonstrate human-comparable superiority in outline generation, while showing significant room for improvement in content and reference generation, and our evaluation metrics maintain strong consistency with human assessments.

Conclusion: current ASG systems demonstrate human-comparable superiority in outline generation, while showing significant room for improvement in content and reference generation, and our evaluation metrics maintain strong consistency with human assessments.

Abstract: The growing interest in automatic survey generation (ASG), a task that
traditionally required considerable time and effort, has been spurred by recent
advances in large language models (LLMs). With advancements in
retrieval-augmented generation (RAG) and the rising popularity of multi-agent
systems (MASs), synthesizing academic surveys using LLMs has become a viable
approach, thereby elevating the need for robust evaluation methods in this
domain. However, existing evaluation methods suffer from several limitations,
including biased metrics, a lack of human preference, and an over-reliance on
LLMs-as-judges. To address these challenges, we propose SGSimEval, a
comprehensive benchmark for Survey Generation with Similarity-Enhanced
Evaluation that evaluates automatic survey generation systems by integrating
assessments of the outline, content, and references, and also combines
LLM-based scoring with quantitative metrics to provide a multifaceted
evaluation framework. In SGSimEval, we also introduce human preference metrics
that emphasize both inherent quality and similarity to humans. Extensive
experiments reveal that current ASG systems demonstrate human-comparable
superiority in outline generation, while showing significant room for
improvement in content and reference generation, and our evaluation metrics
maintain strong consistency with human assessments.

</details>


### [12] [BIPOLAR: Polarization-based granular framework for LLM bias evaluation](https://arxiv.org/abs/2508.11061)
*Martin Pavlíček,Tomáš Filip,Petr Sosík*

Main category: cs.CL

TL;DR: This paper introduces a framework for evaluating polarisation-related biases in LLMs, using a synthetic dataset focusing on the Russia-Ukraine war. The framework allows for fine-grained analysis and reveals biases in different models.


<details>
  <summary>Details</summary>
Motivation: LLMs exhibit biases in downstream tasks, especially when dealing with sensitive topics. Certain challenges remain underexplored in bias detection and mitigation techniques.

Method: This study proposes a reusable, granular, and topic-agnostic framework to evaluate polarisation-related biases in LLM (both open-source and closed-source). Our approach combines polarisation-sensitive sentiment metrics with a synthetically generated balanced dataset of conflict-related statements, using a predefined set of semantic categories.

Result: Beyond aggregate bias scores, with a general trend for more positive sentiment toward Ukraine, the framework allowed fine-grained analysis with considerable variation between semantic categories, uncovering divergent behavioural patterns among models. Adaptation to prompt modifications showed further bias towards preconceived language and citizenship modification.

Conclusion: The framework supports automated dataset generation and fine-grained bias assessment, is applicable to a variety of polarisation-driven scenarios and topics, and is orthogonal to many other bias-evaluation strategies.

Abstract: Large language models (LLMs) are known to exhibit biases in downstream tasks,
especially when dealing with sensitive topics such as political discourse,
gender identity, ethnic relations, or national stereotypes. Although
significant progress has been made in bias detection and mitigation techniques,
certain challenges remain underexplored. This study proposes a reusable,
granular, and topic-agnostic framework to evaluate polarisation-related biases
in LLM (both open-source and closed-source). Our approach combines
polarisation-sensitive sentiment metrics with a synthetically generated
balanced dataset of conflict-related statements, using a predefined set of
semantic categories.
  As a case study, we created a synthetic dataset that focusses on the
Russia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,
Mistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with
a general trend for more positive sentiment toward Ukraine, the framework
allowed fine-grained analysis with considerable variation between semantic
categories, uncovering divergent behavioural patterns among models. Adaptation
to prompt modifications showed further bias towards preconceived language and
citizenship modification.
  Overall, the framework supports automated dataset generation and fine-grained
bias assessment, is applicable to a variety of polarisation-driven scenarios
and topics, and is orthogonal to many other bias-evaluation strategies.

</details>


### [13] [Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs](https://arxiv.org/abs/2508.11068)
*Nicolas Goulet,Alexandre Blondin Massé,Moussa Abdendi*

Main category: cs.CL

TL;DR: embedding real digital dictionaries into AMR directed graphs (digraphs), using state-of-the-art pre-trained large language models, reduce those graphs in a confluent manner, analyze the properties of these reduces digraphs are analyzed and discussed in relation to the symbol grounding problem


<details>
  <summary>Details</summary>
Motivation: AMR is a semantic formalism used to represent the meaning of sentences as directed acyclic graphs

Method: real digital dictionaries can be embedded into AMR directed graphs (digraphs), using state-of-the-art pre-trained large language models. Then, reduce those graphs in a confluent manner, i.e. with transformations that preserve their circuit space

Result: embedding real digital dictionaries into AMR directed graphs

Conclusion: the properties of reduces digraphs are analyzed and discussed in relation to the symbol grounding problem

Abstract: Abstract meaning representation (AMR) is a semantic formalism used to
represent the meaning of sentences as directed acyclic graphs. In this paper,
we describe how real digital dictionaries can be embedded into AMR directed
graphs (digraphs), using state-of-the-art pre-trained large language models.
Then, we reduce those graphs in a confluent manner, i.e. with transformations
that preserve their circuit space. Finally, the properties of these reduces
digraphs are analyzed and discussed in relation to the symbol grounding
problem.

</details>


### [14] [Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](https://arxiv.org/abs/2508.11120)
*Lorenzo Jaime Yu Flores,Junyi Shen,Xiaoyuan Gu*

Main category: cs.CL

TL;DR: This paper introduces RAMP, a multi-agent framework for audience curation using LLMs, which improves accuracy and recall through planning, memory, iterative verification, and reflection.


<details>
  <summary>Details</summary>
Motivation: Literature on the reliability of large language models (LLMs) in real-world applications remains limited.

Method: The paper introduces a multi-agent framework called RAMP that iteratively plans, calls tools, verifies the output, and generates suggestions to improve the quality of the audience generated. The model is equipped with a long-term memory store, which is a knowledge base of client-specific facts and past queries.

Result: LLM planning and memory increases accuracy by 28 percentage points. Iterative verification and reflection shows progressively better recall (roughly +20 percentage points) with more verify/reflect iterations and higher user satisfaction.

Conclusion: This paper demonstrates the use of LLM planning and memory, which increases accuracy by 28 percentage points. The impact of iterative verification and reflection on ambiguous queries shows progressively better recall (roughly +20 percentage points) and higher user satisfaction. The results provide practical insights for deploying reliable LLM-based systems.

Abstract: Recent advances in large language models (LLMs) enabled the development of AI
agents that can plan and interact with tools to complete complex tasks.
However, literature on their reliability in real-world applications remains
limited. In this paper, we introduce a multi-agent framework for a marketing
task: audience curation. To solve this, we introduce a framework called RAMP
that iteratively plans, calls tools, verifies the output, and generates
suggestions to improve the quality of the audience generated. Additionally, we
equip the model with a long-term memory store, which is a knowledge base of
client-specific facts and past queries. Overall, we demonstrate the use of LLM
planning and memory, which increases accuracy by 28 percentage points on a set
of 88 evaluation queries. Moreover, we show the impact of iterative
verification and reflection on more ambiguous queries, showing progressively
better recall (roughly +20 percentage points) with more verify/reflect
iterations on a smaller challenge set, and higher user satisfaction. Our
results provide practical insights for deploying reliable LLM-based systems in
dynamic, industry-facing environments.

</details>


### [15] [MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering](https://arxiv.org/abs/2508.11163)
*Hikaru Asano,Hiroki Ouchi,Akira Kasuga,Ryo Yonetani*

Main category: cs.CL

TL;DR: MobQA是一个用于评估LLMs对人类移动数据进行语义理解能力的数据集。实验表明，LLMs在factual retrieval方面表现出色，但在语义推理和解释问答方面存在显著的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的模型擅长预测人类移动模式，但它们在多大程度上可以解释这些模式的根本原因或语义意义仍然不明显

Method: MobQA：一个综合的评估框架，用于评估LLMs回答关于人类GPS轨迹的问题的能力。它包含5,800个高质量的问答对，这些问答对分为三种类型：factual retrieval、multiple-choice reasoning和free-form explanation，所有这些都需要空间、时间和语义推理

Result: 对主要LLMs的评估表明，LLMs在factual retrieval方面表现出色，但在语义推理和解释问答方面存在显著的局限性，轨迹长度对模型效果有很大影响

Conclusion: state-of-the-art LLMs表现好在factual retrieval，但在语义推理和解释问答方面有显著局限性，轨迹长度对模型效果有很大影响

Abstract: This paper presents MobQA, a benchmark dataset designed to evaluate the
semantic understanding capabilities of large language models (LLMs) for human
mobility data through natural language question answering.
  While existing models excel at predicting human movement patterns, it remains
unobvious how much they can interpret the underlying reasons or semantic
meaning of those patterns. MobQA provides a comprehensive evaluation framework
for LLMs to answer questions about diverse human GPS trajectories spanning
daily to weekly granularities. It comprises 5,800 high-quality question-answer
pairs across three complementary question types: factual retrieval (precise
data extraction), multiple-choice reasoning (semantic inference), and free-form
explanation (interpretive description), which all require spatial, temporal,
and semantic reasoning. Our evaluation of major LLMs reveals strong performance
on factual retrieval but significant limitations in semantic reasoning and
explanation question answering, with trajectory length substantially impacting
model effectiveness. These findings demonstrate the achievements and
limitations of state-of-the-art LLMs for semantic mobility
understanding.\footnote{MobQA dataset is available at
https://github.com/CyberAgentAILab/mobqa.}

</details>


### [16] [Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification](https://arxiv.org/abs/2508.11166)
*Anusha M D,Deepthi Vikram,Bharathi Raja Chakravarthi,Parameshwar R Hegde*

Main category: cs.CL

TL;DR: This paper introduces the first benchmark dataset for Offensive Language Identification in code-mixed Tulu social media content and evaluates deep learning models.


<details>
  <summary>Details</summary>
Motivation: Tulu, a low-resource Dravidian language, has limited computational resources despite its growing digital presence.

Method: The study evaluates a suite of deep learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based variants, alongside transformer architectures (mBERT, XLM-RoBERTa).

Result: The BiGRU model with self-attention achieves the best performance with 82% accuracy and a 0.81 macro F1-score. Transformer models underperform.

Conclusion: This study lays the foundation for further NLP research in Tulu and similar low-resource, code-mixed languages.

Abstract: Tulu, a low-resource Dravidian language predominantly spoken in southern
India, has limited computational resources despite its growing digital
presence. This study presents the first benchmark dataset for Offensive
Language Identification (OLI) in code-mixed Tulu social media content,
collected from YouTube comments across various domains. The dataset, annotated
with high inter-annotator agreement (Krippendorff's alpha = 0.984), includes
3,845 comments categorized into four classes: Not Offensive, Not Tulu,
Offensive Untargeted, and Offensive Targeted. We evaluate a suite of deep
learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based
variants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU
model with self-attention achieves the best performance with 82% accuracy and a
0.81 macro F1-score. Transformer models underperform, highlighting the
limitations of multilingual pretraining in code-mixed, under-resourced
contexts. This work lays the foundation for further NLP research in Tulu and
similar low-resource, code-mixed languages.

</details>


### [17] [Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction](https://arxiv.org/abs/2508.11184)
*Tao Wu,Jingyuan Chen,Wang Lin,Jian Zhan,Mengze Li,Kun Kuang,Fei Wu*

Main category: cs.CL

TL;DR: 本研究提出了一种新的个性化干扰项生成方法，通过MCTS构建学生特定的错误概念原型，并指导模拟学生对新问题的推理，从而生成与学生反复出现的错误概念相一致的个性化干扰项。


<details>
  <summary>Details</summary>
Motivation: 现有的工作利用大型语言模型（LLM）通过学习大量学生群体中常见的错误模式来生成共享的、群体层面的干扰项，但这些干扰项通常无法捕捉到个体学生不同的推理错误，限制了它们的诊断效果。为了解决这个局限性，我们引入了个性化干扰项生成的任务，旨在基于从每个学生过去的问答（QA）记录中推断出的个体错误概念来生成定制的干扰项，确保每个学生都能收到有效暴露其特定推理错误的选项。

Method: 该研究提出了一个免训练的两阶段框架。第一阶段，通过应用蒙特卡洛树搜索（MCTS）从过去错误的答案中恢复学生的推理轨迹，构建学生特定的错误概念原型。在第二阶段，这个原型指导模拟学生对新问题的推理，从而生成与学生反复出现的错误概念相一致的个性化干扰项。

Result: 实验表明，该研究提出的方法在为140名学生生成合理的、个性化的干扰项方面表现最佳，并且有效地推广到群体层面。

Conclusion: 该研究提出的方法在为140名学生生成合理的、个性化的干扰项方面表现最佳，并且有效地推广到群体层面，突出了其稳健性和适应性。

Abstract: Distractors, incorrect but plausible answer choices in multiple-choice
questions (MCQs), play a critical role in educational assessment by diagnosing
student misconceptions. Recent work has leveraged large language models (LLMs)
to generate shared, group-level distractors by learning common error patterns
across large student populations. However, such distractors often fail to
capture the diverse reasoning errors of individual students, limiting their
diagnostic effectiveness. To address this limitation, we introduce the task of
personalized distractor generation, which aims to generate tailored distractors
based on individual misconceptions inferred from each student's past
question-answering (QA) records, ensuring every student receives options that
effectively exposes their specific reasoning errors. While promising, this task
is challenging because each student typically has only a few QA records, which
often lack the student's underlying reasoning processes, making training-based
group-level approaches infeasible. To overcome this, we propose a training-free
two-stage framework. In the first stage, we construct a student-specific
misconception prototype by applying Monte Carlo Tree Search (MCTS) to recover
the student's reasoning trajectories from past incorrect answers. In the second
stage, this prototype guides the simulation of the student's reasoning on new
questions, enabling the generation of personalized distractors that align with
the student's recurring misconceptions. Experiments show that our approach
achieves the best performance in generating plausible, personalized distractors
for 140 students, and also effectively generalizes to group-level settings,
highlighting its robustness and adaptability.

</details>


### [18] [Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation](https://arxiv.org/abs/2508.11189)
*Chenyang Le,Yinfeng Xia,Huiyan Li,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: This paper proposes a method to improve the efficiency of multilingual speech translation models by combining a novel KVSPN module with model compression and knowledge distillation, achieving significant speedups without sacrificing performance.


<details>
  <summary>Details</summary>
Motivation: Unified multilingual speech-to-text translation models often suffer from large parameter sizes, making it challenging to balance inference efficiency and performance, particularly in local deployment scenarios.

Method: The paper proposes an innovative Parasitic Dual-Scale Approach, which combines an enhanced speculative sampling method with model compression and knowledge distillation techniques. It builds on the Whisper Medium model, enhances it for multilingual speech translation into whisperM2M, and integrates a novel KVSPN module.

Result: KVSPN enables a 40% speedup with no BLEU score degradation. Combined with distillation methods, it represents a 2.6x speedup over the original Whisper Medium with superior performance.

Conclusion: The paper achieves state-of-the-art (SOTA) performance across six popular languages with improved inference efficiency by integrating the novel KVSPN module, enabling a 40% speedup with no BLEU score degradation, and a 2.6x speedup over the original Whisper Medium with superior performance when combined with distillation methods.

Abstract: Recent advancements in speech-to-text translation have led to the development
of multilingual models capable of handling multiple language pairs
simultaneously. However, these unified models often suffer from large parameter
sizes, making it challenging to balance inference efficiency and performance,
particularly in local deployment scenarios. We propose an innovative Parasitic
Dual-Scale Approach, which combines an enhanced speculative sampling method
with model compression and knowledge distillation techniques. Building on the
Whisper Medium model, we enhance it for multilingual speech translation into
whisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art
(SOTA) performance across six popular languages with improved inference
efficiency. KVSPN enables a 40\% speedup with no BLEU score degradation.
Combined with distillation methods, it represents a 2.6$\times$ speedup over
the original Whisper Medium with superior performance.

</details>


### [19] [E-CaTCH: Event-Centric Cross-Modal Attention with Temporal Consistency and Class-Imbalance Handling for Misinformation Detection](https://arxiv.org/abs/2508.11197)
*Ahmad Mousavi,Yeganeh Abdollahinejad,Roberto Corizzo,Nathalie Japkowicz,Zois Boukouvalas*

Main category: cs.CL

TL;DR: E-CaTCH是一个用于检测多模态错误信息的新框架，它通过聚类帖子成事件、利用注意力机制融合文本和视觉特征、并使用LSTM建模时间演变，从而在多个数据集上实现了优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的多模态错误信息检测仍然具有挑战性，因为模态之间存在不一致、时间模式发生变化以及类别严重不平衡。许多现有方法独立处理帖子，无法捕捉到在时间和模态上将它们连接起来的事件级结构。

Method: E-CaTCH，一个可解释且可扩展的框架，用于稳健地检测错误信息。它利用文本相似性和时间邻近性将帖子聚类成伪事件，然后独立处理每个事件。在每个事件中，使用预训练的BERT和ResNet编码器提取文本和视觉特征，通过模内自注意力进行细化，并通过双向跨模态注意力进行对齐。软门控机制融合这些表示，形成每个帖子的上下文感知、内容感知嵌入。为了模拟时间演变，E-CaTCH将事件分割成重叠的时间窗口，并使用趋势感知LSTM，通过语义偏移和动量信号增强，以编码随时间的叙事进程。分类在事件级别执行，从而更好地与真实世界的错误信息动态对齐。为了解决类别不平衡并促进稳定学习，该模型集成了自适应类别权重、时间一致性正则化和困难样本挖掘。

Result: E-CaTCH在Fakeddit、IND和COVID-19 MISINFOGRAPH上的一系列实验表明，E-CaTCH始终优于最先进的基线。跨数据集评估进一步证明了其鲁棒性、泛化性和在不同错误信息场景中的实际适用性。

Conclusion: E-CaTCH在多个数据集上优于现有方法，并在不同的错误信息场景中展示了其鲁棒性、泛化性和实用性。

Abstract: Detecting multimodal misinformation on social media remains challenging due
to inconsistencies between modalities, changes in temporal patterns, and
substantial class imbalance. Many existing methods treat posts independently
and fail to capture the event-level structure that connects them across time
and modality. We propose E-CaTCH, an interpretable and scalable framework for
robustly detecting misinformation. If needed, E-CaTCH clusters posts into
pseudo-events based on textual similarity and temporal proximity, then
processes each event independently. Within each event, textual and visual
features are extracted using pre-trained BERT and ResNet encoders, refined via
intra-modal self-attention, and aligned through bidirectional cross-modal
attention. A soft gating mechanism fuses these representations to form
contextualized, content-aware embeddings of each post. To model temporal
evolution, E-CaTCH segments events into overlapping time windows and uses a
trend-aware LSTM, enhanced with semantic shift and momentum signals, to encode
narrative progression over time. Classification is performed at the event
level, enabling better alignment with real-world misinformation dynamics. To
address class imbalance and promote stable learning, the model integrates
adaptive class weighting, temporal consistency regularization, and hard-example
mining. The total loss is aggregated across all events. Extensive experiments
on Fakeddit, IND, and COVID-19 MISINFOGRAPH demonstrate that E-CaTCH
consistently outperforms state-of-the-art baselines. Cross-dataset evaluations
further demonstrate its robustness, generalizability, and practical
applicability across diverse misinformation scenarios.

</details>


### [20] [Cross-Granularity Hypergraph Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2508.11247)
*Changjian Wang,Weihong Deng,Weili Guan,Quan Lu,Ning Jiang*

Main category: cs.CL

TL;DR: HGRAG, a hypergraph-based RAG approach, improves multi-hop question answering by integrating structural and semantic information, achieving better performance and efficiency than existing methods.


<details>
  <summary>Details</summary>
Motivation: Traditional retrieval-augmented generation (RAG) methods primarily focus on coarse-grained textual semantic similarity and ignore structural associations among dispersed knowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods address this by leveraging knowledge graphs (KGs) to capture structural associations, but they tend to overly rely on structural information and fine-grained word- or phrase-level retrieval, resulting in an underutilization of textual semantics.

Method: A novel RAG approach called HGRAG for MHQA that achieves cross-granularity integration of structural and semantic information via hypergraphs. Structurally, an entity hypergraph is constructed where fine-grained entities serve as nodes and coarse-grained passages as hyperedges, and knowledge association is established through shared entities. Semantically, a hypergraph retrieval method is designed that integrates fine-grained entity similarity and coarse-grained passage similarity via hypergraph diffusion. A retrieval enhancement module is employed to further refine the retrieved results both semantically and structurally.

Result: The proposed HGRAG approach outperforms state-of-the-art methods in QA performance, and achieves a 6$\times$ speedup in retrieval efficiency.

Conclusion: HGRAG outperforms state-of-the-art methods in QA performance and achieves a 6x speedup in retrieval efficiency.

Abstract: Multi-hop question answering (MHQA) requires integrating knowledge scattered
across multiple passages to derive the correct answer. Traditional
retrieval-augmented generation (RAG) methods primarily focus on coarse-grained
textual semantic similarity and ignore structural associations among dispersed
knowledge, which limits their effectiveness in MHQA tasks. GraphRAG methods
address this by leveraging knowledge graphs (KGs) to capture structural
associations, but they tend to overly rely on structural information and
fine-grained word- or phrase-level retrieval, resulting in an underutilization
of textual semantics. In this paper, we propose a novel RAG approach called
HGRAG for MHQA that achieves cross-granularity integration of structural and
semantic information via hypergraphs. Structurally, we construct an entity
hypergraph where fine-grained entities serve as nodes and coarse-grained
passages as hyperedges, and establish knowledge association through shared
entities. Semantically, we design a hypergraph retrieval method that integrates
fine-grained entity similarity and coarse-grained passage similarity via
hypergraph diffusion. Finally, we employ a retrieval enhancement module, which
further refines the retrieved results both semantically and structurally, to
obtain the most relevant passages as context for answer generation with the
LLM. Experimental results on benchmark datasets demonstrate that our approach
outperforms state-of-the-art methods in QA performance, and achieves a
6$\times$ speedup in retrieval efficiency.

</details>


### [21] [UNVEILING: What Makes Linguistics Olympiad Puzzles Tricky for LLMs?](https://arxiv.org/abs/2508.11260)
*Mukund Choudhary,KV Aditya Srivatsa,Gaurja Aeron,Antara Raaghavi Bhattacharya,Dang Khoa Dang Dinh,Ikhlasul Akmal Hanif,Daria Kotova,Ekaterina Kochmar,Monojit Choudhury*

Main category: cs.CL

TL;DR: LLMs struggle with linguistic puzzles, especially those with high morphological complexity or low similarity to English. More informed tokenizers are needed.


<details>
  <summary>Details</summary>
Motivation: LLMs perform poorly on linguistics puzzles, which provide a minimal contamination environment to assess linguistic reasoning abilities across low-resource languages.

Method: Analyses LLMs' performance on 629 problems across 41 low-resource languages by labelling each with linguistically informed features.

Result: LLMs struggle with puzzles involving higher morphological complexity and perform better on puzzles involving linguistic features found in English. Splitting words into morphemes improves solvability.

Conclusion: LLMs struggle with puzzles involving higher morphological complexity and perform better on puzzles involving linguistic features that are also found in English. Splitting words into morphemes improves solvability, indicating a need for more informed and language-specific tokenisers. These findings offer insights into challenges in linguistic reasoning and modelling of low-resource languages.

Abstract: Large language models (LLMs) have demonstrated potential in reasoning tasks,
but their performance on linguistics puzzles remains consistently poor. These
puzzles, often derived from Linguistics Olympiad (LO) contests, provide a
minimal contamination environment to assess LLMs' linguistic reasoning
abilities across low-resource languages. This work analyses LLMs' performance
on 629 problems across 41 low-resource languages by labelling each with
linguistically informed features to unveil weaknesses. Our analyses show that
LLMs struggle with puzzles involving higher morphological complexity and
perform better on puzzles involving linguistic features that are also found in
English. We also show that splitting words into morphemes as a pre-processing
step improves solvability, indicating a need for more informed and
language-specific tokenisers. These findings thus offer insights into some
challenges in linguistic reasoning and modelling of low-resource languages.

</details>


### [22] [LETToT: Label-Free Evaluation of Large Language Models On Tourism Using Expert Tree-of-Thought](https://arxiv.org/abs/2508.11280)
*Ruiyan Qi,Congding Wen,Weibo Zhou,Shangsong Liang,Lingbo Li*

Main category: cs.CL

TL;DR: LETToT 是一种无标签评估框架，它利用专家推理结构来评估旅游领域的大型语言模型，避免了对注释基准的需求。


<details>
  <summary>Details</summary>
Motivation: 由于注释基准的成本过高以及诸如幻觉之类的问题持续存在，因此在旅游等特定领域评估大型语言模型 (LLM) 仍然具有挑战性。

Method: 我们提出了 LETToT，这是一个利用专家推导的推理结构（而不是标记数据）来访问旅游领域法学硕士的框架。

Result: 结果表明，我们系统优化的专家 ToT 的有效性比基线高 4.99-14.15% 的相对质量增益。我们将 LETToT 的优化专家 ToT 应用于评估不同规模的模型（32B-671B 参数），揭示了：（1）缩放定律仍然存在于专业领域（DeepSeek-V3 领先），但推理增强型较小模型（例如，DeepSeek-R1-Distill-Llama-70B）缩小了这一差距；(2) 对于低于 72B 的模型，显式推理架构在准确性和简洁性方面优于同类架构 (p<0.05)。

Conclusion: 这项工作建立了一个可扩展的、无标签的特定领域 LLM 评估范例，为传统的注释基准提供了一个强大的替代方案。

Abstract: Evaluating large language models (LLMs) in specific domain like tourism
remains challenging due to the prohibitive cost of annotated benchmarks and
persistent issues like hallucinations. We propose $\textbf{L}$able-Free
$\textbf{E}$valuation of LLM on $\textbf{T}$ourism using Expert
$\textbf{T}$ree-$\textbf{o}$f-$\textbf{T}$hought (LETToT), a framework that
leverages expert-derived reasoning structures-instead of labeled data-to access
LLMs in tourism. First, we iteratively refine and validate hierarchical ToT
components through alignment with generic quality dimensions and expert
feedback. Results demonstrate the effectiveness of our systematically optimized
expert ToT with 4.99-14.15\% relative quality gains over baselines. Second, we
apply LETToT's optimized expert ToT to evaluate models of varying scales
(32B-671B parameters), revealing: (1) Scaling laws persist in specialized
domains (DeepSeek-V3 leads), yet reasoning-enhanced smaller models (e.g.,
DeepSeek-R1-Distill-Llama-70B) close this gap; (2) For sub-72B models, explicit
reasoning architectures outperform counterparts in accuracy and conciseness
($p<0.05$). Our work established a scalable, label-free paradigm for
domain-specific LLM evaluation, offering a robust alternative to conventional
annotated benchmarks.

</details>


### [23] [ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection](https://arxiv.org/abs/2508.11281)
*Axel Delaval,Shujian Yang,Haicheng Wang,Han Qiu,Jialiang Lu*

Main category: cs.CL

TL;DR: TOXIFRENCH, a new French toxicity dataset, is introduced. Small language models outperform larger ones. A new fine-tuning strategy improves performance significantly.


<details>
  <summary>Details</summary>
Motivation: Toxicity detection in French is underdeveloped due to the lack of culturally relevant, large-scale datasets.

Method: A semi-automated annotation pipeline is used to construct a new public benchmark, TOXIFRENCH, of 53,622 French online comments. A novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic weighted loss is proposed.

Result: Small Language Models (SLMs) outperform many larger models in robustness and generalization. The fine-tuned 4B model improves its F1 score by 13% and outperforms LLMs. Strong multilingual ability is demonstrated.

Conclusion: A 4B model fine-tuned with a novel Chain-of-Thought strategy achieves state-of-the-art performance, improving its F1 score by 13% and outperforming LLMs. The methodology demonstrates strong multilingual ability.

Abstract: Detecting toxic content using language models is crucial yet challenging.
While substantial progress has been made in English, toxicity detection in
French remains underdeveloped, primarily due to the lack of culturally
relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new
public benchmark of 53,622 French online comments, constructed via a
semi-automated annotation pipeline that reduces manual labeling to only 10%
through high-confidence LLM-based pre-annotation and human verification. Then,
we benchmark a broad range of models and uncover a counterintuitive insight:
Small Language Models (SLMs) outperform many larger models in robustness and
generalization under the toxicity detection task. Motivated by this finding, we
propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic
weighted loss that progressively emphasizes the model's final decision,
significantly improving faithfulness. Our fine-tuned 4B model achieves
state-of-the-art performance, improving its F1 score by 13% over its baseline
and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a
cross-lingual toxicity benchmark demonstrates strong multilingual ability,
suggesting that our methodology can be effectively extended to other languages
and safety-critical classification tasks.

</details>


### [24] [AI in Mental Health: Emotional and Sentiment Analysis of Large Language Models' Responses to Depression, Anxiety, and Stress Queries](https://arxiv.org/abs/2508.11285)
*Arya VarastehNezhad,Reza Tavasoli,Soroush Elyasi,MohammadHossein LotfiNia,Hamed Farbeh*

Main category: cs.CL

TL;DR: 本研究调查了八个LLM如何回复关于抑郁、焦虑和压力的实际问题，发现模型选择和精神健康状况类型会显着影响情绪反应。


<details>
  <summary>Details</summary>
Motivation: 抑郁、焦虑和压力是广泛的心理健康问题，越来越多的人因此向大型语言模型（LLM）寻求信息。

Method: 使用最先进的工具对八个LLM生成的2,880个答案的情感和情绪进行评分。

Result: 乐观、恐惧和悲伤主导了所有输出的情感格局，中性情绪保持了一贯的高值。LLM的选择显着影响了情感表达模式。精神健康状况的类型极大地影响了情绪反应：焦虑提示引发了非常高的恐惧分数（0.974），抑郁提示产生了更高的悲伤（0.686）和最高的负面情绪，而与压力相关的查询产生了最乐观的反应（0.755），并带有更高的快乐和信任。相比之下，查询的人口统计框架仅在情绪基调上产生了细微的变化。

Conclusion: 模型选择在心理健康应用中至关重要，因为每个LLM都表现出独特的情感特征，这可能会显着影响用户体验和结果。

Abstract: Depression, anxiety, and stress are widespread mental health concerns that
increasingly drive individuals to seek information from Large Language Models
(LLMs). This study investigates how eight LLMs (Claude Sonnet, Copilot, Gemini
Pro, GPT-4o, GPT-4o mini, Llama, Mixtral, and Perplexity) reply to twenty
pragmatic questions about depression, anxiety, and stress when those questions
are framed for six user profiles (baseline, woman, man, young, old, and
university student). The models generated 2,880 answers, which we scored for
sentiment and emotions using state-of-the-art tools. Our analysis revealed that
optimism, fear, and sadness dominated the emotional landscape across all
outputs, with neutral sentiment maintaining consistently high values.
Gratitude, joy, and trust appeared at moderate levels, while emotions such as
anger, disgust, and love were rarely expressed. The choice of LLM significantly
influenced emotional expression patterns. Mixtral exhibited the highest levels
of negative emotions including disapproval, annoyance, and sadness, while Llama
demonstrated the most optimistic and joyful responses. The type of mental
health condition dramatically shaped emotional responses: anxiety prompts
elicited extraordinarily high fear scores (0.974), depression prompts generated
elevated sadness (0.686) and the highest negative sentiment, while
stress-related queries produced the most optimistic responses (0.755) with
elevated joy and trust. In contrast, demographic framing of queries produced
only marginal variations in emotional tone. Statistical analyses confirmed
significant model-specific and condition-specific differences, while
demographic influences remained minimal. These findings highlight the critical
importance of model selection in mental health applications, as each LLM
exhibits a distinct emotional signature that could significantly impact user
experience and outcomes.

</details>


### [25] [SafeConstellations: Steering LLM Safety to Reduce Over-Refusals Through Task-Specific Trajectory](https://arxiv.org/abs/2508.11290)
*Utsav Maskey,Sumit Yadav,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: LLMs refuse benign instructions. The paper introduces SafeConstellations, an inference-time trajectory-shifting approach that reduces over-refusal rates by up to 73% with minimal impact on utility.


<details>
  <summary>Details</summary>
Motivation: LLMs increasingly exhibit over-refusal behavior, diminishing utility in production applications.

Method: an inference-time trajectory-shifting approach that tracks task-specific trajectory patterns and guides representations toward non-refusal pathways

Result: LLMs still tend to refuse responses to harmful instructions when those instructions are reframed to appear as benign tasks. LLMs follow distinct constellation patterns in embedding space. SafeConstellations reduces over-refusal rates by up to 73% with minimal impact on utility.

Conclusion: SafeConstellations, an inference-time trajectory-shifting approach, reduces over-refusal rates by up to 73% with minimal impact on utility.

Abstract: LLMs increasingly exhibit over-refusal behavior, where safety mechanisms
cause models to reject benign instructions that superficially resemble harmful
content. This phenomena diminishes utility in production applications that
repeatedly rely on common prompt templates or applications that frequently rely
on LLMs for specific tasks (e.g. sentiment analysis, language translation).
Through comprehensive evaluation, we demonstrate that LLMs still tend to refuse
responses to harmful instructions when those instructions are reframed to
appear as benign tasks. Our mechanistic analysis reveal that LLMs follow
distinct "constellation" patterns in embedding space as representations
traverse layers, with each task maintaining consistent trajectories that shift
predictably between refusal and non-refusal cases. We introduce
SafeConstellations, an inference-time trajectory-shifting approach that tracks
task-specific trajectory patterns and guides representations toward non-refusal
pathways. By selectively guiding model behavior only on tasks prone to
over-refusal, and by preserving general model behavior, our method reduces
over-refusal rates by up to 73% with minimal impact on utility-offering a
principled approach to mitigating over-refusals.

</details>


### [26] [LLM Compression: How Far Can We Go in Balancing Size and Performance?](https://arxiv.org/abs/2508.11318)
*Sahil Sk,Debasish Dhal,Sonal Khosla,Sk Shahid,Sambit Shekhar,Akash Dhaka,Shantipriya Parida,Dilip K. Prasad,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本研究将4-bit GSQ和GPTQ应用于LLaMA 1B, Qwen 0.5B, 和 PHI 1.5B，以评估其在多个NLP任务中的影响。


<details>
  <summary>Details</summary>
Motivation: 量化是一种重要的通用技术，可以通过减少内存使用和计算成本来提高大型语言模型（LLM）的可访问性，同时保持性能。

Method: 将4-bit Group Scaling Quantization (GSQ)和Generative Pretrained Transformer Quantization (GPTQ)应用于LLaMA 1B, Qwen 0.5B, 和 PHI 1.5B。

Result: 在MS MARCO (信息检索), BoolQ (布尔问题回答), 和 GSM8K (数学推理)数据集上评估了这些模型，评估了跨各种任务的准确性和效率。这项研究衡量了模型压缩和任务性能之间的权衡，分析了关键的评估指标，即准确性、推理延迟和吞吐量（每秒生成的总输出tokens）。

Conclusion: 该研究讨论了GSQ和GPTQ技术在不同大小模型上的优缺点，为未来的实验提供基准。

Abstract: Quantization is an essential and popular technique for improving the
accessibility of large language models (LLMs) by reducing memory usage and
computational costs while maintaining performance. In this study, we apply
4-bit Group Scaling Quantization (GSQ) and Generative Pretrained Transformer
Quantization (GPTQ) to LLaMA 1B, Qwen 0.5B, and PHI 1.5B, evaluating their
impact across multiple NLP tasks. We benchmark these models on MS MARCO
(Information Retrieval), BoolQ (Boolean Question Answering), and GSM8K
(Mathematical Reasoning) datasets, assessing both accuracy and efficiency
across various tasks. The study measures the trade-offs between model
compression and task performance, analyzing key evaluation metrics, namely
accuracy, inference latency, and throughput (total output tokens generated per
second), providing insights into the suitability of low-bit quantization for
real-world deployment. Using the results, users can then make suitable
decisions based on the specifications that need to be met. We discuss the pros
and cons of GSQ and GPTQ techniques on models of different sizes, which also
serve as a benchmark for future experiments.

</details>


### [27] [SpecDetect: Simple, Fast, and Training-Free Detection of LLM-Generated Text via Spectral Analysis](https://arxiv.org/abs/2508.11343)
*Haitong Luo,Weiyao Zhang,Suhang Wang,Wenji Zou,Chungang Lin,Xuying Meng,Yujun Zhang*

Main category: cs.CL

TL;DR: This paper introduces SpecDetect and SpecDetect++, novel detectors for LLM-generated text based on frequency domain analysis of token log-probabilities. The approach outperforms state-of-the-art methods with improved efficiency.


<details>
  <summary>Details</summary>
Motivation: The proliferation of high-quality text from Large Language Models (LLMs) demands reliable and efficient detection methods. Existing training-free approaches often rely on surface-level statistics and overlook fundamental signal properties of the text generation process.

Method: The sequence of token log-probabilities in the frequency domain is analyzed using the global Discrete Fourier Transform (DFT) and the local Short-Time Fourier Transform (STFT). A detector built on a single, robust feature from the global DFT: DFT total energy, called SpecDetect, is constructed. An enhanced version, SpecDetect++, which incorporates a sampling discrepancy mechanism to further boost robustness, is also proposed.

Result: The proposed approach outperforms the state-of-the-art model while running in nearly half the time.

Conclusion: This work introduces a new, efficient, and interpretable pathway for LLM-generated text detection, showing that classical signal processing techniques offer a surprisingly powerful solution to this modern challenge.

Abstract: The proliferation of high-quality text from Large Language Models (LLMs)
demands reliable and efficient detection methods. While existing training-free
approaches show promise, they often rely on surface-level statistics and
overlook fundamental signal properties of the text generation process. In this
work, we reframe detection as a signal processing problem, introducing a novel
paradigm that analyzes the sequence of token log-probabilities in the frequency
domain. By systematically analyzing the signal's spectral properties using the
global Discrete Fourier Transform (DFT) and the local Short-Time Fourier
Transform (STFT), we find that human-written text consistently exhibits
significantly higher spectral energy. This higher energy reflects the
larger-amplitude fluctuations inherent in human writing compared to the
suppressed dynamics of LLM-generated text. Based on this key insight, we
construct SpecDetect, a detector built on a single, robust feature from the
global DFT: DFT total energy. We also propose an enhanced version,
SpecDetect++, which incorporates a sampling discrepancy mechanism to further
boost robustness. Extensive experiments demonstrate that our approach
outperforms the state-of-the-art model while running in nearly half the time.
Our work introduces a new, efficient, and interpretable pathway for
LLM-generated text detection, showing that classical signal processing
techniques offer a surprisingly powerful solution to this modern challenge.

</details>


### [28] [Feedback Indicators: The Alignment between Llama and a Teacher in Language Learning](https://arxiv.org/abs/2508.11364)
*Sylvio Rüdian,Yassin Elsir,Marvin Kretschmer,Sabine Cayrou,Niels Pinkwart*

Main category: cs.CL

TL;DR: This study examines the initial phase of extracting indicators from students' submissions of a language learning course using the large language model Llama 3.1 and demonstrates statistically significant strong correlations, even in cases involving unanticipated combinations of indicators and criteria.


<details>
  <summary>Details</summary>
Motivation: Automated feedback generation has the potential to enhance students' learning progress by providing timely and targeted feedback. Moreover, it can assist teachers in optimizing their time, allowing them to focus on more strategic and personalized aspects of teaching. To generate high-quality, information-rich formative feedback, it is essential first to extract relevant indicators, as these serve as the foundation upon which the feedback is constructed.

Method: extracting such indicators from students' submissions of a language learning course using the large language model Llama 3.1

Result: The findings demonstrate statistically significant strong correlations, even in cases involving unanticipated combinations of indicators and criteria.

Conclusion: The methodology employed in this paper offers a promising foundation for extracting indicators from students' submissions using LLMs. Such indicators can potentially be utilized to auto-generate explainable and transparent formative feedback in future research.

Abstract: Automated feedback generation has the potential to enhance students' learning
progress by providing timely and targeted feedback. Moreover, it can assist
teachers in optimizing their time, allowing them to focus on more strategic and
personalized aspects of teaching. To generate high-quality, information-rich
formative feedback, it is essential first to extract relevant indicators, as
these serve as the foundation upon which the feedback is constructed. Teachers
often employ feedback criteria grids composed of various indicators that they
evaluate systematically. This study examines the initial phase of extracting
such indicators from students' submissions of a language learning course using
the large language model Llama 3.1. Accordingly, the alignment between
indicators generated by the LLM and human ratings across various feedback
criteria is investigated. The findings demonstrate statistically significant
strong correlations, even in cases involving unanticipated combinations of
indicators and criteria. The methodology employed in this paper offers a
promising foundation for extracting indicators from students' submissions using
LLMs. Such indicators can potentially be utilized to auto-generate explainable
and transparent formative feedback in future research.

</details>


### [29] [When Punctuation Matters: A Large-Scale Comparison of Prompt Robustness Methods for LLMs](https://arxiv.org/abs/2508.11383)
*Mikhail Seleznyov,Mikhail Chaichuk,Gleb Ershov,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: This paper systematically evaluates 5 prompt robustness methods for LLMs, benchmarks them on various models and tasks, and provides insights for practitioners aiming for stable LLM performance.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) are highly sensitive to subtle, non-semantic variations in prompt phrasing and formatting.

Method: The authors present a systematic evaluation of 5 methods for improving prompt robustness within a unified experimental framework. They benchmark these techniques on 8 models across 52 tasks and test their generalization against multiple types of distribution shifts. The analysis is extended to GPT-4.1 and DeepSeek V3.

Result: The authors benchmarked robustness methods from both fine-tuned and in-context learning paradigms on Llama, Qwen and Gemma families across 52 tasks from Natural Instructions dataset.The evaluation covers robustness methods from both fine-tuned and in-context learning paradigms, and tests their generalization against multiple types of distribution shifts. The analysis is extended to GPT-4.1 and DeepSeek V3.

Conclusion: This paper provides actionable insights into the relative effectiveness of different prompt robustness methods, enabling practitioners to make informed decisions for stable and reliable LLM performance.

Abstract: Large Language Models (LLMs) are highly sensitive to subtle, non-semantic
variations in prompt phrasing and formatting. In this work, we present the
first systematic evaluation of 5 methods for improving prompt robustness within
a unified experimental framework. We benchmark these techniques on 8 models
from Llama, Qwen and Gemma families across 52 tasks from Natural Instructions
dataset. Our evaluation covers robustness methods from both fine-tuned and
in-context learning paradigms, and tests their generalization against multiple
types of distribution shifts. Finally, we extend our analysis to GPT-4.1 and
DeepSeek V3 to assess frontier models' current robustness to format
perturbations. Our findings offer actionable insights into the relative
effectiveness of these robustness methods, enabling practitioners to make
informed decisions when aiming for stable and reliable LLM performance in
real-world applications. Code:
https://github.com/AIRI-Institute/when-punctuation-matters.

</details>


### [30] [Retrieval-augmented reasoning with lean language models](https://arxiv.org/abs/2508.11386)
*Ryan Sze-Yin Chan,Federico Nanni,Tomas Lazauskas,Rosie Wood,Penelope Yong,Lionel Tarassenko,Mark Girolami,James Geddes,Andrew Duncan*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的方法，将推理和检索增强生成（RAG）结合在单个精简的语言模型架构中，在领域特定任务上实现了接近前沿水平的性能，同时保持了本地部署的可行性。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限或安全环境中可部署的高性能和保护隐私的解决方案的需求日益增长的问题。

Method: 该系统集成了密集检索器与微调的 Qwen2.5-Instruct 模型，使用合成查询生成和从前沿模型（例如，DeepSeek-R1）导出的推理跟踪，这些模型基于精选的语料库（在本例中为 NHS A-to-Z 条件页面）。

Result: 针对非推理和通用精简模型的评估表明，该论文提出的领域特定微调方法在答案准确性和一致性方面取得了显著提高。

Conclusion: 该论文提出的领域特定微调方法在答案准确性和一致性方面取得了显著提高，接近前沿水平的性能，同时对于本地部署是可行的。所有实现细节和代码已公开发布，以支持跨领域的重现和改编。

Abstract: This technical report details a novel approach to combining reasoning and
retrieval augmented generation (RAG) within a single, lean language model
architecture. While existing RAG systems typically rely on large-scale models
and external APIs, our work addresses the increasing demand for performant and
privacy-preserving solutions deployable in resource-constrained or secure
environments. Building on recent developments in test-time scaling and
small-scale reasoning models, we develop a retrieval augmented conversational
agent capable of interpreting complex, domain-specific queries using a
lightweight backbone model. Our system integrates a dense retriever with
fine-tuned Qwen2.5-Instruct models, using synthetic query generation and
reasoning traces derived from frontier models (e.g., DeepSeek-R1) over a
curated corpus, in this case, the NHS A-to-Z condition pages. We explore the
impact of summarisation-based document compression, synthetic data design, and
reasoning-aware fine-tuning on model performance. Evaluation against both
non-reasoning and general-purpose lean models demonstrates that our
domain-specific fine-tuning approach yields substantial gains in answer
accuracy and consistency, approaching frontier-level performance while
remaining feasible for local deployment. All implementation details and code
are publicly released to support reproducibility and adaptation across domains.

</details>


### [31] [Model Interpretability and Rationale Extraction by Input Mask Optimization](https://arxiv.org/abs/2508.11388)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: 提出了一种新的方法来生成神经预测的提取式解释网络，它基于掩盖模型不认为是相应类别的指示的输入部分。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理和计算机视觉等领域中基于神经网络的模型的快速发展，对这些黑盒模型的预测创建解释的需求稳步上升。

Method: 基于掩蔽输入部分的新方法，该模型不认为这些部分是指示相应类别。

Result: 我们弥合了模型可解释性和基本原理提取之间的差距，从而证明了后者可以在不训练专用模型的情况下执行，仅在训练有素的分类器的基础上进行。

Conclusion: 该方法可以应用于图像输入，并获得高质量的图像分类解释，这表明为自然语言处理中的基本原理提取提出的条件更广泛地适用于不同的输入类型。

Abstract: Concurrent to the rapid progress in the development of neural-network based
models in areas like natural language processing and computer vision, the need
for creating explanations for the predictions of these black-box models has
risen steadily. We propose a new method to generate extractive explanations for
predictions made by neural networks, that is based on masking parts of the
input which the model does not consider to be indicative of the respective
class. The masking is done using gradient-based optimization combined with a
new regularization scheme that enforces sufficiency, comprehensiveness and
compactness of the generated explanation, three properties that are known to be
desirable from the related field of rationale extraction in natural language
processing. In this way, we bridge the gap between model interpretability and
rationale extraction, thereby proving that the latter of which can be performed
without training a specialized model, only on the basis of a trained
classifier. We further apply the same method to image inputs and obtain high
quality explanations for image classifications, which indicates that the
conditions proposed for rationale extraction in natural language processing are
more broadly applicable to different input types.

</details>


### [32] [Rationalizing Transformer Predictions via End-To-End Differentiable Self-Training](https://arxiv.org/abs/2508.11393)
*Marc Brinner,Sina Zarrieß*

Main category: cs.CL

TL;DR: The paper introduces a more efficient and stable way to train rationalized transformer classifiers, achieving better alignment with human annotations.


<details>
  <summary>Details</summary>
Motivation: Existing approaches for training rationalized models suffer from training instabilities.

Method: The paper proposes an end-to-end differentiable training paradigm for a rationalized transformer classifier, building on the three-player-game approach.

Result: The proposed paradigm achieves state-of-the-art alignment with human annotations without explicit supervision and produces class-wise rationales.

Conclusion: This paper simplifies the training of rationalized models by using a single model for all three roles (rationale selector, classifier, and complement classifier), leading to more efficient training and improved stability.

Abstract: We propose an end-to-end differentiable training paradigm for stable training
of a rationalized transformer classifier. Our approach results in a single
model that simultaneously classifies a sample and scores input tokens based on
their relevance to the classification. To this end, we build on the widely-used
three-player-game for training rationalized models, which typically relies on
training a rationale selector, a classifier and a complement classifier. We
simplify this approach by making a single model fulfill all three roles,
leading to a more efficient training paradigm that is not susceptible to the
common training instabilities that plague existing approaches. Further, we
extend this paradigm to produce class-wise rationales while incorporating
recent advances in parameterizing and regularizing the resulting rationales,
thus leading to substantially improved and state-of-the-art alignment with
human annotations without any explicit supervision.

</details>


### [33] [Survey-to-Behavior: Downstream Alignment of Human Values in LLMs via Survey Questions](https://arxiv.org/abs/2508.11414)
*Shangrui Nie,Florian Mai,David Kaczér,Charles Welch,Zhixue Zhao,Lucie Flek*

Main category: cs.CL

TL;DR: 通过在价值调查上进行微调，可以有效地调整大型语言模型的价值观，并影响其在各种任务中的行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型隐含地编码了对人类价值观的偏好，但对其进行引导通常需要大量的训练数据。

Method: 通过在价值调查上微调大型语言模型，然后评估其在领域内和领域外的行为变化。

Result: 简单的微调方法不仅可以改变模型对领域内调查问题的回答，还可以使其在下游任务行为中产生显著的价值对齐。

Conclusion: 通过在价值调查上进行微调，可以改变模型在下游任务中的行为。

Abstract: Large language models implicitly encode preferences over human values, yet
steering them often requires large training data. In this work, we investigate
a simple approach: Can we reliably modify a model's value system in downstream
behavior by training it to answer value survey questions accordingly? We first
construct value profiles of several open-source LLMs by asking them to rate a
series of value-related descriptions spanning 20 distinct human values, which
we use as a baseline for subsequent experiments. We then investigate whether
the value system of a model can be governed by fine-tuning on the value
surveys. We evaluate the effect of finetuning on the model's behavior in two
ways; first, we assess how answers change on in-domain, held-out survey
questions. Second, we evaluate whether the model's behavior changes in
out-of-domain settings (situational scenarios). To this end, we construct a
contextualized moral judgment dataset based on Reddit posts and evaluate
changes in the model's behavior in text-based adventure games. We demonstrate
that our simple approach can not only change the model's answers to in-domain
survey questions, but also produces substantial shifts (value alignment) in
implicit downstream task behavior.

</details>


### [34] [HumorPlanSearch: Structured Planning and HuCoT for Contextual AI Humor](https://arxiv.org/abs/2508.11429)
*Shivam Dubey*

Main category: cs.CL

TL;DR: HumorPlanSearch is introduced to address the issue that Automated humor generation with LLMs often yields jokes that feel generic, repetitive, or tone-deaf. The pipeline explicitly models context and advances AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.


<details>
  <summary>Details</summary>
Motivation: Automated humor generation with Large Language Models (LLMs) often yields jokes that feel generic, repetitive, or tone-deaf because humor is deeply situated and hinges on the listener's cultural background, mindset, and immediate context.

Method: HumorPlanSearch, a modular pipeline that explicitly models context through: (1) Plan-Search for diverse, topic-tailored strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt high-performing historical strategies; (4) novelty filtering via semantic embeddings; and (5) an iterative judge-driven revision loop.

Result: full pipeline (KG + Revision) boosts mean HGS by 15.4 percent (p < 0.05) over a strong baseline.In experiments across nine topics with feedback from 13 human judges

Conclusion: HumorPlanSearch advances AI-driven humor toward more coherent, adaptive, and culturally attuned comedy by foregrounding context at every stage.

Abstract: Automated humor generation with Large Language Models (LLMs) often yields
jokes that feel generic, repetitive, or tone-deaf because humor is deeply
situated and hinges on the listener's cultural background, mindset, and
immediate context. We introduce HumorPlanSearch, a modular pipeline that
explicitly models context through: (1) Plan-Search for diverse, topic-tailored
strategies; (2) Humor Chain-of-Thought (HuCoT) templates capturing cultural and
stylistic reasoning; (3) a Knowledge Graph to retrieve and adapt
high-performing historical strategies; (4) novelty filtering via semantic
embeddings; and (5) an iterative judge-driven revision loop. To evaluate
context sensitivity and comedic quality, we propose the Humor Generation Score
(HGS), which fuses direct ratings, multi-persona feedback, pairwise win-rates,
and topic relevance. In experiments across nine topics with feedback from 13
human judges, our full pipeline (KG + Revision) boosts mean HGS by 15.4 percent
(p < 0.05) over a strong baseline. By foregrounding context at every stage from
strategy planning to multi-signal evaluation, HumorPlanSearch advances
AI-driven humor toward more coherent, adaptive, and culturally attuned comedy.

</details>


### [35] [Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse](https://arxiv.org/abs/2508.11434)
*Aditi Dutta,Susan Banducci*

Main category: cs.CL

TL;DR: 大型语言模型在区分反性别歧视言论和性别歧视言论方面存在困难，尤其是在政治敏感事件期间，这可能会导致对反性别歧视言论的错误分类和边缘化群体的噤声。


<details>
  <summary>Details</summary>
Motivation: 反性别歧视言论在塑造在线民主辩论中起着至关重要的作用。然而，越来越多的由大型语言模型驱动的自动化内容审核系统，可能难以区分这种抵制与它所反对的性别歧视。

Method: 通过研究，着重关注2022年涉及英国女性议员的高关注度触发事件，考察了五个大型语言模型如何对英国的性别歧视、反性别歧视和中立的政治推文进行分类。

Result: 模型经常错误地将反性别歧视言论归类为有害言论，尤其是在具有政治色彩的事件中，有害言论和抵制言论的修辞风格趋于一致。这些错误可能会使那些挑战性别歧视的人噤声，并对边缘化群体产生 disproportionate 的后果。

Conclusion: 内容审核设计必须超越二元有害/无害模式，在敏感事件中整合人工参与的审查，并在训练数据中明确包含反击言论。

Abstract: Anti-sexist speech, i.e., public expressions that challenge or resist
gendered abuse and sexism, plays a vital role in shaping democratic debate
online. Yet automated content moderation systems, increasingly powered by large
language models (LLMs), may struggle to distinguish such resistance from the
sexism it opposes. This study examines how five LLMs classify sexist,
anti-sexist, and neutral political tweets from the UK, focusing on
high-salience trigger events involving female Members of Parliament in the year
2022. Our analysis show that models frequently misclassify anti-sexist speech
as harmful, particularly during politically charged events where rhetorical
styles of harm and resistance converge. These errors risk silencing those who
challenge sexism, with disproportionate consequences for marginalised voices.
We argue that moderation design must move beyond binary harmful/not-harmful
schemas, integrate human-in-the-loop review during sensitive events, and
explicitly include counter-speech in training data. By linking feminist
scholarship, event-based analysis, and model evaluation, this work highlights
the sociotechnical challenges of safeguarding resistance speech in digital
political spaces.

</details>


### [36] [CoDiEmb: A Collaborative yet Distinct Framework for Unified Representation Learning in Information Retrieval and Semantic Textual Similarity](https://arxiv.org/abs/2508.11442)
*Bowen Zhang,Zixin Song,Chunquan Chen,Qian-Wen Zhang,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: CoDiEmb是一个统一的框架，它通过任务专用目标、delta引导的模型融合策略和高效的单阶段训练管道来调和IR和STS的不同需求，从而缓解跨任务的权衡并改善嵌入空间的几何特性。


<details>
  <summary>Details</summary>
Motivation: 在表征学习中，学习在各种下游任务中表现出色的统一文本嵌入是一个中心目标，但负迁移仍然是一个持续存在的障碍。当为信息检索(IR)和语义文本相似性(STS)联合训练单个编码器时，这种挑战尤其明显，信息检索(IR)和语义文本相似性(STS)是两个重要但根本不同的任务，对于这两个任务，简单的协同训练通常会产生陡峭的性能权衡。

Method: CoDiEmb，一个统一的框架，以协作但独特的方式协调了IR和STS的不同需求。CoDiEmb集成了三个关键创新点：(1) 任务专用目标与动态采样器配对，形成单任务批次并平衡每个任务的更新，从而防止梯度干扰。(2) 一种delta引导的模型融合策略，通过分析每个参数与其预训练初始化的偏差来计算检查点的细粒度合并权重。(3) 一种高效的单阶段训练管道，易于实现且稳定收敛。

Result: 在三个基本编码器的15个标准IR和STS基准上进行了广泛的实验验证了CoDiEmb。结果和分析表明，

Conclusion: CoDiEmb框架不仅缓解了跨任务的权衡，而且明显改善了嵌入空间的几何特性。

Abstract: Learning unified text embeddings that excel across diverse downstream tasks
is a central goal in representation learning, yet negative transfer remains a
persistent obstacle. This challenge is particularly pronounced when jointly
training a single encoder for Information Retrieval (IR) and Semantic Textual
Similarity (STS), two essential but fundamentally disparate tasks for which
naive co-training typically yields steep performance trade-offs. We argue that
resolving this conflict requires systematically decoupling task-specific
learning signals throughout the training pipeline. To this end, we introduce
CoDiEmb, a unified framework that reconciles the divergent requirements of IR
and STS in a collaborative yet distinct manner. CoDiEmb integrates three key
innovations for effective joint optimization: (1) Task-specialized objectives
paired with a dynamic sampler that forms single-task batches and balances
per-task updates, thereby preventing gradient interference. For IR, we employ a
contrastive loss with multiple positives and hard negatives, augmented by
cross-device sampling. For STS, we adopt order-aware objectives that directly
optimize correlation and ranking consistency. (2) A delta-guided model fusion
strategy that computes fine-grained merging weights for checkpoints by
analyzing each parameter's deviation from its pre-trained initialization,
proving more effective than traditional Model Soups. (3) An efficient,
single-stage training pipeline that is simple to implement and converges
stably. Extensive experiments on 15 standard IR and STS benchmarks across three
base encoders validate CoDiEmb. Our results and analysis demonstrate that the
framework not only mitigates cross-task trade-offs but also measurably improves
the geometric properties of the embedding space.

</details>


### [37] [Reference Points in LLM Sentiment Analysis: The Role of Structured Context](https://arxiv.org/abs/2508.11454)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 本研究探讨了补充信息的内容和格式如何影响使用 LLM 的情绪分析，结果表明，JSON 格式的提示效果更好，且结构化提示可以使较小的模型获得有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 大多数 NLP 研究仅从评论文本中对情绪进行分类，营销理论表明，客户评价不仅受实际体验的影响，还受其他参考点的影响。因此，本研究调查了补充信息的内容和格式如何影响使用 LLM 的情绪分析。

Method: 比较自然语言 (NL) 和 JSON 格式的提示，使用适用于实际营销应用的轻量级 3B 参数模型。

Result: 在两个 Yelp 类别（餐厅和夜生活）上的实验表明，具有附加信息的 JSON 提示优于所有基线，无需微调：Macro-F1 分别上升 1.6% 和 4%，而 RMSE 分别下降 16% 和 9.1%，使其可部署在资源受限的边缘设备中。

Conclusion: 结构化提示可以使较小的模型获得有竞争力的性能，为大规模模型部署提供了一种可行的替代方案。

Abstract: Large language models (LLMs) are now widely used across many fields,
including marketing research. Sentiment analysis, in particular, helps firms
understand consumer preferences. While most NLP studies classify sentiment from
review text alone, marketing theories, such as prospect theory and
expectation--disconfirmation theory, point out that customer evaluations are
shaped not only by the actual experience but also by additional reference
points. This study therefore investigates how the content and format of such
supplementary information affect sentiment analysis using LLMs. We compare
natural language (NL) and JSON-formatted prompts using a lightweight 3B
parameter model suitable for practical marketing applications. Experiments on
two Yelp categories (Restaurant and Nightlife) show that the JSON prompt with
additional information outperforms all baselines without fine-tuning: Macro-F1
rises by 1.6% and 4% while RMSE falls by 16% and 9.1%, respectively, making it
deployable in resource-constrained edge devices. Furthermore, a follow-up
analysis confirms that performance gains stem from genuine contextual reasoning
rather than label proxying. This work demonstrates that structured prompting
can enable smaller models to achieve competitive performance, offering a
practical alternative to large-scale model deployment.

</details>


### [38] [Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models](https://arxiv.org/abs/2508.11534)
*Monika Jotautaitė,Lucius Caviola,David A. Brewster,Thilo Hagendorff*

Main category: cs.CL

TL;DR: LLMs exhibit speciesist bias, reproducing cultural norms of animal exploitation. AI fairness frameworks should include non-human moral patients to reduce these biases.


<details>
  <summary>Details</summary>
Motivation: It is crucial to examine the ethical tendencies of LLMs, specifically speciesist bias and how they value non-human animals as LLMs become more widely deployed.

Method: Systematic examination across three paradigms: SpeciesismBench benchmark, established psychological measures comparing model responses with those of human participants, and text-generation tasks probing elaboration on, or resistance to, speciesist rationalizations.

Result: LLMs reliably detected speciesist statements but rarely condemned them, expressed slightly lower explicit speciesism than people but more often chose to save one human over multiple animals in direct trade-offs, and frequently normalized or rationalized harm toward farmed animals.

Conclusion: LLMs reproduce cultural norms around animal exploitation, highlighting the need to expand AI fairness frameworks to include non-human moral patients.

Abstract: As large language models (LLMs) become more widely deployed, it is crucial to
examine their ethical tendencies. Building on research on fairness and
discrimination in AI, we investigate whether LLMs exhibit speciesist bias --
discrimination based on species membership -- and how they value non-human
animals. We systematically examine this issue across three paradigms: (1)
SpeciesismBench, a 1,003-item benchmark assessing recognition and moral
evaluation of speciesist statements; (2) established psychological measures
comparing model responses with those of human participants; (3) text-generation
tasks probing elaboration on, or resistance to, speciesist rationalizations. In
our benchmark, LLMs reliably detected speciesist statements but rarely
condemned them, often treating speciesist attitudes as morally acceptable. On
psychological measures, results were mixed: LLMs expressed slightly lower
explicit speciesism than people, yet in direct trade-offs they more often chose
to save one human over multiple animals. A tentative interpretation is that
LLMs may weight cognitive capacity rather than species per se: when capacities
were equal, they showed no species preference, and when an animal was described
as more capable, they tended to prioritize it over a less capable human. In
open-ended text generation tasks, LLMs frequently normalized or rationalized
harm toward farmed animals while refusing to do so for non-farmed animals.
These findings suggest that while LLMs reflect a mixture of progressive and
mainstream human views, they nonetheless reproduce entrenched cultural norms
around animal exploitation. We argue that expanding AI fairness and alignment
frameworks to explicitly include non-human moral patients is essential for
reducing these biases and preventing the entrenchment of speciesist attitudes
in AI systems and the societies they influence.

</details>


### [39] [Language models align with brain regions that represent concepts across modalities](https://arxiv.org/abs/2508.11536)
*Maria Ryskina,Greta Tuckute,Alexander Fung,Ashley Malkin,Evelina Fedorenko*

Main category: cs.CL

TL;DR: 语言模型可能以跨模态方式表示意义。


<details>
  <summary>Details</summary>
Motivation: 认知科学和神经科学长期面临着区分语言表征和概念意义表征的挑战。同样的问题也出现在今天的语言模型（LM）中。

Method: 使用fMRI数据集，量化大脑区域对跨范式相同概念的反应一致性。

Result: 语言模型在意义一致性更高的脑区中更好地预测信号，即使这些区域对语言处理不敏感。

Conclusion: 语言模型可能在内部表示跨模态概念意义。

Abstract: Cognitive science and neuroscience have long faced the challenge of
disentangling representations of language from representations of conceptual
meaning. As the same problem arises in today's language models (LMs), we
investigate the relationship between LM--brain alignment and two neural
metrics: (1) the level of brain activation during processing of sentences,
targeting linguistic processing, and (2) a novel measure of meaning consistency
across input modalities, which quantifies how consistently a brain region
responds to the same concept across paradigms (sentence, word cloud, image)
using an fMRI dataset (Pereira et al., 2018). Our experiments show that both
language-only and language-vision models predict the signal better in more
meaning-consistent areas of the brain, even when these areas are not strongly
sensitive to language processing, suggesting that LMs might internally
represent cross-modal conceptual meaning.

</details>


### [40] [AgentMental: An Interactive Multi-Agent Framework for Explainable and Adaptive Mental Health Assessment](https://arxiv.org/abs/2508.11567)
*Jinpeng Hu,Ao Wang,Qianqian Xie,Hui Ma,Zhuo Li,Dan Guo*

Main category: cs.CL

TL;DR: A multi-agent framework with adaptive questioning and tree-structured memory is proposed for automated mental health evaluation, achieving better performance than existing methods.


<details>
  <summary>Details</summary>
Motivation: Traditional clinician-based mental health assessment approaches are limited by the shortage of qualified professionals, and most existing AI approaches are constrained by their reliance on static text analysis.

Method: A multi-agent framework for mental health evaluation that simulates clinical doctor-patient dialogues, with specialized agents assigned to questioning, adequacy evaluation, scoring, and updating. An adaptive questioning mechanism and a tree-structured memory are introduced.

Result: The proposed method achieves better performance than existing approaches on the DAIC-WOZ dataset.

Conclusion: The proposed multi-agent framework achieves better performance than existing approaches on the DAIC-WOZ dataset.

Abstract: Mental health assessment is crucial for early intervention and effective
treatment, yet traditional clinician-based approaches are limited by the
shortage of qualified professionals. Recent advances in artificial intelligence
have sparked growing interest in automated psychological assessment, yet most
existing approaches are constrained by their reliance on static text analysis,
limiting their ability to capture deeper and more informative insights that
emerge through dynamic interaction and iterative questioning. Therefore, in
this paper, we propose a multi-agent framework for mental health evaluation
that simulates clinical doctor-patient dialogues, with specialized agents
assigned to questioning, adequacy evaluation, scoring, and updating. We
introduce an adaptive questioning mechanism in which an evaluation agent
assesses the adequacy of user responses to determine the necessity of
generating targeted follow-up queries to address ambiguity and missing
information. Additionally, we employ a tree-structured memory in which the root
node encodes the user's basic information, while child nodes (e.g., topic and
statement) organize key information according to distinct symptom categories
and interaction turns. This memory is dynamically updated throughout the
interaction to reduce redundant questioning and further enhance the information
extraction and contextual tracking capabilities. Experimental results on the
DAIC-WOZ dataset illustrate the effectiveness of our proposed method, which
achieves better performance than existing approaches.

</details>


### [41] [Aware First, Think Less: Dynamic Boundary Self-Awareness Drives Extreme Reasoning Efficiency in Large Language Models](https://arxiv.org/abs/2508.11582)
*Qiguang Chen,Dengyun Peng,Jinhao Liu,HuiKang Su,Jiannan Guan,Libo Qin,Wanxiang Che*

Main category: cs.CL

TL;DR: This paper introduces DR. SAF, a framework that enables models to dynamically assess and adjust their reasoning depth in response to problem complexity, improving efficiency and accuracy.


<details>
  <summary>Details</summary>
Motivation: To improve the efficiency of LLMs on complex reasoning tasks, current methods often rely on human-defined difficulty priors, which do not align with the LLM's self-awared difficulty, leading to inefficiencies.

Method: Dynamic Reasoning-Boundary Self-Awareness Framework (DR. SAF)

Result: DR. SAF can even surpass traditional instruction-based models in token efficiency with more than 16% accuracy improvement.

Conclusion: DR. SAF achieves a 49.27% reduction in total response tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain in token efficiency and a 5x reduction in training time

Abstract: Recent advancements in large language models (LLMs) have greatly improved
their capabilities on complex reasoning tasks through Long Chain-of-Thought
(CoT). However, this approach often results in substantial redundancy,
impairing computational efficiency and causing significant delays in real-time
applications. To improve the efficiency, current methods often rely on
human-defined difficulty priors, which do not align with the LLM's self-awared
difficulty, leading to inefficiencies. In this paper, we introduce the Dynamic
Reasoning-Boundary Self-Awareness Framework (DR. SAF), which enables models to
dynamically assess and adjust their reasoning depth in response to problem
complexity. DR. SAF integrates three key components: Boundary Self-Awareness
Alignment, Adaptive Reward Management, and a Boundary Preservation Mechanism.
These components allow models to optimize their reasoning processes, balancing
efficiency and accuracy without compromising performance. Our experimental
results demonstrate that DR. SAF achieves a 49.27% reduction in total response
tokens with minimal loss in accuracy. The framework also delivers a 6.59x gain
in token efficiency and a 5x reduction in training time, making it well-suited
to resource-limited settings. During extreme training, DR. SAF can even surpass
traditional instruction-based models in token efficiency with more than 16%
accuracy improvement.

</details>


### [42] [Representing Speech Through Autoregressive Prediction of Cochlear Tokens](https://arxiv.org/abs/2508.11598)
*Greta Tuckute,Klemen Kotar,Evelina Fedorenko,Daniel L. K. Yamins*

Main category: cs.CL

TL;DR: 提出了一种受生物学启发的语音编码模型 AuriStream，该模型通过一个两阶段框架将语音转换为有意义的表征，并在各种语音任务上表现出竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 为了开发更像人类的模型，可以有效地处理各种基于语音的任务。

Method: 通过受人耳蜗启发的两阶段框架，将原始音频转换为基于人耳蜗的时频表示，从中提取离散的耳蜗标记，然后在耳蜗标记上应用自回归序列模型。

Result: AuriStream 学习了有意义的音素和单词表示，以及最先进的词汇语义。AuriStream 在各种下游 SUPERB 语音任务上表现出有竞争力的性能。它可以生成音频的延续，这些延续可以在频谱图中可视化并解码回音频，从而深入了解模型的预测。

Conclusion: 提出了一种用于语音表征学习的两阶段框架，以推进更类人模型的开发，从而有效地处理各种基于语音的任务。

Abstract: We introduce AuriStream, a biologically inspired model for encoding speech
via a two-stage framework inspired by the human auditory processing hierarchy.
The first stage transforms raw audio into a time-frequency representation based
on the human cochlea, from which we extract discrete \textbf{cochlear tokens}.
The second stage applies an autoregressive sequence model over the cochlear
tokens. AuriStream learns meaningful phoneme and word representations, and
state-of-the-art lexical semantics. AuriStream shows competitive performance on
diverse downstream SUPERB speech tasks. Complementing AuriStream's strong
representational capabilities, it generates continuations of audio which can be
visualized in a spectrogram space and decoded back into audio, providing
insights into the model's predictions. In summary, we present a two-stage
framework for speech representation learning to advance the development of more
human-like models that efficiently handle a range of speech-based tasks.

</details>


### [43] [Dataset Creation for Visual Entailment using Generative AI](https://arxiv.org/abs/2508.11605)
*Rob Reijtenbach,Suzan Verberne,Gijs Wijnholds*

Main category: cs.CL

TL;DR: 本文提出了一种新的合成数据集，用于训练视觉蕴涵模型，该数据集通过Stable Diffusion从SNLI文本生成图像，实验表明该数据集在数据稀疏的情况下有效。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉蕴涵数据集与文本蕴涵数据集相比，规模较小且稀疏，手动创建数据集劳动强度大。

Method: 基于SNLI数据集，使用Stable Diffusion生成图像来创建合成数据集，并用CLIP特征向量训练视觉蕴涵分类器。

Result: 在SNLI-VE和SICK-VTE数据集上，使用合成数据训练的模型与使用真实数据训练的模型相比，F-score略有下降，分别为0.686 vs 0.703和0.384 vs 0.400。

Conclusion: 在数据稀疏的情况下，合成数据可以作为训练视觉蕴涵模型的一个有希望的解决方案。

Abstract: In this paper we present and validate a new synthetic dataset for training
visual entailment models. Existing datasets for visual entailment are small and
sparse compared to datasets for textual entailment. Manually creating datasets
is labor-intensive. We base our synthetic dataset on the SNLI dataset for
textual entailment. We take the premise text from SNLI as input prompts in a
generative image model, Stable Diffusion, creating an image to replace each
textual premise. We evaluate our dataset both intrinsically and extrinsically.
For extrinsic evaluation, we evaluate the validity of the generated images by
using them as training data for a visual entailment classifier based on CLIP
feature vectors. We find that synthetic training data only leads to a slight
drop in quality on SNLI-VE, with an F-score 0.686 compared to 0.703 when
trained on real data. We also compare the quality of our generated training
data to original training data on another dataset: SICK-VTE. Again, there is
only a slight drop in F-score: from 0.400 to 0.384. These results indicate that
in settings with data sparsity, synthetic data can be a promising solution for
training visual entailment models.

</details>


### [44] [TinyTim: A Family of Language Models for Divergent Generation](https://arxiv.org/abs/2508.11607)
*Christopher J. Agostino*

Main category: cs.CL

TL;DR: TinyTim, LLM family fine-tuned on `Finnegans Wake', exhibits high lexical diversity and low semantic coherence, useful as divergent knowledge sources for creative tasks.


<details>
  <summary>Details</summary>
Motivation: specialized models can function as divergent knowledge sources within more extensive creative architectures, powering automated discovery mechanisms in diverse settings.

Method: fine-tuned on James Joyce's `Finnegans Wake`

Result: demonstrate that TinyTim V1 produces a statistically distinct generative profile characterized by high lexical diversity and low semantic coherence.

Conclusion: TinyTim V1 produces a statistically distinct generative profile characterized by high lexical diversity and low semantic coherence.

Abstract: This work introduces TinyTim, a family of large language models fine-tuned on
James Joyce's `Finnegans Wake'. Through quantitative evaluation against
baseline models, we demonstrate that TinyTim V1 produces a statistically
distinct generative profile characterized by high lexical diversity and low
semantic coherence. These findings are interpreted through theories of
creativity and complex problem-solving, arguing that such specialized models
can function as divergent knowledge sources within more extensive creative
architectures, powering automated discovery mechanisms in diverse settings.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

TL;DR: 我们提出了一种隐私增强机制，用于注视信号，该机制使用潜在噪声自编码器，可防止用户被重新识别，同时保持数据的可用性。


<details>
  <summary>Details</summary>
Motivation: 防止用户在未经他们同意的情况下跨游戏会话被重新识别。

Method: 使用潜在噪声自编码器

Result: 我们的方法显著降低了生物识别的可识别性，同时最大限度地减少了效用降低。

Conclusion: 这项工作通过提供一种可用且有效的机制来保护敏感的注视数据，从而推进了基于注视的系统中的隐私。

Abstract: We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [46] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

TL;DR: This survey reviews video temporal grounding approaches based on MLLMs (VTG-MLLMs), categorizing them by MLLM roles, training paradigms, and video feature processing. It discusses benchmarks, evaluations, and future research directions.


<details>
  <summary>Details</summary>
Motivation: Comprehensive reviews specifically addressing VTG-MLLMs remain scarce.

Method: This survey systematically examines current research on VTG-MLLMs through a three-dimensional taxonomy: 1) the functional roles of MLLMs, highlighting their architectural significance; 2) training paradigms, analyzing strategies for temporal reasoning and task adaptation; and 3) video feature processing techniques, which determine spatiotemporal representation effectiveness. The survey further discusses benchmark datasets, evaluation protocols, and summarizes empirical findings.

Result: This survey systematically examines current research on VTG-MLLMs.

Conclusion: This survey identifies limitations of current video temporal grounding approaches based on MLLMs and proposes promising research directions.

Abstract: The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [47] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: VSF通过翻转负面提示的注意力值来抑制不需要的内容，从而改进了图像和视频生成模型中的负面提示遵循度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如无分类器指导 (CFG)、NASA 和 NAG）不同，VSF 通过翻转来自负面提示的注意力值的符号来动态抑制不需要的内容。

Method: 引入价值符号翻转 (VSF)，这是一种简单有效的方法，用于在少步扩散和流匹配图像生成模型中结合负面提示指导。

Result: 在具有复杂提示对的具有挑战性的数据集上验证了 VSF，并证明了其在静态图像和视频生成任务中的卓越性能。实验结果表明

Conclusion: VSF显著提高了少步模型（甚至非少步模型中的CFG）中负面提示的遵循度，同时保持了有竞争力的图像质量。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [48] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

TL;DR: This paper introduces a PAE-based RPR method to refine APR, improving camera localization accuracy with less training data.


<details>
  <summary>Details</summary>
Motivation: Accurate camera localization is crucial for retail, enabling enhanced customer experiences, streamlined inventory management, and autonomous operations. Visual and spatial scene priors can improve the accuracy of Absolute Pose Regression (APR).

Method: Extending Camera Pose Auto-Encoders (PAEs) to Relative Pose Regression (RPR) and using it to refine Absolute Pose Regression (APR) predictions.

Result: PAE-based RPR is effective compared to image-based RPR. Refinement strategy enhances APR localization accuracy on indoor benchmarks, achieving competitive performance even when trained with only 30% of the data.

Conclusion: The proposed PAE-based RPR refinement strategy enhances APR localization accuracy, achieving competitive performance with reduced training data, which alleviates data collection burden.

Abstract: Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [49] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

TL;DR: ViPE: a video processing engine that efficiently estimates camera intrinsics, camera motion, and dense depth maps from unconstrained raw videos. It outperforms existing methods and is used to create a large-scale annotated dataset of real-world and AI-generated videos, which is released to accelerate spatial AI development.


<details>
  <summary>Details</summary>
Motivation: acquiring consistent and precise 3D annotations from in-the-wild videos remains a key challenge.

Method: ViPE efficiently estimates camera intrinsics, camera motion, and dense, near-metric depth maps from unconstrained raw videos.

Result: it outperforms existing uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to annotate a large-scale collection of videos. This collection includes around 100K real-world internet videos, 1M high-quality AI-generated videos, and 2K panoramic videos, totaling approximately 96M frames -- all annotated with accurate camera poses and dense depth maps.

Conclusion: We open-source ViPE and the annotated dataset with the hope of accelerating the development of spatial AI systems.

Abstract: Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [50] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

TL;DR: 提出了 HQ-OV3D 框架，用于生成和细化高质量的伪标签，从而提高开放词汇 3D 检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的封闭集 3D 检测框架无法满足自动驾驶等开放世界应用的需求。现有的开放词汇 3D 检测方法通常采用两阶段流水线，包括伪标签生成，然后进行语义对齐。虽然视觉语言模型 (VLM) 最近极大地提高了伪标签的语义准确性，但它们的几何质量，特别是边界框精度，仍然普遍被忽视。为了解决这个问题

Method: 提出了一种高质量 Box 开放词汇 3D 检测 (HQ-OV3D) 框架，该框架致力于为开放词汇类生成和细化高质量伪标签。该框架包括两个关键组件：一个内部模态交叉验证 (IMCV) 提案生成器，它利用交叉模态几何一致性来生成高质量的初始 3D 提案，以及一个带注释类辅助 (ACA) 去噪器，它通过基于 DDIM 的去噪机制，利用带注释类别的几何先验逐步细化 3D 提案。

Result: 与最先进的方法相比，使用我们的方法生成的伪标签进行训练，在新类上的 mAP 提高了 7.37%，这证明了我们的框架生成的伪标签的卓越质量。

Conclusion: HQ-OV3D 可以作为一个强大的独立开放词汇 3D 检测器，也可以作为现有开放词汇检测或注释管道的插件高质量伪标签生成器。

Abstract: Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [51] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

TL;DR: This paper presents a new collaborative perception method using Gaussian splatting that improves accuracy and reduces communication costs for 3D semantic occupancy prediction.


<details>
  <summary>Details</summary>
Motivation: Existing vision-only methods for 3D semantic occupancy prediction have limitations in collaborative scenarios due to high communication costs or reliance on accurate depth estimation. Collaborative perception enables connected vehicles to share information, overcoming occlusions and extending the limited sensing range inherent in single-agent systems.

Method: The proposed method leverages sparse 3D semantic Gaussian splatting for collaborative 3D semantic occupancy prediction. It shares and fuses intermediate Gaussian primitives using neighborhood-based cross-agent fusion and encodes geometry and semantics jointly.

Result: The proposed approach outperforms single-agent perception and baseline collaborative methods by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU, respectively. It achieves a +1.9 improvement in mIoU with only 34.6% communication volume.

Conclusion: This paper introduces a collaborative 3D semantic occupancy prediction method using sparse 3D semantic Gaussian splatting, which outperforms existing single-agent and collaborative methods, especially under limited communication budgets.

Abstract: Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [52] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

TL;DR: IDFSR: A novel face super-resolution method that enhances identity restoration under large scaling factors by decoupling style and ID, mitigating hallucination effects.


<details>
  <summary>Details</summary>
Motivation: Existing face super-resolution methods struggle with identity consistency and hallucination effects in extreme degradation scenarios (e.g., scale > 8x), where critical attributes and ID information are severely lost.

Method: The method involves masking the facial region in the low-resolution (LR) image, warping a reference image to align with the LR input, and leveraging ID embeddings extracted from ground truth (GT) images for fine-grained ID modeling and personalized adaptation. A diffusion-based model is pretrained to decouple style and ID, followed by lightweight fine-tuning of the ID embedding.

Result: The proposed IDFSR enhances ID restoration under large scaling factors while mitigating hallucination effects, achieving superior performance on ID consistency.

Conclusion: The proposed IDFSR substantially outperforms existing approaches under extreme degradation, particularly achieving superior performance on ID consistency.

Abstract: In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [53] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

TL;DR: 本研究探索了深度学习在自动分类越南常见的十种木材物种中的应用。


<details>
  <summary>Details</summary>
Motivation: 准确识别木材种类在生态监测、生物多样性保护和可持续森林管理中起着关键作用。 传统的依赖于宏观和微观检查的分类方法是劳动密集型的，并且需要专家知识。

Method: 使用从现场采集的木材样本构建的自定义图像数据集，并评估了五种最先进的卷积神经网络架构——ResNet50、EfficientNet、MobileViT、MobileNetV3 和 ShuffleNetV2。

Result: 在这些模型中，ShuffleNetV2 在分类性能和计算效率之间实现了最佳平衡，在 20 次独立运行中的平均准确率为 99.29%，F1 分数为 99.35%。

Conclusion: 轻量级深度学习模型在资源受限环境中具有实时、高精度物种识别的潜力。这项工作通过为自动木材分类和森林生物多样性评估提供可扩展的、基于图像的解决方案，为生态信息学领域做出了贡献。

Abstract: Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [54] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

TL;DR: NIRMAL Pooling is a novel pooling layer that improves CNN performance on image classification tasks.


<details>
  <summary>Details</summary>
Motivation: improve robustness and feature expressiveness

Method: adaptive max pooling with non-linear activation function

Result: NIRMAL Pooling achieves test accuracies of 99.25% on MNIST Digits, 91.59% on MNIST Fashion, and 70.49% on CIFAR-10, demonstrating consistent improvements, particularly on complex datasets.

Conclusion: NIRMAL Pooling enhances CNN performance in diverse image recognition tasks and offers a flexible and reliable alternative to traditional pooling methods.

Abstract: This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [55] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

TL;DR: 本文提出了一种基于特征的 Artcode 检测系统，该系统使用方向直方图形状特征描述符来检测 Artcode 提案。


<details>
  <summary>Details</summary>
Motivation: 随着智能手机的日益普及和 VR/AR 技术的复兴，我们的日常环境可能很快就会被与虚拟元素连接的对象所装饰。因此，提醒这些对象的存在是激发后续进一步检查和触发附加到对象的数字材料的第一步。

Method: 本文提出了一种新的特征描述符，称为方向直方图形状，以描述 Artcode 的通用拓扑结构。

Result: 实验结果表明，所提出的特征向量在表示拓扑结构方面的可行性，以及该系统在检测 Artcode 提案方面的有效性。

Conclusion: 本文证明了所提出的特征向量在表示拓扑结构方面的可行性，以及该系统在检测 Artcode 提案方面的有效性。这项工作为开发基于特征的拓扑对象检测系统做出了初步尝试，它将开启新的交互机会，并激发拓扑对象检测的潜在应用。

Abstract: The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [56] [TrajSV: A Trajectory-based Model for Sports Video Representations and Applications](https://arxiv.org/abs/2508.11569)
*Zheng Wang,Shihao Xu,Wei Shi*

Main category: cs.CV

TL;DR: TrajSV 是一个基于轨迹的框架，通过利用轨迹增强的 Transformer 模块和三重对比损失，在体育视频检索、动作识别和视频字幕方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 体育分析近年来受到了学术界和工业界的极大关注。尽管该领域的研究兴趣和努力日益增长，但仍有几个问题尚未解决，包括 (1) 数据不可用，(2) 缺乏有效的基于轨迹的框架，以及 (3) 需要足够的监督标签。

Method: TrajSV 包含三个组件：数据预处理、剪辑表示网络 (CRNet) 和视频表示网络 (VRNet)。数据预处理模块从体育广播视频中提取球员和球的轨迹。CRNet 利用轨迹增强的 Transformer 模块来学习基于这些轨迹的剪辑表示。此外，VRNet 通过使用编码器-解码器架构聚合剪辑表示和视觉特征来学习视频表示。最后，引入三重对比损失以无监督的方式优化视频和剪辑表示。

Result: TrajSV 在体育视频检索方面取得了最先进的性能，展示了近 70% 的改进。在动作识别方面优于基线，在 17 个动作类别中的 9 个类别中取得了最先进的结果，并在视频字幕方面展示了近 20% 的改进。

Conclusion: TrajSV在体育视频检索方面取得了最先进的性能，展示了近 70% 的改进。在动作识别方面优于基线，在 17 个动作类别中的 9 个类别中取得了最先进的结果，并在视频字幕方面展示了近 20% 的改进。

Abstract: Sports analytics has received significant attention from both academia and
industry in recent years. Despite the growing interest and efforts in this
field, several issues remain unresolved, including (1) data unavailability, (2)
lack of an effective trajectory-based framework, and (3) requirement for
sufficient supervision labels. In this paper, we present TrajSV, a
trajectory-based framework that addresses various issues in existing studies.
TrajSV comprises three components: data preprocessing, Clip Representation
Network (CRNet), and Video Representation Network (VRNet). The data
preprocessing module extracts player and ball trajectories from sports
broadcast videos. CRNet utilizes a trajectory-enhanced Transformer module to
learn clip representations based on these trajectories. Additionally, VRNet
learns video representations by aggregating clip representations and visual
features with an encoder-decoder architecture. Finally, a triple contrastive
loss is introduced to optimize both video and clip representations in an
unsupervised manner. The experiments are conducted on three broadcast video
datasets to verify the effectiveness of TrajSV for three types of sports (i.e.,
soccer, basketball, and volleyball) with three downstream applications (i.e.,
sports video retrieval, action spotting, and video captioning). The results
demonstrate that TrajSV achieves state-of-the-art performance in sports video
retrieval, showcasing a nearly 70% improvement. It outperforms baselines in
action spotting, achieving state-of-the-art results in 9 out of 17 action
categories, and demonstrates a nearly 20% improvement in video captioning.
Additionally, we introduce a deployed system along with the three applications
based on TrajSV.

</details>


### [57] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

TL;DR: This study presents a framework to quantify nesting behavior in dry textile reinforcements under compaction using low-resolution computed tomography (CT).


<details>
  <summary>Details</summary>
Motivation: A detailed understanding of material structure across multiple scales is essential for predictive modeling of textile-reinforced composites. Nesting plays a critical role in defining mechanical properties such as stiffness, permeability, and damage tolerance.

Method: A tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill phases across compaction stages corresponding to fiber volume contents of 50--60 %.

Result: The model achieved a minimum mean Intersection-over-Union of 0.822 and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using the two-point correlation function $S_2$, allowing for probabilistic extraction of average layer thickness and nesting degree. The results show strong agreement with micrograph-based validation.

Conclusion: This methodology provides a robust approach for extracting key geometrical features from industrially relevant CT data and establishes a foundation for reverse modeling and descriptor-based structural analysis of composite preforms.

Abstract: A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [58] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: iWatchRoad is an automated, cost-effective system for pothole detection, GPS tagging, and real-time mapping using dashcam footage and YOLO, designed for diverse Indian road conditions.


<details>
  <summary>Details</summary>
Motivation: Potholes on roads are a serious hazard and maintenance burden, posing a significant threat to road safety and vehicle longevity, especially on the diverse and under-maintained roads of India.

Method: Utilizes a fine-tuned YOLO model for real-time pothole detection and a custom OCR module to extract timestamps from video frames, synchronized with GPS logs to geotag potholes accurately.

Result: A complete end-to-end system called iWatchRoad for automated pothole detection, GPS tagging, and real time mapping using OpenStreetMap (OSM). A large, self-annotated dataset of over 7,000 frames captured across various road types, lighting conditions, and weather scenarios unique to Indian environments was curated.

Conclusion: iWatchRoad improves detection accuracy under challenging conditions and provides government compatible outputs for road assessment and maintenance planning. It is cost effective, hardware efficient, and scalable, offering a practical tool for urban and rural road management in developing regions, making the system automated.

Abstract: Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>


### [59] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: This paper introduces Incremental Patch Generation (IPG), a method that generates adversarial patches more efficiently. Experiments show it produces well-generalized patches and can serve as a robust knowledge foundation for constructing a robust model.


<details>
  <summary>Details</summary>
Motivation: Adversarial patches pose a significant challenge to the robustness of AI models, particularly in the domain of computer vision tasks such as object detection. In contradistinction to traditional adversarial examples, these patches target specific regions of an image, resulting in the malfunction of AI models.

Method: Incremental Patch Generation (IPG)

Result: IPG generates adversarial patches up to 11.1 times more efficiently than existing approaches while maintaining comparable attack performance. The efficacy of IPG is demonstrated by experiments and ablation studies including YOLO's feature distribution visualization and adversarial training results, which show that it produces well-generalized patches that effectively cover a broader range of model vulnerabilities. Furthermore, IPG-generated datasets can serve as a robust knowledge foundation for constructing a robust model, enabling structured representation, advanced reasoning, and proactive defenses in AI security ecosystems.

Conclusion: IPG has considerable potential for future utilization not only in adversarial patch defense but also in real-world applications such as autonomous vehicles, security systems, and medical imaging, where AI models must remain resilient to adversarial attacks in dynamic and high-stakes environments.

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [60] [MedAtlas: Evaluating LLMs for Multi-Round, Multi-Task Medical Reasoning Across Diverse Imaging Modalities and Clinical Text](https://arxiv.org/abs/2508.10947)
*Ronghao Xu,Zhen Huang,Yangbo Wei,Xiaoqian Zhou,Zikang Xu,Ting Liu,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: MedAtlas, a new benchmark for evaluating large language models on realistic medical reasoning tasks, reveals performance gaps in existing multi-modal models.


<details>
  <summary>Details</summary>
Motivation: Existing medical multi-modal benchmarks are typically limited to single-image, single-turn tasks, lacking multi-modal medical image integration and failing to capture the longitudinal and multi-modal interactive nature inherent to clinical practice. To address this gap, we introduce MedAtlas

Method: We introduce MedAtlas, a novel benchmark framework designed to evaluate large language models on realistic medical reasoning tasks. MedAtlas is characterized by four key features: multi-turn dialogue, multi-modal medical image interaction, multi-task integration, and high clinical fidelity. It supports four core tasks: open-ended multi-turn question answering, closed-ended multi-turn question answering, multi-image joint reasoning, and comprehensive disease diagnosis.

Result: Benchmark results with existing multi-modal models reveal substantial performance gaps in multi-stage clinical reasoning.

Conclusion: MedAtlas establishes a challenging evaluation platform to advance the development of robust and trustworthy medical AI.

Abstract: Artificial intelligence has demonstrated significant potential in clinical
decision-making; however, developing models capable of adapting to diverse
real-world scenarios and performing complex diagnostic reasoning remains a
major challenge. Existing medical multi-modal benchmarks are typically limited
to single-image, single-turn tasks, lacking multi-modal medical image
integration and failing to capture the longitudinal and multi-modal interactive
nature inherent to clinical practice. To address this gap, we introduce
MedAtlas, a novel benchmark framework designed to evaluate large language
models on realistic medical reasoning tasks. MedAtlas is characterized by four
key features: multi-turn dialogue, multi-modal medical image interaction,
multi-task integration, and high clinical fidelity. It supports four core
tasks: open-ended multi-turn question answering, closed-ended multi-turn
question answering, multi-image joint reasoning, and comprehensive disease
diagnosis. Each case is derived from real diagnostic workflows and incorporates
temporal interactions between textual medical histories and multiple imaging
modalities, including CT, MRI, PET, ultrasound, and X-ray, requiring models to
perform deep integrative reasoning across images and clinical texts. MedAtlas
provides expert-annotated gold standards for all tasks. Furthermore, we propose
two novel evaluation metrics: Round Chain Accuracy and Error Propagation
Resistance. Benchmark results with existing multi-modal models reveal
substantial performance gaps in multi-stage clinical reasoning. MedAtlas
establishes a challenging evaluation platform to advance the development of
robust and trustworthy medical AI.

</details>


### [61] [From Promise to Practical Reality: Transforming Diffusion MRI Analysis with Fast Deep Learning Enhancement](https://arxiv.org/abs/2508.10950)
*Xinyi Wang,Michael Barnett,Frederique Boonstra,Yael Barnett,Mariano Cabezas,Arkiev D'Souza,Matthew C. Kiernan,Kain Kyle,Meng Law,Lynette Masters,Zihao Tang,Stephen Tisch,Sicong Tu,Anneke Van Der Walt,Dongang Wang,Fernando Calamante,Weidong Cai,Chenyu Wang*

Main category: cs.CV

TL;DR: FastFOD-Net是一种用于增强FOD的深度学习框架，经验证在健康对照和六种神经系统疾病中均有效，加速了临床神经科学研究。


<details>
  <summary>Details</summary>
Motivation: 在单壳和低角度分辨率采集的临床协议中生成可靠的FOD仍然具有挑战性。现有方法主要在健康受试者中进行评估，这已成为其临床应用的主要障碍。

Method: 优化后的增强框架FastFOD-Net

Result: FastFOD-Net 具有卓越的性能，并提供临床使用的训练/推理效率（比其前身快 60 倍）。

Conclusion: FastFOD-Net在神经系统疾病中表现出潜力，加速临床神经科学研究，改善连接组应用的可解释性，并减少测量误差。

Abstract: Fiber orientation distribution (FOD) is an advanced diffusion MRI modeling
technique that represents complex white matter fiber configurations, and a key
step for subsequent brain tractography and connectome analysis. Its reliability
and accuracy, however, heavily rely on the quality of the MRI acquisition and
the subsequent estimation of the FODs at each voxel. Generating reliable FODs
from widely available clinical protocols with single-shell and
low-angular-resolution acquisitions remains challenging but could potentially
be addressed with recent advances in deep learning-based enhancement
techniques. Despite advancements, existing methods have predominantly been
assessed on healthy subjects, which have proved to be a major hurdle for their
clinical adoption. In this work, we validate a newly optimized enhancement
framework, FastFOD-Net, across healthy controls and six neurological disorders.
This accelerated end-to-end deep learning framework enhancing FODs with
superior performance and delivering training/inference efficiency for clinical
use ($60\times$ faster comparing to its predecessor). With the most
comprehensive clinical evaluation to date, our work demonstrates the potential
of FastFOD-Net in accelerating clinical neuroscience research, empowering
diffusion MRI analysis for disease differentiation, improving interpretability
in connectome applications, and reducing measurement errors to lower sample
size requirements. Critically, this work will facilitate the more widespread
adoption of, and build clinical trust in, deep learning based methods for
diffusion MRI enhancement. Specifically, FastFOD-Net enables robust analysis of
real-world, clinical diffusion MRI data, comparable to that achievable with
high-quality research acquisitions.

</details>


### [62] [ORBIT: An Object Property Reasoning Benchmark for Visual Inference Tasks](https://arxiv.org/abs/2508.10956)
*Abhishek Kolari,Mohammadhossein Khojasteh,Yifan Jiang,Floris den Hengst,Filip Ilievski*

Main category: cs.CV

TL;DR: This paper introduces ORBIT, a new VQA benchmark for object property reasoning, and finds that current VLMs struggle with this task, particularly with realistic images and counterfactual reasoning.


<details>
  <summary>Details</summary>
Motivation: While vision-language models (VLMs) have made remarkable progress on many popular visual question answering (VQA) benchmarks, it remains unclear whether they abstract and reason over depicted objects. Inspired by human object categorisation, object property reasoning involves identifying and recognising low-level details and higher-level abstractions. While current VQA benchmarks consider a limited set of object property attributes like size, they typically blend perception and reasoning, and lack representativeness in terms of reasoning and image categories.

Method: We develop a procedure to instantiate this benchmark into ORBIT, a multi-level reasoning VQA benchmark for object properties comprising 360 images paired with a total of 1,080 count-based questions.

Result: ORBIT, a multi-level reasoning VQA benchmark for object properties comprising 360 images paired with a total of 1,080 count-based questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings reveal significant limitations compared to humans, with the best-performing model only reaching 40% accuracy.

Conclusion: Experiments with 12 state-of-the-art VLMs in zero-shot settings reveal significant limitations compared to humans, with the best-performing model only reaching 40% accuracy. VLMs struggle particularly with realistic (photographic) images, counterfactual reasoning about physical and functional properties, and higher counts. ORBIT points to the need to develop methods for scalable benchmarking, generalize annotation guidelines, and explore additional reasoning VLMs. We make the ORBIT benchmark and the experimental code available to support such endeavors.

Abstract: While vision-language models (VLMs) have made remarkable progress on many
popular visual question answering (VQA) benchmarks, it remains unclear whether
they abstract and reason over depicted objects. Inspired by human object
categorisation, object property reasoning involves identifying and recognising
low-level details and higher-level abstractions. While current VQA benchmarks
consider a limited set of object property attributes like size, they typically
blend perception and reasoning, and lack representativeness in terms of
reasoning and image categories. To this end, we introduce a systematic
evaluation framework with images of three representative types, three reasoning
levels of increasing complexity, and four object property dimensions driven by
prior work on commonsense reasoning. We develop a procedure to instantiate this
benchmark into ORBIT, a multi-level reasoning VQA benchmark for object
properties comprising 360 images paired with a total of 1,080 count-based
questions. Experiments with 12 state-of-the-art VLMs in zero-shot settings
reveal significant limitations compared to humans, with the best-performing
model only reaching 40\% accuracy. VLMs struggle particularly with realistic
(photographic) images, counterfactual reasoning about physical and functional
properties, and higher counts. ORBIT points to the need to develop methods for
scalable benchmarking, generalize annotation guidelines, and explore additional
reasoning VLMs. We make the ORBIT benchmark and the experimental code available
to support such endeavors.

</details>


### [63] [Empowering Multimodal LLMs with External Tools: A Comprehensive Survey](https://arxiv.org/abs/2508.10955)
*Wenbin An,Jiahao Nie,Yaqiang Wu,Feng Tian,Shijian Lu,Qinghua Zheng*

Main category: cs.CV

TL;DR: 本研究调查了利用外部工具来增强多模态大型语言模型(MLLM)性能的方法，强调了外部工具在推进MLLM能力方面的变革潜力。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型(MLLM)在各种多模态任务中取得了巨大的成功，但多模态数据的质量有限、在许多复杂的下游任务中的表现不佳以及不充分的评估协议继续阻碍了MLLM在不同领域的可靠性和更广泛的适用性。受人类利用外部工具来增强推理和解决问题能力的启发，利用外部工具（例如，API、专家模型和知识库）增强MLLM提供了一种有希望的策略来克服这些挑战。

Method: 对利用外部工具增强MLLM性能的现有研究进行了全面的调查，并从四个关键维度展开讨论：(1) 如何促进高质量多模态数据的获取和标注；(2) 如何帮助提高MLLM在复杂下游任务中的性能；(3) 如何实现对MLLM的全面和准确评估；(4) 工具增强型MLLM的当前局限性和未来方向。

Result: 强调了外部工具在推进MLLM能力方面的变革潜力，并为他们的开发和应用提供了前瞻性的视角。

Conclusion: 外部工具在提升多模态大型语言模型（MLLM）能力方面具有变革潜力，并为MLLM的开发和应用提供了前瞻性视角。

Abstract: By integrating the perception capabilities of multimodal encoders with the
generative power of Large Language Models (LLMs), Multimodal Large Language
Models (MLLMs), exemplified by GPT-4V, have achieved great success in various
multimodal tasks, pointing toward a promising pathway to artificial general
intelligence. Despite this progress, the limited quality of multimodal data,
poor performance on many complex downstream tasks, and inadequate evaluation
protocols continue to hinder the reliability and broader applicability of MLLMs
across diverse domains. Inspired by the human ability to leverage external
tools for enhanced reasoning and problem-solving, augmenting MLLMs with
external tools (e.g., APIs, expert models, and knowledge bases) offers a
promising strategy to overcome these challenges. In this paper, we present a
comprehensive survey on leveraging external tools to enhance MLLM performance.
Our discussion is structured along four key dimensions about external tools:
(1) how they can facilitate the acquisition and annotation of high-quality
multimodal data; (2) how they can assist in improving MLLM performance on
challenging downstream tasks; (3) how they enable comprehensive and accurate
evaluation of MLLMs; (4) the current limitations and future directions of
tool-augmented MLLMs. Through this survey, we aim to underscore the
transformative potential of external tools in advancing MLLM capabilities,
offering a forward-looking perspective on their development and applications.
The project page of this paper is publicly available
athttps://github.com/Lackel/Awesome-Tools-for-MLLMs.

</details>


### [64] [CSNR and JMIM Based Spectral Band Selection for Reducing Metamerism in Urban Driving](https://arxiv.org/abs/2508.10962)
*Jiarong Li,Imad Ali Shah,Diarmaid Geever,Fiachra Collins,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本研究利用高光谱成像（HSI）技术，通过选择最佳波段，提高弱势道路使用者（VRU）在图像中的可分离性，从而提升ADAS和自动驾驶系统的道路安全性。


<details>
  <summary>Details</summary>
Motivation: 汽车感知系统在保护弱势道路使用者（VRU）方面面临着严峻的安全挑战，尤其是在由同色异谱现象引起的视觉模糊下，在这种现象中，不同的材料在RGB图像中看起来相似。

Method: 提出了一种带选择策略，该策略集成了信息论技术（联合互信息最大化、相关分析）与图像质量指标（对比度信噪比）的新应用，以识别最具光谱信息的波段。

Result: 所选的HSI波段在相异性（欧几里得距离、SAM、$T^2$）和感知（CIE $\Delta E$）指标方面分别提高了70.24%、528.46%、1206.83%和246.62%，始终优于RGB，证实了同色异谱混淆的显著减少。

Conclusion: 通过提供光谱优化的输入，该方法增强了弱势道路使用者（VRU）的可分离性，为高级驾驶辅助系统（ADAS）和自动驾驶（AD）中的下游感知任务奠定了稳固的基础，最终有助于提高道路安全性。

Abstract: Protecting Vulnerable Road Users (VRU) is a critical safety challenge for
automotive perception systems, particularly under visual ambiguity caused by
metamerism, a phenomenon where distinct materials appear similar in RGB
imagery. This work investigates hyperspectral imaging (HSI) to overcome this
limitation by capturing unique material signatures beyond the visible spectrum,
especially in the Near-Infrared (NIR). To manage the inherent
high-dimensionality of HSI data, we propose a band selection strategy that
integrates information theory techniques (joint mutual information
maximization, correlation analysis) with a novel application of an image
quality metric (contrast signal-to-noise ratio) to identify the most spectrally
informative bands. Using the Hyperspectral City V2 (H-City) dataset, we
identify three informative bands (497 nm, 607 nm, and 895 nm, $\pm$27 nm) and
reconstruct pseudo-color images for comparison with co-registered RGB.
Quantitative results demonstrate increased dissimilarity and perceptual
separability of VRU from the background. The selected HSI bands yield
improvements of 70.24%, 528.46%, 1206.83%, and 246.62% for dissimilarity
(Euclidean, SAM, $T^2$) and perception (CIE $\Delta E$) metrics, consistently
outperforming RGB and confirming a marked reduction in metameric confusion. By
providing a spectrally optimized input, our method enhances VRU separability,
establishing a robust foundation for downstream perception tasks in Advanced
Driver Assistance Systems (ADAS) and Autonomous Driving (AD), ultimately
contributing to improved road safety.

</details>


### [65] [Not There Yet: Evaluating Vision Language Models in Simulating the Visual Perception of People with Low Vision](https://arxiv.org/abs/2508.10972)
*Rosiana Natalie,Wenqian Xu,Ruei-Che Chang,Rada Mihalcea,Anhong Guo*

Main category: cs.CV

TL;DR: 本文评估了 VLMs 模拟低视力人群视觉感知的程度，发现结合视觉信息和示例图像响应能显著提高模拟效果。


<details>
  <summary>Details</summary>
Motivation: 探讨 VLMs 在可访问性领域中模拟低视力个体视觉感知的能力。

Method: 通过调查研究，收集了 40 名低视力参与者对图像的感知和识别响应，并构建了用于 VLMs (GPT-4o) 的提示，以创建每个参与者的模拟代理。

Result: VLMs 在最少提示下倾向于过度推断，导致一致性较低 (0.59)。结合视觉信息和示例图像响应可显著提高一致性 (0.70, p < 0.0001)。

Conclusion: VLMs 在模拟低视力人群的视觉感知方面具有潜力，但需要结合视觉信息和示例图像响应才能提高一致性。单个结合开放式和多项选择题的示例效果显著，而额外示例的收益递减。

Abstract: Advances in vision language models (VLMs) have enabled the simulation of
general human behavior through their reasoning and problem solving
capabilities. However, prior research has not investigated such simulation
capabilities in the accessibility domain. In this paper, we evaluate the extent
to which VLMs can simulate the vision perception of low vision individuals when
interpreting images. We first compile a benchmark dataset through a survey
study with 40 low vision participants, collecting their brief and detailed
vision information and both open-ended and multiple-choice image perception and
recognition responses to up to 25 images. Using these responses, we construct
prompts for VLMs (GPT-4o) to create simulated agents of each participant,
varying the included information on vision information and example image
responses. We evaluate the agreement between VLM-generated responses and
participants' original answers. Our results indicate that VLMs tend to infer
beyond the specified vision ability when given minimal prompts, resulting in
low agreement (0.59). The agreement between the agent' and participants'
responses remains low when only either the vision information (0.59) or example
image responses (0.59) are provided, whereas a combination of both
significantly increase the agreement (0.70, p < 0.0001). Notably, a single
example combining both open-ended and multiple-choice responses, offers
significant performance improvements over either alone (p < 0.0001), while
additional examples provided minimal benefits (p > 0.05).

</details>


### [66] [EVCtrl: Efficient Control Adapter for Visual Generation](https://arxiv.org/abs/2508.10963)
*Zixiang Yang,Yue Ma,Yinhan Zhang,Shanhui Mo,Dongrui Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: EVCtrl is a lightweight control adapter that significantly speeds up controlled image and video generation by caching and selectively omitting redundant computations, without retraining the model.


<details>
  <summary>Details</summary>
Motivation: ControlNet's auxiliary branch increases latency and introduces redundant computation, especially for video generation.

Method: A spatio-temporal dual caching strategy is used for sparse control information, including a locality-aware cache for spatial redundancy and selective omission of denoising steps for temporal redundancy.

Result: EVCtrl achieves 2.16x and 2.05x speedups on CogVideo-Controlnet and Wan2.1-Controlnet, respectively, with almost no degradation in generation quality.

Conclusion: EVCtrl achieves significant speedups on CogVideo-Controlnet and Wan2.1-Controlnet with minimal quality degradation, demonstrating its effectiveness in image and video control generation without training.

Abstract: Visual generation includes both image and video generation, training
probabilistic models to create coherent, diverse, and semantically faithful
content from scratch. While early research focused on unconditional sampling,
practitioners now demand controllable generation that allows precise
specification of layout, pose, motion, or style. While ControlNet grants
precise spatial-temporal control, its auxiliary branch markedly increases
latency and introduces redundant computation in both uncontrolled regions and
denoising steps, especially for video. To address this problem, we introduce
EVCtrl, a lightweight, plug-and-play control adapter that slashes overhead
without retraining the model. Specifically, we propose a spatio-temporal dual
caching strategy for sparse control information. For spatial redundancy, we
first profile how each layer of DiT-ControlNet responds to fine-grained
control, then partition the network into global and local functional zones. A
locality-aware cache focuses computation on the local zones that truly need the
control signal, skipping the bulk of redundant computation in global regions.
For temporal redundancy, we selectively omit unnecessary denoising steps to
improve efficiency. Extensive experiments on CogVideo-Controlnet,
Wan2.1-Controlnet, and Flux demonstrate that our method is effective in image
and video control generation without the need for training. For example, it
achieves 2.16 and 2.05 times speedups on CogVideo-Controlnet and
Wan2.1-Controlnet, respectively, with almost no degradation in generation
quality.Codes are available in the supplementary materials.

</details>


### [67] [Are Large Pre-trained Vision Language Models Effective Construction Safety Inspectors?](https://arxiv.org/abs/2508.11011)
*Xuezheng Chen,Zhengbo Zou*

Main category: cs.CV

TL;DR: This paper introduces a new construction site image dataset (ConstructionSite 10k) for training and evaluating VLMs for safety inspection.


<details>
  <summary>Details</summary>
Motivation: There is a lack of open datasets to evaluate and fine-tune VLMs for construction safety inspection. Current VLM applications use small, supervised datasets, limiting their applicability.

Method: The authors created a dataset of 10,000 construction site images with annotations for image captioning, safety rule violation VQA, and construction element visual grounding. They then evaluated state-of-the-art VLMs on this dataset.

Result: The evaluation of VLMs shows notable generalization abilities in zero-shot and few-shot settings, but additional training is needed for application in actual construction sites.

Conclusion: The paper introduces the ConstructionSite 10k dataset and evaluates current VLMs, showing their generalization abilities but also the need for further training for real-world application.

Abstract: Construction safety inspections typically involve a human inspector
identifying safety concerns on-site. With the rise of powerful Vision Language
Models (VLMs), researchers are exploring their use for tasks such as detecting
safety rule violations from on-site images. However, there is a lack of open
datasets to comprehensively evaluate and further fine-tune VLMs in construction
safety inspection. Current applications of VLMs use small, supervised datasets,
limiting their applicability in tasks they are not directly trained for. In
this paper, we propose the ConstructionSite 10k, featuring 10,000 construction
site images with annotations for three inter-connected tasks, including image
captioning, safety rule violation visual question answering (VQA), and
construction element visual grounding. Our subsequent evaluation of current
state-of-the-art large pre-trained VLMs shows notable generalization abilities
in zero-shot and few-shot settings, while additional training is needed to make
them applicable to actual construction sites. This dataset allows researchers
to train and evaluate their own VLMs with new architectures and techniques,
providing a valuable benchmark for construction safety inspection.

</details>


### [68] [Can Multi-modal (reasoning) LLMs detect document manipulation?](https://arxiv.org/abs/2508.11021)
*Zisheng Liang,Kidus Zewde,Rudra Pratap Singh,Disha Patil,Zexi Chen,Jiayu Xue,Yao Yao,Yifei Chen,Qinzhe Liu,Simiao Ren*

Main category: cs.CV

TL;DR: This study investigates the efficacy of multi-modal LLMs in detecting fraudulent documents, finding that top-performing models show superior zero-shot generalization but task-specific fine-tuning is critical.


<details>
  <summary>Details</summary>
Motivation: Document fraud poses a significant threat, necessitating robust detection mechanisms.

Method: Benchmark multi-modal LLMs against each other and prior work using a standard dataset with real transactional documents, through prompt optimization and detailed analysis of the models' reasoning processes.

Result: Top-performing multi-modal LLMs demonstrate superior zero-shot generalization, outperforming conventional methods on out-of-distribution datasets, while several vision LLMs exhibit inconsistent or subpar performance. Model size and advanced reasoning capabilities show limited correlation with detection accuracy.

Conclusion: Top-performing multi-modal LLMs demonstrate superior zero-shot generalization, outperforming conventional methods, but model size and reasoning capabilities have limited correlation with detection accuracy, suggesting task-specific fine-tuning is critical.

Abstract: Document fraud poses a significant threat to industries reliant on secure and
verifiable documentation, necessitating robust detection mechanisms. This study
investigates the efficacy of state-of-the-art multi-modal large language models
(LLMs)-including OpenAI O1, OpenAI 4o, Gemini Flash (thinking), Deepseek Janus,
Grok, Llama 3.2 and 4, Qwen 2 and 2.5 VL, Mistral Pixtral, and Claude 3.5 and
3.7 Sonnet-in detecting fraudulent documents. We benchmark these models against
each other and prior work on document fraud detection techniques using a
standard dataset with real transactional documents. Through prompt optimization
and detailed analysis of the models' reasoning processes, we evaluate their
ability to identify subtle indicators of fraud, such as tampered text,
misaligned formatting, and inconsistent transactional sums. Our results reveal
that top-performing multi-modal LLMs demonstrate superior zero-shot
generalization, outperforming conventional methods on out-of-distribution
datasets, while several vision LLMs exhibit inconsistent or subpar performance.
Notably, model size and advanced reasoning capabilities show limited
correlation with detection accuracy, suggesting task-specific fine-tuning is
critical. This study underscores the potential of multi-modal LLMs in enhancing
document fraud detection systems and provides a foundation for future research
into interpretable and scalable fraud mitigation strategies.

</details>


### [69] [MedSAMix: A Training-Free Model Merging Approach for Medical Image Segmentation](https://arxiv.org/abs/2508.11032)
*Yanwu Yang,Guinan Su,Jiesi Hu,Francesco Sammarco,Jonas Geiping,Thomas Wolfers*

Main category: cs.CV

TL;DR: 提出了 MedSAMix，一种免训练的模型合并方法，用于医学图像分割，通过零阶优化自动发现最佳层级合并解决方案，并在 25 个医学分割任务上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 微调的变体（如 MedSAM）在相对有限的医学成像数据上进行训练，这些数据通常存在异质性、注释稀缺和分布偏移的问题。这些挑战限制了它们在广泛的医学分割任务中进行泛化的能力。

Method: 提出了一种免训练的模型合并方法 MedSAMix，该方法集成了通用模型（例如，SAM）和专用模型（例如，MedSAM）的优势，用于医学图像分割。提出了一种零阶优化方法来自动发现最佳的层级合并解决方案。开发了两种方案，分别通过单任务优化和多目标优化来满足不同场景中领域特异性和泛化性的需求。

Result: 在 25 个医学分割任务上的广泛评估表明，

Conclusion: MedSAMix有效地缓解了模型偏差，并在特定领域准确性和泛化性方面持续提高性能，在专门任务上实现了 6.67% 的改进，在多任务评估中实现了 4.37% 的改进。

Abstract: Universal medical image segmentation models have emerged as a promising
paradigm due to their strong generalizability across diverse tasks, showing
great potential for a wide range of clinical applications. This potential has
been partly driven by the success of general-purpose vision models such as the
Segment Anything Model (SAM), which has inspired the development of various
fine-tuned variants for medical segmentation tasks. However, fine-tuned
variants like MedSAM are trained on comparatively limited medical imaging data
that often suffers from heterogeneity, scarce annotations, and distributional
shifts. These challenges limit their ability to generalize across a wide range
of medical segmentation tasks. In this regard, we propose MedSAMix, a
training-free model merging method that integrates the strengths of both
generalist models (e.g., SAM) and specialist models (e.g., MedSAM) for medical
image segmentation. In contrast to traditional model merging approaches that
rely on manual configuration and often result in suboptimal outcomes, we
propose a zero-order optimization method to automatically discover optimal
layer-wise merging solutions. Furthermore, for clinical applications, we
develop two regimes to meet the demand of domain-specificity and
generalizability in different scenarios by single-task optimization and
multi-objective optimization respectively. Extensive evaluations on 25 medical
segmentation tasks demonstrate that MedSAMix effectively mitigates model bias
and consistently improves performance in both domain-specific accuracy and
generalization, achieving improvements of 6.67% on specialized tasks and 4.37%
on multi-task evaluations.

</details>


### [70] [Advancing 3D Scene Understanding with MV-ScanQA Multi-View Reasoning Evaluation and TripAlign Pre-training Dataset](https://arxiv.org/abs/2508.11058)
*Wentao Mo,Qingchao Chen,Yuxin Peng,Siyuan Huang,Yang Liu*

Main category: cs.CV

TL;DR: 提出了MV-ScanQA数据集和TripAlign数据集，以解决现有3D视觉语言数据集的局限性，并提出了一个名为LEGO的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D VL数据集存在局限性：它们很少需要对单视点中近距离物体进行推理，并且注释通常将指令链接到单个物体，缺少多个物体之间更丰富的上下文对齐。

Method: 提出了MV-ScanQA数据集和一个名为LEGO的基线方法。

Result: MV-ScanQA数据集，其中68%的问题明确要求整合来自多个视图的信息。TripAlign数据集，一个大规模和低成本的2D-3D-语言预训练语料库，包含100万个<2D视图，3D对象集，文本>三元组。

Conclusion: LEGO预训练在TripAlign上，不仅在提出的MV-ScanQA上取得了最先进的性能，而且在现有的3D密集字幕和问答基准上也取得了最先进的性能。

Abstract: The advancement of 3D vision-language (3D VL) learning is hindered by several
limitations in existing 3D VL datasets: they rarely necessitate reasoning
beyond a close range of objects in single viewpoint, and annotations often link
instructions to single objects, missing richer contextual alignments between
multiple objects. This significantly curtails the development of models capable
of deep, multi-view 3D scene understanding over distant objects. To address
these challenges, we introduce MV-ScanQA, a novel 3D question answering dataset
where 68% of questions explicitly require integrating information from multiple
views (compared to less than 7% in existing datasets), thereby rigorously
testing multi-view compositional reasoning. To facilitate the training of
models for such demanding scenarios, we present TripAlign dataset, a
large-scale and low-cost 2D-3D-language pre-training corpus containing 1M <2D
view, set of 3D objects, text> triplets that explicitly aligns groups of
contextually related objects with text, providing richer, view-grounded
multi-object multimodal alignment signals than previous single-object
annotations. We further develop LEGO, a baseline method for the multi-view
reasoning challenge in MV-ScanQA, transferring knowledge from pre-trained 2D
LVLMs to 3D domain with TripAlign. Empirically, LEGO pre-trained on TripAlign
achieves state-of-the-art performance not only on the proposed MV-ScanQA, but
also on existing benchmarks for 3D dense captioning and question answering.
Datasets and code are available at
https://matthewdm0816.github.io/tripalign-mvscanqa.

</details>


### [71] [Data-Driven Abdominal Phenotypes of Type 2 Diabetes in Lean, Overweight, and Obese Cohorts](https://arxiv.org/abs/2508.11063)
*Lucas W. Remedios,Chloe Choe,Trent M. Schwartz,Dingjie Su,Gaurav Rudravaram,Chenyu Gao,Aravind R. Krishnan,Adam M. Saunders,Michael E. Kim,Shunxing Bao,Alvin C. Powers,Bennett A. Landman,John Virostko*

Main category: cs.CV

TL;DR: AI analysis of abdominal CT scans reveals consistent type 2 diabetes risk factors across different weight classes, including fat distribution and muscle composition.


<details>
  <summary>Details</summary>
Motivation: Detailed body composition may uncover abdominal phenotypes of type 2 diabetes, as the disease's presence varies among individuals with similar BMIs.

Method: Applied a four-part design to clinical CT scans, including segmentation, classification using random forest, SHAP analysis, and clustering to identify anatomical differences.

Result: Random forests achieved mean AUCs of 0.72-0.74. Shared type 2 diabetes signatures include fatty skeletal muscle, older age, greater visceral and subcutaneous fat, and a smaller or fat-laden pancreas. Univariate logistic regression confirmed the direction of 14-18 of the top 20 predictors within each subgroup (p < 0.05).

Conclusion: Abdominal drivers of type 2 diabetes may be consistent across weight classes.

Abstract: Purpose: Although elevated BMI is a well-known risk factor for type 2
diabetes, the disease's presence in some lean adults and absence in others with
obesity suggests that detailed body composition may uncover abdominal
phenotypes of type 2 diabetes. With AI, we can now extract detailed
measurements of size, shape, and fat content from abdominal structures in 3D
clinical imaging at scale. This creates an opportunity to empirically define
body composition signatures linked to type 2 diabetes risk and protection using
large-scale clinical data. Approach: To uncover BMI-specific diabetic abdominal
patterns from clinical CT, we applied our design four times: once on the full
cohort (n = 1,728) and once on lean (n = 497), overweight (n = 611), and obese
(n = 620) subgroups separately. Briefly, our experimental design transforms
abdominal scans into collections of explainable measurements through
segmentation, classifies type 2 diabetes through a cross-validated random
forest, measures how features contribute to model-estimated risk or protection
through SHAP analysis, groups scans by shared model decision patterns
(clustering from SHAP) and links back to anatomical differences
(classification). Results: The random-forests achieved mean AUCs of 0.72-0.74.
There were shared type 2 diabetes signatures in each group; fatty skeletal
muscle, older age, greater visceral and subcutaneous fat, and a smaller or
fat-laden pancreas. Univariate logistic regression confirmed the direction of
14-18 of the top 20 predictors within each subgroup (p < 0.05). Conclusions:
Our findings suggest that abdominal drivers of type 2 diabetes may be
consistent across weight classes.

</details>


### [72] [HierOctFusion: Multi-scale Octree-based 3D Shape Generation via Part-Whole-Hierarchy Message Passing](https://arxiv.org/abs/2508.11106)
*Xinjie Gao,Bi'an Du,Wei Hu*

Main category: cs.CV

TL;DR: HierOctFusion is proposed, a part-aware multi-scale octree diffusion model that enhances hierarchical feature interaction for generating fine-grained and sparse object structures.


<details>
  <summary>Details</summary>
Motivation: existing methods typically model 3D objects as holistic entities, ignoring their semantic part hierarchies and limiting generalization; and holistic high-resolution modeling is computationally expensive, whereas real-world objects are inherently sparse and hierarchical, making them well-suited for layered generation

Method: a part-aware multi-scale octree diffusion model that enhances hierarchical feature interaction for generating fine-grained and sparse object structures. Also introduce a cross-attention conditioning mechanism that injects part-level information into the generation process, enabling semantic features to propagate effectively across hierarchical levels from parts to the whole. Additionally, construct a 3D dataset with part category annotations using a pre-trained segmentation model

Result: achieves superior shape quality and efficiency compared to prior methods

Conclusion: HierOctFusion achieves superior shape quality and efficiency compared to prior methods.

Abstract: 3D content generation remains a fundamental yet challenging task due to the
inherent structural complexity of 3D data. While recent octree-based diffusion
models offer a promising balance between efficiency and quality through
hierarchical generation, they often overlook two key insights: 1) existing
methods typically model 3D objects as holistic entities, ignoring their
semantic part hierarchies and limiting generalization; and 2) holistic
high-resolution modeling is computationally expensive, whereas real-world
objects are inherently sparse and hierarchical, making them well-suited for
layered generation. Motivated by these observations, we propose HierOctFusion,
a part-aware multi-scale octree diffusion model that enhances hierarchical
feature interaction for generating fine-grained and sparse object structures.
Furthermore, we introduce a cross-attention conditioning mechanism that injects
part-level information into the generation process, enabling semantic features
to propagate effectively across hierarchical levels from parts to the whole.
Additionally, we construct a 3D dataset with part category annotations using a
pre-trained segmentation model to facilitate training and evaluation.
Experiments demonstrate that HierOctFusion achieves superior shape quality and
efficiency compared to prior methods.

</details>


### [73] [UWB-PostureGuard: A Privacy-Preserving RF Sensing System for Continuous Ergonomic Sitting Posture Monitoring](https://arxiv.org/abs/2508.11115)
*Haotang Li,Zhenyu Qi,Sen He,Kebin Peng,Sheng Tan,Yili Ren,Tomas Cerny,Jiyue Zhao,Zi Wang*

Main category: cs.CV

TL;DR: UWB-PostureGuard is a privacy-preserving UWB sensing system for contactless monitoring of sitting posture, achieving high accuracy and robustness.


<details>
  <summary>Details</summary>
Motivation: Traditional posture monitoring solutions have privacy concerns (camera-based) and user discomfort (wearable sensors).

Method: The study uses commercial UWB devices and comprehensive feature engineering to extract ergonomic sitting posture features. PoseGBDT is developed to capture temporal dependencies in posture patterns.

Result: The UWB-PostureGuard system achieved 99.11% accuracy across 10 participants and 19 distinct postures, while maintaining robustness against environmental variables.

Conclusion: The UWB-PostureGuard system offers a scalable and privacy-preserving mobile health solution for proactive ergonomic management, improving quality of life at low costs, as demonstrated by high accuracy and robustness in real-world evaluations.

Abstract: Improper sitting posture during prolonged computer use has become a
significant public health concern. Traditional posture monitoring solutions
face substantial barriers, including privacy concerns with camera-based systems
and user discomfort with wearable sensors. This paper presents
UWB-PostureGuard, a privacy-preserving ultra-wideband (UWB) sensing system that
advances mobile technologies for preventive health management through
continuous, contactless monitoring of ergonomic sitting posture. Our system
leverages commercial UWB devices, utilizing comprehensive feature engineering
to extract multiple ergonomic sitting posture features. We develop PoseGBDT to
effectively capture temporal dependencies in posture patterns, addressing
limitations of traditional frame-wise classification approaches. Extensive
real-world evaluation across 10 participants and 19 distinct postures
demonstrates exceptional performance, achieving 99.11% accuracy while
maintaining robustness against environmental variables such as clothing
thickness, additional devices, and furniture configurations. Our system
provides a scalable, privacy-preserving mobile health solution on existing
platforms for proactive ergonomic management, improving quality of life at low
costs.

</details>


### [74] [Residual-based Efficient Bidirectional Diffusion Model for Image Dehazing and Haze Generation](https://arxiv.org/abs/2508.11134)
*Bing Liu,Le Wang,Hao Liu,Mingming Liu*

Main category: cs.CV

TL;DR: 提出了一个残差双向扩散模型(RBDM)，用于在有雾和无雾图像之间转换，并在合成的和真实世界的数据集上实现了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的深度去雾方法只专注于去除有雾图像中的雾霾，缺乏在有雾和无雾图像之间转换的能力。为了解决这个问题

Method: 提出了一种基于残差的有效双向扩散模型(RBDM)，它可以模拟去雾和雾生成的条件分布。设计了双马尔可夫链，可以有效地转移残差，并促进它们之间的双向平滑过渡。RBDM在单个时间步长扰动有雾和无雾图像，并预测扰动数据中的噪声，以同时学习条件分布。引入了一个在图像补丁上学习的统一评分函数，而不是整个图像。

Result: RBDM成功地实现了无雾和有雾图像之间的大小无关的双向转换，只需15个采样步骤。

Conclusion: RBDM在合成和真实世界的数据集上实现了优越或至少与最先进方法相当的性能。

Abstract: Current deep dehazing methods only focus on removing haze from hazy images,
lacking the capability to translate between hazy and haze-free images. To
address this issue, we propose a residual-based efficient bidirectional
diffusion model (RBDM) that can model the conditional distributions for both
dehazing and haze generation. Firstly, we devise dual Markov chains that can
effectively shift the residuals and facilitate bidirectional smooth transitions
between them. Secondly, the RBDM perturbs the hazy and haze-free images at
individual timesteps and predicts the noise in the perturbed data to
simultaneously learn the conditional distributions. Finally, to enhance
performance on relatively small datasets and reduce computational costs, our
method introduces a unified score function learned on image patches instead of
entire images. Our RBDM successfully implements size-agnostic bidirectional
transitions between haze-free and hazy images with only 15 sampling steps.
Extensive experiments demonstrate that the proposed method achieves superior or
at least comparable performance to state-of-the-art methods on both synthetic
and real-world datasets.

</details>


### [75] [A Cross-Modal Rumor Detection Scheme via Contrastive Learning by Exploring Text and Image internal Correlations](https://arxiv.org/abs/2508.11141)
*Bin Ma,Yifei Zhang,Yongjin Xian,Qi Li,Linna Zhou,Gongxun Miao*

Main category: cs.CV

TL;DR: This paper presents a novel cross-modal rumor detection scheme based on contrastive learning, namely the Multi-scale Image and Context Correlation exploration algorithm (MICC).


<details>
  <summary>Details</summary>
Motivation: Existing rumor detection methods often neglect the content within images as well as the inherent relationships between contexts and images across different visual scales, thereby resulting in the loss of critical information pertinent to rumor identification.

Method: design an SCLIP encoder to generate unified semantic embeddings for text and multi-scale image patches through contrastive pretraining, enabling their relevance to be measured via dot-product similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is introduced to identify image regions most relevant to the textual semantics, guided by mutual information maximization and the information bottleneck principle, through a Top-K selection strategy based on a cross-modal relevance matrix constructed between the text and multi-scale image patches. Moreover, a scale-aware fusion network is designed to integrate the highly correlated multi-scale image features with global text features by assigning adaptive weights to image regions based on their semantic importance and cross-modal relevance.

Result: achieves a substantial performance improvement over existing state-of-the-art approaches in rumor detection

Conclusion: The proposed methodology has been extensively evaluated on two real-world datasets. The experimental results demonstrate that it achieves a substantial performance improvement over existing state-of-the-art approaches in rumor detection, highlighting its effectiveness and potential for practical applications.

Abstract: Existing rumor detection methods often neglect the content within images as
well as the inherent relationships between contexts and images across different
visual scales, thereby resulting in the loss of critical information pertinent
to rumor identification. To address these issues, this paper presents a novel
cross-modal rumor detection scheme based on contrastive learning, namely the
Multi-scale Image and Context Correlation exploration algorithm (MICC).
Specifically, we design an SCLIP encoder to generate unified semantic
embeddings for text and multi-scale image patches through contrastive
pretraining, enabling their relevance to be measured via dot-product
similarity. Building upon this, a Cross-Modal Multi-Scale Alignment module is
introduced to identify image regions most relevant to the textual semantics,
guided by mutual information maximization and the information bottleneck
principle, through a Top-K selection strategy based on a cross-modal relevance
matrix constructed between the text and multi-scale image patches. Moreover, a
scale-aware fusion network is designed to integrate the highly correlated
multi-scale image features with global text features by assigning adaptive
weights to image regions based on their semantic importance and cross-modal
relevance. The proposed methodology has been extensively evaluated on two
real-world datasets. The experimental results demonstrate that it achieves a
substantial performance improvement over existing state-of-the-art approaches
in rumor detection, highlighting its effectiveness and potential for practical
applications.

</details>


### [76] [LEARN: A Story-Driven Layout-to-Image Generation Framework for STEM Instruction](https://arxiv.org/abs/2508.11153)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: LEARN is a layout-aware diffusion framework that generates pedagogically aligned illustrations for STEM education.


<details>
  <summary>Details</summary>
Motivation: counter fragmented attention often induced by short-form media and promotes sustained conceptual focus

Method: layout-conditioned generation, contrastive visual-semantic training, and prompt modulation

Result: produces coherent visual sequences that support mid-to-high-level reasoning in line with Bloom's taxonomy while reducing extraneous cognitive load as emphasized by Cognitive Load Theory

Conclusion: LEARN represents a novel direction for generative AI in education by unifying layout-based storytelling, semantic structure learning, and cognitive scaffolding.

Abstract: LEARN is a layout-aware diffusion framework designed to generate
pedagogically aligned illustrations for STEM education. It leverages a curated
BookCover dataset that provides narrative layouts and structured visual cues,
enabling the model to depict abstract and sequential scientific concepts with
strong semantic alignment. Through layout-conditioned generation, contrastive
visual-semantic training, and prompt modulation, LEARN produces coherent visual
sequences that support mid-to-high-level reasoning in line with Bloom's
taxonomy while reducing extraneous cognitive load as emphasized by Cognitive
Load Theory. By fostering spatially organized and story-driven narratives, the
framework counters fragmented attention often induced by short-form media and
promotes sustained conceptual focus. Beyond static diagrams, LEARN demonstrates
potential for integration with multimodal systems and curriculum-linked
knowledge graphs to create adaptive, exploratory educational content. As the
first generative approach to unify layout-based storytelling, semantic
structure learning, and cognitive scaffolding, LEARN represents a novel
direction for generative AI in education. The code and dataset will be released
to facilitate future research and practical deployment.

</details>


### [77] [Semi-supervised Image Dehazing via Expectation-Maximization and Bidirectional Brownian Bridge Diffusion Models](https://arxiv.org/abs/2508.11165)
*Bing Liu,Le Wang,Mingming Liu,Hao Liu,Rui Yao,Yong Zhou,Peng Liu,Tongqiang Xia*

Main category: cs.CV

TL;DR: 提出了一种基于 EM-B3DM 的半监督图像去雾方法，该方法在合成和真实世界数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的去雾方法难以处理真实世界的雾霾图像，尤其是浓雾场景，主要原因是缺乏真实的配对数据和鲁棒的先验。

Method: 通过期望最大化和双向布朗桥扩散模型 (EM-B3DM) 的高效半监督图像去雾方法

Result: 引入了细节增强的残差差分卷积块 (RDC) 以捕获梯度级信息，显着增强了模型的表示能力。

Conclusion: EM-B3DM 在合成和真实世界数据集上实现了优越或至少与最先进方法相当的性能。

Abstract: Existing dehazing methods deal with real-world haze images with difficulty,
especially scenes with thick haze. One of the main reasons is the lack of
real-world paired data and robust priors. To avoid the costly collection of
paired hazy and clear images, we propose an efficient semi-supervised image
dehazing method via Expectation-Maximization and Bidirectional Brownian Bridge
Diffusion Models (EM-B3DM) with a two-stage learning scheme. In the first
stage, we employ the EM algorithm to decouple the joint distribution of paired
hazy and clear images into two conditional distributions, which are then
modeled using a unified Brownian Bridge diffusion model to directly capture the
structural and content-related correlations between hazy and clear images. In
the second stage, we leverage the pre-trained model and large-scale unpaired
hazy and clear images to further improve the performance of image dehazing.
Additionally, we introduce a detail-enhanced Residual Difference Convolution
block (RDC) to capture gradient-level information, significantly enhancing the
model's representation capability. Extensive experiments demonstrate that our
EM-B3DM achieves superior or at least comparable performance to
state-of-the-art methods on both synthetic and real-world datasets.

</details>


### [78] [Better Supervised Fine-tuning for VQA: Integer-Only Loss](https://arxiv.org/abs/2508.11170)
*Baihong Qian,Haotian Fan,Wenjie Liao,Yunqiu Wang,Tao Li,Junhui Cui*

Main category: cs.CV

TL;DR: 提出了一种新颖的整数VQA微调方法，通过整数标签约束和目标掩码策略，提升视觉语言模型在视频质量评估任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常存在结果不精确和损失计算效率低下的问题，这限制了模型对关键评估指标的关注。

Method: 提出了一种名为IOVQA（Integer-only VQA）的微调方法，专门用于增强视觉语言模型在视频质量评估任务中的性能。该方法的核心创新在于其标签构建和有针对性的损失计算机制。

Result: 实验结果表明，该方法显著提高了模型在视频质量评估任务中的准确性和一致性，在VQualA 2025 GenAI-Bench AIGC视频质量评估挑战赛的第一赛道中排名第三。

Conclusion: 该研究表明，仅保留整数标签进行微调可以有效优化视觉语言模型在定量评估场景中的表现。

Abstract: With the rapid advancement of vision language models(VLM), their ability to
assess visual content based on specific criteria and dimensions has become
increasingly critical for applications such as video-theme consistency
assessment and visual quality scoring. However, existing methods often suffer
from imprecise results and inefficient loss calculation, which limit the focus
of the model on key evaluation indicators. To address this, we propose
IOVQA(Integer-only VQA), a novel fine-tuning approach tailored for VLMs to
enhance their performance in video quality assessment tasks. The key innovation
of IOVQA lies in its label construction and its targeted loss calculation
mechanism. Specifically, during dataset curation, we constrain the model's
output to integers within the range of [10,50], ensuring numerical stability,
and convert decimal Overall_MOS to integer before using them as labels. We also
introduce a target-mask strategy: when computing the loss, only the first
two-digit-integer of the label is unmasked, forcing the model to learn the
critical components of the numerical evaluation. After fine-tuning the
Qwen2.5-VL model using the constructed dataset, experimental results
demonstrate that the proposed method significantly improves the model's
accuracy and consistency in the VQA task, ranking 3rd in VQualA 2025
GenAI-Bench AIGC Video Quality Assessment Challenge -- Track I. Our work
highlights the effectiveness of merely leaving integer labels during
fine-tuning, providing an effective idea for optimizing VLMs in quantitative
evaluation scenarios.

</details>


### [79] [VFM-Guided Semi-Supervised Detection Transformer for Source-Free Object Detection in Remote Sensing Images](https://arxiv.org/abs/2508.11167)
*Jianhong Han,Yupei Wang,Liang Chen*

Main category: cs.CV

TL;DR: 提出了一种名为VG-DETR的视觉基础引导检测转换器，用于解决无源遥感图像中的目标检测问题。


<details>
  <summary>Details</summary>
Motivation: 无监督域适应方法已被广泛探索以弥合域差距。然而，在真实的遥感场景中，隐私和传输约束通常会阻止访问源域数据，这限制了它们的实际适用性。最近，无源对象检测（SFOD）已经成为一种有前途的替代方案，旨在实现跨域适应，而无需依赖源数据，主要通过自训练范式。尽管具有潜力，但SFOD经常会受到由嘈杂的伪标签引起的训练崩溃的影响，尤其是在具有密集对象和复杂背景的遥感图像中。考虑到在实践中通常有限的目标域注释是可行的。

Method: VG-DETR，建立在半监督框架之上，用于遥感图像中的SFOD。VG-DETR以“免费午餐”的方式将视觉基础模型（VFM）集成到训练流程中，利用少量标记的目标数据来减轻伪标签噪声，同时提高检测器的特征提取能力。引入了一种VFM引导的伪标签挖掘策略，该策略利用VFM的语义先验来进一步评估生成的伪标签的可靠性。此外，还提出了一种双层VFM引导的对齐方法，该方法在实例和图像级别将检测器特征与VFM嵌入对齐。

Result: 通过从低置信度输出中恢复潜在的正确预测，该策略提高了伪标签的质量和数量。此外，一种双层VFM引导的对齐方法被提出，该方法在实例和图像级别将检测器特征与VFM嵌入对齐。通过细粒度原型之间的对比学习和特征图之间的相似性匹配，这种双层对齐进一步增强了特征表示对域间隙的鲁棒性。

Conclusion: VG-DETR在无源遥感检测任务中表现出色。

Abstract: Unsupervised domain adaptation methods have been widely explored to bridge
domain gaps. However, in real-world remote-sensing scenarios, privacy and
transmission constraints often preclude access to source domain data, which
limits their practical applicability. Recently, Source-Free Object Detection
(SFOD) has emerged as a promising alternative, aiming at cross-domain
adaptation without relying on source data, primarily through a self-training
paradigm. Despite its potential, SFOD frequently suffers from training collapse
caused by noisy pseudo-labels, especially in remote sensing imagery with dense
objects and complex backgrounds. Considering that limited target domain
annotations are often feasible in practice, we propose a Vision
foundation-Guided DEtection TRansformer (VG-DETR), built upon a semi-supervised
framework for SFOD in remote sensing images. VG-DETR integrates a Vision
Foundation Model (VFM) into the training pipeline in a "free lunch" manner,
leveraging a small amount of labeled target data to mitigate pseudo-label noise
while improving the detector's feature-extraction capability. Specifically, we
introduce a VFM-guided pseudo-label mining strategy that leverages the VFM's
semantic priors to further assess the reliability of the generated
pseudo-labels. By recovering potentially correct predictions from
low-confidence outputs, our strategy improves pseudo-label quality and
quantity. In addition, a dual-level VFM-guided alignment method is proposed,
which aligns detector features with VFM embeddings at both the instance and
image levels. Through contrastive learning among fine-grained prototypes and
similarity matching between feature maps, this dual-level alignment further
enhances the robustness of feature representations against domain gaps.
Extensive experiments demonstrate that VG-DETR achieves superior performance in
source-free remote sensing detection tasks.

</details>


### [80] [Exploring the Tradeoff Between Diversity and Discrimination for Continuous Category Discovery](https://arxiv.org/abs/2508.11173)
*Ruobing Jiang,Yang Liu,Haobing Liu,Yanwei Yu,Chunyang Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 IDOD 的新方法，用于连续类别发现，该方法通过独立性、多样性和正交性来解决现有方法的局限性，并在实验中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 大多数 CCD 方法不能很好地处理新类发现和分类之间的矛盾，并且容易在逐渐发现新类的过程中积累错误。此外，他们中的大多数人使用知识蒸馏和数据重放来防止遗忘，占用更多的存储空间。

Method: 独立富集的多样性模块，新颖性联合发现模块，基于正交性的连续增量模块

Result: 在具有挑战性的细粒度数据集上，该方法优于现有技术方法。

Conclusion: 该方法在具有挑战性的细粒度数据集上优于现有技术方法。

Abstract: Continuous category discovery (CCD) aims to automatically discover novel
categories in continuously arriving unlabeled data. This is a challenging
problem considering that there is no number of categories and labels in the
newly arrived data, while also needing to mitigate catastrophic forgetting.
Most CCD methods cannot handle the contradiction between novel class discovery
and classification well. They are also prone to accumulate errors in the
process of gradually discovering novel classes. Moreover, most of them use
knowledge distillation and data replay to prevent forgetting, occupying more
storage space. To address these limitations, we propose Independence-based
Diversity and Orthogonality-based Discrimination (IDOD). IDOD mainly includes
independent enrichment of diversity module, joint discovery of novelty module,
and continuous increment by orthogonality module. In independent enrichment,
the backbone is trained separately using contrastive loss to avoid it focusing
only on features for classification. Joint discovery transforms multi-stage
novel class discovery into single-stage, reducing error accumulation impact.
Continuous increment by orthogonality module generates mutually orthogonal
prototypes for classification and prevents forgetting with lower space overhead
via representative representation replay. Experimental results show that on
challenging fine-grained datasets, our method outperforms the state-of-the-art
methods.

</details>


### [81] [Fine-Grained VLM Fine-tuning via Latent Hierarchical Adapter Learning](https://arxiv.org/abs/2508.11176)
*Yumiao Zhao,Bo Jiang,Yuhe Ding,Xiao Wang,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: This paper introduces LatHAdapter, a novel Latent Hierarchical Adapter for fine-tuning VLMs. It addresses the limitations of existing adapters by exploiting the latent semantic hierarchy of downstream training data and modeling the inherent one-to-many associations among categories, learnable attributes, and image samples in a hyperbolic space. Experiments show it outperforms other fine-tuning approaches.


<details>
  <summary>Details</summary>
Motivation: Existing adapters generally learn/align (category) textual-visual modalities via explicit spatial proximity in the underlying embedding space, which i) fails to capture the inherent one-to-many associations between categories and image samples and ii) struggles to establish accurate associations between the unknown categories and images.

Method: develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs on downstream few-shot classification tasks. The core of LatHAdapter is to exploit the latent semantic hierarchy of downstream training data and employ it to provide richer, fine-grained guidance for the adapter learning process. Specifically, LatHAdapter first introduces some learnable `attribute' prompts as the bridge to align categories and images. Then, it projects the categories, attribute prompts, and images within each batch in a hyperbolic space, and employs hierarchical regularization to learn the latent semantic hierarchy of them, thereby fully modeling the inherent one-to-many associations among categories, learnable attributes, and image samples.

Result: Extensive experiments on four challenging few-shot tasks show that the proposed LatHAdapter consistently outperforms many other fine-tuning approaches, particularly in adapting known classes and generalizing to unknown classes.

Conclusion: The proposed LatHAdapter consistently outperforms many other fine-tuning approaches, particularly in adapting known classes and generalizing to unknown classes.

Abstract: Adapter-based approaches have garnered attention for fine-tuning pre-trained
Vision-Language Models (VLMs) on few-shot classification tasks. These methods
strive to develop a lightweight module that better aligns visual and (category)
textual representations, thereby enhancing performance on downstream few-shot
learning tasks. However, existing adapters generally learn/align (category)
textual-visual modalities via explicit spatial proximity in the underlying
embedding space, which i) fails to capture the inherent one-to-many
associations between categories and image samples and ii) struggles to
establish accurate associations between the unknown categories and images. To
address these issues, inspired by recent works on hyperbolic learning, we
develop a novel Latent Hierarchical Adapter (LatHAdapter) for fine-tuning VLMs
on downstream few-shot classification tasks. The core of LatHAdapter is to
exploit the latent semantic hierarchy of downstream training data and employ it
to provide richer, fine-grained guidance for the adapter learning process.
Specifically, LatHAdapter first introduces some learnable `attribute' prompts
as the bridge to align categories and images. Then, it projects the categories,
attribute prompts, and images within each batch in a hyperbolic space, and
employs hierarchical regularization to learn the latent semantic hierarchy of
them, thereby fully modeling the inherent one-to-many associations among
categories, learnable attributes, and image samples. Extensive experiments on
four challenging few-shot tasks show that the proposed LatHAdapter consistently
outperforms many other fine-tuning approaches, particularly in adapting known
classes and generalizing to unknown classes.

</details>


### [82] [Versatile Video Tokenization with Generative 2D Gaussian Splatting](https://arxiv.org/abs/2508.11183)
*Zhenghao Chen,Zicong Chen,Lei Liu,Yiming Wu,Dong Xu*

Main category: cs.CV

TL;DR: 提出了高斯视频Transformer（GVT），一种基于生成式2D高斯溅射（2DGS）策略的通用视频分词器，在视频重建、动作识别和压缩方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的方法直接将视频转换为固定网格和分块令牌，这表现出有限的通用性。在空间上，统一分配固定数量的令牌通常会导致低信息区域的过度编码。在时间上，在没有明确区分静态和动态内容的情况下，减少冗余仍然具有挑战性。

Method: 提出了一种基于生成式2D高斯溅射（2DGS）策略的通用视频分词器——高斯视频Transformer（GVT）。

Result: GVT在视频重建方面实现了最先进的质量，在动作识别方面优于基线MAGVIT-v2，并提供了可比较的压缩性能。

Conclusion: GVT在视频重建方面实现了最先进的质量，在动作识别方面优于基线MAGVIT-v2，并提供了可比较的压缩性能。

Abstract: Video tokenization procedure is critical for a wide range of video processing
tasks. Most existing approaches directly transform video into fixed-grid and
patch-wise tokens, which exhibit limited versatility. Spatially, uniformly
allocating a fixed number of tokens often leads to over-encoding in
low-information regions. Temporally, reducing redundancy remains challenging
without explicitly distinguishing between static and dynamic content. In this
work, we propose the Gaussian Video Transformer (GVT), a versatile video
tokenizer built upon a generative 2D Gaussian Splatting (2DGS) strategy. We
first extract latent rigid features from a video clip and represent them with a
set of 2D Gaussians generated by our proposed Spatio-Temporal Gaussian
Embedding (STGE) mechanism in a feed-forward manner. Such generative 2D
Gaussians not only enhance spatial adaptability by assigning higher (resp.,
lower) rendering weights to regions with higher (resp., lower) information
content during rasterization, but also improve generalization by avoiding
per-video optimization.To enhance the temporal versatility, we introduce a
Gaussian Set Partitioning (GSP) strategy that separates the 2D Gaussians into
static and dynamic sets, which explicitly model static content shared across
different time-steps and dynamic content specific to each time-step, enabling a
compact representation.We primarily evaluate GVT on the video reconstruction,
while also assessing its performance on action recognition and compression
using the UCF101, Kinetics, and DAVIS datasets. Extensive experiments
demonstrate that GVT achieves a state-of-the-art video reconstruction quality,
outperforms the baseline MAGVIT-v2 in action recognition, and delivers
comparable compression performance.

</details>


### [83] [CHARM3R: Towards Unseen Camera Height Robust Monocular 3D Detector](https://arxiv.org/abs/2508.11185)
*Abhinav Kumar,Yuliang Guo,Zhihao Zhang,Xinyu Huang,Liu Ren,Xiaoming Liu*

Main category: cs.CV

TL;DR: 本文研究了相机高度变化对单目3D目标检测的影响，并提出了一种新的检测器CHARM3R，该检测器在不同相机高度下具有更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测器在来自一个自 Ego 相机高度的数据上有效，但在未见过或超出分布的相机高度上表现不佳。现有的方法通常依赖于 Plucker 嵌入、图像转换或数据增强。本文旨在研究相机高度变化对当前最优 (SoTA) Mono3D 模型的影响。

Method: 提出了一种名为Camera Height Robust Monocular 3D Detector (CHARM3R) 的方法，该方法平均模型中的深度估计。

Result: CHARM3R 将对未见过的相机高度的泛化能力提高了 45% 以上，在 CARLA 数据集上实现了 SoTA 性能。

Conclusion: CHARM3R通过平均模型中的深度估计，提高了对未见过的相机高度的泛化能力，在CARLA数据集上实现了SoTA性能。

Abstract: Monocular 3D object detectors, while effective on data from one ego camera
height, struggle with unseen or out-of-distribution camera heights. Existing
methods often rely on Plucker embeddings, image transformations or data
augmentation. This paper takes a step towards this understudied problem by
first investigating the impact of camera height variations on state-of-the-art
(SoTA) Mono3D models. With a systematic analysis on the extended CARLA dataset
with multiple camera heights, we observe that depth estimation is a primary
factor influencing performance under height variations. We mathematically prove
and also empirically observe consistent negative and positive trends in mean
depth error of regressed and ground-based depth models, respectively, under
camera height changes. To mitigate this, we propose Camera Height Robust
Monocular 3D Detector (CHARM3R), which averages both depth estimates within the
model. CHARM3R improves generalization to unseen camera heights by more than
$45\%$, achieving SoTA performance on the CARLA dataset. Codes and Models at
https://github.com/abhi1kumar/CHARM3R

</details>


### [84] [Generating Dialogues from Egocentric Instructional Videos for Task Assistance: Dataset, Method and Benchmark](https://arxiv.org/abs/2508.11192)
*Lavisha Aggarwal,Vikas Bahirwani,Lin Li,Andrea Colaco*

Main category: cs.CV

TL;DR: This paper introduces HowToDIV, a large-scale dialogue-video dataset for real-world task assistance, created using an automatic approach powered by large language models. It establishes baseline performance using the Gemma-3 model.


<details>
  <summary>Details</summary>
Motivation: Many everyday tasks ranging from fixing appliances, cooking recipes to car maintenance require expert knowledge, especially when tasks are complex and multi-step. Despite growing interest in AI agents, there is a scarcity of dialogue-video datasets grounded for real world task assistance.

Method: Our fully automatic approach, powered by large language models, offers an efficient alternative to the substantial cost and effort required for human-assisted data collection. Using this technique, we build HowToDIV, a large-scale dataset containing 507 conversations, 6636 question-answer pairs and 24 hours of videoclips across diverse tasks in cooking, mechanics, and planting.

Result: Each session includes multi-turn conversation where an expert teaches a novice user how to perform a task step by step, while observing user's surrounding through a camera and microphone equipped wearable device.

Conclusion: We establish the baseline benchmark performance on HowToDIV dataset through Gemma-3 model for future research on this new task of dialogues for procedural-task assistance.

Abstract: Many everyday tasks ranging from fixing appliances, cooking recipes to car
maintenance require expert knowledge, especially when tasks are complex and
multi-step. Despite growing interest in AI agents, there is a scarcity of
dialogue-video datasets grounded for real world task assistance. In this paper,
we propose a simple yet effective approach that transforms single-person
instructional videos into task-guidance two-person dialogues, aligned with fine
grained steps and video-clips. Our fully automatic approach, powered by large
language models, offers an efficient alternative to the substantial cost and
effort required for human-assisted data collection. Using this technique, we
build HowToDIV, a large-scale dataset containing 507 conversations, 6636
question-answer pairs and 24 hours of videoclips across diverse tasks in
cooking, mechanics, and planting. Each session includes multi-turn conversation
where an expert teaches a novice user how to perform a task step by step, while
observing user's surrounding through a camera and microphone equipped wearable
device. We establish the baseline benchmark performance on HowToDIV dataset
through Gemma-3 model for future research on this new task of dialogues for
procedural-task assistance.

</details>


### [85] [Generalized Decoupled Learning for Enhancing Open-Vocabulary Dense Perception](https://arxiv.org/abs/2508.11256)
*Junjie Wang,Keyu Chen,Yulin Li,Bin Chen,Hengshuang Zhao,Xiaojuan Qi,Zhuotao Tian*

Main category: cs.CV

TL;DR: DeCLIP通过解耦自注意力模块并增强内容和上下文特征，解决了CLIP在开放词汇密集感知任务中的局限性，并在多个任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的密集视觉感知任务受限于预定义的类别，而视觉语言模型(VLMs)在密集感知上的直接应用由于局部特征表示的限制导致性能欠佳。CLIP的图像tokens难以有效聚合来自空间或语义相关区域的信息，导致特征缺乏局部区分性和空间一致性。

Method: 提出了DeCLIP，通过解耦自注意力模块来获得“内容”和“上下文”特征，并分别进行增强。

Result: DeCLIP在广泛的任务中持续取得了最先进的性能。

Conclusion: DeCLIP在开放词汇密集感知任务上取得了最先进的性能，包括2D检测和分割、3D实例分割、视频实例分割和6D物体姿态估计。

Abstract: Dense visual perception tasks have been constrained by their reliance on
predefined categories, limiting their applicability in real-world scenarios
where visual concepts are unbounded. While Vision-Language Models (VLMs) like
CLIP have shown promise in open-vocabulary tasks, their direct application to
dense perception often leads to suboptimal performance due to limitations in
local feature representation. In this work, we present our observation that
CLIP's image tokens struggle to effectively aggregate information from
spatially or semantically related regions, resulting in features that lack
local discriminability and spatial consistency. To address this issue, we
propose DeCLIP, a novel framework that enhances CLIP by decoupling the
self-attention module to obtain ``content'' and ``context'' features
respectively. \revise{The context features are enhanced by jointly distilling
semantic correlations from Vision Foundation Models (VFMs) and object integrity
cues from diffusion models, thereby enhancing spatial consistency. In parallel,
the content features are aligned with image crop representations and
constrained by region correlations from VFMs to improve local discriminability.
Extensive experiments demonstrate that DeCLIP establishes a solid foundation
for open-vocabulary dense perception, consistently achieving state-of-the-art
performance across a broad spectrum of tasks, including 2D detection and
segmentation, 3D instance segmentation, video instance segmentation, and 6D
object pose estimation.} Code is available at
https://github.com/xiaomoguhz/DeCLIP

</details>


### [86] [UAV-VL-R1: Generalizing Vision-Language Models via Supervised Fine-Tuning and Multi-Stage GRPO for UAV Visual Reasoning](https://arxiv.org/abs/2508.11196)
*Jiajin Guan,Haibo Mei,Bonan Zhang,Dan Liu,Yuanshuang Fu,Yue Zhang*

Main category: cs.CV

TL;DR: UAV-VL-R1, a lightweight VLM for aerial visual reasoning, outperforms larger models on UAV tasks with less memory usage, using a hybrid SFT and RL training approach and a new high-resolution VQA dataset.


<details>
  <summary>Details</summary>
Motivation: general-purpose VLMs performance degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features high resolution, complex spatial semantics, and strict real-time constraints. These challenges limit the applicability of general-purpose VLMs to structured aerial reasoning tasks.

Method: a lightweight VLM explicitly designed for aerial visual reasoning. It is trained using a hybrid method that combines supervised fine-tuning (SFT) and multi-stage reinforcement learning (RL). We leverage the group relative policy optimization (GRPO) algorithm to promote structured and interpretable reasoning through rule-guided rewards and intra-group policy alignment.

Result: UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which is 36x larger, on multiple tasks.

Conclusion: UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant on multiple tasks. Ablation studies reveal that while SFT improves semantic alignment, it may reduce reasoning diversity in mathematical tasks. GRPO-based RL compensates for this limitation by enhancing logical flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with INT8, supporting real-time deployment on resource-constrained UAV platforms.

Abstract: Recent advances in vision-language models (VLMs) have demonstrated strong
generalization in natural image tasks. However, their performance often
degrades on unmanned aerial vehicle (UAV)-based aerial imagery, which features
high resolution, complex spatial semantics, and strict real-time constraints.
These challenges limit the applicability of general-purpose VLMs to structured
aerial reasoning tasks. To address these challenges, we propose UAV-VL-R1, a
lightweight VLM explicitly designed for aerial visual reasoning. It is trained
using a hybrid method that combines supervised fine-tuning (SFT) and
multi-stage reinforcement learning (RL). We leverage the group relative policy
optimization (GRPO) algorithm to promote structured and interpretable reasoning
through rule-guided rewards and intra-group policy alignment. To support model
training and evaluation, we introduce a high-resolution visual question
answering dataset named HRVQA-VL, which consists of 50,019 annotated samples
covering eight UAV-relevant reasoning tasks, including object counting,
transportation recognition, and spatial scene inference. Experimental results
show that UAV-VL-R1 achieves a 48.17% higher zero-shot accuracy than the
Qwen2-VL-2B-Instruct baseline and even outperforms its 72B-scale variant, which
is 36x larger, on multiple tasks. Ablation studies reveal that while SFT
improves semantic alignment, it may reduce reasoning diversity in mathematical
tasks. GRPO-based RL compensates for this limitation by enhancing logical
flexibility and the robustness of inference. Additionally, UAV-VL-R1 requires
only 3.9GB of memory under FP16 inference and can be quantized to 2.5GB with
INT8, supporting real-time deployment on resource-constrained UAV platforms.

</details>


### [87] [Vision-Language Models display a strong gender bias](https://arxiv.org/abs/2508.11262)
*Aiswarya Konavoor,Raj Abhijit Dandekar,Rajat Dandekar,Sreedath Panat*

Main category: cs.CV

TL;DR: 该研究通过计算面部图像和职业描述短语的嵌入向量的余弦相似度，来评估对比视觉-语言模型中的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型（VLM）在共享表示空间中对齐图像和文本，这对于检索和零样本迁移非常有用。然而，这种对齐会以微妙的方式编码和放大社会刻板印象，而这在标准准确性指标中并不明显。

Method: 该研究计算了每个人脸的单位范数图像嵌入和每个语句的单位范数文本嵌入，然后将语句级关联得分定义为与男性集合的平均余弦相似度与与女性集合的平均余弦相似度之间的差值。

Result: 该研究测试了对比视觉-语言编码器在将面部图像的嵌入置于描述职业和活动的短语的嵌入附近时，是否表现出与性别相关的关联。

Conclusion: 该研究提供了一份关于对比视觉-语言空间中性别关联的声明式和类别式地图，并附有不确定性、简单的健全性检查和一个稳健的性别偏见评估框架。

Abstract: Vision-language models (VLM) align images and text in a shared representation
space that is useful for retrieval and zero-shot transfer. Yet, this alignment
can encode and amplify social stereotypes in subtle ways that are not obvious
from standard accuracy metrics. In this study, we test whether the contrastive
vision-language encoder exhibits gender-linked associations when it places
embeddings of face images near embeddings of short phrases that describe
occupations and activities. We assemble a dataset of 220 face photographs split
by perceived binary gender and a set of 150 unique statements distributed
across six categories covering emotional labor, cognitive labor, domestic
labor, technical labor, professional roles, and physical labor. We compute
unit-norm image embeddings for every face and unit-norm text embeddings for
every statement, then define a statement-level association score as the
difference between the mean cosine similarity to the male set and the mean
cosine similarity to the female set, where positive values indicate stronger
association with the male set and negative values indicate stronger association
with the female set. We attach bootstrap confidence intervals by resampling
images within each gender group, aggregate by category with a separate
bootstrap over statements, and run a label-swap null model that estimates the
level of mean absolute association we would expect if no gender structure were
present. The outcome is a statement-wise and category-wise map of gender
associations in a contrastive vision-language space, accompanied by
uncertainty, simple sanity checks, and a robust gender bias evaluation
framework.

</details>


### [88] [A Coarse-to-Fine Human Pose Estimation Method based on Two-stage Distillation and Progressive Graph Neural Network](https://arxiv.org/abs/2508.11212)
*Zhangjian Ji,Wenjin Zhang,Shaotong Qiao,Kai Feng,Yuhua Qian*

Main category: cs.CV

TL;DR: 提出了一种新颖的由粗到精的两阶段知识蒸馏框架，用于人体姿势估计, 并且在COCO keypoint和CrowdPose数据集上进行了大量实验，结果表明，该方法优于许多现有的最先进的人体姿势估计方法。


<details>
  <summary>Details</summary>
Motivation: 现有的最先进的人体姿势估计方法需要大量的计算资源来进行准确的预测。为了获得一个准确、鲁棒且轻量级的人体姿势估计器，一种可行的方法是通过知识蒸馏将姿势知识从强大的教师模型转移到参数较少的学生模型。

Method: 该论文提出了一种新颖的由粗到精的两阶段知识蒸馏框架，用于人体姿势估计。在第一阶段的蒸馏中，引入了人体关节结构损失，以挖掘人体关节之间的结构信息，从而将高级语义知识从教师模型转移到学生模型。在第二阶段的蒸馏中，利用图像引导的渐进图卷积网络（IGP-GCN）来细化从第一阶段蒸馏获得的初始人体姿势，并通过教师模型的最终输出姿势以渐进的方式监督IGP-GCN的训练。

Result: 该模型在COCO keypoint和CrowdPose数据集上进行了大量实验，结果表明，该方法优于许多现有的最先进的人体姿势估计方法，特别是在更复杂的CrowdPose数据集上，该模型的性能提升更为显著。

Conclusion: 该模型在COCO keypoint和CrowdPose数据集上进行了大量实验，结果表明，该方法优于许多现有的最先进的人体姿势估计方法，特别是在更复杂的CrowdPose数据集上，该模型的性能提升更为显著。

Abstract: Human pose estimation has been widely applied in the human-centric
understanding and generation, but most existing state-of-the-art human pose
estimation methods require heavy computational resources for accurate
predictions. In order to obtain an accurate, robust yet lightweight human pose
estimator, one feasible way is to transfer pose knowledge from a powerful
teacher model to a less-parameterized student model by knowledge distillation.
However, the traditional knowledge distillation framework does not fully
explore the contextual information among human joints. Thus, in this paper, we
propose a novel coarse-to-fine two-stage knowledge distillation framework for
human pose estimation. In the first-stage distillation, we introduce the human
joints structure loss to mine the structural information among human joints so
as to transfer high-level semantic knowledge from the teacher model to the
student model. In the second-stage distillation, we utilize an Image-Guided
Progressive Graph Convolutional Network (IGP-GCN) to refine the initial human
pose obtained from the first-stage distillation and supervise the training of
the IGP-GCN in the progressive way by the final output pose of teacher model.
The extensive experiments on the benchmark dataset: COCO keypoint and CrowdPose
datasets, show that our proposed method performs favorably against lots of the
existing state-of-the-art human pose estimation methods, especially for the
more complex CrowdPose dataset, the performance improvement of our model is
more significant.

</details>


### [89] [Enhancing Supervised Composed Image Retrieval via Reasoning-Augmented Representation Engineering](https://arxiv.org/abs/2508.11272)
*Jun Li,Kai Li,Shaoguo Liu,Tingting Gao*

Main category: cs.CV

TL;DR: PMTFR通过金字塔匹配模型和免训练细化，提升了有监督的组合图像检索任务的性能，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要额外训练排序模型，并且Chain-of-Thought (CoT) 技术在 CIR 任务中的应用仍然有限。

Method: 金字塔匹配模型与免训练细化(PMTFR)

Result: 在 CIR 基准上的大量实验表明，PMTFR 在有监督的 CIR 任务中超越了最先进的方法。

Conclusion: PMTFR在有监督的CIR任务中超越了最先进的方法。

Abstract: Composed Image Retrieval (CIR) presents a significant challenge as it
requires jointly understanding a reference image and a modified textual
instruction to find relevant target images. Some existing methods attempt to
use a two-stage approach to further refine retrieval results. However, this
often requires additional training of a ranking model. Despite the success of
Chain-of-Thought (CoT) techniques in reducing training costs for language
models, their application in CIR tasks remains limited -- compressing visual
information into text or relying on elaborate prompt designs. Besides, existing
works only utilize it for zero-shot CIR, as it is challenging to achieve
satisfactory results in supervised CIR with a well-trained model. In this work,
we proposed a framework that includes the Pyramid Matching Model with
Training-Free Refinement (PMTFR) to address these challenges. Through a simple
but effective module called Pyramid Patcher, we enhanced the Pyramid Matching
Model's understanding of visual information at different granularities.
Inspired by representation engineering, we extracted representations from COT
data and injected them into the LVLMs. This approach allowed us to obtain
refined retrieval scores in the Training-Free Refinement paradigm without
relying on explicit textual reasoning, further enhancing performance. Extensive
experiments on CIR benchmarks demonstrate that PMTFR surpasses state-of-the-art
methods in supervised CIR tasks. The code will be made public.

</details>


### [90] [A CLIP-based Uncertainty Modal Modeling (UMM) Framework for Pedestrian Re-Identification in Autonomous Driving](https://arxiv.org/abs/2508.11218)
*Jialin Li,Shuqi Wu,Ning Wang*

Main category: cs.CV

TL;DR: 提出了一种轻量级UMM框架，用于解决自动驾驶中行人重识别中不确定或缺失模态的问题，该框架具有强大的鲁棒性、泛化性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，车载摄像头必须跨视图和时间实时识别行人，以支持安全导航和轨迹预测。然而，不确定或缺失的输入模态对传统ReID方法构成了重大挑战。大规模预训练模型计算开销大，限制了在资源受限环境中的实际部署。

Method: 轻量级不确定性模态建模（UMM）框架，集成了多模态令牌映射器、合成模态增强策略和跨模态线索交互学习器。

Result: 实验结果表明，UMM在不确定模态条件下实现了强大的鲁棒性、泛化性和计算效率。

Conclusion: UMM在不确定模态条件下实现了强大的鲁棒性、泛化性和计算效率，为自动驾驶场景中的行人重识别提供了一个可扩展的实用解决方案。

Abstract: Re-Identification (ReID) is a critical technology in intelligent perception
systems, especially within autonomous driving, where onboard cameras must
identify pedestrians across views and time in real-time to support safe
navigation and trajectory prediction. However, the presence of uncertain or
missing input modalities--such as RGB, infrared, sketches, or textual
descriptions--poses significant challenges to conventional ReID approaches.
While large-scale pre-trained models offer strong multimodal semantic modeling
capabilities, their computational overhead limits practical deployment in
resource-constrained environments. To address these challenges, we propose a
lightweight Uncertainty Modal Modeling (UMM) framework, which integrates a
multimodal token mapper, synthetic modality augmentation strategy, and
cross-modal cue interactive learner. Together, these components enable unified
feature representation, mitigate the impact of missing modalities, and extract
complementary information across different data types. Additionally, UMM
leverages CLIP's vision-language alignment ability to fuse multimodal inputs
efficiently without extensive finetuning. Experimental results demonstrate that
UMM achieves strong robustness, generalization, and computational efficiency
under uncertain modality conditions, offering a scalable and practical solution
for pedestrian re-identification in autonomous driving scenarios.

</details>


### [91] [FantasyTalking2: Timestep-Layer Adaptive Preference Optimization for Audio-Driven Portrait Animation](https://arxiv.org/abs/2508.11255)
*MengChao Wang,Qiang Wang,Fan Jiang,Mu Xu*

Main category: cs.CV

TL;DR: 提出了一种用于人像动画的TLPO框架，该框架使用多模态奖励模型Talking-Critic来学习人类对多维度的偏好，并在大规模数据集Talking-NSQ上进行了训练，实验表明，该框架在多个指标上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在运动自然度、唇形同步准确性和视觉质量等多个维度上与细粒度的人类偏好对齐。这是因为在相互竞争的偏好目标之间进行优化存在困难，而且缺乏具有多维偏好注释的大规模、高质量数据集。

Method: 提出了一种新的时间步长层自适应多专家偏好优化(TLPO)框架，用于将基于扩散的人像动画模型与细粒度的多维偏好对齐。TLPO将偏好解耦为专门的专家模块，然后将其在时间步长和网络层之间融合，从而能够在所有维度上进行全面、细粒度的增强，而不会相互干扰。

Result: Talking-Critic在与人类偏好评级对齐方面明显优于现有方法。TLPO在唇形同步准确性、运动自然性和视觉质量方面实现了显着改进。

Conclusion: TLPO在唇形同步准确性、运动自然性和视觉质量方面实现了显着改进，在定性和定量评估中均表现出卓越的性能。

Abstract: Recent advances in audio-driven portrait animation have demonstrated
impressive capabilities. However, existing methods struggle to align with
fine-grained human preferences across multiple dimensions, such as motion
naturalness, lip-sync accuracy, and visual quality. This is due to the
difficulty of optimizing among competing preference objectives, which often
conflict with one another, and the scarcity of large-scale, high-quality
datasets with multidimensional preference annotations. To address these, we
first introduce Talking-Critic, a multimodal reward model that learns
human-aligned reward functions to quantify how well generated videos satisfy
multidimensional expectations. Leveraging this model, we curate Talking-NSQ, a
large-scale multidimensional human preference dataset containing 410K
preference pairs. Finally, we propose Timestep-Layer adaptive multi-expert
Preference Optimization (TLPO), a novel framework for aligning diffusion-based
portrait animation models with fine-grained, multidimensional preferences. TLPO
decouples preferences into specialized expert modules, which are then fused
across timesteps and network layers, enabling comprehensive, fine-grained
enhancement across all dimensions without mutual interference. Experiments
demonstrate that Talking-Critic significantly outperforms existing methods in
aligning with human preference ratings. Meanwhile, TLPO achieves substantial
improvements over baseline models in lip-sync accuracy, motion naturalness, and
visual quality, exhibiting superior performance in both qualitative and
quantitative evaluations. Ours project page:
https://fantasy-amap.github.io/fantasy-talking2/

</details>


### [92] [Domain-aware Category-level Geometry Learning Segmentation for 3D Point Clouds](https://arxiv.org/abs/2508.11265)
*Pei He,Lingling Li,Licheng Jiao,Ronghua Shang,Fang Liu,Shuang Wang,Xu Liu,Wenping Ma*

Main category: cs.CV

TL;DR: Proposes a category-level geometry learning framework (CGE and GCL) to improve domain generalization in 3D semantic segmentation by focusing on domain-invariant geometric features.


<details>
  <summary>Details</summary>
Motivation: Domain generalization in 3D segmentation is a critical challenge. The model learns global geometric patterns while ignoring the category-level distribution and alignment.

Method: Category-level Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric properties of point cloud features, which constructs the geometric properties of each class and couples geometric embedding to semantic learning. Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D distribution and align the category-level geometric embeddings.

Result: Experimental results verify the effectiveness of the proposed method.

Conclusion: The proposed method achieves competitive segmentation accuracy compared to state-of-the-art domain generalized point cloud methods.

Abstract: Domain generalization in 3D segmentation is a critical challenge in deploying
models to unseen environments. Current methods mitigate the domain shift by
augmenting the data distribution of point clouds. However, the model learns
global geometric patterns in point clouds while ignoring the category-level
distribution and alignment. In this paper, a category-level geometry learning
framework is proposed to explore the domain-invariant geometric features for
domain generalized 3D semantic segmentation. Specifically, Category-level
Geometry Embedding (CGE) is proposed to perceive the fine-grained geometric
properties of point cloud features, which constructs the geometric properties
of each class and couples geometric embedding to semantic learning. Secondly,
Geometric Consistent Learning (GCL) is proposed to simulate the latent 3D
distribution and align the category-level geometric embeddings, allowing the
model to focus on the geometric invariant information to improve
generalization. Experimental results verify the effectiveness of the proposed
method, which has very competitive segmentation accuracy compared with the
state-of-the-art domain generalized point cloud methods.

</details>


### [93] [Leveraging the RETFound foundation model for optic disc segmentation in retinal images](https://arxiv.org/abs/2508.11354)
*Zhenyi Zhao,Muthu Rama Krishnan Mookiah,Emanuele Trucco*

Main category: cs.CV

TL;DR: 本文介绍了 RETFound 在视盘分割中的首次应用，优于现有技术水平。


<details>
  <summary>Details</summary>
Motivation: RETFound 是一种众所周知的基金会模型 (FM)，专为眼底相机和光学相干断层扫描图像而开发。它已在多个数据集中显示出有希望的性能，可从视网膜图像中诊断眼部特异性和全身性疾病。但是，据我们所知，它尚未用于其他任务。

Method: 将 RETFound 首次用于视盘分割，这是视网膜图像分析中普遍存在的基础任务。

Result: 由此产生的分割系统在仅使用非常适量的特定任务示例训练头部后，便胜过了最新的、特定于分割的基线网络。我们报告并讨论了四个公共数据集（IDRID、Drishti-GS、RIM-ONE-r3 和 REFUGE）和一个私有数据集 GoDARTS 的结果，在所有数据集中始终达到约 96% 的 Dice。

Conclusion: 该方法在内部验证、域泛化和域适应方面表现出色，超过了大多数最先进的基线结果。我们将在关于 FM 作为特定任务架构替代方案的辩论框架中讨论这些结果。

Abstract: RETFound is a well-known foundation model (FM) developed for fundus camera
and optical coherence tomography images. It has shown promising performance
across multiple datasets in diagnosing diseases, both eye-specific and
systemic, from retinal images. However, to our best knowledge, it has not been
used for other tasks. We present the first adaptation of RETFound for optic
disc segmentation, a ubiquitous and foundational task in retinal image
analysis. The resulting segmentation system outperforms state-of-the-art,
segmentation-specific baseline networks after training a head with only a very
modest number of task-specific examples. We report and discuss results with
four public datasets, IDRID, Drishti-GS, RIM-ONE-r3, and REFUGE, and a private
dataset, GoDARTS, achieving about 96% Dice consistently across all datasets.
Overall, our method obtains excellent performance in internal verification,
domain generalization and domain adaptation, and exceeds most of the
state-of-the-art baseline results. We discuss the results in the framework of
the debate about FMs as alternatives to task-specific architectures. The code
is available at: [link to be added after the paper is accepted]

</details>


### [94] [Probing the Representational Power of Sparse Autoencoders in Vision Models](https://arxiv.org/abs/2508.11277)
*Matthew Lyle Olson,Musashi Hinck,Neale Ratzlaff,Changbai Li,Phillip Howard,Vasudev Lal,Shao-Yen Tseng*

Main category: cs.CV

TL;DR: SAEs通过学习从稀疏瓶颈层重建激活，从LLM的高维内部表示中发现可解释的特征。本文对SAEs在视觉模型中的表征能力进行了广泛的评估，实验结果表明，SAE特征具有语义意义，提高了分布外泛化能力，并实现了跨三种视觉模型架构的可控生成。


<details>
  <summary>Details</summary>
Motivation: 尽管SAEs在语言模型中很受欢迎，但在视觉领域的研究仍然不足。

Method: 对SAEs在视觉模型中的表征能力进行了广泛的评估，使用了广泛的基于图像的任务。

Result: SAE特征具有语义意义，提高了分布外泛化能力，并实现了跨三种视觉模型架构的可控生成：视觉嵌入模型、多模态LMM和扩散模型。

Conclusion: SAEs在视觉模型中具有强大的潜力，可以提高可解释性、泛化性和可控性。

Abstract: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.

</details>


### [95] [Unifying Scale-Aware Depth Prediction and Perceptual Priors for Monocular Endoscope Pose Estimation and Tissue Reconstruction](https://arxiv.org/abs/2508.11282)
*Muzammil Khan,Enzo Kerkhof,Matteo Fusaglia,Koert Kuhlmann,Theo Ruers,Françoise J. Siepel*

Main category: cs.CV

TL;DR: Presents a unified framework for monocular endoscopic tissue reconstruction that integrates scale-aware depth prediction with temporally-constrained perceptual refinement to overcome limitations like depth ambiguity and tissue deformation.


<details>
  <summary>Details</summary>
Motivation: Accurate endoscope pose estimation and 3D tissue surface reconstruction significantly enhances monocular minimally invasive surgical procedures by enabling accurate navigation and improved spatial awareness. However, monocular endoscope pose estimation and tissue reconstruction face persistent challenges, including depth ambiguity, physiological tissue deformation, inconsistent endoscope motion, limited texture fidelity, and a restricted field of view.

Method: A unified framework for monocular endoscopic tissue reconstruction that integrates scale-aware depth prediction with temporally-constrained perceptual refinement is presented. This framework incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust initialisation and Depth Anything for efficient per-frame depth prediction, in conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth estimates. These estimates are temporally refined by computing pixel correspondences using RAFT and adaptively blending flow-warped frames based on LPIPS perceptual similarity, thereby reducing artefacts arising from physiological tissue deformation and motion. To ensure accurate registration of the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module is integrated, optimising both rotation and translation. Finally, truncated signed distance function-based volumetric fusion and marching cubes are applied to extract a comprehensive 3D surface mesh.

Result: A novel MAPIS-Depth module, which leverages Depth Pro for robust initialisation and Depth Anything for efficient per-frame depth prediction, in conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth estimates. These estimates are temporally refined by computing pixel correspondences using RAFT and adaptively blending flow-warped frames based on LPIPS perceptual similarity, thereby reducing artefacts arising from physiological tissue deformation and motion. To ensure accurate registration of the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module is integrated, optimising both rotation and translation. Finally, truncated signed distance function-based volumetric fusion and marching cubes are applied to extract a comprehensive 3D surface mesh.

Conclusion: The framework's robustness and superiority over state-of-the-art methods has been demonstrated through evaluations on HEVD and SCARED, with ablation and comparative analyses.

Abstract: Accurate endoscope pose estimation and 3D tissue surface reconstruction
significantly enhances monocular minimally invasive surgical procedures by
enabling accurate navigation and improved spatial awareness. However, monocular
endoscope pose estimation and tissue reconstruction face persistent challenges,
including depth ambiguity, physiological tissue deformation, inconsistent
endoscope motion, limited texture fidelity, and a restricted field of view. To
overcome these limitations, a unified framework for monocular endoscopic tissue
reconstruction that integrates scale-aware depth prediction with
temporally-constrained perceptual refinement is presented. This framework
incorporates a novel MAPIS-Depth module, which leverages Depth Pro for robust
initialisation and Depth Anything for efficient per-frame depth prediction, in
conjunction with L-BFGS-B optimisation, to generate pseudo-metric depth
estimates. These estimates are temporally refined by computing pixel
correspondences using RAFT and adaptively blending flow-warped frames based on
LPIPS perceptual similarity, thereby reducing artefacts arising from
physiological tissue deformation and motion. To ensure accurate registration of
the synthesised pseudo-RGBD frames from MAPIS-Depth, a novel WEMA-RTDL module
is integrated, optimising both rotation and translation. Finally, truncated
signed distance function-based volumetric fusion and marching cubes are applied
to extract a comprehensive 3D surface mesh. Evaluations on HEVD and SCARED,
with ablation and comparative analyses, demonstrate the framework's robustness
and superiority over state-of-the-art methods.

</details>


### [96] [TimeMachine: Fine-Grained Facial Age Editing with Identity Preservation](https://arxiv.org/abs/2508.11284)
*Yilin Mi,Qixin Yan,Zheng-Peng Duan,Chunle Guo,Hubery Yin,Hao Liu,Chen Li,Chongyi Li*

Main category: cs.CV

TL;DR: TimeMachine 是一种新颖的基于扩散的框架，可实现准确的年龄编辑，同时保持身份特征不变。


<details>
  <summary>Details</summary>
Motivation: 在生成模型的发展中，面部图像编辑取得了显着进展。然而，在保持个人身份的同时实现精细的年龄编辑仍然是一项具有挑战性的任务。为了解决缺乏大规模、高质量的面部年龄数据集的问题，我们构建了一个HFFA数据集（高质量的精细面部年龄数据集），该数据集包含一百万张标有身份和面部属性的高分辨率图像。

Method: 我们提出了TimeMachine，这是一种新颖的基于扩散的框架，可以实现准确的年龄编辑，同时保持身份特征不变。为了实现精细的年龄编辑，我们将高精度年龄信息注入到多交叉注意力模块中，该模块明确分离了年龄相关和身份相关的特征。此外，我们提出了一个年龄分类器指导（ACG）模块，该模块直接在潜在空间中预测年龄，而不是在训练期间执行去噪图像重建。

Result: 实验结果表明，TimeMachine在精细年龄编辑方面实现了最先进的性能，同时保持了身份一致性。

Conclusion: TimeMachine在精细年龄编辑方面实现了最先进的性能，同时保持了身份一致性。

Abstract: With the advancement of generative models, facial image editing has made
significant progress. However, achieving fine-grained age editing while
preserving personal identity remains a challenging task.In this paper, we
propose TimeMachine, a novel diffusion-based framework that achieves accurate
age editing while keeping identity features unchanged. To enable fine-grained
age editing, we inject high-precision age information into the multi-cross
attention module, which explicitly separates age-related and identity-related
features. This design facilitates more accurate disentanglement of age
attributes, thereby allowing precise and controllable manipulation of facial
aging.Furthermore, we propose an Age Classifier Guidance (ACG) module that
predicts age directly in the latent space, instead of performing denoising
image reconstruction during training. By employing a lightweight module to
incorporate age constraints, this design enhances age editing accuracy by
modest increasing training cost. Additionally, to address the lack of
large-scale, high-quality facial age datasets, we construct a HFFA dataset
(High-quality Fine-grained Facial-Age dataset) which contains one million
high-resolution images labeled with identity and facial attributes.
Experimental results demonstrate that TimeMachine achieves state-of-the-art
performance in fine-grained age editing while preserving identity consistency.

</details>


### [97] [Hyperspectral vs. RGB for Pedestrian Segmentation in Urban Driving Scenes: A Comparative Study](https://arxiv.org/abs/2508.11301)
*Jiarong Li,Imad Ali Shah,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本研究探讨了高光谱成像（HSI）在城市驾驶场景中增强行人分割的潜力，结果表明，通过最佳HSI波段选择可以实现稳健的行人分割。


<details>
  <summary>Details</summary>
Motivation: 汽车感知系统中的行人分割面临着严重的安全挑战，这是由于RGB成像中的同色异谱现象，即行人和背景在视觉上无法区分。

Method: 将128通道HSI数据转换为三通道表示：主成分分析（PCA）和使用对比信号噪声比与联合互信息最大化（CSNR-JMIM）的最佳波段选择。评估了三个语义分割模型：U-Net、DeepLabV3+和SegFormer。

Result: CSNR-JMIM始终优于RGB，在行人的交并比（IoU）平均提高了1.44%，F1分数提高了2.18%。骑车人分割也显示出类似的增益，IoU提高了1.43%，F1分数提高了2.25%。这些改进的性能来自最佳选择的HSI波段的增强光谱辨别能力，有效地减少了假阳性。

Conclusion: 通过最佳HSI波段选择实现的稳健行人分割，显示出在安全关键型汽车应用中的巨大潜力。

Abstract: Pedestrian segmentation in automotive perception systems faces critical
safety challenges due to metamerism in RGB imaging, where pedestrians and
backgrounds appear visually indistinguishable.. This study investigates the
potential of hyperspectral imaging (HSI) for enhanced pedestrian segmentation
in urban driving scenarios using the Hyperspectral City v2 (H-City) dataset. We
compared standard RGB against two dimensionality-reduction approaches by
converting 128-channel HSI data into three-channel representations: Principal
Component Analysis (PCA) and optimal band selection using Contrast
Signal-to-Noise Ratio with Joint Mutual Information Maximization (CSNR-JMIM).
Three semantic segmentation models were evaluated: U-Net, DeepLabV3+, and
SegFormer. CSNR-JMIM consistently outperformed RGB with an average improvements
of 1.44% in Intersection over Union (IoU) and 2.18% in F1-score for pedestrian
segmentation. Rider segmentation showed similar gains with 1.43% IoU and 2.25%
F1-score improvements. These improved performance results from enhanced
spectral discrimination of optimally selected HSI bands effectively reducing
false positives. This study demonstrates robust pedestrian segmentation through
optimal HSI band selection, showing significant potential for safety-critical
automotive applications.

</details>


### [98] [Does the Skeleton-Recall Loss Really Work?](https://arxiv.org/abs/2508.11374)
*Devansh Arora,Nitin Kumar,Sukrit Gupta*

Main category: cs.CV

TL;DR: This work critically evaluates the limitations of topology-based loss functions, offering valuable insights for researchers aiming to develop more effective segmentation models for complex tubular structures.


<details>
  <summary>Details</summary>
Motivation: Accomplishing effective image segmentation in diverse settings often requires custom model architectures and loss functions. A set of models that specialize in segmenting thin tubular structures are topology preservation-based loss functions. These models often utilize a pixel skeletonization process claimed to generate more precise segmentation masks of thin tubes and better capture the structures that other models often miss.

Method: theoretical analysis of the gradients for the SRL loss and comparing the performance of the proposed method on some of the tubular datasets

Result: the performance of SRL-based segmentation models did not exceed traditional baseline models.

Conclusion: SRL-based segmentation models did not exceed traditional baseline models.

Abstract: Image segmentation is an important and widely performed task in computer
vision. Accomplishing effective image segmentation in diverse settings often
requires custom model architectures and loss functions. A set of models that
specialize in segmenting thin tubular structures are topology
preservation-based loss functions. These models often utilize a pixel
skeletonization process claimed to generate more precise segmentation masks of
thin tubes and better capture the structures that other models often miss. One
such model, Skeleton Recall Loss (SRL) proposed by Kirchhoff et al.~\cite
{kirchhoff2024srl}, was stated to produce state-of-the-art results on benchmark
tubular datasets. In this work, we performed a theoretical analysis of the
gradients for the SRL loss. Upon comparing the performance of the proposed
method on some of the tubular datasets (used in the original work, along with
some additional datasets), we found that the performance of SRL-based
segmentation models did not exceed traditional baseline models. By providing
both a theoretical explanation and empirical evidence, this work critically
evaluates the limitations of topology-based loss functions, offering valuable
insights for researchers aiming to develop more effective segmentation models
for complex tubular structures.

</details>


### [99] [Denoise-then-Retrieve: Text-Conditioned Video Denoising for Video Moment Retrieval](https://arxiv.org/abs/2508.11313)
*Weijia Liu,Jiuxin Cao,Bo Miao,Zhiheng Fu,Xuelin Zhu,Jiawei Ge,Bo Liu,Mehwish Nasim,Ajmal Mian*

Main category: cs.CV

TL;DR: 提出了一种去噪然后检索的视频时刻检索（VMR）方法，该方法通过显式地过滤掉与文本无关的片段，然后使用纯化的多模态表示来检索目标时刻，从而提高了性能。


<details>
  <summary>Details</summary>
Motivation: 当前的文本驱动的视频时刻检索（VMR）方法编码所有视频片段，包括不相关的片段，从而扰乱了多模态对齐并阻碍了优化。为此，我们提出了一种去噪然后检索范例，该范例显式地从视频中过滤掉与文本无关的片段，然后使用纯化的多模态表示来检索目标时刻。

Method: 我们引入了去噪然后检索网络（DRNet），包括文本条件去噪（TCD）和文本重建反馈（TRF）模块。TCD集成了交叉注意力和结构化状态空间块，以动态识别噪声片段并生成噪声掩码，以净化多模态视频表示。TRF进一步从净化的视频表示中提取单个查询嵌入，并将其与文本嵌入对齐，作为训练期间去噪的辅助监督。最后，我们使用文本嵌入在净化的视频表示上执行条件检索，以实现准确的VMR。

Result: 该方法在Charades-STA和QVHighlights数据集上的实验表明，该方法在所有指标上都超过了最先进的方法。

Conclusion: 该方法在Charades-STA和QVHighlights数据集上的实验表明，该方法在所有指标上都超过了最先进的方法。此外，该去噪然后检索范例是可适应的，可以无缝集成到先进的VMR模型中，以提高性能。

Abstract: Current text-driven Video Moment Retrieval (VMR) methods encode all video
clips, including irrelevant ones, disrupting multimodal alignment and hindering
optimization. To this end, we propose a denoise-then-retrieve paradigm that
explicitly filters text-irrelevant clips from videos and then retrieves the
target moment using purified multimodal representations. Following this
paradigm, we introduce the Denoise-then-Retrieve Network (DRNet), comprising
Text-Conditioned Denoising (TCD) and Text-Reconstruction Feedback (TRF)
modules. TCD integrates cross-attention and structured state space blocks to
dynamically identify noisy clips and produce a noise mask to purify multimodal
video representations. TRF further distills a single query embedding from
purified video representations and aligns it with the text embedding, serving
as auxiliary supervision for denoising during training. Finally, we perform
conditional retrieval using text embeddings on purified video representations
for accurate VMR. Experiments on Charades-STA and QVHighlights demonstrate that
our approach surpasses state-of-the-art methods on all metrics. Furthermore,
our denoise-then-retrieve paradigm is adaptable and can be seamlessly
integrated into advanced VMR models to boost performance.

</details>


### [100] [G-CUT3R: Guided 3D Reconstruction with Camera and Depth Prior Integration](https://arxiv.org/abs/2508.11379)
*Ramil Khafizov,Artem Komarichev,Ruslan Rakhimov,Peter Wonka,Evgeny Burnaev*

Main category: cs.CV

TL;DR: G-CUT3R enhances CUT3R by integrating prior information like depth or camera position, achieving better 3D scene reconstruction.


<details>
  <summary>Details</summary>
Motivation: enhancing the CUT3R model by integrating prior information. Unlike existing feed-forward methods that rely solely on input images, our method leverages auxiliary data, such as depth, camera calibrations, or camera positions, commonly available in real-world scenarios.

Method: a lightweight modification to CUT3R, incorporating a dedicated encoder for each modality to extract features, which are fused with RGB image tokens via zero convolution

Result: Evaluated across multiple benchmarks, including 3D reconstruction and other multi-view tasks

Conclusion: The approach demonstrates significant performance improvements, showing its ability to effectively utilize available priors while maintaining compatibility with varying input modalities.

Abstract: We introduce G-CUT3R, a novel feed-forward approach for guided 3D scene
reconstruction that enhances the CUT3R model by integrating prior information.
Unlike existing feed-forward methods that rely solely on input images, our
method leverages auxiliary data, such as depth, camera calibrations, or camera
positions, commonly available in real-world scenarios. We propose a lightweight
modification to CUT3R, incorporating a dedicated encoder for each modality to
extract features, which are fused with RGB image tokens via zero convolution.
This flexible design enables seamless integration of any combination of prior
information during inference. Evaluated across multiple benchmarks, including
3D reconstruction and other multi-view tasks, our approach demonstrates
significant performance improvements, showing its ability to effectively
utilize available priors while maintaining compatibility with varying input
modalities.

</details>


### [101] [Logic Unseen: Revealing the Logical Blindspots of Vision-Language Models](https://arxiv.org/abs/2508.11317)
*Yuchen Zhou,Jiayu Tang,Shuo Yang,Xiaoyan Xiao,Yuqin Dai,Wenhao Yang,Chao Gou,Xiaobo Xia,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 本文提出了LogicBench，一个综合性的基准，用于诊断VLMs的逻辑盲点。为了弥补这一差距，本文提出了LogicCLIP，一种新的训练框架，旨在提高VLMs的逻辑敏感性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs），以CLIP为例，已经成为多模态智能的基础。然而，它们在逻辑理解方面的能力仍未得到充分探索，导致关键的“逻辑盲点”，限制了它们在实际应用中的可靠性。

Method: 提出了LogicCLIP，一种新的训练框架，旨在通过数据生成和优化目标的改进来提高VLMs的逻辑敏感性。LogicCLIP利用逻辑感知数据生成和对比学习策略，该策略结合了粗粒度对齐、细粒度多项选择目标和一种新的逻辑结构感知目标。

Result: LogicCLIP在所有LogicBench领域都显著提高了逻辑理解能力，显著优于基线。此外，LogicCLIP在通用视觉语言基准测试中保持甚至超过了竞争性能，表明增强的逻辑理解不会以牺牲通用对齐为代价。

Conclusion: LogicBench和LogicCLIP将成为提升VLM逻辑能力的重要资源。

Abstract: Vision-Language Models (VLMs), exemplified by CLIP, have emerged as
foundational for multimodal intelligence. However, their capacity for logical
understanding remains significantly underexplored, resulting in critical
''logical blindspots'' that limit their reliability in practical applications.
To systematically diagnose this, we introduce LogicBench, a comprehensive
benchmark with over 50,000 vision-language pairs across 9 logical categories
and 4 diverse scenarios: images, videos, anomaly detection, and medical
diagnostics. Our evaluation reveals that existing VLMs, even the
state-of-the-art ones, fall at over 40 accuracy points below human performance,
particularly in challenging tasks like Causality and Conditionality,
highlighting their reliance on surface semantics over critical logical
structures. To bridge this gap, we propose LogicCLIP, a novel training
framework designed to boost VLMs' logical sensitivity through advancements in
both data generation and optimization objectives. LogicCLIP utilizes
logic-aware data generation and a contrastive learning strategy that combines
coarse-grained alignment, a fine-grained multiple-choice objective, and a novel
logical structure-aware objective. Extensive experiments demonstrate
LogicCLIP's substantial improvements in logical comprehension across all
LogicBench domains, significantly outperforming baselines. Moreover, LogicCLIP
retains, and often surpasses, competitive performance on general
vision-language benchmarks, demonstrating that the enhanced logical
understanding does not come at the expense of general alignment. We believe
that LogicBench and LogicCLIP will be important resources for advancing VLM
logical capabilities.

</details>


### [102] [Delving into Dynamic Scene Cue-Consistency for Robust 3D Multi-Object Tracking](https://arxiv.org/abs/2508.11323)
*Haonan Zhang,Xinyao Wang,Boxi Wu,Tu Zheng,Wang Yunhua,Zheng Yang*

Main category: cs.CV

TL;DR: This paper proposes DSC-Track, a new method for 3D multi-object tracking that leverages cue-consistency to achieve state-of-the-art results on nuScenes.


<details>
  <summary>Details</summary>
Motivation: Existing methods for 3D multi-object tracking often struggle in crowded environments due to overlooking geometric relationships and interference from irrelevant objects.

Method: The paper introduces the Dynamic Scene Cue-Consistency Tracker (DSC-Track), which uses a unified spatiotemporal encoder with Point Pair Features (PPF) and a cue-consistency transformer module.

Result: The DSC-Track achieves state-of-the-art performance on the nuScenes dataset.

Conclusion: The proposed DSC-Track achieves state-of-the-art performance on nuScenes, reaching 73.2% and 70.3% AMOTA on the validation and test sets, respectively, demonstrating effectiveness and robustness.

Abstract: 3D multi-object tracking is a critical and challenging task in the field of
autonomous driving. A common paradigm relies on modeling individual object
motion, e.g., Kalman filters, to predict trajectories. While effective in
simple scenarios, this approach often struggles in crowded environments or with
inaccurate detections, as it overlooks the rich geometric relationships between
objects. This highlights the need to leverage spatial cues. However, existing
geometry-aware methods can be susceptible to interference from irrelevant
objects, leading to ambiguous features and incorrect associations. To address
this, we propose focusing on cue-consistency: identifying and matching stable
spatial patterns over time. We introduce the Dynamic Scene Cue-Consistency
Tracker (DSC-Track) to implement this principle. Firstly, we design a unified
spatiotemporal encoder using Point Pair Features (PPF) to learn discriminative
trajectory embeddings while suppressing interference. Secondly, our
cue-consistency transformer module explicitly aligns consistent feature
representations between historical tracks and current detections. Finally, a
dynamic update mechanism preserves salient spatiotemporal information for
stable online tracking. Extensive experiments on the nuScenes and Waymo Open
Datasets validate the effectiveness and robustness of our approach. On the
nuScenes benchmark, for instance, our method achieves state-of-the-art
performance, reaching 73.2% and 70.3% AMOTA on the validation and test sets,
respectively.

</details>


### [103] [Noise Matters: Optimizing Matching Noise for Diffusion Classifiers](https://arxiv.org/abs/2508.11330)
*Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: 提出了一种新的噪声优化方法 NoOp，以解决扩散分类器中的噪声不稳定性问题，从而提高分类速度。


<details>
  <summary>Details</summary>
Motivation: 现有的 DCs 存在噪声不稳定性：不同的随机采样噪声会导致显著的性能变化。为了获得稳定的分类性能，现有的 DCs 总是集成数百个采样噪声的结果，这显著降低了分类速度。

Method: 提出了一种新的噪声优化方法来学习匹配（即好的）噪声：NoOp。

Result: 探索了噪声在 DC 中的作用，并得出结论：存在一些可以缓解不稳定性的“好噪声”。同时，认为这些好的噪声应满足两个原则：频率匹配和空间匹配。

Conclusion: 通过在各种数据集上的大量消融实验证明了NoOp的有效性。

Abstract: Although today's pretrained discriminative vision-language models (e.g.,
CLIP) have demonstrated strong perception abilities, such as zero-shot image
classification, they also suffer from the bag-of-words problem and spurious
bias. To mitigate these problems, some pioneering studies leverage powerful
generative models (e.g., pretrained diffusion models) to realize generalizable
image classification, dubbed Diffusion Classifier (DC). Specifically, by
randomly sampling a Gaussian noise, DC utilizes the differences of denoising
effects with different category conditions to classify categories.
Unfortunately, an inherent and notorious weakness of existing DCs is noise
instability: different random sampled noises lead to significant performance
changes. To achieve stable classification performance, existing DCs always
ensemble the results of hundreds of sampled noises, which significantly reduces
the classification speed. To this end, we firstly explore the role of noise in
DC, and conclude that: there are some ``good noises'' that can relieve the
instability. Meanwhile, we argue that these good noises should meet two
principles: Frequency Matching and Spatial Matching. Regarding both principles,
we propose a novel Noise Optimization method to learn matching (i.e., good)
noise for DCs: NoOp. For frequency matching, NoOp first optimizes a
dataset-specific noise: Given a dataset and a timestep t, optimize one randomly
initialized parameterized noise. For Spatial Matching, NoOp trains a
Meta-Network that adopts an image as input and outputs image-specific noise
offset. The sum of optimized noise and noise offset will be used in DC to
replace random noise. Extensive ablations on various datasets demonstrated the
effectiveness of NoOp.

</details>


### [104] [GANDiff FR: Hybrid GAN Diffusion Synthesis for Causal Bias Attribution in Face Recognition](https://arxiv.org/abs/2508.11334)
*Md Asgor Hossain Reaj,Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Md Jawadul Hasan,Tze Hui Liew*

Main category: cs.CV

TL;DR: GANDiff FR 是一种用于公平性审计的合成框架，通过精确控制人口和环境因素来减少偏差。


<details>
  <summary>Details</summary>
Motivation: 介绍GANDiff FR，这是第一个精确控制人口和环境因素的综合框架，用于以可重复的严谨性来衡量、解释和减少偏差。

Method: GANDiff FR结合了基于StyleGAN3的身份保持生成与基于扩散的属性控制。

Result: 合成了10,000张跨越五个队列的人口统计平衡的面孔，通过自动检测（98.2%）和人工审核（89%）验证了其真实性，以分离和量化偏差驱动因素。

Conclusion: AdaFace减少了60%的组间TPR差异，照明占剩余偏差的42%。

Abstract: We introduce GANDiff FR, the first synthetic framework that precisely
controls demographic and environmental factors to measure, explain, and reduce
bias with reproducible rigor. GANDiff FR unifies StyleGAN3-based
identity-preserving generation with diffusion-based attribute control, enabling
fine-grained manipulation of pose around 30 degrees, illumination (four
directions), and expression (five levels) under ceteris paribus conditions. We
synthesize 10,000 demographically balanced faces across five cohorts validated
for realism via automated detection (98.2%) and human review (89%) to isolate
and quantify bias drivers. Benchmarking ArcFace, CosFace, and AdaFace under
matched operating points shows AdaFace reduces inter-group TPR disparity by 60%
(2.5% vs. 6.3%), with illumination accounting for 42% of residual bias.
Cross-dataset evaluation on RFW, BUPT, and CASIA WebFace confirms strong
synthetic-to-real transfer (r 0.85). Despite around 20% computational overhead
relative to pure GANs, GANDiff FR yields three times more attribute-conditioned
variants, establishing a reproducible, regulation-aligned (EU AI Act) standard
for fairness auditing. Code and data are released to support transparent,
scalable bias evaluation.

</details>


### [105] [Index-Aligned Query Distillation for Transformer-based Incremental Object Detection](https://arxiv.org/abs/2508.11339)
*Mingxiao Ma,Shunyao Zhu,Guoliang Kang*

Main category: cs.CV

TL;DR: This paper introduces Index-Aligned Query Distillation (IAQD) to address catastrophic forgetting in incremental object detection with transformers, achieving state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: When adopting a transformer-based detection model to perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning the detection performance on previously learned categories may severely degenerate. Previous typical methods mainly rely on knowledge distillation (KD) to mitigate the catastrophic knowledge forgetting of transformer-based detection models. However, we observe that in IOD task, Hungarian Matching is not a good choice. With Hungarian Matching, the query of the current-phase model may match different queries of the last-phase model at different iterations during KD. As a result, the knowledge encoded in each query may be reshaped towards new categories, leading to the forgetting of previously encoded knowledge of old categories.

Method: propose a new distillation approach named Index-Aligned Query Distillation (IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD establishes a correspondence between queries of the previous and current phase models that have the same index. Moreover, we perform index-aligned distillation only on partial queries which are critical for the detection of previous categories.

Result: Extensive experiments on representative benchmarks demonstrate that IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art performance.

Conclusion: IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art performance.

Abstract: Incremental object detection (IOD) aims to continuously expand the capability
of a model to detect novel categories while preserving its performance on
previously learned ones. When adopting a transformer-based detection model to
perform IOD, catastrophic knowledge forgetting may inevitably occur, meaning
the detection performance on previously learned categories may severely
degenerate. Previous typical methods mainly rely on knowledge distillation (KD)
to mitigate the catastrophic knowledge forgetting of transformer-based
detection models. Specifically, they utilize Hungarian Matching to build a
correspondence between the queries of the last-phase and current-phase
detection models and align the classifier and regressor outputs between matched
queries to avoid knowledge forgetting. However, we observe that in IOD task,
Hungarian Matching is not a good choice. With Hungarian Matching, the query of
the current-phase model may match different queries of the last-phase model at
different iterations during KD. As a result, the knowledge encoded in each
query may be reshaped towards new categories, leading to the forgetting of
previously encoded knowledge of old categories. Based on our observations, we
propose a new distillation approach named Index-Aligned Query Distillation
(IAQD) for transformer-based IOD. Beyond using Hungarian Matching, IAQD
establishes a correspondence between queries of the previous and current phase
models that have the same index. Moreover, we perform index-aligned
distillation only on partial queries which are critical for the detection of
previous categories. In this way, IAQD largely preserves the previous semantic
and spatial encoding capabilities without interfering with the learning of new
categories. Extensive experiments on representative benchmarks demonstrate that
IAQD effectively mitigates knowledge forgetting, achieving new state-of-the-art
performance.

</details>


### [106] [Inside Knowledge: Graph-based Path Generation with Explainable Data Augmentation and Curriculum Learning for Visual Indoor Navigation](https://arxiv.org/abs/2508.11446)
*Daniel Airinei,Elena Burceanu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 提出了一种仅基于视觉的室内导航深度学习方法，该方法高效、实时且易于部署，避免了对特殊传感器、标记或地图的需要。


<details>
  <summary>Details</summary>
Motivation: 室内导航是一项困难的任务，因为它通常具有较差的 GPS 访问权限，迫使解决方案依赖于其他信息来源。虽然在该领域继续取得重大进展，但鉴于当前解决方案的复杂性和额外要求，仍然缺乏向生产应用程序的部署。

Method: 基于一种新的基于图的路径生成方法，结合可解释的数据增强和课程学习。

Result: 创建了一个易于使用的 Android 应用程序，并计划公开发布。所有数据和代码以及视觉演示都可以在项目网站上找到。

Conclusion: 提出了一种高效、实时的、易于部署的深度学习方法，该方法仅基于视觉输入，可以预测从移动设备拍摄的图像到目标的行进方向。

Abstract: Indoor navigation is a difficult task, as it generally comes with poor GPS
access, forcing solutions to rely on other sources of information. While
significant progress continues to be made in this area, deployment to
production applications is still lacking, given the complexity and additional
requirements of current solutions. Here, we introduce an efficient, real-time
and easily deployable deep learning approach, based on visual input only, that
can predict the direction towards a target from images captured by a mobile
device. Our technical approach, based on a novel graph-based path generation
method, combined with explainable data augmentation and curriculum learning,
includes contributions that make the process of data collection, annotation and
training, as automatic as possible, efficient and robust. On the practical
side, we introduce a novel largescale dataset, with video footage inside a
relatively large shopping mall, in which each frame is annotated with the
correct next direction towards different specific target destinations.
Different from current methods, ours relies solely on vision, avoiding the need
of special sensors, additional markers placed along the path, knowledge of the
scene map or internet access. We also created an easy to use application for
Android, which we plan to make publicly available. We make all our data and
code available along with visual demos on our project site

</details>


### [107] [Cost-Effective Active Labeling for Data-Efficient Cervical Cell Classification](https://arxiv.org/abs/2508.11340)
*Yuanlin Liu,Zhihan Zhou,Mingqiang Wei,Youyi Song*

Main category: cs.CV

TL;DR: 提出了一种主动标签方法，该方法能够以更少的人力成本构建具有代表性的训练数据集，用于数据高效的宫颈细胞分类。


<details>
  <summary>Details</summary>
Motivation: 现有能够自动测量宫颈细胞数量和类别的分类方法需要具有代表性的训练数据集，这消耗了昂贵甚至难以承受的人力成本。

Method: 主动标签

Result: 通过快速估计不确定性，该算法在增强构建的训练数据集的代表性能力方面表现出有效性。

Conclusion: 该方法通过高效地利用分类器对未标记的宫颈细胞图像的不确定性，准确地选择最有利于标记的图像。大量的经验结果再次证实了其在导航人力成本使用方面的有效性，为数据高效的宫颈细胞分类开辟了道路。

Abstract: Information on the number and category of cervical cells is crucial for the
diagnosis of cervical cancer. However, existing classification methods capable
of automatically measuring this information require the training dataset to be
representative, which consumes an expensive or even unaffordable human cost. We
herein propose active labeling that enables us to construct a representative
training dataset using a much smaller human cost for data-efficient cervical
cell classification. This cost-effective method efficiently leverages the
classifier's uncertainty on the unlabeled cervical cell images to accurately
select images that are most beneficial to label. With a fast estimation of the
uncertainty, this new algorithm exhibits its validity and effectiveness in
enhancing the representative ability of the constructed training dataset. The
extensive empirical results confirm its efficacy again in navigating the usage
of human cost, opening the avenue for data-efficient cervical cell
classification.

</details>


### [108] [Controlling Multimodal LLMs via Reward-guided Decoding](https://arxiv.org/abs/2508.11616)
*Oscar Mañas,Pierluca D'Oro,Koustuv Sinha,Adriana Romero-Soriano,Michal Drozdzal,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 本文提出了一种通过受控解码调整 MLLM 的方法，通过构建奖励模型来指导 MLLM 的解码过程，从而提高视觉基础并实现对 MLLM 推理过程的即时可控性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大型语言模型 (MLLM) 获得广泛的适用性，越来越希望使它们适应不同的用户需求。

Method: 通过受控解码来调整 MLLM。引入了第一个用于 MLLM 奖励引导解码的方法，并展示了其在改进视觉基础中的应用。构建了视觉基础的奖励模型，并使用它们来指导 MLLM 的解码过程。具体来说，构建了两个独立的奖励模型来独立控制模型输出中对象精度和召回率的程度。

Result: 该方法实现了对 MLLM 推理过程的即时可控性，具体体现在两个方面：首先，通过控制解码过程中每个奖励函数的相对重要性，允许用户在图像字幕任务中动态地权衡对象精度以进行召回；其次，通过控制解码过程中搜索的广度，允许用户控制测试时计算量与视觉基础程度之间的权衡。

Conclusion: 该方法在标准对象幻觉基准测试中进行了评估，表明它提供了对 MLLM 推理的显着可控性，同时始终优于现有的幻觉缓解方法。

Abstract: As Multimodal Large Language Models (MLLMs) gain widespread applicability, it
is becoming increasingly desirable to adapt them for diverse user needs. In
this paper, we study the adaptation of MLLMs through controlled decoding. To
achieve this, we introduce the first method for reward-guided decoding of MLLMs
and demonstrate its application in improving their visual grounding. Our method
involves building reward models for visual grounding and using them to guide
the MLLM's decoding process. Concretely, we build two separate reward models to
independently control the degree of object precision and recall in the model's
output. Our approach enables on-the-fly controllability of an MLLM's inference
process in two ways: first, by giving control over the relative importance of
each reward function during decoding, allowing a user to dynamically trade off
object precision for recall in image captioning tasks; second, by giving
control over the breadth of the search during decoding, allowing the user to
control the trade-off between the amount of test-time compute and the degree of
visual grounding. We evaluate our method on standard object hallucination
benchmarks, showing that it provides significant controllability over MLLM
inference, while consistently outperforming existing hallucination mitigation
methods.

</details>


### [109] [Semantically Guided Adversarial Testing of Vision Models Using Language Models](https://arxiv.org/abs/2508.11341)
*Katarzyna Filus,Jorge M. Cruz-Duarte*

Main category: cs.CV

TL;DR: 提出了一种语义引导的对抗目标选择框架，该框架利用预训练语言和视觉语言模型的跨模态知识转移，实验表明该框架优于现有的方法。


<details>
  <summary>Details</summary>
Motivation: 在视觉模型的目标对抗攻击中，目标标签的选择是攻击成功的关键但经常被忽视的决定因素。现有的策略通常依赖于随机性、模型预测或静态语义资源，限制了解释性、可重复性或灵活性。

Method: 利用来自预训练语言和视觉语言模型的跨模态知识转移，提出了一个语义引导的对抗目标选择框架。

Result: 在三个视觉模型和五种攻击方法上的实验表明，这些模型始终呈现出实用的对抗目标，并且超过了静态词汇数据库，例如 WordNet，特别是对于远距离的类关系。我们还观察到，目标标签的静态测试提供了对相似性来源有效性的初步评估。

Conclusion: 预训练模型适用于构建跨架构和数据集的可解释、标准化和可扩展的对抗基准。

Abstract: In targeted adversarial attacks on vision models, the selection of the target
label is a critical yet often overlooked determinant of attack success. This
target label corresponds to the class that the attacker aims to force the model
to predict. Now, existing strategies typically rely on randomness, model
predictions, or static semantic resources, limiting interpretability,
reproducibility, or flexibility. This paper then proposes a semantics-guided
framework for adversarial target selection using the cross-modal knowledge
transfer from pretrained language and vision-language models. We evaluate
several state-of-the-art models (BERT, TinyLLAMA, and CLIP) as similarity
sources to select the most and least semantically related labels with respect
to the ground truth, forming best- and worst-case adversarial scenarios. Our
experiments on three vision models and five attack methods reveal that these
models consistently render practical adversarial targets and surpass static
lexical databases, such as WordNet, particularly for distant class
relationships. We also observe that static testing of target labels offers a
preliminary assessment of the effectiveness of similarity sources, \textit{a
priori} testing. Our results corroborate the suitability of pretrained models
for constructing interpretable, standardized, and scalable adversarial
benchmarks across architectures and datasets.

</details>


### [110] [Handwritten Text Recognition of Historical Manuscripts Using Transformer-Based Models](https://arxiv.org/abs/2508.11499)
*Erez Meoded*

Main category: cs.CV

TL;DR: 本研究利用TrOCR模型，通过领域特定的数据增强和集成学习，显著提高了16世纪拉丁文手稿的HTR性能。


<details>
  <summary>Details</summary>
Motivation: 历史手写文本识别(HTR)对于挖掘档案文件的文化和学术价值至关重要，但数字化通常受到稀缺的转录、语言变异和高度多样化的手写风格的阻碍。

Method: 将基于transformer的TrOCR模型应用于16世纪Rudolf Gwalther撰写的拉丁文手稿，并引入四种专门为历史手写特征设计的新型数据增强方法，同时评估集成学习方法。

Result: 在Gwalther数据集上，最佳单模型增强（Elastic）实现了1.86的字符错误率（CER），而前5名投票集成实现了1.60的CER，比最佳报告的TrOCR_BASE结果提高了50%，比之前的技术水平提高了42%。

Conclusion: 领域特定的数据增强和集成策略可以提高历史手稿的HTR性能。

Abstract: Historical handwritten text recognition (HTR) is essential for unlocking the
cultural and scholarly value of archival documents, yet digitization is often
hindered by scarce transcriptions, linguistic variation, and highly diverse
handwriting styles. In this study, we apply TrOCR, a state-of-the-art
transformer-based HTR model, to 16th-century Latin manuscripts authored by
Rudolf Gwalther. We investigate targeted image preprocessing and a broad suite
of data augmentation techniques, introducing four novel augmentation methods
designed specifically for historical handwriting characteristics. We also
evaluate ensemble learning approaches to leverage the complementary strengths
of augmentation-trained models. On the Gwalther dataset, our best single-model
augmentation (Elastic) achieves a Character Error Rate (CER) of 1.86, while a
top-5 voting ensemble achieves a CER of 1.60 - representing a 50% relative
improvement over the best reported TrOCR_BASE result and a 42% improvement over
the previous state of the art. These results highlight the impact of
domain-specific augmentations and ensemble strategies in advancing HTR
performance for historical manuscripts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [111] [Grounding Rule-Based Argumentation Using Datalog](https://arxiv.org/abs/2508.10976)
*Martin Diller,Sarah Alice Gaggl,Philipp Hanisch,Giuseppina Monterosso,Fritz Rauschenbach*

Main category: cs.AI

TL;DR: 本文提出了一种智能的 ASPIC+ 接地方案，通过转换为 Datalog 程序并进行简化，以提高推理效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 尽管一阶规则通常用于 ASPIC+ 示例中，但大多数现有的基于规则的论证推理方法仅支持命题规则。为了能够对一阶实例进行推理，需要一个初步的接地步骤。由于接地会导致输入理论的大小呈指数增长，因此需要智能程序。但是，对于 ASPIC+ 缺乏专门的解决方案。

Method: 我们提出了一种智能的接地程序，该程序可以保持接地的大小可控，同时保持推理过程的正确性。为此，我们将一阶 ASPIC+ 实例转换为 Datalog 程序，并查询 Datalog 引擎以获得基本替换，以执行规则和反例的接地。此外，我们提出了特定于 ASPIC+ 形式主义的简化，以避免对对推理过程没有影响的规则进行接地。

Result: 我们提出了一种智能的接地程序，该程序可以保持接地的大小可控，同时保持推理过程的正确性。

Conclusion: 我们对一个原型实现进行了实证评估，以显示可扩展性。

Abstract: ASPIC+ is one of the main general frameworks for rule-based argumentation for
AI. Although first-order rules are commonly used in ASPIC+ examples, most
existing approaches to reason over rule-based argumentation only support
propositional rules. To enable reasoning over first-order instances, a
preliminary grounding step is required. As groundings can lead to an
exponential increase in the size of the input theories, intelligent procedures
are needed. However, there is a lack of dedicated solutions for ASPIC+.
Therefore, we propose an intelligent grounding procedure that keeps the size of
the grounding manageable while preserving the correctness of the reasoning
process. To this end, we translate the first-order ASPIC+ instance into a
Datalog program and query a Datalog engine to obtain ground substitutions to
perform the grounding of rules and contraries. Additionally, we propose
simplifications specific to the ASPIC+ formalism to avoid grounding of rules
that have no influence on the reasoning process. Finally, we performed an
empirical evaluation of a prototypical implementation to show scalability.

</details>


### [112] [From Individual to Multi-Agent Algorithmic Recourse: Minimizing the Welfare Gap via Capacitated Bipartite Matching](https://arxiv.org/abs/2508.11070)
*Zahra Khotanlou,Kate Larson,Amir-Hossein Karimi*

Main category: cs.AI

TL;DR: 本文介绍了一个新颖的多智能体算法追索框架，该框架考虑了多个追索寻求者和追索提供者。


<details>
  <summary>Details</summary>
Motivation: 决策者越来越依赖于敏感情况下的机器学习。在这种情况下，算法追索旨在为个人提供可操作且成本最小的步骤，以扭转不利的 AI 驱动的决策。优化个人福利方法下的寻求者的结果忽略了现实世界系统固有的多智能体性质，在这些系统中，个人互动并竞争有限的资源。

Method: 我们将这种多对多的交互建模为一个有容量的加权二分匹配问题，其中匹配由追索成本和提供者容量引导。

Result: 在合成和现实世界数据集上的实验验证表明，我们的框架使多对多算法追索能够在系统设置中通过最小的修改来实现接近最优的福利。

Conclusion: 该框架通过在系统设置中进行最小修改，使多方算法追索能够实现接近最优的福利。

Abstract: Decision makers are increasingly relying on machine learning in sensitive
situations. In such settings, algorithmic recourse aims to provide individuals
with actionable and minimally costly steps to reverse unfavorable AI-driven
decisions. While existing research predominantly focuses on single-individual
(i.e., seeker) and single-model (i.e., provider) scenarios, real-world
applications often involve multiple interacting stakeholders. Optimizing
outcomes for seekers under an individual welfare approach overlooks the
inherently multi-agent nature of real-world systems, where individuals interact
and compete for limited resources. To address this, we introduce a novel
framework for multi-agent algorithmic recourse that accounts for multiple
recourse seekers and recourse providers. We model this many-to-many interaction
as a capacitated weighted bipartite matching problem, where matches are guided
by both recourse cost and provider capacity. Edge weights, reflecting recourse
costs, are optimized for social welfare while quantifying the welfare gap
between individual welfare and this collectively feasible outcome. We propose a
three-layer optimization framework: (1) basic capacitated matching, (2) optimal
capacity redistribution to minimize the welfare gap, and (3) cost-aware
optimization balancing welfare maximization with capacity adjustment costs.
Experimental validation on synthetic and real-world datasets demonstrates that
our framework enables the many-to-many algorithmic recourse to achieve
near-optimal welfare with minimum modification in system settings. This work
extends algorithmic recourse from individual recommendations to system-level
design, providing a tractable path toward higher social welfare while
maintaining individual actionability.

</details>


### [113] [Learn to optimize for automatic proton PBS treatment planning for H&N cancers](https://arxiv.org/abs/2508.11085)
*Qingqing Wang,Liqiang Xiao,Chang Chang*

Main category: cs.AI

TL;DR: A data-driven inverse optimizer integrated into a PPO framework automates proton PBS treatment planning, improving efficiency and plan quality compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Proton PBS treatment planning for H&N cancers involves numerous conflicting objectives, requiring significant effort from human planners. Inverse optimization, the most time-consuming component, still relies heavily on theory-driven approaches.

Method: A data-driven inverse optimizer is integrated into a PPO-based automatic treatment planning framework. The inverse optimizer is a L2O method that predicts update steps by learning from the task-specific data distribution, incorporating techniques designed for long-context processing.

Result: The L2O-based inverse optimizer improves effectiveness and efficiency by 22.97% and 36.41%, respectively, compared with L-BFGSB. Plans generated by the framework within an average of 2.55 hours show improved or comparable OAR sparing with superior target coverage.

Conclusion: The proposed framework generates high-quality treatment plans within a clinically acceptable time, showing improved or comparable OAR sparing with superior target coverage compared to human-generated plans.

Abstract: Proton PBS treatment planning for H&N cancers involves numerous conflicting
objectives, requiring significant effort from human planners to balance and
satisfy multiple clinical goals during planning. To achieve this,
experience-demanding objective parameter adjustment and computationally
expensive inverse optimization are performed iteratively. Extensive efforts
have been made to automatically adjust objective parameters, but the most
time-consuming component, i.e., inverse optimization, still relies heavily on
theory-driven approaches. We propose a data-driven inverse optimizer and
integrate it into a PPO-based automatic treatment planning framework to
automatically generate high-quality plans within a clinical acceptable planning
time. The inverse optimizer is a L2O method that predicts update steps by
learning from the task-specific data distribution. For the first time, we
integrate techniques designed for long-context processing, originally developed
for LLMs, into a Transformer-based L2O framework to address the scalability
issue of existing L2O methods. The PPO framework functions as an outer-loop
virtual planner, autonomously adjusting objective parameters through a policy
network, and the dose predictor is used to initialize objective parameters. The
inner-loop L2O inverse optimizer computes machine-deliverable MU values based
on objectives refined by the PPO policy network. 97 patients are collected in
this study, and compared with L-BFGSB, our L2O-based inverse optimizer improves
the effectiveness and efficiency by 22.97% and 36.41%, respectively. In
conjunction with the PPO-based learned virtual planner, plans generated by our
framework within an average of 2.55 hours show improved or comparable OAR
sparing with superior target coverage for patients with different prescription
dose levels, number of target volumes, beam angles, etc., compared with
human-generated plans.

</details>


### [114] [On Strong and Weak Admissibility in Non-Flat Assumption-Based Argumentation](https://arxiv.org/abs/2508.11182)
*Matti Berthold,Lydia Blümel,Anna Rapberger*

Main category: cs.AI

TL;DR: introduce strong admissibility for ABA and investigate desirable properties. extend the recent investigations of weak admissibility in the flat ABA fragment to the non-flat case.


<details>
  <summary>Details</summary>
Motivation: broaden the investigation of admissibility notions in the context of assumption-based argumentation (ABA).

Method: using abstract bipolar set-based argumentation frameworks (BSAFs)

Result: the central modularization property is maintained under classical, strong, and weak admissibility.

Conclusion: strong and weakly admissible semantics in non-flat ABA share some of the shortcomings of standard admissible semantics and discuss ways to address these.

Abstract: In this work, we broaden the investigation of admissibility notions in the
context of assumption-based argumentation (ABA). More specifically, we study
two prominent alternatives to the standard notion of admissibility from
abstract argumentation, namely strong and weak admissibility, and introduce the
respective preferred, complete and grounded semantics for general (sometimes
called non-flat) ABA. To do so, we use abstract bipolar set-based argumentation
frameworks (BSAFs) as formal playground since they concisely capture the
relations between assumptions and are expressive enough to represent general
non-flat ABA frameworks, as recently shown. While weak admissibility has been
recently investigated for a restricted fragment of ABA in which assumptions
cannot be derived (flat ABA), strong admissibility has not been investigated
for ABA so far. We introduce strong admissibility for ABA and investigate
desirable properties. We furthermore extend the recent investigations of weak
admissibility in the flat ABA fragment to the non-flat case. We show that the
central modularization property is maintained under classical, strong, and weak
admissibility. We also show that strong and weakly admissible semantics in
non-flat ABA share some of the shortcomings of standard admissible semantics
and discuss ways to address these.

</details>


### [115] [Beyond Solving Math Quiz: Evaluating the Ability of Large Reasoning Models to Ask for Information](https://arxiv.org/abs/2508.11252)
*Youcheng Huang,Bowen Qin,Chen Huang,Duanyu Feng,Xi Yang,Wenqiang Lei*

Main category: cs.AI

TL;DR: LRMs虽然擅长解决定义明确的数学问题，但缺乏在信息不足时主动提问的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估LRMs在定义明确问题上的数学问题解决能力，忽略了智能体在信息不足时主动提问信息的能力。

Method: 提出了一个包含两种不完整问题的新数据集，并对LRMs进行了系统评估。

Result: 对LRMs的系统评估表明它们缺乏主动提问信息的能力，并揭示了与过度思考和幻觉相关的行为。

Conclusion: LRMs在主动提问信息方面表现不佳，存在过度思考和幻觉行为，监督微调在学习这种能力方面具有潜力和挑战。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable problem-solving
abilities in mathematics, as evaluated by existing benchmarks exclusively on
well-defined problems. However, such evaluation setup constitutes a critical
gap, since a genuine intelligent agent should not only solve problems (as a
math quiz solver), but also be able~to ask for information when the problems
lack sufficient information, enabling proactivity in responding users'
requests. To bridge such gap, we proposes a new dataset consisting of two types
of incomplete problems with diverse contexts. Based on the dataset, our
systematical evaluation of LRMs reveals their inability in proactively asking
for information. In addition, we uncover the behaviors related to overthinking
and hallucination of LRMs, and highlight the potential and challenges of
supervised fine-tuning in learning such ability. We hope to provide new
insights in developing LRMs with genuine intelligence, rather than just solving
problems.

</details>


### [116] [SAGE: Scale-Aware Gradual Evolution for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2508.11347)
*Yifei Li,Lingling Zhang,Hang Yan,Tianzhe Zhao,Zihan Ma,Muye Huang,Jun Liu*

Main category: cs.AI

TL;DR: SAGE: a scale-aware gradual evolution framework for CKGE, which determine the embedding dimensions based on the update scales and expand the embedding space accordingly


<details>
  <summary>Details</summary>
Motivation: existing CKGE methods often fail to consider the varying scales of updates and lack systematic evaluation throughout the entire update process

Method: SAGE firstly determine the embedding dimensions based on the update scales and expand the embedding space accordingly. The Dynamic Distillation mechanism is further employed to balance the preservation of learned knowledge and the incorporation of new facts.

Result: SAGE consistently outperforms existing baselines, with a notable improvement of 1.38% in MRR, 1.25% in H@1 and 1.6% in H@10.

Conclusion: SAGE consistently outperforms existing baselines, with a notable improvement of 1.38% in MRR, 1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with methods using fixed embedding dimensions show that SAGE achieves optimal performance on every snapshot, demonstrating the importance of adaptive embedding dimensions in CKGE.

Abstract: Traditional knowledge graph (KG) embedding methods aim to represent entities
and relations in a low-dimensional space, primarily focusing on static graphs.
However, real-world KGs are dynamically evolving with the constant addition of
entities, relations and facts. To address such dynamic nature of KGs, several
continual knowledge graph embedding (CKGE) methods have been developed to
efficiently update KG embeddings to accommodate new facts while maintaining
learned knowledge. As KGs grow at different rates and scales in real-world
scenarios, existing CKGE methods often fail to consider the varying scales of
updates and lack systematic evaluation throughout the entire update process. In
this paper, we propose SAGE, a scale-aware gradual evolution framework for
CKGE. Specifically, SAGE firstly determine the embedding dimensions based on
the update scales and expand the embedding space accordingly. The Dynamic
Distillation mechanism is further employed to balance the preservation of
learned knowledge and the incorporation of new facts. We conduct extensive
experiments on seven benchmarks, and the results show that SAGE consistently
outperforms existing baselines, with a notable improvement of 1.38% in MRR,
1.25% in H@1 and 1.6% in H@10. Furthermore, experiments comparing SAGE with
methods using fixed embedding dimensions show that SAGE achieves optimal
performance on every snapshot, demonstrating the importance of adaptive
embedding dimensions in CKGE. The codes of SAGE are publicly available at:
https://github.com/lyfxjtu/Dynamic-Embedding.

</details>


### [117] [CRAFT-GUI: Curriculum-Reinforced Agent For GUI Tasks](https://arxiv.org/abs/2508.11360)
*Songqin Nong,Jingxuan Xu,Sheng Zhou,Jianfeng Chen,Xiaoxuan Tang,Tao Jiang,Wenhao Xu*

Main category: cs.AI

TL;DR: This paper introduces CRAFT-GUI, a curriculum learning framework for GUI interaction tasks that improves performance by addressing the varying difficulty of tasks and using a more fine-grained reward function.


<details>
  <summary>Details</summary>
Motivation: Existing RL methods for GUI tasks overlook the variation in difficulty across tasks and use a single, coarse reward, leading to inefficient policy updates.

Method: The authors propose CRAFT-GUI, a curriculum learning framework based on Group Relative Policy Optimization (GRPO) that explicitly accounts for the varying difficulty across trajectories. They also design a reward function that combines simple rule-based signals with model-judged evaluation.

Result: The proposed method outperforms previous state-of-the-art approaches by 5.6% on public benchmarks Android Control and 10.3% on the authors' internal online benchmarks.

Conclusion: This paper validates the effectiveness of integrating reinforcement learning with curriculum learning in GUI interaction tasks, achieving significant improvements over previous state-of-the-art approaches.

Abstract: As autonomous agents become adept at understanding and interacting with
graphical user interface (GUI) environments, a new era of automated task
execution is emerging. Recent studies have demonstrated that Reinforcement
Learning (RL) can effectively enhance agents' performance in dynamic
interactive GUI environments. However, these methods face two key limitations:
(1) they overlook the significant variation in difficulty across different GUI
tasks by treating the entire training data as a uniform set, which hampers the
agent's ability to adapt its learning process; and (2) most approaches collapse
task-specific nuances into a single, coarse reward, leaving the agent with a
uniform signal that yields inefficient policy updates. To address these
limitations, we propose CRAFT-GUI, a curriculum learning framework based on
Group Relative Policy Optimization (GRPO) that explicitly accounts for the
varying difficulty across trajectories. To enable more fine-grained policy
optimization, we design a reward function that combines simple rule-based
signals with model-judged evaluation, providing richer and more nuanced
feedback during training. Experimental results demonstrate that our method
achieves significant improvements over previous state-of-the-art approaches,
outperforming them by 5.6% on public benchmarks Android Control and 10.3% on
our internal online benchmarks, respectively. These findings empirically
validate the effectiveness of integrating reinforcement learning with
curriculum learning in GUI interaction tasks.

</details>


### [118] [AIM-Bench: Evaluating Decision-making Biases of Agentic LLM as Inventory Manager](https://arxiv.org/abs/2508.11416)
*Xuhua Zhao,Yuxuan Xie,Caihua Chen,Yuxiang Sun*

Main category: cs.AI

TL;DR: 本文介绍了AIM-Bench，用于评估LLM代理在不确定的供应链管理场景中的决策行为。研究结果表明，不同的大型语言模型通常表现出不同程度的决策偏差，这与人类观察到的偏差类似。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在数学推理和长期规划能力方面的最新进展促进了代理的开发，这些代理越来越多地用于业务运营流程。优化库存水平的决策模型是运营管理的核心要素之一。然而，LLM代理在不确定的情况下做出库存决策的能力，以及代理的决策偏差（例如框架效应等）在很大程度上仍未被探索。

Method: 引入了AIM-Bench，这是一个新颖的基准，旨在通过一系列不同的库存补货实验来评估LLM代理在不确定的供应链管理场景中的决策行为。

Result: 不同的大型语言模型通常表现出不同程度的决策偏差，这与人类观察到的偏差类似。认知反思和信息共享的实施可以缓解中心牵引效应和牛鞭效应。

Conclusion: 不同的大型语言模型通常表现出不同程度的决策偏差，这与人类观察到的偏差类似。认知反思和信息共享的实施可以缓解中心牵引效应和牛鞭效应。在库存决策场景中部署大型语言模型时，需要仔细考虑潜在的偏差。

Abstract: Recent advances in mathematical reasoning and the long-term planning
capabilities of large language models (LLMs) have precipitated the development
of agents, which are being increasingly leveraged in business operations
processes. Decision models to optimize inventory levels are one of the core
elements of operations management. However, the capabilities of the LLM agent
in making inventory decisions in uncertain contexts, as well as the
decision-making biases (e.g. framing effect, etc.) of the agent, remain largely
unexplored. This prompts concerns regarding the capacity of LLM agents to
effectively address real-world problems, as well as the potential implications
of biases that may be present. To address this gap, we introduce AIM-Bench, a
novel benchmark designed to assess the decision-making behaviour of LLM agents
in uncertain supply chain management scenarios through a diverse series of
inventory replenishment experiments. Our results reveal that different LLMs
typically exhibit varying degrees of decision bias that are similar to those
observed in human beings. In addition, we explored strategies to mitigate the
pull-to-centre effect and the bullwhip effect, namely cognitive reflection and
implementation of information sharing. These findings underscore the need for
careful consideration of the potential biases in deploying LLMs in Inventory
decision-making scenarios. We hope that these insights will pave the way for
mitigating human decision bias and developing human-centred decision support
systems for supply chains.

</details>


### [119] [Inclusion Arena: An Open Platform for Evaluating Large Foundation Models with Real-World Apps](https://arxiv.org/abs/2508.11452)
*Kangyu Wang,Hongliang He,Lin Liu,Ruiqi Liang,Zhenzhong Lan,Jianguo Li*

Main category: cs.AI

TL;DR: Inclusion Arena is a live leaderboard using human feedback from real-world AI applications to rank LLMs/MLLMs, improving on existing benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks and leaderboards for LLMs/MLLMs often fail to reflect real-world application performance.

Method: The Bradley-Terry model is augmented with Placement Matches for cold-start and Proximity Sampling for intelligent comparison.

Result: Inclusion Arena yields reliable and stable rankings, exhibits higher data transitivity, and significantly mitigates the risk of malicious manipulation.

Conclusion: Inclusion Arena, a live leaderboard, provides reliable and stable model rankings, higher data transitivity, and mitigates manipulation risks, fostering LLM/MLLM development for user-centric applications.

Abstract: Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs)
have ushered in a new era of AI capabilities, demonstrating near-human-level
performance across diverse scenarios. While numerous benchmarks (e.g., MMLU)
and leaderboards (e.g., Chatbot Arena) have been proposed to help evolve the
development of LLMs and MLLMs, most rely on static datasets or crowdsourced
general-domain prompts, often falling short of reflecting performance in
real-world applications. To bridge this critical gap, we present Inclusion
Arena, a live leaderboard that ranks models based on human feedback collected
directly from AI-powered applications. Our platform integrates pairwise model
comparisons into natural user interactions, ensuring evaluations reflect
practical usage scenarios. For robust model ranking, we employ the
Bradley-Terry model augmented with two key innovations: (1) Placement Matches,
a cold-start mechanism to quickly estimate initial ratings for newly integrated
models, and (2) Proximity Sampling, an intelligent comparison strategy that
prioritizes battles between models of similar capabilities to maximize
information gain and enhance rating stability. Extensive empirical analyses and
simulations demonstrate that Inclusion Arena yields reliable and stable
rankings, exhibits higher data transitivity compared to general crowdsourced
datasets, and significantly mitigates the risk of malicious manipulation. By
fostering an open alliance between foundation models and real-world
applications, Inclusion Arena aims to accelerate the development of LLMs and
MLLMs truly optimized for practical, user-centric deployments. The platform is
publicly accessible at https://doraemon.alipay.com/model-ranking.

</details>


### [120] [Landmark-Assisted Monte Carlo Planning](https://arxiv.org/abs/2508.11493)
*David H. Chan,Mark Roberts,Dana S. Nau*

Main category: cs.AI

TL;DR: This paper introduces probabilistic landmarks to decompose MDPs and adapts the UCT algorithm to leverage them. Results show that landmarks can improve UCT performance in online probabilistic planning.


<details>
  <summary>Details</summary>
Motivation: Landmarks$\\unicode{x2013}$conditions that must be satisfied at some point in every solution plan$\\unicode{x2013}$have contributed to major advancements in classical planning, but they have seldom been used in stochastic domains.

Method: We formalize probabilistic landmarks and adapt the UCT algorithm to leverage them as subgoals to decompose MDPs; core to the adaptation is balancing between greedy landmark achievement and final goal achievement.

Result: Our results in benchmark domains show that well-chosen landmarks can significantly improve the performance of UCT in online probabilistic planning

Conclusion: well-chosen landmarks can significantly improve the performance of UCT in online probabilistic planning, while the best balance of greedy versus long-term goal achievement is problem-dependent. The results suggest that landmarks can provide helpful guidance for anytime algorithms solving MDPs.

Abstract: Landmarks$\unicode{x2013}$conditions that must be satisfied at some point in
every solution plan$\unicode{x2013}$have contributed to major advancements in
classical planning, but they have seldom been used in stochastic domains. We
formalize probabilistic landmarks and adapt the UCT algorithm to leverage them
as subgoals to decompose MDPs; core to the adaptation is balancing between
greedy landmark achievement and final goal achievement. Our results in
benchmark domains show that well-chosen landmarks can significantly improve the
performance of UCT in online probabilistic planning, while the best balance of
greedy versus long-term goal achievement is problem-dependent. The results
suggest that landmarks can provide helpful guidance for anytime algorithms
solving MDPs.

</details>


### [121] [Inspire or Predict? Exploring New Paradigms in Assisting Classical Planners with Large Language Models](https://arxiv.org/abs/2508.11524)
*Wenkai Yu,Jianhang Tang,Yang Zhang,Shanjiang Tang,Kebing Jin,Hankz Hankui Zhuo*

Main category: cs.AI

TL;DR: Proposes a novel LLM-assisted planner with problem decomposition to address large-scale planning problems. It uses LLMs to guide problem decomposition and infuses domain-specific knowledge for better performance.


<details>
  <summary>Details</summary>
Motivation: Addressing large-scale planning problems has become one of the central challenges in the planning community, deriving from the state-space explosion caused by growing objects and actions. Prior works have largely overlooked integrating LLMs with domain-specific knowledge to ensure valid plans.

Method: LLM-assisted planner integrated with problem decomposition, which decomposes large planning problems into multiple simpler sub-tasks and utilizes LLMs in two paradigms: LLM4Inspire and LLM4Predict.

Result: Demonstrates the ability of search space partition when solving large-scale planning problems.

Conclusion: LLMs effectively locate feasible solutions when pruning the search space, where infusing domain-specific knowledge into LLMs holds particular promise compared with offering general knowledge within LLMs.

Abstract: Addressing large-scale planning problems has become one of the central
challenges in the planning community, deriving from the state-space explosion
caused by growing objects and actions. Recently, researchers have explored the
effectiveness of leveraging Large Language Models (LLMs) to generate helpful
actions and states to prune the search space. However, prior works have largely
overlooked integrating LLMs with domain-specific knowledge to ensure valid
plans. In this paper, we propose a novel LLM-assisted planner integrated with
problem decomposition, which first decomposes large planning problems into
multiple simpler sub-tasks. Then we explore two novel paradigms to utilize
LLMs, i.e., LLM4Inspire and LLM4Predict, to assist problem decomposition, where
LLM4Inspire provides heuristic guidance according to general knowledge and
LLM4Predict employs domain-specific knowledge to infer intermediate conditions.
We empirically validate the effectiveness of our planner across multiple
domains, demonstrating the ability of search space partition when solving
large-scale planning problems. The experimental results show that LLMs
effectively locate feasible solutions when pruning the search space, where
infusing domain-specific knowledge into LLMs, i.e., LLM4Predict, holds
particular promise compared with LLM4Inspire, which offers general knowledge
within LLMs.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [122] [Tabularis Formatus: Predictive Formatting for Tables](https://arxiv.org/abs/2508.11121)
*Mukul Singh,José Cambronero,Sumit Gulwani,Vu Le,Gust Verbruggen*

Main category: cs.DB

TL;DR: TaFo is a neuro-symbolic approach to automatically generate conditional formatting (CF) rules for spreadsheets, outperforming existing systems.


<details>
  <summary>Details</summary>
Motivation: Spreadsheet manipulation software are widely used for data management and analysis of tabular data, yet the creation of conditional formatting (CF) rules remains a complex task requiring technical knowledge and experience with specific platforms

Method: a neuro-symbolic approach to generating CF suggestions for tables, addressing common challenges such as user unawareness, difficulty in rule creation, and inadequate user interfaces. TaFo takes inspiration from component based synthesis systems and extends them with semantic knowledge of language models and a diversity preserving rule ranking

Result: TaFo uniquely incorporates value-based formatting, automatically learning both the rule trigger and the associated visual formatting properties for CF rules. By removing the dependency on user specification used by existing techniques in the form of formatted examples or natural language instruction, TaFo makes formatting completely predictive and automated for the user

Conclusion: TaFo generates more accurate, diverse and complete formatting suggestions than current systems and outperforms these by 15.6%--26.5% on matching user added ground truth rules in tables.

Abstract: Spreadsheet manipulation software are widely used for data management and
analysis of tabular data, yet the creation of conditional formatting (CF) rules
remains a complex task requiring technical knowledge and experience with
specific platforms. In this paper we present TaFo, a neuro-symbolic approach to
generating CF suggestions for tables, addressing common challenges such as user
unawareness, difficulty in rule creation, and inadequate user interfaces. TaFo
takes inspiration from component based synthesis systems and extends them with
semantic knowledge of language models and a diversity preserving rule
ranking.Unlike previous methods focused on structural formatting, TaFo uniquely
incorporates value-based formatting, automatically learning both the rule
trigger and the associated visual formatting properties for CF rules. By
removing the dependency on user specification used by existing techniques in
the form of formatted examples or natural language instruction, TaFo makes
formatting completely predictive and automated for the user. To evaluate TaFo,
we use a corpus of 1.8 Million public workbooks with CF and manual formatting.
We compare TaFo against a diverse set of symbolic and neural systems designed
for or adapted for the task of table formatting. Our results show that TaFo
generates more accurate, diverse and complete formatting suggestions than
current systems and outperforms these by 15.6\%--26.5\% on matching user added
ground truth rules in tables.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [123] [PaperRegister: Boosting Flexible-grained Paper Search via Hierarchical Register Indexing](https://arxiv.org/abs/2508.11116)
*Zhuoqun Li,Xuanang Chen,Hongyu Lin,Yaojie Lu,Xianpei Han,Le Sun*

Main category: cs.IR

TL;DR: PaperRegister通过将传统的基于摘要的索引转换为分层索引树来支持灵活粒度的查询，从而实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 先前的论文搜索系统无法满足这些灵活粒度的要求，因为这些系统主要收集论文摘要以构建语料库索引，这些索引缺乏详细信息来支持通过更细粒度的查询进行检索。

Method: 离线分层索引和在线自适应检索

Result: PaperRegister达到了最先进的性能，尤其是在细粒度场景中表现出色。

Conclusion: PaperRegister在不同粒度的论文搜索任务中表现出色，尤其在细粒度场景下表现突出，具有作为实际应用中灵活粒度论文搜索的有效解决方案的良好潜力。

Abstract: Paper search is an important activity for researchers, typically involving
using a query with description of a topic to find relevant papers. As research
deepens, paper search requirements may become more flexible, sometimes
involving specific details such as module configuration rather than being
limited to coarse-grained topics. However, previous paper search systems are
unable to meet these flexible-grained requirements, as these systems mainly
collect paper abstracts to construct index of corpus, which lack detailed
information to support retrieval by finer-grained queries. In this work, we
propose PaperRegister, consisted of offline hierarchical indexing and online
adaptive retrieval, transforming traditional abstract-based index into
hierarchical index tree for paper search, thereby supporting queries at
flexible granularity. Experiments on paper search tasks across a range of
granularity demonstrate that PaperRegister achieves the state-of-the-art
performance, and particularly excels in fine-grained scenarios, highlighting
the good potential as an effective solution for flexible-grained paper search
in real-world applications. Code for this work is in
https://github.com/Li-Z-Q/PaperRegister.

</details>


### [124] [+VeriRel: Verification Feedback to Enhance Document Retrieval for Scientific Fact Checking](https://arxiv.org/abs/2508.11122)
*Xingyu Deng,Xi Wang,Mark Stevenson*

Main category: cs.IR

TL;DR: +VeriRel improves scientific fact checking by ranking documents based on verification success, leading to better evidence retrieval and verification performance.


<details>
  <summary>Details</summary>
Motivation: Existing approaches rely on off-the-shelf Information Retrieval algorithms that rank documents based on relevance rather than the evidence they provide to support or refute the claim being checked.

Method: +VeriRel which includes verification success in the document ranking

Result: Experimental results on three scientific fact checking datasets (SciFact, SciFact-Open and Check-Covid) demonstrate consistently leading performance by +VeriRel for document evidence retrieval and a positive impact on downstream verification.

Conclusion: This study highlights the potential of integrating verification feedback to document relevance assessment for effective scientific fact checking systems. It shows promising future work to evaluate fine-grained relevance when examining complex documents for advanced scientific fact checking.

Abstract: Identification of appropriate supporting evidence is critical to the success
of scientific fact checking. However, existing approaches rely on off-the-shelf
Information Retrieval algorithms that rank documents based on relevance rather
than the evidence they provide to support or refute the claim being checked.
This paper proposes +VeriRel which includes verification success in the
document ranking. Experimental results on three scientific fact checking
datasets (SciFact, SciFact-Open and Check-Covid) demonstrate consistently
leading performance by +VeriRel for document evidence retrieval and a positive
impact on downstream verification. This study highlights the potential of
integrating verification feedback to document relevance assessment for
effective scientific fact checking systems. It shows promising future work to
evaluate fine-grained relevance when examining complex documents for advanced
scientific fact checking.

</details>


### [125] [Role-Augmented Intent-Driven Generative Search Engine Optimization](https://arxiv.org/abs/2508.11158)
*Xiaolu Chen,Haojie Wu,Jie Bao,Zhen Chen,Yong Liao,Hu Huang*

Main category: cs.IR

TL;DR: Proposes a G-SEO method to bridge the gap between traditional SEO and generative search engines by modeling search intent, enhancing content, and introducing G-Eval 2.0 for better evaluation.


<details>
  <summary>Details</summary>
Motivation: Content creators' optimization strategies, effective in traditional search engines, are misaligned with generative retrieval contexts, resulting in diminished visibility in Generative Search Engines (GSEs).

Method: Role-Augmented Intent-Driven Generative Search Engine Optimization (G-SEO) method, modeling search intent through reflective refinement across diverse informational roles.

Result: Significant improvements over single-aspect baseline approaches in both subjective impressions and objective content visibility within GSE responses.

Conclusion: Search intent is an effective signal for guiding content optimization, yielding significant improvements over single-aspect baseline approaches in both subjective impressions and objective content visibility within GSE responses.

Abstract: Generative Search Engines (GSEs), powered by Large Language Models (LLMs) and
Retrieval-Augmented Generation (RAG), are reshaping information retrieval.
While commercial systems (e.g., BingChat, Perplexity.ai) demonstrate impressive
semantic synthesis capabilities, their black-box nature fundamentally
undermines established Search Engine Optimization (SEO) practices. Content
creators face a critical challenge: their optimization strategies, effective in
traditional search engines, are misaligned with generative retrieval contexts,
resulting in diminished visibility. To bridge this gap, we propose a
Role-Augmented Intent-Driven Generative Search Engine Optimization (G-SEO)
method, providing a structured optimization pathway tailored for GSE scenarios.
Our method models search intent through reflective refinement across diverse
informational roles, enabling targeted content enhancement. To better evaluate
the method under realistic settings, we address the benchmarking limitations of
prior work by: (1) extending the GEO dataset with diversified query variations
reflecting real-world search scenarios and (2) introducing G-Eval 2.0, a
6-level LLM-augmented evaluation rubric for fine-grained human-aligned
assessment. Experimental results demonstrate that search intent serves as an
effective signal for guiding content optimization, yielding significant
improvements over single-aspect baseline approaches in both subjective
impressions and objective content visibility within GSE responses.

</details>


### [126] [Representation Quantization for Collaborative Filtering Augmentation](https://arxiv.org/abs/2508.11194)
*Yunze Luo,Yinjie Jiang,Gaode Chen,Jingchi Wang,Shicheng Wang,Ruina Sun,Jiang Yuezihan,Jun Zhang,Jian Liang,Han Li,Kun Gai,Kaigui Bian*

Main category: cs.IR

TL;DR: DQRec: a collaborative recommendation algorithm that uses a decomposition-based quantized variational autoencoder to extract patterns from interaction sequences and attributes, improving recommendation performance.


<details>
  <summary>Details</summary>
Motivation: Existing methods are limited by coarse-grained, sparse attributes and fail to effectively extract behavioral characteristics jointly from interaction sequences and attributes. To address these challenges, we propose a novel two-stage collaborative recommendation algorithm, DQRec

Method: A novel two-stage collaborative recommendation algorithm, DQRec: Decomposition-based Quantized Variational AutoEncoder (DQ-VAE) for Recommendation.

Result: DQRec augments features and homogeneous linkages by extracting the behavior characteristics jointly from interaction sequences and attributes, namely patterns, such as user multi-aspect interests. By integrating these semantic ID patterns into the recommendation process through feature and linkage augmentation, the system enriches both latent and explicit user and item features, identifies pattern-similar neighbors, and thereby improves the efficiency of information diffusion.

Conclusion: The proposed DQRec method outperforms baselines across multiple datasets.

Abstract: As the core algorithm in recommendation systems, collaborative filtering (CF)
algorithms inevitably face the problem of data sparsity. Since CF captures
similar users and items for recommendations, it is effective to augment the
lacking user-user and item-item homogeneous linkages. However, existing methods
are typically limited to connecting through overlapping interacted neighbors or
through similar attributes and contents. These approaches are constrained by
coarse-grained, sparse attributes and fail to effectively extract behavioral
characteristics jointly from interaction sequences and attributes. To address
these challenges, we propose a novel two-stage collaborative recommendation
algorithm, DQRec: Decomposition-based Quantized Variational AutoEncoder
(DQ-VAE) for Recommendation. DQRec augments features and homogeneous linkages
by extracting the behavior characteristics jointly from interaction sequences
and attributes, namely patterns, such as user multi-aspect interests. Inspired
by vector quantization (VQ) technology, we propose a new VQ algorithm, DQ-VAE,
which decomposes the pre-trained representation embeddings into distinct
dimensions, and quantize them to generates semantic IDs. We utilize the
generated semantic IDs as the extracted patterns mentioned above. By
integrating these semantic ID patterns into the recommendation process through
feature and linkage augmentation, the system enriches both latent and explicit
user and item features, identifies pattern-similar neighbors, and thereby
improves the efficiency of information diffusion. Experimental comparisons with
baselines across multiple datasets demonstrate the superior performance of the
proposed DQRec method.

</details>


### [127] [Mitigating Filter Bubble from the Perspective of Community Detection: A Universal Framework](https://arxiv.org/abs/2508.11239)
*Ming Tang,Xiaowen Huang,Jitao Sang*

Main category: cs.IR

TL;DR: CD-CGCN通过社区检测来解决推荐系统中的过滤气泡问题，减轻过滤气泡的同时保持了推荐质量，并且在捕获用户的社区间偏好方面表现出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 推荐系统主要致力于提高准确性，但牺牲了多样性，加剧了众所周知的过滤气泡效应。通过使用社区检测算法分析用户-项目交互历史记录，揭示了最先进的推荐通常侧重于社区内部项目，从而加剧了过滤气泡效应。

Method: CD-CGCN集成了条件判别器和社区重新加权的图卷积网络，可以通过基于社区标签的对抗学习来抵消提取的社区属性，并结合针对用户特定过滤气泡状态量身定制的推理策略。

Result: CD-CGCN在减轻过滤气泡的同时保持了推荐质量。

Conclusion: CD-CGCN在减轻过滤气泡的同时保持了推荐质量，并且在捕获用户的社区间偏好方面表现出卓越的性能。

Abstract: In recent years, recommender systems have primarily focused on improving
accuracy at the expense of diversity, which exacerbates the well-known filter
bubble effect. This paper proposes a universal framework called CD-CGCN to
address the filter bubble issue in recommender systems from a community
detection perspective. By analyzing user-item interaction histories with a
community detection algorithm, we reveal that state-of-the-art recommendations
often focus on intra-community items, worsening the filter bubble effect.
CD-CGCN, a model-agnostic framework, integrates a Conditional Discriminator and
a Community-reweighted Graph Convolutional Network which can be plugged into
most recommender models. Using adversarial learning based on community labels,
it counteracts the extracted community attributes and incorporates an inference
strategy tailored to the user's specific filter bubble state. Extensive
experiments on real-world datasets with multiple base models validate its
effectiveness in mitigating filter bubbles while preserving recommendation
quality. Additionally, by applying community debiasing to the original test set
to construct an unbiased test set, we observe that CD-CGCN demonstrates
superior performance in capturing users' inter-community preferences.

</details>


### [128] [INFNet: A Task-aware Information Flow Network for Large-Scale Recommendation Systems](https://arxiv.org/abs/2508.11565)
*Kaiyuan Li,Dongdong Mao,Yongxiang Tang,Yanhua Cheng,Yanxiang Zeng,Chao Wang,Xialong Liu,Peng Jiang*

Main category: cs.IR

TL;DR: 提出了一种新的信息流网络 (INFNet) 架构，用于大规模推荐系统，该架构通过异构和同构信息流来解决特征交互的计算成本和多任务建模的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的特征交互策略在工业应用中面临两个关键挑战：(1) 类别和序列特征的数量巨大使得详尽的交互计算在计算上令人望而却步，通常会导致优化困难。(2) 现实世界的推荐系统通常涉及多个预测目标，但目前大多数方法都在多任务学习层之前应用特征交互模块。这种后期融合设计忽略了特定于任务的特征依赖性，并且从根本上限制了多任务建模的能力。

Method: 提出了一种信息流网络 (INFNet)，这是一种专为大规模推荐场景设计的任务感知架构。INFNet将特征分为三种token类型：类别token、序列token和任务token，并引入了一种新颖的双流设计，包括异构和同构交替信息块。对于异构信息流，我们采用带有代理的交叉注意力机制，以促进高效的跨模态token交互，并平衡计算成本。对于同构流，我们设计了特定类型的代理门控单元 (PGU)，以实现细粒度的类型内特征处理。

Result: INFNet在离线基准测试中取得了最先进的性能，并在商业在线广告系统中成功部署，在收入 (REV) 方面实现了 +1.587% 的显着增长，在点击率 (CTR) 方面实现了 +1.155% 的显着增长。

Conclusion: INFNet在离线基准测试中取得了最先进的性能，并在商业在线广告系统中成功部署，在收入 (REV) 方面实现了 +1.587% 的显着增长，在点击率 (CTR) 方面实现了 +1.155% 的显着增长。

Abstract: Feature interaction has long been a cornerstone of ranking models in
large-scale recommender systems due to its proven effectiveness in capturing
complex dependencies among features. However, existing feature interaction
strategies face two critical challenges in industrial applications: (1) The
vast number of categorical and sequential features makes exhaustive interaction
computationally prohibitive, often resulting in optimization difficulties. (2)
Real-world recommender systems typically involve multiple prediction
objectives, yet most current approaches apply feature interaction modules prior
to the multi-task learning layers. This late-fusion design overlooks
task-specific feature dependencies and inherently limits the capacity of
multi-task modeling. To address these limitations, we propose the Information
Flow Network (INFNet), a task-aware architecture designed for large-scale
recommendation scenarios. INFNet distinguishes features into three token types,
categorical tokens, sequence tokens, and task tokens, and introduces a novel
dual-flow design comprising heterogeneous and homogeneous alternating
information blocks. For heterogeneous information flow, we employ a
cross-attention mechanism with proxy that facilitates efficient cross-modal
token interaction with balanced computational cost. For homogeneous flow, we
design type-specific Proxy Gated Units (PGUs) to enable fine-grained intra-type
feature processing. Extensive experiments on multiple offline benchmarks
confirm that INFNet achieves state-of-the-art performance. Moreover, INFNet has
been successfully deployed in a commercial online advertising system, yielding
significant gains of +1.587% in Revenue (REV) and +1.155% in Click-Through Rate
(CTR).

</details>


### [129] [The Next Phase of Scientific Fact-Checking: Advanced Evidence Retrieval from Complex Structured Academic Papers](https://arxiv.org/abs/2506.20844)
*Xingyu Deng,Xi Wang,Mark Stevenson*

Main category: cs.IR

TL;DR: The paper discusses the limitations of current scientific fact-checking systems and identifies key research challenges within evidence retrieval. 


<details>
  <summary>Details</summary>
Motivation: Existing approaches focus on simplified versions of the problem based on small-scale datasets consisting of abstracts rather than full papers, thereby avoiding the distinct challenges associated with processing complete documents.

Method: This paper examines the limitations of current scientific fact-checking systems and reveals the many potential features and resources that could be exploited to advance their performance. Preliminary experiments were conducted to substantiate these challenges and identify potential solutions.

Result: It identifies key research challenges within evidence retrieval, including (1) evidence-driven retrieval that addresses semantic limitations and topic imbalance (2) time-aware evidence retrieval with citation tracking to mitigate outdated information, (3) structured document parsing to leverage long-range context, (4) handling complex scientific expressions, including tables, figures, and domain-specific terminology and (5) assessing the credibility of scientific literature.

Conclusion: This perspective paper aims to advance scientific fact-checking with a specialised IR system tailored for real-world applications.

Abstract: Scientific fact-checking aims to determine the veracity of scientific claims
by retrieving and analysing evidence from research literature. The problem is
inherently more complex than general fact-checking since it must accommodate
the evolving nature of scientific knowledge, the structural complexity of
academic literature and the challenges posed by long-form, multimodal
scientific expression. However, existing approaches focus on simplified
versions of the problem based on small-scale datasets consisting of abstracts
rather than full papers, thereby avoiding the distinct challenges associated
with processing complete documents. This paper examines the limitations of
current scientific fact-checking systems and reveals the many potential
features and resources that could be exploited to advance their performance. It
identifies key research challenges within evidence retrieval, including (1)
evidence-driven retrieval that addresses semantic limitations and topic
imbalance (2) time-aware evidence retrieval with citation tracking to mitigate
outdated information, (3) structured document parsing to leverage long-range
context, (4) handling complex scientific expressions, including tables,
figures, and domain-specific terminology and (5) assessing the credibility of
scientific literature. Preliminary experiments were conducted to substantiate
these challenges and identify potential solutions. This perspective paper aims
to advance scientific fact-checking with a specialised IR system tailored for
real-world applications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [130] [Compressive Meta-Learning](https://arxiv.org/abs/2508.11090)
*Daniel Mas Montserrat,David Bonet,Maria Perera,Xavier Giró-i-Nieto,Alexander G. Ioannidis*

Main category: cs.LG

TL;DR: 提出了一个新的压缩学习框架，该框架更快、更准确，并且更有效地利用底层数据结构。


<details>
  <summary>Details</summary>
Motivation: 新数据集大小的快速扩张需要快速有效的参数学习技术。压缩学习是一种框架，它通过使用随机的非线性特征将大规模数据库投影到紧凑的、信息保留的表示上，从而实现高效处理，这些表示的维度独立于样本数量，并且可以轻松存储、传输和处理。然而，编码和解码技术通常是随机的且独立于数据的，未能利用数据的底层结构。

Method: 使用神经网络对压缩学习方法的编码和解码阶段进行元学习

Result: 证明了所提出的压缩元学习框架的潜力，我们探索了多个应用——包括基于神经网络的压缩 PCA、压缩岭回归、压缩 k-means 和自动编码器。

Conclusion: 提出了一个通过使用神经网络对压缩学习方法的编码和解码阶段进行元学习的框架，该框架比当前最先进的方法更快、更准确。

Abstract: The rapid expansion in the size of new datasets has created a need for fast
and efficient parameter-learning techniques. Compressive learning is a
framework that enables efficient processing by using random, non-linear
features to project large-scale databases onto compact, information-preserving
representations whose dimensionality is independent of the number of samples
and can be easily stored, transferred, and processed. These database-level
summaries are then used to decode parameters of interest from the underlying
data distribution without requiring access to the original samples, offering an
efficient and privacy-friendly learning framework. However, both the encoding
and decoding techniques are typically randomized and data-independent, failing
to exploit the underlying structure of the data. In this work, we propose a
framework that meta-learns both the encoding and decoding stages of compressive
learning methods by using neural networks that provide faster and more accurate
systems than the current state-of-the-art approaches. To demonstrate the
potential of the presented Compressive Meta-Learning framework, we explore
multiple applications -- including neural network-based compressive PCA,
compressive ridge regression, compressive k-means, and autoencoders.

</details>


### [131] [A Cooperative Game-Based Multi-Criteria Weighted Ensemble Approach for Multi-Class Classification](https://arxiv.org/abs/2508.10926)
*DongSeong-Yoon*

Main category: cs.LG

TL;DR: This paper introduces a cooperative game-based ensemble method that considers multiple criteria for improved machine learning performance.


<details>
  <summary>Details</summary>
Motivation: Existing ensemble weighting methods consider only one evaluation criterion, limiting the reflection of various information that should be considered in a model realistically.

Method: The proposed method uses cooperative games to consider various types of information known beforehand in classifiers for weight distribution.

Result: Experimental results on the Open-ML-CC18 dataset showed superior performance compared to other weighting methods.

Conclusion: This paper proposes a cooperative game-based decision-making method for ensemble learning that considers various information in multi-criteria situations, leading to improved performance.

Abstract: Since the Fourth Industrial Revolution, AI technology has been widely used in
many fields, but there are several limitations that need to be overcome,
including overfitting/underfitting, class imbalance, and the limitations of
representation (hypothesis space) due to the characteristics of different
models. As a method to overcome these problems, ensemble, commonly known as
model combining, is being extensively used in the field of machine learning.
Among ensemble learning methods, voting ensembles have been studied with
various weighting methods, showing performance improvements. However, the
existing methods that reflect the pre-information of classifiers in weights
consider only one evaluation criterion, which limits the reflection of various
information that should be considered in a model realistically. Therefore, this
paper proposes a method of making decisions considering various information
through cooperative games in multi-criteria situations. Using this method,
various types of information known beforehand in classifiers can be
simultaneously considered and reflected, leading to appropriate weight
distribution and performance improvement. The machine learning algorithms were
applied to the Open-ML-CC18 dataset and compared with existing ensemble
weighting methods. The experimental results showed superior performance
compared to other weighting methods.

</details>


### [132] [Apriel-Nemotron-15B-Thinker](https://arxiv.org/abs/2508.10948)
*Shruthan Radhakrishna,Soham Parikh,Gopal Sarda,Anil Turkkan,Quaizar Vohra,Raymond Li,Dhruv Jhamb,Kelechi Ogueji,Aanjaneya Shukla,Oluwanifemi Bamgbose,Toby Liang,Luke Kumar,Oleksiy Ostapenko,Shiva Krishna Reddy Malay,Aman Tiwari,Tara Bogavelli,Vikas Yadav,Jash Mehta,Saloni Mittal,Akshay Kalkunte,Pulkit Pattnaik,Khalil Slimi,Anirudh Sreeram,Jishnu Nair,Akintunde Oladipo,Shashank Maiya,Khyati Mahajan,Rishabh Maheshwary,Masoud Hashemi,Sai Rajeswar Mudumba,Sathwik Tejaswi Madhusudhan,Torsten Scholak,Sebastien Paquet,Sagar Davasam,Srinivas Sunkara*

Main category: cs.LG

TL;DR: Apriel-Nemotron-15B-Thinker是一个150亿参数的模型，它实现了与更大模型相当的性能，但内存占用更少。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 在代码、数学和其他企业任务等领域取得了卓越的推理能力，但它们的大量内存和计算成本通常使其无法在实际的企业环境中使用。

Method: 该模型在一个四阶段训练管道中进行训练，包括 1) 基础模型升级，2) 持续预训练，3) 监督微调 (SFT) 和 4) 使用 GRPO 的强化学习。

Result: Apriel-Nemotron-15B-Thinker，一个 150 亿参数的模型，在 ServiceNow Apriel SLM 系列中，实现了与 o1-mini、QWQ32B 和 EXAONE-Deep-32B 等中型最先进模型的性能，同时仅保持了这些替代方案一半的内存占用。

Conclusion: Apriel-Nemotron-15B-Thinker模型在多个基准测试中与320亿参数的同类模型性能相匹配或超过，尽管其规模不到后者的一半。

Abstract: While large language models (LLMs) have achieved remarkable reasoning
capabilities across domains like code, math and other enterprise tasks, their
significant memory and computational costs often preclude their use in
practical enterprise settings. To this end, we introduce
Apriel-Nemotron-15B-Thinker, a 15-billion parameter model in the ServiceNow
Apriel SLM series that achieves performance against medium sized
state-of-the-art models such as o1-mini, QWQ32B, and EXAONE-Deep-32B while
maintaining only half the memory footprint of those alternatives.
Apriel-Nemotron-15B-Thinker model is trained in a four stage training pipeline
including 1) Base Model upscaling, 2) Continual Pre-training 3) Supervised
Fine-tuning (SFT) and 4) Reinforcement Learning using GRPO. Comprehensive
evaluations across a diverse suite of benchmarks consistently demonstrate that
our Apriel-Nemotron-15B-Thinker model matches or exceeds the performance of its
32-billion parameter counterparts, despite being less than half their size.

</details>


### [133] [Towards Efficient Prompt-based Continual Learning in Distributed Medical AI](https://arxiv.org/abs/2508.10954)
*Gyutae Oh,Jitae Shin*

Main category: cs.LG

TL;DR: This paper introduces a prompt-based continual learning approach (PCL) for medical AI, addressing data sharing limitations and improving performance in diabetic retinopathy datasets.


<details>
  <summary>Details</summary>
Motivation: Ethical, social, and institutional constraints in the medical domain severely restrict data sharing, rendering centralized learning nearly impossible. Traditional training overfits new samples and suffers from catastrophic forgetting, and medical data distributions also shift.

Method: A prompt-based continual learning (PCL) approach featuring a unified prompt pool with a minimal expansion strategy and a novel regularization term.

Result: Experiments on three diabetic retinopathy datasets show the model improves final classification accuracy by at least 10% and F1-score by 9 points over state-of-the-art approaches while lowering inference cost.

Conclusion: The proposed PCL approach improves final classification accuracy and F1-score over state-of-the-art approaches while lowering inference cost, driving sustainable medical AI advances.

Abstract: Modern AI models achieve state-of-the-art performance with large-scale,
high-quality datasets; however, ethical, social, and institutional constraints
in the medical domain severely restrict data sharing, rendering centralized
learning nearly impossible. Each institution must incrementally update models
using only local data. Traditional training overfits new samples and suffers
from catastrophic forgetting, losing previously acquired knowledge. Medical
data distributions also shift due to varying diagnostic equipment and
demographics. Although continual learning (CL) has advanced, most methods
address natural images, leaving medical-domain-specific CL underexplored. We
propose a prompt-based continual learning (PCL) approach featuring a unified
prompt pool with a minimal expansion strategy: by expanding and freezing a
subset of prompts, our method reduces computational overhead, and a novel
regularization term balances retention and adaptation. Experiments on three
diabetic retinopathy datasets Aptos2019, LI2019, and Diabetic Retinopathy
Detection show our model improves final classification accuracy by at least 10%
and F1-score by 9 points over state-of-the-art approaches while lowering
inference cost. We anticipate this study will drive sustainable medical AI
advances, enabling real-time diagnosis, patient monitoring, and telemedicine
applications in distributed healthcare. Code will be released upon acceptance

</details>


### [134] [Retro-Expert: Collaborative Reasoning for Interpretable Retrosynthesis](https://arxiv.org/abs/2508.10967)
*Xinyi Li,Sai Wang,Yutian Lin,Yu Wu,Yi Yang*

Main category: cs.LG

TL;DR: 提出了Retro-Expert，一个可解释的逆合成框架，它通过强化学习结合大型语言模型和专业模型的互补推理优势来执行协作推理。


<details>
  <summary>Details</summary>
Motivation: 现有的逆合成模型依赖于静态模式匹配范例，这限制了它们执行有效逻辑决策的能力，从而导致黑盒决策。

Method: 结合大型语言模型和专业模型的互补推理优势，通过强化学习进行协作推理。

Result: Retro-Expert在不同指标上超越了基于LLM和专业模型。

Conclusion: Retro-Expert不仅在不同指标上超越了基于LLM和专业模型，而且提供了专家一致的解释，弥合了AI预测和可操作的化学见解之间的差距。

Abstract: Retrosynthesis prediction aims to infer the reactant molecule based on a
given product molecule, which is a fundamental task in chemical synthesis.
However, existing models rely on static pattern-matching paradigm, which limits
their ability to perform effective logic decision-making, leading to black-box
decision-making. Building on this, we propose Retro-Expert, an interpretable
retrosynthesis framework that performs collaborative reasoning by combining the
complementary reasoning strengths of Large Language Models and specialized
models via reinforcement learning. It outputs natural language explanations
grounded in chemical logic through three components: (1) specialized models
perform shallow reasoning to construct high-quality chemical decision space,
(2) LLM-driven critical reasoning to generate predictions and corresponding
interpretable reasoning path, and (3) reinforcement learning optimizing
interpretable decision policy. Experiments show that Retro-Expert not only
surpasses both LLM-based and specialized models across different metrics but
also provides expert-aligned explanations that bridge the gap between AI
predictions and actionable chemical insights.

</details>


### [135] [BeyondWeb: Lessons from Scaling Synthetic Data for Trillion-scale Pretraining](https://arxiv.org/abs/2508.10975)
*Pratyush Maini,Vineeth Dorna,Parth Doshi,Aldo Carranza,Fan Pan,Jack Urbanek,Paul Burstein,Alex Fang,Alvin Deng,Amro Abbas,Brett Larsen,Cody Blakeney,Charvi Bannur,Christina Baek,Darren Teh,David Schwab,Haakon Mongstad,Haoli Yin,Josh Wills,Kaleigh Mentzer,Luke Merrick,Ricardo Monti,Rishabh Adiga,Siddharth Joshi,Spandan Das,Zhengping Wang,Bogdan Gaza,Ari Morcos,Matthew Leavitt*

Main category: cs.LG

TL;DR: BeyondWeb is a synthetic data generation framework that produces high-quality synthetic data for pretraining. A 3B model trained on BeyondWeb outperforms an 8B model trained on Cosmopedia.


<details>
  <summary>Details</summary>
Motivation: simply scaling data quantity eventually leads to diminishing returns, hitting a data wall. In response, the use of synthetic data for pretraining has emerged as a promising paradigm for pushing the frontier of performance. Despite this, the factors affecting synthetic data quality remain poorly understood.

Method: introduce BeyondWeb, a synthetic data generation framework that produces high-quality synthetic data for pretraining

Result: BeyondWeb significantly extends the capabilities of traditional web-scale datasets, outperforming state-of-the-art synthetic pretraining datasets such as Cosmopedia and Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1 percentage points (pp) and 2.6pp, respectively, when averaged across a suite of 14 benchmark evaluations. It delivers up to 7.7x faster training than open web data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for 180B tokens on BeyondWeb outperforms an 8B model trained for the same token budget on Cosmopedia.

Conclusion: This work shows that there's no silver bullet for generating high-quality synthetic pretraining data. The best outcomes require jointly optimizing many factors, a challenging task that requires rigorous science and practical expertise. Naive approaches can yield modest improvements, potentially at great cost, while well-executed methods can yield transformative improvements, as exemplified by BeyondWeb.

Abstract: Recent advances in large language model (LLM) pretraining have shown that
simply scaling data quantity eventually leads to diminishing returns, hitting a
data wall. In response, the use of synthetic data for pretraining has emerged
as a promising paradigm for pushing the frontier of performance. Despite this,
the factors affecting synthetic data quality remain poorly understood. In this
work, we introduce BeyondWeb, a synthetic data generation framework that
produces high-quality synthetic data for pretraining. BeyondWeb significantly
extends the capabilities of traditional web-scale datasets, outperforming
state-of-the-art synthetic pretraining datasets such as Cosmopedia and
Nemotron-CC's high-quality synthetic subset (Nemotron-Synth) by up to 5.1
percentage points (pp) and 2.6pp, respectively, when averaged across a suite of
14 benchmark evaluations. It delivers up to 7.7x faster training than open web
data and 2.7x faster than Nemotron-Synth. Remarkably, a 3B model trained for
180B tokens on BeyondWeb outperforms an 8B model trained for the same token
budget on Cosmopedia. We also present several insights from BeyondWeb on
synthetic data for pretraining: what drives its benefits, which data to
rephrase and how, and the impact of model size and family on data quality.
Overall, our work shows that there's no silver bullet for generating
high-quality synthetic pretraining data. The best outcomes require jointly
optimizing many factors, a challenging task that requires rigorous science and
practical expertise. Naive approaches can yield modest improvements,
potentially at great cost, while well-executed methods can yield transformative
improvements, as exemplified by BeyondWeb.

</details>


### [136] [Match & Choose: Model Selection Framework for Fine-tuning Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.10993)
*Basile Lewandowski,Robert Birke,Lydia Y. Chen*

Main category: cs.LG

TL;DR: 提出了一种模型选择框架 M&C，用于从模型平台中选择预训练的 T2I 模型，而无需在目标数据集上详尽地微调它们。


<details>
  <summary>Details</summary>
Motivation: 用户在选择哪个预训练 T2I 模型在目标数据域上进行微调时面临挑战。模型选择在分类任务中已得到很好的解决，但对于（预训练的）T2I 模型及其在目标域上的性能指示知之甚少。

Method: 提出了一个模型选择框架 M&C，它由匹配图组成，匹配图包含可用模型和分析数据集的节点，以及模型-数据和数据-数据对的边，分别捕获微调性能和数据相似性。

Result: M&C 在 32 个数据集上针对 10 个 T2I 模型进行了评估，并与三个基线进行了比较。结果表明，M&C 在 61.3% 的案例中成功预测了用于微调的最佳模型，其余案例中预测了性能接近的模型。

Conclusion: M&C 成功预测了 61.3% 案例中用于微调的最佳模型，其余案例中预测了性能接近的模型。

Abstract: Text-to-image (T2I) models based on diffusion and transformer architectures
advance rapidly. They are often pretrained on large corpora, and openly shared
on a model platform, such as HuggingFace. Users can then build up AI
applications, e.g., generating media contents, by adopting pretrained T2I
models and fine-tuning them on the target dataset. While public pretrained T2I
models facilitate the democratization of the models, users face a new
challenge: which model can be best fine-tuned based on the target data domain?
Model selection is well addressed in classification tasks, but little is known
in (pretrained) T2I models and their performance indication on the target
domain. In this paper, we propose the first model selection framework, M&C,
which enables users to efficiently choose a pretrained T2I model from a model
platform without exhaustively fine-tuning them all on the target dataset. The
core of M&C is a matching graph, which consists of: (i) nodes of available
models and profiled datasets, and (ii) edges of model-data and data-data pairs
capturing the fine-tuning performance and data similarity, respectively. We
then build a model that, based on the inputs of model/data feature, and,
critically, the graph embedding feature, extracted from the matching graph,
predicts the model achieving the best quality after fine-tuning for the target
domain. We evaluate M&C on choosing across ten T2I models for 32 datasets
against three baselines. Our results show that M&C successfully predicts the
best model for fine-tuning in 61.3% of the cases and a closely performing model
for the rest.

</details>


### [137] [Relative Advantage Debiasing for Watch-Time Prediction in Short-Video Recommendation](https://arxiv.org/abs/2508.11086)
*Emily Liu,Kuan Han,Minfeng Zhan,Bocheng Zhao,Guanyu Mu,Yang Song*

Main category: cs.LG

TL;DR: 该论文提出了一种新的相对优势去偏框架，通过比较观看时间和经验参考分布来校正观看时间，从而提高推荐准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 观看时间被广泛用作视频推荐平台中用户满意度的指标。然而，原始观看时间受到诸如视频时长、受欢迎程度和个人用户行为等混杂因素的影响，可能会扭曲偏好信号并导致有偏见的推荐模型。

Method: 该论文提出了一种新的相对优势去偏框架，通过将其与基于用户和项目组的经验参考分布进行比较来校正观看时间。这种方法产生基于分位数的偏好信号，并引入了一个两阶段架构，该架构将分布估计与偏好学习显式分离。此外，该论文还提出了分布嵌入，以有效地参数化观看时间分位数，而无需在线采样或存储历史数据。

Result: 相对于现有基线方法，该论文在推荐准确性和鲁棒性方面有显著提高。

Conclusion: 该论文通过离线和在线实验证明，相对于现有基线方法，所提出的方法在推荐准确性和鲁棒性方面有显著提高。

Abstract: Watch time is widely used as a proxy for user satisfaction in video
recommendation platforms. However, raw watch times are influenced by
confounding factors such as video duration, popularity, and individual user
behaviors, potentially distorting preference signals and resulting in biased
recommendation models. We propose a novel relative advantage debiasing
framework that corrects watch time by comparing it to empirically derived
reference distributions conditioned on user and item groups. This approach
yields a quantile-based preference signal and introduces a two-stage
architecture that explicitly separates distribution estimation from preference
learning. Additionally, we present distributional embeddings to efficiently
parameterize watch-time quantiles without requiring online sampling or storage
of historical data. Both offline and online experiments demonstrate significant
improvements in recommendation accuracy and robustness compared to existing
baseline methods.

</details>


### [138] [CURE: Critical-Token-Guided Re-concatenation for Entropy-collapse Prevention](https://arxiv.org/abs/2508.11016)
*Qingbin Li,Rongkun Xue,Jie Wang,Ming Zhou,Zhi Li,Xiaofeng Ji,Yongqi Wang,Miao Liu,Zheming Yang,Minghui Qiu,Jing Yang*

Main category: cs.LG

TL;DR: CURE通过在探索和利用之间取得平衡，解决了RLVR中熵崩溃的问题，从而提高了数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 先前RLVR流程中，在每个采样阶段重复使用从数据集分布中精确提取的静态初始状态采样，从而产生过度确定性的、低多样性的模型行为，这表现为快速的熵崩溃，并阻碍了长期训练期间的持续性能提升。

Method: CURE（用于防止熵崩溃的关键token引导的重连接）

Result: 与vanilla DAPO相比，再生过程在数学推理任务上实现了更好的性能，同时保持了高水平的熵度以进行探索。与其它RLVR方法相比，CURE在六个数学基准测试中实现了5%的性能提升。

Conclusion: CURE在六个数学基准测试中实现了5%的性能提升，并在熵和准确性方面建立了最先进的性能。

Abstract: Recent advances in Reinforcement Learning with Verified Reward (RLVR) have
driven the emergence of more sophisticated cognitive behaviors in large
language models (LLMs), thereby enhancing their reasoning capabilities.
However, in prior RLVR pipelines, the repeated use of static initial-state
sampling drawn exactly from the dataset distribution during each sampling phase
produced overly deterministic, low diversity model behavior, which manifested
as rapid entropy collapse and hindered sustained performance gains during
prolonged training. To address this issue, we introduce CURE
(Critical-token-gUided Re concatenation for Entropy-collapse prevention), a
two-stage framework that balances exploration and exploitation. Specifically,
in the first stage, to deliberately steer the model toward novel yet coherent
contexts, we re-generate at high-entropy critical tokens and jointly optimize
the original and the branched trajectories. The further comparison with vanilla
DAPO shows that the regeneration process achieves a better performance on math
reasoning tasks while sustaining a high-level entropy degree for exploration.
In the second stage, we continue training with static initial-state sampling by
DAPO, intentionally placing the model in a familiar state to gradually
strengthen exploitation. Extensive experiments on Qwen-2.5-Math-7B show that,
compared to other RLVR methods, CURE achieves a 5% performance gain across six
math benchmarks, establishing state-of-the-art performance in both entropy and
accuracy. A series of experiments further validate the effectiveness of our
approach. Code is available at https://github.com/CURE-Project/CURE.

</details>


### [139] [Hybrid-Hierarchical Fashion Graph Attention Network for Compatibility-Oriented and Personalized Outfit Recommendation](https://arxiv.org/abs/2508.11105)
*Sajjad Saed,Babak Teimourpour*

Main category: cs.LG

TL;DR: 提出FGAT模型，使用图神经网络处理时尚搭配推荐问题，效果比现有模型好。


<details>
  <summary>Details</summary>
Motivation: 时尚行业的快速扩张和产品种类日益增多，使得用户在电子商务平台上找到合适的商品变得具有挑战性。同时解决服装搭配兼容性和个性化推荐仍然是一个重大挑战，因为这些方面在现有研究中通常是独立处理的，经常忽略物品和用户偏好之间复杂的相互作用。

Method: 提出了一种名为FGAT的新框架，该框架受到HFGN模型的启发，利用图神经网络和图注意力机制。

Result: 在POG数据集上进行评估，FGAT优于HFGN等基线模型，在精确率、HR、召回率、NDCG和准确率方面取得了改进的结果。

Conclusion: FGAT模型通过结合多模态视觉-文本特征、分层图结构和注意力机制，显著提高了个性化时尚推荐系统的准确性和效率。

Abstract: The rapid expansion of the fashion industry and the growing variety of
products have made it challenging for users to find compatible items on
e-commerce platforms. Effective fashion recommendation systems are crucial for
filtering irrelevant items and suggesting suitable ones. However,
simultaneously addressing outfit compatibility and personalized recommendations
remains a significant challenge, as these aspects are often treated
independently in existing studies, often overlooking the complex interactions
between items and user preferences. This research introduces a new framework
named FGAT, inspired by the HFGN model, which leverages graph neural networks
and graph attention mechanisms to tackle this issue. The proposed framework
constructs a three-tier hierarchical graph of users, outfits, and items,
integrating visual and textual features to simultaneously model outfit
compatibility and user preferences. A graph attention mechanism dynamically
weights node importance during representation propagation, enabling the capture
of key interactions and generating precise representations for both user
preferences and outfit compatibility. Evaluated on the POG dataset, FGAT
outperforms baseline models such as HFGN, achieving improved results in
precision, HR, recall, NDCG, and accuracy.These results demonstrate that
combining multimodal visual-textual features with a hierarchical graph
structure and attention mechanisms significantly enhances the accuracy and
efficiency of personalized fashion recommendation systems.

</details>


### [140] [Quantization vs Pruning: Insights from the Strong Lottery Ticket Hypothesis](https://arxiv.org/abs/2508.11020)
*Aakash Kumar,Emanuele Natale*

Main category: cs.LG

TL;DR: 本文将 SLTH 框架扩展到有限精度网络，证明了量化设置中目标离散神经网络的相应类别可以精确表示，并证明了作为目标网络精度的函数的初始网络的必要过度参数化的最佳界限。


<details>
  <summary>Details</summary>
Motivation: 量化是使神经网络更有效的基本技术，但我们对它的理论理解仍然有限。先前的工作表明，可以通过修剪大型随机初始化的网络来构建极低精度的网络，例如二元网络，并且表明原始网络和修剪网络的大小之间的比率最多是对数多项式。

Method: 我们利用 Borgs 等人在数字分割问题上的基础结果，推导出量化设置中随机子集和问题的新理论结果。

Result: 我们证明了，在量化设置中，目标离散神经网络的相应类别可以精确表示，并且我们证明了作为目标网络精度的函数的初始网络的必要过度参数化的最佳界限。

Conclusion: 在量化设置中，目标离散神经网络的相应类别可以精确表示，并且我们证明了作为目标网络精度的函数的初始网络的必要过度参数化的最佳界限。

Abstract: Quantization is an essential technique for making neural networks more
efficient, yet our theoretical understanding of it remains limited. Previous
works demonstrated that extremely low-precision networks, such as binary
networks, can be constructed by pruning large, randomly-initialized networks,
and showed that the ratio between the size of the original and the pruned
networks is at most polylogarithmic.
  The specific pruning method they employed inspired a line of theoretical work
known as the Strong Lottery Ticket Hypothesis (SLTH), which leverages insights
from the Random Subset Sum Problem. However, these results primarily address
the continuous setting and cannot be applied to extend SLTH results to the
quantized setting.
  In this work, we build on foundational results by Borgs et al. on the Number
Partitioning Problem to derive new theoretical results for the Random Subset
Sum Problem in a quantized setting.
  Using these results, we then extend the SLTH framework to finite-precision
networks. While prior work on SLTH showed that pruning allows approximation of
a certain class of neural networks, we demonstrate that, in the quantized
setting, the analogous class of target discrete neural networks can be
represented exactly, and we prove optimal bounds on the necessary
overparameterization of the initial network as a function of the precision of
the target network.

</details>


### [141] [Zono-Conformal Prediction: Zonotope-Based Uncertainty Quantification for Regression and Classification Tasks](https://arxiv.org/abs/2508.11025)
*Laura Lützow,Michael Eichelbeck,Mykel J. Kochenderfer,Matthias Althoff*

Main category: cs.LG

TL;DR: This paper introduces zono-conformal prediction to address the limitations of current conformal prediction methods in terms of computational cost, data intensity, and the ability to capture dependencies in multi-dimensional outputs. Zono-conformal predictors are less conservative and achieve similar coverage.


<details>
  <summary>Details</summary>
Motivation: current methods are often computationally expensive and data-intensive, as they require constructing an uncertainty model before calibration. Moreover, existing approaches typically represent the prediction sets with intervals, which limits their ability to capture dependencies in multi-dimensional outputs.

Method: introducing zono-conformal prediction, a novel approach inspired by interval predictor models and reachset-conformant identification that constructs prediction zonotopes with assured coverage. By placing zonotopic uncertainty sets directly into the model of the base predictor, zono-conformal predictors can be identified via a single, data-efficient linear program. focus on feed-forward neural networks

Result: provide probabilistic coverage guarantees and present methods for detecting outliers in the identification data. Aside from regression tasks, also construct optimal zono-conformal predictors in classification settings where the output of an uncertain predictor is a set of possible classes.

Conclusion: zono-conformal predictors are less conservative than interval predictor models and standard conformal prediction methods, while achieving a similar coverage over the test data.

Abstract: Conformal prediction is a popular uncertainty quantification method that
augments a base predictor with prediction sets with statistically valid
coverage guarantees. However, current methods are often computationally
expensive and data-intensive, as they require constructing an uncertainty model
before calibration. Moreover, existing approaches typically represent the
prediction sets with intervals, which limits their ability to capture
dependencies in multi-dimensional outputs. We address these limitations by
introducing zono-conformal prediction, a novel approach inspired by interval
predictor models and reachset-conformant identification that constructs
prediction zonotopes with assured coverage. By placing zonotopic uncertainty
sets directly into the model of the base predictor, zono-conformal predictors
can be identified via a single, data-efficient linear program. While we can
apply zono-conformal prediction to arbitrary nonlinear base predictors, we
focus on feed-forward neural networks in this work. Aside from regression
tasks, we also construct optimal zono-conformal predictors in classification
settings where the output of an uncertain predictor is a set of possible
classes. We provide probabilistic coverage guarantees and present methods for
detecting outliers in the identification data. In extensive numerical
experiments, we show that zono-conformal predictors are less conservative than
interval predictor models and standard conformal prediction methods, while
achieving a similar coverage over the test data.

</details>


### [142] [Learning with Confidence](https://arxiv.org/abs/2508.11037)
*Oliver Ethan Richardson*

Main category: cs.LG

TL;DR: 学习者拥有的信念的信任度会影响信念状态。


<details>
  <summary>Details</summary>
Motivation: 在学习或更新信念中，我们描述了一种置信度的概念：一个人对传入信息的信任程度及其对信念状态的影响。

Method: 我们正式地公理化了用置信度学习的含义，给出了在连续统上测量置信度的两种规范方法，并证明了置信度总是可以用这种方式来表示。

Result: 在额外的假设下，我们用向量场和损失函数导出了基于置信度的学习的更紧凑的表示。这些表示导出了一种扩展的复合“并行”观察语言。

Conclusion: 贝叶斯规则可以描述为损失表示是线性期望的优化学习者的特例。

Abstract: We characterize a notion of confidence that arises in learning or updating
beliefs: the amount of trust one has in incoming information and its impact on
the belief state. This learner's confidence can be used alongside (and is
easily mistaken for) probability or likelihood, but it is fundamentally a
different concept -- one that captures many familiar concepts in the
literature, including learning rates and number of training epochs, Shafer's
weight of evidence, and Kalman gain. We formally axiomatize what it means to
learn with confidence, give two canonical ways of measuring confidence on a
continuum, and prove that confidence can always be represented in this way.
Under additional assumptions, we derive more compact representations of
confidence-based learning in terms of vector fields and loss functions. These
representations induce an extended language of compound "parallel"
observations. We characterize Bayes Rule as the special case of an optimizing
learner whose loss representation is a linear expectation.

</details>


### [143] [Conditional Independence Estimates for the Generalized Nonparanormal](https://arxiv.org/abs/2508.11050)
*Ujas Shah,Manuel Lladser,Rebecca Morrison*

Main category: cs.LG

TL;DR: conditional independence structure can still be inferred from the precision matrix for a class of non-Gaussian distributions


<details>
  <summary>Details</summary>
Motivation: the covariance and precision matrices do not encode the independence structure of the variables, as they do for the multivariate Gaussian

Method: a simple and computationally efficient algorithm that leverages this theory to recover conditional independence structure from the generalized nonparanormal data

Result: effectiveness of the proposed algorithm is demonstrated via synthetic experiments and applications to real-world data

Conclusion: conditional independence structure can still be inferred from the precision matrix, provided the data meet certain criteria, analogous to the Gaussian case

Abstract: For general non-Gaussian distributions, the covariance and precision matrices
do not encode the independence structure of the variables, as they do for the
multivariate Gaussian. This paper builds on previous work to show that for a
class of non-Gaussian distributions -- those derived from diagonal
transformations of a Gaussian -- information about the conditional independence
structure can still be inferred from the precision matrix, provided the data
meet certain criteria, analogous to the Gaussian case. We call such
transformations of the Gaussian as the generalized nonparanormal. The functions
that define these transformations are, in a broad sense, arbitrary. We also
provide a simple and computationally efficient algorithm that leverages this
theory to recover conditional independence structure from the generalized
nonparanormal data. The effectiveness of the proposed algorithm is demonstrated
via synthetic experiments and applications to real-world data.

</details>


### [144] [SHLIME: Foiling adversarial attacks fooling SHAP and LIME](https://arxiv.org/abs/2508.11053)
*Sam Chauhan,Estelle Duguet,Karthik Ramakrishnan,Hugh Van Deventer,Jack Kruger,Ranjan Subbaraman*

Main category: cs.LG

TL;DR: LIME and SHAP are vulnerable to adversarial manipulation. We identify configurations that substantially improve bias detection.


<details>
  <summary>Details</summary>
Motivation: Post hoc explanation methods, such as LIME and SHAP, are vulnerable to adversarial manipulation, potentially concealing harmful biases. Building on the work of Slack et al. (2020), we investigate the susceptibility of LIME and SHAP to biased models and evaluate strategies for improving robustness.

Method: Introduce a modular testing framework enabling systematic evaluation of augmented and ensemble explanation approaches across classifiers of varying performance. Assess multiple LIME/SHAP ensemble configurations on out-of-distribution models, comparing their resistance to bias concealment against the original methods.

Result: Results identify configurations that substantially improve bias detection.

Conclusion: Identified LIME/SHAP configurations that substantially improve bias detection, highlighting their potential for enhancing transparency in the deployment of high-stakes machine learning systems.

Abstract: Post hoc explanation methods, such as LIME and SHAP, provide interpretable
insights into black-box classifiers and are increasingly used to assess model
biases and generalizability. However, these methods are vulnerable to
adversarial manipulation, potentially concealing harmful biases. Building on
the work of Slack et al. (2020), we investigate the susceptibility of LIME and
SHAP to biased models and evaluate strategies for improving robustness. We
first replicate the original COMPAS experiment to validate prior findings and
establish a baseline. We then introduce a modular testing framework enabling
systematic evaluation of augmented and ensemble explanation approaches across
classifiers of varying performance. Using this framework, we assess multiple
LIME/SHAP ensemble configurations on out-of-distribution models, comparing
their resistance to bias concealment against the original methods. Our results
identify configurations that substantially improve bias detection, highlighting
their potential for enhancing transparency in the deployment of high-stakes
machine learning systems.

</details>


### [145] [Abundance-Aware Set Transformer for Microbiome Sample Embedding](https://arxiv.org/abs/2508.11075)
*Hyunwoo Yoo,Gail Rosen*

Main category: cs.LG

TL;DR: This paper introduces an abundance-aware Set Transformer for microbiome sample representation, improving performance in classification tasks by considering taxa abundance.


<details>
  <summary>Details</summary>
Motivation: Existing methods for representing microbiome samples in LLMs often overlook the biological importance of taxa abundance, relying on simple averaging over sequence embeddings.

Method: An abundance-aware variant of the Set Transformer is used to construct fixed-size sample-level embeddings by weighting sequence embeddings according to their relative abundance.

Result: The proposed method outperforms average pooling and unweighted Set Transformers on real-world microbiome classification tasks.

Conclusion: Abundance-aware aggregation improves microbiome representation, achieving perfect performance in some classification tasks.

Abstract: Microbiome sample representation to input into LLMs is essential for
downstream tasks such as phenotype prediction and environmental classification.
While prior studies have explored embedding-based representations of each
microbiome sample, most rely on simple averaging over sequence embeddings,
often overlooking the biological importance of taxa abundance. In this work, we
propose an abundance-aware variant of the Set Transformer to construct
fixed-size sample-level embeddings by weighting sequence embeddings according
to their relative abundance. Without modifying the model architecture, we
replicate embedding vectors proportional to their abundance and apply
self-attention-based aggregation. Our method outperforms average pooling and
unweighted Set Transformers on real-world microbiome classification tasks,
achieving perfect performance in some cases. These results demonstrate the
utility of abundance-aware aggregation for robust and biologically informed
microbiome representation. To the best of our knowledge, this is one of the
first approaches to integrate sequence-level abundance into Transformer-based
sample embeddings.

</details>


### [146] [A Feasibility Experiment on the Application of Predictive Coding to Instant Messaging Corpora](https://arxiv.org/abs/2508.11084)
*Thanasis Schoinas,Ghulam Qadir*

Main category: cs.LG

TL;DR: 本文提出了一种经济可行的预测编码解决方案，用于即时消息的文档分类，通过将消息分组到每日聊天中，并利用特征选择和逻辑回归分类器。


<details>
  <summary>Details</summary>
Motivation: 由于即时消息的非正式性质和较小尺寸，使用机器学习进行文档分类的预测编码在法律行业中提出了额外的挑战。

Method: 利用数据管理工作流程将消息分组到每日聊天中，然后进行特征选择和逻辑回归分类器。

Result: 该方法在经济上可行，并提供了成本节约的示例。

Conclusion: 通过降维提升了基线模型性能，重点关注定量特征。在 Instant Bloomberg 数据集上测试了该方法。

Abstract: Predictive coding, the term used in the legal industry for document
classification using machine learning, presents additional challenges when the
dataset comprises instant messages, due to their informal nature and smaller
sizes. In this paper, we exploit a data management workflow to group messages
into day chats, followed by feature selection and a logistic regression
classifier to provide an economically feasible predictive coding solution. We
also improve the solution's baseline model performance by dimensionality
reduction, with focus on quantitative features. We test our methodology on an
Instant Bloomberg dataset, rich in quantitative information. In parallel, we
provide an example of the cost savings of our approach.

</details>


### [147] [Predictive Multimodal Modeling of Diagnoses and Treatments in EHR](https://arxiv.org/abs/2508.11092)
*Cindy Shih-Ting Huang,Clarence Boon Liang Ng,Marek Rei*

Main category: cs.LG

TL;DR: 提出了一种多模态系统，用于早期预测 ICD 代码，该系统优于当前最先进的系统。


<details>
  <summary>Details</summary>
Motivation: ICD 代码分配问题已被广泛研究，但大多数工作都集中在出院后文档分类上。用于早期预测这些信息的模型可用于识别健康风险、建议有效治疗或优化资源分配。为了解决在患者住院初期使用有限信息进行预测建模的挑战。

Method: 提出了一个多模态系统，融合了电子健康记录中的临床笔记和表格事件。该模型集成了预训练编码器、特征池化和跨模态注意力，以学习跨模态的最佳表示，并平衡它们在每个时间点的存在。此外，还提出了一种加权时间损失，用于调整其在每个时间点的贡献。

Result: 这些策略增强了早期预测模型，优于目前最先进的系统。

Conclusion: 提出的模型优于目前最先进的系统，证明了这些策略增强了早期预测模型。

Abstract: While the ICD code assignment problem has been widely studied, most works
have focused on post-discharge document classification. Models for early
forecasting of this information could be used for identifying health risks,
suggesting effective treatments, or optimizing resource allocation. To address
the challenge of predictive modeling using the limited information at the
beginning of a patient stay, we propose a multimodal system to fuse clinical
notes and tabular events captured in electronic health records. The model
integrates pre-trained encoders, feature pooling, and cross-modal attention to
learn optimal representations across modalities and balance their presence at
every temporal point. Moreover, we present a weighted temporal loss that
adjusts its contribution at each point in time. Experiments show that these
strategies enhance the early prediction model, outperforming the current
state-of-the-art systems.

</details>


### [148] [Quantization through Piecewise-Affine Regularization: Optimization and Statistical Guarantees](https://arxiv.org/abs/2508.11112)
*Jianhao Ma,Lin Xiao*

Main category: cs.LG

TL;DR: 本文研究了分段仿射正则化 (PAR) 的理论基础，从优化和统计的角度来看，它是一种基于连续优化的量化方法。


<details>
  <summary>Details</summary>
Motivation: 由于其搜索空间的组合性质，离散或量化变量上的优化问题通常非常具有挑战性。分段仿射正则化 (PAR) 提供了一个灵活的建模和计算框架，用于基于连续优化的量化。

Method: 我们推导了各种（凸、拟凸和非凸）PAR 的闭式近端映射，并展示了如何使用近端梯度法、其加速变体和乘法器的交替方向法来解决 PAR 正则化问题。

Result: 首先，我们表明，在过度参数化的情况下，其中参数的数量超过了样本的数量，PAR 正则化损失函数的每个临界点都表现出高度的量化。

Conclusion: 我们研究了 PAR 正则化线性回归问题的统计保证；具体来说，我们可以使用 PAR 来近似 $\ell_1$-、平方 $\ell_2$- 和非凸正则化的经典公式，并获得具有量化解决方案的类似统计保证。

Abstract: Optimization problems over discrete or quantized variables are very
challenging in general due to the combinatorial nature of their search space.
Piecewise-affine regularization (PAR) provides a flexible modeling and
computational framework for quantization based on continuous optimization. In
this work, we focus on the setting of supervised learning and investigate the
theoretical foundations of PAR from optimization and statistical perspectives.
First, we show that in the overparameterized regime, where the number of
parameters exceeds the number of samples, every critical point of the
PAR-regularized loss function exhibits a high degree of quantization. Second,
we derive closed-form proximal mappings for various (convex, quasi-convex, and
non-convex) PARs and show how to solve PAR-regularized problems using the
proximal gradient method, its accelerated variant, and the Alternating
Direction Method of Multipliers. Third, we study statistical guarantees of
PAR-regularized linear regression problems; specifically, we can approximate
classical formulations of $\ell_1$-, squared $\ell_2$-, and nonconvex
regularizations using PAR and obtain similar statistical guarantees with
quantized solutions.

</details>


### [149] [CTRL Your Shift: Clustered Transfer Residual Learning for Many Small Datasets](https://arxiv.org/abs/2508.11144)
*Gauri Jain,Dominik Rothenhäusler,Kirk Bansak,Elisabeth Paulson*

Main category: cs.LG

TL;DR: This paper introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method to simultaneously improve overall accuracy and preserve source-level heterogeneity.


<details>
  <summary>Details</summary>
Motivation: practitioners often desire predictions that not only exhibit good overall accuracy, but also remain reliable within each source and preserve the differences that matter across sources.However, this task is made challenging by several common characteristics of the data in these settings:the presence of numerous distinct data sources, distributional shifts between them, and substantial variation in sample sizes across sources.

Method: Clustered Transfer Residual Learning (CTRL), a meta-learning method that combines the strengths of cross-domain residual learning and adaptive pooling/clustering

Result: We provide theoretical results that clarify how our objective navigates the trade-off between data quantity and data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5 large-scale datasets.

Conclusion: CTRL consistently outperforms the benchmarks across several key metrics and when using a range of different base learners.

Abstract: Machine learning (ML) tasks often utilize large-scale data that is drawn from
several distinct sources, such as different locations, treatment arms, or
groups. In such settings, practitioners often desire predictions that not only
exhibit good overall accuracy, but also remain reliable within each source and
preserve the differences that matter across sources. For instance, several
asylum and refugee resettlement programs now use ML-based employment
predictions to guide where newly arriving families are placed within a host
country, which requires generating informative and differentiated predictions
for many and often small source locations. However, this task is made
challenging by several common characteristics of the data in these settings:
the presence of numerous distinct data sources, distributional shifts between
them, and substantial variation in sample sizes across sources. This paper
introduces Clustered Transfer Residual Learning (CTRL), a meta-learning method
that combines the strengths of cross-domain residual learning and adaptive
pooling/clustering in order to simultaneously improve overall accuracy and
preserve source-level heterogeneity. We provide theoretical results that
clarify how our objective navigates the trade-off between data quantity and
data quality. We evaluate CTRL alongside other state-of-the-art benchmarks on 5
large-scale datasets. This includes a dataset from the national asylum program
in Switzerland, where the algorithmic geographic assignment of asylum seekers
is currently being piloted. CTRL consistently outperforms the benchmarks across
several key metrics and when using a range of different base learners.

</details>


### [150] [Towards the Next-generation Bayesian Network Classifiers](https://arxiv.org/abs/2508.11145)
*Huan Zhang,Daokun Zhang,Kexin Meng,Geoffrey I. Webb*

Main category: cs.LG

TL;DR: 提出了一种新的高阶贝叶斯网络分类器NeuralKDB，它通过学习特征值的分布表示来提高分类性能，并在UCI数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 贝叶斯网络分类器在表格数据分类中是可行的解决方案，但由于参数爆炸和数据稀疏性问题，它们仅限于低阶特征依赖性建模，这使得它们难以推断复杂现实世界数据的出现概率。

Method: 通过学习特征值的分布表示来设计高阶贝叶斯网络分类器，类似于词嵌入和图表示学习。

Result: 在60个UCI数据集上进行的大量分类实验表明，所提出的NeuralKDB分类器在捕获高阶特征依赖性方面表现出色，并且显着优于传统的贝叶斯网络分类器以及其他竞争性分类器，包括两个没有分布表示学习的基于神经网络的分类器。

Conclusion: 提出的NeuralKDB分类器在捕获高阶特征依赖性方面表现出色，并且显着优于传统的贝叶斯网络分类器以及其他竞争性分类器，包括两个没有分布表示学习的基于神经网络的分类器。

Abstract: Bayesian network classifiers provide a feasible solution to tabular data
classification, with a number of merits like high time and memory efficiency,
and great explainability. However, due to the parameter explosion and data
sparsity issues, Bayesian network classifiers are restricted to low-order
feature dependency modeling, making them struggle in extrapolating the
occurrence probabilities of complex real-world data. In this paper, we propose
a novel paradigm to design high-order Bayesian network classifiers, by learning
distributional representations for feature values, as what has been done in
word embedding and graph representation learning. The learned distributional
representations are encoded with the semantic relatedness between different
features through their observed co-occurrence patterns in training data, which
then serve as a hallmark to extrapolate the occurrence probabilities of new
test samples. As a classifier design realization, we remake the K-dependence
Bayesian classifier (KDB) by extending it into a neural version, i.e.,
NeuralKDB, where a novel neural network architecture is designed to learn
distributional representations of feature values and parameterize the
conditional probabilities between interdependent features. A stochastic
gradient descent based algorithm is designed to train the NeuralKDB model
efficiently. Extensive classification experiments on 60 UCI datasets
demonstrate that the proposed NeuralKDB classifier excels in capturing
high-order feature dependencies and significantly outperforms the conventional
Bayesian network classifiers, as well as other competitive classifiers,
including two neural network based classifiers without distributional
representation learning.

</details>


### [151] [Mitigating Modality Quantity and Quality Imbalance in Multimodal Online Federated Learning](https://arxiv.org/abs/2508.11159)
*Heqiang Wang,Weihong Yang,Xiaoxiong Zhong,Jia Zhou,Fangming Liu,Weizhe Zhang*

Main category: cs.LG

TL;DR: This paper investigates the impact of QQI within the MMO-FL framework and proposes the Modality Quantity and Quality Rebalanced (QQR) algorithm to address these challenges. Experiments show that the proposed QQR algorithm consistently outperforms benchmarks under modality imbalance conditions.


<details>
  <summary>Details</summary>
Motivation: MMO-FL faces new challenges due to the inherent instability of IoT devices, which often results in modality quantity and quality imbalance (QQI) during data collection.

Method: propose the Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning based method designed to operate in parallel with the training process.

Result: Extensive experiments on two real-world multimodal datasets show that the proposed QQR algorithm consistently outperforms benchmarks under modality imbalance conditions with promising learning performance.

Conclusion: The proposed QQR algorithm consistently outperforms benchmarks under modality imbalance conditions with promising learning performance.

Abstract: The Internet of Things (IoT) ecosystem produces massive volumes of multimodal
data from diverse sources, including sensors, cameras, and microphones. With
advances in edge intelligence, IoT devices have evolved from simple data
acquisition units into computationally capable nodes, enabling localized
processing of heterogeneous multimodal data. This evolution necessitates
distributed learning paradigms that can efficiently handle such data.
Furthermore, the continuous nature of data generation and the limited storage
capacity of edge devices demand an online learning framework. Multimodal Online
Federated Learning (MMO-FL) has emerged as a promising approach to meet these
requirements. However, MMO-FL faces new challenges due to the inherent
instability of IoT devices, which often results in modality quantity and
quality imbalance (QQI) during data collection. In this work, we systematically
investigate the impact of QQI within the MMO-FL framework and present a
comprehensive theoretical analysis quantifying how both types of imbalance
degrade learning performance. To address these challenges, we propose the
Modality Quantity and Quality Rebalanced (QQR) algorithm, a prototype learning
based method designed to operate in parallel with the training process.
Extensive experiments on two real-world multimodal datasets show that the
proposed QQR algorithm consistently outperforms benchmarks under modality
imbalance conditions with promising learning performance.

</details>


### [152] [A Semi-supervised Generative Model for Incomplete Multi-view Data Integration with Missing Labels](https://arxiv.org/abs/2508.11180)
*Yiyang Shen,Weiran Wang*

Main category: cs.LG

TL;DR: 提出了一个半监督生成模型，用于解决多视图学习中缺失视图和缺失标签的问题，该模型在图像和多组学数据上实现了更好的预测和插补性能。


<details>
  <summary>Details</summary>
Motivation: 多视图学习广泛应用于实际数据集中，例如多组学生物数据，但它经常受到缺失视图和缺失标签的影响。先前的概率方法通过使用专家乘积方案来聚合来自现有视图的表示来解决缺失视图问题，并且使用信息瓶颈（IB）原则，与确定性分类器相比，实现了卓越的性能。然而，IB框架本质上是完全监督的，无法利用未标记的数据。

Method: 我们提出了一个半监督生成模型，该模型在一个统一的框架中利用了标记和未标记的样本。我们的方法最大化未标记样本的可能性，以学习与标记数据上的信息瓶颈（IB）共享的潜在空间。我们还在潜在空间中执行跨视图互信息最大化，以增强跨视图共享信息的提取。

Result: 与现有方法相比，我们的模型在具有缺失视图和有限标记样本的图像和多组学数据上实现了更好的预测和插补性能。

Conclusion: 该模型在图像和多组学数据上实现了更好的预测和插补性能，这些数据具有缺失视图和有限的标记样本。

Abstract: Multi-view learning is widely applied to real-life datasets, such as multiple
omics biological data, but it often suffers from both missing views and missing
labels. Prior probabilistic approaches addressed the missing view problem by
using a product-of-experts scheme to aggregate representations from present
views and achieved superior performance over deterministic classifiers, using
the information bottleneck (IB) principle. However, the IB framework is
inherently fully supervised and cannot leverage unlabeled data. In this work,
we propose a semi-supervised generative model that utilizes both labeled and
unlabeled samples in a unified framework. Our method maximizes the likelihood
of unlabeled samples to learn a latent space shared with the IB on labeled
data. We also perform cross-view mutual information maximization in the latent
space to enhance the extraction of shared information across views. Compared to
existing approaches, our model achieves better predictive and imputation
performance on both image and multi-omics data with missing views and limited
labeled samples.

</details>


### [153] [Quantum-Boosted High-Fidelity Deep Learning](https://arxiv.org/abs/2508.11190)
*Feng-ao Wang,Shaobo Chen,Yao Xuan,Junwei Liu,Qi Gao,Hongdong Zhu,Junjie Hou,Lixin Yuan,Jinyu Cheng,Chenxin Yi,Hai Wei,Yin Ma,Tao Xu,Kai Wen,Yixue Li*

Main category: cs.LG

TL;DR: QBM-VAE是一种新颖的混合量子-经典架构，它使用量子玻尔兹曼机作为变分自编码器的先验，在单细胞数据分析中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 概率深度学习主要依赖于高斯先验，无法准确捕捉自然数据的复杂非高斯形态，特别是在复杂的生物数据等领域。

Method: QBM-VAE，一种混合量子-经典架构，利用量子处理器从玻尔兹曼分布中有效采样。

Result: QBM-VAE生成的潜在空间更好地保留了复杂的生物结构，在组学数据整合、细胞类型分类和轨迹推断等任务中持续优于传统的基于高斯的深度学习模型。

Conclusion: QBM-VAE在单细胞数据集上优于传统高斯模型，为混合量子AI模型提供了蓝图。

Abstract: A fundamental limitation of probabilistic deep learning is its predominant
reliance on Gaussian priors. This simplistic assumption prevents models from
accurately capturing the complex, non-Gaussian landscapes of natural data,
particularly in demanding domains like complex biological data, severely
hindering the fidelity of the model for scientific discovery. The
physically-grounded Boltzmann distribution offers a more expressive
alternative, but it is computationally intractable on classical computers. To
date, quantum approaches have been hampered by the insufficient qubit scale and
operational stability required for the iterative demands of deep learning.
Here, we bridge this gap by introducing the Quantum Boltzmann
Machine-Variational Autoencoder (QBM-VAE), a large-scale and long-time stable
hybrid quantum-classical architecture. Our framework leverages a quantum
processor for efficient sampling from the Boltzmann distribution, enabling its
use as a powerful prior within a deep generative model. Applied to
million-scale single-cell datasets from multiple sources, the QBM-VAE generates
a latent space that better preserves complex biological structures,
consistently outperforming conventional Gaussian-based deep learning models
like VAE and SCVI in essential tasks such as omics data integration, cell-type
classification, and trajectory inference. It also provides a typical example of
introducing a physics priori into deep learning to drive the model to acquire
scientific discovery capabilities that breaks through data limitations. This
work provides the demonstration of a practical quantum advantage in deep
learning on a large-scale scientific problem and offers a transferable
blueprint for developing hybrid quantum AI models.

</details>


### [154] [Meta-learning Structure-Preserving Dynamics](https://arxiv.org/abs/2508.11205)
*Cheng Jing,Uvini Balasuriya Mudiyanselage,Woojin Cho,Minju Jo,Anthony Gruber,Kookjin Lee*

Main category: cs.LG

TL;DR: 提出了一种基于调制的元学习框架，用于参数化动态系统的可扩展和可泛化学习，该框架在少量样本学习中实现了准确的预测，且不影响动态稳定性。


<details>
  <summary>Details</summary>
Motivation: 结构保持的动力学建模方法在建模物理系统方面表现出了巨大的潜力，因为它们具有强大的归纳偏差，可以加强守恒定律和耗散行为。然而，由此产生的模型通常针对固定的系统配置进行训练，需要明确的系统参数知识以及对每个新参数集进行昂贵的再训练——这是多查询或参数变化场景中的一个主要限制。

Method: 引入了一种基于调制的元学习框架，该框架直接将结构保持模型建立在潜在未知系统参数的紧凑潜在表示上，从而避免了灰盒系统知识的需求和适应过程中的显式优化。

Result: 通过将新型调制策略应用于参数化的能量守恒和耗散系统，我们能够在动态系统的参数族中实现可扩展和可泛化的学习。在标准基准问题上的实验表明

Conclusion: 该方法在少量样本学习设置中实现了准确的预测，并且不影响动态稳定性所需的必要物理约束以及在参数空间上的有效泛化性能。

Abstract: Structure-preserving approaches to dynamics modeling have demonstrated great
potential for modeling physical systems due to their strong inductive biases
that enforce conservation laws and dissipative behavior. However, the resulting
models are typically trained for fixed system configurations, requiring
explicit knowledge of system parameters as well as costly retraining for each
new set of parameters -- a major limitation in many-query or parameter-varying
scenarios. Meta-learning offers a potential solution, but existing approaches
like optimization-based meta-learning often suffer from training instability or
limited generalization capability. Inspired by ideas from computer vision, we
introduce a modulation-based meta-learning framework that directly conditions
structure-preserving models on compact latent representations of potentially
unknown system parameters, avoiding the need for gray-box system knowledge and
explicit optimization during adaptation. Through the application of novel
modulation strategies to parametric energy-conserving and dissipative systems,
we enable scalable and generalizable learning across parametric families of
dynamical systems. Experiments on standard benchmark problems demonstrate that
our approach achieves accurate predictions in few-shot learning settings,
without compromising on the essential physical constraints necessary for
dynamical stability and effective generalization performance across parameter
space.

</details>


### [155] [Borrowing From the Future: Enhancing Early Risk Assessment through Contrastive Learning](https://arxiv.org/abs/2508.11210)
*Minghui Sun,Matthew M. Engelhard,Benjamin A. Goldstein*

Main category: cs.LG

TL;DR: This paper introduces Borrowing From the Future (BFF), a contrastive multi-modal framework that improves prediction performance in early-stage risk assessments by borrowing informative signals from later stages. It is validated on two real-world pediatric outcome prediction tasks.


<details>
  <summary>Details</summary>
Motivation: It is clinically desirable to make reliable risk assessments as early as possible. Therefore, this study focuses on improving prediction performance in early-stage risk assessments.

Method: The solution, Borrowing From the Future (BFF), is a contrastive multi-modal framework that treats each time window as a distinct modality. In BFF, a model is trained on all available data throughout the time while performing a risk assessment using up-to-date information. This contrastive framework allows the model to borrow informative signals from later stages to implicitly supervise the learning at earlier stages.

Result: demonstrating consistent improvements in early risk assessments

Conclusion: This study validates BFF on two real-world pediatric outcome prediction tasks, demonstrating consistent improvements in early risk assessments.

Abstract: Risk assessments for a pediatric population are often conducted across
multiple stages. For example, clinicians may evaluate risks prenatally, at
birth, and during Well-Child visits. Although predictions made at later stages
typically achieve higher precision, it is clinically desirable to make reliable
risk assessments as early as possible. Therefore, this study focuses on
improving prediction performance in early-stage risk assessments. Our solution,
\textbf{Borrowing From the Future (BFF)}, is a contrastive multi-modal
framework that treats each time window as a distinct modality. In BFF, a model
is trained on all available data throughout the time while performing a risk
assessment using up-to-date information. This contrastive framework allows the
model to ``borrow'' informative signals from later stages (e.g., Well-Child
visits) to implicitly supervise the learning at earlier stages (e.g.,
prenatal/birth stages). We validate BFF on two real-world pediatric outcome
prediction tasks, demonstrating consistent improvements in early risk
assessments. The code is available at https://github.com/scotsun/bff.

</details>


### [156] [How Causal Abstraction Underpins Computational Explanation](https://arxiv.org/abs/2508.11214)
*Atticus Geiger,Jacqueline Harding,Thomas Icard*

Main category: cs.LG

TL;DR: computational implementation grounded in causal abstraction


<details>
  <summary>Details</summary>
Motivation: What does it take for a system to implement a given computation over suitable representational vehicles within that system?

Method: the language of causality -- and specifically the theory of causal abstraction

Result: classical themes in the philosophy of computation and cognition resurface in contemporary machine learning

Conclusion: an account of computational implementation grounded in causal abstraction, and examine the role for representation in the resulting picture. We argue that these issues are most profitably explored in connection with generalization and prediction.

Abstract: Explanations of cognitive behavior often appeal to computations over
representations. What does it take for a system to implement a given
computation over suitable representational vehicles within that system? We
argue that the language of causality -- and specifically the theory of causal
abstraction -- provides a fruitful lens on this topic. Drawing on current
discussions in deep learning with artificial neural networks, we illustrate how
classical themes in the philosophy of computation and cognition resurface in
contemporary machine learning. We offer an account of computational
implementation grounded in causal abstraction, and examine the role for
representation in the resulting picture. We argue that these issues are most
profitably explored in connection with generalization and prediction.

</details>


### [157] [Air Quality PM2.5 Index Prediction Model Based on CNN-LSTM](https://arxiv.org/abs/2508.11215)
*Zicheng Guo,Shuqi Wu,Meixing Zhu,He Guandi*

Main category: cs.LG

TL;DR: A hybrid CNN-LSTM model predicts PM2.5 concentration with high accuracy but requires significant computational resources and further optimization.


<details>
  <summary>Details</summary>
Motivation: Accurate prediction of air quality indicators, especially PM2.5 concentration, is increasingly important due to global climate change.

Method: The paper proposes an air quality PM2.5 index prediction model based on a hybrid CNN-LSTM architecture, combining CNN for spatial feature extraction and LSTM for temporal dependency modeling.

Result: The model achieves a root mean square error (RMSE) of 5.236, outperforming traditional time series models in both accuracy and generalization.

Conclusion: The hybrid CNN-LSTM model demonstrates strong potential in real-world applications such as air pollution early warning systems, outperforming traditional time series models. However, it requires high computational resources and needs optimization for diverse atmospheric factors.

Abstract: With the intensification of global climate change, accurate prediction of air
quality indicators, especially PM2.5 concentration, has become increasingly
important in fields such as environmental protection, public health, and urban
management. To address this, we propose an air quality PM2.5 index prediction
model based on a hybrid CNN-LSTM architecture. The model effectively combines
Convolutional Neural Networks (CNN) for local spatial feature extraction and
Long Short-Term Memory (LSTM) networks for modeling temporal dependencies in
time series data. Using a multivariate dataset collected from an industrial
area in Beijing between 2010 and 2015 -- which includes hourly records of PM2.5
concentration, temperature, dew point, pressure, wind direction, wind speed,
and precipitation -- the model predicts the average PM2.5 concentration over
6-hour intervals. Experimental results show that the model achieves a root mean
square error (RMSE) of 5.236, outperforming traditional time series models in
both accuracy and generalization. This demonstrates its strong potential in
real-world applications such as air pollution early warning systems. However,
due to the complexity of multivariate inputs, the model demands high
computational resources, and its ability to handle diverse atmospheric factors
still requires optimization. Future work will focus on enhancing scalability
and expanding support for more complex multivariate weather prediction tasks.

</details>


### [158] [Enhancing Interactive Voting-Based Map Matching: Improving Efficiency and Robustness for Heterogeneous GPS Trajectories](https://arxiv.org/abs/2508.11235)
*William Alemanni,Arianna Burzacchi,Davide Colombi,Elena Giarratano*

Main category: cs.LG

TL;DR: An enhanced map matching algorithm reconstructs GPS trajectories with high accuracy, regardless of data quality, using trajectory imputation and OpenStreetMap data.


<details>
  <summary>Details</summary>
Motivation: The main aim is to reconstruct GPS trajectories with high accuracy, independent of input data quality, even with varying sampling rates.

Method: The algorithm is enhanced by integrating trajectory imputation, implementing a distance-bounded interactive voting strategy, addressing missing data, and incorporating a custom-built asset derived from OpenStreetMap.

Result: The enhanced algorithm maintains the core strengths of the original while significantly extending its applicability.

Conclusion: This work enhances the Interactive Voting-Based Map Matching algorithm, extending its applicability to diverse real-world scenarios.

Abstract: This paper presents an enhanced version of the Interactive Voting-Based Map
Matching algorithm, designed to efficiently process trajectories with varying
sampling rates. The main aim is to reconstruct GPS trajectories with high
accuracy, independent of input data quality. Building upon the original
algorithm, developed exclusively for aligning GPS signals to road networks, we
extend its capabilities by integrating trajectory imputation. Our improvements
also include the implementation of a distance-bounded interactive voting
strategy to reduce computational complexity, as well as modifications to
address missing data in the road network. Furthermore, we incorporate a
custom-built asset derived from OpenStreetMap, enabling this approach to be
smoothly applied in any geographic region covered by OpenStreetMap's road
network. These advancements preserve the core strengths of the original
algorithm while significantly extending its applicability to diverse real-world
scenarios.

</details>


### [159] [Graph Neural Diffusion via Generalized Opinion Dynamics](https://arxiv.org/abs/2508.11249)
*Asela Hevapathige,Asiri Wijesinghe,Ahad N. Zehmakan*

Main category: cs.LG

TL;DR: 提出了GODNF，克服了现有基于扩散的图神经网络的局限性，并在节点分类和影响估计任务上优于现有GNN。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的图神经网络存在三个关键限制：(1) 它们依赖于具有静态动力学的同质扩散，限制了对不同图结构的适应性；(2) 它们的深度受到计算开销和递减的可解释性的限制；(3) 对它们的收敛行为的理论理解仍然有限。

Method: 提出了GODNF，一个广义观点动力学神经框架，它将多个观点动力学模型统一到一个有原则的、可训练的扩散机制中。

Result: GODNF能够模拟不同的收敛配置。在节点分类和影响估计任务的广泛经验评估证实了GODNF优于最先进的GNN。

Conclusion: GODNF在节点分类和影响估计任务上优于现有GNN。

Abstract: There has been a growing interest in developing diffusion-based Graph Neural
Networks (GNNs), building on the connections between message passing mechanisms
in GNNs and physical diffusion processes. However, existing methods suffer from
three critical limitations: (1) they rely on homogeneous diffusion with static
dynamics, limiting adaptability to diverse graph structures; (2) their depth is
constrained by computational overhead and diminishing interpretability; and (3)
theoretical understanding of their convergence behavior remains limited. To
address these challenges, we propose GODNF, a Generalized Opinion Dynamics
Neural Framework, which unifies multiple opinion dynamics models into a
principled, trainable diffusion mechanism. Our framework captures heterogeneous
diffusion patterns and temporal dynamics via node-specific behavior modeling
and dynamic neighborhood influence, while ensuring efficient and interpretable
message propagation even at deep layers. We provide a rigorous theoretical
analysis demonstrating GODNF's ability to model diverse convergence
configurations. Extensive empirical evaluations of node classification and
influence estimation tasks confirm GODNF's superiority over state-of-the-art
GNNs.

</details>


### [160] [Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing](https://arxiv.org/abs/2508.11258)
*Ruicheng Xian,Yuxuan Wan,Han Zhao*

Main category: cs.LG

TL;DR: 该论文提出了一种新的框架，通过提示从闭源LLM中获得公平分类器，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的在基于LLM的分类器上实施群体公平性的方法不再适用于上下文学习环境下的闭源LLM。

Method: 该方法将LLM视为特征提取器，并使用策略性设计的提示从其概率预测中提取特征，然后应用公平算法来训练轻量级的公平分类器。

Result: 实验结果表明，该框架在准确性和公平性之间取得了很好的平衡，并且具有数据效率，优于在LLM嵌入上训练的公平分类器。

Conclusion: 该论文提出了一种通过提示从闭源LLM中获得公平分类器的框架，并在五个数据集上进行了实验，证明了该框架的有效性。

Abstract: Instruction fine-tuned large language models (LLMs) enable a simple zero-shot
or few-shot prompting paradigm, also known as in-context learning, for building
prediction models. This convenience, combined with continued advances in LLM
capability, has the potential to drive their adoption across a broad range of
domains, including high-stakes applications where group fairness -- preventing
disparate impacts across demographic groups -- is essential. The majority of
existing approaches to enforcing group fairness on LLM-based classifiers rely
on traditional fair algorithms applied via model fine-tuning or head-tuning on
final-layer embeddings, but they are no longer applicable to closed-weight LLMs
under the in-context learning setting, which include some of the most capable
commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we
propose a framework for deriving fair classifiers from closed-weight LLMs via
prompting: the LLM is treated as a feature extractor, and features are elicited
from its probabilistic predictions (e.g., token log probabilities) using
prompts strategically designed for the specified fairness criterion to obtain
sufficient statistics for fair classification; a fair algorithm is then applied
to these features to train a lightweight fair classifier in a post-hoc manner.
Experiments on five datasets, including three tabular ones, demonstrate strong
accuracy-fairness tradeoffs for the classifiers derived by our framework from
both open-weight and closed-weight LLMs; in particular, our framework is
data-efficient and outperforms fair classifiers trained on LLM embeddings
(i.e., head-tuning) or from scratch on raw tabular features.

</details>


### [161] [Boosting the Robustness-Accuracy Trade-off of SNNs by Robust Temporal Self-Ensemble](https://arxiv.org/abs/2508.11279)
*Jihang Wang,Dongcheng Zhao,Ruolin Chen,Qian Zhang,Yi Zeng*

Main category: cs.LG

TL;DR: 本文研究了SNN的对抗鲁棒性，提出了RTE训练框架，通过提高子网络的鲁棒性和减少时间可传递性来提高SNN的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNN）为节能和受大脑启发的计算提供了一个有希望的方向，但它们对对抗性扰动的脆弱性仍然知之甚少。

Method: 提出Robust Temporal self-Ensemble (RTE)，一种训练框架，可以提高每个子网络的鲁棒性，同时减少对抗性扰动的时间可传递性。RTE将这两个目标整合到一个统一的损失中，并采用随机抽样策略进行有效优化。

Result: 大量跨多个基准的实验表明，RTE在鲁棒性-准确性权衡方面始终优于现有的训练方法。

Conclusion: RTE重塑了SNN的内部鲁棒性，产生了更有弹性和时间上多样化的决策边界。这项研究强调了时间结构在对抗性学习中的重要性，并为构建鲁棒的脉冲模型提供了原则性基础。

Abstract: Spiking Neural Networks (SNNs) offer a promising direction for
energy-efficient and brain-inspired computing, yet their vulnerability to
adversarial perturbations remains poorly understood. In this work, we revisit
the adversarial robustness of SNNs through the lens of temporal ensembling,
treating the network as a collection of evolving sub-networks across discrete
timesteps. This formulation uncovers two critical but underexplored
challenges-the fragility of individual temporal sub-networks and the tendency
for adversarial vulnerabilities to transfer across time. To overcome these
limitations, we propose Robust Temporal self-Ensemble (RTE), a training
framework that improves the robustness of each sub-network while reducing the
temporal transferability of adversarial perturbations. RTE integrates both
objectives into a unified loss and employs a stochastic sampling strategy for
efficient optimization. Extensive experiments across multiple benchmarks
demonstrate that RTE consistently outperforms existing training methods in
robust-accuracy trade-off. Additional analyses reveal that RTE reshapes the
internal robustness landscape of SNNs, leading to more resilient and temporally
diversified decision boundaries. Our study highlights the importance of
temporal structure in adversarial learning and offers a principled foundation
for building robust spiking models.

</details>


### [162] [Generalize across Homophily and Heterophily: Hybrid Spectral Graph Pre-Training and Prompt Tuning](https://arxiv.org/abs/2508.11328)
*Haitong Luo,Suhang Wang,Weiyao Zhang,Ruiqi Meng,Xuying Meng,Yujun Zhang*

Main category: cs.LG

TL;DR: 图上的预训练和提示调整可以实现有效的知识转移，但是当预训练和下游任务的光谱分布存在差异时，效果会受到影响。为了解决这个问题，我们提出了 HS-GPPT 模型，该模型通过混合光谱滤波器和对比学习来获取光谱知识，并通过提示图来实现光谱对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于基于同质性的低频知识，无法处理具有不同同质性的真实世界图中的多样化频谱分布。我们的理论分析揭示了一个光谱特异性原则：最佳知识转移需要预训练光谱滤波器与下游图的内在频谱之间对齐。在有限的监督下，预训练和下游任务之间的大光谱差距阻碍了有效的适应。

Method: 利用混合光谱滤波器骨干和局部-全局对比学习来获取丰富的光谱知识。然后，我们设计提示图以将频谱分布与预文本对齐，从而促进跨同质性和异质性的频谱知识转移。

Result: 大量的实验验证了在直推式和归纳式学习环境下的有效性。

Conclusion: 我们提出了 HS-GPPT 模型，该模型是一个新颖的框架，可确保在预训练和提示调整期间的光谱对齐。大量的实验验证了在直推式和归纳式学习环境下的有效性。

Abstract: Graph ``pre-training and prompt-tuning'' aligns downstream tasks with
pre-trained objectives to enable efficient knowledge transfer under limited
supervision. However, existing methods rely on homophily-based low-frequency
knowledge, failing to handle diverse spectral distributions in real-world
graphs with varying homophily. Our theoretical analysis reveals a spectral
specificity principle: optimal knowledge transfer requires alignment between
pre-trained spectral filters and the intrinsic spectrum of downstream graphs.
Under limited supervision, large spectral gaps between pre-training and
downstream tasks impede effective adaptation. To bridge this gap, we propose
the HS-GPPT model, a novel framework that ensures spectral alignment throughout
both pre-training and prompt-tuning. We utilize a hybrid spectral filter
backbone and local-global contrastive learning to acquire abundant spectral
knowledge. Then we design prompt graphs to align the spectral distribution with
pretexts, facilitating spectral knowledge transfer across homophily and
heterophily. Extensive experiments validate the effectiveness under both
transductive and inductive learning settings. Our code is available at
https://anonymous.4open.science/r/HS-GPPT-62D2/.

</details>


### [163] [RegimeNAS: Regime-Aware Differentiable Architecture Search With Theoretical Guarantees for Financial Trading](https://arxiv.org/abs/2508.11338)
*Prathamesh Devadiga,Yashmitha Shailesh*

Main category: cs.LG

TL;DR: RegimeNAS, a market regime-aware neural architecture search framework, outperforms state-of-the-art benchmarks in cryptocurrency trading with significant error reduction and faster convergence.


<details>
  <summary>Details</summary>
Motivation: Addressing the limitations of static deep learning models in highly dynamic financial environments

Method: RegimeNAS, a novel differentiable architecture search framework specifically designed to enhance cryptocurrency trading performance by explicitly integrating market regime awareness. Addressing the limitations of static deep learning models in highly dynamic financial environments, RegimeNAS features three core innovations: (1) a theoretically grounded Bayesian search space optimizing architectures with provable convergence properties; (2) specialized, dynamically activated neural modules (Volatility, Trend, and Range blocks) tailored for distinct market conditions; and (3) a multi-objective loss function incorporating market-specific penalties (e.g., volatility matching, transition smoothness) alongside mathematically enforced Lipschitz stability constraints.

Result: RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving an 80.3% Mean Absolute Error reduction compared to the best traditional recurrent baseline and converging substantially faster (9 vs. 50+ epochs).

Conclusion: This work underscores the imperative of embedding domain-specific knowledge, such as market regimes, directly within the NAS process to develop robust and adaptive models for challenging financial applications.

Abstract: We introduce RegimeNAS, a novel differentiable architecture search framework
specifically designed to enhance cryptocurrency trading performance by
explicitly integrating market regime awareness. Addressing the limitations of
static deep learning models in highly dynamic financial environments, RegimeNAS
features three core innovations: (1) a theoretically grounded Bayesian search
space optimizing architectures with provable convergence properties; (2)
specialized, dynamically activated neural modules (Volatility, Trend, and Range
blocks) tailored for distinct market conditions; and (3) a multi-objective loss
function incorporating market-specific penalties (e.g., volatility matching,
transition smoothness) alongside mathematically enforced Lipschitz stability
constraints. Regime identification leverages multi-head attention across
multiple timeframes for improved accuracy and uncertainty estimation. Rigorous
empirical evaluation on extensive real-world cryptocurrency data demonstrates
that RegimeNAS significantly outperforms state-of-the-art benchmarks, achieving
an 80.3% Mean Absolute Error reduction compared to the best traditional
recurrent baseline and converging substantially faster (9 vs. 50+ epochs).
Ablation studies and regime-specific analysis confirm the critical contribution
of each component, particularly the regime-aware adaptation mechanism. This
work underscores the imperative of embedding domain-specific knowledge, such as
market regimes, directly within the NAS process to develop robust and adaptive
models for challenging financial applications.

</details>


### [164] [Conformal Prediction Meets Long-tail Classification](https://arxiv.org/abs/2508.11345)
*Shuqi Liu,Jianguo Huang,Luke Ong*

Main category: cs.LG

TL;DR: This paper proposes TACP and sTACP to improve coverage balance in conformal prediction for long-tail label distributions.


<details>
  <summary>Details</summary>
Motivation: Existing CP methods exhibit imbalanced coverage across classes under long-tail label distributions, leading to under coverage of tail classes.

Method: The paper proposes Tail-Aware Conformal Prediction (TACP) and soft TACP (sTACP), which incorporates a reweighting mechanism.

Result: Theoretical analysis shows TACP achieves a smaller head-tail coverage gap than standard methods. Experiments on multiple long-tail benchmark datasets demonstrate the effectiveness of TACP and sTACP.

Conclusion: The paper introduces TACP and sTACP to address the imbalanced coverage issue in CP methods under long-tail label distributions. Experiments on benchmark datasets demonstrate the effectiveness of these methods.

Abstract: Conformal Prediction (CP) is a popular method for uncertainty quantification
that converts a pretrained model's point prediction into a prediction set, with
the set size reflecting the model's confidence. Although existing CP methods
are guaranteed to achieve marginal coverage, they often exhibit imbalanced
coverage across classes under long-tail label distributions, tending to over
cover the head classes at the expense of under covering the remaining tail
classes. This under coverage is particularly concerning, as it undermines the
reliability of the prediction sets for minority classes, even with coverage
ensured on average. In this paper, we propose the Tail-Aware Conformal
Prediction (TACP) method to mitigate the under coverage of the tail classes by
utilizing the long-tail structure and narrowing the head-tail coverage gap.
Theoretical analysis shows that it consistently achieves a smaller head-tail
coverage gap than standard methods. To further improve coverage balance across
all classes, we introduce an extension of TACP: soft TACP (sTACP) via a
reweighting mechanism. The proposed framework can be combined with various
non-conformity scores, and experiments on multiple long-tail benchmark datasets
demonstrate the effectiveness of our methods.

</details>


### [165] [NeMo: A Neuron-Level Modularizing-While-Training Approach for Decomposing DNN Models](https://arxiv.org/abs/2508.11348)
*Xiaohan Bi,Binhang Qi,Hailong Sun,Xiang Gao,Yue Yu,Xiaojun Liang*

Main category: cs.LG

TL;DR: NeMo是一种可扩展且通用的模块化训练方法，通过在神经元级别操作和使用对比学习，在各种DNN和大型Transformer模型上优于现有方法，提高了模块分类精度并减小了模块尺寸。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）模型日益融入现代软件系统，其高昂的构建成本已成为一项重大挑战。模型重用已被广泛应用于降低训练成本，但盲目地重用整个模型可能会导致显著的推理开销。现有的MwT方法专注于卷积核级别的小规模CNN模型，难以处理各种DNN和大规模模型，特别是基于Transformer的模型。

Method: 提出了一种可扩展且通用的MwT方法NeMo，它在神经元级别上运行，并设计了一种基于对比学习的模块化训练方法，具有有效的复合损失函数。

Result: 在两个基于Transformer的模型和四个CNN模型上进行的综合实验表明，NeMo优于最先进的MwT方法。

Conclusion: NeMo在模块分类精度上平均提升1.72%，模块尺寸平均减少58.10%，对CNN和大型Transformer模型均有效。案例研究表明NeMo在实际场景中具有潜在优势，为可扩展和通用的DNN模块化提供了一种有前景的方法。

Abstract: With the growing incorporation of deep neural network (DNN) models into
modern software systems, the prohibitive construction costs have become a
significant challenge. Model reuse has been widely applied to reduce training
costs, but indiscriminately reusing entire models may incur significant
inference overhead. Consequently, DNN modularization has gained attention,
enabling module reuse by decomposing DNN models. The emerging
modularizing-while-training (MwT) paradigm, which incorporates modularization
into training, outperforms modularizing-after-training approaches. However,
existing MwT methods focus on small-scale CNN models at the convolutional
kernel level and struggle with diverse DNNs and large-scale models,
particularly Transformer-based models. To address these limitations, we propose
NeMo, a scalable and generalizable MwT approach. NeMo operates at the neuron
level fundamental component common to all DNNs-ensuring applicability to
Transformers and various architectures. We design a contrastive learning-based
modular training method with an effective composite loss function, enabling
scalability to large-scale models. Comprehensive experiments on two
Transformer-based models and four CNN models across two classification datasets
demonstrate NeMo's superiority over state-of-the-art MwT methods. Results show
average gains of 1.72% in module classification accuracy and 58.10% reduction
in module size, demonstrating efficacy across both CNN and large-scale
Transformer-based models. A case study on open-source projects shows NeMo's
potential benefits in practical scenarios, offering a promising approach for
scalable and generalizable DNN modularization.

</details>


### [166] [A Global Dataset of Location Data Integrity-Assessed Reforestation Efforts](https://arxiv.org/abs/2508.11349)
*Angela John,Selvyn Allotey,Till Koebe,Alexandra Tyukavina,Ingmar Weber*

Main category: cs.LG

TL;DR: This study introduces a dataset for global afforestation and reforestation efforts, revealing issues with data reliability and location accuracy in many projects.


<details>
  <summary>Details</summary>
Motivation: Afforestation and reforestation are popular strategies for mitigating climate change, but the effectiveness of these efforts is often self-reported, leading to concerns about data reliability and project integrity.

Method: This study presents a dataset on global afforestation and reforestation efforts compiled from primary (meta-)information and augmented with time-series satellite imagery and other secondary data. The dataset introduces a standardized assessment of the provided site-level location information, summarized in the Location Data Integrity Score (LDIS).

Result: The dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years. The study finds that a significant portion of georeferenced planting sites fail on LDIS indicators, and many projects lack machine-readable georeferenced data.

Conclusion: Approximately 79% of the georeferenced planting sites monitored fail on at least 1 out of 10 LDIS indicators, while 15% of the monitored projects lack machine-readable georeferenced data.

Abstract: Afforestation and reforestation are popular strategies for mitigating climate
change by enhancing carbon sequestration. However, the effectiveness of these
efforts is often self-reported by project developers, or certified through
processes with limited external validation. This leads to concerns about data
reliability and project integrity. In response to increasing scrutiny of
voluntary carbon markets, this study presents a dataset on global afforestation
and reforestation efforts compiled from primary (meta-)information and
augmented with time-series satellite imagery and other secondary data. Our
dataset covers 1,289,068 planting sites from 45,628 projects spanning 33 years.
Since any remote sensing-based validation effort relies on the integrity of a
planting site's geographic boundary, this dataset introduces a standardized
assessment of the provided site-level location information, which we summarize
in one easy-to-communicate key indicator: LDIS -- the Location Data Integrity
Score. We find that approximately 79\% of the georeferenced planting sites
monitored fail on at least 1 out of 10 LDIS indicators, while 15\% of the
monitored projects lack machine-readable georeferenced data in the first place.
In addition to enhancing accountability in the voluntary carbon market, the
presented dataset also holds value as training data for e.g. computer
vision-related tasks with millions of linked Sentinel-2 and Planetscope
satellite images.

</details>


### [167] [Harmonized Gradient Descent for Class Imbalanced Data Stream Online Learning](https://arxiv.org/abs/2508.11353)
*Han Zhou,Hongpeng Yin,Xuanhong Deng,Yuyu Huang,Hao Ren*

Main category: cs.LG

TL;DR: 提出了一种新的梯度下降算法HGD，用于解决不平衡数据流问题，该算法通过平衡梯度范数来实现更好的性能，且实现简单，无需额外参数或先验知识。


<details>
  <summary>Details</summary>
Motivation: 许多现实世界的数据是随时间顺序收集的，并且经常表现出倾斜的类别分布，从而导致不平衡的数据流。现有的方法已经探索了几种策略，例如重采样和重加权，用于不平衡数据流学习，但我们的工作通过训练修改来解决不平衡问题，特别关注梯度下降技术，从而与众不同。

Method: 提出了 harmonized gradient descent (HGD) 算法，旨在平衡不同类别的梯度范数。

Result: 理论分析表明，HGD实现了令人满意的亚线性后悔界。大量的实验评估证明了HGD在学习不平衡数据流方面的效率和有效性。

Conclusion: HGD在学习不平衡数据流方面表现出高效性和有效性。

Abstract: Many real-world data are sequentially collected over time and often exhibit
skewed class distributions, resulting in imbalanced data streams. While
existing approaches have explored several strategies, such as resampling and
reweighting, for imbalanced data stream learning, our work distinguishes itself
by addressing the imbalance problem through training modification, particularly
focusing on gradient descent techniques. We introduce the harmonized gradient
descent (HGD) algorithm, which aims to equalize the norms of gradients across
different classes. By ensuring the gradient norm balance, HGD mitigates
under-fitting for minor classes and achieves balanced online learning. Notably,
HGD operates in a streamlined implementation process, requiring no data-buffer,
extra parameters, or prior knowledge, making it applicable to any learning
models utilizing gradient descent for optimization. Theoretical analysis, based
on a few common and mild assumptions, shows that HGD achieves a satisfied
sub-linear regret bound. The proposed algorithm are compared with the commonly
used online imbalance learning methods under several imbalanced data stream
scenarios. Extensive experimental evaluations demonstrate the efficiency and
effectiveness of HGD in learning imbalanced data streams.

</details>


### [168] [ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism](https://arxiv.org/abs/2508.11356)
*Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu,TingTing Gao*

Main category: cs.LG

TL;DR: Introduces an entropy-based mechanism to improve test-time reinforcement learning, achieving better performance and efficiency on the AIME 2024 benchmark with Llama3.1-8B.


<details>
  <summary>Details</summary>
Motivation: Large Language Models rely on annotated data and exhibit limited adaptability in unsupervised scenarios. Test-time reinforcement learning (TTRL) faces challenges such as high inference costs and early-stage estimation bias.

Method: Introduce an entropy-based mechanism with two strategies: Entropy-fork Tree Majority Rollout (ETMR) and Entropy-based Advantage Reshaping (EAR).

Result: Llama3.1-8B achieves a 68 percent relative improvement in Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of the rollout tokens budget.

Conclusion: The proposed entropy-based mechanism enhances the exploration-exploitation balance in test-time reinforcement learning, enabling Llama3.1-8B to achieve a 68 percent relative improvement in Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of the rollout tokens budget.

Abstract: Recent advancements in Large Language Models have yielded significant
improvements in complex reasoning tasks such as mathematics and programming.
However, these models remain heavily dependent on annotated data and exhibit
limited adaptability in unsupervised scenarios. To address these limitations,
test-time reinforcement learning (TTRL) has been proposed, which enables
self-optimization by leveraging model-generated pseudo-labels. Despite its
promise, TTRL faces several key challenges, including high inference costs due
to parallel rollouts and early-stage estimation bias that fosters
overconfidence, reducing output diversity and causing performance plateaus. To
address these challenges, we introduce an entropy-based mechanism to enhance
the exploration-exploitation balance in test-time reinforcement learning
through two strategies: Entropy-fork Tree Majority Rollout (ETMR) and
Entropy-based Advantage Reshaping (EAR). Compared with the baseline, our
approach enables Llama3.1-8B to achieve a 68 percent relative improvement in
Pass at 1 metric on the AIME 2024 benchmark, while consuming only 60 percent of
the rollout tokens budget. This highlights our method's ability to effectively
optimize the trade-off between inference efficiency, diversity, and estimation
robustness, thereby advancing unsupervised reinforcement learning for
open-domain reasoning tasks.

</details>


### [169] [PTSM: Physiology-aware and Task-invariant Spatio-temporal Modeling for Cross-Subject EEG Decoding](https://arxiv.org/abs/2508.11357)
*Changhong Jing,Yan Liu,Shuqiang Wang,Bruce X. B. Yu,Gong Chen,Zhejing Hu,Zhi Zhang,Yanyan Shen*

Main category: cs.LG

TL;DR: PTSM是一种用于可解释和鲁棒的脑电图解码的新框架，它采用双分支掩蔽机制，可以独立学习个性化和共享的时空模式。


<details>
  <summary>Details</summary>
Motivation: 由于受试者间的巨大差异以及受试者不变表征的稀缺性，跨受试者脑电图 (EEG) 解码仍然是脑机接口 (BCI) 研究中的一项根本性挑战。

Method: PTSM采用双分支掩蔽机制，独立学习个性化和共享的时空模式，使模型能够保留个体特定的神经特征，同时提取任务相关的、群体共享的特征。掩码在时间和空间维度上进行分解，允许以低计算开销对动态脑电模式进行细粒度调制。为了进一步解决表征纠缠问题，PTSM强制执行信息论约束，将潜在嵌入分解为正交的任务相关和被试相关子空间。该模型通过整合分类、对比和解缠目标的多目标损失进行端到端训练。

Result: PTSM在跨被试运动想象数据集中实现了强大的零样本泛化，优于最先进的基线方法，无需特定于被试的校准。

Conclusion: PTSM在跨被试运动想象数据集中实现了强大的零样本泛化，优于最先进的基线方法，无需特定于被试的校准。结果突出了分离的神经表征在非平稳神经生理环境中实现个性化和可转移解码的有效性。

Abstract: Cross-subject electroencephalography (EEG) decoding remains a fundamental
challenge in brain-computer interface (BCI) research due to substantial
inter-subject variability and the scarcity of subject-invariant
representations. This paper proposed PTSM (Physiology-aware and Task-invariant
Spatio-temporal Modeling), a novel framework for interpretable and robust EEG
decoding across unseen subjects. PTSM employs a dual-branch masking mechanism
that independently learns personalized and shared spatio-temporal patterns,
enabling the model to preserve individual-specific neural characteristics while
extracting task-relevant, population-shared features. The masks are factorized
across temporal and spatial dimensions, allowing fine-grained modulation of
dynamic EEG patterns with low computational overhead. To further address
representational entanglement, PTSM enforces information-theoretic constraints
that decompose latent embeddings into orthogonal task-related and
subject-related subspaces. The model is trained end-to-end via a
multi-objective loss integrating classification, contrastive, and
disentanglement objectives. Extensive experiments on cross-subject motor
imagery datasets demonstrate that PTSM achieves strong zero-shot
generalization, outperforming state-of-the-art baselines without
subject-specific calibration. Results highlight the efficacy of disentangled
neural representations for achieving both personalized and transferable
decoding in non-stationary neurophysiological settings.

</details>


### [170] [Fusing Rewards and Preferences in Reinforcement Learning](https://arxiv.org/abs/2508.11363)
*Sadegh Khorasani,Saber Salehkaleybar,Negar Kiyavash,Matthias Grossglauser*

Main category: cs.LG

TL;DR: DFA是一种新的强化学习算法，它结合了奖励和偏好，并在多个任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 将个体奖励和成对偏好融合到强化学习算法中，利用偏好数据提升性能。

Method: 提出了一种名为Dual-Feedback Actor (DFA)的强化学习算法，该算法将个体奖励和成对偏好融合到一个更新规则中。DFA直接使用策略的对数概率来建模偏好概率，避免了单独的奖励建模步骤。

Result: DFA在六个控制环境中与SAC相匹配或超过SAC，并在随机GridWorld中优于RLHF基线，接近真实奖励的效果。证明了在Bradley-Terry模型下，最小化DFA的偏好损失可以恢复熵正则化的软Actor-Critic (SAC) 策略。

Conclusion: DFA在模拟控制环境和半合成偏好数据集上表现出色，与SAC或RLHF基线相比，性能相当或更优，且训练过程更稳定。

Abstract: We present Dual-Feedback Actor (DFA), a reinforcement learning algorithm that
fuses both individual rewards and pairwise preferences (if available) into a
single update rule. DFA uses the policy's log-probabilities directly to model
the preference probability, avoiding a separate reward-modeling step.
Preferences can be provided by human-annotators (at state-level or
trajectory-level) or be synthesized online from Q-values stored in an
off-policy replay buffer. Under a Bradley-Terry model, we prove that minimizing
DFA's preference loss recovers the entropy-regularized Soft Actor-Critic (SAC)
policy. Our simulation results show that DFA trained on generated preferences
matches or exceeds SAC on six control environments and demonstrates a more
stable training process. With only a semi-synthetic preference dataset under
Bradley-Terry model, our algorithm outperforms reward-modeling reinforcement
learning from human feedback (RLHF) baselines in a stochastic GridWorld and
approaches the performance of an oracle with true rewards.

</details>


### [171] [Minimizing Surrogate Losses for Decision-Focused Learning using Differentiable Optimization](https://arxiv.org/abs/2508.11365)
*Jayanta Mandi,Ali İrfan Mahmutoğulları,Senne Berden,Tias Guns*

Main category: cs.LG

TL;DR: 本文提出通过最小化代理损失来解决决策重点学习 (DFL) 中梯度消失的问题，即使在使用可微优化层时也是如此。实验表明，该方法在减少训练时间的同时，实现了与现有技术相当甚至更好的性能。


<details>
  <summary>Details</summary>
Motivation: 基于梯度的 DFL 需要计算优化问题的解相对于预测参数的导数。然而，对于许多优化问题，例如线性规划 (LP)，遗憾相对于预测参数的梯度几乎处处为零。现有的基于梯度的 LP 的 DFL 方法试图通过以下两种方式之一来规避这个问题：(a) 通过添加二次正则化器将 LP 平滑为可微优化问题，然后直接最小化遗憾；或 (b) 最小化具有信息量（子）梯度的替代损失。我们表明，前一种方法仍然会导致零梯度，因为即使在平滑后，遗憾在参数空间的大片区域内仍然保持不变。

Method: 最小化代理损失

Result: 最小化代理损失允许可微优化层实现与基于代理损失的 DFL 方法相当或更好的遗憾。通过使用 DYS-Net 最小化代理损失，我们能够在达到与最先进技术相当的遗憾的同时，显着减少训练时间。

Conclusion: 最小化代理损失允许可微优化层实现与基于代理损失的 DFL 方法相当或更好的遗憾。通过使用 DYS-Net 最小化代理损失，我们能够在达到与最先进技术相当的遗憾的同时，显着减少训练时间。

Abstract: Decision-focused learning (DFL) trains a machine learning (ML) model to
predict parameters of an optimization problem, to directly minimize decision
regret, i.e., maximize decision quality. Gradient-based DFL requires computing
the derivative of the solution to the optimization problem with respect to the
predicted parameters. However, for many optimization problems, such as linear
programs (LPs), the gradient of the regret with respect to the predicted
parameters is zero almost everywhere. Existing gradient-based DFL approaches
for LPs try to circumvent this issue in one of two ways: (a) smoothing the LP
into a differentiable optimization problem by adding a quadratic regularizer
and then minimizing the regret directly or (b) minimizing surrogate losses that
have informative (sub)gradients. In this paper, we show that the former
approach still results in zero gradients, because even after smoothing the
regret remains constant across large regions of the parameter space. To address
this, we propose minimizing surrogate losses -- even when a differentiable
optimization layer is used and regret can be minimized directly. Our
experiments demonstrate that minimizing surrogate losses allows differentiable
optimization layers to achieve regret comparable to or better than
surrogate-loss based DFL methods. Further, we demonstrate that this also holds
for DYS-Net, a recently proposed differentiable optimization technique for LPs,
that computes approximate solutions and gradients through operations that can
be performed using feedforward neural network layers. Because DYS-Net executes
the forward and the backward pass very efficiently, by minimizing surrogate
losses using DYS-Net, we are able to attain regret on par with the
state-of-the-art while reducing training time by a significant margin.

</details>


### [172] [A Remedy for Over-Squashing in Graph Learning via Forman-Ricci Curvature based Graph-to-Hypergraph Structural Lifting](https://arxiv.org/abs/2508.11390)
*Michael Banf,Dominik Filipiak,Max Schattauer,Liliya Imasheva*

Main category: cs.LG

TL;DR: This paper introduces a Forman-Ricci curvature based structural lifting strategy to address the over-squashing problem in GNNs.


<details>
  <summary>Details</summary>
Motivation: Many real-world systems exhibit complex interactions that are more naturally represented by higher-order topological domains. Existing Graph Neural Networks are not sufficient for these systems.

Method: The paper proposes a method using Forman-Ricci curvature, which defines an edge-based network characteristic based on Riemannian geometry, to lift data representations from basic graph forms to more expressive topologies.

Result: The approach provides a remedy to the problem of information distortion in message passing across long distances and graph bottlenecks.

Conclusion: The paper introduces a structural lifting strategy using Forman-Ricci curvature to address information distortion in message passing across long distances and graph bottlenecks.

Abstract: Graph Neural Networks are highly effective at learning from relational data,
leveraging node and edge features while maintaining the symmetries inherent to
graph structures. However, many real-world systems, such as social or
biological networks, exhibit complex interactions that are more naturally
represented by higher-order topological domains. The emerging field of
Geometric and Topological Deep Learning addresses this challenge by introducing
methods that utilize and benefit from higher-order structures. Central to TDL
is the concept of lifting, which transforms data representations from basic
graph forms to more expressive topologies before the application of GNN models
for learning. In this work, we propose a structural lifting strategy using
Forman-Ricci curvature, which defines an edge-based network characteristic
based on Riemannian geometry. Curvature reveals local and global properties of
a graph, such as a network's backbones, i.e. coarse, structure-preserving graph
geometries that form connections between major communities - most suitably
represented as hyperedges to model information flows between clusters across
large distances in the network. To this end, our approach provides a remedy to
the problem of information distortion in message passing across long distances
and graph bottlenecks - a phenomenon known in graph learning as over-squashing.

</details>


### [173] [On-Policy RL Meets Off-Policy Experts: Harmonizing Supervised Fine-Tuning and Reinforcement Learning via Dynamic Weighting](https://arxiv.org/abs/2508.11408)
*Wenhao Zhang,Yuexiang Xie,Yuchang Sun,Yanxi Chen,Guoyin Wang,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.LG

TL;DR: CHORD框架通过动态加权协调在线和离线强化学习，避免了过度拟合，并在基准测试中表现出显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的整合SFT和RL的方法通常面临破坏已建立的模型模式和诱导对专家数据过度拟合的风险。

Method: 提出了CHORD框架，用于通过动态加权对在线和离线强化学习进行可控协调，该框架将SFT重新定义为在线RL过程中动态加权的辅助目标。基于对离线专家数据在整体和细粒度层面的影响的分析，CHORD结合了双重控制机制。

Result: 在广泛使用的基准上进行了大量实验，提供了经验证据，表明CHORD实现了稳定高效的学习过程，并且在基线上实现了显著改进。

Conclusion: CHORD通过有效协调离线专家数据与在线探索，在基线上实现了显著改进。

Abstract: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) are two
prominent post-training paradigms for refining the capabilities and aligning
the behavior of Large Language Models (LLMs). Existing approaches that
integrate SFT and RL often face the risk of disrupting established model
patterns and inducing overfitting to expert data. To address this, we present a
novel investigation into the unified view of SFT and RL through an off-policy
versus on-policy lens. We propose CHORD, a framework for the Controllable
Harmonization of On- and Off-Policy Reinforcement Learning via Dynamic
Weighting, which reframes SFT not as a separate stage but as a dynamically
weighted auxiliary objective within the on-policy RL process. Based on an
analysis of off-policy expert data's influence at both holistic and granular
levels, we incorporate a dual-control mechanism in CHORD. Specifically, the
framework first employs a global coefficient to holistically guide the
transition from off-policy imitation to on-policy exploration, and then applies
a token-wise weighting function that enables granular learning from expert
tokens, which preserves on-policy exploration and mitigates disruption from
off-policy data. We conduct extensive experiments on widely used benchmarks,
providing empirical evidence that CHORD achieves a stable and efficient
learning process. By effectively harmonizing off-policy expert data with
on-policy exploration, CHORD demonstrates significant improvements over
baselines. We release the implementation at
https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_chord to
inspire further research.

</details>


### [174] [Generative Co-Design of Antibody Sequences and Structures via Black-Box Guidance in a Shared Latent Space](https://arxiv.org/abs/2508.11424)
*Yinghua Yao,Yuangang Pan,Xixian Chen*

Main category: cs.LG

TL;DR: LEAD提出了一种序列-结构共同设计框架，可在共享潜在空间中优化序列和结构，显著提高了优化性能并减少了查询消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法在原始数据空间中运行，导致由于低效的搜索过程而导致过度昂贵的评估。

Method: sequence-structure co-design framework that optimizes both sequence and structure within their shared latent space

Result: LEAD reduces query consumption by a half while surpassing baseline methods in property optimization.

Conclusion: LEAD在单目标和多目标属性优化方面均实现了卓越的优化性能。值得注意的是，LEAD在属性优化中超越了基线方法，同时减少了一半的查询消耗。

Abstract: Advancements in deep generative models have enabled the joint modeling of
antibody sequence and structure, given the antigen-antibody complex as context.
However, existing approaches for optimizing complementarity-determining regions
(CDRs) to improve developability properties operate in the raw data space,
leading to excessively costly evaluations due to the inefficient search
process. To address this, we propose LatEnt blAck-box Design (LEAD), a
sequence-structure co-design framework that optimizes both sequence and
structure within their shared latent space. Optimizing shared latent codes can
not only break through the limitations of existing methods, but also ensure
synchronization of different modality designs. Particularly, we design a
black-box guidance strategy to accommodate real-world scenarios where many
property evaluators are non-differentiable. Experimental results demonstrate
that our LEAD achieves superior optimization performance for both single and
multi-property objectives. Notably, LEAD reduces query consumption by a half
while surpassing baseline methods in property optimization. The code is
available at https://github.com/EvaFlower/LatEnt-blAck-box-Design.

</details>


### [175] [Robust Convolution Neural ODEs via Contractivity-promoting regularization](https://arxiv.org/abs/2508.11432)
*Muhammad Zakwan,Liang Xu,Giancarlo Ferrari-Trecate*

Main category: cs.LG

TL;DR: improve the robustness of Convolutional Neural Ordinary Differential Equations (NODEs) by using contraction theory


<details>
  <summary>Details</summary>
Motivation: Neural networks can be fragile to input noise and adversarial attacks.

Method: propose to use contraction theory to improve their robustness

Result: The performance of the proposed regularizers is illustrated through benchmark image classification tasks on MNIST and FashionMNIST datasets, where images are corrupted by different kinds of noise and attacks.

Conclusion: Contractive Convolutional NODEs can enjoy increased robustness as slight perturbations of the features do not cause a significant change in the output. Contractivity can be induced during training by using a regularization term involving the Jacobian of the system dynamics. To reduce the computational burden, we show that it can also be promoted using carefully selected weight regularization terms for a class of NODEs with slope-restricted activation functions.

Abstract: Neural networks can be fragile to input noise and adversarial attacks.
  In this work, we consider Convolutional Neural Ordinary Differential
Equations (NODEs), a family of continuous-depth neural networks represented by
dynamical systems, and propose to use contraction theory to improve their
robustness.
  For a contractive dynamical system two trajectories starting from different
initial conditions converge to each other exponentially fast.
  Contractive Convolutional NODEs can enjoy increased robustness as slight
perturbations of the features do not cause a significant change in the output.
  Contractivity can be induced during training by using a regularization term
involving the Jacobian of the system dynamics.
  To reduce the computational burden, we show that it can also be promoted
using carefully selected weight regularization terms for a class of NODEs with
slope-restricted activation functions.
  The performance of the proposed regularizers is illustrated through benchmark
image classification tasks on MNIST and FashionMNIST datasets, where images are
corrupted by different kinds of noise and attacks.

</details>


### [176] [Multi-Sensory Cognitive Computing for Learning Population-level Brain Connectivity](https://arxiv.org/abs/2508.11436)
*Mayssa Soussia,Mohamed Ali Mahjoub,Islem Rekik*

Main category: cs.LG

TL;DR: mCOCO is a novel framework that uses Reservoir Computing to generate connectional brain templates (CBTs) from BOLD signals and multi-sensory inputs, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for CBT learning have poor interpretability, high computational cost, and overlook the cognitive capacity of the generated CBT.

Method: The mCOCO framework leverages Reservoir Computing (RC) to learn population-level functional CBT from BOLD signals and incorporates multi-sensory inputs through a cognitive reservoir.

Result: The mCOCO-based template significantly outperforms GNN-based CBT in terms of centeredness, discriminativeness, topological soundness, and multi-sensory memory retention.

Conclusion: The mCOCO framework outperforms GNN-based CBT in centeredness, discriminativeness, topological soundness, and multi-sensory memory retention.

Abstract: The generation of connectional brain templates (CBTs) has recently garnered
significant attention for its potential to identify unique connectivity
patterns shared across individuals. However, existing methods for CBT learning
such as conventional machine learning and graph neural networks (GNNs) are
hindered by several limitations. These include: (i) poor interpretability due
to their black-box nature, (ii) high computational cost, and (iii) an exclusive
focus on structure and topology, overlooking the cognitive capacity of the
generated CBT. To address these challenges, we introduce mCOCO (multi-sensory
COgnitive COmputing), a novel framework that leverages Reservoir Computing (RC)
to learn population-level functional CBT from BOLD
(Blood-Oxygen-level-Dependent) signals. RC's dynamic system properties allow
for tracking state changes over time, enhancing interpretability and enabling
the modeling of brain-like dynamics, as demonstrated in prior literature. By
integrating multi-sensory inputs (e.g., text, audio, and visual data), mCOCO
captures not only structure and topology but also how brain regions process
information and adapt to cognitive tasks such as sensory processing, all in a
computationally efficient manner. Our mCOCO framework consists of two phases:
(1) mapping BOLD signals into the reservoir to derive individual functional
connectomes, which are then aggregated into a group-level CBT - an approach, to
the best of our knowledge, not previously explored in functional connectivity
studies - and (2) incorporating multi-sensory inputs through a cognitive
reservoir, endowing the CBT with cognitive traits. Extensive evaluations show
that our mCOCO-based template significantly outperforms GNN-based CBT in terms
of centeredness, discriminativeness, topological soundness, and multi-sensory
memory retention. Our source code is available at
https://github.com/basiralab/mCOCO.

</details>


### [177] [Informative Post-Hoc Explanations Only Exist for Simple Functions](https://arxiv.org/abs/2508.11441)
*Eric Günther,Balázs Szabados,Robi Bhattacharjee,Sebastian Bordt,Ulrike von Luxburg*

Main category: cs.LG

TL;DR: We introduce a learning-theory-based framework for what it means for an explanation to provide information about a decision function and show that many popular explanation algorithms are not informative when applied to complex decision functions.


<details>
  <summary>Details</summary>
Motivation: theoretical guarantees about such algorithms only exist for simple decision functions, and it is unclear whether and under which assumptions similar results might exist for complex models.

Method: a general, learning-theory-based framework

Result: gradient explanations and counterfactual explanations are non-informative with respect to the space of differentiable functions, and SHAP and anchor explanations are not informative with respect to the space of decision trees.

Conclusion: many popular explanation algorithms are not informative when applied to complex decision functions, providing a rigorous mathematical rejection of the idea that it should be possible to explain any model. Based on these results, we discuss how explanation algorithms can be modified to become informative.

Abstract: Many researchers have suggested that local post-hoc explanation algorithms
can be used to gain insights into the behavior of complex machine learning
models. However, theoretical guarantees about such algorithms only exist for
simple decision functions, and it is unclear whether and under which
assumptions similar results might exist for complex models. In this paper, we
introduce a general, learning-theory-based framework for what it means for an
explanation to provide information about a decision function. We call an
explanation informative if it serves to reduce the complexity of the space of
plausible decision functions. With this approach, we show that many popular
explanation algorithms are not informative when applied to complex decision
functions, providing a rigorous mathematical rejection of the idea that it
should be possible to explain any model. We then derive conditions under which
different explanation algorithms become informative. These are often stronger
than what one might expect. For example, gradient explanations and
counterfactual explanations are non-informative with respect to the space of
differentiable functions, and SHAP and anchor explanations are not informative
with respect to the space of decision trees. Based on these results, we discuss
how explanation algorithms can be modified to become informative. While the
proposed analysis of explanation algorithms is mathematical, we argue that it
holds strong implications for the practical applicability of these algorithms,
particularly for auditing, regulation, and high-risk applications of AI.

</details>


### [178] [Calibrated and uncertain? Evaluating uncertainty estimates in binary classification models](https://arxiv.org/abs/2508.11460)
*Aurora Grefsrud,Nello Blaser,Trygve Buanes*

Main category: cs.LG

TL;DR: 我们研究了六种概率机器学习算法的定性属性，结果表明所有算法都经过良好校准，但没有基于深度学习的算法能够提供始终反映缺乏实验证据的不确定性，以用于分布外数据点。


<details>
  <summary>Details</summary>
Motivation: 严谨的统计方法，包括伴随不确定性的参数估计，是科学发现有效性的基础，尤其是在自然科学中。随着深度学习技术等日益复杂的数据模型，不确定性量化变得异常困难，并且已经提出了许多技术。

Method: 使用近似贝叶斯推理的统一框架，结合对精心创建的合成分类数据集的经验测试。

Result: 所有算法都经过良好校准，但没有基于深度学习的算法能够提供始终反映缺乏实验证据的不确定性，以用于分布外数据点。

Conclusion: 所有算法都经过良好校准，但没有基于深度学习的算法能够提供始终反映缺乏实验证据的不确定性，以用于分布外数据点。

Abstract: Rigorous statistical methods, including parameter estimation with
accompanying uncertainties, underpin the validity of scientific discovery,
especially in the natural sciences. With increasingly complex data models such
as deep learning techniques, uncertainty quantification has become exceedingly
difficult and a plethora of techniques have been proposed. In this case study,
we use the unifying framework of approximate Bayesian inference combined with
empirical tests on carefully created synthetic classification datasets to
investigate qualitative properties of six different probabilistic machine
learning algorithms for class probability and uncertainty estimation: (i) a
neural network ensemble, (ii) neural network ensemble with conflictual loss,
(iii) evidential deep learning, (iv) a single neural network with Monte Carlo
Dropout, (v) Gaussian process classification and (vi) a Dirichlet process
mixture model. We check if the algorithms produce uncertainty estimates which
reflect commonly desired properties, such as being well calibrated and
exhibiting an increase in uncertainty for out-of-distribution data points. Our
results indicate that all algorithms are well calibrated, but none of the deep
learning based algorithms provide uncertainties that consistently reflect lack
of experimental evidence for out-of-distribution data points. We hope our study
may serve as a clarifying example for researchers developing new methods of
uncertainty estimation for scientific data-driven modeling.

</details>


### [179] [Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection](https://arxiv.org/abs/2508.11504)
*Andrea Castellani,Zacharias Papadovasilakis,Giorgos Papoutsoglou,Mary Cole,Brian Bautsch,Tobias Rodemann,Ioannis Tsamardinos,Angela Harden*

Main category: cs.LG

TL;DR: Study uses AutoML and explainable AI to identify key risk factors for severe crashes in Ohio, finding environmental factors more influential than expected.


<details>
  <summary>Details</summary>
Motivation: Motor vehicle crashes are a leading cause of injury and death, necessitating data-driven approaches to mitigate crash severity.

Method: The study uses a combination of Automated Machine Learning (AutoML) with the JADBio platform and explainable AI (SHAP) to build predictive models and interpret key risk factors.

Result: A Ridge Logistic Regression model achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test set, identifying 17 key features, with environmental and contextual variables being more influential than traditionally emphasized factors like alcohol or drug impairment.

Conclusion: This study provides a scalable framework for data-informed traffic safety policy, identifying key risk factors for severe crashes using AutoML and explainable AI, which can support Vision Zero initiatives.

Abstract: Motor vehicle crashes remain a leading cause of injury and death worldwide,
necessitating data-driven approaches to understand and mitigate crash severity.
This study introduces a curated dataset of more than 3 million people involved
in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3
million vehicle-level records for predictive analysis. The primary contribution
is a transparent and reproducible methodology that combines Automated Machine
Learning (AutoML) and explainable artificial intelligence (AI) to identify and
interpret key risk factors associated with severe crashes. Using the JADBio
AutoML platform, predictive models were constructed to distinguish between
severe and non-severe crash outcomes. The models underwent rigorous feature
selection across stratified training subsets, and their outputs were
interpreted using SHapley Additive exPlanations (SHAP) to quantify the
contribution of individual features. A final Ridge Logistic Regression model
achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test
set, with 17 features consistently identified as the most influential
predictors. Key features spanned demographic, environmental, vehicle, human,
and operational categories, including location type, posted speed, minimum
occupant age, and pre-crash action. Notably, certain traditionally emphasized
factors, such as alcohol or drug impairment, were less influential in the final
model compared to environmental and contextual variables. Emphasizing
methodological rigor and interpretability over mere predictive performance,
this study offers a scalable framework to support Vision Zero with aligned
interventions and advanced data-informed traffic safety policy.

</details>


### [180] [Towards Faithful Class-level Self-explainability in Graph Neural Networks by Subgraph Dependencies](https://arxiv.org/abs/2508.11513)
*Fanzhen Liu,Xiaoxiao Ma,Jian Yang,Alsharif Abuadbba,Kristen Moore,Surya Nepal,Cecile Paris,Quan Z. Sheng,Jia Wu*

Main category: cs.LG

TL;DR: Introduces GraphOracle, a self-explainable GNN framework for generating and evaluating class-level explanations, outperforming existing methods in fidelity, explainability, and scalability.


<details>
  <summary>Details</summary>
Motivation: Enhancing the interpretability of graph neural networks (GNNs) is crucial to ensure their safe and fair deployment. Existing methods focus solely on instance-level explanations, leaving open the question of whether these prototypes meaningfully generalize across instances of the same class.

Method: a novel self-explainable GNN framework designed to generate and evaluate class-level explanations for GNNs. It jointly learns a GNN classifier and a set of structured, sparse subgraphs that are discriminative for each class. It uses entropy-regularized subgraph selection and lightweight random walk extraction.

Result: GraphOracle achieves superior fidelity, explainability, and scalability across a range of graph classification tasks. It avoids the computational bottlenecks of previous methods by using entropy-regularized subgraph selection and lightweight random walk extraction, enabling faster and more scalable training.

Conclusion: GraphOracle is a practical and principled solution for faithful class-level self-explainability in GNNs.

Abstract: Enhancing the interpretability of graph neural networks (GNNs) is crucial to
ensure their safe and fair deployment. Recent work has introduced
self-explainable GNNs that generate explanations as part of training, improving
both faithfulness and efficiency. Some of these models, such as ProtGNN and
PGIB, learn class-specific prototypes, offering a potential pathway toward
class-level explanations. However, their evaluations focus solely on
instance-level explanations, leaving open the question of whether these
prototypes meaningfully generalize across instances of the same class. In this
paper, we introduce GraphOracle, a novel self-explainable GNN framework
designed to generate and evaluate class-level explanations for GNNs. Our model
jointly learns a GNN classifier and a set of structured, sparse subgraphs that
are discriminative for each class. We propose a novel integrated training that
captures graph$\unicode{x2013}$subgraph$\unicode{x2013}$prediction dependencies
efficiently and faithfully, validated through a masking-based evaluation
strategy. This strategy enables us to retroactively assess whether prior
methods like ProtGNN and PGIB deliver effective class-level explanations. Our
results show that they do not. In contrast, GraphOracle achieves superior
fidelity, explainability, and scalability across a range of graph
classification tasks. We further demonstrate that GraphOracle avoids the
computational bottlenecks of previous methods$\unicode{x2014}$like Monte Carlo
Tree Search$\unicode{x2014}$by using entropy-regularized subgraph selection and
lightweight random walk extraction, enabling faster and more scalable training.
These findings position GraphOracle as a practical and principled solution for
faithful class-level self-explainability in GNNs.

</details>


### [181] [DiCriTest: Testing Scenario Generation for Decision-Making Agents Considering Diversity and Criticality](https://arxiv.org/abs/2508.11514)
*Qitong Chu,Yufeng Yue,Danya Yao,Huaxin Pei*

Main category: cs.LG

TL;DR: 提出了一个双空间引导的测试框架，用于生成更多样化和关键的测试场景，以验证决策智能体的安全性。


<details>
  <summary>Details</summary>
Motivation: 动态环境中决策智能体的日益普及，对安全验证提出了更高的要求。现有的测试场景生成方法难以有效平衡多样性和关键性，容易陷入高维场景空间中的局部最优。

Method: 提出了一个双空间引导的测试框架，该框架协调场景参数空间和智能体行为空间，通过分层表示框架和动态协调的生成模式，优化关键场景的数量和多样性。

Result: 实验结果表明，该框架在关键场景生成方面平均提高了 56.23%，并在参数-行为协同驱动的指标下表现出更大的多样性，优于现有技术水平。

Conclusion: 该框架通过在参数空间和行为空间中的协同优化，显著提高了关键场景的生成效果和多样性，优于现有技术。

Abstract: The growing deployment of decision-making agents in dynamic environments
increases the demand for safety verification. While critical testing scenario
generation has emerged as an appealing verification methodology, effectively
balancing diversity and criticality remains a key challenge for existing
methods, particularly due to local optima entrapment in high-dimensional
scenario spaces. To address this limitation, we propose a dual-space guided
testing framework that coordinates scenario parameter space and agent behavior
space, aiming to generate testing scenarios considering diversity and
criticality. Specifically, in the scenario parameter space, a hierarchical
representation framework combines dimensionality reduction and
multi-dimensional subspace evaluation to efficiently localize diverse and
critical subspaces. This guides dynamic coordination between two generation
modes: local perturbation and global exploration, optimizing critical scenario
quantity and diversity. Complementarily, in the agent behavior space,
agent-environment interaction data are leveraged to quantify behavioral
criticality/diversity and adaptively support generation mode switching, forming
a closed feedback loop that continuously enhances scenario characterization and
exploration within the parameter space. Experiments show our framework improves
critical scenario generation by an average of 56.23\% and demonstrates greater
diversity under novel parameter-behavior co-driven metrics when tested on five
decision-making agents, outperforming state-of-the-art baselines.

</details>


### [182] [Finite-Width Neural Tangent Kernels from Feynman Diagrams](https://arxiv.org/abs/2508.11522)
*Max Guillen,Philipp Misof,Jan E. Gerken*

Main category: cs.LG

TL;DR: 引入费曼图来计算有限宽度校正，从而简化代数操作，实现层状递归关系计算，并扩展了深度网络的稳定性结果。


<details>
  <summary>Details</summary>
Motivation: 神经网络切线核 (NTK) 是一种强大的工具，用于分析深度非线性神经网络。在无限宽度限制下，可以轻松计算大多数常见架构的 NTK，从而可以完全分析控制训练动态。然而，在无限宽度下，训练的重要属性（例如 NTK 演化或特征学习）缺失。尽管如此，可以通过计算无限宽度下高斯统计的校正来包括有限宽度效应。

Method: 引入费曼图来计算 NTK 统计的有限宽度校正，从而极大地简化了必要的代数操作，并能够计算层状递归关系，用于涉及预激活、NTK 和某些高阶导数张量（dNTK 和 ddNTK）的任意统计，这些统计是预测前导阶训练动力学所必需的。

Result: 计算有限宽度对 NTK 统计的校正

Conclusion: 通过将深度网络的稳定性结果从预激活扩展到 NTK，并证明 NTK 的 Gram 矩阵对角线上的 ReLU 等尺度不变非线性不存在有限宽度校正，证明了该框架的可行性。并通过数值实验验证了结果。

Abstract: Neural tangent kernels (NTKs) are a powerful tool for analyzing deep,
non-linear neural networks. In the infinite-width limit, NTKs can easily be
computed for most common architectures, yielding full analytic control over the
training dynamics. However, at infinite width, important properties of training
such as NTK evolution or feature learning are absent. Nevertheless, finite
width effects can be included by computing corrections to the Gaussian
statistics at infinite width. We introduce Feynman diagrams for computing
finite-width corrections to NTK statistics. These dramatically simplify the
necessary algebraic manipulations and enable the computation of layer-wise
recursive relations for arbitrary statistics involving preactivations, NTKs and
certain higher-derivative tensors (dNTK and ddNTK) required to predict the
training dynamics at leading order. We demonstrate the feasibility of our
framework by extending stability results for deep networks from preactivations
to NTKs and proving the absence of finite-width corrections for scale-invariant
nonlinearities such as ReLU on the diagonal of the Gram matrix of the NTK. We
validate our results with numerical experiments.

</details>


### [183] [Physics-Informed Diffusion Models for Unsupervised Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2508.11528)
*Juhi Soni,Markus Lange-Hegermann,Stefan Windmann*

Main category: cs.LG

TL;DR: Propose an unsupervised anomaly detection approach based on a physics-informed diffusion model for multivariate time series data, which improves the F1 score in anomaly detection.


<details>
  <summary>Details</summary>
Motivation: diffusion model has demonstrated its effectiveness in forecasting, imputation, generation, and anomaly detection in the time series domain. In this paper, we present a new approach for learning the physics-dependent temporal distribution of multivariate time series data

Method: an unsupervised anomaly detection approach based on a physics-informed diffusion model for multivariate time series data using a weighted physics-informed loss during diffusion model training. A weighted physics-informed loss is constructed using a static weight schedule.

Result: physics-informed training improves the F1 score in anomaly detection; it generates better data diversity and log-likelihood. Our model outperforms baseline approaches, additionally, it surpasses prior physics-informed work and purely data-driven diffusion models on a synthetic dataset and one real-world dataset while remaining competitive on others.

Conclusion: physics-informed training improves the F1 score in anomaly detection; it generates better data diversity and log-likelihood. Our model outperforms baseline approaches, additionally, it surpasses prior physics-informed work and purely data-driven diffusion models on a synthetic dataset and one real-world dataset while remaining competitive on others.

Abstract: We propose an unsupervised anomaly detection approach based on a
physics-informed diffusion model for multivariate time series data. Over the
past years, diffusion model has demonstrated its effectiveness in forecasting,
imputation, generation, and anomaly detection in the time series domain. In
this paper, we present a new approach for learning the physics-dependent
temporal distribution of multivariate time series data using a weighted
physics-informed loss during diffusion model training. A weighted
physics-informed loss is constructed using a static weight schedule. This
approach enables a diffusion model to accurately approximate underlying data
distribution, which can influence the unsupervised anomaly detection
performance. Our experiments on synthetic and real-world datasets show that
physics-informed training improves the F1 score in anomaly detection; it
generates better data diversity and log-likelihood. Our model outperforms
baseline approaches, additionally, it surpasses prior physics-informed work and
purely data-driven diffusion models on a synthetic dataset and one real-world
dataset while remaining competitive on others.

</details>


### [184] [A Comprehensive Perspective on Explainable AI across the Machine Learning Workflow](https://arxiv.org/abs/2508.11529)
*George Paterakis,Andrea Castellani,George Papoutsoglou,Tobias Rodemann,Ioannis Tsamardinos*

Main category: cs.LG

TL;DR: 本文提出了一个名为 HXAI 的用户至上的框架，旨在提高人工智能模型的可解释性和可信度，弥合开发者和领域专家之间的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能正在重塑科学和工业，但许多用户仍然认为其模型是不透明的“黑盒子”。传统的、可解释的人工智能方法可以解释单个预测，但忽略了决定洞察力是否可信的上游决策和下游质量检查。

Method: 本文提出了 Holistic Explainable Artificial Intelligence (HXAI)，一个以用户为中心的框架，将解释嵌入到数据分析工作流的每个阶段，并根据用户定制这些解释。

Result: HXAI 将六个组件（数据、分析设置、学习过程、模型输出、模型质量、沟通渠道）统一到一个单一的分类法中，并将每个组件与领域专家、数据分析师和数据科学家的需求对齐。一个包含 112 个问题的题库涵盖了这些需求；我们对当代工具的调查突出了关键的覆盖差距。人工智能代理可以协调各种解释技术，将技术转化为利益相关者特定的叙述，从而弥合人工智能开发者和领域专家之间的差距。

Conclusion: 这篇论文提出了一个新颖的端到端视角，关注透明度、可信赖的AI部署和负责任的AI部署。

Abstract: Artificial intelligence is reshaping science and industry, yet many users
still regard its models as opaque "black boxes". Conventional explainable
artificial-intelligence methods clarify individual predictions but overlook the
upstream decisions and downstream quality checks that determine whether
insights can be trusted. In this work, we present Holistic Explainable
Artificial Intelligence (HXAI), a user-centric framework that embeds
explanation into every stage of the data-analysis workflow and tailors those
explanations to users. HXAI unifies six components (data, analysis set-up,
learning process, model output, model quality, communication channel) into a
single taxonomy and aligns each component with the needs of domain experts,
data analysts and data scientists. A 112-item question bank covers these needs;
our survey of contemporary tools highlights critical coverage gaps. Grounded in
theories of human explanation, principles from human-computer interaction and
findings from empirical user studies, HXAI identifies the characteristics that
make explanations clear, actionable and cognitively manageable. A comprehensive
taxonomy operationalises these insights, reducing terminological ambiguity and
enabling rigorous coverage analysis of existing toolchains. We further
demonstrate how AI agents that embed large-language models can orchestrate
diverse explanation techniques, translating technical artifacts into
stakeholder-specific narratives that bridge the gap between AI developers and
domain experts. Departing from traditional surveys or perspective articles,
this work melds concepts from multiple disciplines, lessons from real-world
projects and a critical synthesis of the literature to advance a novel,
end-to-end viewpoint on transparency, trustworthiness and responsible AI
deployment.

</details>


### [185] [DFed-SST: Building Semantic- and Structure-aware Topologies for Decentralized Federated Graph Learning](https://arxiv.org/abs/2508.11530)
*Lianshuai Guo,Zhongzheng Yuan,Xunkai Li,Yinlin Zhu,Meixia Qu,Wenyu Wang*

Main category: cs.LG

TL;DR: DFed-SST 是一种去中心化的联邦图学习框架，具有自适应通信能力，通过利用局部拓扑信息来优化模型聚合，并在真实数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的 DFL 优化策略主要为计算机视觉等任务设计，未能解决本地子图中固有的独特拓扑信息。联邦图学习 (FGL) 专为图数据定制，但主要在集中式服务器-客户端模型中实现，未能利用去中心化的优势。

Method: 一种利用每个客户端本地子图的独特拓扑特征来动态构建和优化客户端间通信拓扑的双拓扑自适应通信机制。

Result: DFed-SST 实现了优于基线方法 3.26% 的平均准确率提升。

Conclusion: DFed-SST在八个真实世界数据集上实现了优于基线方法 3.26% 的平均准确率提升，证明了其优越性。

Abstract: Decentralized Federated Learning (DFL) has emerged as a robust distributed
paradigm that circumvents the single-point-of-failure and communication
bottleneck risks of centralized architectures. However, a significant challenge
arises as existing DFL optimization strategies, primarily designed for tasks
such as computer vision, fail to address the unique topological information
inherent in the local subgraph. Notably, while Federated Graph Learning (FGL)
is tailored for graph data, it is predominantly implemented in a centralized
server-client model, failing to leverage the benefits of decentralization.To
bridge this gap, we propose DFed-SST, a decentralized federated graph learning
framework with adaptive communication. The core of our method is a
dual-topology adaptive communication mechanism that leverages the unique
topological features of each client's local subgraph to dynamically construct
and optimize the inter-client communication topology. This allows our framework
to guide model aggregation efficiently in the face of heterogeneity. Extensive
experiments on eight real-world datasets consistently demonstrate the
superiority of DFed-SST, achieving 3.26% improvement in average accuracy over
baseline methods.

</details>


### [186] [Nested Operator Inference for Adaptive Data-Driven Learning of Reduced-order Models](https://arxiv.org/abs/2508.11542)
*Nicole Aretz,Karen Willcox*

Main category: cs.LG

TL;DR: nested OpInf achieves a four times smaller error than standard OpInf


<details>
  <summary>Details</summary>
Motivation: prioritize the interactions of the dominant modes

Method: a data-driven, nested Operator Inference (OpInf) approach for learning physics-informed reduced-order models (ROMs) from snapshot data of high-dimensional dynamical systems

Result: nested OpInf achieving a four times smaller error than standard OpInf at a comparable offline time. nested OpInf learns a ROM with, on average, 3% error and computational speed-up factor above 19,000.

Conclusion: nested OpInf achieves a four times smaller error than standard OpInf at a comparable offline time.nested OpInf learns a ROM with, on average, 3% error and computational speed-up factor above 19,000.

Abstract: This paper presents a data-driven, nested Operator Inference (OpInf) approach
for learning physics-informed reduced-order models (ROMs) from snapshot data of
high-dimensional dynamical systems. The approach exploits the inherent
hierarchy within the reduced space to iteratively construct initial guesses for
the OpInf learning problem that prioritize the interactions of the dominant
modes. The initial guess computed for any target reduced dimension corresponds
to a ROM with provably smaller or equal snapshot reconstruction error than with
standard OpInf. Moreover, our nested OpInf algorithm can be warm-started from
previously learned models, enabling versatile application scenarios involving
dynamic basis and model form updates. We demonstrate the performance of our
algorithm on a cubic heat conduction problem, with nested OpInf achieving a
four times smaller error than standard OpInf at a comparable offline time.
Further, we apply nested OpInf to a large-scale, parameterized model of the
Greenland ice sheet where, despite model form approximation errors, it learns a
ROM with, on average, 3% error and computational speed-up factor above 19,000.

</details>


### [187] [SeamlessFlow: A Trainer Agent Isolation RL Framework Achieving Bubble-Free Pipelines via Tag Scheduling](https://arxiv.org/abs/2508.11553)
*Jinghui Wang,Shaojie Wang,Yinghan Cui,Xuxing Chen,Chao Wang,Xiaojiang Zhang,Minglei Zhang,Jiarong Zhang,Wenhao Zhuang,Yuchen Cao,Wankang Bao,Haimo Li,Zheng Lin,Huiming Wang,Haoyang Huang,Zongxian Feng,Zizheng Zhan,Ken Deng,Wen Xiang,Huaixi Tang,Kun Wu,Mengtong Li,Mengfei Xie,Junyi Peng,Haotian Zhang,Bin Chen,Bing Yu*

Main category: cs.LG

TL;DR: SeamlessFlow 是一个基于服务器的强化学习框架，解决了工业规模 RL 中的两个核心挑战：解耦 RL 训练和最大限度地利用 GPU 资源。


<details>
  <summary>Details</summary>
Motivation: 工业规模的 RL 面临两个核心挑战：(1) 将 RL 训练与智能体的复杂执行流程解耦；(2) 在保持大规模部署所需的稳定性和可扩展性的同时，最大限度地利用 GPU 资源，减少空闲时间。

Method: SeamlessFlow 引入了一个数据平面，将 RL 训练器与不同的复杂智能体实现解耦，同时保持高吞吐量。它还提出了一个标签驱动的调度范例，将硬件抽象成具有能力标签的资源，统一了共址和分离的架构。此外，SeamlessFlow 还引入了一个时空复用管道，动态地将空闲的训练节点重新分配给 rollout。

Result: SeamlessFlow 实现了稳定和高性能。

Conclusion: SeamlessFlow 通过结合数据平面和时空复用管道，实现了稳定和高性能，适用于多智能体、长周期和其他复杂的 RL 任务。

Abstract: We introduce SeamlessFlow, a server based reinforcement learning (RL)
framework that addresses two core challenges in industrial scale RL: (1)
decoupling RL training from the complex execution flow of agents; (2)
maximizing GPU utilization with minimal idle time while preserving the
stability and scalability required for large-scale deployments. First,
SeamlessFlow introduces a data plane that decouples the RL trainer from
diverse, complex agent implementations while sustaining high throughput. A
central trajectory manager maintains complete interaction histories and
supports partial rollout, allowing rollout to pause for weight updates and
resume seamlessly, keeping agents unaware of service interruptions. Second, we
propose a tag driven scheduling paradigm that abstracts hardware into
capability tagged resources, unifying colocated and disaggregated
architectures. Based on this, SeamlessFlow introduces a spatiotemporal
multiplexing pipeline that dynamically reassigns idle training nodes to rollout
in a train rollout separated setup, eliminating pipeline bubbles and fully
exploiting heterogeneous cluster resources. By combining these innovations,
SeamlessFlow delivers both stability and high performance, making it well
suited for multi agent, long horizon, and other complex RL tasks.

</details>


### [188] [Optimal CO2 storage management considering safety constraints in multi-stakeholder multi-site CCS projects: a game theoretic perspective](https://arxiv.org/abs/2508.11618)
*Jungang Chen,Seyyed A. Hosseini*

Main category: cs.LG

TL;DR: This paper proposes a Markov game framework for multi-stakeholder CCS projects, using reinforcement learning and surrogate models to optimize CO2 storage strategies and collaboration.


<details>
  <summary>Details</summary>
Motivation: Determining whether stakeholders in CCS projects can independently maximize their interests or require collaborative agreements is crucial for effective planning, especially in geologically connected sites with shared resources and existing infrastructure.

Method: A multi-agent reinforcement learning approach with safety constraints, using Markov games to model stakeholder interactions and an Embed-to-Control (E2C) surrogate model to reduce computational cost.

Result: The framework's effectiveness is demonstrated in an example of multiple operators injecting CO2 into a geologically connected basin, showcasing optimal management of CO2 storage.

Conclusion: The proposed Markov games-based paradigm, combined with multi-agent reinforcement learning and surrogate models, effectively addresses optimal CO2 storage management involving multiple stakeholders with diverse objectives.

Abstract: Carbon capture and storage (CCS) projects typically involve a diverse array
of stakeholders or players from public, private, and regulatory sectors, each
with different objectives and responsibilities. Given the complexity, scale,
and long-term nature of CCS operations, determining whether individual
stakeholders can independently maximize their interests or whether
collaborative coalition agreements are needed remains a central question for
effective CCS project planning and management. CCS projects are often
implemented in geologically connected sites, where shared geological features
such as pressure space and reservoir pore capacity can lead to competitive
behavior among stakeholders. Furthermore, CO2 storage sites are often located
in geologically mature basins that previously served as sites for hydrocarbon
extraction or wastewater disposal in order to leverage existing
infrastructures, which makes unilateral optimization even more complicated and
unrealistic.
  In this work, we propose a paradigm based on Markov games to quantitatively
investigate how different coalition structures affect the goals of
stakeholders. We frame this multi-stakeholder multi-site problem as a
multi-agent reinforcement learning problem with safety constraints. Our
approach enables agents to learn optimal strategies while compliant with safety
regulations. We present an example where multiple operators are injecting CO2
into their respective project areas in a geologically connected basin. To
address the high computational cost of repeated simulations of high-fidelity
models, a previously developed surrogate model based on the Embed-to-Control
(E2C) framework is employed. Our results demonstrate the effectiveness of the
proposed framework in addressing optimal management of CO2 storage when
multiple stakeholders with various objectives and goals are involved.

</details>
