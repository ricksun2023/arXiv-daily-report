{"id": "2506.22439", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22439", "abs": "https://arxiv.org/abs/2506.22439", "authors": ["Javier Conde", "Miguel Gonz\u00e1lez", "Mar\u00eda Grandury", "Gonzalo Mart\u00ednez", "Pedro Reviriego", "Mar Brysbaert"], "title": "Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans", "comment": "Accepted for the GEM2 workshop at ACL 2025", "summary": "The evaluation of LLMs has so far focused primarily on how well they can\nperform different tasks such as reasoning, question-answering, paraphrasing, or\ntranslating. For most of these tasks, performance can be measured with\nobjective metrics, such as the number of correct answers. However, other\nlanguage features are not easily quantified. For example, arousal,\nconcreteness, or gender associated with a given word, as well as the extent to\nwhich we experience words with senses and relate them to a specific sense.\nThose features have been studied for many years by psycholinguistics,\nconducting large-scale experiments with humans to produce ratings for thousands\nof words. This opens an opportunity to evaluate how well LLMs align with human\nratings on these word features, taking advantage of existing studies that cover\nmany different language features in a large number of words. In this paper, we\nevaluate the alignment of a representative group of LLMs with human ratings on\ntwo psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets\ncover thirteen features over thousands of words. The results show that\nalignment is \\textcolor{black}{generally} better in the Glasgow norms evaluated\n(arousal, valence, dominance, concreteness, imageability, familiarity, and\ngender) than on the Lancaster norms evaluated (introceptive, gustatory,\nolfactory, haptic, auditory, and visual). This suggests a potential limitation\nof current LLMs in aligning with human sensory associations for words, which\nmay be due to their lack of embodied cognition present in humans and\nillustrates the usefulness of evaluating LLMs with psycholinguistic datasets.", "AI": {"tldr": "This paper evaluates how well LLMs align with human ratings on psycholinguistic datasets. LLMs align better with abstract features than sensory associations, possibly due to lack of embodied cognition.", "motivation": "LLMs are typically evaluated on tasks with objective metrics, but other language features like arousal, concreteness, or gender are not easily quantified. Psycholinguistic studies offer human ratings for these features, providing an opportunity to evaluate how well LLMs align with human perception.", "method": "Evaluate the alignment of a representative group of LLMs with human ratings on two psycholinguistic datasets: the Glasgow and Lancaster norms, which cover thirteen features over thousands of words.", "result": "Alignment is generally better in the Glasgow norms than on the Lancaster norms, suggesting a potential limitation of current LLMs in aligning with human sensory associations for words.", "conclusion": "LLMs align better with human ratings on Glasgow norms (arousal, valence, dominance, concreteness, imageability, familiarity, and gender) than on Lancaster norms (introceptive, gustatory, olfactory, haptic, auditory, and visual), suggesting a limitation in aligning with human sensory associations, potentially due to lack of embodied cognition."}}
{"id": "2506.22485", "categories": ["cs.CL", "cs.AI", "68T07, 68T50", "I.2.1; I.2.3; I.2.7; H.3.3"], "pdf": "https://arxiv.org/pdf/2506.22485", "abs": "https://arxiv.org/abs/2506.22485", "authors": ["Sudip Dasgupta", "Himanshu Shankar"], "title": "AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents", "comment": "17 pages, 2 system diagrams, 1 table, no prior conference publication", "summary": "This study presents a modular, multi-agent system for the automated review of\nhighly structured enterprise business documents using AI agents. Unlike prior\nsolutions focused on unstructured texts or limited compliance checks, this\nframework leverages modern orchestration tools such as LangChain, CrewAI,\nTruLens, and Guidance to enable section-by-section evaluation of documents for\naccuracy, consistency, completeness, and clarity. Specialized agents, each\nresponsible for discrete review criteria such as template compliance or factual\ncorrectness, operate in parallel or sequence as required. Evaluation outputs\nare enforced to a standardized, machine-readable schema, supporting downstream\nanalytics and auditability. Continuous monitoring and a feedback loop with\nhuman reviewers allow for iterative system improvement and bias mitigation.\n  Quantitative evaluation demonstrates that the AI Agent-as-Judge system\napproaches or exceeds human performance in key areas: achieving 99% information\nconsistency (vs. 92% for humans), halving error and bias rates, and reducing\naverage review time from 30 to 2.5 minutes per document, with a 95% agreement\nrate between AI and expert human judgment. While promising for a wide range of\nindustries, the study also discusses current limitations, including the need\nfor human oversight in highly specialized domains and the operational cost of\nlarge-scale LLM usage. The proposed system serves as a flexible, auditable, and\nscalable foundation for AI-driven document quality assurance in the enterprise\ncontext.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2aAI\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5ba1\u67e5\u4f01\u4e1a\u6587\u6863\uff0c\u5728\u51c6\u786e\u6027\u3001\u901f\u5ea6\u548c\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8e\u4eba\u5de5\u5ba1\u67e5\uff0c\u4f46\u4ecd\u9700\u4eba\u5de5\u76d1\u7763\u3002", "motivation": "\u4e0e\u4ee5\u5f80\u4e13\u6ce8\u4e8e\u975e\u7ed3\u6784\u5316\u6587\u672c\u6216\u6709\u9650\u5408\u89c4\u6027\u68c0\u67e5\u7684\u89e3\u51b3\u65b9\u6848\u4e0d\u540c\uff0c\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7528\u4e8e\u4f7f\u7528AI\u4ee3\u7406\u81ea\u52a8\u5ba1\u67e5\u9ad8\u5ea6\u7ed3\u6784\u5316\u7684\u4f01\u4e1a\u4e1a\u52a1\u6587\u6863\u3002", "method": "\u8be5\u6846\u67b6\u5229\u7528LangChain\u3001CrewAI\u3001TruLens\u548cGuidance\u7b49\u73b0\u4ee3\u7f16\u6392\u5de5\u5177\uff0c\u5bf9\u6587\u6863\u8fdb\u884c\u9010\u8282\u8bc4\u4f30\uff0c\u4ee5\u786e\u4fdd\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u5b8c\u6574\u6027\u548c\u6e05\u6670\u5ea6\u3002", "result": "AI Agent-as-Judge\u7cfb\u7edf\u5728\u5173\u952e\u9886\u57df\u63a5\u8fd1\u6216\u8d85\u8fc7\u4e86\u4eba\u7c7b\u7684\u8868\u73b0\uff1a\u5b9e\u73b0\u4e8699%\u7684\u4fe1\u606f\u4e00\u81f4\u6027\uff08\u4eba\u7c7b\u4e3a92%\uff09\uff0c\u8bef\u5dee\u548c\u504f\u5dee\u7387\u964d\u4f4e\u4e86\u4e00\u534a\uff0c\u5e73\u5747\u5ba1\u67e5\u65f6\u95f4\u4ece\u6bcf\u4efd\u6587\u686330\u5206\u949f\u51cf\u5c11\u52302.5\u5206\u949f\uff0cAI\u548c\u4e13\u5bb6\u4eba\u7c7b\u5224\u65ad\u4e4b\u95f4\u7684\u4e00\u81f4\u7387\u4e3a95%\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u4f01\u4e1a\u73af\u5883\u4e2dAI\u9a71\u52a8\u7684\u6587\u6863\u8d28\u91cf\u4fdd\u8bc1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u3001\u53ef\u5ba1\u8ba1\u548c\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2506.22486", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22486", "abs": "https://arxiv.org/abs/2506.22486", "authors": ["Ming Cheung"], "title": "Hallucination Detection with Small Language Models", "comment": null, "summary": "Since the introduction of ChatGPT, large language models (LLMs) have\ndemonstrated significant utility in various tasks, such as answering questions\nthrough retrieval-augmented generation. Context can be retrieved using a\nvectorized database, serving as a foundation for LLMs to generate responses.\nHowever, hallucinations in responses can undermine the reliability of LLMs in\npractical applications, and they are not easily detectable in the absence of\nground truth, particularly in question-and-answer scenarios. This paper\nproposes a framework that integrates multiple small language models to verify\nresponses generated by LLMs using the retrieved context from a vectorized\ndatabase. By breaking down the responses into individual sentences and\nutilizing the probability of generating \"Yes\" tokens from the outputs of\nmultiple models for a given set of questions, responses, and relevant context,\nhallucinations can be detected. The proposed framework is validated through\nexperiments with real datasets comprising over 100 sets of questions, answers,\nand contexts, including responses with fully and partially correct sentences.\nThe results demonstrate a 10\\% improvement in F1 scores for detecting correct\nresponses compared to hallucinations, indicating that multiple small language\nmodels can be effectively employed for answer verification, providing a\nscalable and efficient solution for both academic and practical applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u6765\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u54cd\u5e94\u4e2d\u5e7b\u89c9\u7684\u6846\u67b6\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u53ef\u4ee5\u6709\u6548\u63d0\u9ad8\u68c0\u6d4b\u6b63\u786e\u54cd\u5e94\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u54cd\u5e94\u4e2d\u7684\u5e7b\u89c9\u4f1a\u7834\u574f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u5e76\u4e14\u5728\u6ca1\u6709\u771f\u5b9e\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4e0d\u5bb9\u6613\u68c0\u6d4b\u5230\uff0c\u5c24\u5176\u662f\u5728\u95ee\u7b54\u573a\u666f\u4e2d\u3002", "method": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u96c6\u6210\u4e86\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u9a8c\u8bc1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u4ece\u77e2\u91cf\u5316\u6570\u636e\u5e93\u68c0\u7d22\u5230\u7684\u4e0a\u4e0b\u6587\u751f\u6210\u7684\u54cd\u5e94\u3002\u901a\u8fc7\u5c06\u54cd\u5e94\u5206\u89e3\u4e3a\u5355\u72ec\u7684\u53e5\u5b50\uff0c\u5e76\u5229\u7528\u591a\u4e2a\u6a21\u578b\u9488\u5bf9\u7ed9\u5b9a\u7684\u4e00\u7ec4\u95ee\u9898\u3001\u54cd\u5e94\u548c\u76f8\u5173\u4e0a\u4e0b\u6587\u751f\u6210\u201c\u662f\u201d\u4ee4\u724c\u7684\u6982\u7387\uff0c\u53ef\u4ee5\u68c0\u6d4b\u5230\u5e7b\u89c9\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5728\u68c0\u6d4b\u6b63\u786e\u54cd\u5e94\u65b9\u9762\uff0cF1 \u5206\u6570\u63d0\u9ad8\u4e86 10%\uff0c\u4e0e\u5e7b\u89c9\u76f8\u6bd4\u3002", "conclusion": "\u591a\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u6709\u6548\u5730\u7528\u4e8e\u7b54\u6848\u9a8c\u8bc1\uff0c\u4e3a\u5b66\u672f\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.22491", "categories": ["cs.CL", "cs.AI", "cs.CY", "I.2.7; J.4; K.4.2"], "pdf": "https://arxiv.org/pdf/2506.22491", "abs": "https://arxiv.org/abs/2506.22491", "authors": ["Oliver Warke", "Joemon M. Jose", "Faegheh Hasibi", "Jan Breitsohl"], "title": "PromptAug: Fine-grained Conflict Classification Using Data Augmentation", "comment": null, "summary": "Given the rise of conflicts on social media, effective classification models\nto detect harmful behaviours are essential. Following the\ngarbage-in-garbage-out maxim, machine learning performance depends heavily on\ntraining data quality. However, high-quality labelled data, especially for\nnuanced tasks like identifying conflict behaviours, is limited, expensive, and\ndifficult to obtain. Additionally, as social media platforms increasingly\nrestrict access to research data, text data augmentation is gaining attention\nas an alternative to generate training data. Augmenting conflict-related data\nposes unique challenges due to Large Language Model (LLM) guardrails that\nprevent generation of offensive content. This paper introduces PromptAug, an\ninnovative LLM-based data augmentation method. PromptAug achieves statistically\nsignificant improvements of 2% in both accuracy and F1-score on conflict and\nemotion datasets. To thoroughly evaluate PromptAug against other data\naugmentation methods we conduct a robust evaluation using extreme data scarcity\nscenarios, quantitative diversity analysis and a qualitative thematic analysis.\nThe thematic analysis identifies four problematic patterns in augmented text:\nLinguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and\nAugmented Content Misinterpretation.\n  Overall, this work presents PromptAug as an effective method for augmenting\ndata in sensitive tasks like conflict detection, offering a unique,\ninterdisciplinary evaluation grounded in both natural language processing and\nsocial science methodology.", "AI": {"tldr": "PromptAug, an LLM-based data augmentation method, improves accuracy and F1-score on conflict and emotion datasets by 2%.", "motivation": "High-quality labelled data for identifying conflict behaviours is limited, expensive, and difficult to obtain. Social media platforms increasingly restrict access to research data, text data augmentation is gaining attention as an alternative to generate training data. Augmenting conflict-related data poses unique challenges due to Large Language Model (LLM) guardrails that prevent generation of offensive content.", "method": "an innovative LLM-based data augmentation method called PromptAug", "result": "PromptAug achieves statistically significant improvements of 2% in both accuracy and F1-score on conflict and emotion datasets. The thematic analysis identifies four problematic patterns in augmented text: Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and Augmented Content Misinterpretation.", "conclusion": "This work presents PromptAug as an effective method for augmenting data in sensitive tasks like conflict detection."}}
{"id": "2506.22604", "categories": ["cs.AI", "cs.HC", "cs.RO"], "pdf": "https://arxiv.org/pdf/2506.22604", "abs": "https://arxiv.org/abs/2506.22604", "authors": ["David Porfirio", "Vincent Hsiao", "Morgan Fine-Morris", "Leslie Smith", "Laura M. Hiatt"], "title": "Bootstrapping Human-Like Planning via LLMs", "comment": "Accepted by the 2025 34th IEEE International Conference on Robot and\n  Human Interactive Communication (RO-MAN)", "summary": "Robot end users increasingly require accessible means of specifying tasks for\nrobots to perform. Two common end-user programming paradigms include\ndrag-and-drop interfaces and natural language programming. Although natural\nlanguage interfaces harness an intuitive form of human communication,\ndrag-and-drop interfaces enable users to meticulously and precisely dictate the\nkey actions of the robot's task. In this paper, we investigate the degree to\nwhich both approaches can be combined. Specifically, we construct a large\nlanguage model (LLM)-based pipeline that accepts natural language as input and\nproduces human-like action sequences as output, specified at a level of\ngranularity that a human would produce. We then compare these generated action\nsequences to another dataset of hand-specified action sequences. Although our\nresults reveal that larger models tend to outperform smaller ones in the\nproduction of human-like action sequences, smaller models nonetheless achieve\nsatisfactory performance.", "AI": {"tldr": "This paper combines natural language and drag-and-drop interfaces for robot task specification, finding that larger language models perform better but smaller ones are still satisfactory.", "motivation": "Robot end users require accessible means of specifying tasks. Natural language and drag-and-drop interfaces are two common end-user programming paradigms.  This paper investigates combining both approaches.", "method": "Construct a large language model (LLM)-based pipeline that accepts natural language as input and produces human-like action sequences as output, specified at a level of granularity that a human would produce.  Compare these generated action sequences to another dataset of hand-specified action sequences.", "result": "Larger models tend to outperform smaller ones in the production of human-like action sequences.", "conclusion": "Smaller models achieve satisfactory performance, while larger models outperform smaller ones in producing human-like action sequences."}}
{"id": "2506.22441", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22441", "abs": "https://arxiv.org/abs/2506.22441", "authors": ["Lei Yang"], "title": "Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation", "comment": null, "summary": "Intelligent transportation systems (ITS) rely heavily on complete and\nhigh-quality spatiotemporal traffic data to achieve optimal performance.\nNevertheless, in real-word traffic data collection processes, issues such as\ncommunication failures and sensor malfunctions often lead to incomplete or\ncorrupted datasets, thereby posing significant challenges to the advancement of\nITS. Among various methods for imputing missing spatiotemporal traffic data,\nthe latent factorization of tensors (LFT) model has emerged as a widely adopted\nand effective solution. However, conventional LFT models typically employ the\nstandard L2-norm in their learning objective, which makes them vulnerable to\nthe influence of outliers. To overcome this limitation, this paper proposes a\nthreshold distance weighted (TDW) loss-incorporated Latent Factorization of\nTensors (TDWLFT) model. The proposed loss function effectively reduces the\nmodel's sensitivity to outliers by assigning differentiated weights to\nindividual samples. Extensive experiments conducted on two traffic speed\ndatasets sourced from diverse urban environments confirm that the proposed\nTDWLFT model consistently outperforms state-of-the-art approaches in terms of\nboth in both prediction accuracy and computational efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684TDW-LFT\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u6837\u672c\u8fdb\u884c\u52a0\u6743\u6765\u51cf\u5c11\u79bb\u7fa4\u503c\u7684\u5f71\u54cd\uff0c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf (ITS) \u4e25\u91cd\u4f9d\u8d56\u5b8c\u6574\u4e14\u9ad8\u8d28\u91cf\u7684\u65f6\u7a7a\u4ea4\u901a\u6570\u636e\u6765\u5b9e\u73b0\u6700\u4f73\u6027\u80fd\u3002\u7136\u800c\uff0c\u5728\u5b9e\u9645\u7684\u4ea4\u901a\u6570\u636e\u6536\u96c6\u8fc7\u7a0b\u4e2d\uff0c\u901a\u4fe1\u6545\u969c\u548c\u4f20\u611f\u5668\u6545\u969c\u7b49\u95ee\u9898\u7ecf\u5e38\u5bfc\u81f4\u6570\u636e\u96c6\u4e0d\u5b8c\u6574\u6216\u635f\u574f\uff0c\u4ece\u800c\u5bf9 ITS \u7684\u53d1\u5c55\u6784\u6210\u91cd\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u9608\u503c\u8ddd\u79bb\u52a0\u6743\uff08TDW\uff09\u635f\u5931\u7684\u5f20\u91cf\u6f5c\u5728\u56e0\u5b50\u5206\u89e3\uff08TDWLFT\uff09\u6a21\u578b\u3002", "result": "\u5728\u6765\u81ea\u4e0d\u540c\u57ce\u5e02\u73af\u5883\u7684\u4e24\u4e2a\u4ea4\u901a\u901f\u5ea6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8bc1\u5b9e", "conclusion": "TDWLFT\u6a21\u578b\u5728\u9884\u6d4b\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002"}}
{"id": "2506.23322", "categories": ["cs.DB", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2506.23322", "abs": "https://arxiv.org/abs/2506.23322", "authors": ["Wei Zhou", "Ji Sun", "Xuanhe Zhou", "Guoliang Li", "Luyang Liu", "Hao Wu", "Tianyuan Wang"], "title": "GaussMaster: An LLM-based Database Copilot System", "comment": "We welcome contributions from the community. For reference, please\n  see the code at: https://gitcode.com/opengauss/openGauss-GaussMaster", "summary": "In the financial industry, data is the lifeblood of operations, and DBAs\nshoulder significant responsibilities for SQL tuning, database deployment,\ndiagnosis, and service repair. In recent years, both database vendors and\ncustomers have increasingly turned to autonomous database platforms in an\neffort to alleviate the heavy workload of DBAs. However, existing autonomous\ndatabase platforms are limited in their capabilities, primarily addressing\nsingle-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual\nintervention remains a necessity for comprehensive database maintenance.\nGaussMaster aims to revolutionize this landscape by introducing an LLM-based\ndatabase copilot system. This innovative solution is designed not only to\nassist developers in writing efficient SQL queries but also to provide\ncomprehensive care for database services. When database instances exhibit\nabnormal behavior, GaussMaster is capable of orchestrating the entire\nmaintenance process automatically. It achieves this by analyzing hundreds of\nmetrics and logs, employing a Tree-of-thought approach to identify root causes,\nand invoking appropriate tools to resolve issues. We have successfully\nimplemented GaussMaster in real-world scenarios, such as the banking industry,\nwhere it has achieved zero human intervention for over 34 database maintenance\nscenarios. In this paper, we present significant improvements in these tasks\nwith code at https://gitcode.com/opengauss/openGauss-GaussMaster.", "AI": {"tldr": "GaussMaster, an LLM-based database copilot, automates database maintenance with zero human intervention in banking scenarios, outperforming existing platforms.", "motivation": "Existing autonomous database platforms are limited in their capabilities, primarily addressing single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual intervention remains a necessity for comprehensive database maintenance.", "method": "Employing a Tree-of-thought approach to identify root causes, and invoking appropriate tools to resolve issues by analyzing hundreds of metrics and logs.", "result": "GaussMaster assists developers in writing efficient SQL queries and provides comprehensive care for database services. It has achieved zero human intervention for over 34 database maintenance scenarios in the banking industry.", "conclusion": "GaussMaster, an LLM-based database copilot system, achieves zero human intervention for over 34 database maintenance scenarios in the banking industry."}}
{"id": "2506.22437", "categories": ["cs.CV", "68T45 (Computer Vision)"], "pdf": "https://arxiv.org/pdf/2506.22437", "abs": "https://arxiv.org/abs/2506.22437", "authors": ["Xinxin Sun", "Peter Chang"], "title": "Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring", "comment": "43 pages, 5 figures, 19 tables. Submitted to NDT&E International.\n  This work may also be of interest to researchers in optical NDE and civil\n  engineering SHM", "summary": "Accurate image alignment is essential for monitoring crack evolution in\nstructural health monitoring (SHM), particularly under real-world conditions\ninvolving perspective distortion, occlusion, and low contrast. However,\ntraditional feature detectors such as SIFT and SURF, which rely on\nGaussian-based scale spaces, tend to suppress high-frequency edges, making them\nunsuitable for thin crack localization. Lightweight binary alternatives like\nORB and BRISK, while computationally efficient, often suffer from poor keypoint\nrepeatability on textured or shadowed surfaces. This study presents a\nphysics-informed alignment framework that adapts the open KAZE architecture to\nSHM-specific challenges. By utilizing nonlinear anisotropic diffusion to\nconstruct a crack-preserving scale space, and integrating RANSAC-based\nhomography estimation, the framework enables accurate geometric correction\nwithout the need for training, parameter tuning, or prior calibration. The\nmethod is validated on time-lapse images of masonry and concrete acquired via\nhandheld smartphone under varied field conditions, including shadow\ninterference, cropping, oblique viewing angles, and surface clutter. Compared\nto classical detectors, the proposed framework reduces crack area and spine\nlength errors by up to 70 percent and 90 percent, respectively, while\nmaintaining sub-5 percent alignment error in key metrics. Unsupervised,\ninterpretable, and computationally lightweight, this approach supports scalable\ndeployment via UAVs and mobile platforms. By tailoring nonlinear scale-space\nmodeling to SHM image alignment, this work offers a robust and physically\ngrounded alternative to conventional techniques for tracking real-world crack\nevolution.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u56fe\u50cf\u5bf9\u9f50\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u5730\u76d1\u6d4b\u5efa\u7b51\u7269\u88c2\u7f1d\uff0c\u5373\u4f7f\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u73b0\u5b9e\u6761\u4ef6\u4e0b\u4e5f\u662f\u5982\u6b64\u3002", "motivation": "\u7cbe\u786e\u7684\u56fe\u50cf\u5bf9\u9f50\u5bf9\u4e8e\u76d1\u6d4b\u7ed3\u6784\u5065\u5eb7\u76d1\u6d4b (SHM) \u4e2d\u7684\u88c2\u7f1d\u6f14\u53d8\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u900f\u89c6\u7578\u53d8\u3001\u906e\u6321\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u7684\u771f\u5b9e\u6761\u4ef6\u4e0b\u3002\u7136\u800c\uff0c\u4f20\u7edf\u7684\u7279\u5f81\u68c0\u6d4b\u5668\uff08\u4f8b\u5982 SIFT \u548c SURF\uff09\u4f9d\u8d56\u4e8e\u57fa\u4e8e\u9ad8\u65af\u7684\u5c3a\u5ea6\u7a7a\u95f4\uff0c\u5f80\u5f80\u4f1a\u6291\u5236\u9ad8\u9891\u8fb9\u7f18\uff0c\u4f7f\u5176\u4e0d\u9002\u5408\u4e8e\u7ec6\u88c2\u7eb9\u5b9a\u4f4d\u3002\u8f7b\u91cf\u7ea7\u4e8c\u503c\u66ff\u4ee3\u65b9\u6848\uff08\u5982 ORB \u548c BRISK\uff09\u867d\u7136\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u4f46\u901a\u5e38\u5728\u7eb9\u7406\u6216\u9634\u5f71\u8868\u9762\u4e0a\u7684\u5173\u952e\u70b9\u91cd\u590d\u6027\u8f83\u5dee\u3002", "method": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u5f00\u653e\u7684KAZE\u67b6\u6784\u6765\u5e94\u5bf9SHM\u7684\u7279\u5b9a\u6311\u6218\u3002\u901a\u8fc7\u5229\u7528\u975e\u7ebf\u6027\u5404\u5411\u5f02\u6027\u6269\u6563\u6765\u6784\u5efa\u88c2\u7f1d\u4fdd\u6301\u5c3a\u5ea6\u7a7a\u95f4\uff0c\u5e76\u96c6\u6210\u57fa\u4e8eRANSAC\u7684\u5355\u5e94\u6027\u4f30\u8ba1\uff0c\u8be5\u6846\u67b6\u65e0\u9700\u8bad\u7ec3\u3001\u53c2\u6570\u8c03\u6574\u6216\u4e8b\u5148\u6821\u51c6\u5373\u53ef\u5b9e\u73b0\u7cbe\u786e\u7684\u51e0\u4f55\u6821\u6b63\u3002", "result": "\u4e0e\u7ecf\u5178\u68c0\u6d4b\u5668\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u5c06\u88c2\u7eb9\u9762\u79ef\u548c\u810a\u67f1\u957f\u5ea6\u8bef\u5dee\u5206\u522b\u964d\u4f4e\u9ad8\u8fbe 70% \u548c 90%\uff0c\u540c\u65f6\u5728\u5173\u952e\u6307\u6807\u4e2d\u4fdd\u6301\u4f4e\u4e8e 5% \u7684\u5bf9\u9f50\u8bef\u5dee\u3002\u8be5\u65b9\u6cd5\u662f\u65e0\u76d1\u7763\u7684\u3001\u53ef\u89e3\u91ca\u7684\u4e14\u8ba1\u7b97\u91cf\u8f7b\uff0c\u652f\u6301\u901a\u8fc7\u65e0\u4eba\u673a\u548c\u79fb\u52a8\u5e73\u53f0\u8fdb\u884c\u53ef\u6269\u5c55\u90e8\u7f72\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9a\u5236\u975e\u7ebf\u6027\u5c3a\u5ea6\u7a7a\u95f4\u5efa\u6a21\u6765\u9002\u5e94SHM\u56fe\u50cf\u5bf9\u9f50\uff0c\u4e3a\u8ddf\u8e2a\u771f\u5b9e\u88c2\u7f1d\u6f14\u53d8\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5065\u4e14\u7269\u7406\u57fa\u7840\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u6280\u672f\u3002"}}
{"id": "2506.22508", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22508", "abs": "https://arxiv.org/abs/2506.22508", "authors": ["Chenyang Shao", "Tianxing Li", "Chenhao Pu", "Fengli Xu", "Yong Li"], "title": "AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text", "comment": "This work has been submitted to NeurIPS 2025. Under review", "summary": "In today's digital world, casual user-generated content often contains subtle\ncues that may inadvertently expose sensitive personal attributes. Such risks\nunderscore the growing importance of effective text anonymization to safeguard\nindividual privacy. However, existing methods either rely on rigid replacements\nthat damage utility or cloud-based LLMs that are costly and pose privacy risks.\nTo address these issues, we explore the use of locally deployed smaller-scale\nlanguage models (SLMs) for anonymization. Yet training effective SLMs remains\nchallenging due to limited high-quality supervision. To address the challenge,\nwe propose AgentStealth, a self-reinforcing LLM anonymization framework.First,\nwe introduce an adversarial anonymization workflow enhanced by In-context\nContrastive Learning and Adaptive Utility-Aware Control. Second, we perform\nsupervised adaptation of SLMs using high-quality data collected from the\nworkflow, which includes both anonymization and attack signals. Finally, we\napply online reinforcement learning where the model leverages its internal\nadversarial feedback to iteratively improve anonymization performance.\nExperiments on two datasets show that our method outperforms baselines in both\nanonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight\ndesign supports direct deployment on edge devices, avoiding cloud reliance and\ncommunication-based privacy risks. Our code is open-source at\nhttps://github.com/tsinghua-fib-lab/AgentStealth.", "AI": {"tldr": "The paper introduces AgentStealth, a self-reinforcing LLM anonymization framework that uses locally deployed smaller-scale language models (SLMs) to improve anonymization effectiveness and utility while avoiding cloud reliance and privacy risks.", "motivation": "Existing text anonymization methods either damage utility or rely on costly and privacy-risky cloud-based LLMs. Training effective smaller-scale language models (SLMs) for anonymization is challenging due to limited high-quality supervision.", "method": "The paper proposes AgentStealth, a self-reinforcing LLM anonymization framework that includes an adversarial anonymization workflow enhanced by In-context Contrastive Learning and Adaptive Utility-Aware Control. It performs supervised adaptation of SLMs using high-quality data collected from the workflow, and applies online reinforcement learning.", "result": "Experiments on two datasets show that AgentStealth outperforms baselines in both anonymization effectiveness (+12.3%) and utility (+6.8%).", "conclusion": "The proposed AgentStealth framework outperforms baselines in both anonymization effectiveness and utility. The lightweight design supports direct deployment on edge devices, avoiding cloud reliance and communication-based privacy risks."}}
{"id": "2506.22609", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2506.22609", "abs": "https://arxiv.org/abs/2506.22609", "authors": ["Graham Todd", "Alexander G. Padula", "Dennis J. N. J. Soemers", "Julian Togelius"], "title": "Ludax: A GPU-Accelerated Domain Specific Language for Board Games", "comment": "18 pages, 3 figures", "summary": "Games have long been used as benchmarks and testing environments for research\nin artificial intelligence. A key step in supporting this research was the\ndevelopment of game description languages: frameworks that compile\ndomain-specific code into playable and simulatable game environments, allowing\nresearchers to generalize their algorithms and approaches across multiple games\nwithout having to manually implement each one. More recently, progress in\nreinforcement learning (RL) has been largely driven by advances in hardware\nacceleration. Libraries like JAX allow practitioners to take full advantage of\ncutting-edge computing hardware, often speeding up training and testing by\norders of magnitude. Here, we present a synthesis of these strands of research:\na domain-specific language for board games which automatically compiles into\nhardware-accelerated code. Our framework, Ludax, combines the generality of\ngame description languages with the speed of modern parallel processing\nhardware and is designed to fit neatly into existing deep learning pipelines.\nWe envision Ludax as a tool to help accelerate games research generally, from\nRL to cognitive science, by enabling rapid simulation and providing a flexible\nrepresentation scheme. We present a detailed breakdown of Ludax's description\nlanguage and technical notes on the compilation process, along with speed\nbenchmarking and a demonstration of training RL agents. The Ludax framework,\nalong with implementations of existing board games, is open-source and freely\navailable.", "AI": {"tldr": "Ludax, a domain-specific language for board games, compiles into hardware-accelerated code, combining the generality of game description languages with the speed of modern parallel processing hardware. It accelerates games research and is open-source.", "motivation": "Games have long been used as benchmarks and testing environments for research in artificial intelligence. Libraries like JAX allow practitioners to take full advantage of cutting-edge computing hardware, often speeding up training and testing by orders of magnitude.", "method": "A domain-specific language for board games which automatically compiles into hardware-accelerated code.", "result": "The paper presents a detailed breakdown of Ludax's description language and technical notes on the compilation process, along with speed benchmarking and a demonstration of training RL agents.", "conclusion": "The Ludax framework accelerates games research, from RL to cognitive science, by enabling rapid simulation and providing a flexible representation scheme. The Ludax framework, along with implementations of existing board games, is open-source and freely available."}}
{"id": "2506.22442", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22442", "abs": "https://arxiv.org/abs/2506.22442", "authors": ["Piotr Makarevich"], "title": "Features-based embedding or Feature-grounding", "comment": "13 pages, 12 figures", "summary": "In everyday reasoning, when we think about a particular object, we associate\nit with a unique set of expected properties such as weight, size, or more\nabstract attributes like density or horsepower. These expectations are shaped\nby our prior knowledge and the conceptual categories we have formed through\nexperience. This paper investigates how such knowledge-based structured\nthinking can be reproduced in deep learning models using features based\nembeddings. Specially, it introduces an specific approach to build\nfeature-grounded embedding, aiming to align shareable representations of\noperable dictionary with interpretable domain-specific conceptual features.", "AI": {"tldr": "This paper introduces a feature-grounded embedding approach to reproduce knowledge-based structured thinking in deep learning models.", "motivation": "Reproducing knowledge-based structured thinking in deep learning models using feature based embeddings.", "method": "an specific approach to build feature-grounded embedding", "result": "The paper investigates how knowledge-based structured thinking can be reproduced in deep learning models.", "conclusion": "This paper introduces a feature-grounded embedding approach to align shareable representations of operable dictionary with interpretable domain-specific conceptual features."}}
{"id": "2506.22530", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2506.22530", "abs": "https://arxiv.org/abs/2506.22530", "authors": ["Jakub Pele\u0161ka", "Gustav \u0160\u00edr"], "title": "Task-Agnostic Contrastive Pretraining for Relational Deep Learning", "comment": "arXiv admin note: text overlap with arXiv:2506.22199", "summary": "Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph\nNeural Network principles to learn directly from relational databases by\nrepresenting them as heterogeneous graphs. However, existing RDL models\ntypically rely on task-specific supervised learning, requiring training\nseparate models for each predictive task, which may hamper scalability and\nreuse.\n  In this work, we propose a novel task-agnostic contrastive pretraining\napproach for RDL that enables database-wide representation learning. For that\naim, we introduce three levels of contrastive objectives$-$row-level,\nlink-level, and context-level$-$designed to capture the structural and semantic\nheterogeneity inherent to relational data. We implement the respective\npretraining approach through a modular RDL architecture and an efficient\nsampling strategy tailored to the heterogeneous database setting. Our\npreliminary results on standard RDL benchmarks demonstrate that fine-tuning the\npretrained models measurably outperforms training from scratch, validating the\npromise of the proposed methodology in learning transferable representations\nfor relational data.", "AI": {"tldr": "propose a novel task-agnostic contrastive pretraining approach for RDL that enables database-wide representation learning", "motivation": "existing RDL models typically rely on task-specific supervised learning, requiring training separate models for each predictive task, which may hamper scalability and reuse.", "method": "a novel task-agnostic contrastive pretraining approach for RDL that enables database-wide representation learning. For that aim, we introduce three levels of contrastive objectives$-$row-level, link-level, and context-level$-$designed to capture the structural and semantic heterogeneity inherent to relational data. We implement the respective pretraining approach through a modular RDL architecture and an efficient sampling strategy tailored to the heterogeneous database setting.", "result": "preliminary results on standard RDL benchmarks demonstrate that fine-tuning the pretrained models measurably outperforms training from scratch", "conclusion": "fine-tuning the pretrained models measurably outperforms training from scratch, validating the promise of the proposed methodology in learning transferable representations for relational data."}}
{"id": "2506.22438", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.22438", "abs": "https://arxiv.org/abs/2506.22438", "authors": ["Xumin Gao", "Mark Stevens", "Grzegorz Cielniak"], "title": "Counting with Confidence: Accurate Pest Monitoring in Water Traps", "comment": "\\c{opyright} 20XX the authors. This work has been accepted to IFAC\n  for publication under a Creative Commons Licence CC-BY-NC-ND", "summary": "Accurate pest population monitoring and tracking their dynamic changes are\ncrucial for precision agriculture decision-making. A common limitation in\nexisting vision-based automatic pest counting research is that models are\ntypically evaluated on datasets with ground truth but deployed in real-world\nscenarios without assessing the reliability of counting results due to the lack\nof ground truth. To this end, this paper proposed a method for comprehensively\nevaluating pest counting confidence in the image, based on information related\nto counting results and external environmental conditions. First, a pest\ndetection network is used for pest detection and counting, extracting counting\nresult-related information. Then, the pest images undergo image quality\nassessment, image complexity assessment, and pest distribution uniformity\nassessment. And the changes in image clarity caused by stirring during image\nacquisition are quantified by calculating the average gradient magnitude.\nNotably, we designed a hypothesis-driven multi-factor sensitivity analysis\nmethod to select the optimal image quality assessment and image complexity\nassessment methods. And we proposed an adaptive DBSCAN clustering algorithm for\npest distribution uniformity assessment. Finally, the obtained information\nrelated to counting results and external environmental conditions is input into\na regression model for prediction, resulting in the final pest counting\nconfidence. To the best of our knowledge, this is the first study dedicated to\ncomprehensively evaluating counting confidence in counting tasks, and\nquantifying the relationship between influencing factors and counting\nconfidence through a model. Experimental results show our method reduces MSE by\n31.7% and improves R2 by 15.2% on the pest counting confidence test set,\ncompared to the baseline built primarily on information related to counting\nresults.", "AI": {"tldr": "This paper presents a new method for evaluating the confidence of pest counting in images, using image analysis and a regression model, leading to more reliable results.", "motivation": "Existing pest counting models lack reliability assessment in real-world scenarios due to the absence of ground truth data.", "method": "The method involves pest detection, image quality assessment, image complexity assessment, pest distribution uniformity assessment using adaptive DBSCAN, and a regression model to predict pest counting confidence.", "result": "The proposed method reduces MSE by 31.7% and improves R2 by 15.2% on the pest counting confidence test set.", "conclusion": "This paper introduces a method to comprehensively evaluate pest counting confidence by considering counting results and external environmental conditions, achieving improved MSE and R2 scores compared to the baseline."}}
{"id": "2506.22648", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.22648", "abs": "https://arxiv.org/abs/2506.22648", "authors": ["Pedro R. Pires", "Tiago A. Almeida"], "title": "Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems", "comment": "Accepted for publication in Applied Soft Computing (ASOC), 49 pages,\n  14 figures", "summary": "Over the past decade, recommender systems have experienced a surge in\npopularity. Despite notable progress, they grapple with challenging issues,\nsuch as high data dimensionality and sparseness. Representing users and items\nas low-dimensional embeddings learned via neural networks has become a leading\nsolution. However, while recent studies show promising results, many approaches\nrely on complex architectures or require content data, which may not always be\navailable. This paper presents Interact2Vec, a novel neural network-based model\nthat simultaneously learns distributed embeddings for users and items while\ndemanding only implicit feedback. The model employs state-of-the-art strategies\nthat natural language processing models commonly use to optimize the training\nphase and enhance the final embeddings. Two types of experiments were conducted\nregarding the extrinsic and intrinsic quality of the model. In the former, we\nbenchmarked the recommendations generated by Interact2Vec's embeddings in a\ntop-$N$ ranking problem, comparing them with six other recommender algorithms.\nThe model achieved the second or third-best results in 30\\% of the datasets,\nbeing competitive with other recommenders, and has proven to be very efficient\nwith an average training time reduction of 274\\% compared to other\nembedding-based models. Later, we analyzed the intrinsic quality of the\nembeddings through similarity tables. Our findings suggest that Interact2Vec\ncan achieve promising results, especially on the extrinsic task, and is an\nexcellent embedding-generator model for scenarios of scarce computing\nresources, enabling the learning of item and user embeddings simultaneously and\nefficiently.", "AI": {"tldr": "Interact2Vec \u662f\u4e00\u79cd\u65b0\u9896\u7684\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\uff0c\u53ef\u540c\u65f6\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u7684\u5d4c\u5165\uff0c\u4ece\u800c\u5728\u63a8\u8350\u4efb\u52a1\u4e2d\u5b9e\u73b0\u6709\u7ade\u4e89\u529b\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u4e0e\u5176\u4ed6\u57fa\u4e8e\u5d4c\u5165\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e86 274%\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u9762\u4e34\u7740\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u4f8b\u5982\u9ad8\u6570\u636e\u7ef4\u5ea6\u548c\u7a00\u758f\u6027\u3002\u5c06\u7528\u6237\u548c\u9879\u76ee\u8868\u793a\u4e3a\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u7684\u4f4e\u7ef4\u5d4c\u5165\u5df2\u6210\u4e3a\u4e00\u79cd\u9886\u5148\u7684\u89e3\u51b3\u65b9\u6848\u3002\u7136\u800c\uff0c\u867d\u7136\u6700\u8fd1\u7684\u7814\u7a76\u663e\u793a\u51fa\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u4f46\u8bb8\u591a\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u590d\u6742\u7684\u67b6\u6784\u6216\u9700\u8981\u5185\u5bb9\u6570\u636e\uff0c\u800c\u5185\u5bb9\u6570\u636e\u53ef\u80fd\u5e76\u4e0d\u603b\u662f\u53ef\u7528\u7684\u3002", "method": "Interact2Vec\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u6a21\u578b\uff0c\u5b83\u540c\u65f6\u5b66\u4e60\u7528\u6237\u548c\u9879\u76ee\u7684\u5206\u5e03\u5f0f\u5d4c\u5165\uff0c\u540c\u65f6\u4ec5\u9700\u8981\u9690\u5f0f\u53cd\u9988\u3002\u8be5\u6a21\u578b\u91c7\u7528\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u5e38\u7528\u7684\u6700\u65b0\u7b56\u7565\u6765\u4f18\u5316\u8bad\u7ec3\u9636\u6bb5\u5e76\u589e\u5f3a\u6700\u7ec8\u5d4c\u5165\u3002", "result": "Interact2Vec \u5728 30% \u7684\u6570\u636e\u96c6\u4e2d\u53d6\u5f97\u4e86\u7b2c\u4e8c\u6216\u7b2c\u4e09\u597d\u7684\u7ed3\u679c\uff0c\u4e0e\u5176\u4ed6\u63a8\u8350\u5668\u76f8\u6bd4\u5177\u6709\u7ade\u4e89\u529b\uff0c\u5e76\u4e14\u5df2\u88ab\u8bc1\u660e\u975e\u5e38\u6709\u6548\uff0c\u4e0e\u5176\u4ed6\u57fa\u4e8e\u5d4c\u5165\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u5e73\u5747\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c11\u4e86 274%\u3002", "conclusion": "Interact2Vec \u80fd\u591f\u53d6\u5f97\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u7279\u522b\u662f\u5728\u5916\u5728\u4efb\u52a1\u4e0a\uff0c\u5e76\u4e14\u5bf9\u4e8e\u8ba1\u7b97\u8d44\u6e90\u7a00\u7f3a\u7684\u573a\u666f\u6765\u8bf4\uff0c\u662f\u4e00\u79cd\u6781\u597d\u7684\u5d4c\u5165\u751f\u6210\u6a21\u578b\uff0c\u80fd\u591f\u540c\u65f6\u6709\u6548\u5730\u5b66\u4e60\u9879\u76ee\u548c\u7528\u6237\u5d4c\u5165\u3002"}}
