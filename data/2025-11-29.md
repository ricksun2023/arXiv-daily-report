<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Prompt Engineering Techniques for Context-dependent Text-to-SQL in Arabic](https://arxiv.org/abs/2511.20677)
*Saleh Almohaimeed,May Alsofyani,Saad Almohaimeed,Mansour Al Ghanim,Liqiang Wang*

Main category: cs.CL

TL;DR: 提出了第一个阿拉伯语跨领域、上下文相关的text-to-SQL数据集（Ar-SParC），并使用GPT-3.5-turbo和GPT-4.5-turbo进行了实验，结合prompt工程技术和GAT corrector方法。


<details>
  <summary>Details</summary>
Motivation: 缺乏阿拉伯语的跨领域、上下文相关的text-to-SQL数据集。

Method: 构建了包含3,450个问题序列的Ar-SParC数据集，使用了10种prompt工程技术（包括问题表示和上下文学习），并提出了GAT corrector方法。

Result: GAT corrector在zero-shot设置下平均提高了1.9%的EX和IX，在上下文学习设置下平均提高了1.72% EX和0.92% IX。

Conclusion: GAT corrector优于之前的GAT verifier技术，特别是在阿拉伯语上，并通过消融实验解释了原因。

Abstract: In recent years, the task of cross-domain, context-dependent text-to-SQL has received significant attention. Enables users with no prior knowledge of SQL to have a conversation with databases using natural language. However, most of the available datasets and research have been conducted in English, along with some work in Chinese. To this date, no effort has been made to address this task in the Arabic language. In this paper, we introduce Ar-SParC, the first Arabic cross-domain, context-dependent text-to-SQL dataset. The dataset consists of 3,450 sequences of interrelated questions, each sequence containing an average of approximately three questions, which results in a total of 10225 questions along with their corresponding SQL queries. We conducted 40 experiments on the Ar-SParC dataset using two large language models, GPT-3.5-turbo and GPT-4.5-turbo, applying 10 different prompt engineering techniques, including four question representation methods and six in-context learning techniques. Furthermore, we developed a novel approach named GAT corrector, which enhanced the performance across all 40 experiments, yielding an average improvement of 1.9% in execution accuracy (EX) and 1.9% in interaction accuracy (IX) under zero-shot settings, and an average increase of 1.72% EX and 0.92% IX under in-context learning settings. Finally, we conducted an ablation study with two more experiments to explain why the GAT corrector outperformed the previous GAT verifier technique, particularly for the Arabic language.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [2] [MorphingDB: A Task-Centric AI-Native DBMS for Model Management and Inference](https://arxiv.org/abs/2511.21160)
*Wu Sai,Xia Ruichen,Yang Dingyu,Wang Rui,Lai Huihang,Guan Jiarui,Bai Jiameng,Zhang Dongxiang,Tang Xiu,Xie Zhongle,Lu Peng,Chen Gang*

Main category: cs.DB

TL;DR: MorphingDB是一个AI原生数据库管理系统，它自动化了PostgreSQL中的模型存储、选择和推理。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案需要手动选择、配置和维护模型，导致开发开销高，或者采用以任务为中心的AutoML方法，计算成本高，DBMS集成性差。

Method: 该论文提出MorphingDB，一个以任务为中心的AI原生数据库管理系统，它采用专门的模式和多维张量数据类型来支持基于BLOB的一体式和解耦模型存储，并设计了一个迁移学习框架，通过离线嵌入历史任务构建可迁移子空间，并通过特征感知映射进行在线投影，以实现实时任务的模型选择。此外，还提出了带有向量共享的预嵌入来消除冗余计算，以及带有成本感知调度的基于DAG的批处理管道，以最大限度地减少推理时间。

Result: MorphingDB在九个公共数据集上优于AI原生数据库管理系统(EvaDB, Madlib, GaussML)和AutoML平台(AutoGluon, AutoKeras, AutoSklearn)，涵盖序列、NLP和图像任务。

Conclusion: MorphingDB在模型选择中实现了准确性、资源消耗和时间成本之间的稳健平衡，并在吞吐量和资源效率方面实现了显著提高。

Abstract: The increasing demand for deep neural inference within database environments has driven the emergence of AI-native DBMSs. However, existing solutions either rely on model-centric designs requiring developers to manually select, configure, and maintain models, resulting in high development overhead, or adopt task-centric AutoML approaches with high computational costs and poor DBMS integration. We present MorphingDB, a task-centric AI-native DBMS that automates model storage, selection, and inference within PostgreSQL. To enable flexible, I/O-efficient storage of deep learning models, we first introduce specialized schemas and multi-dimensional tensor data types to support BLOB-based all-in-one and decoupled model storage. Then we design a transfer learning framework for model selection in two phases, which builds a transferability subspace via offline embedding of historical tasks and employs online projection through feature-aware mapping for real-time tasks. To further optimize inference throughput, we propose pre-embedding with vectoring sharing to eliminate redundant computations and DAG-based batch pipelines with cost-aware scheduling to minimize the inference time. Implemented as a PostgreSQL extension with LibTorch, MorphingDB outperforms AI-native DBMSs (EvaDB, Madlib, GaussML) and AutoML platforms (AutoGluon, AutoKeras, AutoSklearn) across nine public datasets, encompassing series, NLP, and image tasks. Our evaluation demonstrates a robust balance among accuracy, resource consumption, and time cost in model selection and significant gains in throughput and resource efficiency.

</details>


### [3] [HIRE: A Hybrid Learned Index for Robust and Efficient Performance under Mixed Workloads](https://arxiv.org/abs/2511.21307)
*Xinyi Zhang,Liang Liang,Anastasia Ailamaki,Jianliang Xu*

Main category: cs.DB

TL;DR: HIRE: a hybrid in-memory index structure, combines learned indexes with traditional indexes to improve performance.


<details>
  <summary>Details</summary>
Motivation: Learned indexes have high tail latency, suboptimal range query performance, and inconsistent effectiveness across diverse workloads.

Method: HIRE employs hybrid leaf nodes, model-accelerated internal nodes, a nonblocking, cost-driven recalibration mechanism, and an inter-level optimized bulk-loading algorithm.

Result: HIRE outperforms both state-of-the-art learned indexes and traditional structures in range-query throughput, tail latency, and overall stability. HIRE achieves up to 41.7× higher throughput under mixed workloads, reduces tail latency by up to 98%.

Conclusion: HIRE delivers efficient performance consistently.

Abstract: Indexes are critical for efficient data retrieval and updates in modern databases. Recent advances in machine learning have led to the development of learned indexes, which model the cumulative distribution function of data to predict search positions and accelerate query processing. While learned indexes substantially outperform traditional structures for point lookups, they often suffer from high tail latency, suboptimal range query performance, and inconsistent effectiveness across diverse workloads. To address these challenges, this paper proposes HIRE, a hybrid in-memory index structure designed to deliver efficient performance consistently. HIRE combines the structural and performance robustness of traditional indexes with the predictive power of model-based prediction to reduce search overhead while maintaining worst-case stability. Specifically, it employs (1) hybrid leaf nodes adaptive to varying data distributions and workloads, (2) model-accelerated internal nodes augmented by log-based updates for efficient updates, (3) a nonblocking, cost-driven recalibration mechanism for dynamic data, and (4) an inter-level optimized bulk-loading algorithm accounting for leaf and internal-node errors. Experimental results on multiple real-world datasets demonstrate that HIRE outperforms both state-of-the-art learned indexes and traditional structures in range-query throughput, tail latency, and overall stability. Compared to state-of-the-art learned indexes and traditional indexes, HIRE achieves up to 41.7$\times$ higher throughput under mixed workloads, reduces tail latency by up to 98% across varying scenarios.

</details>


### [4] [Beyond Accuracy: An Empirical Study of Uncertainty Estimation in Imputation](https://arxiv.org/abs/2511.21607)
*Zarin Tahia Hossain,Mostafa Milani*

Main category: cs.DB

TL;DR: 本研究系统性地评估了插补方法中不确定性的可靠性和校准性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动分析中，处理缺失数据是一个核心挑战，现代插补方法旨在准确重建数据并量化不确定性，但这些不确定性估计的可靠性仍不清楚。

Method: 比较了来自三个主要系列的代表性方法：统计方法（MICE、SoftImpute）、分布对齐方法（OT-Impute）和深度生成方法（GAIN、MIWAE、TabCSDI），并在多个数据集、缺失机制和缺失率上进行了实验。通过多运行变异性、条件抽样和预测分布建模三种互补途径估计不确定性，并使用校准曲线和预期校准误差（ECE）进行评估。

Result: 结果表明，准确性和校准性通常不一致：具有高重建准确性的模型不一定产生可靠的不确定性。分析了方法在准确性、校准性和运行时之间的权衡，识别了稳定配置。

Conclusion: 为在数据清理和下游机器学习管道中选择不确定性感知插补器提供了指导。

Abstract: Handling missing data is a central challenge in data-driven analysis. Modern imputation methods not only aim for accurate reconstruction but also differ in how they represent and quantify uncertainty. Yet, the reliability and calibration of these uncertainty estimates remain poorly understood. This paper presents a systematic empirical study of uncertainty in imputation, comparing representative methods from three major families: statistical (MICE, SoftImpute), distribution alignment (OT-Impute), and deep generative (GAIN, MIWAE, TabCSDI). Experiments span multiple datasets, missingness mechanisms (MCAR, MAR, MNAR), and missingness rates. Uncertainty is estimated through three complementary routes: multi-run variability, conditional sampling, and predictive-distribution modeling, and evaluated using calibration curves and the Expected Calibration Error (ECE). Results show that accuracy and calibration are often misaligned: models with high reconstruction accuracy do not necessarily yield reliable uncertainty. We analyze method-specific trade-offs among accuracy, calibration, and runtime, identify stable configurations, and offer guidelines for selecting uncertainty-aware imputers in data cleaning and downstream machine learning pipelines.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [5] [E-GEO: A Testbed for Generative Engine Optimization in E-Commerce](https://arxiv.org/abs/2511.20867)
*Puneet S. Bagga,Vivek F. Farias,Tamar Korkotashvili,Tianyi Peng,Yuhang Wu*

Main category: cs.IR

TL;DR: 提出了一个名为E-GEO的电商GEO基准，用于提升生成式引擎的内容可见性和相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的GEO实践是临时的，并且它们的影响仍然知之甚少，尤其是在电子商务中。

Method: 构建了E-GEO基准，包含超过7,000个真实的、多句消费者产品查询，并评估了15种常见的重写启发式方法，并提出了一个轻量级的迭代提示优化算法。

Result: 优化后的prompt揭示了一种稳定的、领域无关的模式，表明存在一种“普遍有效的”GEO策略。

Conclusion: E-GEO基准的提出和实验结果为电商领域的GEO提供了新的方向和方法。

Abstract: With the rise of large language models (LLMs), generative engines are becoming powerful alternatives to traditional search, reshaping retrieval tasks. In e-commerce, for instance, conversational shopping agents now guide consumers to relevant products. This shift has created the need for generative engine optimization (GEO)--improving content visibility and relevance for generative engines. Yet despite its growing importance, current GEO practices are ad hoc, and their impacts remain poorly understood, especially in e-commerce. We address this gap by introducing E-GEO, the first benchmark built specifically for e-commerce GEO. E-GEO contains over 7,000 realistic, multi-sentence consumer product queries paired with relevant listings, capturing rich intent, constraints, preferences, and shopping contexts that existing datasets largely miss. Using this benchmark, we conduct the first large-scale empirical study of e-commerce GEO, evaluating 15 common rewriting heuristics and comparing their empirical performance. To move beyond heuristics, we further formulate GEO as a tractable optimization problem and develop a lightweight iterative prompt-optimization algorithm that can significantly outperform these baselines. Surprisingly, the optimized prompts reveal a stable, domain-agnostic pattern--suggesting the existence of a "universally effective" GEO strategy. Our data and code are publicly available at https://github.com/psbagga17/E-GEO.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [6] [Prototype-Guided Non-Exemplar Continual Learning for Cross-subject EEG Decoding](https://arxiv.org/abs/2511.20696)
*Dan Li,Hye-Bin Shin,Yeon-Woo Choi*

Main category: cs.LG

TL;DR: 提出了一种名为ProNECL的非示例持续学习框架，用于脑电信号解码，该框架在不访问历史脑电样本的情况下保留先验知识。


<details>
  <summary>Details</summary>
Motivation: 脑电信号在个体间差异显著，持续脑电解码任务中，先前受试者的知识容易被新受试者覆盖。以往方法依赖存储历史数据，但存在隐私和内存限制。

Method: 构建类别级原型来概括每个受试者的判别性表征，并通过跨受试者特征对齐和知识蒸馏，逐步将新的特征空间与全局原型记忆对齐。

Result: 在BCI Competition IV 2a和2b数据集上验证，该框架有效地平衡了知识保留和适应性，在跨受试者持续脑电解码任务中实现了卓越的性能。

Conclusion: ProNECL框架在跨受试者持续脑电解码任务中表现出色，解决了知识遗忘和数据隐私问题。

Abstract: Due to the significant variability in electroencephalogram (EEG) signals across individuals, knowledge acquired from previous subjects is often overwritten as new subjects are introduced in continual EEG decoding task. Current works mainly rely on storing the historical data of seen subjects as a replay buffer to prevent forgetting. However, privacy concerns or memory constraints make keeping such data impractical. Instead, we propose a Prototype-guided Non-Exemplar Continual Learning (ProNECL)framework that preserves prior knowledge without accessing any historical EEG samples. ProNECL constructs class-level prototypes to summarize discriminative representations from each subject and incrementally aligns new feature spaces with the global prototype memory through cross-subject feature alignment and knowledge distillation. Validated on the BCI Competition IV 2a and 2b datasets, our framework effectively balances knowledge retention and adaptability, achieving superior performance in cross-subject continual EEG decoding tasks.

</details>
