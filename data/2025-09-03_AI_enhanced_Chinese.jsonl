{"id": "2509.00109", "categories": ["cs.IR", "cs.LG", "H.3.3; I.2.6; K.4.1"], "pdf": "https://arxiv.org/pdf/2509.00109", "abs": "https://arxiv.org/abs/2509.00109", "authors": ["Theodor Stoecker", "Samed Bayer", "Ingo Weber"], "title": "Bias Mitigation for AI-Feedback Loops in Recommender Systems: A Systematic Literature Review and Taxonomy", "comment": "11 pages, 6 figures, 2 tables. Accepted at the FAccTRec '25 Workshop,\n  ACM RecSys 2025 (Prague)", "summary": "Recommender systems continually retrain on user reactions to their own\npredictions, creating AI feedback loops that amplify biases and diminish\nfairness over time. Despite this well-known risk, most bias mitigation\ntechniques are tested only on static splits, so their long-term fairness across\nmultiple retraining rounds remains unclear. We therefore present a systematic\nliterature review of bias mitigation methods that explicitly consider AI\nfeedback loops and are validated in multi-round simulations or live A/B tests.\nScreening 347 papers yields 24 primary studies published between 2019-2025.\nEach study is coded on six dimensions: mitigation technique, biases addressed,\ndynamic testing set-up, evaluation focus, application domain, and ML task,\norganising them into a reusable taxonomy. The taxonomy offers industry\npractitioners a quick checklist for selecting robust methods and gives\nresearchers a clear roadmap to the field's most urgent gaps. Examples include\nthe shortage of shared simulators, varying evaluation metrics, and the fact\nthat most studies report either fairness or performance; only six use both.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7efc\u8ff0\u4e86\u5728\u63a8\u8350\u7cfb\u7edf\u4e2d\u51cf\u8f7b\u56e0AI\u53cd\u9988\u5faa\u73af\u800c\u4ea7\u751f\u7684\u504f\u5dee\u7684\u65b9\u6cd5\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u5728\u591a\u8f6e\u6a21\u62df\u6216A/B\u6d4b\u8bd5\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u4e0d\u65ad\u5730\u6839\u636e\u7528\u6237\u5bf9\u5176\u81ea\u8eab\u9884\u6d4b\u7684\u53cd\u5e94\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\uff0c\u4ece\u800c\u4ea7\u751fAI\u53cd\u9988\u5faa\u73af\uff0c\u968f\u7740\u65f6\u95f4\u7684\u63a8\u79fb\uff0c\u8fd9\u4f1a\u653e\u5927\u504f\u5dee\u5e76\u964d\u4f4e\u516c\u5e73\u6027\u3002\u5c3d\u7ba1\u5b58\u5728\u8fd9\u79cd\u4f17\u6240\u5468\u77e5\u7684\u98ce\u9669\uff0c\u4f46\u5927\u591a\u6570\u504f\u5dee\u7f13\u89e3\u6280\u672f\u4ec5\u5728\u9759\u6001\u5206\u5272\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u56e0\u6b64\u5b83\u4eec\u5728\u591a\u4e2a\u91cd\u65b0\u8bad\u7ec3\u8f6e\u6b21\u4e2d\u7684\u957f\u671f\u516c\u5e73\u6027\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u8be5\u7814\u7a76\u5bf9347\u7bc7\u8bba\u6587\u8fdb\u884c\u4e86\u7b5b\u9009\uff0c\u6700\u7ec8\u9009\u62e9\u4e862019-2025\u5e74\u95f4\u53d1\u8868\u768424\u7bc7\u4e3b\u8981\u7814\u7a76\uff0c\u5e76\u4ece\u516d\u4e2a\u7ef4\u5ea6\u5bf9\u6bcf\u9879\u7814\u7a76\u8fdb\u884c\u7f16\u7801\uff1a\u7f13\u89e3\u6280\u672f\u3001\u89e3\u51b3\u7684\u504f\u5dee\u3001\u52a8\u6001\u6d4b\u8bd5\u8bbe\u7f6e\u3001\u8bc4\u4f30\u91cd\u70b9\u3001\u5e94\u7528\u9886\u57df\u548cML\u4efb\u52a1\uff0c\u5e76\u5c06\u5b83\u4eec\u7ec4\u7ec7\u6210\u4e00\u4e2a\u53ef\u91cd\u7528\u7684\u5206\u7c7b\u3002", "result": "\u8be5\u5206\u7c7b\u6cd5\u4e3a\u884c\u4e1a\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5feb\u901f\u68c0\u67e5\u8868\uff0c\u7528\u4e8e\u9009\u62e9\u7a33\u5065\u7684\u65b9\u6cd5\uff0c\u5e76\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6e05\u6670\u7684\u8def\u7ebf\u56fe\uff0c\u4ee5\u4e86\u89e3\u8be5\u9886\u57df\u6700\u7d27\u8feb\u7684\u5dee\u8ddd\u3002\u4f8b\u5b50\u5305\u62ec\u5171\u4eab\u6a21\u62df\u5668\u7684\u77ed\u7f3a\u3001\u4e0d\u540c\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u4ee5\u53ca\u5927\u591a\u6570\u7814\u7a76\u62a5\u544a\u516c\u5e73\u6027\u6216\u6027\u80fd\uff1b\u53ea\u6709\u516d\u9879\u7814\u7a76\u540c\u65f6\u4f7f\u7528\u4e24\u8005\u3002", "conclusion": "\u603b\u7ed3\u4e86\u73b0\u6709\u504f\u5dee\u7f13\u89e3\u65b9\u6cd5\u5728\u8003\u8651AI\u53cd\u9988\u5faa\u73af\u65b9\u9762\u7684\u7814\u7a76\uff0c\u5e76\u6307\u51fa\u4e86\u8be5\u9886\u57df\u5b58\u5728\u7684\u5dee\u8ddd\uff0c\u4e3a\u4ece\u4e1a\u8005\u548c\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2509.00199", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.00199", "abs": "https://arxiv.org/abs/2509.00199", "authors": ["Chen Zheng", "Zhenyu Zhao"], "title": "Algorithm Adaptation Bias in Recommendation System Online Experiments", "comment": null, "summary": "Online experiments (A/B tests) are widely regarded as the gold standard for\nevaluating recommender system variants and guiding launch decisions. However, a\nvariety of biases can distort the results of the experiment and mislead\ndecision-making. An underexplored but critical bias is algorithm adaptation\neffect. This bias arises from the flywheel dynamics among production models,\nuser data, and training pipelines: new models are evaluated on user data whose\ndistributions are shaped by the incumbent system or tested only in a small\ntreatment group. As a result, the measured effect of a new product change in\nmodeling and user experience in this constrained experimental setting can\ndiverge substantially from its true impact in full deployment. In practice, the\nexperiment results often favor the production variant with large traffic while\nunderestimating the performance of the test variant with small traffic, which\nleads to missing opportunities to launch a true winning arm or underestimating\nthe impact. This paper aims to raise awareness of algorithm adaptation bias,\nsituate it within the broader landscape of RecSys evaluation biases, and\nmotivate discussion of solutions that span experiment design, measurement, and\nadjustment. We detail the mechanisms of this bias, present empirical evidence\nfrom real-world experiments, and discuss potential methods for a more robust\nonline evaluation.", "AI": {"tldr": "\u7b97\u6cd5\u9002\u5e94\u6027\u504f\u5dee\u4f1a\u626d\u66f2\u5728\u7ebf\u5b9e\u9a8c\uff08A/B\u6d4b\u8bd5\uff09\u7684\u7ed3\u679c\uff0c\u5bfc\u81f4\u51b3\u7b56\u5931\u8bef\u3002", "motivation": "\u73b0\u6709\u63a8\u8350\u7cfb\u7edf\u5728\u7ebf\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\u5b58\u5728\u7b97\u6cd5\u9002\u5e94\u6027\u504f\u5dee\u95ee\u9898\uff0c\u5bf9\u65b0\u6a21\u578b\u6548\u679c\u8bc4\u4f30\u4e0d\u51c6\u786e\u3002", "method": "\u5206\u6790\u7b97\u6cd5\u9002\u5e94\u6027\u504f\u5dee\u7684\u673a\u5236\uff0c\u5e76\u63d0\u4f9b\u5b9e\u9645\u6848\u4f8b\u3002", "result": "\u5728\u7ebf\u5b9e\u9a8c\u7ed3\u679c\u901a\u5e38\u4f1a\u9ad8\u4f30\u73b0\u6709\u7cfb\u7edf\uff0c\u4f4e\u4f30\u65b0\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "\u9700\u8981\u91cd\u89c6\u7b97\u6cd5\u9002\u5e94\u6027\u504f\u5dee\uff0c\u5e76\u5728\u5b9e\u9a8c\u8bbe\u8ba1\u3001\u6d4b\u91cf\u548c\u8c03\u6574\u7b49\u65b9\u9762\u5bfb\u6c42\u66f4\u53ef\u9760\u7684\u5728\u7ebf\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2509.00389", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.00389", "abs": "https://arxiv.org/abs/2509.00389", "authors": ["Xiaoxin Ye", "Chengkai Huang", "Hongtao Huang", "Lina Yao"], "title": "Beyond Negative Transfer: Disentangled Preference-Guided Diffusion for Cross-Domain Sequential Recommendation", "comment": null, "summary": "Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across\ndomains to enhance recommendation quality. However, naive aggregation of\nsequential signals can introduce conflicting domain-specific preferences,\nleading to negative transfer. While Sequential Recommendation (SR) already\nsuffers from noisy behaviors such as misclicks and impulsive actions, CDSR\nfurther amplifies this issue due to domain heterogeneity arising from diverse\nitem types and user intents. The core challenge is disentangling three\nintertwined signals: domain-invariant preferences, domain-specific preferences,\nand noise. Diffusion Models (DMs) offer a generative denoising framework\nwell-suited for disentangling complex user preferences and enhancing robustness\nto noise. Their iterative refinement process enables gradual denoising, making\nthem effective at capturing subtle preference signals. However, existing\napplications in recommendation face notable limitations: sequential DMs often\nconflate shared and domain-specific preferences, while cross-domain\ncollaborative filtering DMs neglect temporal dynamics, limiting their ability\nto model evolving user preferences. To bridge these gaps, we propose\n\\textbf{DPG-Diff}, a novel Disentangled Preference-Guided Diffusion Model, the\nfirst diffusion-based approach tailored for CDSR, to or best knowledge.\nDPG-Diff decomposes user preferences into domain-invariant and domain-specific\ncomponents, which jointly guide the reverse diffusion process. This\ndisentangled guidance enables robust cross-domain knowledge transfer, mitigates\nnegative transfer, and filters sequential noise. Extensive experiments on\nreal-world datasets demonstrate that DPG-Diff consistently outperforms\nstate-of-the-art baselines across multiple metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3a DPG-Diff \u7684\u65b0\u9896\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8de8\u57df\u5e8f\u5217\u63a8\u8350\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u89e3\u8026\u7528\u6237\u504f\u597d\uff0c\u4ece\u800c\u5b9e\u73b0\u9c81\u68d2\u7684\u8de8\u57df\u77e5\u8bc6\u8f6c\u79fb\uff0c\u51cf\u8f7b\u8d1f\u8fc1\u79fb\uff0c\u5e76\u8fc7\u6ee4\u5e8f\u5217\u566a\u58f0\u3002", "motivation": "\u8de8\u57df\u5e8f\u5217\u63a8\u8350 (CDSR) \u5229\u7528\u8de8\u57df\u7684\u7528\u6237\u884c\u4e3a\u6765\u63d0\u9ad8\u63a8\u8350\u8d28\u91cf\u3002\u7136\u800c\uff0c\u7b80\u5355\u5730\u805a\u5408\u5e8f\u5217\u4fe1\u53f7\u4f1a\u5f15\u5165\u51b2\u7a81\u7684\u9886\u57df\u7279\u5b9a\u504f\u597d\uff0c\u4ece\u800c\u5bfc\u81f4\u8d1f\u8fc1\u79fb\u3002\u5e8f\u5217\u63a8\u8350 (SR) \u5df2\u7ecf\u53d7\u5230\u9519\u8bef\u70b9\u51fb\u548c\u51b2\u52a8\u884c\u4e3a\u7b49\u566a\u58f0\u884c\u4e3a\u7684\u5f71\u54cd\uff0c\u800c CDSR \u7531\u4e8e\u9879\u76ee\u7c7b\u578b\u548c\u7528\u6237\u610f\u56fe\u7684\u591a\u6837\u6027\u800c\u4ea7\u751f\u7684\u9886\u57df\u5f02\u8d28\u6027\uff0c\u8fdb\u4e00\u6b65\u52a0\u5267\u4e86\u8fd9\u4e2a\u95ee\u9898\u3002\u6838\u5fc3\u6311\u6218\u662f\u89e3\u5f00\u4e09\u4e2a\u76f8\u4e92\u4ea4\u7ec7\u7684\u4fe1\u53f7\uff1a\u9886\u57df\u4e0d\u53d8\u504f\u597d\u3001\u9886\u57df\u7279\u5b9a\u504f\u597d\u548c\u566a\u58f0\u3002", "method": "DPG-Diff \u5c06\u7528\u6237\u504f\u597d\u5206\u89e3\u4e3a\u9886\u57df\u4e0d\u53d8\u548c\u9886\u57df\u7279\u5b9a\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u8fd9\u4e9b\u7ec4\u6210\u90e8\u5206\u5171\u540c\u6307\u5bfc\u53cd\u5411\u6269\u6563\u8fc7\u7a0b\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDPG-Diff \u5728\u591a\u4e2a\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u3002", "conclusion": "DPG-Diff \u662f\u4e00\u79cd\u4e13\u4e3a CDSR \u5b9a\u5236\u7684\u9996\u4e2a\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5b83\u53ef\u4ee5\u5b9e\u73b0\u9c81\u68d2\u7684\u8de8\u57df\u77e5\u8bc6\u8f6c\u79fb\uff0c\u51cf\u8f7b\u8d1f\u8fc1\u79fb\uff0c\u5e76\u8fc7\u6ee4\u5e8f\u5217\u566a\u58f0\u3002"}}
