<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 42]
- [cs.CV](#cs.CV) [Total: 40]
- [cs.AI](#cs.AI) [Total: 41]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IR](#cs.IR) [Total: 13]
- [cs.LG](#cs.LG) [Total: 41]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Clinically Grounded Agent-based Report Evaluation: An Interpretable Metric for Radiology Report Generation](https://arxiv.org/abs/2508.02808)
*Radhika Dua,Young Joon,Kwon,Siddhant Dogra,Daniel Freedman,Diana Ruan,Motaz Nashawaty,Danielle Rigau,Daniel Alexander Alber,Kang Zhang,Kyunghyun Cho,Eric Karl Oermann*

Main category: cs.CL

TL;DR: ICARE 是一种可解释的评估框架，它使用大型语言模型代理和动态多项选择问题回答 (MCQA) 来评估放射学报告。


<details>
  <summary>Details</summary>
Motivation: 现有的指标通常依赖于表面相似性或表现为黑盒，缺乏可解释性。因此，安全部署需要对生成的报告进行可靠的临床评估。

Method: ICARE (Interpretable and Clinically-grounded Agent-based Report Evaluation)，它是一个可解释的评估框架，利用大型语言模型代理和动态多项选择问题回答 (MCQA)。

Result: 临床医生研究表明，ICARE 比以前的指标更符合专家判断。扰动分析证实了对临床内容和可重复性的敏感性，而模型比较揭示了可解释的错误模式。

Conclusion: ICARE通过将分数与问答对联系起来，实现了透明且可解释的评估。

Abstract: Radiological imaging is central to diagnosis, treatment planning, and
clinical decision-making. Vision-language foundation models have spurred
interest in automated radiology report generation (RRG), but safe deployment
requires reliable clinical evaluation of generated reports. Existing metrics
often rely on surface-level similarity or behave as black boxes, lacking
interpretability. We introduce ICARE (Interpretable and Clinically-grounded
Agent-based Report Evaluation), an interpretable evaluation framework
leveraging large language model agents and dynamic multiple-choice question
answering (MCQA). Two agents, each with either the ground-truth or generated
report, generate clinically meaningful questions and quiz each other. Agreement
on answers captures preservation and consistency of findings, serving as
interpretable proxies for clinical precision and recall. By linking scores to
question-answer pairs, ICARE enables transparent, and interpretable assessment.
Clinician studies show ICARE aligns significantly more with expert judgment
than prior metrics. Perturbation analyses confirm sensitivity to clinical
content and reproducibility, while model comparisons reveal interpretable error
patterns.

</details>


### [2] [Modeling Annotator Disagreement with Demographic-Aware Experts and Synthetic Perspectives](https://arxiv.org/abs/2508.02853)
*Yinuo Xu,Veronica Derricks,Allison Earl,David Jurgens*

Main category: cs.CL

TL;DR: The paper introduces DEM-MoE to model annotator disagreement using demographic information and explores synthetic data to improve performance.


<details>
  <summary>Details</summary>
Motivation: The motivation is to model annotator disagreement in subjective NLP tasks.

Method: The paper proposes DEM-MoE (Demographic-Aware Mixture of Experts), a model that routes inputs to expert subnetworks based on annotator demographics.

Result: DEM-MoE performs competitively across demographic groups and shows strong results on datasets with high annotator disagreement. Synthetic annotations align moderately well with human annotations and offer a scalable way to enrich training data. The optimal strategies for blending real and synthetic data depend on dataset structure.

Conclusion: This paper improves the representation of diverse perspectives in subjective NLP tasks.

Abstract: We present an approach to modeling annotator disagreement in subjective NLP
tasks through both architectural and data-centric innovations. Our model,
DEM-MoE (Demographic-Aware Mixture of Experts), routes inputs to expert
subnetworks based on annotator demographics, enabling it to better represent
structured, group-level variation compared to prior models. DEM-MoE
consistently performs competitively across demographic groups, and shows
especially strong results on datasets with high annotator disagreement. To
address sparse demographic coverage, we test whether LLM-generated synthetic
annotations via zero-shot persona prompting can be used for data imputation. We
show these synthetic judgments align moderately well with human annotations on
our data and offer a scalable way to potentially enrich training data. We then
propose and evaluate approaches for blending real and synthetic data using
strategies tailored to dataset structure. We find that the optimal strategies
depend on dataset structure. Together, these contributions improve the
representation of diverse perspectives.

</details>


### [3] [Highlight & Summarize: RAG without the jailbreaks](https://arxiv.org/abs/2508.02872)
*Giovanni Cherubin,Andrew Paverd*

Main category: cs.CL

TL;DR: Highlight & Summarize (H&S), a new design pattern for RAG, prevents attacks by not revealing the user's question to the generative LLM, and it performs better than standard RAG.


<details>
  <summary>Details</summary>
Motivation: Preventing jailbreaking and model hijacking of Large Language Models (LLMs) is an important yet challenging task.

Method: a new design pattern for retrieval-augmented generation (RAG) systems

Result: the majority of H&S responses are judged to be better than those of a standard RAG pipeline.

Conclusion: Highlight & Summarize (H&S) can generate better responses than a standard RAG pipeline.

Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs)
is an important yet challenging task. For example, when interacting with a
chatbot, malicious users can input specially crafted prompts to cause the LLM
to generate undesirable content or perform a completely different task from its
intended purpose. Existing mitigations for such attacks typically rely on
hardening the LLM's system prompt or using a content classifier trained to
detect undesirable content or off-topic conversations. However, these
probabilistic approaches are relatively easy to bypass due to the very large
space of possible inputs and undesirable outputs. In this paper, we present and
evaluate Highlight & Summarize (H&S), a new design pattern for
retrieval-augmented generation (RAG) systems that prevents these attacks by
design. The core idea is to perform the same task as a standard RAG pipeline
(i.e., to provide natural language answers to questions, based on relevant
sources) without ever revealing the user's question to the generative LLM. This
is achieved by splitting the pipeline into two components: a highlighter, which
takes the user's question and extracts relevant passages ("highlights") from
the retrieved documents, and a summarizer, which takes the highlighted passages
and summarizes them into a cohesive answer. We describe several possible
instantiations of H&S and evaluate their generated responses in terms of
correctness, relevance, and response quality. Surprisingly, when using an
LLM-based highlighter, the majority of H&S responses are judged to be better
than those of a standard RAG pipeline.

</details>


### [4] [Merge-based syntax is mediated by distinct neurocognitive mechanisms: A clustering analysis of comprehension abilities in 84,000 individuals with language deficits across nine languages](https://arxiv.org/abs/2508.02885)
*Elliot Murphy,Rohan Venkatesh,Edward Khokhlovich,Andrey Vyshedskiy*

Main category: cs.CL

TL;DR: 合并句法可能在进化时间中突然出现，但不同的认知机制似乎支持不同类型的基于合并的对象的处理。


<details>
  <summary>Details</summary>
Motivation: 在现代语言科学中，句法的核心计算操作“合并”被定义为一种组合两个语言单位（例如，“棕色”、“猫”）以形成分类结构（“棕色猫”，一个名词短语）的操作。一些语言学家认为合并是一种基本的、不可分割的操作，它是在一个进化步骤中出现的。

Method: 系统地调查参与者对具有递增句法复杂度的句子的理解。

Result: 聚类分析揭示了三种不同结构类型的行为证据，我们讨论了这些结构类型可能在不同的发展阶段出现，并受到选择性损伤。

Conclusion: 不同的认知机制似乎支持不同类型的基于合并的对象的处理。

Abstract: In the modern language sciences, the core computational operation of syntax,
'Merge', is defined as an operation that combines two linguistic units (e.g.,
'brown', 'cat') to form a categorized structure ('brown cat', a Noun Phrase).
This can then be further combined with additional linguistic units based on
this categorial information, respecting non-associativity such that abstract
grouping is respected. Some linguists have embraced the view that Merge is an
elementary, indivisible operation that emerged in a single evolutionary step.
From a neurocognitive standpoint, different mental objects constructed by Merge
may be supported by distinct mechanisms: (1) simple command constructions
(e.g., "eat apples"); (2) the merging of adjectives and nouns ("red boat"); and
(3) the merging of nouns with spatial prepositions ("laptop behind the sofa").
Here, we systematically investigate participants' comprehension of sentences
with increasing levels of syntactic complexity. Clustering analyses revealed
behavioral evidence for three distinct structural types, which we discuss as
potentially emerging at different developmental stages and subject to selective
impairment. While a Merge-based syntax may still have emerged suddenly in
evolutionary time, responsible for the structured symbolic turn our species
took, different cognitive mechanisms seem to underwrite the processing of
various types of Merge-based objects.

</details>


### [5] [Coherent Multimodal Reasoning with Iterative Self-Evaluation for Vision-Language Models](https://arxiv.org/abs/2508.02886)
*Wenjie Luo,Ruocheng Li,Shanshan Zhu,Julian Perry*

Main category: cs.CL

TL;DR: CMRF improves LVLMs' common sense reasoning using iterative, self-evaluating inference, achieving state-of-the-art performance on challenging benchmarks.


<details>
  <summary>Details</summary>
Motivation: Current large language models (LLMs) and vision-language models (LVLMs) struggle with complex, multi-step, cross-modal common sense reasoning tasks, often lacking "deliberative thinking" and relying on superficial associations.

Method: The Coherent Multimodal Reasoning Framework (CMRF) enhances LVLMs' common sense reasoning through an iterative, self-evaluating inference mechanism, integrating a Reasoning Decomposition Unit (RDU), a Contextual Inference Engine (CIE), and a Coherence Assessment Module (CAM).

Result: CMRF attains an average accuracy of 69.4%, surpassing the best open-source baseline by +2.4 percentage points.

Conclusion: CMRF achieves state-of-the-art performance among open-source LVLMs on challenging benchmarks and demonstrates strength in complex reasoning.

Abstract: Despite significant advancements, current large language models (LLMs) and
vision-language models (LVLMs) continue to struggle with complex, multi-step,
cross-modal common sense reasoning tasks, often exhibiting a lack of
"deliberative thinking." They tend to rely on superficial associations rather
than deep, chained inference, particularly when integrating visual information
with abstract concepts. To address this, we propose the Coherent Multimodal
Reasoning Framework (CMRF), a novel approach that enhances LVLMs' common sense
reasoning capabilities through an iterative, self-evaluating inference
mechanism. CMRF mimics human problem-solving by decomposing complex queries,
generating step-by-step inferences, and self-correcting errors. Our framework
integrates three key modules: a Reasoning Decomposition Unit (RDU) for breaking
down problems into sub-questions, a Contextual Inference Engine (CIE) for
contextual inference, and a Coherence Assessment Module (CAM) for evaluating
logical consistency and confidence. Coupled with an Adaptive Iterative
Refinement strategy, CMRF systematically refines its reasoning paths. Built
upon LLaVA-1.6-34B and trained on a novel Multimodal Daily Activity Reasoning
(MDAR) dataset, CMRF achieves state-of-the-art performance among open-source
LVLMs on challenging benchmarks like VCR, A-OKVQA, and DailyLife-MRC. It
attains an average accuracy of 69.4%, surpassing the best open-source baseline
by +2.4 percentage points, with particular strength in complex reasoning
scenarios. Extensive ablation studies and human evaluations confirm the
critical contributions of each module and the effectiveness of iterative
refinement in fostering more coherent and accurate reasoning.

</details>


### [6] [SLIM-LLMs: Modeling of Style-Sensory Language RelationshipsThrough Low-Dimensional Representations](https://arxiv.org/abs/2508.02901)
*Osama Khalid,Sanvesh Srivastava,Padmini Srinivasan*

Main category: cs.CL

TL;DR: This paper explores the relationship between sensorial language and traditional stylistic features, and introduces SLIM-LLMs, which match the performance of full-scale language models while reducing parameters by up to 80%.


<details>
  <summary>Details</summary>
Motivation: Sensorial language plays a fundamental role in how we communicate experiences and perceptions.

Method: Reduced-Rank Ridge Regression (R4) approach and Stylometrically Lean Interpretable Models (SLIM-LLMs)

Result: low-dimensional latent representations of LIWC features r = 24 effectively capture stylistic information for sensorial language prediction compared to the full feature set (r = 74)

Conclusion: SLIM-LLMs with low-rank LIWC features match the performance of full-scale language models while reducing parameters by up to 80%.

Abstract: Sensorial language -- the language connected to our senses including vision,
sound, touch, taste, smell, and interoception, plays a fundamental role in how
we communicate experiences and perceptions. We explore the relationship between
sensorial language and traditional stylistic features, like those measured by
LIWC, using a novel Reduced-Rank Ridge Regression (R4) approach. We demonstrate
that low-dimensional latent representations of LIWC features r = 24 effectively
capture stylistic information for sensorial language prediction compared to the
full feature set (r = 74). We introduce Stylometrically Lean Interpretable
Models (SLIM-LLMs), which model non-linear relationships between these style
dimensions. Evaluated across five genres, SLIM-LLMs with low-rank LIWC features
match the performance of full-scale language models while reducing parameters
by up to 80%.

</details>


### [7] [Can LLMs Generate High-Quality Task-Specific Conversations?](https://arxiv.org/abs/2508.02931)
*Shengqi Li,Amarnath Gupta*

Main category: cs.CL

TL;DR: This paper introduces a parameterization framework for controlling conversation quality in large language models.


<details>
  <summary>Details</summary>
Motivation: address challenges in conversation generation, including topic coherence, knowledge progression, character consistency, and control granularity

Method: a parameterization framework for controlling conversation quality in large language models with nine key parameters across six dimensions

Result: enable precise specification of dialogue properties

Conclusion: parameter-based control produces statistically significant differences in generated conversation properties and the framework provides a standardized method for conversation quality control with applications in education, therapy, customer service, and entertainment

Abstract: This paper introduces a parameterization framework for controlling
conversation quality in large language models. We explore nine key parameters
across six dimensions that enable precise specification of dialogue properties.
Through experiments with state-of-the-art LLMs, we demonstrate that
parameter-based control produces statistically significant differences in
generated conversation properties. Our approach addresses challenges in
conversation generation, including topic coherence, knowledge progression,
character consistency, and control granularity. The framework provides a
standardized method for conversation quality control with applications in
education, therapy, customer service, and entertainment. Future work will focus
on implementing additional parameters through architectural modifications and
developing benchmark datasets for evaluation.

</details>


### [8] [CoCoTen: Detecting Adversarial Inputs to Large Language Models through Latent Space Features of Contextual Co-occurrence Tensors](https://arxiv.org/abs/2508.02997)
*Sri Durga Sai Sowmya Kadali,Evangelos E. Papalexakis*

Main category: cs.CL

TL;DR: This paper proposes a novel method leveraging the latent space characteristics of Contextual Co-occurrence Matrices and Tensors for the effective identification of adversarial and jailbreak prompts. The method achieves a notable F1 score of 0.83 using only 0.5% of labeled prompts, which is a 96.6% improvement over baselines. The implementation is publicly available.


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) are vulnerable to attacks, especially jailbreaks designed to produce harmful responses. Developing strong detection methods is essential for the safe and reliable use of LLMs.

Method: A novel method leveraging the latent space characteristics of Contextual Co-occurrence Matrices and Tensors.

Result: The proposed method achieves a notable F1 score of 0.83 using only 0.5% of labeled prompts, which is a 96.6% improvement over baselines. The method is also significantly faster, with speedups ranging from 2.3 to 128.4 times compared to the baseline models.

Conclusion: The proposed method achieves a notable F1 score of 0.83 using only 0.5% of labeled prompts, which is a 96.6% improvement over baselines. The method is also significantly faster, with speedups ranging from 2.3 to 128.4 times compared to the baseline models. The implementation is publicly available.

Abstract: The widespread use of Large Language Models (LLMs) in many applications marks
a significant advance in research and practice. However, their complexity and
hard-to-understand nature make them vulnerable to attacks, especially
jailbreaks designed to produce harmful responses. To counter these threats,
developing strong detection methods is essential for the safe and reliable use
of LLMs. This paper studies this detection problem using the Contextual
Co-occurrence Matrix, a structure recognized for its efficacy in data-scarce
environments. We propose a novel method leveraging the latent space
characteristics of Contextual Co-occurrence Matrices and Tensors for the
effective identification of adversarial and jailbreak prompts. Our evaluations
show that this approach achieves a notable F1 score of 0.83 using only 0.5% of
labeled prompts, which is a 96.6% improvement over baselines. This result
highlights the strength of our learned patterns, especially when labeled data
is scarce. Our method is also significantly faster, speedup ranging from 2.3 to
128.4 times compared to the baseline models. To support future research and
reproducibility, we have made our implementation publicly available.

</details>


### [9] [When Algorithms Meet Artists: Topic Modeling the AI-Art Debate, 2013-2025](https://arxiv.org/abs/2508.03037)
*Ariya Mukherjee-Gandhi,Oliver Muellerklein*

Main category: cs.CL

TL;DR: This paper analyzes AI art discourse, revealing a disconnect between artists' concerns and media narratives, and calls for greater consideration of artists' perspectives.


<details>
  <summary>Details</summary>
Motivation: Artists are raising concerns about consent, transparency, and the future of creative labor due to generative AI, but their voices are often marginalized.

Method: A twelve-year analysis (2013-2025) of 439 excerpts from various English-language sources using a reproducible methodology and BERTopic.

Result: Identified five stable thematic clusters and uncovered a misalignment between artists' perceptions and media narratives. The study also provides a BERTopic-based methodology and a multimodal baseline for future research.

Conclusion: The study highlights a misalignment between artists' perceptions and prevailing media narratives regarding AI-generated art, revealing how technical jargon can marginalize artists' concerns. It advocates for deeper engagement with artist perspectives.

Abstract: As generative AI continues to reshape artistic production and alternate modes
of human expression, artists whose livelihoods are most directly affected have
raised urgent concerns about consent, transparency, and the future of creative
labor. However, the voices of artists are often marginalized in dominant public
and scholarly discourse. This study presents a twelve-year analysis, from 2013
to 2025, of English-language discourse surrounding AI-generated art. It draws
from 439 curated 500-word excerpts sampled from opinion articles, news reports,
blogs, legal filings, and spoken-word transcripts. Through a reproducible
methodology, we identify five stable thematic clusters and uncover a
misalignment between artists' perceptions and prevailing media narratives. Our
findings highlight how the use of technical jargon can function as a subtle
form of gatekeeping, often sidelining the very issues artists deem most urgent.
Our work provides a BERTopic-based methodology and a multimodal baseline for
future research, alongside a clear call for deeper, transparency-driven
engagement with artist perspectives in the evolving AI-creative landscape.

</details>


### [10] [Privacy-Aware Decoding: Mitigating Privacy Leakage of Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03098)
*Haoran Wang,Xiongxiao Xu,Baixiang Huang,Kai Shu*

Main category: cs.CL

TL;DR: This paper introduces Privacy-Aware Decoding (PAD), a novel defense mechanism against privacy leaks in Retrieval-Augmented Generation (RAG) systems. PAD injects noise during decoding to protect sensitive information and offers provable privacy guarantees, outperforming existing methods with minimal overhead.


<details>
  <summary>Details</summary>
Motivation: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large language models (LLMs) by conditioning outputs on external knowledge sources. However, when retrieval involves private or sensitive data, RAG systems are susceptible to extraction attacks that can leak confidential information through generated responses.

Method: Privacy-Aware Decoding (PAD), a lightweight, inference-time defense that adaptively injects calibrated Gaussian noise into token logits during generation. PAD integrates confidence-based screening to selectively protect high-risk tokens, efficient sensitivity estimation to minimize unnecessary noise, and context-aware noise calibration to balance privacy with generation quality. A Renyi Differential Privacy (RDP) accountant rigorously tracks cumulative privacy loss, enabling explicit per-response (epsilon, delta)-DP guarantees for sensitive outputs.

Result: Experiments on three real-world datasets demonstrate that PAD substantially reduces private information leakage while preserving response utility, outperforming existing retrieval- and post-processing-based defenses.

Conclusion: PAD substantially reduces private information leakage while preserving response utility, outperforming existing retrieval- and post-processing-based defenses. The work takes an important step toward mitigating privacy risks in RAG via decoding strategies, paving the way for universal and scalable privacy solutions in sensitive domains.

Abstract: Retrieval-Augmented Generation (RAG) enhances the factual accuracy of large
language models (LLMs) by conditioning outputs on external knowledge sources.
However, when retrieval involves private or sensitive data, RAG systems are
susceptible to extraction attacks that can leak confidential information
through generated responses. We propose Privacy-Aware Decoding (PAD), a
lightweight, inference-time defense that adaptively injects calibrated Gaussian
noise into token logits during generation. PAD integrates confidence-based
screening to selectively protect high-risk tokens, efficient sensitivity
estimation to minimize unnecessary noise, and context-aware noise calibration
to balance privacy with generation quality. A \renyi Differential Privacy (RDP)
accountant rigorously tracks cumulative privacy loss, enabling explicit
per-response $(\varepsilon, \delta)$-DP guarantees for sensitive outputs.
Unlike prior approaches requiring retraining or corpus-level filtering, PAD is
model-agnostic and operates entirely at decoding time with minimal
computational overhead. Experiments on three real-world datasets demonstrate
that PAD substantially reduces private information leakage while preserving
response utility, outperforming existing retrieval- and post-processing-based
defenses. Our work takes an important step toward mitigating privacy risks in
RAG via decoding strategies, paving the way for universal and scalable privacy
solutions in sensitive domains. Our code is available:
https://github.com/wang2226/PAD.

</details>


### [11] [Token-Level Precise Attack on RAG: Searching for the Best Alternatives to Mislead Generation](https://arxiv.org/abs/2508.03110)
*Zizhong Li,Haopeng Zhang,Jiawei Zhang*

Main category: cs.CL

TL;DR: 本文提出了TPARAG，一种针对白盒和黑盒RAG系统的新型框架，通过在token级别生成和优化恶意段落，提高了攻击RAG系统的成功率。实验表明，TPARAG优于现有方法，并揭示了RAG管道中的关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在为知识密集型任务提供值得信赖的响应方面取得了显著成功，但它们仍然面临诸如幻觉和过时知识等关键限制。为了解决这些问题，检索增强生成（RAG）框架通过检索器增强LLM对外部知识的访问，从而能够实现关于最新事件的更准确和实时的输出。然而，这种集成带来了新的安全漏洞：外部数据库中的恶意内容可能被检索并用于操纵模型输出的风险。

Method: 我们提出了令牌级精确攻击RAG（TPARAG），这是一个新颖的框架，旨在用于白盒和黑盒RAG系统。TPARAG利用轻量级白盒LLM作为攻击者，以在令牌级别生成和迭代优化恶意段落，从而确保可检索性和生成中的高攻击成功率。

Result: 在开放域QA数据集上的大量实验表明，TPARAG在检索阶段和端到端攻击有效性方面始终优于以前的方法。

Conclusion: TPARAG在检索阶段和端到端攻击有效性方面始终优于以前的方法。这些结果进一步揭示了RAG管道中的关键漏洞，并为提高其鲁棒性提供了新的见解。

Abstract: While large language models (LLMs) have achieved remarkable success in
providing trustworthy responses for knowledge-intensive tasks, they still face
critical limitations such as hallucinations and outdated knowledge. To address
these issues, the retrieval-augmented generation (RAG) framework enhances LLMs
with access to external knowledge via a retriever, enabling more accurate and
real-time outputs about the latest events. However, this integration brings new
security vulnerabilities: the risk that malicious content in the external
database can be retrieved and used to manipulate model outputs. Although prior
work has explored attacks on RAG systems, existing approaches either rely
heavily on access to the retriever or fail to jointly consider both retrieval
and generation stages, limiting their effectiveness, particularly in black-box
scenarios. To overcome these limitations, we propose Token-level Precise Attack
on the RAG (TPARAG), a novel framework that targets both white-box and
black-box RAG systems. TPARAG leverages a lightweight white-box LLM as an
attacker to generate and iteratively optimize malicious passages at the token
level, ensuring both retrievability and high attack success in generation.
Extensive experiments on open-domain QA datasets demonstrate that TPARAG
consistently outperforms previous approaches in retrieval-stage and end-to-end
attack effectiveness. These results further reveal critical vulnerabilities in
RAG pipelines and offer new insights into improving their robustness.

</details>


### [12] [Cross-lingual Opinions and Emotions Mining in Comparable Documents](https://arxiv.org/abs/2508.03112)
*Motaz Saad,David Langlois,Kamel Smaili*

Main category: cs.CL

TL;DR: 本研究调查了英语-阿拉伯语可比较文档中情感和情绪的差异。结果表明，情感和情绪注释在文章来自同一新闻机构时一致，而当文章来自不同的新闻机构时则不一致。


<details>
  <summary>Details</summary>
Motivation: 可比较文本是多种语言中主题对齐但非直接翻译的文档。它们对于理解跨语言如何讨论一个主题很有价值。这项研究调查了英语-阿拉伯语可比较文档中情感和情绪的差异。

Method: 我们应用了一种跨语言方法来标记具有观点类别（主观/客观）的文档，避免依赖机器翻译。为了用情绪（愤怒、厌恶、恐惧、快乐、悲伤、惊讶）进行注释，我们手动将英语 WordNet-Affect (WNA) 词典翻译成阿拉伯语，创建用于标记可比较语料库的双语情感词典。然后，我们应用统计测量来评估每个源-目标文档对中情感和情绪的一致性。

Result: 情感和情绪注释在文章来自同一新闻机构时一致，而当文章来自不同的新闻机构时则不一致。

Conclusion: 情感和情绪注释在文章来自同一新闻机构时一致，而当文章来自不同的新闻机构时则不一致。所提出的方法是语言独立的，并且可以推广到其他语言对。

Abstract: Comparable texts are topic-aligned documents in multiple languages that are
not direct translations. They are valuable for understanding how a topic is
discussed across languages. This research studies differences in sentiments and
emotions across English-Arabic comparable documents. First, texts are annotated
with sentiment and emotion labels. We apply a cross-lingual method to label
documents with opinion classes (subjective/objective), avoiding reliance on
machine translation. To annotate with emotions (anger, disgust, fear, joy,
sadness, surprise), we manually translate the English WordNet-Affect (WNA)
lexicon into Arabic, creating bilingual emotion lexicons used to label the
comparable corpora. We then apply a statistical measure to assess the agreement
of sentiments and emotions in each source-target document pair. This comparison
is especially relevant when the documents originate from different sources. To
our knowledge, this aspect has not been explored in prior literature. Our study
includes English-Arabic document pairs from Euronews, BBC, and Al-Jazeera
(JSC). Results show that sentiment and emotion annotations align when articles
come from the same news agency and diverge when they come from different ones.
The proposed method is language-independent and generalizable to other language
pairs.

</details>


### [13] [Long Story Generation via Knowledge Graph and Literary Theory](https://arxiv.org/abs/2508.03137)
*Ge Shi,Kaiyu Huang,Guochen Feng*

Main category: cs.CL

TL;DR: Introduces a multi-agent story generator with memory and a theme obstacle framework to improve long story generation quality.


<details>
  <summary>Details</summary>
Motivation: Theme drift and tedious plots with incoherent logic in previous outline-based long story generation methods.

Method: A multi-agent Story Generator structure with memory storage (long-term and short-term) and a story theme obstacle framework based on literary narratology theory.

Result: The proposed approach generates higher-quality long stories compared to previous methods.

Conclusion: The proposed multi-agent Story Generator structure improves the multi-stage method by using LLMs as agents, incorporating memory storage models and a story theme obstacle framework, and establishing a multi-agent interaction stage to simulate writer-reader interaction, resulting in higher-quality long stories.

Abstract: The generation of a long story consisting of several thousand words is a
sub-task in the field of long text generation~(LTG). Previous research has
addressed this challenge through outline-based generation, which employs a
multi-stage method for generating outlines into stories. However, this approach
suffers from two common issues: almost inevitable theme drift caused by the
loss of memory of previous outlines, and tedious plots with incoherent logic
that are less appealing to human readers.
  In this paper, we propose the multi-agent Story Generator structure to
improve the multi-stage method, using large language models~(LLMs) as the core
components of agents. To avoid theme drift, we introduce a memory storage model
comprising two components: a long-term memory storage that identifies the most
important memories, thereby preventing theme drift; and a short-term memory
storage that retains the latest outlines from each generation round. To
incorporate engaging elements into the story, we design a story theme obstacle
framework based on literary narratology theory that introduces uncertain
factors and evaluation criteria to generate outline. This framework calculates
the similarity of the former storyline and enhances the appeal of the story by
building a knowledge graph and integrating new node content. Additionally, we
establish a multi-agent interaction stage to simulate writer-reader interaction
through dialogue and revise the story text according to feedback, to ensure it
remains consistent and logical. Evaluations against previous methods
demonstrate that our approach can generate higher-quality long stories.

</details>


### [14] [RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior](https://arxiv.org/abs/2508.03140)
*Junyao Yang,Jianwei Wang,Huiping Zhuang,Cen Chen,Ziqian Zeng*

Main category: cs.CL

TL;DR: The paper introduces RCP-Merging, a novel merging framework that integrates domain-specific LLMs with long CoT capability while preserving reasoning abilities and domain performance, achieving significant improvements over existing methods in BioMedicine and Finance domains.


<details>
  <summary>Details</summary>
Motivation: To create a dual-capability model with long CoT capability and domain-specific knowledge without substantial computational and data costs, model merging emerges as a highly resource-efficient method. However, significant challenges lie in merging domain-specific LLMs with long CoT ones since nowadays merging methods suffer from reasoning capability degradation, even gibberish output and output collapse.

Method: RCP-Merging: Merging Long Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning Capability as Prior, a novel merging framework designed to integrate domain-specific LLMs with long CoT capability, meanwhile maintaining model performance in the original domain. Treating reasoning model weights as foundational prior, our method utilizes a reasoning capability indicator to preserve core long CoT capability model weights while selectively merging essential domain-specific weights.

Result: RCP-Merging successfully merges a reasoning model with domain-specific ones, improving domain task performance by 9.5% and 9.2% over state-of-the-art methods, without significantly harming the original long CoT reasoning capability.

Conclusion: RCP-Merging successfully merges a reasoning model with domain-specific ones, improving domain task performance by 9.5% and 9.2% over state-of-the-art methods, without significantly harming the original long CoT reasoning capability.

Abstract: Large Language Models (LLMs) with long chain-of-thought (CoT) capability,
termed Reasoning Models, demonstrate superior intricate problem-solving
abilities through multi-step long CoT reasoning. To create a dual-capability
model with long CoT capability and domain-specific knowledge without
substantial computational and data costs, model merging emerges as a highly
resource-efficient method. However, significant challenges lie in merging
domain-specific LLMs with long CoT ones since nowadays merging methods suffer
from reasoning capability degradation, even gibberish output and output
collapse. To overcome this, we introduce RCP-Merging: Merging Long
Chain-of-Thought Models with Domain-Specific Models by Considering Reasoning
Capability as Prior, a novel merging framework designed to integrate
domain-specific LLMs with long CoT capability, meanwhile maintaining model
performance in the original domain. Treating reasoning model weights as
foundational prior, our method utilizes a reasoning capability indicator to
preserve core long CoT capability model weights while selectively merging
essential domain-specific weights. We conducted extensive experiments on
Qwen2.5-7B, Llama3.1-8B, and Qwen2.5-1.5B models in BioMedicine and Finance
domains. Our results show that RCP-Merging successfully merges a reasoning
model with domain-specific ones, improving domain task performance by 9.5% and
9.2% over state-of-the-art methods, without significantly harming the original
long CoT reasoning capability.

</details>


### [15] [Light-IF: Endowing LLMs with Generalizable Reasoning via Preview and Self-Checking for Complex Instruction Following](https://arxiv.org/abs/2508.03178)
*Chenyang Wang,Liang Wen,Shousheng Jia,Xiangzheng Zhang,Liang Xu*

Main category: cs.CL

TL;DR: 论文提出了一种框架，通过预览和自我检查来提高LLM在复杂指令下的遵循能力，并在指令遵循基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在解决数学问题、编码任务和一般谜题方面的能力显著增强，但在准确遵循指令方面的有效性仍然不稳定，尤其是在更复杂的指令下。研究发现，思考阶段的惰性推理是导致指令遵循不佳的主要因素。

Method: 提出了一个综合框架，该框架通过预览和自我检查实现严格的推理过程，并结合了Entropy-SFT策略和token-wise entropy-adaptive (TEA-RL)强化学习。

Result: 在指令遵循基准测试中取得了显著的性能提升，Light-IF-32B模型超越了DeepSeek-R1和Doubao-1.6等模型。

Conclusion: Light-IF-32B模型在指令遵循基准测试中表现出色，超越了DeepSeek-R1和Doubao-1.6等大型开源和闭源模型。

Abstract: While advancements in the reasoning abilities of LLMs have significantly
enhanced their performance in solving mathematical problems, coding tasks, and
general puzzles, their effectiveness in accurately adhering to instructions
remains inconsistent, particularly with more complex directives. Our
investigation identifies lazy reasoning during the thinking stage as the
primary factor contributing to poor instruction adherence. To mitigate this
issue, we propose a comprehensive framework designed to enable rigorous
reasoning processes involving preview and self-checking, essential for
satisfying strict instruction constraints. Specifically, we first generate
instructions with complex constraints and apply a filtering process to obtain
valid prompts, resulting in three distinct prompt datasets categorized as hard,
easy, and pass. Then, we employ rejection sampling on the pass prompts to
curate a small yet high-quality dataset, enabling a cold-start initialization
of the model and facilitating its adaptation to effective reasoning patterns.
Subsequently, we employ an entropy-preserving supervised fine-tuning
(Entropy-SFT) strategy coupled with token-wise entropy-adaptive (TEA-RL)
reinforcement learning guided by rule-based dense rewards. This approach
encourages the model to transform its reasoning mechanism, ultimately fostering
generalizable reasoning abilities that encompass preview and self-checking.
Extensive experiments conducted on instruction-following benchmarks demonstrate
remarkable performance improvements across various model scales. Notably, our
Light-IF-32B model surpasses both larger open-source models such as DeepSeek-R1
and closed-source models like Doubao-1.6.

</details>


### [16] [Taggus: An Automated Pipeline for the Extraction of Characters' Social Networks from Portuguese Fiction Literature](https://arxiv.org/abs/2508.03358)
*Tiago G Canário,Catarina Duarte,Flávio L. Pinheiro,João L. M. Pereira*

Main category: cs.CL

TL;DR: The paper proposes a pipeline, Taggus, to extract social networks from literary fiction works in Portuguese, achieving better results than state-of-the-art tools.


<details>
  <summary>Details</summary>
Motivation: Currently available methods tend to underperform, especially in less-represented languages, due to a lack of manually annotated data for training.

Method: The pipeline uses POS tagging and a combination of heuristics.

Result: The Taggus pipeline achieves satisfying results with an average F1-Score of $94.1\%$ in the task of identifying characters and solving for co-reference and $75.9\%$ in interaction detection. These represent, respectively, an increase of $50.7\%$ and $22.3\%$ on results achieved by the readily available State-of-the-Art tools.

Conclusion: The Taggus pipeline achieves satisfying results with an average F1-Score of $94.1\%$ in the task of identifying characters and solving for co-reference and $75.9\%$ in interaction detection, which represents an increase of $50.7\%$ and $22.3\%$ on results achieved by the readily available State-of-the-Art tools. The Taggus pipeline is publicly available to encourage development in this field for the Portuguese language.

Abstract: Automatically identifying characters and their interactions from fiction
books is, arguably, a complex task that requires pipelines that leverage
multiple Natural Language Processing (NLP) methods, such as Named Entity
Recognition (NER) and Part-of-speech (POS) tagging. However, these methods are
not optimized for the task that leads to the construction of Social Networks of
Characters. Indeed, the currently available methods tend to underperform,
especially in less-represented languages, due to a lack of manually annotated
data for training. Here, we propose a pipeline, which we call Taggus, to
extract social networks from literary fiction works in Portuguese. Our results
show that compared to readily available State-of-the-Art tools -- off-the-shelf
NER tools and Large Language Models (ChatGPT) -- the resulting pipeline, which
uses POS tagging and a combination of heuristics, achieves satisfying results
with an average F1-Score of $94.1\%$ in the task of identifying characters and
solving for co-reference and $75.9\%$ in interaction detection. These
represent, respectively, an increase of $50.7\%$ and $22.3\%$ on results
achieved by the readily available State-of-the-Art tools. Further steps to
improve results are outlined, such as solutions for detecting relationships
between characters. Limitations on the size and scope of our testing samples
are acknowledged. The Taggus pipeline is publicly available to encourage
development in this field for the Portuguese language.2

</details>


### [17] [Analyzing German Parliamentary Speeches: A Machine Learning Approach for Topic and Sentiment Classification](https://arxiv.org/abs/2508.03181)
*Lukas Pätz,Moritz Beyer,Jannik Späth,Lasse Bohlen,Patrick Zschech,Mathias Kraus,Julian Rosenberger*

Main category: cs.CL

TL;DR: ML analysis of Bundestag speeches reveals how party roles (government vs. opposition) shape discourse, with high accuracy in topic and sentiment classification.


<details>
  <summary>Details</summary>
Motivation: investigating political discourse in the German parliament (Bundestag) to understand topic trends, sentiment dynamics, and party-specific discourse strategies.

Method: machine learning models for topic and sentiment classification trained on a manually labeled dataset of 28,000 parliamentary speeches.

Result: models achieved AUROCs of 0.94 for topic classification and 0.89 for sentiment classification; analysis reveals relationships between parties and their parliamentary roles.

Conclusion: governing responsibilities shape discourse in the Bundestag, with changes observed as parties transition between government and opposition.

Abstract: This study investigates political discourse in the German parliament, the
Bundestag, by analyzing approximately 28,000 parliamentary speeches from the
last five years. Two machine learning models for topic and sentiment
classification were developed and trained on a manually labeled dataset. The
models showed strong classification performance, achieving an area under the
receiver operating characteristic curve (AUROC) of 0.94 for topic
classification (average across topics) and 0.89 for sentiment classification.
Both models were applied to assess topic trends and sentiment distributions
across political parties and over time. The analysis reveals remarkable
relationships between parties and their role in parliament. In particular, a
change in style can be observed for parties moving from government to
opposition. While ideological positions matter, governing responsibilities also
shape discourse. The analysis directly addresses key questions about the
evolution of topics, sentiment dynamics, and party-specific discourse
strategies in the Bundestag.

</details>


### [18] [fact check AI at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-checked Claim Retrieval](https://arxiv.org/abs/2508.03475)
*Pranshu Rastogi*

Main category: cs.CL

TL;DR: 使用 bi-encoder 模型进行多语言和跨语言事实检查声明检索，在 Kaggle T4 GPU 上训练的轻量级模型在多语言中实现了 92% 的 Success@10，在跨语言中实现了 80% 的 Success@10。


<details>
  <summary>Details</summary>
Motivation: SemEval-2025 Task 7：多语言和跨语言事实检查声明检索。

Method: 使用 bi-encoder 模型，该模型从针对句子相似性优化的预训练 Transformer 中进行微调，将 SemEval-2025 Task 7：多语言和跨语言事实检查声明检索作为 Learning-to-Rank 任务处理。

Result: 使用少于 5 亿个参数的轻量级模型并在 Kaggle T4 GPU 上进行训练，该方法在多语言中实现了 92% 的 Success@10，在跨语言中排名第 5，在多语言中排名第 10。

Conclusion: 该方法在多语言中实现了 92% 的 Success@10，在跨语言中实现了 80% 的 Success@10。

Abstract: SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim
Retrieval is approached as a Learning-to-Rank task using a bi-encoder model
fine-tuned from a pre-trained transformer optimized for sentence similarity.
Training used both the source languages and their English translations for
multilingual retrieval and only English translations for cross-lingual
retrieval. Using lightweight models with fewer than 500M parameters and
training on Kaggle T4 GPUs, the method achieved 92% Success@10 in multilingual
and 80% Success@10 in 5th in crosslingual and 10th in multilingual tracks.

</details>


### [19] [Beyond Content: How Grammatical Gender Shapes Visual Representation in Text-to-Image Models](https://arxiv.org/abs/2508.03199)
*Muhammed Saeed,Shaina Raza,Ashmal Vayani,Muhammad Abdul-Mageed,Ali Emami,Shady Shehata*

Main category: cs.CL

TL;DR: 该研究表明，语法性别会影响文本到图像模型中图像的生成，阳性语法标记会增加男性表征，而阴性语法标记会增加女性表征。


<details>
  <summary>Details</summary>
Motivation: 文本到图像 (T2I) 模型中的偏见研究主要集中在人口统计学表征和刻板印象属性上，忽略了一个基本问题：语法性别如何在不同语言中影响视觉表征？

Method: 引入了一个跨语言基准，该基准检查了语法性别与刻板性别关联相矛盾的词语。该数据集跨越五种有性别的语言（法语、西班牙语、德语、意大利语、俄语）和两种性别中立的控制语言（英语、中文），包含 800 个独特的提示，这些提示在三种最先进的 T2I 模型中生成了 28,800 张图像。

Result: 语法性别会显着影响图像生成：阳性语法标记平均将男性表征提高到 73%（相比之下，性别中立的英语为 22%），而阴性语法标记将女性表征提高到 38%（相比之下，英语为 28%）。这些影响因语言资源可用性和模型架构而异，高资源语言显示出更强的影响。

Conclusion: 语言结构本身（而不仅仅是内容）会影响 AI 生成的视觉输出，从而为理解多语言、多模态系统中的偏见和公平性引入了一个新的维度。

Abstract: Research on bias in Text-to-Image (T2I) models has primarily focused on
demographic representation and stereotypical attributes, overlooking a
fundamental question: how does grammatical gender influence visual
representation across languages? We introduce a cross-linguistic benchmark
examining words where grammatical gender contradicts stereotypical gender
associations (e.g., ``une sentinelle'' - grammatically feminine in French but
referring to the stereotypically masculine concept ``guard''). Our dataset
spans five gendered languages (French, Spanish, German, Italian, Russian) and
two gender-neutral control languages (English, Chinese), comprising 800 unique
prompts that generated 28,800 images across three state-of-the-art T2I models.
Our analysis reveals that grammatical gender dramatically influences image
generation: masculine grammatical markers increase male representation to 73\%
on average (compared to 22\% with gender-neutral English), while feminine
grammatical markers increase female representation to 38\% (compared to 28\% in
English). These effects vary systematically by language resource availability
and model architecture, with high-resource languages showing stronger effects.
Our findings establish that language structure itself, not just content, shapes
AI-generated visual outputs, introducing a new dimension for understanding bias
and fairness in multilingual, multimodal systems.

</details>


### [20] [Are We on the Right Way for Assessing Document Retrieval-Augmented Generation?](https://arxiv.org/abs/2508.03644)
*Wenxuan Shen,Mingjia Wang,Yaochen Wang,Dongping Chen,Junjie Yang,Yao Wan,Weiwei Lin*

Main category: cs.CL

TL;DR: 提出了Double-Bench，一个新的大型、多语言和多模态评估系统，用于评估文档RAG系统。


<details>
  <summary>Details</summary>
Motivation: 当前基准通常侧重于文档RAG系统的特定部分，并使用具有不完整的ground truth和证据标签的合成数据，因此无法反映现实世界的瓶颈和挑战。

Method: 引入Double-Bench：一种新的大型、多语言和多模态评估系统，能够对文档RAG系统中每个组件进行细粒度评估。它包含3,276份文档（72,880页）和5,168个跨6种语言和4种文档类型的单跳和多跳查询，并为潜在的数据污染问题提供简化的动态更新支持。查询以详尽扫描的证据页面为基础，并由人工专家验证，以确保最高的质量和完整性。

Result: 跨9个最先进的嵌入模型、4个MLLM和4个端到端文档RAG框架的全面实验表明，文本和视觉嵌入模型之间的差距正在缩小，突出了构建更强大的文档检索模型的需求。

Conclusion: Double-Bench的全面实验揭示了文本和视觉嵌入模型之间的差距正在缩小，突出了构建更强大的文档检索模型的需求。研究结果还揭示了当前文档RAG框架中的过度自信困境，即使没有证据支持，也倾向于提供答案。希望完全开源的Double-Bench为未来高级文档RAG系统的研究提供严谨的基础。计划检索及时的语料库，并每年发布新的基准。

Abstract: Retrieval-Augmented Generation (RAG) systems using Multimodal Large Language
Models (MLLMs) show great promise for complex document understanding, yet their
development is critically hampered by inadequate evaluation. Current benchmarks
often focus on specific part of document RAG system and use synthetic data with
incomplete ground truth and evidence labels, therefore failing to reflect
real-world bottlenecks and challenges. To overcome these limitations, we
introduce Double-Bench: a new large-scale, multilingual, and multimodal
evaluation system that is able to produce fine-grained assessment to each
component within document RAG systems. It comprises 3,276 documents (72,880
pages) and 5,168 single- and multi-hop queries across 6 languages and 4
document types with streamlined dynamic update support for potential data
contamination issues. Queries are grounded in exhaustively scanned evidence
pages and verified by human experts to ensure maximum quality and completeness.
Our comprehensive experiments across 9 state-of-the-art embedding models, 4
MLLMs and 4 end-to-end document RAG frameworks demonstrate the gap between text
and visual embedding models is narrowing, highlighting the need in building
stronger document retrieval models. Our findings also reveal the
over-confidence dilemma within current document RAG frameworks that tend to
provide answer even without evidence support. We hope our fully open-source
Double-Bench provide a rigorous foundation for future research in advanced
document RAG systems. We plan to retrieve timely corpus and release new
benchmarks on an annual basis.

</details>


### [21] [Current State in Privacy-Preserving Text Preprocessing for Domain-Agnostic NLP](https://arxiv.org/abs/2508.03204)
*Abhirup Sinha,Pritilata Saha,Tithi Saha*

Main category: cs.CL

TL;DR: 大型语言模型包含私人信息，可以提取。本报告重点介绍了用于领域无关 NLP 任务的几种匿名化方法。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型需要大量数据来学习语言变异，而这些数据通常包含私人信息。研究表明，可以从此类语言模型中提取私人信息。因此，匿名化此类私人和敏感信息至关重要。

Method: 预处理方法，用于屏蔽或假名化文本数据中的私有信息。

Result: 研究表明可以从大型语言模型中提取私人信息。

Conclusion: 本报告重点介绍了用于领域无关 NLP 任务的几种此类方法。

Abstract: Privacy is a fundamental human right. Data privacy is protected by different
regulations, such as GDPR. However, modern large language models require a huge
amount of data to learn linguistic variations, and the data often contains
private information. Research has shown that it is possible to extract private
information from such language models. Thus, anonymizing such private and
sensitive information is of utmost importance. While complete anonymization may
not be possible, a number of different pre-processing approaches exist for
masking or pseudonymizing private information in textual data. This report
focuses on a few of such approaches for domain-agnostic NLP tasks.

</details>


### [22] [Probing Syntax in Large Language Models: Successes and Remaining Challenges](https://arxiv.org/abs/2508.03211)
*Pablo J. Diego-Simón,Emmanuel Chemla,Jean-Rémi King,Yair Lakretz*

Main category: cs.CL

TL;DR: structural probes in LLMs are biased and struggle with deep syntax, but are unaffected by word predictability.


<details>
  <summary>Details</summary>
Motivation: it remains unclear whether structural and/or statistical factors systematically affect the syntactic representations in LLMs.

Method: in-depth analysis of structural probes on three controlled benchmarks

Result: structural probes are biased by word proximity, challenged by linguistic properties, and not affected by word predictability.

Conclusion: structural probes face challenges in representing deep syntactic structures and are biased by superficial properties like word proximity, but are not affected by word predictability.

Abstract: The syntactic structures of sentences can be readily read-out from the
activations of large language models (LLMs). However, the ``structural probes''
that have been developed to reveal this phenomenon are typically evaluated on
an indiscriminate set of sentences. Consequently, it remains unclear whether
structural and/or statistical factors systematically affect these syntactic
representations. To address this issue, we conduct an in-depth analysis of
structural probes on three controlled benchmarks. Our results are three-fold.
First, structural probes are biased by a superficial property: the closer two
words are in a sentence, the more likely structural probes will consider them
as syntactically linked. Second, structural probes are challenged by linguistic
properties: they poorly represent deep syntactic structures, and get interfered
by interacting nouns or ungrammatical verb forms. Third, structural probes do
not appear to be affected by the predictability of individual words. Overall,
this work sheds light on the current challenges faced by structural probes.
Providing a benchmark made of controlled stimuli to better evaluate their
performance.

</details>


### [23] [CardiffNLP at CLEARS-2025: Prompting Large Language Models for Plain Language and Easy-to-Read Text Rewriting](https://arxiv.org/abs/2508.03240)
*Mutaz Ayesh,Nicolás Gutiérrez-Rolón,Fernando Alva-Manchego*

Main category: cs.CL

TL;DR: CardiffNLP 团队使用 LLM 提示方法参加了 IberLEF 2025 CLEARS 西班牙语文本改编共享任务，并在两个子任务中分别获得第三名和第二名。


<details>
  <summary>Details</summary>
Motivation: 本文介绍了 CardiffNLP 团队对 IberLEF 2025 CLEARS 西班牙语文本改编共享任务的贡献。

Method: 该团队采用了基于 LLM 提示的方法，并尝试了不同的提示变体。最初尝试了 LLaMA-3.2，最终使用 Gemma-3 提交。

Result: 该团队在子任务 1 中获得第三名，在子任务 2 中获得第二名。

Conclusion: CardiffNLP 团队在 IberLEF 2025 CLEARS 西班牙语文本改编共享任务中，在两个子任务中均取得了不错的成绩（子任务 1 第三名，子任务 2 第二名）。

Abstract: This paper details the CardiffNLP team's contribution to the CLEARS shared
task on Spanish text adaptation, hosted by IberLEF 2025. The shared task
contained two subtasks and the team submitted to both. Our team took an
LLM-prompting approach with different prompt variations. While we initially
experimented with LLaMA-3.2, we adopted Gemma-3 for our final submission, and
landed third place in Subtask 1 and second place in Subtask 2. We detail our
numerous prompt variations, examples, and experimental results.

</details>


### [24] [Somatic in the East, Psychological in the West?: Investigating Clinically-Grounded Cross-Cultural Depression Symptom Expression in LLMs](https://arxiv.org/abs/2508.03247)
*Shintaro Sakai,Jisun An,Migyeong Kang,Haewoon Kwak*

Main category: cs.CL

TL;DR: LLM在心理健康应用中缺乏文化感知能力，无法区分东西方抑郁症患者的症状差异。


<details>
  <summary>Details</summary>
Motivation: 先前的临床心理学研究表明，西方抑郁症患者倾向于报告心理症状，而东方抑郁症患者报告躯体症状。心理健康领域越来越多地使用大型语言模型(LLM)。

Method: 通过提示LLM扮演西方或东方角色来测试LLM是否能重现这些文化模式。

Result: 结果表明，虽然使用主要东方语言（即中文、日文和印地语）进行提示可以在某些配置中改善一致性，但用英语提示时，LLM在很大程度上未能重现这些模式。分析表明，模型对文化角色不敏感，并且存在强大的、文化不变的症状等级结构，从而覆盖了文化线索。

Conclusion: 当前通用LLM缺乏安全有效的心理健康应用所需强大的文化感知能力。

Abstract: Prior clinical psychology research shows that Western individuals with
depression tend to report psychological symptoms, while Eastern individuals
report somatic ones. We test whether Large Language Models (LLMs), which are
increasingly used in mental health, reproduce these cultural patterns by
prompting them with Western or Eastern personas. Results show that LLMs largely
fail to replicate the patterns when prompted in English, though prompting in
major Eastern languages (i.e., Chinese, Japanese, and Hindi) improves alignment
in several configurations. Our analysis pinpoints two key reasons for this
failure: the models' low sensitivity to cultural personas and a strong,
culturally invariant symptom hierarchy that overrides cultural cues. These
findings reveal that while prompt language is important, current
general-purpose LLMs lack the robust, culture-aware capabilities essential for
safe and effective mental health applications.

</details>


### [25] [RooseBERT: A New Deal For Political Language Modelling](https://arxiv.org/abs/2508.03250)
*Deborah Dore,Elena Cabrio,Serena Villata*

Main category: cs.CL

TL;DR: RooseBERT是一种用于政治语篇语言的新型预训练语言模型，它在政治辩论分析中优于通用语言模型。


<details>
  <summary>Details</summary>
Motivation: 越来越多的政治辩论和与政治相关的讨论需要定义新的计算方法来自动分析这些内容，最终目标是启发公民进行政治审议。然而，政治语言的特殊性和这些辩论的论证形式（采用隐藏的沟通策略和利用隐含的论点）使得这项任务非常具有挑战性，即使对于当前通用的预训练语言模型也是如此。

Method: 我们介绍了一种名为RooseBERT的新的政治语篇语言预训练语言模型。RooseBERT已经在大型政治辩论和演讲语料库（8K辩论，每个辩论由关于不同主题的几个子辩论组成）上进行了训练。

Result: 我们的结果表明，在与政治辩论分析相关的四个下游任务（即，命名实体识别，情感分析，论证成分检测和分类以及论证关系预测和分类）中，RooseBERT的性能优于通用语言模型。

Conclusion: RooseBERT在四个政治辩论分析下游任务中表现出显著改进，表明特定领域的预训练可以提高政治辩论分析的性能。我们为研究团体发布了RooseBERT语言模型。

Abstract: The increasing amount of political debates and politics-related discussions
calls for the definition of novel computational methods to automatically
analyse such content with the final goal of lightening up political
deliberation to citizens. However, the specificity of the political language
and the argumentative form of these debates (employing hidden communication
strategies and leveraging implicit arguments) make this task very challenging,
even for current general-purpose pre-trained Language Models. To address this
issue, we introduce a novel pre-trained Language Model for political discourse
language called RooseBERT. Pre-training a language model on a specialised
domain presents different technical and linguistic challenges, requiring
extensive computational resources and large-scale data. RooseBERT has been
trained on large political debate and speech corpora (8K debates, each composed
of several sub-debates on different topics) in English. To evaluate its
performances, we fine-tuned it on four downstream tasks related to political
debate analysis, i.e., named entity recognition, sentiment analysis, argument
component detection and classification, and argument relation prediction and
classification. Our results demonstrate significant improvements over
general-purpose Language Models on these four tasks, highlighting how
domain-specific pre-training enhances performance in political debate analysis.
We release the RooseBERT language model for the research community.

</details>


### [26] [Exploring Stability-Plasticity Trade-offs for Continual Named Entity Recognition](https://arxiv.org/abs/2508.03259)
*Duzhen Zhang,Chenxing Li,Jiahua Dong,Qi Liu,Dong Yu*

Main category: cs.CL

TL;DR: 提出了一种用于CNER的稳定性-可塑性权衡（SPT）方法，该方法通过合并表示维度并动态合并新旧模型的权重来平衡稳定性和可塑性。


<details>
  <summary>Details</summary>
Motivation: 以前的CNER方法主要利用知识蒸馏（KD）来保存先验知识并克服灾难性遗忘，严格确保旧模型和新模型的表示保持一致。因此，它们通常赋予模型过度的稳定性（即保留旧知识），但可塑性有限（即获取新知识）。

Method: 从表示和权重两个角度平衡稳定性和可塑性。从表示的角度来看，我们将池化操作引入到原始KD中，允许通过合并表示维度来实现一定程度的可塑性。从权重的角度来看，我们动态地合并新旧模型的权重，加强旧知识，同时保持新知识。在此融合过程中，我们实现了一种权重引导的选择机制，以优先考虑重要权重。此外，我们为当前的非实体类型开发了一种基于置信度的伪标记方法，该方法使用旧模型预测实体类型，以处理非实体类型的语义转换，这是CNER特有的挑战，而以前的方法在很大程度上忽略了这一挑战。

Result: 在三个基准数据集上的十个CNER设置中进行的大量实验表明，我们的SPT方法超过了以前的CNER方法，突出了其在实现适当的稳定性-可塑性权衡方面的有效性。

Conclusion: SPT方法在持续命名实体识别（CNER）中优于以前的方法，因为它在实现适当的稳定性和可塑性权衡方面是有效的。

Abstract: Continual Named Entity Recognition (CNER) is an evolving field that focuses
on sequentially updating an existing model to incorporate new entity types.
Previous CNER methods primarily utilize Knowledge Distillation (KD) to preserve
prior knowledge and overcome catastrophic forgetting, strictly ensuring that
the representations of old and new models remain consistent. Consequently, they
often impart the model with excessive stability (i.e., retention of old
knowledge) but limited plasticity (i.e., acquisition of new knowledge). To
address this issue, we propose a Stability-Plasticity Trade-off (SPT) method
for CNER that balances these aspects from both representation and weight
perspectives. From the representation perspective, we introduce a pooling
operation into the original KD, permitting a level of plasticity by
consolidating representation dimensions. From the weight perspective, we
dynamically merge the weights of old and new models, strengthening old
knowledge while maintaining new knowledge. During this fusion, we implement a
weight-guided selective mechanism to prioritize significant weights. Moreover,
we develop a confidence-based pseudo-labeling approach for the current
non-entity type, which predicts entity types using the old model to handle the
semantic shift of the non-entity type, a challenge specific to CNER that has
largely been ignored by previous methods. Extensive experiments across ten CNER
settings on three benchmark datasets demonstrate that our SPT method surpasses
previous CNER approaches, highlighting its effectiveness in achieving a
suitable stability-plasticity trade-off.

</details>


### [27] [Pay What LLM Wants: Can LLM Simulate Economics Experiment with 522 Real-human Persona?](https://arxiv.org/abs/2508.03262)
*Junhyuk Choi,Hyeonchu Park,Haemin Lee,Hyebeen Shin,Hyun Joung Jin,Bugeun Kim*

Main category: cs.CL

TL;DR: LLMs在模拟个体经济行为方面存在局限性，但可以模拟群体行为。


<details>
  <summary>Details</summary>
Motivation: 大多数研究依赖于虚构的人物角色而不是实际的人类数据。我们通过评估LLM使用真实522个人物角色的Pay-What-You-Want (PWYW)定价实验来预测个体经济决策的能力，从而解决这一局限性。

Method: 使用来自522名韩国参与者在文化消费场景中的详细人物信息，系统地比较了三种最先进的多模态LLM。

Result: LLMs在精确的个体层面预测方面表现不佳，但在合理的群体层面行为倾向方面表现出一定的能力。常用的prompting技术并不比简单的prompting方法好；个人叙事的重建和检索增强生成对简单的prompting方法没有明显的提升。

Conclusion: LLMs在精确的个体层面预测方面表现不佳，但在合理的群体层面行为倾向方面表现出一定的能力。常用的prompting技术并不比简单的prompting方法好；个人叙事的重建和检索增强生成对简单的prompting方法没有明显的提升。

Abstract: Recent advances in Large Language Models (LLMs) have generated significant
interest in their capacity to simulate human-like behaviors, yet most studies
rely on fictional personas rather than actual human data. We address this
limitation by evaluating LLMs' ability to predict individual economic
decision-making using Pay-What-You-Want (PWYW) pricing experiments with real
522 human personas. Our study systematically compares three state-of-the-art
multimodal LLMs using detailed persona information from 522 Korean participants
in cultural consumption scenarios. We investigate whether LLMs can accurately
replicate individual human choices and how persona injection methods affect
prediction performance. Results reveal that while LLMs struggle with precise
individual-level predictions, they demonstrate reasonable group-level
behavioral tendencies. Also, we found that commonly adopted prompting
techniques are not much better than naive prompting methods; reconstruction of
personal narrative nor retrieval augmented generation have no significant gain
against simple prompting method. We believe that these findings can provide the
first comprehensive evaluation of LLMs' capabilities on simulating economic
behavior using real human data, offering empirical guidance for persona-based
simulation in computational social science.

</details>


### [28] [LECTOR: LLM-Enhanced Concept-based Test-Oriented Repetition for Adaptive Spaced Learning](https://arxiv.org/abs/2508.03275)
*Jiahao Zhao*

Main category: cs.CL

TL;DR: LECTOR is a novel adaptive scheduling algorithm that uses LLMs to improve learning and memory retention.


<details>
  <summary>Details</summary>
Motivation: Existing spaced repetition algorithms often struggle with semantic interference and personalized adaptation.

Method: LECTOR leverages large language models for semantic analysis while incorporating personalized learning profiles, addressing the critical challenge of semantic confusion in vocabulary learning by utilizing LLM-powered semantic similarity assessment and integrating it with established spaced repetition principles.

Result: LECTOR achieves a 90.2% success rate compared to 88.4% for the best baseline (SSP-MMC), representing a 2.0% relative improvement. The algorithm shows particular strength in handling semantically similar concepts, reducing confusion-induced errors while maintaining computational efficiency.

Conclusion: The results establish LECTOR as a promising direction for intelligent tutoring systems and adaptive learning platforms.

Abstract: Spaced repetition systems are fundamental to efficient learning and memory
retention, but existing algorithms often struggle with semantic interference
and personalized adaptation. We present LECTOR (\textbf{L}LM-\textbf{E}nhanced
\textbf{C}oncept-based \textbf{T}est-\textbf{O}riented \textbf{R}epetition), a
novel adaptive scheduling algorithm specifically designed for test-oriented
learning scenarios, particularly language examinations where success rate is
paramount. LECTOR leverages large language models for semantic analysis while
incorporating personalized learning profiles, addressing the critical challenge
of semantic confusion in vocabulary learning by utilizing LLM-powered semantic
similarity assessment and integrating it with established spaced repetition
principles. Our comprehensive evaluation against six baseline algorithms
(SSP-MMC, SM2, HLR, FSRS, ANKI, THRESHOLD) across 100 simulated learners over
100 days demonstrates significant improvements: LECTOR achieves a 90.2\%
success rate compared to 88.4\% for the best baseline (SSP-MMC), representing a
2.0\% relative improvement. The algorithm shows particular strength in handling
semantically similar concepts, reducing confusion-induced errors while
maintaining computational efficiency. Our results establish LECTOR as a
promising direction for intelligent tutoring systems and adaptive learning
platforms.

</details>


### [29] [Do language models accommodate their users? A study of linguistic convergence](https://arxiv.org/abs/2508.03276)
*Terra Blevins,Susanne Schmalwieser,Benjamin Roth*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型是否会像人类一样趋同于用户的语言模式。研究发现，模型会强烈趋同于对话风格，但与人类的趋同方式不同。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）通常被认为是精通生成语言的，但它们在多大程度上与人类的语言使用相似，这一点仍未得到充分研究。在本文中，我们测试模型是否表现出语言趋同，这是人类语言交流的核心语用要素，询问：模型是否适应或趋同于其用户的语言模式？

Method: 系统地比较了现有对话的模型补全与原始人类响应在16个语言模型、3个对话语料库和各种文体特征上的差异。

Result: 模型强烈趋同于对话的风格，相对于人类基线通常过度拟合。虽然收敛模式通常是特定于特征的，但我们观察到跨建模设置的收敛的持续变化，指令调整和更大的模型比它们预训练的对应模型收敛得更少。

Conclusion: 模型在很大程度上趋同于对话的风格，相对于人类基线通常过度拟合。指令调整和更大的模型比它们预训练的对应模型收敛得更少。人类和模型收敛模式之间的差异，我们假设这些行为的潜在机制非常不同。

Abstract: While large language models (LLMs) are generally considered proficient in
generating language, how similar their language usage is to that of humans
remains understudied. In this paper, we test whether models exhibit linguistic
convergence, a core pragmatic element of human language communication, asking:
do models adapt, or converge, to the linguistic patterns of their user? To
answer this, we systematically compare model completions of exisiting dialogues
to the original human responses across sixteen language models, three dialogue
corpora, and a variety of stylometric features. We find that models strongly
converge to the conversation's style, often significantly overfitting relative
to the human baseline. While convergence patterns are often feature-specific,
we observe consistent shifts in convergence across modeling settings, with
instruction-tuned and larger models converging less than their pretrained
counterparts. Given the differences between human and model convergence
patterns, we hypothesize that the underlying mechanisms for these behaviors are
very different.

</details>


### [30] [Investigating Gender Bias in LLM-Generated Stories via Psychological Stereotypes](https://arxiv.org/abs/2508.03292)
*Shahed Masoudian,Gustavo Escobedo,Hannah Strauss,Markus Schedl*

Main category: cs.CL

TL;DR: 本研究通过心理学角度评估大型语言模型中的性别偏见，发现模型存在性别偏见，且与心理学刻板印象一致，模型越大偏见越明显。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）越来越多地应用于不同的应用，人们越来越关注它们在各种任务中放大性别偏见的可能性。以往的研究通常使用明确的性别线索作为反事实来探测性别偏见，或者在句子补全和简短的问答任务中研究它们。这些形式可能会忽略嵌入在较长内容的生成行为中的更隐性的偏见形式。

Method: 使用包含短篇故事的新数据集StereoBias-Stories，故事包含非条件提示或基于25种心理刻板印象的随机属性的条件提示，以及三个与任务相关的故事结尾来研究LLM中的性别偏见。

Result: (1) 模型在非条件提示下平均而言高度偏向男性，但以独立于性别刻板印象的属性为条件可以减轻这种偏见。(2) 组合与同一性别刻板印象相关的多个属性会加剧模型行为，其中男性属性会放大偏见，而女性属性会减轻偏见。(3) 模型偏差与用于分类的心理学基本事实相一致，并且一致性强度随模型大小而增加。

Conclusion: 大型语言模型（LLM）在各种任务中都存在性别偏见，并且这种偏见与心理学研究中的性别刻板印象相符，模型越大，这种一致性越强。

Abstract: As Large Language Models (LLMs) are increasingly used across different
applications, concerns about their potential to amplify gender biases in
various tasks are rising. Prior research has often probed gender bias using
explicit gender cues as counterfactual, or studied them in sentence completion
and short question answering tasks. These formats might overlook more implicit
forms of bias embedded in generative behavior of longer content. In this work,
we investigate gender bias in LLMs using gender stereotypes studied in
psychology (e.g., aggressiveness or gossiping) in an open-ended task of
narrative generation. We introduce a novel dataset called StereoBias-Stories
containing short stories either unconditioned or conditioned on (one, two, or
six) random attributes from 25 psychological stereotypes and three task-related
story endings. We analyze how the gender contribution in the overall story
changes in response to these attributes and present three key findings: (1)
While models, on average, are highly biased towards male in unconditioned
prompts, conditioning on attributes independent from gender stereotypes
mitigates this bias. (2) Combining multiple attributes associated with the same
gender stereotype intensifies model behavior, with male ones amplifying bias
and female ones alleviating it. (3) Model biases align with psychological
ground-truth used for categorization, and alignment strength increases with
model size. Together, these insights highlight the importance of
psychology-grounded evaluation of LLMs.

</details>


### [31] [NLP Methods May Actually Be Better Than Professors at Estimating Question Difficulty](https://arxiv.org/abs/2508.03294)
*Leonidas Zotos,Ivo Pascal de Jong,Matias Valdenegro-Toro,Andreea Ioana Sburlea,Malvina Nissim,Hedderik van Rijn*

Main category: cs.CL

TL;DR: 大型语言模型在预测考题难度方面优于教授，有监督学习使用LLM不确定性可以进一步提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 评估考题的难度对于开发好的考试至关重要，但教授并不总是擅长这项任务。

Method: 比较各种基于大型语言模型的方法与三位教授在估计神经网络和机器学习领域中学生正确回答是非题的百分比的能力。

Result: 教授区分简单和困难问题的能力有限，并且他们的表现不如直接要求Gemini 2.5解决此任务。然而，通过在监督学习环境中使用LLM解决问题的不确定性，我们获得了更好的结果，仅使用了42个训练样本。

Conclusion: 有监督学习使用LLM不确定性可以帮助教授更好地估计考题的难度，从而提高评估质量。

Abstract: Estimating the difficulty of exam questions is essential for developing good
exams, but professors are not always good at this task. We compare various
Large Language Model-based methods with three professors in their ability to
estimate what percentage of students will give correct answers on True/False
exam questions in the areas of Neural Networks and Machine Learning. Our
results show that the professors have limited ability to distinguish between
easy and difficult questions and that they are outperformed by directly asking
Gemini 2.5 to solve this task. Yet, we obtained even better results using
uncertainties of the LLMs solving the questions in a supervised learning
setting, using only 42 training samples. We conclude that supervised learning
using LLM uncertainty can help professors better estimate the difficulty of
exam questions, improving the quality of assessment.

</details>


### [32] [Towards Trustworthy Multimodal Moderation via Policy-Aligned Reasoning and Hierarchical Labeling](https://arxiv.org/abs/2508.03296)
*Anqi Li,Wenwei Jin,Jintao Tong,Pengda Qin,Weijia Li,Guo Lu*

Main category: cs.CL

TL;DR: Hi-Guard is a multimodal moderation framework with a hierarchical structure and policy-aligned decision paradigm that improves classification accuracy, generalization, and interpretability.


<details>
  <summary>Details</summary>
Motivation: Current moderation approaches largely rely on noisy, label-driven learning, lacking alignment with moderation rules and producing opaque decisions that hinder human review.

Method: Hi-Guard, a multimodal moderation framework that introduces a new policy-aligned decision paradigm with a hierarchical moderation pipeline and a hierarchical taxonomy, incorporating rule definitions into the model prompt and optimizing with Group Relative Policy Optimization (GRPO).

Result: Hi-Guard achieves superior classification accuracy, generalization, and interpretability in experiments and real-world deployment.

Conclusion: Hi-Guard achieves superior classification accuracy, generalization, and interpretability, paving the way toward scalable, transparent, and trustworthy content safety systems.

Abstract: Social platforms have revolutionized information sharing, but also
accelerated the dissemination of harmful and policy-violating content. To
ensure safety and compliance at scale, moderation systems must go beyond
efficiency and offer accuracy and interpretability. However, current approaches
largely rely on noisy, label-driven learning, lacking alignment with moderation
rules and producing opaque decisions that hinder human review. Therefore, we
propose Hierarchical Guard (Hi-Guard), a multimodal moderation framework that
introduces a new policy-aligned decision paradigm. The term "Hierarchical"
reflects two key aspects of our system design: (1) a hierarchical moderation
pipeline, where a lightweight binary model first filters safe content and a
stronger model handles fine-grained risk classification; and (2) a hierarchical
taxonomy in the second stage, where the model performs path-based
classification over a hierarchical taxonomy ranging from coarse to fine-grained
levels. To ensure alignment with evolving moderation policies, Hi-Guard
directly incorporates rule definitions into the model prompt. To further
enhance structured prediction and reasoning, we introduce a multi-level
soft-margin reward and optimize with Group Relative Policy Optimization (GRPO),
penalizing semantically adjacent misclassifications and improving explanation
quality. Extensive experiments and real-world deployment demonstrate that
Hi-Guard achieves superior classification accuracy, generalization, and
interpretability, paving the way toward scalable, transparent, and trustworthy
content safety systems. Code is available at:
https://github.com/lianqi1008/Hi-Guard.

</details>


### [33] [CTTS: Collective Test-Time Scaling](https://arxiv.org/abs/2508.03333)
*Zhende Song,Shengji Tang,Peng Ye,Jiayuan Fan,Tao Chen*

Main category: cs.CL

TL;DR: This paper explores Collective Test-Time Scaling (CTTS) and proposes CTTS-MM, a novel framework that leverages multi-agent and multi-reward-model collaboration for enhanced inference, achieving superior performance.


<details>
  <summary>Details</summary>
Motivation: Existing test-time scaling approaches rely on a single agent interacting with a reward model, constrained by limited capabilities. Collective-agent methods can break through the upper bound of single-agent systems.

Method: The paper designs three primary paradigms to investigate the optimal paradigm of CTTS: (1) single agent to multiple reward models (SA-MR); (2) multiple agents to single reward model (MA-SR); and (3) multiple agents to multiple reward models (MA-MR). It proposes Agent Collaboration Search (ACS) for multi-agent collaboration and Mixture of Reword Models (MoR) for multi-reward-model collaboration.

Result: MA-MR consistently achieves the best performance. The proposed CTTS-MM consistently obtains superior performance across seven mainstream benchmarks.

Conclusion: The proposed CTTS-MM framework, leveraging both multi-agent and multi-reward-model collaboration, achieves superior performance across seven mainstream benchmarks.

Abstract: Test-time scaling (TTS) has emerged as a promising research field for
enhancing the effectiveness of large language models (LLMs) without extra
training. However, most existing approaches, e.g., Best-of-N and
Self-Consistency rely on a single agent interacting with a reward model
(SA-SR), constrained by limited capabilities of a single test-time scaling
(STTS) paradigm. On the other hand, recent works demonstrate that
collective-agent methods can break through the upper bound of single-agent
systems by orchestrating diverse models. Thus, in this paper, we take a first
step towards exploring Collective Test-Time Scaling (CTTS). Consider the
different interaction types of single and multiple models, we design three
primary paradigms to investigate the optimal paradigm of CTTS: (1) single agent
to multiple reward models (SA-MR); (2) multiple agents to single reward model
(MA-SR); and (3) multiple agents to multiple reward models (MA-MR). Extensive
experiments demonstrate that MA-MR consistently achieves the best performance.
Based on this, we propose a novel framework named CTTS-MM that effectively
leverages both multi-agent and multi-reward-model collaboration for enhanced
inference. Specifically, for multi-agent collaboration, we propose an Agent
Collaboration Search (ACS), which searches for the most effective combination
of LLM agents from a large candidate pool; for multi-reward-model
collaboration, we propose Mixture of Reword Models (MoR), which consists of a
curated question pool and a Prior Reward model Ensemble Selection (PRES) to
select the optimal combinations of reward models via Pair-wise Reward Ranking
(PRR) metric. Experiments across seven mainstream benchmarks demonstrate that
the proposed CTTS-MM consistently obtains superior performance. Code will be
released at https://github.com/magent4aci/CTTS-MM.

</details>


### [34] [Thinking with Nothinking Calibration: A New In-Context Learning Paradigm in Reasoning Large Language Models](https://arxiv.org/abs/2508.03363)
*Haotian Wu,Bo Xu,Yao Shu,Menglin Yang,Chengwei Qin*

Main category: cs.CL

TL;DR: This paper introduces JointThinking, a new ICL paradigm that leverages the structured difference between two reasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy. It achieves comparable in-distribution performance to training-based SOTA method, while substantially outperforming on out-of-distribution tasks.


<details>
  <summary>Details</summary>
Motivation: While prior research has primarily focused on improving their training and inference strategies, their potential for in-context learning (ICL) remains largely underexplored. To fill this gap, we propose Thinking with Nothinking Calibration (JointThinking)

Method: Thinking with Nothinking Calibration (JointThinking), a new ICL paradigm that leverages the structured difference between two reasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.  prompts the model to generate two answers in parallel: one in Thinking mode and the other in Nothinking mode. A second round of Thinking is triggered only when the two initial responses are inconsistent, using a single prompt that incorporates the original question and both candidate answers.

Result: leveraging different reasoning modes consistently lowers the error rate and highlights the value of structural thinking diversity.

Conclusion: JointThinking significantly outperforms few-shot chain-of-thought (CoT) and majority voting with improved answer robustness. Moreover, It achieves comparable in-distribution performance to training-based SOTA method, while substantially outperforming on out-of-distribution tasks. the performance gap between actual and ideal reasoning narrows as model size increases in the second round of thinking, indicating the strong scalability of our approach.

Abstract: Reasoning large language models (RLLMs) have recently demonstrated remarkable
capabilities through structured and multi-step reasoning. While prior research
has primarily focused on improving their training and inference strategies,
their potential for in-context learning (ICL) remains largely underexplored. To
fill this gap, we propose Thinking with Nothinking Calibration (JointThinking),
a new ICL paradigm that leverages the structured difference between two
reasoning modes, i.e., Thinking and Nothinking, to improve reasoning accuracy.
Specifically, our method prompts the model to generate two answers in parallel:
one in Thinking mode and the other in Nothinking mode. A second round of
Thinking is triggered only when the two initial responses are inconsistent,
using a single prompt that incorporates the original question and both
candidate answers. Since such disagreement occurs infrequently (e.g., only 6\%
in GSM8K), our method performs just one round of reasoning in most cases,
resulting in minimal latency overhead. Extensive experiments across multiple
reasoning benchmarks demonstrate that JointThinking significantly outperforms
few-shot chain-of-thought (CoT) and majority voting with improved answer
robustness. Moreover, It achieves comparable in-distribution performance to
training-based SOTA method, while substantially outperforming on
out-of-distribution tasks. We further conduct a systematic analysis of the
calibration mechanism, showing that leveraging different reasoning modes
consistently lowers the error rate and highlights the value of structural
thinking diversity. Additionally, we observe that the performance gap between
actual and ideal reasoning narrows as model size increases in the second round
of thinking, indicating the strong scalability of our approach. Finally, we
discuss current limitations and outline promising directions for future ICL
research in RLLMs.

</details>


### [35] [ReDSM5: A Reddit Dataset for DSM-5 Depression Detection](https://arxiv.org/abs/2508.03399)
*Eliseo Bao,Anxo Pérez,Javier Parapar*

Main category: cs.CL

TL;DR: This paper introduces ReDSM5, a new Reddit corpus annotated for DSM-5 depression symptoms, and establishes baseline benchmarks for symptom classification and explanation generation.


<details>
  <summary>Details</summary>
Motivation: Existing computational approaches often label entire posts simply as depressed or not depressed, without linking language to specific criteria from the DSM-5, the standard clinical framework for diagnosing depression. This limits both clinical relevance and interpretability. Depression is a pervasive mental health condition that affects hundreds of millions of individuals worldwide, yet many cases remain undiagnosed due to barriers in traditional clinical access and pervasive stigma. Social media platforms, and Reddit in particular, offer rich, user-generated narratives that can reveal early signs of depressive symptomatology.

Method: We introduce ReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each exhaustively annotated at the sentence level by a licensed psychologist for the nine DSM-5 depression symptoms. For each label, the annotator also provides a concise clinical rationale grounded in DSM-5 methodology. We conduct an exploratory analysis of the collection, examining lexical, syntactic, and emotional patterns that characterize symptom expression in social media narratives.

Result: Compared to prior resources, ReDSM5 uniquely combines symptom-specific supervision with expert explanations, facilitating the development of models that not only detect depression but also generate human-interpretable reasoning.

Conclusion: We establish baseline benchmarks for both multi-label symptom classification and explanation generation, providing reference results for future research on detection and interpretability.

Abstract: Depression is a pervasive mental health condition that affects hundreds of
millions of individuals worldwide, yet many cases remain undiagnosed due to
barriers in traditional clinical access and pervasive stigma. Social media
platforms, and Reddit in particular, offer rich, user-generated narratives that
can reveal early signs of depressive symptomatology. However, existing
computational approaches often label entire posts simply as depressed or not
depressed, without linking language to specific criteria from the DSM-5, the
standard clinical framework for diagnosing depression. This limits both
clinical relevance and interpretability. To address this gap, we introduce
ReDSM5, a novel Reddit corpus comprising 1484 long-form posts, each
exhaustively annotated at the sentence level by a licensed psychologist for the
nine DSM-5 depression symptoms. For each label, the annotator also provides a
concise clinical rationale grounded in DSM-5 methodology. We conduct an
exploratory analysis of the collection, examining lexical, syntactic, and
emotional patterns that characterize symptom expression in social media
narratives. Compared to prior resources, ReDSM5 uniquely combines
symptom-specific supervision with expert explanations, facilitating the
development of models that not only detect depression but also generate
human-interpretable reasoning. We establish baseline benchmarks for both
multi-label symptom classification and explanation generation, providing
reference results for future research on detection and interpretability.

</details>


### [36] [Variety Is the Spice of Life: Detecting Misinformation with Dynamic Environmental Representations](https://arxiv.org/abs/2508.03420)
*Bing Wang,Ximing Li,Yiming Wang,Changchun Li,Jiaxu Cui,Renchu Guan,Bo Yang*

Main category: cs.CL

TL;DR: MISDER is proposed to address the problem of dynamically changing veracity of news articles in misinformation detection. It learns social environmental representations and uses a temporal model to predict future representations, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The static assumption of mainstream misinformation detection (MD) methods is often violated because the veracity of news articles may vacillate within the dynamically evolving social environment.

Method: A novel framework, MISDER, is proposed to learn social environmental representations for each period and employ a temporal model (LSTM, continuous dynamics equation, and pre-trained dynamics system) to predict the representation for future periods.

Result: MISDER outperforms various MD baselines across 2 prevalent datasets.

Conclusion: The experimental results demonstrate the effectiveness of the proposed MISDER model for misinformation detection.

Abstract: The proliferation of misinformation across diverse social media platforms has
drawn significant attention from both academic and industrial communities due
to its detrimental effects. Accordingly, automatically distinguishing
misinformation, dubbed as Misinformation Detection (MD), has become an
increasingly active research topic. The mainstream methods formulate MD as a
static learning paradigm, which learns the mapping between the content, links,
and propagation of news articles and the corresponding manual veracity labels.
However, the static assumption is often violated, since in real-world
scenarios, the veracity of news articles may vacillate within the dynamically
evolving social environment. To tackle this problem, we propose a novel
framework, namely Misinformation detection with Dynamic Environmental
Representations (MISDER). The basic idea of MISDER lies in learning a social
environmental representation for each period and employing a temporal model to
predict the representation for future periods. In this work, we specify the
temporal model as the LSTM model, continuous dynamics equation, and pre-trained
dynamics system, suggesting three variants of MISDER, namely MISDER-LSTM,
MISDER-ODE, and MISDER-PT, respectively. To evaluate the performance of MISDER,
we compare it to various MD baselines across 2 prevalent datasets, and the
experimental results can indicate the effectiveness of our proposed model.

</details>


### [37] [LLMs Have a Heart of Stone: Demystifying the Soft Thinking Ability of Large Reasoning Models](https://arxiv.org/abs/2508.03440)
*Junhong Wu,Jinliang Lu,Zixuan Ren,Ganqiang Hu,Zhi Wu,Dai Dai,Hua Wu*

Main category: cs.CL

TL;DR: LLMs 虽然具备软思考能力，但倾向于依赖最主要的信息，限制了推理路径的多样性。通过引入随机性，特别是 Gumbel-Softmax 技巧，可以有效提升软思考的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理模型通常依赖于生成离散 tokens，这可能会限制其表达能力。最近的进展旨在通过使大型语言模型 (LLM) 能够生成软的、抽象的 tokens 来解决这一限制，从而促进在连续概念空间内的推理。

Method: 通过使用一套探测技术检查模型的内部行为来探索各种 LLM 的“软思考”能力。

Result: LLMs 主要依赖于软输入中最有影响力的部分，这阻碍了不同推理路径的探索，并将 vanilla 软思考简化为一种贪婪解码的形式。引入随机性可以缓解 vanilla 方法的局限性并释放软思考的潜力。Gumbel-Softmax 技巧提供了足够的随机性与受控的平滑性，从而在八个推理基准测试中实现了卓越的性能。

Conclusion: LLMs在后续解码步骤中主要依赖于软输入中最有影响力的部分，这阻碍了不同推理路径的探索。引入随机性的抽样策略可以缓解 vanilla 方法的局限性，并释放软思考的潜力。Gumbel-Softmax 技巧提供了足够的随机性与受控的平滑性，从而在八个推理基准测试中实现了卓越的性能。

Abstract: Human cognition naturally engages with abstract and fluid concepts, whereas
existing reasoning models often rely on generating discrete tokens, potentially
constraining their expressive capabilities. Recent advancements aim to address
this limitation by enabling large language models (LLMs) to generate soft,
abstract tokens, thus facilitating reasoning within a continuous concept space.
This paper explores the `Soft Thinking' capabilities of various LLMs by
examining the models' internal behavior using a suite of probing techniques.
Contrary to the common belief that Soft Thinking enables the simultaneous
exploration of diverse reasoning paths, our findings reveal that LLMs
predominantly rely on the most influential component of the soft inputs during
subsequent decoding steps. This reliance hinders the exploration of different
reasoning paths and reduces vanilla Soft Thinking to a form of greedy decoding,
obscuring the advantage of transmitting more information through Soft Tokens.
To tackle this issue, we explore sampling strategies to introduce
\emph{randomness}, employing methods such as Dirichlet resampling and the
Gumbel-Softmax trick. Our experiments demonstrate that incorporating randomness
can alleviate the limitations of vanilla approaches and unleash the potential
of Soft Thinking. Notably, the Gumbel-Softmax trick provides adequate
randomness with controlled smoothness, resulting in superior performance across
eight reasoning benchmarks.

</details>


### [38] [Cropping outperforms dropout as an augmentation strategy for training self-supervised text embeddings](https://arxiv.org/abs/2508.03453)
*Rita González-Márquez,Philipp Berens,Dmitry Kobak*

Main category: cs.CL

TL;DR: 对比了对比学习中正对生成对的两种数据增强策略，发现裁剪增强优于基于 dropout 的方法，并且自监督微调可以在短时间内生成高质量的文本嵌入。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入在许多 NLP 应用中起着重要作用。目前，性能最佳的嵌入模型是通过使用精选的文本对进行广泛的监督微调，从预训练的语言模型中获得的。这与计算机视觉形成对比，在计算机视觉中，基于数据增强的自监督训练已显示出显著的成功。

Method: 对比学习中正对生成对使用两种数据增强策略，即裁剪增强和基于 dropout 的方法。

Result: 裁剪增强优于基于 dropout 的方法。在领域外数据上，生成的嵌入质量低于有监督的 SOTA 模型，但对于领域内数据，自监督微调可以在非常短的微调后生成高质量的文本嵌入。

Conclusion: 自监督微调可以在短时间内生成高质量的文本嵌入，有时仅略低于有监督的 SOTA。表示质量在最后一个 transformer 层中有所提高，并且仅微调最后几层就足以达到相似的嵌入质量。

Abstract: Text embeddings, i.e. vector representations of entire texts, play an
important role in many NLP applications, such as retrieval-augmented
generation, sentiment analysis, clustering, or visualizing collections of texts
for data exploration. Currently, top-performing embedding models are derived
from pre-trained language models via extensive supervised fine-tuning using
curated text pairs. This contrasts with computer vision, where self-supervised
training based on data augmentations has demonstrated remarkable success. Here
we systematically compare the two most well-known augmentation strategies for
positive pair generation in contrastive learning of text embeddings. We assess
embedding quality on MTEB and additional in-domain evaluations and show that
cropping augmentation strongly outperforms the dropout-based approach. We find
that on out-of-domain data, the quality of resulting embeddings is below the
supervised SOTA models, but for in-domain data, self-supervised fine-tuning
produces high-quality text embeddings after very short fine-tuning, sometimes
only marginally below the supervised SOTA. Finally, we show that representation
quality increases towards the last transformer layers, which undergo the
largest change during fine-tuning; and that fine-tuning only those last layers
is sufficient to reach similar embedding quality.

</details>


### [39] [CF-RAG: A Dataset and Method for Carbon Footprint QA Using Retrieval-Augmented Generation](https://arxiv.org/abs/2508.03489)
*Kaiwen Zhao,Bharathan Balaji,Stephen Lee*

Main category: cs.CL

TL;DR: 本文介绍了 CarbonPDF-QA，一个包含 1735 份产品报告文档的问答对的开源数据集，以及人工注释的答案。


<details>
  <summary>Details</summary>
Motivation: 产品可持续性报告提供了对产品环境影响的有价值的见解，通常以 PDF 格式分发。这些报告通常包括表格和文本的组合，这使得它们的分析变得复杂。缺乏标准化和报告格式的可变性进一步加剧了从大量文档中提取和解释相关信息的难度。

Method: 本文提出 CarbonPDF，一种基于 LLM 的技术，通过使用训练数据对 Llama 3 进行微调来开发，专门用于回答碳足迹问题。

Result: GPT-4o 难以回答数据不一致的问题。本文提出的 CarbonPDF 技术优于当前最先进的技术，包括在表格和文本数据上微调的问答 (QA) 系统。

Conclusion: 本文提出了一种名为 CarbonPDF 的基于 LLM 的技术，专门用于回答有关此类数据集上的碳足迹问题。通过使用我们的训练数据对 Llama 3 进行微调来开发 CarbonPDF。结果表明，该技术优于当前最先进的技术，包括在表格和文本数据上微调的问答 (QA) 系统。

Abstract: Product sustainability reports provide valuable insights into the
environmental impacts of a product and are often distributed in PDF format.
These reports often include a combination of tables and text, which complicates
their analysis. The lack of standardization and the variability in reporting
formats further exacerbate the difficulty of extracting and interpreting
relevant information from large volumes of documents. In this paper, we tackle
the challenge of answering questions related to carbon footprints within
sustainability reports available in PDF format. Unlike previous approaches, our
focus is on addressing the difficulties posed by the unstructured and
inconsistent nature of text extracted from PDF parsing. To facilitate this
analysis, we introduce CarbonPDF-QA, an open-source dataset containing
question-answer pairs for 1735 product report documents, along with
human-annotated answers. Our analysis shows that GPT-4o struggles to answer
questions with data inconsistencies. To address this limitation, we propose
CarbonPDF, an LLM-based technique specifically designed to answer carbon
footprint questions on such datasets. We develop CarbonPDF by fine-tuning Llama
3 with our training data. Our results show that our technique outperforms
current state-of-the-art techniques, including question-answering (QA) systems
finetuned on table and text data.

</details>


### [40] [UPLME: Uncertainty-Aware Probabilistic Language Modelling for Robust Empathy Regression](https://arxiv.org/abs/2508.03520)
*Md Rakibul Hasan,Md Zakir Hossain,Aneesh Krishna,Shafin Rahman,Tom Gedeon*

Main category: cs.CL

TL;DR: UPLME, a new uncertainty-aware probabilistic language model, improves empathy detection in noisy data.


<details>
  <summary>Details</summary>
Motivation: Supervised learning for empathy regression is challenged by noisy self-reported empathy scores, and the regression counterpart is relatively under-explored.

Method: The paper proposes UPLME, an uncertainty-aware probabilistic language modelling framework with variational model ensembling, and introduces two novel loss components: one penalising degenerate Uncertainty Quantification (UQ), and another enforcing the similarity between the input pairs.

Result: UPLME provides state-of-the-art performance (Pearson Correlation Coefficient: 0.558->0.580 and 0.629->0.634) and outperforms (Calibration error: 0.571->0.376) a recent variational model ensembling-based UQ method.

Conclusion: UPLME achieves state-of-the-art performance on two public benchmarks with noisy labels and outperforms a recent variational model ensembling-based UQ method.

Abstract: Supervised learning for empathy regression is challenged by noisy
self-reported empathy scores. While many algorithms have been proposed for
learning with noisy labels in textual classification problems, the regression
counterpart is relatively under-explored. We propose UPLME, an
uncertainty-aware probabilistic language modelling framework to capture label
noise in the regression setting of empathy detection. UPLME includes a
probabilistic language model that predicts both empathy score and
heteroscedastic uncertainty and is trained using Bayesian concepts with
variational model ensembling. We further introduce two novel loss components:
one penalises degenerate Uncertainty Quantification (UQ), and another enforces
the similarity between the input pairs on which we predict empathy. UPLME
provides state-of-the-art performance (Pearson Correlation Coefficient:
$0.558\rightarrow0.580$ and $0.629\rightarrow0.634$) in terms of the
performance reported in the literature in two public benchmarks, having label
noise. Through synthetic label noise injection, we show that UPLME is effective
in separating noisy and clean samples based on the predicted uncertainty. UPLME
further outperform (Calibration error: $0.571\rightarrow0.376$) a recent
variational model ensembling-based UQ method designed for regression problems.

</details>


### [41] [FilBench: Can LLMs Understand and Generate Filipino?](https://arxiv.org/abs/2508.03523)
*Lester James V. Miranda,Elyanah Aco,Conner Manuel,Jan Christian Blaise Cruz,Joseph Marvin Imperial*

Main category: cs.CL

TL;DR: FilBench, a new benchmark for evaluating LLMs on Filipino languages, reveals challenges in reading comprehension and translation for many models, even those trained for Southeast Asian languages.


<details>
  <summary>Details</summary>
Motivation: little is known about their capabilities in specific languages such as Filipino

Method: introducing FilBench, a Filipino-centric benchmark designed to evaluate LLMs across a diverse set of tasks and capabilities in Filipino, Tagalog, and Cebuano

Result: several LLMs suffer from reading comprehension and translation capabilities

Conclusion: FilBench is challenging, with the best model, GPT-4o, achieving only a score of 72.23%. Models trained specifically for Southeast Asian languages tend to underperform on FilBench.

Abstract: Despite the impressive performance of LLMs on English-based tasks, little is
known about their capabilities in specific languages such as Filipino. In this
work, we address this gap by introducing FilBench, a Filipino-centric benchmark
designed to evaluate LLMs across a diverse set of tasks and capabilities in
Filipino, Tagalog, and Cebuano. We carefully curate the tasks in FilBench to
reflect the priorities and trends of NLP research in the Philippines such as
Cultural Knowledge, Classical NLP, Reading Comprehension, and Generation. By
evaluating 27 state-of-the-art LLMs on FilBench, we find that several LLMs
suffer from reading comprehension and translation capabilities. Our results
indicate that FilBench is challenging, with the best model, GPT-4o, achieving
only a score of 72.23%. Moreover, we also find that models trained specifically
for Southeast Asian languages tend to underperform on FilBench, with the
highest-performing model, SEA-LION v3 70B, achieving only a score of 61.07%.
Our work demonstrates the value of curating language-specific LLM benchmarks to
aid in driving progress on Filipino NLP and increasing the inclusion of
Philippine languages in LLM development.

</details>


### [42] [Marito: Structuring and Building Open Multilingual Terminologies for South African NLP](https://arxiv.org/abs/2508.03529)
*Vukosi Marivate,Isheanesu Dzingirai,Fiskani Banda,Richard Lastrucci,Thapelo Sindane,Keabetswe Madumo,Kayode Olaleye,Abiodun Modupe,Unarine Netshifhefhe,Herkulaas Combrink,Mohlatlego Nakeng,Matome Ledwaba*

Main category: cs.CL

TL;DR: Marito addresses the challenge of fragmented terminology lists for South Africa's official languages by creating an open dataset and improving machine translation accuracy.


<details>
  <summary>Details</summary>
Motivation: critical lack of structured terminological data for South Africa's official languages hampers progress in multilingual NLP

Method: systematically aggregating, cleaning, and standardising scattered resources into open, interoperable datasets

Result: substantial improvements in the accuracy and domain-specific consistency of English-to-Tshivenḓa machine translation for large language models

Conclusion: Marito provides a scalable foundation for developing robust and equitable NLP technologies, ensuring South Africa's rich linguistic diversity is represented in the digital age.

Abstract: The critical lack of structured terminological data for South Africa's
official languages hampers progress in multilingual NLP, despite the existence
of numerous government and academic terminology lists. These valuable assets
remain fragmented and locked in non-machine-readable formats, rendering them
unusable for computational research and development. \emph{Marito} addresses
this challenge by systematically aggregating, cleaning, and standardising these
scattered resources into open, interoperable datasets. We introduce the
foundational \emph{Marito} dataset, released under the equitable,
Africa-centered NOODL framework. To demonstrate its immediate utility, we
integrate the terminology into a Retrieval-Augmented Generation (RAG) pipeline.
Experiments show substantial improvements in the accuracy and domain-specific
consistency of English-to-Tshivenda machine translation for large language
models. \emph{Marito} provides a scalable foundation for developing robust and
equitable NLP technologies, ensuring South Africa's rich linguistic diversity
is represented in the digital age.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [43] [PyCAT4: A Hierarchical Vision Transformer-based Framework for 3D Human Pose Estimation](https://arxiv.org/abs/2508.02806)
*Zongyou Yang,Jonathan Loo*

Main category: cs.CV

TL;DR: This paper optimizes the Pymaf network using Transformers and multi-scale feature fusion, leading to improved human pose estimation accuracy on COCO and 3DPW datasets.


<details>
  <summary>Details</summary>
Motivation: Significant accuracy improvements in 3D human pose estimation via CNNs with pyramid grid alignment feedback loops and breakthroughs in computer vision using Transformer-based temporal analysis architectures.

Method: Optimizing the Pymaf network architecture by introducing a Transformer feature extraction network layer, enhancing temporal signal understanding through feature temporal fusion, and implementing spatial pyramid structures for multi-scale feature fusion.

Result: Experiments on COCO and 3DPW datasets validate that the proposed improvement strategies significantly enhance the network's detection capability in human pose estimation.

Conclusion: The improved PyCAT4 model significantly enhances network detection capability in human pose estimation.

Abstract: Recently, a significant improvement in the accuracy of 3D human pose
estimation has been achieved by combining convolutional neural networks (CNNs)
with pyramid grid alignment feedback loops. Additionally, innovative
breakthroughs have been made in the field of computer vision through the
adoption of Transformer-based temporal analysis architectures. Given these
advancements, this study aims to deeply optimize and improve the existing Pymaf
network architecture. The main innovations of this paper include: (1)
Introducing a Transformer feature extraction network layer based on
self-attention mechanisms to enhance the capture of low-level features; (2)
Enhancing the understanding and capture of temporal signals in video sequences
through feature temporal fusion techniques; (3) Implementing spatial pyramid
structures to achieve multi-scale feature fusion, effectively balancing feature
representations differences across different scales. The new PyCAT4 model
obtained in this study is validated through experiments on the COCO and 3DPW
datasets. The results demonstrate that the proposed improvement strategies
significantly enhance the network's detection capability in human pose
estimation, further advancing the development of human pose estimation
technology.

</details>


### [44] [DreamVVT: Mastering Realistic Video Virtual Try-On in the Wild via a Stage-Wise Diffusion Transformer Framework](https://arxiv.org/abs/2508.02807)
*Tongchun Zuo,Zaiyu Huang,Shuliang Ning,Ente Lin,Chao Liang,Zerong Zheng,Jianwen Jiang,Yuan Zhang,Mingyuan Gao,Xin Dong*

Main category: cs.CV

TL;DR: DreamVVT是一个两阶段框架，它使用扩散转换器和视觉语言模型来提高视频虚拟试穿的准确性和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端方法严重依赖稀缺的以服装为中心的数据集，并且未能有效利用先进视觉模型和测试时输入的先验知识，因此难以准确地保留细粒度的服装细节，并保持非约束场景中的时间一致性。

Method: 一个精心设计的两阶段框架，建立在扩散转换器（DiTs）之上，利用多帧试穿模型与视觉语言模型（VLM）集成，合成高保真和语义一致的关键帧试穿图像。然后，将骨骼图与细粒度的运动和外观描述一起提取，并与关键帧试穿图像一起输入到预训练的视频生成模型中，该模型通过LoRA适配器增强。

Result: DreamVVT在保留服装细节和真实场景中的时间稳定性方面超越了现有方法。

Conclusion: DreamVVT在保留服装细节和时间稳定性方面优于现有方法。

Abstract: Video virtual try-on (VVT) technology has garnered considerable academic
interest owing to its promising applications in e-commerce advertising and
entertainment. However, most existing end-to-end methods rely heavily on scarce
paired garment-centric datasets and fail to effectively leverage priors of
advanced visual models and test-time inputs, making it challenging to
accurately preserve fine-grained garment details and maintain temporal
consistency in unconstrained scenarios. To address these challenges, we propose
DreamVVT, a carefully designed two-stage framework built upon Diffusion
Transformers (DiTs), which is inherently capable of leveraging diverse unpaired
human-centric data to enhance adaptability in real-world scenarios. To further
leverage prior knowledge from pretrained models and test-time inputs, in the
first stage, we sample representative frames from the input video and utilize a
multi-frame try-on model integrated with a vision-language model (VLM), to
synthesize high-fidelity and semantically consistent keyframe try-on images.
These images serve as complementary appearance guidance for subsequent video
generation. \textbf{In the second stage}, skeleton maps together with
fine-grained motion and appearance descriptions are extracted from the input
content, and these along with the keyframe try-on images are then fed into a
pretrained video generation model enhanced with LoRA adapters. This ensures
long-term temporal coherence for unseen regions and enables highly plausible
dynamic motions. Extensive quantitative and qualitative experiments demonstrate
that DreamVVT surpasses existing methods in preserving detailed garment content
and temporal stability in real-world scenarios. Our project page
https://virtu-lab.github.io/

</details>


### [45] [Elucidating the Role of Feature Normalization in IJEPA](https://arxiv.org/abs/2508.02829)
*Adam Colton*

Main category: cs.CV

TL;DR: feature normalization disrupts the natural energy hierarchy of visual tokens, the paper replace feature LN with a DynTanh activation


<details>
  <summary>Details</summary>
Motivation: feature normalization disrupts the natural energy hierarchy of visual tokens

Method: feature LN be replaced with a DynTanh activation

Result: improves ImageNet linear probe accuracy from 38% to 42.7% for ViT-Small and reduces RMSE by 0.08 on NYU Depth V2 monocular depth estimation

Conclusion: preserving natural token energies is crucial for effective self-supervised visual representation learning

Abstract: In the standard image joint embedding predictive architecture (IJEPA),
features at the output of the teacher encoder are layer normalized (LN) before
serving as a distillation target for the student encoder and predictor. We
propose that this feature normalization disrupts the natural energy hierarchy
of visual tokens, where high-energy tokens (those with larger L2 norms) encode
semantically important image regions. LN forces all features to have identical
L2 norms, effectively equalizing their energies and preventing the model from
prioritizing semantically rich regions. We find that IJEPA models trained with
feature LN exhibit loss maps with significant checkerboard-like artifacts. We
propose that feature LN be replaced with a DynTanh activation as the latter
better preserves token energies and allows high-energy tokens to greater
contribute to the prediction loss. We show that IJEPA trained with feature
DynTanh exhibits a longer-tailed loss distribution and fixes the checkerboard
artifacts in the loss map. Our empirical results show that our simple
modification improves ImageNet linear probe accuracy from 38% to 42.7% for
ViT-Small and reduces RMSE by 0.08 on NYU Depth V2 monocular depth estimation.
These results suggest that preserving natural token energies is crucial for
effective self-supervised visual representation learning.

</details>


### [46] [GENIE: Gaussian Encoding for Neural Radiance Fields Interactive Editing](https://arxiv.org/abs/2508.02831)
*Mikołaj Zieliński,Krzysztof Byrski,Tomasz Szczepanik,Przemysław Spurek*

Main category: cs.CV

TL;DR: GENIE结合了NeRF和GS的优点，实现了可交互编辑的神经渲染。


<details>
  <summary>Details</summary>
Motivation: NeRF通过神经网络学习体积表示来实现高保真度的新视角合成，但其隐式编码使得编辑和物理交互具有挑战性。GS将场景表示为高斯基元的显式集合，从而实现实时渲染、更快的训练和更直观的操作。这种显式结构使GS特别适合于交互式编辑和与基于物理的仿真集成。

Method: GENIE：一种混合模型，它结合了NeRF的光真实感渲染质量和GS的可编辑和结构化表示。为每个高斯分配一个可训练的特征嵌入，用于基于每个查询点的k个最近高斯来调节NeRF网络。引入了光线追踪高斯邻近搜索（RT-GPS），这是一种基于修改后的光线追踪管道的快速最近高斯搜索。还集成了一个多分辨率哈希网格来初始化和更新高斯特征。

Result: GENIE实现了实时、局部感知编辑：当高斯基元被重新定位或修改时，它们的插值影响会立即反映在渲染输出中。

Conclusion: GENIE结合了NeRF和GS的优势，支持直观的场景操作、动态交互以及与物理仿真的兼容性，弥合了几何编辑和神经渲染之间的差距。

Abstract: Neural Radiance Fields (NeRF) and Gaussian Splatting (GS) have recently
transformed 3D scene representation and rendering. NeRF achieves high-fidelity
novel view synthesis by learning volumetric representations through neural
networks, but its implicit encoding makes editing and physical interaction
challenging. In contrast, GS represents scenes as explicit collections of
Gaussian primitives, enabling real-time rendering, faster training, and more
intuitive manipulation. This explicit structure has made GS particularly
well-suited for interactive editing and integration with physics-based
simulation. In this paper, we introduce GENIE (Gaussian Encoding for Neural
Radiance Fields Interactive Editing), a hybrid model that combines the
photorealistic rendering quality of NeRF with the editable and structured
representation of GS. Instead of using spherical harmonics for appearance
modeling, we assign each Gaussian a trainable feature embedding. These
embeddings are used to condition a NeRF network based on the k nearest
Gaussians to each query point. To make this conditioning efficient, we
introduce Ray-Traced Gaussian Proximity Search (RT-GPS), a fast nearest
Gaussian search based on a modified ray-tracing pipeline. We also integrate a
multi-resolution hash grid to initialize and update Gaussian features.
Together, these components enable real-time, locality-aware editing: as
Gaussian primitives are repositioned or modified, their interpolated influence
is immediately reflected in the rendered output. By combining the strengths of
implicit and explicit representations, GENIE supports intuitive scene
manipulation, dynamic interaction, and compatibility with physical simulation,
bridging the gap between geometry-based editing and neural rendering. The code
can be found under (https://github.com/MikolajZielinski/genie)

</details>


### [47] [RefineSeg: Dual Coarse-to-Fine Learning for Medical Image Segmentation](https://arxiv.org/abs/2508.02844)
*Anghong Du,Nay Aung,Theodoros N. Arvanitis,Stefan K. Piechnik,Joao A C Lima,Steffen E. Petersen,Le Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的从粗到精的分割框架，该框架仅依赖于粗糙的注释，通过引入转移矩阵来逐步细化网络，并在三个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高质量的医学图像像素级注释对于有监督的分割任务至关重要，但是获得这种注释的成本很高，并且需要医学专业知识。为了解决这个挑战，我们提出了一种新颖的从粗到精的分割框架，该框架完全依赖于粗糙级别的注释，包括目标图和补充图，尽管它们具有固有的噪声。

Method: 该框架通过引入转移矩阵来对粗糙注释中不准确和不完整的区域进行建模。通过在多组粗糙注释上进行联合训练，它可以逐步细化网络的输出，并通过基于矩阵的建模推断出真实的分割分布，从而实现对精确标签的稳健近似。

Result: 所提出的方法优于目前最好的弱监督方法，并且可以与完全监督方法相媲美。

Conclusion: 该方法在ACDC、MSCMRseg和UK Biobank数据集上的实验结果表明，该方法优于目前最好的弱监督方法，并且可以与完全监督方法相媲美。

Abstract: High-quality pixel-level annotations of medical images are essential for
supervised segmentation tasks, but obtaining such annotations is costly and
requires medical expertise. To address this challenge, we propose a novel
coarse-to-fine segmentation framework that relies entirely on coarse-level
annotations, encompassing both target and complementary drawings, despite their
inherent noise. The framework works by introducing transition matrices in order
to model the inaccurate and incomplete regions in the coarse annotations. By
jointly training on multiple sets of coarse annotations, it progressively
refines the network's outputs and infers the true segmentation distribution,
achieving a robust approximation of precise labels through matrix-based
modeling. To validate the flexibility and effectiveness of the proposed method,
we demonstrate the results on two public cardiac imaging datasets, ACDC and
MSCMRseg, and further evaluate its performance on the UK Biobank dataset.
Experimental results indicate that our approach surpasses the state-of-the-art
weakly supervised methods and closely matches the fully supervised approach.

</details>


### [48] [MIDAR: Mimicking LiDAR Detection for Traffic Applications with a Lightweight Plug-and-Play Model](https://arxiv.org/abs/2508.02858)
*Tianheng Zhu,Yiheng Feng*

Main category: cs.CV

TL;DR: MIDAR is proposed to approximate realistic LiDAR detections using vehicle-level features from microscopic traffic simulators, bridging the gap between high-fidelity but unscalable game-engine-based simulators and efficient but perception-modeling-lacking microscopic traffic simulators.


<details>
  <summary>Details</summary>
Motivation: Game-engine-based simulators like CARLA generate high-fidelity raw sensor data but face scalability challenges in multi-AV scenarios. Microscopic traffic simulators such as SUMO scale efficiently but lack perception modeling capabilities. This paper aims to bridge this gap.

Method: MIDAR, a LiDAR detection mimicking model that approximates realistic LiDAR detections using vehicle-level features readily available from microscopic traffic simulators. A Refined Multi-hop Line-of-Sight (RM-LoS) graph is constructed to encode the occlusion relationships among vehicles, upon which MIDAR employs a GRU-enhanced APPNP architecture to propagate features from the ego AV and occluding vehicles to the prediction target.

Result: MIDAR achieves an AUC of 0.909 in approximating the detection results generated by CenterPoint. Two CP-based traffic applications further validate the necessity of such realistic detection modeling.

Conclusion: MIDAR achieves an AUC of 0.909 in approximating the detection results generated by CenterPoint on the nuScenes AD dataset. Two CP-based traffic applications further validate the necessity of such realistic detection modeling, particularly for tasks requiring accurate individual vehicle observations. MIDAR can be seamlessly integrated into traffic simulators and trajectory datasets and will be open-sourced upon publication.

Abstract: As autonomous driving (AD) technology advances, increasing research has
focused on leveraging cooperative perception (CP) data collected from multiple
AVs to enhance traffic applications. Due to the impracticality of large-scale
real-world AV deployments, simulation has become the primary approach in most
studies. While game-engine-based simulators like CARLA generate high-fidelity
raw sensor data (e.g., LiDAR point clouds) which can be used to produce
realistic detection outputs, they face scalability challenges in multi-AV
scenarios. In contrast, microscopic traffic simulators such as SUMO scale
efficiently but lack perception modeling capabilities. To bridge this gap, we
propose MIDAR, a LiDAR detection mimicking model that approximates realistic
LiDAR detections using vehicle-level features readily available from
microscopic traffic simulators. Specifically, MIDAR predicts true positives
(TPs) and false negatives (FNs) from ideal LiDAR detection results based on the
spatial layouts and dimensions of surrounding vehicles. A Refined Multi-hop
Line-of-Sight (RM-LoS) graph is constructed to encode the occlusion
relationships among vehicles, upon which MIDAR employs a GRU-enhanced APPNP
architecture to propagate features from the ego AV and occluding vehicles to
the prediction target. MIDAR achieves an AUC of 0.909 in approximating the
detection results generated by CenterPoint, a mainstream 3D LiDAR detection
model, on the nuScenes AD dataset. Two CP-based traffic applications further
validate the necessity of such realistic detection modeling, particularly for
tasks requiring accurate individual vehicle observations (e.g., position,
speed, lane index). As demonstrated in the applications, MIDAR can be
seamlessly integrated into traffic simulators and trajectory datasets and will
be open-sourced upon publication.

</details>


### [49] [Evaluation and Analysis of Deep Neural Transformers and Convolutional Neural Networks on Modern Remote Sensing Datasets](https://arxiv.org/abs/2508.02871)
*J. Alex Hurt,Trevor M. Bajkowski,Grant J. Scott,Curt H. Davis*

Main category: cs.CV

TL;DR: This paper explores transformer-based neural networks for object detection in satellite imagery, achieving state-of-the-art performance and comparing various architectures and algorithms.


<details>
  <summary>Details</summary>
Motivation: Understanding the performance of transformer-based neural networks on satellite imagery is imperative due to their success in NLP and CV and their potential in remote sensing.

Method: Compared eleven distinct bounding-box detection and localization algorithms, including five transformer-based architectures and six convolutional networks, on three state-of-the-art open-source high-resolution remote sensing imagery datasets.

Result: Demonstrates state-of-the-art performance of transformer-based neural networks for object detection in high-resolution electro-optical satellite imagery.

Conclusion: Transformer-based architectures achieve state-of-the-art performance in object detection on high-resolution remote sensing imagery datasets.

Abstract: In 2012, AlexNet established deep convolutional neural networks (DCNNs) as
the state-of-the-art in CV, as these networks soon led in visual tasks for many
domains, including remote sensing. With the publication of Visual Transformers,
we are witnessing the second modern leap in computational vision, and as such,
it is imperative to understand how various transformer-based neural networks
perform on satellite imagery. While transformers have shown high levels of
performance in natural language processing and CV applications, they have yet
to be compared on a large scale to modern remote sensing data. In this paper,
we explore the use of transformer-based neural networks for object detection in
high-resolution electro-optical satellite imagery, demonstrating
state-of-the-art performance on a variety of publicly available benchmark data
sets. We compare eleven distinct bounding-box detection and localization
algorithms in this study, of which seven were published since 2020, and all
eleven since 2015. The performance of five transformer-based architectures is
compared with six convolutional networks on three state-of-the-art opensource
high-resolution remote sensing imagery datasets ranging in size and complexity.
Following the training and evaluation of thirty-three deep neural models, we
then discuss and analyze model performance across various feature extraction
methodologies and detection algorithms.

</details>


### [50] [VisuCraft: Enhancing Large Vision-Language Models for Complex Visual-Guided Creative Content Generation via Structured Information Extraction](https://arxiv.org/abs/2508.02890)
*Rongxin Jiang,Robert Long,Chenghao Gu,Mingrui Yan*

Main category: cs.CV

TL;DR: VisuCraft enhances LVLMs for creative content generation by integrating a multimodal structured information extractor and a dynamic prompt generation module, leading to improvements in creativity and instruction adherence.


<details>
  <summary>Details</summary>
Motivation: Existing LVLMs often exhibit limitations in maintaining high visual fidelity, genuine creativity, and precise adherence to nuanced user instructions when generating long-form texts.

Method: integrating a multimodal structured information extractor (E) and a dynamic prompt generation module (G). The extractor distills fine-grained visual attributes from input images into a rich, structured representation, which the dynamic prompt module then combines with user instructions to create highly optimized prompts for underlying LVLMs (e.g., LLaVA, InstructBLIP).

Result: Evaluated on the self-constructed ImageStoryGen-500K dataset using VisuGen Metrics (Visual Grounding, Creativity, and Instruction Adherence), VisuCraft consistently outperforms baseline LVLMs across tasks like story generation and poetry composition.

Conclusion: VisuCraft demonstrates remarkable improvements, particularly in creativity and instruction adherence, validating VisuCraft's effectiveness in producing imaginative, visually grounded, and user-aligned long-form creative text. This work unlocks new potential for LVLMs in sophisticated creative AI applications.

Abstract: This paper introduces VisuCraft, a novel framework designed to significantly
enhance the capabilities of Large Vision-Language Models (LVLMs) in complex
visual-guided creative content generation. Existing LVLMs often exhibit
limitations in maintaining high visual fidelity, genuine creativity, and
precise adherence to nuanced user instructions when generating long-form texts.
VisuCraft addresses these challenges by integrating a multimodal structured
information extractor (E) and a dynamic prompt generation module (G). The
extractor distills fine-grained visual attributes from input images into a
rich, structured representation, which the dynamic prompt module then combines
with user instructions to create highly optimized prompts for underlying LVLMs
(e.g., LLaVA, InstructBLIP). Evaluated on the self-constructed
ImageStoryGen-500K dataset using VisuGen Metrics (Visual Grounding, Creativity,
and Instruction Adherence), VisuCraft consistently outperforms baseline LVLMs
across tasks like story generation and poetry composition. Our results
demonstrate remarkable improvements, particularly in creativity and instruction
adherence, validating VisuCraft's effectiveness in producing imaginative,
visually grounded, and user-aligned long-form creative text. This work unlocks
new potential for LVLMs in sophisticated creative AI applications.

</details>


### [51] [RDDPM: Robust Denoising Diffusion Probabilistic Model for Unsupervised Anomaly Segmentation](https://arxiv.org/abs/2508.02903)
*Mehrdad Moradi,Kamran Paynabar*

Main category: cs.CV

TL;DR: 提出了一种新的稳健去噪扩散模型，用于在只有受污染的未标记数据可用的情况下进行无监督异常分割，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型通常假设可以访问正常数据进行训练，这限制了它们在实际环境中的适用性。本文旨在解决只有受污染的（即正常和异常的混合）未标记数据可用的情况。

Method: 通过将数据的最大似然估计转化为非线性回归问题，并通过稳健回归推导出稳健版本的去噪扩散概率模型。

Result: 该方法优于当前最先进的扩散模型，用于在仅有受污染数据的情况下进行无监督异常分割。

Conclusion: 该方法在仅有受污染数据的情况下，优于现有的基于扩散的方法，在 MVTec 数据集上实现了高达 8.08% 的 AUROC 和 10.37% 的 AUPRC。

Abstract: Recent advancements in diffusion models have demonstrated significant success
in unsupervised anomaly segmentation. For anomaly segmentation, these models
are first trained on normal data; then, an anomalous image is noised to an
intermediate step, and the normal image is reconstructed through backward
diffusion. Unlike traditional statistical methods, diffusion models do not rely
on specific assumptions about the data or target anomalies, making them
versatile for use across different domains. However, diffusion models typically
assume access to normal data for training, limiting their applicability in
realistic settings. In this paper, we propose novel robust denoising diffusion
models for scenarios where only contaminated (i.e., a mix of normal and
anomalous) unlabeled data is available. By casting maximum likelihood
estimation of the data as a nonlinear regression problem, we reinterpret the
denoising diffusion probabilistic model through a regression lens. Using robust
regression, we derive a robust version of denoising diffusion probabilistic
models. Our novel framework offers flexibility in constructing various robust
diffusion models. Our experiments show that our approach outperforms current
state of the art diffusion models, for unsupervised anomaly segmentation when
only contaminated data is available. Our method outperforms existing
diffusion-based approaches, achieving up to 8.08\% higher AUROC and 10.37\%
higher AUPRC on MVTec datasets. The implementation code is available at:
https://github.com/mehrdadmoradi124/RDDPM

</details>


### [52] [How Would It Sound? Material-Controlled Multimodal Acoustic Profile Generation for Indoor Scenes](https://arxiv.org/abs/2508.02905)
*Mahnoor Fatima Saad,Ziad Al-Halah*

Main category: cs.CV

TL;DR: 本文介绍了一种材料控制的声学剖面生成任务，并提出了一个新的基准数据集，用于开发和评估材料感知的 RIR 预测方法。


<details>
  <summary>Details</summary>
Motivation: 研究在具有特定视听特征的室内场景中，地毯地面和墙壁上的吸音瓷砖如何改变工作室中的声音。

Method: 一种新颖的编码器-解码器方法，该方法从视听观察中编码场景的关键属性，并根据用户提供的材料规格生成目标房间脉冲响应（RIR）。

Result: 所提出的模型能够有效地编码材料信息并生成高保真度的 RIR，优于几种基线方法和最先进的方法。

Conclusion: 该模型能够有效地编码材料信息并生成高保真度的房间脉冲响应（RIR），优于其他基线方法和最先进的方法。

Abstract: How would the sound in a studio change with a carpeted floor and acoustic
tiles on the walls? We introduce the task of material-controlled acoustic
profile generation, where, given an indoor scene with specific audio-visual
characteristics, the goal is to generate a target acoustic profile based on a
user-defined material configuration at inference time. We address this task
with a novel encoder-decoder approach that encodes the scene's key properties
from an audio-visual observation and generates the target Room Impulse Response
(RIR) conditioned on the material specifications provided by the user. Our
model enables the generation of diverse RIRs based on various material
configurations defined dynamically at inference time. To support this task, we
create a new benchmark, the Acoustic Wonderland Dataset, designed for
developing and evaluating material-aware RIR prediction methods under diverse
and challenging settings. Our results demonstrate that the proposed model
effectively encodes material information and generates high-fidelity RIRs,
outperforming several baselines and state-of-the-art methods.

</details>


### [53] [Following Route Instructions using Large Vision-Language Models: A Comparison between Low-level and Panoramic Action Spaces](https://arxiv.org/abs/2508.02917)
*Vebjørn Haug Kåsene,Pierre Lison*

Main category: cs.CV

TL;DR: Investigates the effectiveness of off-the-shelf LVLMs for Vision-and-Language Navigation (VLN) across different action spaces, finding they can perform VLN but underperform compared to specialized models.


<details>
  <summary>Details</summary>
Motivation: Explore the potential of off-the-shelf LVLMs in VLN tasks, which are currently underexplored, and investigate whether such models can support both low-level and panoramic action paradigms.

Method: Fine-tune the open-source model Qwen2.5-VL-3B-Instruct on the Room-to-Room (R2R) dataset and evaluate its empirical performance across both low-level and panoramic action spaces.

Result: Achieves a 41% success rate on the R2R test set.

Conclusion: Off-the-shelf LVLMs can learn to perform Vision-and-Language Navigation, but they still lag behind models specifically designed for this task.

Abstract: Vision-and-Language Navigation (VLN) refers to the task of enabling
autonomous robots to navigate unfamiliar environments by following natural
language instructions. While recent Large Vision-Language Models (LVLMs) have
shown promise in this task, most current VLM systems rely on models
specifically designed and optimized for navigation, leaving the potential of
off-the-shelf LVLMs underexplored. Furthermore, while older VLN approaches used
low-level action spaces with egocentric views and atomic actions (such as "turn
left" or "move forward"), newer models tend to favor panoramic action spaces
with discrete navigable viewpoints. This paper investigates (1) whether
off-the-shelf LVLMs (fine-tuned without architectural modifications or
simulator-based training) can effectively support VLN tasks and (2) whether
such models can support both low-level and panoramic action paradigms. To this
end, we fine-tune the open-source model Qwen2.5-VL-3B-Instruct on the
Room-to-Room (R2R) dataset and evaluate its empirical performance across both
low-level and panoramic action spaces. The best resulting model achieves a 41%
success rate on the R2R test set, demonstrating that while off-the-shelf LVLMs
can learn to perform Vision-and-Language Navigation, they still lag behind
models specifically designed for this task.

</details>


### [54] [How Diffusion Prior Landscapes Shape the Posterior in Blind Deconvolution](https://arxiv.org/abs/2508.02923)
*Minh-Hai Nguyen,Edouard Pauwels,Pierre Weiss*

Main category: cs.CV

TL;DR: MAP 估计通常会导致模糊图像，但后验的局部最小值可以提供清晰的图像。


<details>
  <summary>Details</summary>
Motivation: 最大后验 (MAP) 估计是盲反卷积中广泛使用的框架，用于从模糊的观察中恢复清晰的图像。然而，当与稀疏性促进图像先验配对时，MAP 估计已被证明有利于模糊解决方案，从而限制了其有效性。

Method: 使用扩散先验

Result: MAP 估计器倾向于产生锐利的滤波器（接近狄拉克 delta 函数）和模糊的解决方案。然而，可以通过梯度下降获得的后验的局部最小值对应于真实的自然图像，有效地解决了盲反卷积问题。

Conclusion: 克服 MAP 的局限性需要在后验景观中良好地局部初始化到局部最小值。

Abstract: The Maximum A Posteriori (MAP) estimation is a widely used framework in blind
deconvolution to recover sharp images from blurred observations. The estimated
image and blur filter are defined as the maximizer of the posterior
distribution. However, when paired with sparsity-promoting image priors, MAP
estimation has been shown to favors blurry solutions, limiting its
effectiveness. In this paper, we revisit this result using diffusion-based
priors, a class of models that capture realistic image distributions. Through
an empirical examination of the prior's likelihood landscape, we uncover two
key properties: first, blurry images tend to have higher likelihoods; second,
the landscape contains numerous local minimizers that correspond to natural
images. Building on these insights, we provide a theoretical analysis of the
blind deblurring posterior. This reveals that the MAP estimator tends to
produce sharp filters (close to the Dirac delta function) and blurry solutions.
However local minimizers of the posterior, which can be obtained with gradient
descent, correspond to realistic, natural images, effectively solving the blind
deconvolution problem. Our findings suggest that overcoming MAP's limitations
requires good local initialization to local minima in the posterior landscape.
We validate our analysis with numerical experiments, demonstrating the
practical implications of our insights for designing improved priors and
optimization techniques.

</details>


### [55] [Infrared Object Detection with Ultra Small ConvNets: Is ImageNet Pretraining Still Useful?](https://arxiv.org/abs/2508.02927)
*Srikanth Muralidharan,Heitor R. Medeiros,Masih Aminbeidokhti,Eric Granger,Marco Pedersoli*

Main category: cs.CV

TL;DR: 本文研究了 ImageNet 预训练对超小型骨干架构在红外视觉模态的下游目标检测任务中鲁棒性的影响。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用需要对不同操作条件和模式具有鲁棒性的识别模型，但同时运行在具有有限硬件的小型嵌入式设备上。虽然对于正常大小的模型，预训练在准确性和鲁棒性方面已知是非常有益的，但对于可以用于嵌入式和边缘设备的小型模型，其效果尚不清楚。

Method: 使用从标准对象识别架构导出的缩放定律，构建了两个超小型骨干系列，并系统地研究了它们的性能。

Result: 在三个不同的数据集上的实验表明，虽然 ImageNet 预训练仍然有用，但超过某个容量阈值后，它在域外检测鲁棒性方面的收益会递减。

Conclusion: ImageNet 预训练对于小型模型仍然有用，但超过一定容量阈值后，其在域外检测鲁棒性方面的收益会递减。建议从业者仍然使用预训练，并在可能的情况下避免使用太小的模型，因为它们在域内问题上可能表现良好，但在工作条件不同时会变得脆弱。

Abstract: Many real-world applications require recognition models that are robust to
different operational conditions and modalities, but at the same time run on
small embedded devices, with limited hardware. While for normal size models,
pre-training is known to be very beneficial in accuracy and robustness, for
small models, that can be employed for embedded and edge devices, its effect is
not clear. In this work, we investigate the effect of ImageNet pretraining on
increasingly small backbone architectures (ultra-small models, with $<$1M
parameters) with respect to robustness in downstream object detection tasks in
the infrared visual modality. Using scaling laws derived from standard object
recognition architectures, we construct two ultra-small backbone families and
systematically study their performance. Our experiments on three different
datasets reveal that while ImageNet pre-training is still useful, beyond a
certain capacity threshold, it offers diminishing returns in terms of
out-of-distribution detection robustness. Therefore, we advise practitioners to
still use pre-training and, when possible avoid too small models as while they
might work well for in-domain problems, they are brittle when working
conditions are different.

</details>


### [56] [X-Actor: Emotional and Expressive Long-Range Portrait Acting from Audio](https://arxiv.org/abs/2508.02944)
*Chenxu Zhang,Zenan Li,Hongyi Xu,You Xie,Xiaochen Zhao,Tianpei Gu,Guoxian Song,Xin Chen,Chao Liang,Jianwen Jiang,Linjie Luo*

Main category: cs.CV

TL;DR: X-Actor 是一种新的音频驱动肖像动画框架，它可以从单个参考图像和输入音频剪辑生成逼真、情感丰富的说话头像视频。


<details>
  <summary>Details</summary>
Motivation: 与以往强调唇部同步和受限说话场景中的短程视觉保真度的方法不同，X-Actor 能够实现演员级别的长篇肖像表演，捕捉与语音节奏和内容连贯流动的细微、动态发展的情感。

Method: 一个两阶段解耦生成管道：一个音频条件自回归扩散模型，用于预测表情丰富但与身份无关的面部运动潜在标记；然后是一个基于扩散的视频合成模块，将这些运动转化为高保真视频动画。

Result: X-Actor 产生引人注目的电影风格表演，超越了标准的说话头像动画，并在长程音频驱动的情感肖像表演方面取得了最先进的结果。

Conclusion: X-Actor 在长程音频驱动的情感肖像表演方面取得了最先进的结果，能够生成引人注目的电影风格表演。

Abstract: We present X-Actor, a novel audio-driven portrait animation framework that
generates lifelike, emotionally expressive talking head videos from a single
reference image and an input audio clip. Unlike prior methods that emphasize
lip synchronization and short-range visual fidelity in constrained speaking
scenarios, X-Actor enables actor-quality, long-form portrait performance
capturing nuanced, dynamically evolving emotions that flow coherently with the
rhythm and content of speech. Central to our approach is a two-stage decoupled
generation pipeline: an audio-conditioned autoregressive diffusion model that
predicts expressive yet identity-agnostic facial motion latent tokens within a
long temporal context window, followed by a diffusion-based video synthesis
module that translates these motions into high-fidelity video animations. By
operating in a compact facial motion latent space decoupled from visual and
identity cues, our autoregressive diffusion model effectively captures
long-range correlations between audio and facial dynamics through a
diffusion-forcing training paradigm, enabling infinite-length emotionally-rich
motion prediction without error accumulation. Extensive experiments demonstrate
that X-Actor produces compelling, cinematic-style performances that go beyond
standard talking head animations and achieves state-of-the-art results in
long-range, audio-driven emotional portrait acting.

</details>


### [57] [Towards Robust Image Denoising with Scale Equivariance](https://arxiv.org/abs/2508.02967)
*Dawei Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 该论文研究了尺度等变性作为提高 OOD 鲁棒性的核心归纳偏差，并提出了一个稳健的盲去噪框架，该框架在空间异构噪声下优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的图像去噪模型通常难以推广到分布内噪声模式之外，特别是在面对以空间变化噪声为特征的分布外（OOD）条件时，这种泛化差距仍然是一个基本的但尚未充分探索的挑战。

Method: 提出了一个稳健的盲去噪框架，配备了两个关键组件：异构归一化模块（HNM）和交互门控模块（IGM）。

Result: 该模型在空间异构噪声下优于现有技术。

Conclusion: 该模型在合成和真实世界的基准测试中始终优于最先进的方法，尤其是在空间异构噪声下。

Abstract: Despite notable advances in image denoising, existing models often struggle
to generalize beyond in-distribution noise patterns, particularly when
confronted with out-of-distribution (OOD) conditions characterized by spatially
variant noise. This generalization gap remains a fundamental yet underexplored
challenge. In this work, we investigate \emph{scale equivariance} as a core
inductive bias for improving OOD robustness. We argue that incorporating
scale-equivariant structures enables models to better adapt from training on
spatially uniform noise to inference on spatially non-uniform degradations.
Building on this insight, we propose a robust blind denoising framework
equipped with two key components: a Heterogeneous Normalization Module (HNM)
and an Interactive Gating Module (IGM). HNM stabilizes feature distributions
and dynamically corrects features under varying noise intensities, while IGM
facilitates effective information modulation via gated interactions between
signal and feature paths. Extensive evaluations demonstrate that our model
consistently outperforms state-of-the-art methods on both synthetic and
real-world benchmarks, especially under spatially heterogeneous noise. Code
will be made publicly available.

</details>


### [58] [Diffusion Models with Adaptive Negative Sampling Without External Resources](https://arxiv.org/abs/2508.02973)
*Alakh Desai,Nuno Vasconcelos*

Main category: cs.CV

TL;DR: This paper introduces ANSWER, a training-free technique that improves prompt adherence and image quality in diffusion models by adaptively sampling negative prompts without external resources. It outperforms baselines and is preferred by humans.


<details>
  <summary>Details</summary>
Motivation: Diffusion models (DMs) have demonstrated an unparalleled ability to create diverse and high-fidelity images from text prompts. However, they are also well-known to vary substantially regarding both prompt adherence and quality. Negative prompting was introduced to improve prompt compliance by specifying what an image must not contain. Previous works have shown the existence of an ideal negative prompt that can maximize the odds of the positive prompt.

Method: develop a sampling procedure, Adaptive Negative Sampling Without External Resources (ANSWER), that accounts for both positive and negative conditions from a single prompt. This leverages the internal understanding of negation by the diffusion model to increase the odds of generating images faithful to the prompt. ANSWER is a training-free technique, applicable to any model that supports CFG, and allows for negative grounding of image concepts without an explicit negative prompts, which are lossy and incomplete.

Result: adding ANSWER to existing DMs outperforms the baselines on multiple benchmarks and is preferred by humans 2x more over the other methods.

Conclusion: ANSWER outperforms the baselines on multiple benchmarks and is preferred by humans 2x more over the other methods.

Abstract: Diffusion models (DMs) have demonstrated an unparalleled ability to create
diverse and high-fidelity images from text prompts. However, they are also
well-known to vary substantially regarding both prompt adherence and quality.
Negative prompting was introduced to improve prompt compliance by specifying
what an image must not contain. Previous works have shown the existence of an
ideal negative prompt that can maximize the odds of the positive prompt. In
this work, we explore relations between negative prompting and classifier-free
guidance (CFG) to develop a sampling procedure, {\it Adaptive Negative Sampling
Without External Resources} (ANSWER), that accounts for both positive and
negative conditions from a single prompt. This leverages the internal
understanding of negation by the diffusion model to increase the odds of
generating images faithful to the prompt. ANSWER is a training-free technique,
applicable to any model that supports CFG, and allows for negative grounding of
image concepts without an explicit negative prompts, which are lossy and
incomplete. Experiments show that adding ANSWER to existing DMs outperforms the
baselines on multiple benchmarks and is preferred by humans 2x more over the
other methods.

</details>


### [59] [Separating Shared and Domain-Specific LoRAs for Multi-Domain Learning](https://arxiv.org/abs/2508.02978)
*Yusaku Takama,Ning Ding,Tatsuya Yokota,Toru Tamaki*

Main category: cs.CV

TL;DR: proposes a method that ensures that shared and domain-specific LoRAs exist in different subspaces


<details>
  <summary>Details</summary>
Motivation: it remains unclear whether this structure effectively captures domain-specific information

Method: propose a method that ensures that shared and domain-specific LoRAs exist in different subspaces; specifically, the column and left null subspaces of the pre-trained weights

Result: apply the proposed method to action recognition with three datasets (UCF101, Kinetics400, and HMDB51) and demonstrate its effectiveness in some cases

Conclusion: demonstrates its effectiveness in some cases along with the analysis of the dimensions of LoRA weights

Abstract: Existing architectures of multi-domain learning have two types of adapters:
shared LoRA for all domains and domain-specific LoRA for each particular
domain. However, it remains unclear whether this structure effectively captures
domain-specific information. In this paper, we propose a method that ensures
that shared and domain-specific LoRAs exist in different subspaces;
specifically, the column and left null subspaces of the pre-trained weights. We
apply the proposed method to action recognition with three datasets (UCF101,
Kinetics400, and HMDB51) and demonstrate its effectiveness in some cases along
with the analysis of the dimensions of LoRA weights.

</details>


### [60] [MoExDA: Domain Adaptation for Edge-based Action Recognition](https://arxiv.org/abs/2508.02981)
*Takuya Sugimoto,Ning Ding,Toru Tamaki*

Main category: cs.CV

TL;DR: 提出 MoExDA 来解决动作识别模型中的静态偏差问题，实验表明，该方法在降低计算成本的同时，实现了更强大的动作识别。


<details>
  <summary>Details</summary>
Motivation: 现代动作识别模型受到静态偏差的影响，导致泛化性能下降。

Method: 提出了一种 MoExDA，这是一种使用边缘帧以及 RGB 帧在 RGB 和边缘信息之间进行轻量级域适应的方法，以解决静态偏差问题。

Result: 实验表明，该方法以较低的计算成本有效地抑制了静态偏差，从而实现了比以前的方法更强大的动作识别。

Conclusion: 该方法以较低的计算成本有效地抑制了静态偏差，从而实现了比以前的方法更强大的动作识别。

Abstract: Modern action recognition models suffer from static bias, leading to reduced
generalization performance. In this paper, we propose MoExDA, a lightweight
domain adaptation between RGB and edge information using edge frames in
addition to RGB frames to counter the static bias issue. Experiments
demonstrate that the proposed method effectively suppresses static bias with a
lower computational cost, allowing for more robust action recognition than
previous approaches.

</details>


### [61] [Adversarial Attention Perturbations for Large Object Detection Transformers](https://arxiv.org/abs/2508.02987)
*Zachary Yahn,Selim Furkan Tekin,Fatih Ilhan,Sihao Hu,Tiansheng Huang,Yichang Xu,Margaret Loper,Ling Liu*

Main category: cs.CV

TL;DR: AFOG是一种新的对抗攻击方法，它利用注意力机制有效地攻击基于transformer和CNN的目标检测器，优于现有方法，且速度更快，隐蔽性更好。


<details>
  <summary>Details</summary>
Motivation: 现有的目标检测对抗扰动方法要么仅限于攻击基于CNN的检测器，要么对基于transformer的检测器效果不佳。

Method: 提出了一种关注注意力的攻击梯度（AFOG）攻击，通过可学习的注意力机制将扰动集中在易受攻击的图像区域，并通过迭代注入对抗性扰动来整合两种类型的特征损失。

Result: AFOG在多框检测任务中，性能比非注意力基线提高了30.6%。在COCO上对12个大型检测transformer进行的实验证明了AFOG的有效性。

Conclusion: AFOG在攻击基于transformer和CNN的目标检测器方面优于现有攻击，高达83%，并且具有更快的速度和更好的隐蔽性。

Abstract: Adversarial perturbations are useful tools for exposing vulnerabilities in
neural networks. Existing adversarial perturbation methods for object detection
are either limited to attacking CNN-based detectors or weak against
transformer-based detectors. This paper presents an Attention-Focused Offensive
Gradient (AFOG) attack against object detection transformers. By design, AFOG
is neural-architecture agnostic and effective for attacking both large
transformer-based object detectors and conventional CNN-based detectors with a
unified adversarial attention framework. This paper makes three original
contributions. First, AFOG utilizes a learnable attention mechanism that
focuses perturbations on vulnerable image regions in multi-box detection tasks,
increasing performance over non-attention baselines by up to 30.6%. Second,
AFOG's attack loss is formulated by integrating two types of feature loss
through learnable attention updates with iterative injection of adversarial
perturbations. Finally, AFOG is an efficient and stealthy adversarial
perturbation method. It probes the weak spots of detection transformers by
adding strategically generated and visually imperceptible perturbations which
can cause well-trained object detection models to fail. Extensive experiments
conducted with twelve large detection transformers on COCO demonstrate the
efficacy of AFOG. Our empirical results also show that AFOG outperforms
existing attacks on transformer-based and CNN-based object detectors by up to
83% with superior speed and imperceptibility. Code is available at
https://github.com/zacharyyahn/AFOG.

</details>


### [62] [Seeing It Before It Happens: In-Generation NSFW Detection for Diffusion-Based Text-to-Image Models](https://arxiv.org/abs/2508.03006)
*Fan Yang,Yihao Huang,Jiayi Zhu,Ling Shi,Geguang Pu,Jin Song Dong,Kailong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种在扩散模型生成过程中检测 NSFW 内容的方法，该方法利用预测噪声作为信号，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的检测方法主要集中在生成前的提示过滤或生成后的图像审核，而扩散模型的生成阶段在 NSFW 检测方面仍未得到充分探索。初步研究表明，预测的噪声可能捕获语义线索，区分 NSFW 和良性提示。

Method: 利用扩散过程中预测的噪声作为内部信号来识别 NSFW 内容。

Result: 在七个 NSFW 类别上实现了 91.32% 的平均检测准确率，优于七种基线方法。

Conclusion: 本文提出了一种名为In-Generation Detection (IGD) 的方法，该方法利用扩散过程中预测的噪声作为内部信号来识别不适宜工作场所 (NSFW) 内容，并在七个 NSFW 类别上实现了 91.32% 的平均检测准确率，优于七种基线方法。

Abstract: Diffusion-based text-to-image (T2I) models enable high-quality image
generation but also pose significant risks of misuse, particularly in producing
not-safe-for-work (NSFW) content. While prior detection methods have focused on
filtering prompts before generation or moderating images afterward, the
in-generation phase of diffusion models remains largely unexplored for NSFW
detection. In this paper, we introduce In-Generation Detection (IGD), a simple
yet effective approach that leverages the predicted noise during the diffusion
process as an internal signal to identify NSFW content. This approach is
motivated by preliminary findings suggesting that the predicted noise may
capture semantic cues that differentiate NSFW from benign prompts, even when
the prompts are adversarially crafted. Experiments conducted on seven NSFW
categories show that IGD achieves an average detection accuracy of 91.32% over
naive and adversarial NSFW prompts, outperforming seven baseline methods.

</details>


### [63] [Multi-Granularity Feature Calibration via VFM for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.03007)
*Xinhui Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: 本文提出了一种新的多粒度特征校准框架，用于领域泛化语义分割，该框架通过粗到细的特征对齐来增强鲁棒性，并在基准数据集上取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 领域泛化语义分割(DGSS)旨在提高模型在未见过的领域中的泛化能力，而无需在训练期间访问目标数据。最近DGSS的进展越来越多地通过参数高效的微调策略来利用视觉基础模型(VFM)。然而，大多数现有方法都集中于全局特征微调，而忽略了跨特征层次的层次自适应，这对于精确的密集预测至关重要。

Method: 本文提出了一种多粒度特征校准(MGFC)的新框架，该框架执行VFM特征的粗到细对齐，以增强域移位下的鲁棒性。

Result: 通过执行分层和粒度感知校准，MGFC有效地将VFMs的泛化优势转移到DGSS的特定领域任务。在基准数据集上的大量实验表明，该方法优于最先进的DGSS方法，突出了多粒度自适应对于领域泛化的语义分割任务的有效性。

Conclusion: MGFC在基准数据集上的大量实验表明，该方法优于最先进的DGSS方法，突出了多粒度自适应对于领域泛化的语义分割任务的有效性。

Abstract: Domain Generalized Semantic Segmentation (DGSS) aims to improve the
generalization ability of models across unseen domains without access to target
data during training. Recent advances in DGSS have increasingly exploited
vision foundation models (VFMs) via parameter-efficient fine-tuning strategies.
However, most existing approaches concentrate on global feature fine-tuning,
while overlooking hierarchical adaptation across feature levels, which is
crucial for precise dense prediction. In this paper, we propose
Multi-Granularity Feature Calibration (MGFC), a novel framework that performs
coarse-to-fine alignment of VFM features to enhance robustness under domain
shifts. Specifically, MGFC first calibrates coarse-grained features to capture
global contextual semantics and scene-level structure. Then, it refines
medium-grained features by promoting category-level feature discriminability.
Finally, fine-grained features are calibrated through high-frequency spatial
detail enhancement. By performing hierarchical and granularity-aware
calibration, MGFC effectively transfers the generalization strengths of VFMs to
the domain-specific task of DGSS. Extensive experiments on benchmark datasets
demonstrate that our method outperforms state-of-the-art DGSS approaches,
highlighting the effectiveness of multi-granularity adaptation for the semantic
segmentation task of domain generalization.

</details>


### [64] [Enhancing Long Video Question Answering with Scene-Localized Frame Grouping](https://arxiv.org/abs/2508.03009)
*Xuyi Yang,Wenhao Zhang,Hongbo Jin,Lin Liu,Hongbo Xu,Yongwei Nie,Fei Yu,Fei Ma*

Main category: cs.CV

TL;DR: The paper introduces SceneQA, a new scenario under the video question-answering task, and develops the LVSQA dataset. It proposes SLFG, a novel method that combines frames into semantically coherent scene frames to enhance MLLMs' understanding in long videos.


<details>
  <summary>Details</summary>
Motivation: Current Multimodal Large Language Models (MLLMs) often perform poorly in long video understanding due to resource limitations. Existing frameworks do not align with the practical needs of real-world applications.

Method: A novel method called SLFG is introduced, which combines individual frames into semantically coherent scene frames by leveraging scene localization methods and dynamic frame reassembly mechanisms.

Result: Experimental results show that SLFG performs exceptionally well in several long video benchmark tests.

Conclusion: The SLFG method significantly enhances the understanding capabilities of existing MLLMs in long videos, performs exceptionally well in several long video benchmark tests, and requires no modification to the original model architecture.

Abstract: Current Multimodal Large Language Models (MLLMs) often perform poorly in long
video understanding, primarily due to resource limitations that prevent them
from processing all video frames and their associated information. Efficiently
extracting relevant information becomes a challenging task. Existing frameworks
and evaluation tasks focus on identifying specific frames containing core
objects from a large number of irrelevant frames, which does not align with the
practical needs of real-world applications. To address this issue, we propose a
new scenario under the video question-answering task, SceneQA, which emphasizes
scene-based detail perception and reasoning abilities. And we develop the LVSQA
dataset to support the SceneQA task, which is built upon carefully selected
videos from LVBench and contains a new collection of question-answer pairs to
promote a more fair evaluation of MLLMs' scene perception abilities in long
videos. Inspired by human cognition, we introduce a novel method called SLFG.
The core idea of SLFG is to combine individual frames into semantically
coherent scene frames. By leveraging scene localization methods and dynamic
frame reassembly mechanisms, SLFG significantly enhances the understanding
capabilities of existing MLLMs in long videos. SLFG requires no modification to
the original model architecture and boasts excellent plug-and-play usability.
Experimental results show that this method performs exceptionally well in
several long video benchmark tests. Code and dataset will be released at
http://www.slfg.pkuzwh.cn.

</details>


### [65] [SA-3DGS: A Self-Adaptive Compression Method for 3D Gaussian Splatting](https://arxiv.org/abs/2508.03017)
*Liheng Zhang,Weihao Yu,Zubo Lu,Haozhi Gu,Jin Huang*

Main category: cs.CV

TL;DR: SA-3DGS reduces storage costs while maintaining rendering quality via importance score learning, importance-aware clustering and codebook repair.


<details>
  <summary>Details</summary>
Motivation: Representing scenes requires a large number of Gaussian points, leading to high storage demands and limiting practical deployment. The latest methods facilitate the compression of Gaussian models but struggle to identify truly insignificant Gaussian points in the scene, leading to a decline in subsequent Gaussian pruning, compression quality, and rendering performance.

Method: SA-3DGS, which learns an importance score to automatically identify the least significant Gaussians in scene reconstruction, importance-aware clustering module compresses Gaussians attributes more accurately into the codebook, and codebook repair module leverages contextual scene information to repair the codebook.

Result: achieves up to 66x compression while maintaining or even improving rendering quality. The proposed Gaussian pruning approach is not only adaptable to but also improves other pruning-based methods.

Conclusion: The method achieves up to 66x compression while maintaining or even improving rendering quality and improves other pruning-based methods.

Abstract: Recent advancements in 3D Gaussian Splatting have enhanced efficient and
high-quality novel view synthesis. However, representing scenes requires a
large number of Gaussian points, leading to high storage demands and limiting
practical deployment. The latest methods facilitate the compression of Gaussian
models but struggle to identify truly insignificant Gaussian points in the
scene, leading to a decline in subsequent Gaussian pruning, compression
quality, and rendering performance. To address this issue, we propose SA-3DGS,
a method that significantly reduces storage costs while maintaining rendering
quality. SA-3DGS learns an importance score to automatically identify the least
significant Gaussians in scene reconstruction, thereby enabling effective
pruning and redundancy reduction. Next, the importance-aware clustering module
compresses Gaussians attributes more accurately into the codebook, improving
the codebook's expressive capability while reducing model size. Finally, the
codebook repair module leverages contextual scene information to repair the
codebook, thereby recovering the original Gaussian point attributes and
mitigating the degradation in rendering quality caused by information loss.
Experimental results on several benchmark datasets show that our method
achieves up to 66x compression while maintaining or even improving rendering
quality. The proposed Gaussian pruning approach is not only adaptable to but
also improves other pruning-based methods (e.g., LightGaussian), showcasing
excellent performance and strong generalization ability.

</details>


### [66] [MoCA: Identity-Preserving Text-to-Video Generation via Mixture of Cross Attention](https://arxiv.org/abs/2508.03034)
*Qi Xie,Yongjia Ma,Donglin Di,Xuehao Gao,Xun Yang*

Main category: cs.CV

TL;DR: MoCA, a novel Video Diffusion Model, outperforms existing T2V methods in maintaining identity and capturing fine-grained details, as demonstrated on the CelebIPVid dataset.


<details>
  <summary>Details</summary>
Motivation: Achieving ID-preserving text-to-video (T2V) generation remains challenging despite recent advances in diffusion-based models. Existing approaches often fail to capture fine-grained facial dynamics or maintain temporal identity coherence. To address these limitations

Method: a novel Video Diffusion Model built on a Diffusion Transformer (DiT) backbone, incorporating a Mixture of Cross-Attention mechanism inspired by the Mixture-of-Experts paradigm. Our framework improves inter-frame identity consistency by embedding MoCA layers into each DiT block, where Hierarchical Temporal Pooling captures identity features over varying timescales, and Temporal-Aware Cross-Attention Experts dynamically model spatiotemporal relationships. We further incorporate a Latent Video Perceptual Loss to enhance identity coherence and fine-grained details across video frames.

Result: Extensive experiments on CelebIPVid show that MoCA outperforms existing T2V methods by over 5% across Face similarity.

Conclusion: MoCA outperforms existing T2V methods by over 5% across Face similarity.

Abstract: Achieving ID-preserving text-to-video (T2V) generation remains challenging
despite recent advances in diffusion-based models. Existing approaches often
fail to capture fine-grained facial dynamics or maintain temporal identity
coherence. To address these limitations, we propose MoCA, a novel Video
Diffusion Model built on a Diffusion Transformer (DiT) backbone, incorporating
a Mixture of Cross-Attention mechanism inspired by the Mixture-of-Experts
paradigm. Our framework improves inter-frame identity consistency by embedding
MoCA layers into each DiT block, where Hierarchical Temporal Pooling captures
identity features over varying timescales, and Temporal-Aware Cross-Attention
Experts dynamically model spatiotemporal relationships. We further incorporate
a Latent Video Perceptual Loss to enhance identity coherence and fine-grained
details across video frames. To train this model, we collect CelebIPVid, a
dataset of 10,000 high-resolution videos from 1,000 diverse individuals,
promoting cross-ethnicity generalization. Extensive experiments on CelebIPVid
show that MoCA outperforms existing T2V methods by over 5% across Face
similarity.

</details>


### [67] [VideoForest: Person-Anchored Hierarchical Reasoning for Cross-Video Question Answering](https://arxiv.org/abs/2508.03039)
*Yiran Meng,Junhong Ye,Wei Zhou,Guanghui Yue,Xudong Mao,Ruomei Wang,Baoquan Zhao*

Main category: cs.CV

TL;DR: VideoForest 通过以人为中心的层级推理，解决了跨视频问答中的挑战，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 跨视频问答提出了超越传统单视频理解的重大挑战，尤其是在建立跨视频流的有意义连接和管理多源信息检索的复杂性方面。

Method: 该方法利用 ReID 和跟踪算法建立鲁棒的时空关系，并采用多粒度生成树结构和多代理推理框架。

Result: VideoForest 在跨视频推理任务中表现出卓越的性能，在人物识别方面达到 71.93% 的准确率，在行为分析方面达到 83.75% 的准确率，在总结和推理方面达到 51.67% 的准确率，显著优于现有方法。

Conclusion: VideoForest在跨视频推理任务中表现出色，通过以人为中心的特征统一多个视频流，实现了在分布式视觉信息中的复杂推理，同时保持了计算效率，为跨视频理解建立了一个新的范例。

Abstract: Cross-video question answering presents significant challenges beyond
traditional single-video understanding, particularly in establishing meaningful
connections across video streams and managing the complexity of multi-source
information retrieval. We introduce VideoForest, a novel framework that
addresses these challenges through person-anchored hierarchical reasoning. Our
approach leverages person-level features as natural bridge points between
videos, enabling effective cross-video understanding without requiring
end-to-end training. VideoForest integrates three key innovations: 1) a
human-anchored feature extraction mechanism that employs ReID and tracking
algorithms to establish robust spatiotemporal relationships across multiple
video sources; 2) a multi-granularity spanning tree structure that
hierarchically organizes visual content around person-level trajectories; and
3) a multi-agent reasoning framework that efficiently traverses this
hierarchical structure to answer complex cross-video queries. To evaluate our
approach, we develop CrossVideoQA, a comprehensive benchmark dataset
specifically designed for person-centric cross-video analysis. Experimental
results demonstrate VideoForest's superior performance in cross-video reasoning
tasks, achieving 71.93% accuracy in person recognition, 83.75% in behavior
analysis, and 51.67% in summarization and reasoning, significantly
outperforming existing methods. Our work establishes a new paradigm for
cross-video understanding by unifying multiple video streams through
person-level features, enabling sophisticated reasoning across distributed
visual information while maintaining computational efficiency.

</details>


### [68] [Multi-human Interactive Talking Dataset](https://arxiv.org/abs/2508.03050)
*Zeyu Zhu,Weijia Wu,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 该论文介绍了MIT数据集，用于多人对话视频生成，并提出了一个名为CovOG的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有的关于说话视频生成的研究主要集中在单人独白或孤立的面部动画上，限制了它们在真实的多人互动中的适用性。为了弥合这一差距，我们引入了MIT，这是一个专门为多人说话视频生成而设计的大规模数据集。

Method: 该论文开发了一个自动流程，用于收集和注释多人对话视频。提出的CovOG模型集成了多人姿势编码器（MPE）和交互式音频驱动器（IAD）。

Result: 该论文构建了一个包含12小时高分辨率视频的数据集，每个视频包含2到4个说话者，并对身体姿势和语音互动进行了细粒度的注释。

Conclusion: 该论文提出了一个名为CovOG的基线模型，用于生成逼真的多人对话视频，并展示了MIT数据集作为未来研究的宝贵基准的潜力。

Abstract: Existing studies on talking video generation have predominantly focused on
single-person monologues or isolated facial animations, limiting their
applicability to realistic multi-human interactions. To bridge this gap, we
introduce MIT, a large-scale dataset specifically designed for multi-human
talking video generation. To this end, we develop an automatic pipeline that
collects and annotates multi-person conversational videos. The resulting
dataset comprises 12 hours of high-resolution footage, each featuring two to
four speakers, with fine-grained annotations of body poses and speech
interactions. It captures natural conversational dynamics in multi-speaker
scenario, offering a rich resource for studying interactive visual behaviors.
To demonstrate the potential of MIT, we furthur propose CovOG, a baseline model
for this novel task. It integrates a Multi-Human Pose Encoder (MPE) to handle
varying numbers of speakers by aggregating individual pose embeddings, and an
Interactive Audio Driver (IAD) to modulate head dynamics based on
speaker-specific audio features. Together, these components showcase the
feasibility and challenges of generating realistic multi-human talking videos,
establishing MIT as a valuable benchmark for future research. The code is
avalibale at: https://github.com/showlab/Multi-human-Talking-Video-Dataset.

</details>


### [69] [Uncertainty-Guided Face Matting for Occlusion-Aware Face Transformation](https://arxiv.org/abs/2508.03055)
*Hyebin Cho,Jaehyup Lee*

Main category: cs.CV

TL;DR: FaceMat 是一种用于面部抠图的新框架，它在复杂遮挡下优于现有技术，并且不需要额外的输入。


<details>
  <summary>Details</summary>
Motivation: 面部滤镜已成为短视频内容的关键要素，可实现各种视觉效果，例如风格化和面部交换。然而，当手、头发或配饰等物体遮挡面部时，它们的性能通常会下降。

Method: FaceMat，一个无 trimap 的、具有不确定性感知的框架，可以预测复杂遮挡下的高质量 alpha mattes。我们的方法利用了一个两阶段的训练管道：一个教师模型被训练来联合估计 alpha mattes 和使用负对数似然 (NLL) 损失的每像素不确定性，然后这种不确定性被用来通过空间自适应知识蒸馏来指导学生模型。

Result: 广泛的实验表明，FaceMat 在多个基准测试中优于最先进的方法，增强了现实世界中不受约束的视频场景中面部滤镜的视觉质量和鲁棒性。

Conclusion: FaceMat 在多个基准测试中优于最先进的方法，增强了现实世界中不受约束的视频场景中面部滤镜的视觉质量和鲁棒性。

Abstract: Face filters have become a key element of short-form video content, enabling
a wide array of visual effects such as stylization and face swapping. However,
their performance often degrades in the presence of occlusions, where objects
like hands, hair, or accessories obscure the face. To address this limitation,
we introduce the novel task of face matting, which estimates fine-grained alpha
mattes to separate occluding elements from facial regions. We further present
FaceMat, a trimap-free, uncertainty-aware framework that predicts high-quality
alpha mattes under complex occlusions. Our approach leverages a two-stage
training pipeline: a teacher model is trained to jointly estimate alpha mattes
and per-pixel uncertainty using a negative log-likelihood (NLL) loss, and this
uncertainty is then used to guide the student model through spatially adaptive
knowledge distillation. This formulation enables the student to focus on
ambiguous or occluded regions, improving generalization and preserving semantic
consistency. Unlike previous approaches that rely on trimaps or segmentation
masks, our framework requires no auxiliary inputs making it well-suited for
real-time applications. In addition, we reformulate the matting objective by
explicitly treating skin as foreground and occlusions as background, enabling
clearer compositing strategies. To support this task, we newly constructed
CelebAMat, a large-scale synthetic dataset specifically designed for
occlusion-aware face matting. Extensive experiments show that FaceMat
outperforms state-of-the-art methods across multiple benchmarks, enhancing the
visual quality and robustness of face filters in real-world, unconstrained
video scenarios. The source code and CelebAMat dataset are available at
https://github.com/hyebin-c/FaceMat.git

</details>


### [70] [CHARM: Collaborative Harmonization across Arbitrary Modalities for Modality-agnostic Semantic Segmentation](https://arxiv.org/abs/2508.03060)
*Lekang Wen,Jing Xiao,Liang Liao,Jiajun Chen,Mi Wang*

Main category: cs.CV

TL;DR: CHARM：一种用于模态不可知语义分割的互补学习框架，通过互感知单元和双路径优化策略实现跨模态互补，从而在多样性中实现真正的和谐。


<details>
  <summary>Details</summary>
Motivation: 模态不可知语义分割(MaSS)旨在实现跨任意组合的输入模态的鲁棒场景理解。现有方法通常依赖于显式特征对齐来实现模态同质化，这削弱了每种模态的独特优势，并破坏了它们固有的互补性。为了实现协同和谐而不是同质化。

Method: 提出了一种新的互补学习框架CHARM，旨在通过两个组件隐式对齐内容，同时保留模态特定的优势：(1)互感知单元(MPU)，通过基于窗口的跨模态交互实现隐式对齐，其中模态相互充当查询和上下文，以发现模态交互对应关系；(2)双路径优化策略，将训练解耦为用于互补融合学习的协同学习策略(CoL)和用于受保护的模态特定优化的个体增强策略(InE)。

Result: CHARM在多个数据集和骨干网络上始终优于基线，对脆弱模态有显着提升。

Conclusion: CHARM在多个数据集和骨干网络上始终优于基线，对脆弱模态有显着提升。这项工作将重点从模型同质化转移到和谐化，从而实现跨模态互补，从而在多样性中实现真正的和谐。

Abstract: Modality-agnostic Semantic Segmentation (MaSS) aims to achieve robust scene
understanding across arbitrary combinations of input modality. Existing methods
typically rely on explicit feature alignment to achieve modal homogenization,
which dilutes the distinctive strengths of each modality and destroys their
inherent complementarity. To achieve cooperative harmonization rather than
homogenization, we propose CHARM, a novel complementary learning framework
designed to implicitly align content while preserving modality-specific
advantages through two components: (1) Mutual Perception Unit (MPU), enabling
implicit alignment through window-based cross-modal interaction, where
modalities serve as both queries and contexts for each other to discover
modality-interactive correspondences; (2) A dual-path optimization strategy
that decouples training into Collaborative Learning Strategy (CoL) for
complementary fusion learning and Individual Enhancement Strategy (InE) for
protected modality-specific optimization. Experiments across multiple datasets
and backbones indicate that CHARM consistently outperform the baselines, with
significant increment on the fragile modalities. This work shifts the focus
from model homogenization to harmonization, enabling cross-modal
complementarity for true harmony in diversity.

</details>


### [71] [CORE-ReID: Comprehensive Optimization and Refinement through Ensemble fusion in Domain Adaptation for person re-identification](https://arxiv.org/abs/2508.03064)
*Trinh Quoc Nguyen,Oky Dicky Ardiansyah Prima,Katsuyoshi Hotta*

Main category: cs.CV

TL;DR: CORE-ReID is a new framework for UDA in Person ReID that uses CycleGAN, multi-view features, and ensemble fusion to achieve high accuracy.


<details>
  <summary>Details</summary>
Motivation: To address Unsupervised Domain Adaptation (UDA) for Person Re-identification (ReID).

Method: A novel framework, CORE-ReID, using CycleGAN for data generation, multi-view feature integration for multi-level clustering, and a learnable Ensemble Fusion component.

Result: Significant performance gains over state-of-the-art approaches on three common UDAs in Person ReID.

Conclusion: The proposed CORE-ReID framework achieves high accuracy in UDA for Person ReID, outperforming state-of-the-art approaches.

Abstract: This study introduces a novel framework, "Comprehensive Optimization and
Refinement through Ensemble Fusion in Domain Adaptation for Person
Re-identification (CORE-ReID)", to address an Unsupervised Domain Adaptation
(UDA) for Person Re-identification (ReID). The framework utilizes CycleGAN to
generate diverse data that harmonizes differences in image characteristics from
different camera sources in the pre-training stage. In the fine-tuning stage,
based on a pair of teacher-student networks, the framework integrates
multi-view features for multi-level clustering to derive diverse pseudo labels.
A learnable Ensemble Fusion component that focuses on fine-grained local
information within global features is introduced to enhance learning
comprehensiveness and avoid ambiguity associated with multiple pseudo-labels.
Experimental results on three common UDAs in Person ReID demonstrate
significant performance gains over state-of-the-art approaches. Additional
enhancements, such as Efficient Channel Attention Block and Bidirectional Mean
Feature Normalization mitigate deviation effects and adaptive fusion of global
and local features using the ResNet-based model, further strengthening the
framework. The proposed framework ensures clarity in fusion features, avoids
ambiguity, and achieves high ac-curacy in terms of Mean Average Precision,
Top-1, Top-5, and Top-10, positioning it as an advanced and effective solution
for the UDA in Person ReID. Our codes and models are available at
https://github.com/TrinhQuocNguyen/CORE-ReID.

</details>


### [72] [SSFMamba: Symmetry-driven Spatial-Frequency Feature Fusion for 3D Medical Image Segmentation](https://arxiv.org/abs/2508.03069)
*Bo Zhang,Yifan Zhang,Shuo Yan,Yu Bai,Zheng Zhang,Wu Liu,Xiuzhuang Zhou,Wendong Wang*

Main category: cs.CV

TL;DR: SSFMamba, a Mamba-based network, fuses spatial and frequency domain features for improved 3D medical image segmentation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods have limitations in modeling global context in 3D medical image segmentation and overlook the unique properties of frequency domain information. They also fail to account for the fundamental differences in data distribution between the spatial and frequency domains.

Method: The paper proposes SSFMamba, a Mamba based Symmetry-driven Spatial-Frequency feature fusion network for 3D medical image segmentation. It employs a complementary dual-branch architecture that extracts features from both spatial and frequency domains, leveraging a Mamba block to fuse these features. A 3D multi-directional scanning mechanism is designed to strengthen the fusion of local and global cues.

Result: SSFMamba outperforms state-of-the-art methods across various evaluation metrics on the BraTS2020 and BraTS2023 datasets.

Conclusion: The proposed SSFMamba consistently outperforms state-of-the-art methods on the BraTS2020 and BraTS2023 datasets.

Abstract: In light of the spatial domain's limited capacity for modeling global context
in 3D medical image segmentation, emerging approaches have begun to incorporate
frequency domain representations. However, straightforward feature extraction
strategies often overlook the unique properties of frequency domain
information, such as conjugate symmetry. They also fail to account for the
fundamental differences in data distribution between the spatial and frequency
domains, which can ultimately dilute or obscure the complementary strengths
that frequency-based representations offer. In this paper, we propose SSFMamba,
a Mamba based Symmetry-driven Spatial-Frequency feature fusion network for 3D
medical image segmentation. SSFMamba employs a complementary dual-branch
architecture that extracts features from both the spatial and frequency
domains, and leverages a Mamba block to fuse these heterogeneous features to
preserve global context while reinforcing local details. In the frequency
domain branch, we harness Mamba's exceptional capability to extract global
contextual information in conjunction with the synergistic effect of frequency
domain features to further enhance global modeling. Moreover, we design a 3D
multi-directional scanning mechanism to strengthen the fusion of local and
global cues. Extensive experiments on the BraTS2020 and BraTS2023 datasets
demonstrate that our approach consistently outperforms state-of-the-art methods
across various evaluation metrics.

</details>


### [73] [RobustGS: Unified Boosting of Feedforward 3D Gaussian Splatting under Low-Quality Conditions](https://arxiv.org/abs/2508.03077)
*Anran Wu,Long Peng,Xin Di,Xueyuan Dai,Chen Wu,Yang Wang,Xueyang Fu,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: RobustGS enhances feedforward 3DGS robustness to image degradations using a multi-view feature enhancement module.


<details>
  <summary>Details</summary>
Motivation: Existing feedforward 3D Gaussian Splatting (3DGS) methods are vulnerable to real-world image degradations, leading to inaccurate geometry and degraded 3D reconstruction.

Method: A multi-view feature enhancement module, RobustGS, with a Generalized Degradation Learner and a semantic-aware state-space model.

Result: RobustGS substantially improves the robustness of feedforward 3DGS methods under various adverse imaging conditions, enabling high-quality 3D reconstruction.

Conclusion: The proposed RobustGS module, integrated into existing methods, achieves state-of-the-art reconstruction quality across various degradations.

Abstract: Feedforward 3D Gaussian Splatting (3DGS) overcomes the limitations of
optimization-based 3DGS by enabling fast and high-quality reconstruction
without the need for per-scene optimization. However, existing feedforward
approaches typically assume that input multi-view images are clean and
high-quality. In real-world scenarios, images are often captured under
challenging conditions such as noise, low light, or rain, resulting in
inaccurate geometry and degraded 3D reconstruction. To address these
challenges, we propose a general and efficient multi-view feature enhancement
module, RobustGS, which substantially improves the robustness of feedforward
3DGS methods under various adverse imaging conditions, enabling high-quality 3D
reconstruction. The RobustGS module can be seamlessly integrated into existing
pretrained pipelines in a plug-and-play manner to enhance reconstruction
robustness. Specifically, we introduce a novel component, Generalized
Degradation Learner, designed to extract generic representations and
distributions of multiple degradations from multi-view inputs, thereby
enhancing degradation-awareness and improving the overall quality of 3D
reconstruction. In addition, we propose a novel semantic-aware state-space
model. It first leverages the extracted degradation representations to enhance
corrupted inputs in the feature space. Then, it employs a semantic-aware
strategy to aggregate semantically similar information across different views,
enabling the extraction of fine-grained cross-view correspondences and further
improving the quality of 3D representations. Extensive experiments demonstrate
that our approach, when integrated into existing methods in a plug-and-play
manner, consistently achieves state-of-the-art reconstruction quality across
various types of degradations.

</details>


### [74] [Exploring Fairness across Fine-Grained Attributes in Large Vision-Language Models](https://arxiv.org/abs/2508.03079)
*Zaiying Zhao,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: This study explores the fairness of LVLMs across a broader range of attributes, revealing biases beyond race and gender, especially related to cultural, environmental, and behavioral factors.


<details>
  <summary>Details</summary>
Motivation: The rapid expansion of applications using Large Vision-Language Models (LVLMs) has raised significant concerns about their fairness. While existing studies primarily focus on demographic attributes such as race and gender, fairness across a broader range of attributes remains largely unexplored.

Method: constructing an open-set knowledge base of bias attributes leveraging Large Language Models (LLMs) and evaluate the fairness of LVLMs across finer-grained attributes

Result: LVLMs exhibit biased outputs across a diverse set of attributes and further demonstrate that cultural, environmental, and behavioral factors have a more pronounced impact on LVLM decision-making than traditional demographic attributes.

Conclusion: LVLMs exhibit biased outputs across a diverse set of attributes, with cultural, environmental, and behavioral factors having a more pronounced impact than traditional demographic attributes.

Abstract: The rapid expansion of applications using Large Vision-Language Models
(LVLMs), such as GPT-4o, has raised significant concerns about their fairness.
While existing studies primarily focus on demographic attributes such as race
and gender, fairness across a broader range of attributes remains largely
unexplored. In this study, we construct an open-set knowledge base of bias
attributes leveraging Large Language Models (LLMs) and evaluate the fairness of
LVLMs across finer-grained attributes. Our experimental results reveal that
LVLMs exhibit biased outputs across a diverse set of attributes and further
demonstrate that cultural, environmental, and behavioral factors have a more
pronounced impact on LVLM decision-making than traditional demographic
attributes.

</details>


### [75] [Contrastive Cross-Bag Augmentation for Multiple Instance Learning-based Whole Slide Image Classification](https://arxiv.org/abs/2508.03081)
*Bo Zhang,Xu Xinan,Shuo Yan,Yu Bai,Zheng Zhang,Wufan Wang,Wendong Wang*

Main category: cs.CV

TL;DR: 提出了对比跨包增强 (C^2Aug) 以提高多示例学习中全切片图像分类的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于多示例学习 (MIL) 的全切片图像 (WSI) 分类的伪包增强方法从有限数量的包中采样实例，导致多样性受限。引入新实例到伪包中会增加关键实例（例如，肿瘤实例）的数量，从而减少了包含少量关键实例的伪包的出现，从而限制了模型性能，尤其是在肿瘤面积小的测试切片上。

Method: 对比跨包增强 (C^2Aug)，从所有具有相同类别的包中采样实例，以增加伪包的多样性。引入了一个包级别和组级别的对比学习框架，以增强具有不同语义含义的特征的区分，从而提高模型性能。

Result: C^2Aug 在多个评估指标上始终优于最先进的方法。

Conclusion: Contrastive Cross-Bag Augmentation (C^2Aug) 始终优于多种评估指标下的最新方法。

Abstract: Recent pseudo-bag augmentation methods for Multiple Instance Learning
(MIL)-based Whole Slide Image (WSI) classification sample instances from a
limited number of bags, resulting in constrained diversity. To address this
issue, we propose Contrastive Cross-Bag Augmentation ($C^2Aug$) to sample
instances from all bags with the same class to increase the diversity of
pseudo-bags. However, introducing new instances into the pseudo-bag increases
the number of critical instances (e.g., tumor instances). This increase results
in a reduced occurrence of pseudo-bags containing few critical instances,
thereby limiting model performance, particularly on test slides with small
tumor areas. To address this, we introduce a bag-level and group-level
contrastive learning framework to enhance the discrimination of features with
distinct semantic meanings, thereby improving model performance. Experimental
results demonstrate that $C^2Aug$ consistently outperforms state-of-the-art
approaches across multiple evaluation metrics.

</details>


### [76] [Augmenting Continual Learning of Diseases with LLM-Generated Visual Concepts](https://arxiv.org/abs/2508.03094)
*Jiantao Tan,Peixian Ma,Kanghao Chen,Zhiming Dai,Ruixuan Wang*

Main category: cs.CV

TL;DR: 提出了一种利用大型语言模型生成的视觉概念作为判别语义指导的持续学习框架，并在医疗和自然图像数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类系统需要持续学习才能适应动态发展的临床环境。多模态信息的整合可以显著增强图像类别的持续学习。然而，虽然现有方法确实利用了文本模态信息，但它们仅依赖于带有类名称的简单模板，从而忽略了更丰富的语义信息。

Method: 提出了一种新的框架，该框架利用大型语言模型 (LLM) 生成的视觉概念作为判别语义指导。我们的方法动态构建了一个具有基于相似性的过滤机制的视觉概念池，以防止冗余。然后，为了将概念整合到持续学习过程中，我们采用了一种跨模态图像-概念注意模块，并结合了注意损失。通过注意，该模块可以利用来自相关视觉概念的语义知识，并产生用于分类的具有类代表性的融合特征。

Result: 在医疗和自然图像数据集上的实验表明，我们的方法实现了最先进的性能，证明了我们方法的有效性和优越性。

Conclusion: 该方法在医疗和自然图像数据集上实现了最先进的性能，证明了其有效性和优越性。

Abstract: Continual learning is essential for medical image classification systems to
adapt to dynamically evolving clinical environments. The integration of
multimodal information can significantly enhance continual learning of image
classes. However, while existing approaches do utilize textual modality
information, they solely rely on simplistic templates with a class name,
thereby neglecting richer semantic information. To address these limitations,
we propose a novel framework that harnesses visual concepts generated by large
language models (LLMs) as discriminative semantic guidance. Our method
dynamically constructs a visual concept pool with a similarity-based filtering
mechanism to prevent redundancy. Then, to integrate the concepts into the
continual learning process, we employ a cross-modal image-concept attention
module, coupled with an attention loss. Through attention, the module can
leverage the semantic knowledge from relevant visual concepts and produce
class-representative fused features for classification. Experiments on medical
and natural image datasets show our method achieves state-of-the-art
performance, demonstrating the effectiveness and superiority of our method. We
will release the code publicly.

</details>


### [77] [AVATAR: Reinforcement Learning to See, Hear, and Reason Over Video](https://arxiv.org/abs/2508.03100)
*Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: AVATAR 解决了多模态长程视频推理的局限性，通过非策略训练和时间优势塑造提高了样本效率和性能。


<details>
  <summary>Details</summary>
Motivation: 由于需要在跨模式中进行精确的时空融合和对齐，因此对长程视频进行多模式推理具有挑战性。虽然最近的方法（例如 Group Relative Policy Optimization (GRPO)）在该领域显示出希望，但它们存在三个主要局限性：(1) 来自其在策略设计中的数据效率低下，(2) 优势消失问题，其中组内相同或几乎相同的奖励通过产生零值优势来消除学习信号，以及 (3) 未能强调关键推理步骤的统一信用分配。

Method: AVATAR 包含两个核心组件：(1) 一种非策略训练架构，通过重用具有更高奖励多样性的过去经验来提高样本效率并解决优势消失问题，以及 (2) 时间优势塑造 (TAS)，一种新的信用分配策略，可在学习期间增加关键推理阶段的权重。

Result: AVATAR 在各种基准测试中取得了出色的性能，在 MMVU 上超过 Qwen2.5-Omni 基线 +5.4，在 OmniBench 上超过 +4.9，在 Video-Holmes 上超过 +4.5，同时展示了超过 35% 的更高样本效率。

Conclusion: AVATAR在多个基准测试中表现出色，在 MMVU 上超过 Qwen2.5-Omni 基线 +5.4，在 OmniBench 上超过 +4.9，在 Video-Holmes 上超过 +4.5，同时展示了超过 35% 的更高样本效率。

Abstract: Multimodal reasoning over long-horizon video is challenging due to the need
for precise spatiotemporal fusion and alignment across modalities. While recent
methods such as Group Relative Policy Optimization (GRPO) have shown promise in
this domain, they suffer from three key limitations: (1) data inefficiency from
their on-policy design, (2) a vanishing advantage problem, where identical or
near-identical rewards within a group eliminate the learning signal by
producing zero-valued advantages, and (3) uniform credit assignment that fails
to emphasize critical reasoning steps. We introduce AVATAR (Audio-Video Agent
for Alignment and Reasoning), a framework that addresses these limitations
through two core components: (1) an off-policy training architecture that
improves sample efficiency and resolves vanishing advantages by reusing past
experiences with greater reward diversity, and (2) Temporal Advantage Shaping
(TAS), a novel credit assignment strategy that upweights key reasoning phases
during learning. AVATAR achieves strong performance across various benchmarks,
outperforming the Qwen2.5-Omni baseline by +5.4on MMVU, +4.9 on OmniBench, and
+4.5 on Video-Holmes, while demonstrating over 35% higher sample efficiency.

</details>


### [78] [Causal Disentanglement and Cross-Modal Alignment for Enhanced Few-Shot Learning](https://arxiv.org/abs/2508.03102)
*Tianjiao Jiang,Zhen Zhang,Yuhang Liu,Javen Qinfeng Shi*

Main category: cs.CV

TL;DR: 提出了因果CLIP适配器(CCA)，这是一个新颖的框架，它利用无监督独立成分分析(ICA)显式地解开从CLIP中提取的视觉特征。


<details>
  <summary>Details</summary>
Motivation: 现有的FSL方法依赖于纠缠的表征，要求模型隐式地恢复解混过程，以获得仅使用有限监督的解缠表征，这阻碍了有效的适应。

Method: 利用无监督独立成分分析(ICA)显式地解开从CLIP中提取的视觉特征。通过微调基于clip的文本分类器单向增强，并通过交叉注意机制双向增强，通过相互作用丰富视觉和文本表示。

Result: 在少样本性能和对分布偏移的鲁棒性方面，该方法始终优于最先进的方法，同时保持了计算效率。

Conclusion: CCA在11个基准数据集上进行了大量实验，结果表明，在少样本性能和对分布偏移的鲁棒性方面，该方法始终优于最先进的方法，同时保持了计算效率。

Abstract: Few-shot learning (FSL) often requires effective adaptation of models using
limited labeled data. However, most existing FSL methods rely on entangled
representations, requiring the model to implicitly recover the unmixing process
to obtain disentangled representations using only limited supervision, which
hinders effective adaptation. Recent theoretical studies show that multimodal
contrastive learning methods, such as CLIP, can disentangle latent
representations up to linear transformations. In light of this, we propose the
Causal CLIP Adapter (CCA), a novel framework that explicitly disentangles
visual features extracted from CLIP using unsupervised Independent Component
Analysis (ICA). This removes the need to learn the unmixing process from the
labeled data, thereby reducing the number of trainable parameters and
mitigating overfitting. Taking a step further, while ICA can obtain visual
disentangled representations, it may also disrupt CLIP's intra- and inter-modal
alignment. To counteract this, CCA further leverages CLIP's inherent
cross-modal alignment by enhancing it in two ways: unidirectionally, through
fine-tuning a CLIP-based text classifier, and bidirectionally, via a
cross-attention mechanism that enriches visual and textual representations
through mutual interaction. Both unimodal and cross-modal classification
outputs can be effectively combined linearly to improve classification
accuracy. Extensive experiments on 11 benchmark datasets demonstrate that our
method consistently outperforms state-of-the-art approaches in terms of
few-shot performance and robustness to distributional shifts, while maintaining
computational efficiency. Code will be available at
https://github.com/tianjiao-j/CCA.

</details>


### [79] [H3R: Hybrid Multi-view Correspondence for Generalizable 3D Reconstruction](https://arxiv.org/abs/2508.03118)
*Heng Jia,Linchao Zhu,Na Zhao*

Main category: cs.CV

TL;DR: H3R is a hybrid 3D reconstruction framework that combines volumetric latent fusion and attention-based feature aggregation to achieve state-of-the-art performance with faster convergence and better generalization.


<details>
  <summary>Details</summary>
Motivation: Generalizable 3D reconstruction remains challenging, particularly in multi-view correspondence modeling. Existing approaches face a trade-off between geometric precision and robustness.

Method: The paper presents H3R, a hybrid framework that integrates volumetric latent fusion with attention-based feature aggregation, consisting of an efficient latent volume that enforces geometric consistency through epipolar constraints, and a camera-aware Transformer that leverages Pl"ucker coordinates for adaptive correspondence refinement.

Result: H3R enhances generalization while converging 2$\times$ faster than existing methods. Spatial-aligned foundation models (e.g., SD-VAE) substantially outperform semantic-aligned models (e.g., DINOv2). The method supports variable-number and high-resolution input views while demonstrating robust cross-dataset generalization.

Conclusion: The proposed H3R method achieves state-of-the-art performance across multiple benchmarks, with significant PSNR improvements of 0.59 dB, 1.06 dB, and 0.22 dB on the RealEstate10K, ACID, and DTU datasets, respectively.

Abstract: Despite recent advances in feed-forward 3D Gaussian Splatting, generalizable
3D reconstruction remains challenging, particularly in multi-view
correspondence modeling. Existing approaches face a fundamental trade-off:
explicit methods achieve geometric precision but struggle with ambiguous
regions, while implicit methods provide robustness but suffer from slow
convergence. We present H3R, a hybrid framework that addresses this limitation
by integrating volumetric latent fusion with attention-based feature
aggregation. Our framework consists of two complementary components: an
efficient latent volume that enforces geometric consistency through epipolar
constraints, and a camera-aware Transformer that leverages Pl\"ucker
coordinates for adaptive correspondence refinement. By integrating both
paradigms, our approach enhances generalization while converging 2$\times$
faster than existing methods. Furthermore, we show that spatial-aligned
foundation models (e.g., SD-VAE) substantially outperform semantic-aligned
models (e.g., DINOv2), resolving the mismatch between semantic representations
and spatial reconstruction requirements. Our method supports variable-number
and high-resolution input views while demonstrating robust cross-dataset
generalization. Extensive experiments show that our method achieves
state-of-the-art performance across multiple benchmarks, with significant PSNR
improvements of 0.59 dB, 1.06 dB, and 0.22 dB on the RealEstate10K, ACID, and
DTU datasets, respectively. Code is available at
https://github.com/JiaHeng-DLUT/H3R.

</details>


### [80] [Landsat30-AU: A Vision-Language Dataset for Australian Landsat Imagery](https://arxiv.org/abs/2508.03127)
*Sai Ma,Zhuang Li,John A Taylor*

Main category: cs.CV

TL;DR: 提出了 Landsat30-AU，一个大规模的卫星图像视觉语言数据集，并表明现有模型难以理解卫星图像，但可以通过对 Qwen2.5-VL-7B 进行微调来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集主要关注来自有限数量卫星的短期、高分辨率图像，忽略了低分辨率、多卫星、长期档案（如 Landsat），这对于经济实惠且具有偏差鲁棒性的全球监测至关重要。我们通过 Landsat30-AU 解决了这个差距。

Method: 构建了一个大规模视觉语言数据集 Landsat30-AU，该数据集由四个 Landsat 卫星（5、7、8 和 9）在澳大利亚收集的 30 米分辨率图像组成，跨越 36 年以上。该数据集包括两个组成部分：Landsat30-AU-Cap，包含 196,262 个图像-字幕对；以及 Landsat30-AU-VQA，包含 17,725 个跨八个遥感领域的人工验证视觉问题解答 (VQA) 样本。两个数据集都通过一个自举pipeline进行管理，该pipeline利用通用 VLM 进行迭代细化和人工验证以确保质量。

Result: 在我们的基准测试中对八个 VLM 的评估表明，现成的模型很难理解卫星图像。开源遥感 VLM EarthDial 在 captioning 中仅达到 0.07 SPIDEr，VQA 准确率为 0.48，突显了当前方法的局限性。

Conclusion: 轻量级微调 Qwen2.5-VL-7B 在 Landsat30-AU 上将 captioning 性能从 0.11 提高到 0.31 SPIDEr，并将 VQA 准确率从 0.74 提高到 0.87。

Abstract: Vision language models (VLMs) that enable natural language interaction with
satellite imagery can democratize Earth observation by accelerating expert
workflows, making data accessible to non-specialists, and enabling planet-scale
automation. However, existing datasets focus mainly on short-term,
high-resolution imagery from a limited number of satellites, overlooking
low-resolution, multi-satellite, long-term archives, such as Landsat, that are
essential for affordable and bias-robust global monitoring. We address this gap
with Landsat30-AU, a large-scale vision-language dataset built from 30-meter
resolution imagery collected by four Landsat satellites (5, 7, 8, and 9) over
Australia, spanning more than 36 years. The dataset includes two components:
Landsat30-AU-Cap, containing 196,262 image-caption pairs, and Landsat30-AU-VQA,
comprising 17,725 human-verified visual question answering (VQA) samples across
eight remote sensing domains. Both datasets are curated through a bootstrapped
pipeline that leverages generic VLMs with iterative refinement and human
verification to ensure quality. Our evaluation of eight VLMs on our benchmark
reveals that off-the-shelf models struggle to understand satellite imagery. The
open-source remote-sensing VLM EarthDial achieves only 0.07 SPIDEr in
captioning and a VQA accuracy of 0.48, highlighting the limitations of current
approaches. Encouragingly, lightweight fine-tuning of Qwen2.5-VL-7B on
Landsat30-AU improves captioning performance from 0.11 to 0.31 SPIDEr and
boosts VQA accuracy from \textbf{0.74} to 0.87. Code and data are available at
https://github.com/papersubmit1/landsat30-au.

</details>


### [81] [COFFEE: A Shadow-Resilient Real-Time Pose Estimator for Unknown Tumbling Asteroids using Sparse Neural Networks](https://arxiv.org/abs/2508.03132)
*Arion Zimmermann,Soon-Jo Chung,Fred Hadaegh*

Main category: cs.CV

TL;DR: This paper introduces COFFEE, a real-time pose estimation framework for asteroids that leverages sun phase angle information and is bias-free, more accurate, and faster than existing methods.


<details>
  <summary>Details</summary>
Motivation: The accurate state estimation of unknown bodies in space is a critical challenge with applications ranging from the tracking of space debris to the shape estimation of small bodies. Existing methods, such as SIFT, ORB and AKAZE, achieve real-time but inaccurate pose estimates, whereas modern deep learning methods yield higher quality features at the cost of more demanding computational resources which might not be available on space-qualified hardware. Additionally, both classical and data-driven methods are not robust to the highly opaque self-cast shadows on the object of interest. We show that, as the target body rotates, these shadows may lead to large biases in the resulting pose estimates. For these objects, a bias in the real-time pose estimation algorithm may mislead the spacecraft's state estimator and cause a mission failure, especially if the body undergoes a chaotic tumbling motion.

Method: We present COFFEE, the Celestial Occlusion Fast FEature Extractor, a real-time pose estimation framework for asteroids designed to leverage prior information on the sun phase angle given by sun-tracking sensors commonly available onboard spacecraft. By associating salient contours to their projected shadows, a sparse set of features are detected, invariant to the motion of the shadows. A Sparse Neural Network followed by an attention-based Graph Neural Network feature matching model are then jointly trained to provide a set of correspondences between successive frames.

Result: The resulting pose estimation pipeline is found to be bias-free, more accurate than classical pose estimation pipelines and an order of magnitude faster than other state-of-the-art deep learning pipelines on synthetic data as well as on renderings of the tumbling asteroid Apophis.

Conclusion: The resulting pose estimation pipeline is found to be bias-free, more accurate than classical pose estimation pipelines and an order of magnitude faster than other state-of-the-art deep learning pipelines on synthetic data as well as on renderings of the tumbling asteroid Apophis.

Abstract: The accurate state estimation of unknown bodies in space is a critical
challenge with applications ranging from the tracking of space debris to the
shape estimation of small bodies. A necessary enabler to this capability is to
find and track features on a continuous stream of images. Existing methods,
such as SIFT, ORB and AKAZE, achieve real-time but inaccurate pose estimates,
whereas modern deep learning methods yield higher quality features at the cost
of more demanding computational resources which might not be available on
space-qualified hardware. Additionally, both classical and data-driven methods
are not robust to the highly opaque self-cast shadows on the object of
interest. We show that, as the target body rotates, these shadows may lead to
large biases in the resulting pose estimates. For these objects, a bias in the
real-time pose estimation algorithm may mislead the spacecraft's state
estimator and cause a mission failure, especially if the body undergoes a
chaotic tumbling motion. We present COFFEE, the Celestial Occlusion Fast
FEature Extractor, a real-time pose estimation framework for asteroids designed
to leverage prior information on the sun phase angle given by sun-tracking
sensors commonly available onboard spacecraft. By associating salient contours
to their projected shadows, a sparse set of features are detected, invariant to
the motion of the shadows. A Sparse Neural Network followed by an
attention-based Graph Neural Network feature matching model are then jointly
trained to provide a set of correspondences between successive frames. The
resulting pose estimation pipeline is found to be bias-free, more accurate than
classical pose estimation pipelines and an order of magnitude faster than other
state-of-the-art deep learning pipelines on synthetic data as well as on
renderings of the tumbling asteroid Apophis.

</details>


### [82] [Uint: Building Uint Detection Dataset](https://arxiv.org/abs/2508.03139)
*Haozhou Zhai,Yanzhe Gao,Tianjiang Hu*

Main category: cs.CV

TL;DR: 创建了一个无人机拍摄的建筑物火灾合成数据集，以解决带注释的火灾数据的短缺问题。


<details>
  <summary>Details</summary>
Motivation: 缺乏专门针对建筑单元的带注释的数据，这对于训练稳健的计算机视觉模型至关重要，尤其是在火灾早期预警和紧急救援行动等任务中。

Method: 使用真实的多层场景构建背景，结合运动模糊和亮度调整以增强捕获图像的真实性，模拟各种情况下的无人机拍摄条件，并采用大型模型在不同位置生成火灾效果。

Result: 引入了一个由无人机捕获的带注释的建筑物单元数据集，该数据集结合了多种增强技术。生成的合成数据集包含各种建筑场景，共有 1,978 张图像。

Conclusion: 该合成数据集包含各种建筑场景，共有 1,978 张图像。该数据集可以有效提高火灾单元检测的泛化能力，提供多场景和可扩展的数据，同时降低与收集真实火灾数据相关的风险和成本。

Abstract: Fire scene datasets are crucial for training robust computer vision models,
particularly in tasks such as fire early warning and emergency rescue
operations. However, among the currently available fire-related data, there is
a significant shortage of annotated data specifically targeting building
units.To tackle this issue, we introduce an annotated dataset of building units
captured by drones, which incorporates multiple enhancement techniques. We
construct backgrounds using real multi-story scenes, combine motion blur and
brightness adjustment to enhance the authenticity of the captured images,
simulate drone shooting conditions under various circumstances, and employ
large models to generate fire effects at different locations.The synthetic
dataset generated by this method encompasses a wide range of building
scenarios, with a total of 1,978 images. This dataset can effectively improve
the generalization ability of fire unit detection, providing multi-scenario and
scalable data while reducing the risks and costs associated with collecting
real fire data. The dataset is available at
https://github.com/boilermakerr/FireUnitData.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [Efficient Agents: Building Effective Agents While Reducing Cost](https://arxiv.org/abs/2508.02694)
*Ningning Wang,Xavier Hu,Pai Liu,He Zhu,Yue Hou,Heyuan Huang,Shengyu Zhang,Jian Yang,Jiaheng Liu,Ge Zhang,Changwang Zhang,Jun Wang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: LLM agents are expensive. This paper optimizes agent framework design to reduce costs by 28.4% while maintaining 96.7% performance.


<details>
  <summary>Details</summary>
Motivation: Escalating costs of Large Language Model (LLM)-driven agents threaten scalability and accessibility, necessitating cost-effective designs without sacrificing performance.

Method: Empirical analysis on the GAIA benchmark to evaluate the impact of LLM backbone selection, agent framework designs, and test-time scaling strategies, using the cost-of-pass metric.

Result: Efficient Agents retains 96.7% of the performance of OWL while reducing operational costs from $0.398 to $0.228, resulting in a 28.4% improvement in cost-of-pass.

Conclusion: This work introduces Efficient Agents, a novel agent framework that balances complexity and task requirements, achieving 96.7% of OWL's performance with a 28.4% cost-of-pass improvement (reducing costs from $0.398 to $0.228).

Abstract: The remarkable capabilities of Large Language Model (LLM)-driven agents have
enabled sophisticated systems to tackle complex, multi-step tasks, but their
escalating costs threaten scalability and accessibility. This work presents the
first systematic study of the efficiency-effectiveness trade-off in modern
agent systems, addressing the critical need for cost-effective designs without
sacrificing performance. We investigate three key questions: (1) How much
complexity do agentic tasks inherently require? (2) When do additional modules
yield diminishing returns? (3) How much efficiency can be gained through the
design of efficient agent frameworks? Through an empirical analysis on the GAIA
benchmark, we evaluate the impact of LLM backbone selection, agent framework
designs, and test-time scaling strategies. Using the cost-of-pass metric, we
quantify the efficiency-performance trade-off across these dimensions. Our
findings inform the development of Efficient Agents , a novel agent framework
that has an optimal complexity to task requirements. Efficient Agents retains
96.7% of the performance of OWL, one leading open-source agent framework, while
reducing operational costs from $0.398 to $0.228, resulting in a 28.4%
improvement in cost-of-pass. Our work provides actionable insights for
designing efficient, high-performing agent systems, advancing the accessibility
and sustainability of AI-driven solutions.

</details>


### [84] [Planning with Dynamically Changing Domains](https://arxiv.org/abs/2508.02697)
*Mikhail Soutchanski,Yongmei Liu*

Main category: cs.AI

TL;DR: 本文提出了一种解决具有动态对象创建和销毁的规划问题的方法，该方法超越了传统的域封闭假设 (DCA)。


<details>
  <summary>Details</summary>
Motivation: 在经典规划和一致性规划中，假设预先给出了有限多个命名对象，并且只有它们可以参与动作和流畅。这是域封闭假设（DCA）。然而，存在实际的规划问题，其中对象的集合随着动作的执行而动态变化；例如，可以创建新对象，销毁旧对象。

Method: 我们在命题逻辑中制定了规划问题，假设初始理论是流畅文字的有限一致集合，讨论了何时这保证在每种情况下只有有限多个可能的动作，对计划的长度施加有限整数界限，并提出组织在规划时接地的动作序列上的搜索。

Result: 我们的方法可以解决没有 DCA 的有界规划问题，这些问题属于顺序泛化规划（没有感知动作）和一致性规划的交集，但限制在没有流畅文字的分离的情况下。

Conclusion: 我们证明了我们方法的正确性和完整性。它可以用来解决属于序列泛化规划（没有感知动作）和一致性规划的交集的有界规划问题，限制在没有流畅文字的析取的情况下。我们讨论了我们的规划器的概念验证实现。

Abstract: In classical planning and conformant planning, it is assumed that there are
finitely many named objects given in advance, and only they can participate in
actions and in fluents. This is the Domain Closure Assumption (DCA). However,
there are practical planning problems where the set of objects changes
dynamically as actions are performed; e.g., new objects can be created, old
objects can be destroyed. We formulate the planning problem in first-order
logic, assume an initial theory is a finite consistent set of fluent literals,
discuss when this guarantees that in every situation there are only finitely
many possible actions, impose a finite integer bound on the length of the plan,
and propose to organize search over sequences of actions that are grounded at
planning time. We show the soundness and completeness of our approach. It can
be used to solve the bounded planning problems without DCA that belong to the
intersection of sequential generalized planning (without sensing actions) and
conformant planning, restricted to the case without the disjunction over fluent
literals. We discuss a proof-of-the-concept implementation of our planner.

</details>


### [85] [Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model](https://arxiv.org/abs/2508.02734)
*Weiyu Luo,Chenfeng Xiong*

Main category: cs.AI

TL;DR: 本文提出了一种新的解决方案，即变量选择网络融合插入Transformer (VSNIT)，用于恢复不完整活动序列中缺失的片段，同时保留现有数据。


<details>
  <summary>Details</summary>
Motivation: 基于位置的服务(LBS)数据提供了对人类移动性的重要见解，但其稀疏性通常会产生不完整的行程和活动序列，从而难以对行程和活动进行准确的推断。

Method: Variable Selection Network-fused Insertion Transformer (VSNIT)

Result: VSNIT插入了更多样化、更真实的活动模式，更紧密地匹配了真实世界的变异性，并更有效地恢复了中断的活动转换，与目标更加一致。它在所有指标上也明显优于基线模型。

Conclusion: VSNIT在活动序列恢复任务中表现出卓越的准确性和多样性，证明了其增强LBS数据在移动性分析中的效用的潜力。该方法为未来基于位置的研究和应用提供了一个有希望的框架。

Abstract: Location-Based Service (LBS) data provides critical insights into human
mobility, yet its sparsity often yields incomplete trip and activity sequences,
making accurate inferences about trips and activities difficult. We raise a
research problem: Can we use activity sequences derived from high-quality LBS
data to recover incomplete activity sequences at the individual level? This
study proposes a new solution, the Variable Selection Network-fused Insertion
Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence
construction with the Variable Selection Network's dynamic covariate handling
capability, to recover missing segments in incomplete activity sequences while
preserving existing data. The findings show that VSNIT inserts more diverse,
realistic activity patterns, more closely matching real-world variability, and
restores disrupted activity transitions more effectively aligning with the
target. It also performs significantly better than the baseline model across
all metrics. These results highlight VSNIT's superior accuracy and diversity in
activity sequence recovery tasks, demonstrating its potential to enhance LBS
data utility for mobility analysis. This approach offers a promising framework
for future location-based research and applications.

</details>


### [86] [Large Language Model-based Data Science Agent: A Survey](https://arxiv.org/abs/2508.02744)
*Peiran Wang,Yaoning Yu,Ke Chen,Xianyang Zhan,Haohan Wang*

Main category: cs.AI

TL;DR: This survey reviews LLM-based agents for data science, covering design principles and practical workflows.


<details>
  <summary>Details</summary>
Motivation: The rapid advancement of Large Language Models (LLMs) has driven novel applications across diverse domains, with LLM-based agents emerging as a crucial area of exploration.

Method: The survey analyzes LLM-based agents designed for data science tasks, summarizing insights from recent studies.

Result: The survey discusses key design principles from the agent perspective, covering agent roles, execution, knowledge, and reflection methods. It also identifies key processes for LLM-based agents from the data science perspective, including data preprocessing, model development, evaluation, visualization, etc.

Conclusion: This survey offers a comprehensive review of recent developments in applying LLM-based agents to data science tasks and provides a dual-perspective framework that connects general agent design principles with practical workflows in data science.

Abstract: The rapid advancement of Large Language Models (LLMs) has driven novel
applications across diverse domains, with LLM-based agents emerging as a
crucial area of exploration. This survey presents a comprehensive analysis of
LLM-based agents designed for data science tasks, summarizing insights from
recent studies. From the agent perspective, we discuss the key design
principles, covering agent roles, execution, knowledge, and reflection methods.
From the data science perspective, we identify key processes for LLM-based
agents, including data preprocessing, model development, evaluation,
visualization, etc. Our work offers two key contributions: (1) a comprehensive
review of recent developments in applying LLMbased agents to data science
tasks; (2) a dual-perspective framework that connects general agent design
principles with the practical workflows in data science.

</details>


### [87] [Cognitive Loop via In-Situ Optimization: Self-Adaptive Reasoning for Science](https://arxiv.org/abs/2508.02789)
*Newman Cheng,Gordon Broadbent,William Chappell*

Main category: cs.AI

TL;DR: The paper introduces CLIO, a novel approach for AI-driven scientific discovery that offers deep control over the reasoning process, leading to improved accuracy and insights in biology and medicine questions.


<details>
  <summary>Details</summary>
Motivation: Scientists require accuracy, transparency, and steerability in AI-driven scientific discovery, which current AI development landscapes do not fully provide.

Method: The study introduces a cognitive loop via in-situ optimization (CLIO) that enables large language models (LLMs) to self-formulate ways of approaching a problem, adapt behavior when self-confidence is low, and ultimately provide scientists with a final belief or answer.

Result: GPT-4.1 with CLIO yields an accuracy of 22.37% in text-based biology and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82% net or 161.64% relative increase when compared to the base GPT-4.1 model and surpasses OpenAI's o3 performance in high and low reasoning effort modes.

Conclusion: The study found that oscillations within internal uncertainty measures are key in determining the accuracy of CLIO's results, revealing how its open design and internal mechanisms can provide insight and control into scientific decision-making processes.

Abstract: The capacity for artificial intelligence (AI) to formulate, evolve, and test
altered thought patterns under dynamic conditions indicates advanced cognition
that is crucial for scientific discovery. The existing AI development landscape
falls into two categories: 1) frameworks over non-reasoning models that
natively incorporate opinions on how humans think, and 2) reasoning models that
abstract precise control of the reasoning intuition away from end users. While
powerful, for scientists to maximize utility of AI in scientific discovery,
they not only require accuracy and transparency in reasoning, but also
steerability. Hence, we introduce an alternative approach that enables deep and
precise control over the reasoning process called: a cognitive loop via in-situ
optimization (CLIO). CLIO enables large language models (LLMs) to
self-formulate ways of approaching a problem, adapt behavior when
self-confidence is low, and ultimately provide scientists with a final belief
or answer. Through CLIO's open design, scientists can observe uncertainty
levels, understand how final belief states are formulated using graph
structures, and interject corrections. Without any further post-training,
OpenAI's GPT-4.1 with CLIO yields an accuracy of 22.37\% in text-based biology
and medicine questions on Humanity's Last Exam (HLE). This yields a 13.82\% net
or 161.64\% relative increase when compared to the base GPT-4.1 model and
surpasses OpenAI's o3 performance in high and low reasoning effort modes. We
further discovered that oscillations within internal uncertainty measures are
key in determining the accuracy of CLIO's results, revealing how its open
design and internal mechanisms can provide insight and control into scientific
decision-making processes.

</details>


### [88] [A Multi-Agent System for Complex Reasoning in Radiology Visual Question Answering](https://arxiv.org/abs/2508.02841)
*Ziruo Yi,Jinyu Liu,Ting Xiao,Mark V. Albert*

Main category: cs.AI

TL;DR: 引入了一种多智能体系统（MAS），旨在支持RVQA中的复杂推理，与强大的MLLM基线相比，该系统具有优越性和有效性。


<details>
  <summary>Details</summary>
Motivation: 放射学视觉问题回答（RVQA）为关于胸部X射线图像的问题提供精确的答案，从而减轻了放射科医生的工作量。虽然最近基于多模态大型语言模型（MLLM）和检索增强生成（RAG）的方法在RVQA中显示出可喜的进展，但它们仍然面临事实准确性、幻觉和跨模态错位方面的挑战。

Method: 设计了一个多智能体系统（MAS），该系统旨在支持RVQA中的复杂推理，具有用于上下文理解、多模态推理和答案验证的专用代理。

Result: 通过模型不一致过滤，在具有挑战性的RVQA集上评估了该系统，该系统包含跨多个MLLM的一致困难案例。 广泛的实验证明了该系统相对于强大的MLLM基线的优越性和有效性，并通过案例研究说明了其可靠性和可解释性。

Conclusion: 多智能体系统在需要复杂推理的可解释和值得信赖的临床人工智能应用中具有潜力。

Abstract: Radiology visual question answering (RVQA) provides precise answers to
questions about chest X-ray images, alleviating radiologists' workload. While
recent methods based on multimodal large language models (MLLMs) and
retrieval-augmented generation (RAG) have shown promising progress in RVQA,
they still face challenges in factual accuracy, hallucinations, and cross-modal
misalignment. We introduce a multi-agent system (MAS) designed to support
complex reasoning in RVQA, with specialized agents for context understanding,
multimodal reasoning, and answer validation. We evaluate our system on a
challenging RVQA set curated via model disagreement filtering, comprising
consistently hard cases across multiple MLLMs. Extensive experiments
demonstrate the superiority and effectiveness of our system over strong MLLM
baselines, with a case study illustrating its reliability and interpretability.
This work highlights the potential of multi-agent approaches to support
explainable and trustworthy clinical AI applications that require complex
reasoning.

</details>


### [89] [Seemingly Simple Planning Problems are Computationally Challenging: The Countdown Game](https://arxiv.org/abs/2508.02900)
*Michael Katz,Harsha Kokel,Sarath Sreedharan*

Main category: cs.AI

TL;DR: A new NP-complete planning benchmark, Countdown, is proposed to address the shortcomings of existing benchmarks and better evaluate the planning capabilities of LLMs. LLMs struggle with it.


<details>
  <summary>Details</summary>
Motivation: Existing planning benchmarks are inadequate for measuring the planning capabilities of current foundational models and agents.

Method: A procedure for creating a planning benchmark centered around the game Countdown.

Result: The proposed Countdown benchmark is computationally challenging (NP-complete) and remains extremely challenging for existing LLM-based approaches.

Conclusion: Existing LLM-based approaches struggle with the proposed Countdown benchmark, unlike simpler domains like 24 Game.

Abstract: There is a broad consensus that the inability to form long-term plans is one
of the key limitations of current foundational models and agents. However, the
existing planning benchmarks remain woefully inadequate to truly measure their
planning capabilities. Most existing benchmarks either focus on loosely defined
tasks like travel planning or end up leveraging existing domains and problems
from international planning competitions. While the former tasks are hard to
formalize and verify, the latter were specifically designed to test and
challenge the weaknesses of existing automated planners. To address these
shortcomings, we propose a procedure for creating a planning benchmark centered
around the game called Countdown, where a player is expected to form a target
number from a list of input numbers through arithmetic operations. We discuss
how this problem meets many of the desiderata associated with an ideal
benchmark for planning capabilities evaluation. Specifically, the domain allows
for an intuitive, natural language description for each problem instance, it is
computationally challenging (NP-complete), and the instance space is rich
enough that we do not have to worry about memorization. We perform an extensive
theoretical analysis, establishing the computational complexity result and
demonstrate the advantage of our instance generation procedure over public
benchmarks. We evaluate a variety of existing LLM-assisted planning methods on
instances generated using our procedure. Our results show that, unlike other
domains like 24 Game (a special case of Countdown), our proposed dynamic
benchmark remains extremely challenging for existing LLM-based approaches.

</details>


### [90] [Enhancing Japanese Large Language Models with Reasoning Vectors](https://arxiv.org/abs/2508.02913)
*Carolina Minami Oguchi,Leo Wei,Koyo Kobayashi,Hsin-Tai Wu,Dipak Ghosal*

Main category: cs.AI

TL;DR: 我们受到任务向量的启发，该任务向量提取训练前后权重的变化，专门针对某个任务，我们从推理 LLM 中获得推理向量，并将它们应用于日语 LLM 以提高它们的性能。


<details>
  <summary>Details</summary>
Motivation: 由于所需的资源量，训练后方法改进主流大型语言模型 (LLM) 的性能和增强推理能力具有挑战性，但对于日语 LLM 来说，实现同样的目标具有挑战性。

Method: 我们从推理 LLM 中获得推理向量，并将它们应用于日语 LLM 以提高它们的性能。

Result: 将推理向量应用于日语 LLM 以提高它们的性能。

Conclusion: 我们提出了一种简单有效的方法来获得高性能，并希望为其他语言提供灵感。

Abstract: Post-training methods have improved the performance and enhanced the
reasoning capability for mainstream large language models (LLMs), but the same
is challenging for Japanese LLMs to achieve due to the amount of resources
required. Inspired by task vectors that extract the change of weights before
and after training, specifically for a certain task, we obtain reasoning
vectors from reasoning LLMs and apply them to Japanese LLMs to boost their
performance. While the resources available present a challenge to improve
Japanese LLMs, we present a simple and effective way to obtain high improvement
and hope to inspire for other languages.

</details>


### [91] [PentestJudge: Judging Agent Behavior Against Operational Requirements](https://arxiv.org/abs/2508.02921)
*Shane Caldwell,Max Harley,Michael Kouremetis,Vincent Abruzzo,Will Pearce*

Main category: cs.AI

TL;DR: PentestJudge, a LLM-as-judge system, evaluates penetration testing agents, achieving an F1 score of 0.83, and finds weaker models can judge stronger models' pentests.


<details>
  <summary>Details</summary>
Motivation: Evaluating the operations of penetration testing agents is hard, current methods are impractical to evaluate programmatically.

Method: We develop rubrics that use a tree structure to hierarchically collapse the penetration testing task for a particular environment into smaller, simpler, and more manageable sub-tasks and criteria until each leaf node represents simple yes-or-no criteria for PentestJudge to evaluate.

Result: The best model reached an F1 score of 0.83. We find models that are better at tool-use perform more closely to human experts. We find that weaker and cheaper models can judge the trajectories of pentests performed by stronger and more expensive models, suggesting verification may be easier than generation for the penetration testing task.

Conclusion: We share this methodology to facilitate future research in understanding the ability of judges to holistically and scalably evaluate the process quality of AI-based information security agents so that they may be confidently used in sensitive production environments.

Abstract: We introduce PentestJudge, a system for evaluating the operations of
penetration testing agents. PentestJudge is a large language model
(LLM)-as-judge with access to tools that allow it to consume arbitrary
trajectories of agent states and tool call history to determine whether a
security agent's actions meet certain operating criteria that would be
impractical to evaluate programmatically. We develop rubrics that use a tree
structure to hierarchically collapse the penetration testing task for a
particular environment into smaller, simpler, and more manageable sub-tasks and
criteria until each leaf node represents simple yes-or-no criteria for
PentestJudge to evaluate. Task nodes are broken down into different categories
related to operational objectives, operational security, and tradecraft.
LLM-as-judge scores are compared to human domain experts as a ground-truth
reference, allowing us to compare their relative performance with standard
binary classification metrics, such as F1 scores. We evaluate several frontier
and open-source models acting as judge agents, with the best model reaching an
F1 score of 0.83. We find models that are better at tool-use perform more
closely to human experts. By stratifying the F1 scores by requirement type, we
find even models with similar overall scores struggle with different types of
questions, suggesting certain models may be better judges of particular
operating criteria. We find that weaker and cheaper models can judge the
trajectories of pentests performed by stronger and more expensive models,
suggesting verification may be easier than generation for the penetration
testing task. We share this methodology to facilitate future research in
understanding the ability of judges to holistically and scalably evaluate the
process quality of AI-based information security agents so that they may be
confidently used in sensitive production environments.

</details>


### [92] [AQUAH: Automatic Quantification and Unified Agent in Hydrology](https://arxiv.org/abs/2508.02936)
*Songkun Yan,Zhi Li,Siyu Zhu,Yixin Wen,Mofan Zhang,Mengye Chen,Jie Cao,Yang Hong*

Main category: cs.AI

TL;DR: AQUAH is the first end-to-end language-based agent for hydrologic modeling. It uses vision-enabled large language models to automate the process of retrieving data, configuring a hydrologic model, running the simulation, and generating a report.


<details>
  <summary>Details</summary>
Motivation: To introduce AQUAH, the first end-to-end language-based agent designed specifically for hydrologic modeling.

Method: vision-enabled large language models, which interpret maps and rasters on the fly and steer key decisions such as outlet selection, parameter initialization, and uncertainty commentary.

Result: AQUAH autonomously retrieves the required terrain, forcing, and gauge data; configures a hydrologic model; runs the simulation; and generates a self-contained PDF report. Initial experiments across a range of U.S. basins show that AQUAH can complete cold-start simulations and produce analyst-ready documentation without manual intervention. The results are judged by hydrologists as clear, transparent, and physically plausible.

Conclusion: AQUAH can complete cold-start simulations and produce analyst-ready documentation without manual intervention. The results are judged by hydrologists as clear, transparent, and physically plausible. While further calibration and validation are still needed for operational deployment, these early outcomes highlight the promise of LLM-centered, vision-grounded agents to streamline complex environmental modeling and lower the barrier between Earth observation data, physics-based tools, and decision makers.

Abstract: We introduce AQUAH, the first end-to-end language-based agent designed
specifically for hydrologic modeling. Starting from a simple natural-language
prompt (e.g., 'simulate floods for the Little Bighorn basin from 2020 to
2022'), AQUAH autonomously retrieves the required terrain, forcing, and gauge
data; configures a hydrologic model; runs the simulation; and generates a
self-contained PDF report. The workflow is driven by vision-enabled large
language models, which interpret maps and rasters on the fly and steer key
decisions such as outlet selection, parameter initialization, and uncertainty
commentary. Initial experiments across a range of U.S. basins show that AQUAH
can complete cold-start simulations and produce analyst-ready documentation
without manual intervention. The results are judged by hydrologists as clear,
transparent, and physically plausible. While further calibration and validation
are still needed for operational deployment, these early outcomes highlight the
promise of LLM-centered, vision-grounded agents to streamline complex
environmental modeling and lower the barrier between Earth observation data,
physics-based tools, and decision makers.

</details>


### [93] [MedBLINK: Probing Basic Perception in Multimodal Language Models for Medicine](https://arxiv.org/abs/2508.02951)
*Mahtab Bigverdi,Wisdom Ikezogwo,Kevin Zhang,Hyewon Jeong,Mingyu Lu,Sungjae Cho,Linda Shapiro,Ranjay Krishna*

Main category: cs.AI

TL;DR: Medblink, a benchmark, reveals that current MLMs frequently fail at routine perceptual checks


<details>
  <summary>Details</summary>
Motivation: MLMs show promise for clinical decision support and diagnostic reasoning, raising the prospect of end-to-end automated medical image interpretation. However, clinicians are highly selective in adopting AI tools

Method: a benchmark designed to probe these models for such perceptual abilities

Result: While human annotators achieve 96.4% accuracy, the best-performing model reaches only 65%

Conclusion: current MLMs frequently fail at routine perceptual checks, suggesting the need to strengthen their visual grounding to support clinical adoption

Abstract: Multimodal language models (MLMs) show promise for clinical decision support
and diagnostic reasoning, raising the prospect of end-to-end automated medical
image interpretation. However, clinicians are highly selective in adopting AI
tools; a model that makes errors on seemingly simple perception tasks such as
determining image orientation or identifying whether a CT scan is
contrast-enhance are unlikely to be adopted for clinical tasks. We introduce
Medblink, a benchmark designed to probe these models for such perceptual
abilities. Medblink spans eight clinically meaningful tasks across multiple
imaging modalities and anatomical regions, totaling 1,429 multiple-choice
questions over 1,605 images. We evaluate 19 state-of-the-art MLMs, including
general purpose (GPT4o, Claude 3.5 Sonnet) and domain specific (Med Flamingo,
LLaVA Med, RadFM) models. While human annotators achieve 96.4% accuracy, the
best-performing model reaches only 65%. These results show that current MLMs
frequently fail at routine perceptual checks, suggesting the need to strengthen
their visual grounding to support clinical adoption. Data is available on our
project page.

</details>


### [94] [Polymath: A Self-Optimizing Agent with Dynamic Hierarchical Workflow](https://arxiv.org/abs/2508.02959)
*Chia-Tung Ho,Jing Gong,Xufeng Yao,Yunsheng Bai,Abhishek B Akkur,Haoxing Ren*

Main category: cs.AI

TL;DR: Polymath 是一种具有动态分层工作流程的自优化代理，它利用任务流程图的灵活性和代码表示的工作流程的表达能力来解决各种现实世界的动态问题，无需标记数据即可优化工作流程。


<details>
  <summary>Details</summary>
Motivation: 通过文本界面手动将基础模型嵌入到诸如 Chain-of-Thought、Self-Reflection 和 ReACT 等代理系统中，限制了可扩展性和效率。现有方法通常依赖于标记数据集来训练和优化工作流程，这使得它们对于解决无法获得标记数据的现实世界动态问题无效且不灵活。

Method: 提出了一种优化方法，该方法将多网格启发式图优化与自我反思引导的进化算法相结合，以在没有标签数据的情况下改进工作流程。

Result: Polymath 实现了比最先进的基线平均 8.1% 的改进。

Conclusion: Polymath在六个基准数据集（包括编码、数学和多轮 QA 任务）上的实验结果表明，与最先进的基线相比，Polymath 平均提高了 8.1%。

Abstract: Large language models (LLMs) excel at solving complex tasks by executing
agentic workflows composed of detailed instructions and structured operations.
Yet, building general-purpose agents by manually embedding foundation models
into agentic systems such as Chain-of-Thought, Self-Reflection, and ReACT
through text interfaces limits scalability and efficiency. Recently, many
researchers have sought to automate the generation and optimization of these
workflows through code-based representations. However, existing methods often
rely on labeled datasets to train and optimize workflows, making them
ineffective and inflexible for solving real-world, dynamic problems where
labeled data is unavailable. To address this challenge, we introduce Polymath,
a self-optimizing agent with dynamic hierarchical workflow that leverages the
flexibility of task flow graphs and the expressiveness of code-represented
workflows to solve a wide range of real-world, dynamic problems. The proposed
optimization methodology integrates multi-grid-inspired graph optimization with
a self-reflection-guided evolutionary algorithm to refine workflows without
labeled data. Experimental results on six benchmark datasets across coding,
math, and multi-turn QA tasks show that Polymath achieves 8.1% average
improvement over state-of-the-art baselines.

</details>


### [95] [Defend LLMs Through Self-Consciousness](https://arxiv.org/abs/2508.02961)
*Boshi Huang,Fabio Nonato de Paula*

Main category: cs.AI

TL;DR: 该论文提出了一种基于自意识的轻量级、低成本的 LLM 防御机制，可有效防御提示注入攻击，并提高了 LLM 的伦理安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型面临提示注入攻击的威胁，需要有效的防御机制。

Method: 该论文提出了一个包含元认知和仲裁模块的框架，使 LLM 能够自主评估和调节自身的输出。

Result: 在七个最先进的 LLM 上，使用 AdvBench 和 Prompt-Injection-Mixed-Techniques-2024 两个数据集进行评估，结果表明防御成功率显著提高。

Conclusion: 这篇论文提出了一种新颖的自意识防御机制，用于大型语言模型 (LLM) 以对抗提示注入攻击。该方法利用 LLM 固有的推理能力来进行自我保护，而无需依赖外部分类器。实验结果表明，该方法在模型和数据集的防御成功率方面取得了显着改进，在增强模式下，部分模型实现了完美和接近完美的防御。

Abstract: This paper introduces a novel self-consciousness defense mechanism for Large
Language Models (LLMs) to combat prompt injection attacks. Unlike traditional
approaches that rely on external classifiers, our method leverages the LLM's
inherent reasoning capabilities to perform self-protection. We propose a
framework that incorporates Meta-Cognitive and Arbitration Modules, enabling
LLMs to evaluate and regulate their own outputs autonomously. Our approach is
evaluated on seven state-of-the-art LLMs using two datasets: AdvBench and
Prompt-Injection-Mixed-Techniques-2024. Experiment results demonstrate
significant improvements in defense success rates across models and datasets,
with some achieving perfect and near-perfect defense in Enhanced Mode. We also
analyze the trade-off between defense success rate improvement and
computational overhead. This self-consciousness method offers a lightweight,
cost-effective solution for enhancing LLM ethics, particularly beneficial for
GenAI use cases across various platforms.

</details>


### [96] [Unified Tool Integration for LLMs: A Protocol-Agnostic Approach to Function Calling](https://arxiv.org/abs/2508.02979)
*Peng Ding,Rick Stevens*

Main category: cs.AI

TL;DR: Unified approach to tool integration that abstracts protocol differences while optimizing execution performance.


<details>
  <summary>Details</summary>
Motivation: The proliferation of tool-augmented Large Language Models (LLMs) has created a fragmented ecosystem where developers must navigate multiple protocols, manual schema definitions, and complex execution workflows.

Method: a unified approach to tool integration that abstracts protocol differences while optimizing execution performance

Result: Experimental results show 60-80% code reduction across integration scenarios, performance improvements up to 3.1x through optimized concurrency, and full compatibility with existing function calling standards.

Conclusion: This work contributes both theoretical insights into tool integration architecture and practical solutions for real-world LLM application development.

Abstract: The proliferation of tool-augmented Large Language Models (LLMs) has created
a fragmented ecosystem where developers must navigate multiple protocols,
manual schema definitions, and complex execution workflows. We address this
challenge by proposing a unified approach to tool integration that abstracts
protocol differences while optimizing execution performance. Our solution
demonstrates how protocol-agnostic design principles can significantly reduce
development overhead through automated schema generation, dual-mode concurrent
execution, and seamless multi-source tool management. Experimental results show
60-80% code reduction across integration scenarios, performance improvements up
to 3.1x through optimized concurrency, and full compatibility with existing
function calling standards. This work contributes both theoretical insights
into tool integration architecture and practical solutions for real-world LLM
application development.

</details>


### [97] [When AIs Judge AIs: The Rise of Agent-as-a-Judge Evaluation for LLMs](https://arxiv.org/abs/2508.02994)
*Fangyi Yu*

Main category: cs.AI

TL;DR: AI agents are used as evaluators to assess the quality and safety of other models, which can complement but not replace human oversight.


<details>
  <summary>Details</summary>
Motivation: evaluating their outputs-especially in open-ended and complex tasks-has become a critical bottleneck. A new paradigm is emerging: using AI agents as the evaluators themselves.

Method: define the agent-as-a-judge concept, trace its evolution from single-model judges to dynamic multi-agent debate frameworks, and critically examine their strengths and shortcomings. We compare these approaches across reliability, cost, and human alignment, and survey real-world deployments in domains such as medicine, law, finance, and education.

Result: assessing the quality and safety of other models, promising calable and nuanced alternatives to human evaluation.

Conclusion: agent-based judging can complement (but not replace) human oversight, marking a step toward trustworthy, scalable evaluation for next-generation LLMs.

Abstract: As large language models (LLMs) grow in capability and autonomy, evaluating
their outputs-especially in open-ended and complex tasks-has become a critical
bottleneck. A new paradigm is emerging: using AI agents as the evaluators
themselves. This "agent-as-a-judge" approach leverages the reasoning and
perspective-taking abilities of LLMs to assess the quality and safety of other
models, promising calable and nuanced alternatives to human evaluation. In this
review, we define the agent-as-a-judge concept, trace its evolution from
single-model judges to dynamic multi-agent debate frameworks, and critically
examine their strengths and shortcomings. We compare these approaches across
reliability, cost, and human alignment, and survey real-world deployments in
domains such as medicine, law, finance, and education. Finally, we highlight
pressing challenges-including bias, robustness, and meta evaluation-and outline
future research directions. By bringing together these strands, our review
demonstrates how agent-based judging can complement (but not replace) human
oversight, marking a step toward trustworthy, scalable evaluation for
next-generation LLMs.

</details>


### [98] [AGENTiGraph: A Multi-Agent Knowledge Graph Framework for Interactive, Domain-Specific LLM Chatbots](https://arxiv.org/abs/2508.02999)
*Xinjie Zhao,Moritz Blum,Fan Gao,Yingjian Chen,Boming Yang,Luis Marquez-Carpintero,Mónica Pina-Navarro,Yanran Fu,So Morikawa,Yusuke Iwasawa,Yutaka Matsuo,Chanjun Park,Irene Li*

Main category: cs.AI

TL;DR: AGENTiGraph是一个用户友好的、代理驱动的系统，它通过知识图操作来实现领域特定数据的直观交互和管理。


<details>
  <summary>Details</summary>
Motivation: AGENTiGraph使用户能够通过自然语言操作知识图来直观地交互和管理领域特定数据。

Method: AGENTiGraph采用意图分类、任务规划和自动知识集成

Result: AGENTiGraph为非技术用户提供了一个完整的可视化解决方案，以增量方式构建和完善他们的知识库，从而允许进行多轮对话和动态更新，而无需使用专门的查询语言。

Conclusion: AGENTiGraph在教育场景的3,500个查询基准上表现优于强大的zero-shot基线（达到95.12％的分类准确率，90.45％的执行成功率），表明在法律和医学领域具有潜在的可扩展性。

Abstract: AGENTiGraph is a user-friendly, agent-driven system that enables intuitive
interaction and management of domain-specific data through the manipulation of
knowledge graphs in natural language. It gives non-technical users a complete,
visual solution to incrementally build and refine their knowledge bases,
allowing multi-round dialogues and dynamic updates without specialized query
languages. The flexible design of AGENTiGraph, including intent classification,
task planning, and automatic knowledge integration, ensures seamless reasoning
between diverse tasks. Evaluated on a 3,500-query benchmark within an
educational scenario, the system outperforms strong zero-shot baselines
(achieving 95.12% classification accuracy, 90.45% execution success),
indicating potential scalability to compliance-critical or multi-step queries
in legal and medical domains, e.g., incorporating new statutes or research on
the fly. Our open-source demo offers a powerful new paradigm for multi-turn
enterprise knowledge management that bridges LLMs and structured graphs.

</details>


### [99] [Beyond Policy Optimization: A Data Curation Flywheel for Sparse-Reward Long-Horizon Planning](https://arxiv.org/abs/2508.03018)
*Yutong Wang,Pengliang Ji,Kaixin Li,Baolong Bi,Tao Feng,Guillaume Sartoretti*

Main category: cs.AI

TL;DR: 提出了一个三阶段框架，通过自我改进的数据飞轮来开发鲁棒的推理模型，用于长时程、稀疏奖励环境。


<details>
  <summary>Details</summary>
Motivation: 大型语言推理模型在静态任务上已经 демонстрирует 出色的成功，但它们在交互环境中对多轮Agent规划的应用面临着两个根本性的挑战。首先，难处理的信用分配问题使得传统的强化学习在稀疏奖励环境中无效。其次，冗长的、逐步的推理历史的计算开销过高。

Method: 提出了一个三阶段框架（引导、外推和细化），该框架建立了一个自我改进的数据飞轮，以开发用于长时程、稀疏奖励环境的鲁棒推理模型。该框架首先使用提出的带有长短期思维链融合的规划四元数来引导有效的推理。然后，通过复杂性分层课程学习外推到分布外任务。最后，该模型通过专门学习通过奖励门控拒绝抽样选择的经验来迭代地改进自身。

Result: 该方法在ALFWorld、ScienceWorld和WebShop上实现了最先进的性能，并具有显著的token效率。

Conclusion: 该方法在ALFWorld、ScienceWorld和WebShop上实现了最先进的性能，并具有显著的token效率，为Agent规划中的推理模型提供了一种新的方法。

Abstract: Large Language Reasoning Models have demonstrated remarkable success on
static tasks, yet their application to multi-round agentic planning in
interactive environments faces two fundamental challenges. First, the
intractable credit assignment problem renders conventional reinforcement
learning ineffective in sparse-reward settings. Second, the computational
overhead of verbose, step-by-step reasoning histories is prohibitive. To
address these challenges, we propose BPO, a three-stage framework
(bootstrapping, extrapolation, and refinement) that establishes a
self-improving data flywheel to develop robust reasoning models for
long-horizon, sparse-reward environments. Our framework first bootstraps
efficient reasoning using the proposed planning quaternions with long-short
chain-of-thought fusion. It then extrapolates to out-of-distribution tasks
through complexity-stratified curriculum learning. Finally, the model
iteratively refines itself by learning exclusively on experiences selected via
reward-gated rejection sampling. Experiments on ALFWorld, ScienceWorld, and
WebShop demonstrate that our approach achieves state-of-the-art with
significant token efficiency, providing a new recipe for reasoning models in
agentic planning.

</details>


### [100] [Collab-Solver: Collaborative Solving Policy Learning for Mixed-Integer Linear Programming](https://arxiv.org/abs/2508.03030)
*Siyuan Li,Yifan Yu,Yanchen Deng,Zhihao Zhang,Mengjing Chen,Fangzhou Zhu,Tao Zhong,Jianye Hao,Peng Liu,Bo An*

Main category: cs.AI

TL;DR: This paper introduces Collab-Solver, a multi-agent-based policy learning framework for MILP that collaboratively optimizes policies for multiple modules, improving solving performance and generalization abilities.


<details>
  <summary>Details</summary>
Motivation: Existing works independently treat the policy learning in each module of MILP solvers without considering their interdependence, severely hurting the solving speed and quality.

Method: We propose a novel multi-agent-based policy learning framework for MILP (Collab-Solver), which can collaboratively optimize the policies for multiple modules. Specifically, we formulate the collaboration of cut selection and branching in MILP solving as a Stackelberg game. Under this formulation, we develop a two-phase learning paradigm to stabilize the collaborative policy learning, where the first phase achieves the data-communicated policy pretraining and the second phase further orchestrates the policy learning for various modules.

Result: The jointly learned policy significantly improves the solving performance on both synthetic and large-scale real-world MILP datasets. Moreover, the policies learned by Collab-Solver have also demonstrated excellent generalization abilities across different instance sets.

Conclusion: The jointly learned policy significantly improves the solving performance on both synthetic and large-scale real-world MILP datasets. Moreover, the policies learned by Collab-Solver have also demonstrated excellent generalization abilities across different instance sets.

Abstract: Mixed-integer linear programming (MILP) has been a fundamental problem in
combinatorial optimization. Previous works have designed a plethora of
hard-coded heuristics to accomplish challenging MILP solving with domain
knowledge. Driven by the high capability of neural networks, recent research is
devoted to replacing manually designed heuristics with learned policies.
Although learning-based MILP methods have shown great promise, existing
worksindependentlytreatthepolicylearningineachmoduleofMILPsolvers without
considering their interdependence, severely hurting the solving speed and
quality. To address this issue, we propose a novel multi-agent-based policy
learning framework for MILP (Collab-Solver), which can collaboratively optimize
the policies for multiple modules. Specifically, we formulate the collaboration
of cut selection and branching in MILP solving as a Stackelberg game. Under
this formulation, we develop a two-phase learning paradigm to stabilize the
collaborative policy learning, where the first phase achieves the
data-communicated policy pretraining and the second phase further orchestrates
the policy learning for various modules. The jointly learned policy
significantly improves the solving performance on both synthetic and
large-scale real-world MILP datasets. Moreover, the policies learned by
Collab-Solver have also demonstrated excellent generalization abilities across
different instance sets.

</details>


### [101] [From Text to Trajectories: GPT-2 as an ODE Solver via In-Context](https://arxiv.org/abs/2508.03031)
*Ziyang Ma,Baojian Zhou,Deqing Yang,Yanghua Xiao*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型（LLM）在上下文学习（ICL）中解决常微分方程（ODE）的能力。实验表明，GPT-2可以有效地学习元ODE算法，并且具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了揭示ICL的潜在机制，本文研究了LLM是否可以在ICL设置下求解常微分方程（ODE）。

Method: 将标准ODE问题及其解决方案制定为顺序提示，并在这些任务上评估GPT-2模型。

Result: GPT-2可以有效地学习元ODE算法，其收敛行为与欧拉方法相当或更好，并且随着演示数量的增加，实现了指数级的精度提升。此外，该模型可以推广到分布外（OOD）问题，表现出强大的外推能力。

Conclusion: GPT-2可以通过上下文学习有效地学习元ODE算法，其收敛行为与欧拉方法相当或更好，并且随着演示数量的增加，实现了指数级的精度提升。此外，该模型可以推广到分布外问题，表现出强大的外推能力。

Abstract: In-Context Learning (ICL) has emerged as a new paradigm in large language
models (LLMs), enabling them to perform novel tasks by conditioning on a few
examples embedded in the prompt. Yet, the highly nonlinear behavior of ICL for
NLP tasks remains poorly understood. To shed light on its underlying
mechanisms, this paper investigates whether LLMs can solve ordinary
differential equations (ODEs) under the ICL setting. We formulate standard ODE
problems and their solutions as sequential prompts and evaluate GPT-2 models on
these tasks. Experiments on two types of ODEs show that GPT-2 can effectively
learn a meta-ODE algorithm, with convergence behavior comparable to, or better
than, the Euler method, and achieve exponential accuracy gains with increasing
numbers of demonstrations. Moreover, the model generalizes to
out-of-distribution (OOD) problems, demonstrating robust extrapolation
capabilities. These empirical findings provide new insights into the mechanisms
of ICL in NLP and its potential for solving nonlinear numerical problems.

</details>


### [102] [Tree-of-Reasoning: Towards Complex Medical Diagnosis via Multi-Agent Reasoning with Evidence Tree](https://arxiv.org/abs/2508.03038)
*Qi Peng,Jialin Cui,Jiayuan Xie,Yi Cai,Qing Li*

Main category: cs.AI

TL;DR: The paper introduces Tree-of-Reasoning (ToR), a multi-agent framework that improves the clinical reasoning ability of LLMs in complex medical scenarios by using a tree structure to record reasoning paths and a cross-validation mechanism for consistency.


<details>
  <summary>Details</summary>
Motivation: Existing large language models (LLMs) lack sufficient reasoning depth when faced with complex medical diagnosis tasks, leading to information loss or logical jumps and diagnostic errors.

Method: A novel multi-agent framework called Tree-of-Reasoning (ToR) is proposed, which introduces a tree structure to record the reasoning path and uses a cross-validation mechanism to ensure the consistency of multi-agent decision-making.

Result: The proposed framework achieves better performance than existing baseline methods on real-world medical data.

Conclusion: The Tree-of-Reasoning (ToR) framework achieves better performance than existing baseline methods on real-world medical data.

Abstract: Large language models (LLMs) have shown great potential in the medical
domain. However, existing models still fall short when faced with complex
medical diagnosis task in the real world. This is mainly because they lack
sufficient reasoning depth, which leads to information loss or logical jumps
when processing a large amount of specialized medical data, leading to
diagnostic errors. To address these challenges, we propose Tree-of-Reasoning
(ToR), a novel multi-agent framework designed to handle complex scenarios.
Specifically, ToR introduces a tree structure that can clearly record the
reasoning path of LLMs and the corresponding clinical evidence. At the same
time, we propose a cross-validation mechanism to ensure the consistency of
multi-agent decision-making, thereby improving the clinical reasoning ability
of multi-agents in complex medical scenarios. Experimental results on
real-world medical data show that our framework can achieve better performance
than existing baseline methods.

</details>


### [103] [Beyond Surface-Level Detection: Towards Cognitive-Driven Defense Against Jailbreak Attacks via Meta-Operations Reasoning](https://arxiv.org/abs/2508.03054)
*Rui Pu,Chaozhuo Li,Rui Ha,Litian Zhang,Lirong Qiu,Xi Zhang*

Main category: cs.AI

TL;DR: CDD 是一种新的防御框架，通过模仿人类认知推理来防御 LLM 的越狱攻击，并且在未知的攻击中表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 保护大型语言模型 (LLM) 免受越狱攻击对于其安全可靠的部署至关重要。现有的防御通常依赖于浅层模式匹配，这种匹配难以推广到新颖和未知的攻击策略。

Method: 认知驱动防御 (CDD) 框架，通过应用元操作来针对越狱提示的底层结构，元操作被定义为隐藏有害意图的基本操作。CDD 通过结构化的推理链来模拟人类的认知推理。它首先对提示进行全局感知，然后进行局部分析，以发现隐藏的操作。通过对这个结构化的链进行监督微调，该模型学会识别和推理已知的操作模式。为了加强对未知威胁的泛化，引入了一种熵引导的强化学习算法 (EG-GRPO)，以鼓励探索新型和变型的元操作。

Result: CDD 可以实现最先进的防御性能，并对未知的越狱攻击表现出强大的泛化能力。

Conclusion: CDD 可以实现最先进的防御性能，并对未知的越狱攻击表现出强大的泛化能力。

Abstract: Defending large language models (LLMs) against jailbreak attacks is essential
for their safe and reliable deployment. Existing defenses often rely on shallow
pattern matching, which struggles to generalize to novel and unseen attack
strategies. To address this challenge, we propose the Cognitive-Driven Defense
(CDD) framework, which targets the underlying structure of jailbreak prompts by
applying meta-operations, defined as basic manipulations that conceal harmful
intent.CDD emulates human cognitive reasoning through a structured reasoning
chain. It begins with a global perception of the prompt and follows with a
localized analysis to uncover hidden manipulations. By applying supervised
fine-tuning on this structured chain, the model learns to identify and reason
about known manipulation patterns. To enhance generalization to unseen threats,
an entropy-guided reinforcement learning algorithm (EG-GRPO) is introduced to
encourage exploration of new types and variants of meta-operations. Experiments
demonstrate that CDD can achieve state-of-the-art defense performance and
exhibit strong generalization to unseen jailbreak attacks.

</details>


### [104] [ContractEval: Benchmarking LLMs for Clause-Level Legal Risk Identification in Commercial Contracts](https://arxiv.org/abs/2508.03080)
*Shuang Liu,Zelong Li,Ruoyun Ma,Haiyan Zhao,Mengnan Du*

Main category: cs.AI

TL;DR: ContractEval benchmark shows open-source LLMs lag proprietary models in legal risk analysis, needing fine-tuning for high-stakes legal tasks.


<details>
  <summary>Details</summary>
Motivation: The potential of large language models (LLMs) in specialized domains such as legal risk analysis remains underexplored. Growing interest in locally deploying open-source LLMs for legal tasks while preserving data confidentiality.

Method: Introduce ContractEval, the first benchmark to thoroughly evaluate whether open-source LLMs could match proprietary LLMs in identifying clause-level legal risks in commercial contracts. Assess 4 proprietary and 15 open-source LLMs using the Contract Understanding Atticus Dataset (CUAD).

Result: Proprietary models outperform open-source models. Larger open-source models generally perform better, though the improvement slows down as models get bigger. Reasoning mode improves output effectiveness but reduces correctness. Open-source models generate 'no related clause' responses more frequently. Model quantization speeds up inference but at the cost of performance drop.

Conclusion: Open-source LLMs require targeted fine-tuning to ensure correctness and effectiveness in high-stakes legal settings. ContractEval offers a solid benchmark to guide future development of legal-domain LLMs.

Abstract: The potential of large language models (LLMs) in specialized domains such as
legal risk analysis remains underexplored. In response to growing interest in
locally deploying open-source LLMs for legal tasks while preserving data
confidentiality, this paper introduces ContractEval, the first benchmark to
thoroughly evaluate whether open-source LLMs could match proprietary LLMs in
identifying clause-level legal risks in commercial contracts. Using the
Contract Understanding Atticus Dataset (CUAD), we assess 4 proprietary and 15
open-source LLMs. Our results highlight five key findings: (1) Proprietary
models outperform open-source models in both correctness and output
effectiveness, though some open-source models are competitive in certain
specific dimensions. (2) Larger open-source models generally perform better,
though the improvement slows down as models get bigger. (3) Reasoning
("thinking") mode improves output effectiveness but reduces correctness, likely
due to over-complicating simpler tasks. (4) Open-source models generate "no
related clause" responses more frequently even when relevant clauses are
present. This suggests "laziness" in thinking or low confidence in extracting
relevant content. (5) Model quantization speeds up inference but at the cost of
performance drop, showing the tradeoff between efficiency and accuracy. These
findings suggest that while most LLMs perform at a level comparable to junior
legal assistants, open-source models require targeted fine-tuning to ensure
correctness and effectiveness in high-stakes legal settings. ContractEval
offers a solid benchmark to guide future development of legal-domain LLMs.

</details>


### [105] [EoH-S: Evolution of Heuristic Set using LLMs for Automated Heuristic Design](https://arxiv.org/abs/2508.03082)
*Fei Liu,Yilu Liu,Qingfu Zhang,Xialiang Tong,Mingxuan Yuan*

Main category: cs.AI

TL;DR: 提出了自动启发式集合设计（AHSD），一种用于LLM驱动的AHD的新公式，旨在自动生成一个小型互补启发式集合来服务各种问题实例。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅设计一种启发式方法来服务于所有问题实例，通常导致跨不同分布或设置的泛化能力较差。为了解决这个问题，我们提出了自动启发式集合设计（AHSD），这是一种用于LLM驱动的AHD的新公式。AHSD的目的是自动生成一个小型互补启发式集合，以服务于各种问题实例，以便每个问题实例都可以通过此集合中的至少一个启发式方法进行优化。

Method: 提出了一种启发式集合演化（EoH-S）方法，该方法应用AHSD公式进行LLM驱动的AHD。通过互补种群管理和互补感知模因搜索两种新机制，EoH-S可以有效地生成一组高质量和互补的启发式方法。

Result: 表明AHSD的目标函数是单调的和超模的。

Conclusion: EoH-S在各种规模和分布的三个AHD任务上始终优于现有的最先进的AHD方法，并实现了高达60％的性能提升。

Abstract: Automated Heuristic Design (AHD) using Large Language Models (LLMs) has
achieved notable success in recent years. Despite the effectiveness of existing
approaches, they only design a single heuristic to serve all problem instances,
often inducing poor generalization across different distributions or settings.
To address this issue, we propose Automated Heuristic Set Design (AHSD), a new
formulation for LLM-driven AHD. The aim of AHSD is to automatically generate a
small-sized complementary heuristic set to serve diverse problem instances,
such that each problem instance could be optimized by at least one heuristic in
this set. We show that the objective function of AHSD is monotone and
supermodular. Then, we propose Evolution of Heuristic Set (EoH-S) to apply the
AHSD formulation for LLM-driven AHD. With two novel mechanisms of complementary
population management and complementary-aware memetic search, EoH-S could
effectively generate a set of high-quality and complementary heuristics.
Comprehensive experimental results on three AHD tasks with diverse instances
spanning various sizes and distributions demonstrate that EoH-S consistently
outperforms existing state-of-the-art AHD methods and achieves up to 60\%
performance improvements.

</details>


### [106] [MissDDIM: Deterministic and Efficient Conditional Diffusion for Tabular Data Imputation](https://arxiv.org/abs/2508.03083)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.AI

TL;DR: MissDDIM 使用条件扩散框架和 DDIM 来进行表格插补，以解决现有方法的高延迟和可变输出问题。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常基于随机去噪扩散概率模型 (DDPM)，存在高推理延迟和可变输出的问题，限制了它们在真实表格环境中的适用性。

Method: 调整了用于表格插补的去噪扩散隐式模型 (DDIM)

Result: 条件扩散框架

Conclusion: MissDDIM，一个条件扩散框架，它调整了用于表格插补的去噪扩散隐式模型 (DDIM)。

Abstract: Diffusion models have recently emerged as powerful tools for missing data
imputation by modeling the joint distribution of observed and unobserved
variables. However, existing methods, typically based on stochastic denoising
diffusion probabilistic models (DDPMs), suffer from high inference latency and
variable outputs, limiting their applicability in real-world tabular settings.
To address these deficiencies, we present in this paper MissDDIM, a conditional
diffusion framework that adapts Denoising Diffusion Implicit Models (DDIM) for
tabular imputation. While stochastic sampling enables diverse completions, it
also introduces output variability that complicates downstream processing.

</details>


### [107] [T2UE: Generating Unlearnable Examples from Text Descriptions](https://arxiv.org/abs/2508.03091)
*Xingjun Ma,Hanxun Huang,Tianwei Song,Ye Sun,Yifeng Gao,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: The paper introduces T2UE, a framework for generating unlearnable examples from text descriptions to protect data privacy without direct data exposure, addressing the privacy paradox in existing methods.


<details>
  <summary>Details</summary>
Motivation: Large-scale pre-training frameworks like CLIP rely on web-scraped datasets, frequently containing private user data, which raises concerns about misuse. Current Unlearnable Examples (UEs) generation is computationally prohibitive for on-device execution, forcing reliance on external third-party services, creating a privacy paradox.

Method: The paper introduces Text-to-Unlearnable Example (T2UE), a novel framework that enables users to generate UEs using only text descriptions. It employs a text-to-image (T2I) model to map text descriptions into the image (noise) space, combined with an error-minimization framework to produce effective unlearnable noise.

Result: T2UE-protected data substantially degrades performance in downstream tasks for state-of-the-art models, and the protective effect generalizes across diverse architectures and even to supervised learning settings.

Conclusion: The paper demonstrates the feasibility of zero-contact data protection, where personal data can be safeguarded based solely on their textual descriptions, eliminating the need for direct data exposure.

Abstract: Large-scale pre-training frameworks like CLIP have revolutionized multimodal
learning, but their reliance on web-scraped datasets, frequently containing
private user data, raises serious concerns about misuse. Unlearnable Examples
(UEs) have emerged as a promising countermeasure against unauthorized model
training, employing carefully crafted unlearnable noise to disrupt the learning
of meaningful representations from protected data. Current approaches typically
generate UEs by jointly optimizing unlearnable noise for both images and their
associated text descriptions (or labels). However, this optimization process is
often computationally prohibitive for on-device execution, forcing reliance on
external third-party services. This creates a fundamental privacy paradox:
users must initially expose their data to these very services to achieve
protection, thereby compromising privacy in the process. Such a contradiction
has severely hindered the development of practical, scalable data protection
solutions. To resolve this paradox, we introduce \textbf{Text-to-Unlearnable
Example (T2UE)}, a novel framework that enables users to generate UEs using
only text descriptions. T2UE circumvents the need for original image data by
employing a text-to-image (T2I) model to map text descriptions into the image
(noise) space, combined with an error-minimization framework to produce
effective unlearnable noise. Extensive experiments show that T2UE-protected
data substantially degrades performance in downstream tasks (e.g., cross-modal
retrieval) for state-of-the-art models. Notably, the protective effect
generalizes across diverse architectures and even to supervised learning
settings. Our work demonstrates the feasibility of "zero-contact data
protection", where personal data can be safeguarded based solely on their
textual descriptions, eliminating the need for direct data exposure.

</details>


### [108] [Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework](https://arxiv.org/abs/2508.03092)
*Zikun Cui,Tianyi Huang,Chia-En Chiang,Cuiqianhe Du*

Main category: cs.AI

TL;DR: 该研究提出了一种可验证的虚假信息检测LLM Agent，它通过与Web来源交互、评估信息来源可信度并综合证据来检测虚假信息，实验结果表明该Agent优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的普及，虚假信息的检测变得越来越重要和复杂。

Method: 该研究提出了一种创新的可验证的虚假信息检测LLM Agent，该Agent通过与各种Web来源的动态交互来主动验证声明，评估信息来源的可信度，综合证据，并提供完整的可验证的推理过程。该Agent架构包括三个核心工具：精确的Web搜索工具、来源可信度评估工具和数值声明验证工具。

Result: 实验结果表明，该Agent在虚假信息检测准确率、推理透明度和抗信息改写方面优于基线方法。

Conclusion: 该研究提出的LLM Agent在虚假信息检测准确率、推理透明度和抗信息改写方面优于基线方法，为可信的AI辅助事实核查提供了一个新的范例。

Abstract: With the proliferation of Large Language Models (LLMs), the detection of
misinformation has become increasingly important and complex. This research
proposes an innovative verifiable misinformation detection LLM agent that goes
beyond traditional true/false binary judgments. The agent actively verifies
claims through dynamic interaction with diverse web sources, assesses
information source credibility, synthesizes evidence, and provides a complete
verifiable reasoning process. Our designed agent architecture includes three
core tools: precise web search tool, source credibility assessment tool and
numerical claim verification tool. These tools enable the agent to execute
multi-step verification strategies, maintain evidence logs, and form
comprehensive assessment conclusions. We evaluate using standard misinformation
datasets such as FakeNewsNet, comparing with traditional machine learning
models and LLMs. Evaluation metrics include standard classification metrics,
quality assessment of reasoning processes, and robustness testing against
rewritten content. Experimental results show that our agent outperforms
baseline methods in misinformation detection accuracy, reasoning transparency,
and resistance to information rewriting, providing a new paradigm for
trustworthy AI-assisted fact-checking.

</details>


### [109] [AgentSME for Simulating Diverse Communication Modes in Smart Education](https://arxiv.org/abs/2508.03109)
*Wen-Xi Yang,Tian-Fang Zhao*

Main category: cs.AI

TL;DR: This paper proposes AgentSME, a unified generative agent framework powered by LLM, explores three communication modes (Solo, Mono, Echo), and finds Echo mode achieves the highest accuracy.


<details>
  <summary>Details</summary>
Motivation: Generative agent models specifically tailored for smart education are critical, yet remain relatively underdeveloped. A key challenge stems from the inherent complexity of educational contexts: learners are human beings with various cognitive behaviors, and pedagogy is fundamentally centered on personalized human-to-human communication.

Method: a unified generative agent framework powered by LLM. Three directional communication modes are considered in the models, namely Solo, Mono, and Echo

Result: Six widely used LLMs are tested to validate the robustness of communication modes across different model tiers, which are equally divided into base-capacity and high-capacity configurations.

Conclusion: generative agents that employ the Echo communication mode achieve the highest accuracy scores, while DeepSeek exhibits the greatest diversity. This study provides valuable information to improve agent learning capabilities and inspire smart education models.

Abstract: Generative agent models specifically tailored for smart education are
critical, yet remain relatively underdeveloped. A key challenge stems from the
inherent complexity of educational contexts: learners are human beings with
various cognitive behaviors, and pedagogy is fundamentally centered on
personalized human-to-human communication. To address this issue, this paper
proposes AgentSME, a unified generative agent framework powered by LLM. Three
directional communication modes are considered in the models, namely Solo,
Mono, and Echo, reflecting different types of agency autonomy and communicative
reciprocity. Accuracy is adopted as the primary evaluation metric, complemented
by three diversity indices designed to assess the diversity of reasoning
contents. Six widely used LLMs are tested to validate the robustness of
communication modes across different model tiers, which are equally divided
into base-capacity and high-capacity configurations. The results show that
generative agents that employ the Echo communication mode achieve the highest
accuracy scores, while DeepSeek exhibits the greatest diversity. This study
provides valuable information to improve agent learning capabilities and
inspire smart education models.

</details>


### [110] [Toward a Trustworthy Optimization Modeling Agent via Verifiable Synthetic Data Generation](https://arxiv.org/abs/2508.03117)
*Vinicius Lima,Dzung T. Phan,Jayant Kalagnanam,Dhaval Patel,Nianjun Zhou*

Main category: cs.AI

TL;DR: This paper introduces a framework (OptiTrust) for creating reliable LLM agents for optimization by generating verifiable synthetic data. OptiTrust achieves state-of-the-art results on standard benchmarks.


<details>
  <summary>Details</summary>
Motivation: The paper aims to develop trustworthy large language model (LLM) agents for optimization modeling.

Method: The paper introduces a framework for training trustworthy LLM agents for optimization modeling via a verifiable synthetic data generation pipeline. It uses structured symbolic representations to produce natural language descriptions, mathematical formulations, and solver-executable code. The OptiTrust agent, a modular LLM agent, performs multi-stage translation from natural language to solver-ready code, leveraging stepwise demonstrations, multi-language inference, and majority-vote cross-validation.

Result: The OptiTrust agent achieves state-of-the-art performance on standard benchmarks, achieving the highest accuracy on six out of seven datasets and outperforming the next-best algorithm by at least 8 percentage on three of them.

Conclusion: The paper presents a scalable, verifiable, and principled path toward building reliable LLM agents for real-world optimization applications, with the OptiTrust agent achieving state-of-the-art performance on standard benchmarks.

Abstract: We present a framework for training trustworthy large language model (LLM)
agents for optimization modeling via a verifiable synthetic data generation
pipeline. Focusing on linear and mixed-integer linear programming, our approach
begins with structured symbolic representations and systematically produces
natural language descriptions, mathematical formulations, and solver-executable
code. By programmatically constructing each instance with known optimal
solutions, the pipeline ensures full verifiability and enables automatic
filtering of low-quality demonstrations generated by teacher models. Each
dataset instance includes a structured representation of the optimization
problem, a corresponding natural language description, the verified optimal
solution, and step-by-step demonstrations - generated by a teacher model - that
show how to model and solve the problem across multiple optimization modeling
languages. This enables supervised fine-tuning of open-source LLMs specifically
tailored to optimization tasks. To operationalize this pipeline, we introduce
OptiTrust, a modular LLM agent that performs multi-stage translation from
natural language to solver-ready code, leveraging stepwise demonstrations,
multi-language inference, and majority-vote cross-validation. Our agent
achieves state-of-the-art performance on standard benchmarks. Out of 7
datasets, it achieves the highest accuracy on six and outperforms the next-best
algorithm by at least 8 percentage on three of them. Our approach provides a
scalable, verifiable, and principled path toward building reliable LLM agents
for real-world optimization applications.

</details>


### [111] [Can Large Language Models Bridge the Gap in Environmental Knowledge?](https://arxiv.org/abs/2508.03149)
*Linda Smail,David Santandreu Calonge,Firuz Kamalov,Nur H. Orak*

Main category: cs.AI

TL;DR: 本研究评估了 AI 模型在环境教育中的有效性，发现它们具有潜力，但仍需要人工专家验证准确性。


<details>
  <summary>Details</summary>
Motivation: 本研究调查了人工智能 (AI) 模型在弥合大学生环境教育知识差距方面的潜力。

Method: 利用环境知识测试 (EKT-19) 结合有针对性的问题，评估大学生的环境知识，并将其与 AI 模型生成的回答进行比较。

Result: AI 模型拥有庞大、易于访问且有效的知识库，有潜力增强学生和学术人员的能力。

Conclusion: AI模型拥有庞大、易于访问且有效的知识库，有潜力增强学生和学术人员的能力，但可能仍需要环境科学领域的人工学科专家来验证所提供信息的准确性。

Abstract: This research investigates the potential of Artificial Intelligence (AI)
models to bridge the knowledge gap in environmental education among university
students. By focusing on prominent large language models (LLMs) such as
GPT-3.5, GPT-4, GPT-4o, Gemini, Claude Sonnet, and Llama 2, the study assesses
their effectiveness in conveying environmental concepts and, consequently,
facilitating environmental education. The investigation employs a standardized
tool, the Environmental Knowledge Test (EKT-19), supplemented by targeted
questions, to evaluate the environmental knowledge of university students in
comparison to the responses generated by the AI models. The results of this
study suggest that while AI models possess a vast, readily accessible, and
valid knowledge base with the potential to empower both students and academic
staff, a human discipline specialist in environmental sciences may still be
necessary to validate the accuracy of the information provided.

</details>


### [112] [Causal identification with $Y_0$](https://arxiv.org/abs/2508.03167)
*Charles Tapley Hoyt,Craig Bakker,Richard J. Callahan,Joseph Cottam,August George,Benjamin M. Gyori,Haley M. Hummel,Nathaniel Merrill,Sara Mohammad Taheri,Pruthvi Prakash Navada,Marc-Antoine Parent,Adam Rupe,Olga Vitek,Jeremy Zucker*

Main category: cs.AI

TL;DR: Y0 is a Python package for causal identification, helping researchers determine if causal relationships can be estimated from data and providing tools for doing so.


<details>
  <summary>Details</summary>
Motivation: To help researchers determine whether a causal relationship can be estimated from available data and to transform the causal query into a symbolic estimand that can be non-parametrically estimated from the available data.

Method: The package implements causal identification algorithms that apply interventional, counterfactual, and transportability queries to data from various sources. It uses a domain-specific language and ADMGs.

Result: The Y0 package, available under the MIT License and installable via pip, offers a domain-specific language, tools for representing causal graphical models, and implementations of identification algorithms.

Conclusion: The Y0 Python package provides tools for causal identification, allowing researchers to determine if a causal relationship can be estimated from data before quantifying its strength. It transforms causal queries into symbolic estimands.

Abstract: We present the $Y_0$ Python package, which implements causal identification
algorithms that apply interventional, counterfactual, and transportability
queries to data from (randomized) controlled trials, observational studies, or
mixtures thereof. $Y_0$ focuses on the qualitative investigation of causation,
helping researchers determine whether a causal relationship can be estimated
from available data before attempting to estimate how strong that relationship
is. Furthermore, $Y_0$ provides guidance on how to transform the causal query
into a symbolic estimand that can be non-parametrically estimated from the
available data. $Y_0$ provides a domain-specific language for representing
causal queries and estimands as symbolic probabilistic expressions, tools for
representing causal graphical models with unobserved confounders, such as
acyclic directed mixed graphs (ADMGs), and implementations of numerous
identification algorithms from the recent causal inference literature. The
$Y_0$ source code can be found under the MIT License at
https://github.com/y0-causal-inference/y0 and it can be installed with pip
install y0.

</details>


### [113] [Geoint-R1: Formalizing Multimodal Geometric Reasoning with Dynamic Auxiliary Constructions](https://arxiv.org/abs/2508.03173)
*Jingxuan Wei,Caijun Jia,Qi Chen,Honghao He,Linzhuang Sun,Conghui He,Lijun Wu,Bihui Yu,Cheng Tan*

Main category: cs.AI

TL;DR: Geoint-R1: A multimodal reasoning framework designed to generate formally verifiable geometric solutions. It introduces the Geoint benchmark, and surpasses existing models.


<details>
  <summary>Details</summary>
Motivation: existing models typically struggle with formal geometric reasoning, particularly when dynamically constructing and verifying auxiliary geometric elements

Method: a multimodal reasoning framework designed to generate formally verifiable geometric solutions from textual descriptions and visual diagrams. Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning represented via Lean4, and interactive visualization.

Result: introduce Geoint-R1, a multimodal reasoning framework and propose the Geoint benchmark, comprising 1,885 rigorously annotated geometry problems

Conclusion: Geoint-R1 significantly surpasses existing multimodal and math-specific reasoning models, particularly on challenging problems requiring explicit auxiliary element constructions.

Abstract: Mathematical geometric reasoning is essential for scientific discovery and
educational development, requiring precise logic and rigorous formal
verification. While recent advances in Multimodal Large Language Models (MLLMs)
have improved reasoning tasks, existing models typically struggle with formal
geometric reasoning, particularly when dynamically constructing and verifying
auxiliary geometric elements. To address these challenges, we introduce
Geoint-R1, a multimodal reasoning framework designed to generate formally
verifiable geometric solutions from textual descriptions and visual diagrams.
Geoint-R1 uniquely integrates auxiliary elements construction, formal reasoning
represented via Lean4, and interactive visualization. To systematically
evaluate and advance formal geometric reasoning, we propose the Geoint
benchmark, comprising 1,885 rigorously annotated geometry problems across
diverse topics such as plane, spatial, and solid geometry. Each problem
includes structured textual annotations, precise Lean4 code for auxiliary
constructions, and detailed solution steps verified by experts. Extensive
experiments demonstrate that Geoint-R1 significantly surpasses existing
multimodal and math-specific reasoning models, particularly on challenging
problems requiring explicit auxiliary element constructions.

</details>


### [114] [InqEduAgent: Adaptive AI Learning Partners with Gaussian Process Augmentation](https://arxiv.org/abs/2508.03174)
*Tian-Fang Zhao,Wen-Xi Yang*

Main category: cs.AI

TL;DR: Proposes InqEduAgent, an LLM-empowered agent model, for simulating and selecting learning partners in inquiry-oriented learning. It uses generative agents and an adaptive matching algorithm to identify optimal learning-partner matches. Experiments show its optimal performance in knowledge-learning scenarios.


<details>
  <summary>Details</summary>
Motivation: Collaborative partnership matters in inquiry-oriented education. However, most study partners are selected either rely on experience-based assignments with little scientific planning or build on rule-based machine assistants, encountering difficulties in knowledge expansion and inadequate flexibility.

Method: This paper proposes an LLM-empowered agent model for simulating and selecting learning partners tailored to inquiry-oriented learning, named InqEduAgent. Generative agents are designed to capture cognitive and evaluative features of learners in real-world scenarios. Then, an adaptive matching algorithm with Gaussian process augmentation is formulated to identify patterns within prior knowledge.

Result: The experimental results show the optimal performance of InqEduAgent in most knowledge-learning scenarios and LLM environment with different levels of capabilities.

Conclusion: This study promotes the intelligent allocation of human-based learning partners and the formulation of AI-based learning partners.

Abstract: Collaborative partnership matters in inquiry-oriented education. However,
most study partners are selected either rely on experience-based assignments
with little scientific planning or build on rule-based machine assistants,
encountering difficulties in knowledge expansion and inadequate flexibility.
This paper proposes an LLM-empowered agent model for simulating and selecting
learning partners tailored to inquiry-oriented learning, named InqEduAgent.
Generative agents are designed to capture cognitive and evaluative features of
learners in real-world scenarios. Then, an adaptive matching algorithm with
Gaussian process augmentation is formulated to identify patterns within prior
knowledge. Optimal learning-partner matches are provided for learners facing
different exercises. The experimental results show the optimal performance of
InqEduAgent in most knowledge-learning scenarios and LLM environment with
different levels of capabilities. This study promotes the intelligent
allocation of human-based learning partners and the formulation of AI-based
learning partners. The code, data, and appendix are publicly available at
https://github.com/InqEduAgent/InqEduAgent.

</details>


### [115] [Full-History Graphs with Edge-Type Decoupled Networks for Temporal Reasoning](https://arxiv.org/abs/2508.03251)
*Osama Mohammed,Jiaxin Pan,Mojtaba Nayyeri,Daniel Hernández,Steffen Staab*

Main category: cs.AI

TL;DR: ETDNet通过在时间图中明确区分结构和时间关系，在驾驶员意图预测和欺诈检测方面取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 在许多实际任务中，对实体之间不断发展的交互进行建模至关重要。例如，预测交通中的驾驶员操作需要跟踪相邻车辆如何相对于彼此连续加速、制动和变换车道。同样，检测金融欺诈取决于跟踪资金通过连续交易在网络中传播的流程。与经典的时间序列预测不同，这些设置需要推理谁在何时与谁交互，这需要一个时间图表示，明确关系及其演变。

Method: 我们引入了一个完整的历史图，该图在每个时间步长为每个实体实例化一个节点，并分离两个边集：（i）捕获单个帧内关系的帧内时间步长边，以及（ii）将实体连接到连续步骤的帧间时间步长边。为了学习这个图，我们设计了一个具有并行模块的边类型解耦网络（ETDNet）：一个图注意力模块聚合沿帧内时间步长边的信息，一个多头时间注意力模块关注实体间的帧间时间步长历史，一个融合模块在每层之后组合这两个消息。

Result: 在驾驶员意图预测（Waymo）和比特币欺诈检测（Elliptic++）上评估，ETDNet始终超越强大的基线，将Waymo联合精度提高到75.6%（对比74.1%），并将Elliptic++非法类F1提高到88.1%（对比60.4%）。

Conclusion: ETDNet在驾驶员意图预测和比特币欺诈检测方面超越了强大的基线，证明了将结构和时间关系表示为单个图中不同边的优势。

Abstract: Modeling evolving interactions among entities is critical in many real-world
tasks. For example, predicting driver maneuvers in traffic requires tracking
how neighboring vehicles accelerate, brake, and change lanes relative to one
another over consecutive frames. Likewise, detecting financial fraud hinges on
following the flow of funds through successive transactions as they propagate
through the network. Unlike classic time-series forecasting, these settings
demand reasoning over who interacts with whom and when, calling for a
temporal-graph representation that makes both the relations and their evolution
explicit. Existing temporal-graph methods typically use snapshot graphs to
encode temporal evolution. We introduce a full-history graph that instantiates
one node for every entity at every time step and separates two edge sets: (i)
intra-time-step edges that capture relations within a single frame and (ii)
inter-time-step edges that connect an entity to itself at consecutive steps. To
learn on this graph we design an Edge-Type Decoupled Network (ETDNet) with
parallel modules: a graph-attention module aggregates information along
intra-time-step edges, a multi-head temporal-attention module attends over an
entity's inter-time-step history, and a fusion module combines the two messages
after every layer. Evaluated on driver-intention prediction (Waymo) and Bitcoin
fraud detection (Elliptic++), ETDNet consistently surpasses strong baselines,
lifting Waymo joint accuracy to 75.6\% (vs. 74.1\%) and raising Elliptic++
illicit-class F1 to 88.1\% (vs. 60.4\%). These gains demonstrate the benefit of
representing structural and temporal relations as distinct edges in a single
graph.

</details>


### [116] [ToolVQA: A Dataset for Multi-step Reasoning VQA with External Tools](https://arxiv.org/abs/2508.03284)
*Shaofeng Yin,Ting Lei,Yang Liu*

Main category: cs.AI

TL;DR: ToolVQA 是一个大型多模态数据集，包含 23K 个实例，旨在弥合实际工具使用能力方面的差距。


<details>
  <summary>Details</summary>
Motivation: 将外部工具集成到大型基础模型 (LFM) 中已成为一种很有前途的方法，可以增强其解决问题的能力。虽然现有的研究已经证明了在工具增强型视觉问答 (VQA) 方面的强大性能，但最近的基准测试揭示了在实际工具使用能力方面的重大差距，特别是在需要多步骤推理的功能多样的多模式设置中。

Method: 我们提出 ToolEngine，这是一种新颖的数据生成管道，它采用深度优先搜索 (DFS) 和动态上下文示例匹配机制来模拟类人工具使用推理。

Result: 在 ToolVQA 上微调的 7B LFM 不仅在我们的测试集上取得了令人印象深刻的性能，而且在各种分布外 (OOD) 数据集上超过了大型封闭源模型 GPT-3.5-turbo，展示了对真实世界工具使用场景的强大泛化能力。

Conclusion: 微调后的7B LFM 在 ToolVQA 测试集上取得了令人印象深刻的性能，并且在各种分布外 (OOD) 数据集上超过了大型封闭源模型 GPT-3.5-turbo，展示了对真实世界工具使用场景的强大泛化能力。

Abstract: Integrating external tools into Large Foundation Models (LFMs) has emerged as
a promising approach to enhance their problem-solving capabilities. While
existing studies have demonstrated strong performance in tool-augmented Visual
Question Answering (VQA), recent benchmarks reveal significant gaps in
real-world tool-use proficiency, particularly in functionally diverse
multimodal settings requiring multi-step reasoning. In this work, we introduce
ToolVQA, a large-scale multimodal dataset comprising 23K instances, designed to
bridge this gap. Unlike previous datasets that rely on synthetic scenarios and
simplified queries, ToolVQA features real-world visual contexts and challenging
implicit multi-step reasoning tasks, better aligning with real user
interactions. To construct this dataset, we propose ToolEngine, a novel data
generation pipeline that employs Depth-First Search (DFS) with a dynamic
in-context example matching mechanism to simulate human-like tool-use
reasoning. ToolVQA encompasses 10 multimodal tools across 7 diverse task
domains, with an average inference length of 2.78 reasoning steps per instance.
The fine-tuned 7B LFMs on ToolVQA not only achieve impressive performance on
our test set but also surpass the large close-sourced model GPT-3.5-turbo on
various out-of-distribution (OOD) datasets, demonstrating strong
generalizability to real-world tool-use scenarios.

</details>


### [117] [Nemori: Self-Organizing Agent Memory Inspired by Cognitive Science](https://arxiv.org/abs/2508.03341)
*Jiayan Nan,Wenquan Ma,Wenlong Wu,Yize Chen*

Main category: cs.AI

TL;DR: Nemori是一种新型记忆架构，灵感来自人类认知原则，通过自组织和主动学习，显著优于现有系统，尤其是在处理长上下文时。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）展示了卓越的能力，但它们在长上下文中无法维持持久记忆，这限制了它们在长期交互中作为自主代理的效能。现有的记忆系统依赖于任意粒度来定义基本记忆单元，并且采用被动的、基于规则的知识提取机制，这限制了它们进行真正学习和进化的能力。

Method: Nemori，一种受人类认知原则启发的新型自组织记忆架构，具有双重创新：两步对齐原则和预测-校准原则。

Result: Nemori显著优于先前的最先进系统，尤其是在较长的上下文中优势更加明显。

Conclusion: Nemori在LoCoMo和LongMemEval基准测试中显著优于先前的最先进系统，尤其是在较长的上下文中优势更加明显。

Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities, yet their
inability to maintain persistent memory in long contexts limits their
effectiveness as autonomous agents in long-term interactions. While existing
memory systems have made progress, their reliance on arbitrary granularity for
defining the basic memory unit and passive, rule-based mechanisms for knowledge
extraction limits their capacity for genuine learning and evolution. To address
these foundational limitations, we present Nemori, a novel self-organizing
memory architecture inspired by human cognitive principles. Nemori's core
innovation is twofold: First, its Two-Step Alignment Principle, inspired by
Event Segmentation Theory, provides a principled, top-down method for
autonomously organizing the raw conversational stream into semantically
coherent episodes, solving the critical issue of memory granularity. Second,
its Predict-Calibrate Principle, inspired by the Free-energy Principle, enables
the agent to proactively learn from prediction gaps, moving beyond pre-defined
heuristics to achieve adaptive knowledge evolution. This offers a viable path
toward handling the long-term, dynamic workflows of autonomous agents.
Extensive experiments on the LoCoMo and LongMemEval benchmarks demonstrate that
Nemori significantly outperforms prior state-of-the-art systems, with its
advantage being particularly pronounced in longer contexts.

</details>


### [118] [Adaptive AI Agent Placement and Migration in Edge Intelligence Systems](https://arxiv.org/abs/2508.03345)
*Xingdan Wang,Jiayi He,Zhiqing Tang,Jianxiong Guo,Jiong Lou,Liping Qian,Tian Wang,Weijia Jia*

Main category: cs.AI

TL;DR: This paper introduces a system for deploying and managing LLM-based AI agents at the edge, using ant colony algorithms and LLM-based optimization to reduce latency and costs.


<details>
  <summary>Details</summary>
Motivation: The rise of LLMs fuels the need for AI agents capable of real-time task handling. Deploying AI agents at the edge improves efficiency and reduces latency, but edge environments present challenges due to limited and heterogeneous resources. Maintaining QoS for mobile users necessitates agent migration, which is complicated by the complexity of AI agents coordinating LLMs, task planning, memory, and external tools.

Method: The approach models resource constraints and latency/cost, leveraging ant colony algorithms and LLM-based optimization for efficient decision-making. It autonomously places agents to optimize resource utilization and QoS and enables lightweight agent migration by transferring only essential state.

Result: Implemented on a distributed system using AgentScope and validated across globally distributed edge servers, our solution significantly reduces deployment latency and migration costs.

Conclusion: The paper presents a systematic deployment and management solution for LLM-based AI agents in dynamic edge environments, validated on a distributed system, that significantly reduces deployment latency and migration costs.

Abstract: The rise of LLMs such as ChatGPT and Claude fuels the need for AI agents
capable of real-time task handling. However, migrating data-intensive,
multi-modal edge workloads to cloud data centers, traditionally used for agent
deployment, introduces significant latency. Deploying AI agents at the edge
improves efficiency and reduces latency. However, edge environments present
challenges due to limited and heterogeneous resources. Maintaining QoS for
mobile users necessitates agent migration, which is complicated by the
complexity of AI agents coordinating LLMs, task planning, memory, and external
tools. This paper presents the first systematic deployment and management
solution for LLM-based AI agents in dynamic edge environments. We propose a
novel adaptive framework for AI agent placement and migration in edge
intelligence systems. Our approach models resource constraints and
latency/cost, leveraging ant colony algorithms and LLM-based optimization for
efficient decision-making. It autonomously places agents to optimize resource
utilization and QoS and enables lightweight agent migration by transferring
only essential state. Implemented on a distributed system using AgentScope and
validated across globally distributed edge servers, our solution significantly
reduces deployment latency and migration costs.

</details>


### [119] [Compressing Chain-of-Thought in LLMs via Step Entropy](https://arxiv.org/abs/2508.03346)
*Zeju Li,Jianyuan Zhong,Ziyang Zheng,Xiangyu Wen,Zhijian Xu,Yingying Cheng,Fan Zhang,Qiang Xu*

Main category: cs.AI

TL;DR: 提出了一种新颖的CoT压缩框架，该框架基于步骤熵来量化各个推理步骤的信息贡献，以识别冗余。


<details>
  <summary>Details</summary>
Motivation: 思维链（CoT）提示的大型语言模型（LLM）擅长复杂推理，但会生成冗长的思考过程，导致推理成本增加和效率降低。

Method: 基于步骤熵的CoT压缩框架，结合监督微调（SFT）和群体相对策略优化（GRPO）强化学习的两阶段训练策略。

Result: 实验表明，可以修剪80%的低熵中间步骤，而最终答案的准确性略有下降。相比之下，随机或高熵修剪会严重损害推理性能。

Conclusion: 该方法显著提高了LLM的推理效率，同时严格保证了准确性，为实际的LLM部署和对推理结构的更深入理解提供了深刻的意义。

Abstract: Large Language Models (LLMs) using Chain-of-Thought (CoT) prompting excel at
complex reasoning but generate verbose thought processes with considerable
redundancy, leading to increased inference costs and reduced efficiency. We
introduce a novel CoT compression framework based on step entropy, a metric
that quantifies the informational contribution of individual reasoning steps to
identify redundancy. Through theoretical analysis and extensive empirical
validation on mathematical reasoning benchmarks, we demonstrate that steps with
low entropy are indeed highly redundant. Our experiments reveal that an
astonishing 80\% of low-entropy intermediate steps can be pruned with minor
degradation in the final answer accuracy across DeepSeek-R1-7B, 14B and
Qwen3-8B. This finding sharply contrasts with random or high-entropy pruning,
which severely impairs reasoning performance. Building on this, we propose a
novel two-stage training strategy combining Supervised Fine-Tuning (SFT) and
Group Relative Policy Optimization (GRPO) reinforcement learning. This approach
enables LLMs to autonomously learn to generate compressed COTs during inference
by strategically incorporating [SKIP] tokens. Our method significantly enhances
LLM inference efficiency while rigorously preserving accuracy, offering
profound implications for practical LLM deployment and a deeper understanding
of reasoning structures.

</details>


### [120] [CogBench: A Large Language Model Benchmark for Multilingual Speech-Based Cognitive Impairment Assessment](https://arxiv.org/abs/2508.03360)
*Feng Rui,Zhiyao Luo,Wei Wang,Yuting Song,Yong Liu,Tingting Zhu,Jianqing Li,Xingyao Wang*

Main category: cs.AI

TL;DR: 提出了 CogBench 基准来评估大型语言模型在语音认知障碍评估中的跨语言和跨站点泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在跨不同语言和临床环境部署时通常缺乏通用性，限制了它们的实际效用。因此，提出了 CogBench，这是第一个旨在评估大型语言模型（LLM）在基于语音的认知障碍评估中的跨语言和跨站点泛化能力的基准。

Method: 使用统一的多模态管道，在跨越英语和普通话的三个语音数据集（ADReSSo、NCMMSC2021-AD 和新收集的测试集 CIR-E）上评估模型性能。

Result: 传统深度学习模型在跨领域转移时性能大幅下降。相比之下，配备了思维链提示的 LLM 表现出更好的适应性，但其性能仍然对提示设计敏感。

Conclusion: 轻量级微调大型语言模型（LLM）通过低秩适应（LoRA）显著提高了目标领域的泛化能力，为构建临床实用且语言稳健的基于语音的认知评估工具提供了关键一步。

Abstract: Automatic assessment of cognitive impairment from spontaneous speech offers a
promising, non-invasive avenue for early cognitive screening. However, current
approaches often lack generalizability when deployed across different languages
and clinical settings, limiting their practical utility. In this study, we
propose CogBench, the first benchmark designed to evaluate the cross-lingual
and cross-site generalizability of large language models (LLMs) for
speech-based cognitive impairment assessment. Using a unified multimodal
pipeline, we evaluate model performance on three speech datasets spanning
English and Mandarin: ADReSSo, NCMMSC2021-AD, and a newly collected test set,
CIR-E. Our results show that conventional deep learning models degrade
substantially when transferred across domains. In contrast, LLMs equipped with
chain-of-thought prompting demonstrate better adaptability, though their
performance remains sensitive to prompt design. Furthermore, we explore
lightweight fine-tuning of LLMs via Low-Rank Adaptation (LoRA), which
significantly improves generalization in target domains. These findings offer a
critical step toward building clinically useful and linguistically robust
speech-based cognitive assessment tools.

</details>


### [121] [A Comparative Study of Neurosymbolic AI Approaches to Interpretable Logical Reasoning](https://arxiv.org/abs/2508.03366)
*Michael K. Chen*

Main category: cs.AI

TL;DR: This paper compares integrative and hybrid neurosymbolic approaches to improve logical reasoning for LLMs, and the analysis demonstrates that the hybrid approach is more promising for developing general logical reasoning.


<details>
  <summary>Details</summary>
Motivation: Current LLMs fail to reason deterministically and are not interpretable. As such, there has been a recent surge in interest in neurosymbolic AI, which attempts to incorporate logic into neural networks. However, their performance on domain-agnostic benchmarks is understudied. To the best of our knowledge, there has not been a comparison of the contrasting approaches that answers the following question: Which approach is more promising for developing general logical reasoning?

Method: introduce Logic Neural Network (LNN), which uses the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the hybrid approach, Using both models as case studies and representatives of each approach, our analysis demonstrates that the hybrid approach is more promising for developing general logical reasoning

Result: the hybrid approach is more promising for developing general logical reasoning because (i) its reasoning chain is more interpretable, and (ii) it retains the capabilities and advantages of existing LLMs. To support future works using the hybrid approach, we propose a generalizable framework based on LLM-SS that is modular by design, model-agnostic, domain-agnostic, and requires little to no human input.

Conclusion: the hybrid approach is more promising for developing general logical reasoning because (i) its reasoning chain is more interpretable, and (ii) it retains the capabilities and advantages of existing LLMs

Abstract: General logical reasoning, defined as the ability to reason deductively on
domain-agnostic tasks, continues to be a challenge for large language models
(LLMs). Current LLMs fail to reason deterministically and are not
interpretable. As such, there has been a recent surge in interest in
neurosymbolic AI, which attempts to incorporate logic into neural networks. We
first identify two main neurosymbolic approaches to improving logical
reasoning: (i) the integrative approach comprising models where symbolic
reasoning is contained within the neural network, and (ii) the hybrid approach
comprising models where a symbolic solver, separate from the neural network,
performs symbolic reasoning. Both contain AI systems with promising results on
domain-specific logical reasoning benchmarks. However, their performance on
domain-agnostic benchmarks is understudied. To the best of our knowledge, there
has not been a comparison of the contrasting approaches that answers the
following question: Which approach is more promising for developing general
logical reasoning? To analyze their potential, the following best-in-class
domain-agnostic models are introduced: Logic Neural Network (LNN), which uses
the integrative approach, and LLM-Symbolic Solver (LLM-SS), which uses the
hybrid approach. Using both models as case studies and representatives of each
approach, our analysis demonstrates that the hybrid approach is more promising
for developing general logical reasoning because (i) its reasoning chain is
more interpretable, and (ii) it retains the capabilities and advantages of
existing LLMs. To support future works using the hybrid approach, we propose a
generalizable framework based on LLM-SS that is modular by design,
model-agnostic, domain-agnostic, and requires little to no human input.

</details>


### [122] [Board Game Arena: A Framework and Benchmark for Assessing Large Language Models via Strategic Play](https://arxiv.org/abs/2508.03368)
*Lucia Cipolina-Kun,Marianna Nezhurina,Jenia Jitsev*

Main category: cs.AI

TL;DR: The Board Game Arena library provides a framework for evaluating the decision making abilities of LLMs through strategic board games.The framework enables systematic comparisons between LLM based agents and other agents in various game scenarios by wrapping multiple board and matrix games and supporting different agent types.This paper summarizes the structure, key characteristics, and motivation of the repository, highlighting how it contributes to the empirical evaluation of the reasoning of LLM and game-theoretic behavior


<details>
  <summary>Details</summary>
Motivation: Evaluating the decision making abilities of large language models (LLMs) through strategic board games.

Method: The Board Game Arena library uses strategic board games implemented in Google OpenSpiel to evaluate LLMs. It integrates API access to models via LiteLLM, local model deployment via vLLM, and offers distributed execution through Ray. Additionally it provides extensive analysis tools for the LLM reasoning traces.

Result: The framework enables systematic comparisons between LLM based agents and other agents (random, human, reinforcement learning agents, etc.) in various game scenarios by wrapping multiple board and matrix games and supporting different agent types.

Conclusion: This paper summarizes the structure, key characteristics, and motivation of the repository, highlighting how it contributes to the empirical evaluation of the reasoning of LLM and game-theoretic behavior

Abstract: The Board Game Arena library provides a framework for evaluating the decision
making abilities of large language models (LLMs) through strategic board games
implemented in Google OpenSpiel library. The framework enables systematic
comparisons between LLM based agents and other agents (random, human,
reinforcement learning agents, etc.) in various game scenarios by wrapping
multiple board and matrix games and supporting different agent types. It
integrates API access to models via LiteLLM, local model deployment via vLLM,
and offers distributed execution through Ray. Additionally it provides
extensive analysis tools for the LLM reasoning traces. This paper summarizes
the structure, key characteristics, and motivation of the repository,
highlighting how it contributes to the empirical evaluation of the reasoning of
LLM and game-theoretic behavior

</details>


### [123] [Data Dependency Inference for Industrial Code Generation Based on UML Sequence Diagrams](https://arxiv.org/abs/2508.03379)
*Wenxin Mao,Zhitao Wang Long Wang,Sirong Chen,Cuiyun Gao,Luyang Cao,Ziming Liu,Qiming Zhang,Jun Zhou,Zhi Jin*

Main category: cs.AI

TL;DR: UML2Dep framework uses formal UML diagrams and data dependency graphs to generate code from complex requirements, overcoming the ambiguity of natural language descriptions.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the ambiguity of natural language descriptions in code generation, which often fails to capture complex requirements in service-oriented architectures.

Method: The method involves enhancing UML sequence diagrams with decision tables and API specifications, introducing a data dependency inference (DDI) task, and formalizing DDI as a constrained mathematical reasoning task.

Result: The paper focuses on the framework and its components, with the aim of enhancing reasoning accuracy and efficiency.

Conclusion: This paper introduces UML2Dep, a novel code generation framework that uses enhanced UML sequence diagrams and explicit data dependency graphs to address the ambiguity of natural language descriptions in complex system requirements.

Abstract: Large language models (LLMs) excel at generating code from natural language
(NL) descriptions. However, the plain textual descriptions are inherently
ambiguous and often fail to capture complex requirements like intricate system
behaviors, conditional logic, and architectural constraints; implicit data
dependencies in service-oriented architectures are difficult to infer and
handle correctly. To bridge this gap, we propose a novel step-by-step code
generation framework named UML2Dep by leveraging unambiguous formal
specifications of complex requirements. First, we introduce an enhanced Unified
Modeling Language (UML) sequence diagram tailored for service-oriented
architectures. This diagram extends traditional visual syntax by integrating
decision tables and API specifications, explicitly formalizing structural
relationships and business logic flows in service interactions to rigorously
eliminate linguistic ambiguity. Second, recognizing the critical role of data
flow, we introduce a dedicated data dependency inference (DDI) task. DDI
systematically constructs an explicit data dependency graph prior to actual
code synthesis. To ensure reliability, we formalize DDI as a constrained
mathematical reasoning task through novel prompting strategies, aligning with
LLMs' excellent mathematical strengths. Additional static parsing and
dependency pruning further reduce context complexity and cognitive load
associated with intricate specifications, thereby enhancing reasoning accuracy
and efficiency.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [124] [Learned Adaptive Indexing](https://arxiv.org/abs/2508.03471)
*Suvam Kumar Das,Suprio Ray*

Main category: cs.DB

TL;DR: This paper introduces a novel learned adaptive indexing approach that builds indexes on the fly using machine learning models and query workload prediction, achieving significant performance improvements compared to existing adaptive indexes.


<details>
  <summary>Details</summary>
Motivation: Conventional indexes may not be worthwhile in dynamic situations when workload changes frequently. Existing learned indexes have to be constructed upfront and require training the model in advance, posing a challenge in dynamic situations. No learned indexes exist yet for adaptive indexing.

Method: A novel learned approach for adaptive indexing is built on the fly as queries are submitted and utilizes learned models for indexing data. A query workload prediction technique is employed to make future workload projection based on past workload data.

Result: The proposed approach performs better than others in most cases, offering 1.2x - 5.6x improvement in query performance.

Conclusion: The proposed learned adaptive indexing approach outperforms existing adaptive indexes in most cases, offering 1.2x - 5.6x improvement in query performance.

Abstract: Indexes can significantly improve search performance in relational databases.
However, if the query workload changes frequently or new data updates occur
continuously, it may not be worthwhile to build a conventional index upfront
for query processing. Adaptive indexing is a technique in which an index gets
built on the fly as a byproduct of query processing. In recent years, research
in database indexing has taken a new direction where machine learning models
are employed for the purpose of indexing. These indexes, known as learned
indexes, can be more efficient compared to traditional indexes such as B+-tree
in terms of memory footprints and query performance. However, a learned index
has to be constructed upfront and requires training the model in advance, which
becomes a challenge in dynamic situations when workload changes frequently. To
the best of our knowledge, no learned indexes exist yet for adaptive indexing.
We propose a novel learned approach for adaptive indexing. It is built on the
fly as queries are submitted and utilizes learned models for indexing data. To
enhance query performance, we employ a query workload prediction technique that
makes future workload projection based on past workload data. We have evaluated
our learned adaptive indexing approach against existing adaptive indexes for
various query workloads. Our results show that our approach performs better
than others in most cases, offering 1.2x - 5.6x improvement in query
performance.

</details>


### [125] [[Technical Report] ArceKV: Towards Workload-driven LSM-compactions for Key-Value Store Under Dynamic Workloads](https://arxiv.org/abs/2508.03565)
*Junfeng Liu,Haoxuan Xie,Siqiang Luo*

Main category: cs.DB

TL;DR: ElasticLSM 移除传统 LSM 树结构约束，Arce 指导 ElasticLSM 从其扩展的行动空间中选择最佳行动。ArceKV 在动态场景中性能提升了 3 倍。


<details>
  <summary>Details</summary>
Motivation: 由于其简单性和效率，键值存储是各种应用程序的基础。日志结构合并树 (LSM 树) 作为其底层结构占据主导地位，擅长处理快速增长的数据。最近的研究主要集中在优化具有固定读写比率的静态工作负载下的 LSM 树性能。然而，现实世界的工作负载是高度动态的，现有的工作负载感知方法通常难以维持最佳性能，或者在工作负载模式发生变化时会产生大量的转换开销。

Method: 我们提出了 ElasticLSM，它消除了传统的 LSM 树结构约束，以允许更灵活的管理操作（即，压缩和写暂停），从而为持续的性能优化创造了更多机会。我们进一步设计了 Arce，这是一个轻量级压缩决策引擎，它指导 ElasticLSM 从其扩展的行动空间中选择最佳行动。

Result: ArceKV 在动态场景中提供了大约快 3 倍的性能，优于最先进的压缩策略。

Conclusion: ArceKV在各种工作负载中优于最先进的压缩策略，在动态场景中提供大约快 3 倍的性能。

Abstract: Key-value stores underpin a wide range of applications due to their
simplicity and efficiency. Log-Structured Merge Trees (LSM-trees) dominate as
their underlying structure, excelling at handling rapidly growing data. Recent
research has focused on optimizing LSM-tree performance under static workloads
with fixed read-write ratios. However, real-world workloads are highly dynamic,
and existing workload-aware approaches often struggle to sustain optimal
performance or incur substantial transition overhead when workload patterns
shift. To address this, we propose ElasticLSM, which removes traditional
LSM-tree structural constraints to allow more flexible management actions
(i.e., compactions and write stalls) creating greater opportunities for
continuous performance optimization. We further design Arce, a lightweight
compaction decision engine that guides ElasticLSM in selecting the optimal
action from its expanded action space. Building on these components, we
implement ArceKV, a full-fledged key-value store atop RocksDB. Extensive
evaluations demonstrate that ArceKV outperforms state-of-the-art compaction
strategies across diverse workloads, delivering around 3x faster performance in
dynamic scenarios.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [126] [Realizing Scaling Laws in Recommender Systems: A Foundation-Expert Paradigm for Hyperscale Model Deployment](https://arxiv.org/abs/2508.02929)
*Dai Li,Kevin Course,Wei Li,Hongwei Li,Jie Hua,Yiqi Chen,Zhao Zhu,Rui Jian,Xuan Cao,Bi Xue,Yu Shi,Jing Qian,Kai Ren,Matt Ma,Qunshu Zhang,Rui Li*

Main category: cs.IR

TL;DR: Propose and deploy the Foundation-Expert Paradigm to address the challenges of deploying hyperscale models in recommender systems. Achieved online metric improvements and improved developer velocity at Meta.


<details>
  <summary>Details</summary>
Motivation: Efficiently deploying hyperscale models remains a major unsolved challenge. Progress in recommender systems is hindered by unique challenges including the need to learn from online streaming data under shifting data distributions, the need to adapt to different recommendation surfaces with a wide diversity in their downstream tasks and their input distributions, and stringent latency and computational constraints.

Method: Leverage the Foundation-Expert Paradigm: a framework designed for the development and deployment of hyperscale recommendation FMs. In our approach, a central FM is trained on lifelong, cross-surface, multi-modal user data to learn generalizable knowledge. This knowledge is then efficiently transferred to various lightweight, surface-specific ``expert" models via target-aware embeddings, allowing them to adapt to local data distributions and optimization goals with minimal overhead.

Result: Demonstrating online metric improvements over our previous one-stage production system while improving developer velocity and maintaining infrastructure efficiency. The approach is now deployed at Meta serving tens of billions of user requests daily.

Conclusion: This work represents the first successful deployment of a Foundation-Expert paradigm at this scale, offering a proven, compute-efficient, and developer-friendly blueprint to realize the promise of scaling laws in recommender systems.

Abstract: While scaling laws promise significant performance gains for recommender
systems, efficiently deploying hyperscale models remains a major unsolved
challenge. In contrast to fields where FMs are already widely adopted such as
natural language processing and computer vision, progress in recommender
systems is hindered by unique challenges including the need to learn from
online streaming data under shifting data distributions, the need to adapt to
different recommendation surfaces with a wide diversity in their downstream
tasks and their input distributions, and stringent latency and computational
constraints. To bridge this gap, we propose to leverage the Foundation-Expert
Paradigm: a framework designed for the development and deployment of hyperscale
recommendation FMs. In our approach, a central FM is trained on lifelong,
cross-surface, multi-modal user data to learn generalizable knowledge. This
knowledge is then efficiently transferred to various lightweight,
surface-specific ``expert" models via target-aware embeddings, allowing them to
adapt to local data distributions and optimization goals with minimal overhead.
To meet our training, inference and development needs, we built HyperCast, a
production-grade infrastructure system that re-engineers training, serving,
logging and iteration to power this decoupled paradigm. Our approach is now
deployed at Meta serving tens of billions of user requests daily, demonstrating
online metric improvements over our previous one-stage production system while
improving developer velocity and maintaining infrastructure efficiency. To the
best of our knowledge, this work represents the first successful deployment of
a Foundation-Expert paradigm at this scale, offering a proven,
compute-efficient, and developer-friendly blueprint to realize the promise of
scaling laws in recommender systems.

</details>


### [127] [LLM-based IR-system for Bank Supervisors](https://arxiv.org/abs/2508.02945)
*Ilias Aarab*

Main category: cs.IR

TL;DR: An Information Retrieval (IR) System was developed to help bank supervisors draft consistent and effective measures by retrieving relevant historical findings. It achieves high accuracy, outperforming other models.


<details>
  <summary>Details</summary>
Motivation: Bank supervisors need to ensure that new measures are consistently aligned with historical precedents.

Method: The system utilizes a blend of lexical, semantic, and Capital Requirements Regulation (CRR) fuzzy set matching techniques, enhanced by a Transformer-based Denoising AutoEncoder for fine-tuning.

Result: The IR system retrieves relevant historical findings and their associated measures, providing a basis for supervisors to write well-informed measures. The system's performance is validated through a Monte Carlo methodology.

Conclusion: The system achieves a Mean Average Precision (MAP@100) of 0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92, surpassing standalone lexical and semantic models.

Abstract: Bank supervisors face the complex task of ensuring that new measures are
consistently aligned with historical precedents. To address this challenge, we
introduce a novel Information Retrieval (IR) System tailored to assist
supervisors in drafting both consistent and effective measures. This system
ingests findings from on-site investigations. It then retrieves the most
relevant historical findings and their associated measures from a comprehensive
database, providing a solid basis for supervisors to write well-informed
measures for new findings. Utilizing a blend of lexical, semantic, and Capital
Requirements Regulation (CRR) fuzzy set matching techniques, the IR system
ensures the retrieval of findings that closely align with current cases. The
performance of this system, particularly in scenarios with partially labeled
data, is validated through a Monte Carlo methodology, showcasing its robustness
and accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for
fine-tuning, the final model achieves a Mean Average Precision (MAP@100) of
0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those
of both standalone lexical models such as BM25 and semantic BERT-like models.

</details>


### [128] [SustainableQA: A Comprehensive Question Answering Dataset for Corporate Sustainability and EU Taxonomy Reporting](https://arxiv.org/abs/2508.03000)
*Mohammed Ali,Abdelrahman Abdallah,Adam Jatowt*

Main category: cs.IR

TL;DR: 提出了SustainableQA，这是一个新的数据集和一个可扩展的管道，用于从企业可持续发展报告和年度报告中生成全面的QA数据集。


<details>
  <summary>Details</summary>
Motivation: 对企业可持续发展透明度的需求不断增长，尤其是在欧盟分类法等新法规下，需要从大型非结构化企业报告中精确提取数据。大型语言模型（LLM）和检索增强生成（RAG）系统需要高质量、特定领域的问答（QA）数据集才能在特定领域表现出色。

Method: 该方法整合了语义块分类、混合跨度提取管道（结合了微调的命名实体识别（NER）、基于规则的方法和LLM驱动的改进）以及专门的表到段落转换。

Result: 拥有超过195,000个不同的事实型和非事实型问答对。

Conclusion: SustainableQA是一个有效资源，可以开发和评估能够驾驭复杂可持续性合规的高级知识助手。

Abstract: The growing demand for corporate sustainability transparency, particularly
under new regulations like the EU Taxonomy, necessitates precise data
extraction from large, unstructured corporate reports. Large Language Models
(LLMs) and Retrieval-Augmented Generation (RAG) systems, requires high-quality,
domain-specific question-answering (QA) datasets to excel at particular
domains. To address this, we introduce SustainableQA, a novel dataset and a
scalable pipeline for generating a comprehensive QA datasets from corporate
sustainability reports and annual reports. Our approach integrates semantic
chunk classification, a hybrid span extraction pipeline combining fine-tuned
Named Entity Recognition (NER), rule-based methods, and LLM-driven refinement,
alongside a specialized table-to-paragraph transformation. With over 195,000
diverse factoid and non-factoid QA pairs, SustainableQA is an effective
resource for developing and benchmarking advanced knowledge assistants capable
of navigating complex sustainability compliance

</details>


### [129] [KBest: Efficient Vector Search on Kunpeng CPU](https://arxiv.org/abs/2508.03016)
*Kaihao MA,Meiling Wang,Senkevich Oleg,Zijian LI,Daihao Xue,Dmitriy Malyshev,Yangming Lv,Shihai Xiao,Xiao Yan,Radionov Alexander,Weidi Zeng,Yuanzhan Gao,Zhiyu Zou,Yao xin,Liu Lin,Junhao Wu,Yiding Liu,Yaoyao Fu,Gongyi Wang,Gong Zhang,Fei Yi,Yingfan Liu*

Main category: cs.IR

TL;DR: KBest is a vector search library tailored for Kunpeng 920 CPUs, outperforming SOTA libraries with hardware-aware and algorithmic optimizations.


<details>
  <summary>Details</summary>
Motivation: Existing vector search libraries are optimized for x86 CPUs, while Huawei Kunpeng CPUs are based on the ARM architecture and competitive in compute power.

Method: hardware-aware and algorithmic optimizations, including SIMD accelerated distance computation, data prefetch, index refinement, early termination, and vector quantization

Result: KBest outperforms SOTA vector search libraries running on x86 CPUs, and our optimizations can improve the query throughput by over 2x.

Conclusion: KBest outperforms SOTA vector search libraries on x86 CPUs, improving query throughput by over 2x. It serves applications with tens of millions of daily queries.

Abstract: Vector search, which returns the vectors most similar to a given query vector
from a large vector dataset, underlies many important applications such as
search, recommendation, and LLMs. To be economic, vector search needs to be
efficient to reduce the resources required by a given query workload. However,
existing vector search libraries (e.g., Faiss and DiskANN) are optimized for
x86 CPU architectures (i.e., Intel and AMD CPUs) while Huawei Kunpeng CPUs are
based on the ARM architecture and competitive in compute power. In this paper,
we present KBest as a vector search library tailored for the latest Kunpeng 920
CPUs. To be efficient, KBest incorporates extensive hardware-aware and
algorithmic optimizations, which include single-instruction-multiple-data
(SIMD) accelerated distance computation, data prefetch, index refinement, early
termination, and vector quantization. Experiment results show that KBest
outperforms SOTA vector search libraries running on x86 CPUs, and our
optimizations can improve the query throughput by over 2x. Currently, KBest
serves applications from both our internal business and external enterprise
clients with tens of millions of queries on a daily basis.

</details>


### [130] [ADSeeker: A Knowledge-Infused Framework for Anomaly Detection and Reasoning](https://arxiv.org/abs/2508.03088)
*Kai Zhang,Zekai Zhang,Xihe Sun,Jingmeng Nie,Qinghui Chen,Han Hao,Jianyuan Guo,Jinglin Zhang*

Main category: cs.IR

TL;DR: The paper introduces ADSeeker, a knowledge-grounded reasoning framework for anomaly detection that enhances inspection performance. It uses a new visual document knowledge base, a novel RAG framework, and a hierarchical sparse prompt mechanism. A new large-scale anomaly detection dataset is also introduced. ADSeeker achieves state-of-the-art zero-shot performance.


<details>
  <summary>Details</summary>
Motivation: Multimodal large language models (MLLMs) perform worse than human experts in automatic vision inspection due to insufficient integration of anomaly detection (AD) knowledge and the lack of technically precise language generation.

Method: ADSeeker leverages a curated visual document knowledge base, SEEK-MVTec&VisA (SEEK-M&V), and introduces the Query Image-Knowledge Retrieval-Augmented Generation (Q2K RAG) framework. It also leverages the Hierarchical Sparse Prompt mechanism and type-level features. The paper introduces a new large-scale AD dataset, Multi-type Anomaly (MulA).

Result: ADSeeker achieves state-of-the-art zero-shot performance on several benchmark datasets.

Conclusion: ADSeeker achieves state-of-the-art zero-shot performance on several benchmark datasets.

Abstract: Automatic vision inspection holds significant importance in industry
inspection. While multimodal large language models (MLLMs) exhibit strong
language understanding capabilities and hold promise for this task, their
performance remains significantly inferior to that of human experts. In this
context, we identify two key challenges: (i) insufficient integration of
anomaly detection (AD) knowledge during pre-training, and (ii) the lack of
technically precise and conte-aware language generation for anomaly reasoning.
To address these issues, we propose ADSeeker, an anomaly task assistant
designed to enhance inspection performance through knowledge-grounded
reasoning. ADSeeker leverages a curated visual document knowledge base,
SEEK-MVTec&VisA (SEEK-M&V), which we construct to address the limitations of
existing resources that rely solely on unstructured text. SEEK-M&V includes
semantic-rich descriptions and image-document pairs, enabling more
comprehensive anomaly understanding. To effectively retrieve and utilize this
knowledge, we introduce the Query Image-Knowledge Retrieval-Augmented
Generation (Q2K RAG) framework. To further enhance the performance in zero-shot
anomaly detection (ZSAD), ADSeeker leverages the Hierarchical Sparse Prompt
mechanism and type-level features to efficiently extract anomaly patterns.
Furthermore, to tackle the challenge of limited in industry anomaly detection
(IAD) data, we introduce the largest-scale AD dataset, Multi-type Anomaly
(MulA), encompassing 72 multi-scale defect types across 26 Categories.
Extensive experiments show that our plug-and-play framework, ADSeeker, achieves
state-of-the-art zero-shot performance on several benchmark datasets.

</details>


### [131] [Dual-disentangle Framework for Diversified Sequential Recommendation](https://arxiv.org/abs/2508.03172)
*Haoran Zhang,Jingtong Liu,Jiangzhou Deng,Junpeng Guo*

Main category: cs.IR

TL;DR: 该论文提出DDSRec，一个用于多样化序列推荐的双重解耦框架，通过解耦用户兴趣和意图来提高推荐的多样性和准确性。


<details>
  <summary>Details</summary>
Motivation: 用户交互序列的长度不断增加，以及不断变化的用户兴趣和意图的复杂纠缠，给多样性带来了重大挑战。

Method: 提出了一种与模型无关的双重解耦框架，用于多样化序列推荐 (DDSRec)。

Result: 在多个公共数据集上进行的大量实验表明，DDSRec 在序列推荐的准确性和多样性方面具有有效性和优越性。

Conclusion: 该论文通过在交互建模和表征学习中采用解耦视角来改进用户兴趣和意图建模，从而平衡序列推荐的准确性和多样性。

Abstract: Sequential recommendation predicts user preferences over time and has
achieved remarkable success. However, the growing length of user interaction
sequences and the complex entanglement of evolving user interests and
intentions introduce significant challenges to diversity. To address these, we
propose a model-agnostic Dual-disentangle framework for Diversified Sequential
Recommendation (DDSRec). The framework refines user interest and intention
modeling by adopting disentangling perspectives in interaction modeling and
representation learning, thereby balancing accuracy and diversity in sequential
recommendations. Extensive experiments on multiple public datasets demonstrate
the effectiveness and superiority of DDSRec in terms of accuracy and diversity
for sequential recommendations.

</details>


### [132] [Reliable Evaluation Protocol for Low-Precision Retrieval](https://arxiv.org/abs/2508.03306)
*Kisu Yang,Yoonna Jang,Hwanseok Jang,Kenneth Choi,Isabelle Augenstein,Heuiseok Lim*

Main category: cs.IR

TL;DR: Proposes High-Precision Scoring (HPS) and Tie-aware Retrieval Metrics (TRM) to address the instability in low-precision retrieval evaluation caused by spurious ties.


<details>
  <summary>Details</summary>
Motivation: Lowering the numerical precision of model parameters and computations is widely adopted to improve the efficiency of retrieval systems. However, when computing relevance scores between the query and documents in low-precision, we observe spurious ties due to the reduced granularity. This introduces high variability in the results based on tie resolution, making the evaluation less reliable.

Method: High-Precision Scoring (HPS), which upcasts the final scoring step to higher precision to resolve tied candidates with minimal computational cost; and Tie-aware Retrieval Metrics (TRM), which report expected scores, range, and bias to quantify order uncertainty of tied candidates.

Result: HPS dramatically reduces tie-induced instability, and TRM accurately recovers expected metric values.

Conclusion: This combination enables a more consistent and reliable evaluation system for lower-precision retrievals.

Abstract: Lowering the numerical precision of model parameters and computations is
widely adopted to improve the efficiency of retrieval systems. However, when
computing relevance scores between the query and documents in low-precision, we
observe spurious ties due to the reduced granularity. This introduces high
variability in the results based on tie resolution, making the evaluation less
reliable. To address this, we propose a more robust retrieval evaluation
protocol designed to reduce score variation. It consists of: (1) High-Precision
Scoring (HPS), which upcasts the final scoring step to higher precision to
resolve tied candidates with minimal computational cost; and (2) Tie-aware
Retrieval Metrics (TRM), which report expected scores, range, and bias to
quantify order uncertainty of tied candidates. Our experiments test multiple
models with three scoring functions on two retrieval datasets to demonstrate
that HPS dramatically reduces tie-induced instability, and TRM accurately
recovers expected metric values. This combination enables a more consistent and
reliable evaluation system for lower-precision retrievals.

</details>


### [133] [Parameter-Efficient Single Collaborative Branch for Recommendation](https://arxiv.org/abs/2508.03518)
*Marta Moscati,Shah Nawaz,Markus Schedl*

Main category: cs.IR

TL;DR: 提出了一种基于权重共享的推荐系统CoBraR，实验表明CoBraR具有应用于实际场景的潜力。


<details>
  <summary>Details</summary>
Motivation: 现代推荐系统中，获得用户和项目表示的模块由两个不同的神经网络组成。在多模态表示学习中，权重共享已被证明可以有效减少同一项目的多个模态之间的距离。因此，我们受到这些方法的启发。

Method: 提出了一种新颖的推荐系统CoBraR，它利用用户和项目神经网络模块之间的权重共享，以获得共享嵌入空间中的潜在表示。

Result: 通过在电子商务和电影推荐方面的定量实验评估CoBraR。实验表明，

Conclusion: CoBraR在不影响准确性的前提下，减少了参数数量并改善了超越准确性的方面，因此具有应用于实际场景的潜力。

Abstract: Recommender Systems (RS) often rely on representations of users and items in
a joint embedding space and on a similarity metric to compute relevance scores.
In modern RS, the modules to obtain user and item representations consist of
two distinct and separate neural networks (NN). In multimodal representation
learning, weight sharing has been proven effective in reducing the distance
between multiple modalities of a same item. Inspired by these approaches, we
propose a novel RS that leverages weight sharing between the user and item NN
modules used to obtain the latent representations in the shared embedding
space. The proposed framework consists of a single Collaborative Branch for
Recommendation (CoBraR). We evaluate CoBraR by means of quantitative
experiments on e-commerce and movie recommendation. Our experiments show that
by reducing the number of parameters and improving beyond-accuracy aspects
without compromising accuracy, CoBraR has the potential to be applied and
extended for real-world scenarios.

</details>


### [134] [MultiRAG: A Knowledge-guided Framework for Mitigating Hallucination in Multi-source Retrieval Augmented Generation](https://arxiv.org/abs/2508.03553)
*Wenlong Wu,Haofen Wang,Bohan Li,Peixuan Huang,Xinzhe Zhao,Lei Liang*

Main category: cs.IR

TL;DR: MultiRAG通过知识引导方法缓解多源检索增强生成中的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 多源检索增强生成（RAG）可以解决大型语言模型（LLM）中的幻觉问题，但多源集成会引入新的挑战，从而加剧幻觉问题。

Method: MultiRAG框架，通过知识构建模块和检索模块缓解幻觉问题。

Result: 在四个多领域查询数据集和两个多跳QA数据集上的大量实验表明，

Conclusion: MultiRAG显著提高了复杂多源场景中知识检索的可靠性和效率。

Abstract: Retrieval Augmented Generation (RAG) has emerged as a promising solution to
address hallucination issues in Large Language Models (LLMs). However, the
integration of multiple retrieval sources, while potentially more informative,
introduces new challenges that can paradoxically exacerbate hallucination
problems. These challenges manifest primarily in two aspects: the sparse
distribution of multi-source data that hinders the capture of logical
relationships and the inherent inconsistencies among different sources that
lead to information conflicts. To address these challenges, we propose
MultiRAG, a novel framework designed to mitigate hallucination in multi-source
retrieval-augmented generation through knowledge-guided approaches. Our
framework introduces two key innovations: (1) a knowledge construction module
that employs multi-source line graphs to efficiently aggregate logical
relationships across different knowledge sources, effectively addressing the
sparse data distribution issue; and (2) a sophisticated retrieval module that
implements a multi-level confidence calculation mechanism, performing both
graph-level and node-level assessments to identify and eliminate unreliable
information nodes, thereby reducing hallucinations caused by inter-source
inconsistencies. Extensive experiments on four multi-domain query datasets and
two multi-hop QA datasets demonstrate that MultiRAG significantly enhances the
reliability and efficiency of knowledge retrieval in complex multi-source
scenarios. \textcolor{blue}{Our code is available in
https://github.com/wuwenlong123/MultiRAG.

</details>


### [135] [PyLate: Flexible Training and Retrieval for Late Interaction Models](https://arxiv.org/abs/2508.03555)
*Antoine Chaffin,Raphaël Sourty*

Main category: cs.IR

TL;DR: PyLate是一个旨在简化多向量模型的使用和开发的库，它建立在Sentence Transformers之上，并提供了高效的索引等功能，以加速延迟交互模型在现代信息检索系统中的应用。


<details>
  <summary>Details</summary>
Motivation: 单向量搜索将所有信息压缩成一个向量，导致在领域外、长上下文和推理密集型检索任务中性能显著下降。尽管延迟交互模型具有明显的优势，但由于缺乏可访问和模块化的工具，它们的实际采用率和公开可用性仍然较低。

Method: 介绍PyLate，一个建立在Sentence Transformers之上的简化库，以原生支持多向量架构，继承了其高效的训练、高级日志记录和自动化模型卡生成，同时只需要对用户已经熟悉的代码模板进行最少的代码更改。

Result: PyLate已经支持了最先进的模型的开发，包括GTE-ModernColBERT和Reason-ModernColBERT，展示了它在研究和生产环境中的实际效用。

Conclusion: PyLate通过提供高效索引等多向量特定功能，旨在加速延迟交互模型的研究和实际应用，从而释放它们在现代IR系统中的全部潜力。PyLate已经支持了最先进的模型的开发，包括GTE-ModernColBERT和Reason-ModernColBERT，展示了它在研究和生产环境中的实际效用。

Abstract: Neural ranking has become a cornerstone of modern information retrieval.
While single vector search remains the dominant paradigm, it suffers from the
shortcoming of compressing all the information into a single vector. This
compression leads to notable performance degradation in out-of-domain,
long-context, and reasoning-intensive retrieval tasks. Multi-vector approaches
pioneered by ColBERT aim to address these limitations by preserving individual
token embeddings and computing similarity via the MaxSim operator. This
architecture has demonstrated superior empirical advantages, including enhanced
out-of-domain generalization, long-context handling, and performance in complex
retrieval scenarios. Despite these compelling empirical results and clear
theoretical advantages, the practical adoption and public availability of late
interaction models remain low compared to their single-vector counterparts,
primarily due to a lack of accessible and modular tools for training and
experimenting with such models. To bridge this gap, we introduce PyLate, a
streamlined library built on top of Sentence Transformers to support
multi-vector architectures natively, inheriting its efficient training,
advanced logging, and automated model card generation while requiring minimal
code changes to code templates users are already familiar with. By offering
multi-vector-specific features such as efficient indexes, PyLate aims to
accelerate research and real-world application of late interaction models,
thereby unlocking their full potential in modern IR systems. Finally, PyLate
has already enabled the development of state-of-the-art models, including
GTE-ModernColBERT and Reason-ModernColBERT, demonstrating its practical utility
for both research and production environments.

</details>


### [136] [Demystifying Sequential Recommendations: Counterfactual Explanations via Genetic Algorithms](https://arxiv.org/abs/2508.03606)
*Domiziano Scarcelli,Filippo Betello,Giuseppe Perelli,Fabrizio Silvestri,Gabriele Tolomei*

Main category: cs.IR

TL;DR: This paper presents a counterfactual explanation technique for SRSs using a genetic algorithm, showing how minimal changes in user history can alter recommendations, thereby improving explainability and trust.


<details>
  <summary>Details</summary>
Motivation: The inherent complexity of SRSs as black box models poses challenges for explainability.

Method: A specialized genetic algorithm is tailored for discrete sequences.

Result: The method successfully generates interpretable counterfactual explanations while maintaining model fidelity close to one across three datasets and three models.

Conclusion: The paper introduces a counterfactual explanation technique for Sequential Recommender Systems (SRSs), enhancing user trust and system transparency.

Abstract: Sequential Recommender Systems (SRSs) have demonstrated remarkable
effectiveness in capturing users' evolving preferences. However, their inherent
complexity as "black box" models poses significant challenges for
explainability. This work presents the first counterfactual explanation
technique specifically developed for SRSs, introducing a novel approach in this
space, addressing the key question: What minimal changes in a user's
interaction history would lead to different recommendations? To achieve this,
we introduce a specialized genetic algorithm tailored for discrete sequences
and show that generating counterfactual explanations for sequential data is an
NP-Complete problem. We evaluate these approaches across four experimental
settings, varying between targeted-untargeted and categorized-uncategorized
scenarios, to comprehensively assess their capability in generating meaningful
explanations. Using three different datasets and three models, we are able to
demonstrate that our methods successfully generate interpretable counterfactual
explanation while maintaining model fidelity close to one. Our findings
contribute to the growing field of Explainable AI by providing a framework for
understanding sequential recommendation decisions through the lens of "what-if"
scenarios, ultimately enhancing user trust and system transparency.

</details>


### [137] [LLMDistill4Ads: Using Cross-Encoders to Distill from LLM Signals for Advertiser Keyphrase Recommendations at eBay](https://arxiv.org/abs/2508.03628)
*Soumik Dey,Benjamin Braun,Naveen Ravipati,Hansi Wu,Binbin Li*

Main category: cs.IR

TL;DR: This study introduces a two-step LLM distillation process to debias an Embedding Based Retrieval model, enhancing its performance in retrieving relevant advertiser keyphrases at eBay.


<details>
  <summary>Details</summary>
Motivation: The relevance of keyphrases is crucial in avoiding the overcrowding of search systems with irrelevant items and maintaining a positive seller perception. It is essential that keyphrase recommendations align with both seller and Search judgments regarding auctions. Due to the difficulty in procuring negative human judgment at scale, employing LLM-as-a-judge to mimic seller judgment has been established as the norm in several studies.

Method: a novel two-step LLM distillation process from a LLM-judge used to debias our Embedding Based Retrieval (EBR) model from the various biases that exist in click-data. We distill from an LLM teacher via a cross-encoder assistant into a bi-encoder student using a multi-task training approach, ultimately employing the student bi-encoder to retrieve relevant advertiser keyphrases.

Result: integrating a knowledge distillation process from LLMs in a multi-task training setup enhances bi-encoder performance in retrieving relevant advertiser keyphrases at eBay.

Conclusion: Integrating a knowledge distillation process from LLMs in a multi-task training setup enhances bi-encoder performance in retrieving relevant advertiser keyphrases at eBay.

Abstract: Sellers at eBay are recommended keyphrases to bid on to enhance the
performance of their advertising campaigns. The relevance of these keyphrases
is crucial in avoiding the overcrowding of search systems with irrelevant items
and maintaining a positive seller perception. It is essential that keyphrase
recommendations align with both seller and Search judgments regarding auctions.
Due to the difficulty in procuring negative human judgment at scale, employing
LLM-as-a-judge to mimic seller judgment has been established as the norm in
several studies. This study introduces a novel two-step LLM distillation
process from a LLM-judge used to debias our Embedding Based Retrieval (EBR)
model from the various biases that exist in click-data. We distill from an LLM
teacher via a cross-encoder assistant into a bi-encoder student using a
multi-task training approach, ultimately employing the student bi-encoder to
retrieve relevant advertiser keyphrases. We show that integrating a knowledge
distillation process from LLMs in a multi-task training setup enhances
bi-encoder performance in retrieving relevant advertiser keyphrases at eBay.

</details>


### [138] [Personalized Recommendation of Dish and Restaurant Collections on iFood](https://arxiv.org/abs/2508.03670)
*Fernando F. Granado,Davi A. Bezerra,Iuri Queiroz,Nathan Oliveira,Pedro Fernandes,Bruno Schock*

Main category: cs.IR

TL;DR: 本文介绍了RED，一个为iFood设计的自动化推荐系统，用于个性化推荐精选食品集合。


<details>
  <summary>Details</summary>
Motivation: 食品配送平台面临着帮助用户浏览大量餐厅和菜肴目录，找到他们真正喜欢的食物的挑战。本文介绍 RED，这是一个为拉丁美洲最大的按需食品配送平台 iFood 设计的自动化推荐系统，用于个性化向数百万用户展示的精选食品集合。

Method: 采用 LightGBM 分类器，根据集合特征、用户-集合相似度和上下文信息对集合进行评分。为了解决冷启动问题，开发了基于内容的表示，使用项目嵌入并实施单调性约束以提高泛化能力。通过从类别轮播交互中引导以及通过对生产中的展示和购买进行无偏采样来解决数据稀缺问题和可见性偏差。

Result: 通过与 iFood 5-10% 用户群进行的大量 A/B 测试，该系统展示了显著的实际影响。与基于受欢迎程度的基线相比，A/B 测试的在线结果使卡片转化率提高了 97%，整体应用程序转化率提高了 1.4%。

Conclusion: 该论文详细介绍了在动态商业环境中大规模推荐精选食品集合的首个案例。

Abstract: Food delivery platforms face the challenge of helping users navigate vast
catalogs of restaurants and dishes to find meals they truly enjoy. This paper
presents RED, an automated recommendation system designed for iFood, Latin
America's largest on-demand food delivery platform, to personalize the
selection of curated food collections displayed to millions of users. Our
approach employs a LightGBM classifier that scores collections based on three
feature groups: collection characteristics, user-collection similarity, and
contextual information. To address the cold-start problem of recommending newly
created collections, we develop content-based representations using item
embeddings and implement monotonicity constraints to improve generalization. We
tackle data scarcity by bootstrapping from category carousel interactions and
address visibility bias through unbiased sampling of impressions and purchases
in production. The system demonstrates significant real-world impact through
extensive A/B testing with 5-10% of iFood's user base. Online results of our
A/B tests add up to 97% improvement in Card Conversion Rate and 1.4% increase
in overall App Conversion Rate compared to popularity-based baselines. Notably,
our offline accuracy metrics strongly correlate with online performance,
enabling reliable impact prediction before deployment. To our knowledge, this
is the first work to detail large-scale recommendation of curated food
collections in a dynamic commercial environment.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [139] [A Bayesian Hybrid Parameter-Efficient Fine-Tuning Method for Large Language Models](https://arxiv.org/abs/2508.02711)
*Yidong Chai,Yang Liu,Yonghang Zhou,Jiaheng Xie,Daniel Dajun Zeng*

Main category: cs.LG

TL;DR: This paper introduces BH-PEFT, a Bayesian hybrid PEFT method for LLMs that enables uncertainty quantification and dynamic adaptation, outperforming existing methods in business tasks.


<details>
  <summary>Details</summary>
Motivation: Existing hybrid PEFT methods lack uncertainty quantification and struggle to dynamically adapt to emerging data when fine-tuning LLMs for specialized applications.

Method: The paper proposes BH-PEFT, which integrates Bayesian learning into hybrid PEFT, combining Adapter, LoRA, and prefix-tuning. It also proposes a Bayesian dynamic fine-tuning approach.

Result: BH-PEFT outperforms existing PEFT baselines, enables uncertainty quantification, and improves adaptability in dynamic scenarios on business tasks like sentiment analysis, news categorization, and commonsense reasoning.

Conclusion: The paper introduces Bayesian Hybrid Parameter-Efficient Fine-Tuning (BH-PEFT) and a dynamic fine-tuning approach. Experiments show it outperforms existing PEFT methods, enables uncertainty quantification, and improves adaptability in dynamic scenarios.

Abstract: Large Language Models (LLMs) have demonstrated transformative potential in
reshaping the world. As these models are pretrained on general corpora, they
often require domain-specific fine-tuning to optimize performance in
specialized business applications. Due to their massive scale,
parameter-efficient fine-tuning (PEFT) methods are widely used to reduce
training costs. Among them, hybrid PEFT methods that combine multiple PEFT
techniques have achieved the best performance. However, existing hybrid PEFT
methods face two main challenges when fine-tuning LLMs for specialized
applications: (1) relying on point estimates, lacking the ability to quantify
uncertainty for reliable decision-making, and (2) struggling to dynamically
adapt to emerging data, lacking the ability to suit real-world situations. We
propose Bayesian Hybrid Parameter-Efficient Fine-Tuning (BH-PEFT), a novel
method that integrates Bayesian learning into hybrid PEFT. BH-PEFT combines
Adapter, LoRA, and prefix-tuning to fine-tune feedforward and attention layers
of the Transformer. By modeling learnable parameters as distributions, BH-PEFT
enables uncertainty quantification. We further propose a Bayesian dynamic
fine-tuning approach where the last posterior serves as the prior for the next
round, enabling effective adaptation to new data. We evaluated BH-PEFT on
business tasks such as sentiment analysis, news categorization, and commonsense
reasoning. Results show that our method outperforms existing PEFT baselines,
enables uncertainty quantification for more reliable decisions, and improves
adaptability in dynamic scenarios. This work contributes to business analytics
and data science by proposing a novel BH-PEFT method and dynamic fine-tuning
approach that support uncertainty-aware and adaptive decision-making in
real-world situations.

</details>


### [140] [ZetA: A Riemann Zeta-Scaled Extension of Adam for Deep Learning](https://arxiv.org/abs/2508.02719)
*Samiksha BC*

Main category: cs.LG

TL;DR: ZetA: a novel deep learning optimizer that extends Adam and improves generalization and robustness.


<details>
  <summary>Details</summary>
Motivation: improve generalization and robustness

Method: a novel deep learning optimizer that extends Adam by incorporating dynamic scaling based on the Riemann zeta function. The method improves generalization and robustness through a hybrid update mechanism that integrates adaptive damping, cosine similarity-based momentum boosting, entropy-regularized loss, and Sharpness-Aware Minimization (SAM)-style perturbations.

Result: test accuracy improvements over Adam on SVHN, CIFAR10, CIFAR100, STL10, and noisy CIFAR10

Conclusion: ZetA is a computationally efficient and robust alternative to Adam, particularly effective in noisy or high-granularity classification tasks.

Abstract: This work introduces ZetA, a novel deep learning optimizer that extends Adam
by incorporating dynamic scaling based on the Riemann zeta function. To the
best of our knowledge, ZetA is the first optimizer to apply zeta-based gradient
scaling within deep learning optimization. The method improves generalization
and robustness through a hybrid update mechanism that integrates adaptive
damping, cosine similarity-based momentum boosting, entropy-regularized loss,
and Sharpness-Aware Minimization (SAM)-style perturbations. Empirical
evaluations on SVHN, CIFAR10, CIFAR100, STL10, and noisy CIFAR10 consistently
show test accuracy improvements over Adam. All experiments employ a lightweight
fully connected network trained for five epochs under mixed-precision settings.
The results demonstrate that ZetA is a computationally efficient and robust
alternative to Adam, particularly effective in noisy or high-granularity
classification tasks.

</details>


### [141] [ECGTwin: Personalized ECG Generation Using Controllable Diffusion Model](https://arxiv.org/abs/2508.02720)
*Yongfan Lai,Bo Liu,Xinyan Guan,Qinghao Zhao,Hongyan Li,Shenda Hong*

Main category: cs.LG

TL;DR: ECGTwin是一个两阶段框架，可以生成个性化的ECG信号，具有高保真度、多样性和个体特异性，并有可能改善ECG自动诊断。


<details>
  <summary>Details</summary>
Motivation: 个性化心电图（ECG）生成能够模拟患者在特定条件下的ECG数字孪生，从而将传统医疗保健转变为更准确的个体化模式，同时保留传统人群水平ECG合成的关键优势。然而，这项有前景的任务提出了两个根本挑战：在没有ground truth的情况下提取个体特征，以及在不混淆生成模型的情况下注入各种类型的条件。

Method: 使用对比学习训练的个体基础提取器和基于扩散的生成过程，通过AdaX条件注入器整合个体特征和目标心脏状况。

Result: 实验表明，ECGTwin模型不仅可以通过提供细粒度的生成可控性来生成高保真度和多样性的ECG信号，而且还保留了个体特异性特征。此外，ECGTwin显示出在下游应用中增强ECG自动诊断的潜力。

Conclusion: ECGTwin模型能够生成高质量和多样性的ECG信号，同时保留个体特异性特征，并有潜力增强ECG自动诊断。

Abstract: Personalized electrocardiogram (ECG) generation is to simulate a patient's
ECG digital twins tailored to specific conditions. It has the potential to
transform traditional healthcare into a more accurate individualized paradigm,
while preserving the key benefits of conventional population-level ECG
synthesis. However, this promising task presents two fundamental challenges:
extracting individual features without ground truth and injecting various types
of conditions without confusing generative model. In this paper, we present
ECGTwin, a two-stage framework designed to address these challenges. In the
first stage, an Individual Base Extractor trained via contrastive learning
robustly captures personal features from a reference ECG. In the second stage,
the extracted individual features, along with a target cardiac condition, are
integrated into the diffusion-based generation process through our novel AdaX
Condition Injector, which injects these signals via two dedicated and
specialized pathways. Both qualitative and quantitative experiments have
demonstrated that our model can not only generate ECG signals of high fidelity
and diversity by offering a fine-grained generation controllability, but also
preserving individual-specific features. Furthermore, ECGTwin shows the
potential to enhance ECG auto-diagnosis in downstream application, confirming
the possibility of precise personalized healthcare solutions.

</details>


### [142] [Mathematical Foundations of Geometric Deep Learning](https://arxiv.org/abs/2508.02723)
*Haitz Sáez de Ocáriz Borde,Michael Bronstein*

Main category: cs.LG

TL;DR: review of mathematical concepts for Geometric Deep Learning


<details>
  <summary>Details</summary>
Motivation: studying Geometric Deep Learning

Method: reviewing key mathematical concepts

Result: N/A

Conclusion: N/A

Abstract: We review the key mathematical concepts necessary for studying Geometric Deep
Learning.

</details>


### [143] [Forecasting NCAA Basketball Outcomes with Deep Learning: A Comparative Study of LSTM and Transformer Models](https://arxiv.org/abs/2508.02725)
*Md Imtiaz Habib*

Main category: cs.LG

TL;DR: Use LSTM and Transformer to predict the outcome of 2025 NCAA Division 1 Men's and Women's Basketball tournaments


<details>
  <summary>Details</summary>
Motivation: I explore advanced deep learning methodologies to forecast the outcomes of the 2025 NCAA Division 1 Men's and Women's Basketball tournaments. Leveraging historical NCAA game data

Method: I implement two sophisticated sequence-based models: Long Short-Term Memory (LSTM) and Transformer architectures. The predictive power of these models is augmented through comprehensive feature engineering, including team quality metrics derived from Generalized Linear Models (GLM), Elo ratings, seed differences, and aggregated box-score statistics. To evaluate the robustness and reliability of predictions, I train each model variant using both Binary Cross-Entropy (BCE) and Brier loss functions

Result: the Transformer architecture optimized with BCE yields superior discriminative power (highest AUC of 0.8473), the LSTM model trained with Brier loss demonstrates superior probabilistic calibration (lowest Brier score of 0.1589)

Conclusion: The Transformer architecture optimized with BCE yields superior discriminative power, while the LSTM model trained with Brier loss demonstrates superior probabilistic calibration. The importance of selecting appropriate model architectures and loss functions based on the specific requirements of forecasting tasks is underscored.

Abstract: In this research, I explore advanced deep learning methodologies to forecast
the outcomes of the 2025 NCAA Division 1 Men's and Women's Basketball
tournaments. Leveraging historical NCAA game data, I implement two
sophisticated sequence-based models: Long Short-Term Memory (LSTM) and
Transformer architectures. The predictive power of these models is augmented
through comprehensive feature engineering, including team quality metrics
derived from Generalized Linear Models (GLM), Elo ratings, seed differences,
and aggregated box-score statistics. To evaluate the robustness and reliability
of predictions, I train each model variant using both Binary Cross-Entropy
(BCE) and Brier loss functions, providing insights into classification
performance and probability calibration. My comparative analysis reveals that
while the Transformer architecture optimized with BCE yields superior
discriminative power (highest AUC of 0.8473), the LSTM model trained with Brier
loss demonstrates superior probabilistic calibration (lowest Brier score of
0.1589). These findings underscore the importance of selecting appropriate
model architectures and loss functions based on the specific requirements of
forecasting tasks. The detailed analytical pipeline presented here serves as a
reproducible framework for future predictive modeling tasks in sports analytics
and beyond.

</details>


### [144] [Embedding-Enhanced Probabilistic Modeling of Ferroelectric Field Effect Transistors (FeFETs)](https://arxiv.org/abs/2508.02737)
*Tasnia Nobi Afee,Jack Hutchins,Md Mazharul Islam,Thomas Kampfe,Ahmedullah Aziz*

Main category: cs.LG

TL;DR: 本文提出了一个增强的 FeFET 概率建模框架，该框架解决了现有模型的局限性，实现了对 FeFET 随机行为的精确建模，为未来的电路仿真奠定了基础。


<details>
  <summary>Details</summary>
Motivation: FeFET 在推进存储器和逻辑技术方面具有强大的潜力，但其固有的随机性（由操作循环和制造差异引起）给准确和可靠的建模带来了重大挑战。捕捉这种可变性至关重要，因为它使设计人员能够预测行为、优化性能并确保可靠性和鲁棒性，以抵抗制造和操作条件的变化。现有的确定性和基于机器学习的紧凑模型通常无法捕捉到这种可变性的全部范围，或者缺乏稳定电路级集成所需的数学平滑性。

Method: 在混合密度网络 (MDN) 基础上，该方法集成了 C-infinity 连续激活函数，用于平滑、稳定的学习，并集成了一个特定于设备的嵌入层，以捕获器件之间的内在物理可变性。

Result: 该模型在捕捉 FeFET 电流行为的可变性方面表现出很高的精度，R2 为 0.92。

Conclusion: 该框架为 FeFET 的完整随机行为建模提供了一个可扩展的、数据驱动的解决方案，并为未来的紧凑模型开发和电路仿真集成提供了强大的基础。

Abstract: FeFETs hold strong potential for advancing memory and logic technologies, but
their inherent randomness arising from both operational cycling and fabrication
variability poses significant challenges for accurate and reliable modeling.
Capturing this variability is critical, as it enables designers to predict
behavior, optimize performance, and ensure reliability and robustness against
variations in manufacturing and operating conditions. Existing deterministic
and machine learning-based compact models often fail to capture the full extent
of this variability or lack the mathematical smoothness required for stable
circuit-level integration. In this work, we present an enhanced probabilistic
modeling framework for FeFETs that addresses these limitations. Building upon a
Mixture Density Network (MDN) foundation, our approach integrates C-infinity
continuous activation functions for smooth, stable learning and a
device-specific embedding layer to capture intrinsic physical variability
across devices. Sampling from the learned embedding distribution enables the
generation of synthetic device instances for variability-aware simulation. With
an R2 of 0.92, the model demonstrates high accuracy in capturing the
variability of FeFET current behavior. Altogether, this framework provides a
scalable, data-driven solution for modeling the full stochastic behavior of
FeFETs and offers a strong foundation for future compact model development and
circuit simulation integration.

</details>


### [145] [DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening](https://arxiv.org/abs/2508.02741)
*Zhixiang Lu,Yulong Li,Feilong Tang,Zhengyong Jiang,Chong Li,Mian Zhou,Tenglong Li,Jionglong Su*

Main category: cs.LG

TL;DR: DeepGB-TB是一种使用咳嗽音频和基本人口统计数据，通过AI即时分配结核病风险评分的非侵入式系统，在准确性和效率方面都表现出色，适合资源有限的环境。


<details>
  <summary>Details</summary>
Motivation: 传统诊断方法成本高、操作复杂，限制了大规模结核病筛查，因此需要人工智能解决方案。

Method: 该模型结合了一个用于音频处理的轻量级一维卷积神经网络和一个用于表格特征的梯度提升决策树。其主要创新是一个跨模态双向交叉注意模块（CM-BCA），该模块迭代地在模态之间交换显著线索，模拟临床医生整合症状和风险因素的方式。

Result: DeepGB-TB在七个国家收集的包含1105名患者的多样化数据集上进行了评估，实现了0.903的AUROC和0.851的F1分数，代表了新的技术水平。其计算效率使得能够在常见移动设备上直接进行实时离线推理，使其成为资源匮乏环境的理想选择。

Conclusion: DeepGB-TB通过结合AI创新与公共卫生需求，为全球结核病控制提供了一种工具。

Abstract: Large-scale tuberculosis (TB) screening is limited by the high cost and
operational complexity of traditional diagnostics, creating a need for
artificial-intelligence solutions. We propose DeepGB-TB, a non-invasive system
that instantly assigns TB risk scores using only cough audio and basic
demographic data. The model couples a lightweight one-dimensional convolutional
neural network for audio processing with a gradient-boosted decision tree for
tabular features. Its principal innovation is a Cross-Modal Bidirectional
Cross-Attention module (CM-BCA) that iteratively exchanges salient cues between
modalities, emulating the way clinicians integrate symptoms and risk factors.
To meet the clinical priority of minimizing missed cases, we design a
Tuberculosis Risk-Balanced Loss (TRBL) that places stronger penalties on
false-negative predictions, thereby reducing high-risk misclassifications.
DeepGB-TB is evaluated on a diverse dataset of 1,105 patients collected across
seven countries, achieving an AUROC of 0.903 and an F1-score of 0.851,
representing a new state of the art. Its computational efficiency enables
real-time, offline inference directly on common mobile devices, making it ideal
for low-resource settings. Importantly, the system produces clinically
validated explanations that promote trust and adoption by frontline health
workers. By coupling AI innovation with public-health requirements for speed,
affordability, and reliability, DeepGB-TB offers a tool for advancing global TB
control.

</details>


### [146] [Considering Spatial Structure of the Road Network in Pavement Deterioration Modeling](https://arxiv.org/abs/2508.02749)
*Lu Gao,Ke Yu,Pan Lu*

Main category: cs.LG

TL;DR: This research incorporated spatial dependence of road network into pavement deterioration modeling through a graph neural network (GNN).


<details>
  <summary>Details</summary>
Motivation: The key motivation of using a GNN for pavement performance modeling is the ability to easily and directly exploit the rich structural information in the network

Method: incorporated spatial dependence of road network into pavement deterioration modeling through a graph neural network (GNN)

Result: promising comparison results indicates that pavement deterioration prediction models perform better when spatial relationship is considered

Conclusion: pavement deterioration prediction models perform better when spatial relationship is considered

Abstract: Pavement deterioration modeling is important in providing information
regarding the future state of the road network and in determining the needs of
preventive maintenance or rehabilitation treatments. This research incorporated
spatial dependence of road network into pavement deterioration modeling through
a graph neural network (GNN). The key motivation of using a GNN for pavement
performance modeling is the ability to easily and directly exploit the rich
structural information in the network. This paper explored if considering
spatial structure of the road network will improve the prediction performance
of the deterioration models. The data used in this research comprises a large
pavement condition data set with more than a half million observations taken
from the Pavement Management Information System (PMIS) maintained by the Texas
Department of Transportation. The promising comparison results indicates that
pavement deterioration prediction models perform better when spatial
relationship is considered.

</details>


### [147] [Pulse Shape Discrimination Algorithms: Survey and Benchmark](https://arxiv.org/abs/2508.02750)
*Haoran Liu,Yihan Zhan,Mingzhe Liu,Yanhua Liu,Peng Li,Zhuo Zuo,Bingqi Liu,Runxi Liu*

Main category: cs.LG

TL;DR: 本研究对脉冲形状判别 (PSD) 算法进行了全面调查和基准测试，发现深度学习模型通常优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 本综述全面调查和评估了用于辐射检测的脉冲形状判别 (PSD) 算法。

Method: 实现了近六十种方法的分类，分为统计（时域、频域、基于神经网络）和先验知识（机器学习、深度学习）范例，并在两个标准化数据集上评估所有算法：来自 241Am-9Be 源的未标记集和来自 238Pu-9Be 源的飞行时间标记集，使用包括品质因数 (FOM)、F1 分数、ROC-AUC 和方法间相关性等指标。

Result: 我们的分析表明，深度学习模型，特别是多层感知器 (MLP) 和将统计特征与神经回归相结合的混合方法，通常优于传统方法。

Conclusion: 深度学习模型，特别是多层感知器 (MLP) 和将统计特征与神经回归相结合的混合方法，通常优于传统方法。我们讨论了架构适用性、FOM 的局限性、替代评估指标以及跨能量阈值的性能。

Abstract: This review presents a comprehensive survey and benchmark of pulse shape
discrimination (PSD) algorithms for radiation detection, classifying nearly
sixty methods into statistical (time-domain, frequency-domain, neural
network-based) and prior-knowledge (machine learning, deep learning) paradigms.
We implement and evaluate all algorithms on two standardized datasets: an
unlabeled set from a 241Am-9Be source and a time-of-flight labeled set from a
238Pu-9Be source, using metrics including Figure of Merit (FOM), F1-score,
ROC-AUC, and inter-method correlations. Our analysis reveals that deep learning
models, particularly Multi-Layer Perceptrons (MLPs) and hybrid approaches
combining statistical features with neural regression, often outperform
traditional methods. We discuss architectural suitabilities, the limitations of
FOM, alternative evaluation metrics, and performance across energy thresholds.
Accompanying this work, we release an open-source toolbox in Python and MATLAB,
along with the datasets, to promote reproducibility and advance PSD research.

</details>


### [148] [SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference](https://arxiv.org/abs/2508.02751)
*Yi Zhao,Yajuan Peng,Cam-Tu Nguyen,Zuchao Li,Xiaoliang Wang,Hai Zhao,Xiaoming Fu*

Main category: cs.LG

TL;DR: SmallKV通过小模型辅助补偿机制，解决了长文本场景下LLM的KV缓存驱逐问题，实现了更高的吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的token级别驱逐方法通常忽略了两个关键方面：(1)它们不可逆转的驱逐策略无法适应解码过程中动态的注意模式(显著性转移问题)；(2)它们平等地对待边缘重要token和真正不重要的token，尽管边缘token对模型性能具有集体重要性(边缘信息过度压缩问题)。

Method: 基于不同规模LLM之间注意力矩阵的高相似性，设计了两种补偿机制。提出了一种小型模型辅助的KV缓存压缩方法SmallKV。

Result: 在GSM8K、BBH、MT-Bench和LongBench等基准测试中进行了广泛的实验，证明了SmallKV的有效性。效率评估表明，SmallKV的吞吐量比基线方法高1.75 - 2.56倍。

Conclusion: SmallKV在资源受限的环境中，能够实现高效且高性能的LLM推理。

Abstract: KV cache eviction has emerged as an effective solution to alleviate resource
constraints faced by LLMs in long-context scenarios. However, existing
token-level eviction methods often overlook two critical aspects: (1) their
irreversible eviction strategy fails to adapt to dynamic attention patterns
during decoding (the saliency shift problem), and (2) they treat both
marginally important tokens and truly unimportant tokens equally, despite the
collective significance of marginal tokens to model performance (the marginal
information over-compression problem). To address these issues, we design two
compensation mechanisms based on the high similarity of attention matrices
between LLMs of different scales. We propose SmallKV, a small model assisted
compensation method for KV cache compression. SmallKV can maintain attention
matching between different-scale LLMs to: 1) assist the larger model in
perceiving globally important information of attention; and 2) use the smaller
model's attention scores to approximate those of marginal tokens in the larger
model. Extensive experiments on benchmarks including GSM8K, BBH, MT-Bench, and
LongBench demonstrate the effectiveness of SmallKV. Moreover, efficiency
evaluations show that SmallKV achieves 1.75 - 2.56 times higher throughput than
baseline methods, highlighting its potential for efficient and performant LLM
inference in resource constrained environments.

</details>


### [149] [DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting](https://arxiv.org/abs/2508.02753)
*Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan*

Main category: cs.LG

TL;DR: DMSC 是一种用于时间序列预测的新框架，它通过动态多尺度协调来解决现有方法的局限性，并在计算效率方面保持了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测方法在静态分解策略、碎片化的依赖性建模和不灵活的融合机制方面存在不足，限制了它们对复杂时间依赖性进行建模的能力。

Method: 动态多尺度协调框架 (DMSC)，具有多尺度补丁分解块 (EMPD)、三元交互块 (TIB) 和自适应尺度路由 MoE 块 (ASR-MoE)。

Result: 在 13 个真实世界基准上的综合实验表明，DMSC 始终保持最先进 (SOTA) 的性能和卓越的计算效率。

Conclusion: DMSC在时间序列预测任务中始终保持最先进 (SOTA) 的性能和卓越的计算效率。

Abstract: Time Series Forecasting (TSF) faces persistent challenges in modeling
intricate temporal dependencies across different scales. Despite recent
advances leveraging different decomposition operations and novel architectures
based on CNN, MLP or Transformer, existing methods still struggle with static
decomposition strategies, fragmented dependency modeling, and inflexible fusion
mechanisms, limiting their ability to model intricate temporal dependencies. To
explicitly solve the mentioned three problems respectively, we propose a novel
Dynamic Multi-Scale Coordination Framework (DMSC) with Multi-Scale Patch
Decomposition block (EMPD), Triad Interaction Block (TIB) and Adaptive Scale
Routing MoE block (ASR-MoE). Specifically, EMPD is designed as a built-in
component to dynamically segment sequences into hierarchical patches with
exponentially scaled granularities, eliminating predefined scale constraints
through input-adaptive patch adjustment. TIB then jointly models intra-patch,
inter-patch, and cross-variable dependencies within each layer's decomposed
representations. EMPD and TIB are jointly integrated into layers forming a
multi-layer progressive cascade architecture, where coarse-grained
representations from earlier layers adaptively guide fine-grained feature
extraction in subsequent layers via gated pathways. And ASR-MoE dynamically
fuses multi-scale predictions by leveraging specialized global and local
experts with temporal-aware weighting. Comprehensive experiments on thirteen
real-world benchmarks demonstrate that DMSC consistently maintains
state-of-the-art (SOTA) performance and superior computational efficiency for
TSF tasks. Code is available at https://github.com/1327679995/DMSC.

</details>


### [150] [Context-Adaptive Multi-Prompt LLM Embedding for Vision-Language Alignment](https://arxiv.org/abs/2508.02762)
*Dahun Kim,Anelia Angelova*

Main category: cs.LG

TL;DR: enrich semantic representations in vision-language contrastive learning by Context-Adaptive Multi-Prompt Embedding


<details>
  <summary>Details</summary>
Motivation: enrich semantic representations in vision-language contrastive learning. Unlike standard CLIP-style models that rely on a single text embedding

Method: Context-Adaptive Multi-Prompt Embedding, introduces multiple structured prompts, each containing a distinct adaptive token that captures diverse semantic aspects of the input text. We process all prompts jointly in a single forward pass. The resulting prompt embeddings are combined into a unified text representation

Result: enabling semantically richer alignment with visual features. To further promote semantic diversity and representation quality, we incorporate a diversity regularization loss and a negation-aware loss, encouraging specialization across prompts and improving contrastive discrimination

Conclusion: The proposed method achieves consistent improvements on both image-text and video-text retrieval benchmarks.

Abstract: We propose Context-Adaptive Multi-Prompt Embedding, a novel approach to
enrich semantic representations in vision-language contrastive learning. Unlike
standard CLIP-style models that rely on a single text embedding, our method
introduces multiple structured prompts, each containing a distinct adaptive
token that captures diverse semantic aspects of the input text. We process all
prompts jointly in a single forward pass. The resulting prompt embeddings are
combined into a unified text representation, enabling semantically richer
alignment with visual features. To further promote semantic diversity and
representation quality, we incorporate a diversity regularization loss and a
negation-aware loss, encouraging specialization across prompts and improving
contrastive discrimination. Our method achieves consistent improvements on both
image-text and video-text retrieval benchmarks.

</details>


### [151] [Synthetic medical data generation: state of the art and application to trauma mechanism classification](https://arxiv.org/abs/2508.02771)
*Océane Doremus,Ariel Guerra-Adames,Marta Avalos-Fernandez,Vianney Jouhet,Cédric Gil-Jardiné,Emmanuel Lagarde*

Main category: cs.LG

TL;DR: overview of machine learning methods for generating synthetic tabular and textual data in medical databases


<details>
  <summary>Details</summary>
Motivation: Faced with the challenges of patient confidentiality and scientific reproducibility, research on machine learning for health is turning towards the conception of synthetic medical databases.

Method: machine learning methods for generating synthetic tabular and textual data

Result: generating high-quality, synthetic medical records combining tabular and unstructured text data.

Conclusion: This article presents a brief overview of state-of-the-art machine learning methods for generating synthetic tabular and textual data, focusing their application to the automatic classification of trauma mechanisms, followed by our proposed methodology for generating high-quality, synthetic medical records combining tabular and unstructured text data.

Abstract: Faced with the challenges of patient confidentiality and scientific
reproducibility, research on machine learning for health is turning towards the
conception of synthetic medical databases. This article presents a brief
overview of state-of-the-art machine learning methods for generating synthetic
tabular and textual data, focusing their application to the automatic
classification of trauma mechanisms, followed by our proposed methodology for
generating high-quality, synthetic medical records combining tabular and
unstructured text data.

</details>


### [152] [Defending Against Knowledge Poisoning Attacks During Retrieval-Augmented Generation](https://arxiv.org/abs/2508.02835)
*Kennedy Edemacu,Vinay M. Shashidhar,Micheal Tuape,Dan Abudu,Beakcheol Jang,Jong Wook Kim*

Main category: cs.LG

TL;DR: This paper proposes methods to defend against knowledge poisoning attacks in Retrieval-Augmented Generation (RAG) systems.


<details>
  <summary>Details</summary>
Motivation: Retrieval-Augmented Generation (RAG) is vulnerable to knowledge poisoning attacks, such as PoisonedRAG, where attackers compromise the knowledge source to mislead the generation model.

Method: The paper introduces a new property to distinguish between adversarial and clean texts in the knowledge data source. This property is then used to filter out adversarial texts.

Result: The proposed defense methods, FilterRAG and ML-FilterRAG, demonstrate effectiveness against PoisonedRAG attacks, achieving performance close to original RAG systems on benchmark datasets.

Conclusion: The paper proposes FilterRAG and ML-FilterRAG to defend against PoisonedRAG attacks. These methods filter adversarial texts from clean ones using a novel property to differentiate them. Evaluation shows their effectiveness with performance close to original RAG systems.

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful approach to
boost the capabilities of large language models (LLMs) by incorporating
external, up-to-date knowledge sources. However, this introduces a potential
vulnerability to knowledge poisoning attacks, where attackers can compromise
the knowledge source to mislead the generation model. One such attack is the
PoisonedRAG in which the injected adversarial texts steer the model to generate
an attacker-chosen response to a target question. In this work, we propose
novel defense methods, FilterRAG and ML-FilterRAG, to mitigate the PoisonedRAG
attack. First, we propose a new property to uncover distinct properties to
differentiate between adversarial and clean texts in the knowledge data source.
Next, we employ this property to filter out adversarial texts from clean ones
in the design of our proposed approaches. Evaluation of these methods using
benchmark datasets demonstrate their effectiveness, with performances close to
those of the original RAG systems.

</details>


### [153] [Uncertainty Sets for Distributionally Robust Bandits Using Structural Equation Models](https://arxiv.org/abs/2508.02812)
*Katherine Avery,Chinmay Pendse,David Jensen*

Main category: cs.LG

TL;DR: 提出了一种基于结构方程模型的实用 bandit 评估和学习算法，该算法可以更准确地评估和学习低方差策略。


<details>
  <summary>Details</summary>
Motivation: 当前的分布鲁棒评估和学习方法会产生过于保守的评估和策略。

Method: 提出了一种实用的 bandit 评估和学习算法，该算法使用受结构方程模型约束的数学程序为特定问题定制不确定性集。

Result: 结构方程模型 (SEM) 方法比传统方法提供更准确的评估，并学习更低方差的策略，尤其是在大型转移中。此外，假设模型充分明确，SEM 方法可以学习最优策略。

Conclusion: SEM 方法在大型转移中比传统方法提供更准确的评估，并学习更低方差的策略。假设模型充分明确，SEM 方法可以学习最优策略。

Abstract: Distributionally robust evaluation estimates the worst-case expected return
over an uncertainty set of possible covariate and reward distributions, and
distributionally robust learning finds a policy that maximizes that worst-case
return across that uncertainty set. Unfortunately, current methods for
distributionally robust evaluation and learning create overly conservative
evaluations and policies. In this work, we propose a practical bandit
evaluation and learning algorithm that tailors the uncertainty set to specific
problems using mathematical programs constrained by structural equation models.
Further, we show how conditional independence testing can be used to detect
shifted variables for modeling. We find that the structural equation model
(SEM) approach gives more accurate evaluations and learns lower-variance
policies than traditional approaches, particularly for large shifts. Further,
the SEM approach learns an optimal policy, assuming the model is sufficiently
well-specified.

</details>


### [154] [On the Theory and Practice of GRPO: A Trajectory-Corrected Approach with Fast Convergence](https://arxiv.org/abs/2508.02833)
*Lei Pang,Ruinan Jin*

Main category: cs.LG

TL;DR: GRPO更新规则实际上估计的是旧策略而不是当前策略的策略梯度。


<details>
  <summary>Details</summary>
Motivation: DeepSeek最近提出的Group Relative Policy Optimization (GRPO)是一种用于微调大型语言模型的无批评强化学习算法。它用组归一化奖励代替近端策略优化(PPO)中的价值函数，同时保留基于旧策略的PPO风格的令牌级重要性抽样。我们表明，GRPO更新规则实际上估计的是旧策略而不是当前策略的策略梯度。然而，由于旧策略每隔几个步骤就会刷新一次，因此两者之间的差异仍然很小，从而限制了这种偏差在实践中的影响。我们通过一项消融研究验证了这一点，在该研究中，重要性抽样被完全移除，而是使用在多个优化步骤中以固定的旧策略估计的梯度执行更新。值得注意的是，这种简化导致了与标准GRPO相当的性能。

Method: 提出了一种新的算法:轨迹水平重要性校正GRPO(TIC GRPO)

Result: 这种简化导致了与标准GRPO相当的性能

Conclusion: 提出了一个新的算法:轨迹水平重要性校正GRPO(TIC GRPO)。TIC GRPO用单个轨迹水平概率比代替了令牌水平重要性比率，从而在保留无批评者结构的同时，产生了当前策略梯度的无偏估计。此外，我们首次对GRPO风格的方法进行了理论收敛性分析，包括原始GRPO和我们提出的变体。

Abstract: Group Relative Policy Optimization (GRPO), recently proposed by DeepSeek, is
a critic-free reinforcement learning algorithm for fine tuning large language
models. It replaces the value function in Proximal Policy Optimization (PPO)
with group normalized rewards, while retaining PPO style token level importance
sampling based on an old policy. We show that GRPO update rule in fact
estimates the policy gradient at the old policy rather than the current one.
However, since the old policy is refreshed every few steps, the discrepancy
between the two remains small limiting the impact of this bias in practice. We
validate this through an ablation study in which importance sampling is
entirely removed, and updates are instead performed using the gradient
estimated at a fixed old policy across multiple optimization steps. Remarkably,
this simplification results in performance comparable to standard GRPO.
  Motivated by these findings, we propose a new algorithm: Trajectory level
Importance Corrected GRPO (TIC GRPO). TIC GRPO replaces token level importance
ratios with a single trajectory level probability ratio, yielding an unbiased
estimate of the current policy gradient while preserving the critic free
structure. Furthermore, we present the first theoretical convergence analysis
for GRPO style methods, covering both the original GRPO and our proposed
variant.

</details>


### [155] [Learning from B Cell Evolution: Adaptive Multi-Expert Diffusion for Antibody Design via Online Optimization](https://arxiv.org/abs/2508.02834)
*Hanqi Feng,Peng Qiu,Mengchun Zhang,Yiran Tao,You Fan,Jingtao Xu,Barnabas Poczos*

Main category: cs.LG

TL;DR: 该论文提出了一种受 B 细胞亲和力成熟启发的抗体设计框架，该框架利用物理学知识和在线元学习，通过多目标优化来发现针对每个抗原的个性化策略，从而提高抗体质量和设计效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法应用统一的生成策略，无法适应每种抗原的独特需求。受 B 细胞亲和力成熟的启发，抗体通过平衡亲和力、稳定性和自我避免的多目标优化而进化。

Method: 该方法利用在线元学习系统中的基于物理的领域知识，采用多个专业专家（范德华力、分子识别、能量平衡和界面几何），这些专家的参数在基于迭代反馈的生成过程中演变，模仿自然抗体精炼周期。

Result: 该方法：（1）为不同的抗原类别发现最佳的 SE(3)-等变引导策略，无需预训练，在整个优化过程中保持分子对称性；（2）通过靶标特异性适应，显著提高热点覆盖率和界面质量，实现治疗性抗体的平衡多目标优化；（3）为迭代改进建立了一个范例，其中每个抗体-抗原系统通过在线评估学习其独特的优化配置文件；（4）在不同的设计挑战中有效地推广，从小的抗原表位到大的蛋白质界面，为个体目标实现精确聚焦的活动。

Conclusion: 该方法通过在线评估为每个抗体-抗原系统学习其独特的优化配置文件，并在不同的设计挑战中有效地推广，从小的抗原表位到大的蛋白质界面，为个体目标实现精确聚焦的活动。

Abstract: Recent advances in diffusion models have shown remarkable potential for
antibody design, yet existing approaches apply uniform generation strategies
that cannot adapt to each antigen's unique requirements. Inspired by B cell
affinity maturation, where antibodies evolve through multi-objective
optimization balancing affinity, stability, and self-avoidance, we propose the
first biologically-motivated framework that leverages physics-based domain
knowledge within an online meta-learning system. Our method employs multiple
specialized experts (van der Waals, molecular recognition, energy balance, and
interface geometry) whose parameters evolve during generation based on
iterative feedback, mimicking natural antibody refinement cycles. Instead of
fixed protocols, this adaptive guidance discovers personalized optimization
strategies for each target. Our experiments demonstrate that this approach: (1)
discovers optimal SE(3)-equivariant guidance strategies for different antigen
classes without pre-training, preserving molecular symmetries throughout
optimization; (2) significantly enhances hotspot coverage and interface quality
through target-specific adaptation, achieving balanced multi-objective
optimization characteristic of therapeutic antibodies; (3) establishes a
paradigm for iterative refinement where each antibody-antigen system learns its
unique optimization profile through online evaluation; (4) generalizes
effectively across diverse design challenges, from small epitopes to large
protein interfaces, enabling precision-focused campaigns for individual
targets.

</details>


### [156] [Resource-Efficient Automatic Software Vulnerability Assessment via Knowledge Distillation and Particle Swarm Optimization](https://arxiv.org/abs/2508.02840)
*Chaoyang Gao,Xiang Chen,Jiyu Wang,Jibin Wang,Guang Yang*

Main category: cs.LG

TL;DR: A resource-efficient framework that integrates knowledge distillation and particle swarm optimization to enable automated vulnerability assessment.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of software systems has led to a surge in cybersecurity vulnerabilities, necessitating efficient and scalable solutions for vulnerability assessment. However, the deployment of large pre-trained models in real-world scenarios is hindered by their substantial computational and storage demands.

Method: integrates knowledge distillation and particle swarm optimization to enable automated vulnerability assessment. Our framework employs a two-stage approach: First, particle swarm optimization is utilized to optimize the architecture of a compact student model, balancing computational efficiency and model capacity. Second, knowledge distillation is applied to transfer critical vulnerability assessment knowledge from a large teacher model to the optimized student model.

Result: achieves a 99.4% reduction in model size while retaining 89.3% of the original model's accuracy. Furthermore, it outperforms state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The framework also reduces training time by 72.1% and architecture search time by 34.88% compared to traditional genetic algorithms.

Conclusion: The proposed framework achieves a 99.4% reduction in model size while retaining 89.3% of the original model's accuracy. Furthermore, it outperforms state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The framework also reduces training time by 72.1% and architecture search time by 34.88% compared to traditional genetic algorithms.

Abstract: The increasing complexity of software systems has led to a surge in
cybersecurity vulnerabilities, necessitating efficient and scalable solutions
for vulnerability assessment. However, the deployment of large pre-trained
models in real-world scenarios is hindered by their substantial computational
and storage demands. To address this challenge, we propose a novel
resource-efficient framework that integrates knowledge distillation and
particle swarm optimization to enable automated vulnerability assessment. Our
framework employs a two-stage approach: First, particle swarm optimization is
utilized to optimize the architecture of a compact student model, balancing
computational efficiency and model capacity. Second, knowledge distillation is
applied to transfer critical vulnerability assessment knowledge from a large
teacher model to the optimized student model. This process significantly
reduces the model size while maintaining high performance. Experimental results
on an enhanced MegaVul dataset, comprising 12,071 CVSS (Common Vulnerability
Scoring System) v3 annotated vulnerabilities, demonstrate the effectiveness of
our approach. Our approach achieves a 99.4% reduction in model size while
retaining 89.3% of the original model's accuracy. Furthermore, it outperforms
state-of-the-art baselines by 1.7% in accuracy with 60% fewer parameters. The
framework also reduces training time by 72.1% and architecture search time by
34.88% compared to traditional genetic algorithms.

</details>


### [157] [Comparative Evaluation of Kolmogorov-Arnold Autoencoders and Orthogonal Autoencoders for Fault Detection with Varying Training Set Sizes](https://arxiv.org/abs/2508.02860)
*Enrique Luna Villagómez,Vladimir Mahalec*

Main category: cs.LG

TL;DR: KAN-AEs are data-efficient and effective for unsupervised fault detection in chemical processes, with WavKAN and EfficientKAN variants performing particularly well.


<details>
  <summary>Details</summary>
Motivation: Explore the utility of KANs in unsupervised fault detection, an area largely unexplored despite their promise in supervised settings.

Method: Comparative evaluation of four KAN-AE variants (EfficientKAN, FastKAN, FourierKAN, and WavKAN) against an Orthogonal Autoencoder (OAE) on the Tennessee Eastman Process.

Result: WavKAN-AE achieves the highest overall FDR (≥92%) with 4,000 training samples. EfficientKAN-AE reaches ≥90% FDR with 500 samples. FastKAN-AE becomes competitive at larger scales (≥50,000 samples), while FourierKAN-AE underperforms. OAE requires substantially more data to match top KAN-AE performance.

Conclusion: KAN-AEs combine data efficiency with strong fault detection performance and potential for improved model transparency, making them promising for data-constrained industrial settings.

Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a flexible and
parameter-efficient alternative to conventional neural networks. Unlike
standard architectures that use fixed node-based activations, KANs place
learnable functions on edges, parameterized by different function families.
While they have shown promise in supervised settings, their utility in
unsupervised fault detection remains largely unexplored. This study presents a
comparative evaluation of KAN-based autoencoders (KAN-AEs) for unsupervised
fault detection in chemical processes. We investigate four KAN-AE variants,
each based on a different KAN implementation (EfficientKAN, FastKAN,
FourierKAN, and WavKAN), and benchmark them against an Orthogonal Autoencoder
(OAE) on the Tennessee Eastman Process. Models are trained on normal operating
data across 13 training set sizes and evaluated on 21 fault types, using Fault
Detection Rate (FDR) as the performance metric. WavKAN-AE achieves the highest
overall FDR ($\geq$92\%) using just 4,000 training samples and remains the top
performer, even as other variants are trained on larger datasets.
EfficientKAN-AE reaches $\geq$90\% FDR with only 500 samples, demonstrating
robustness in low-data settings. FastKAN-AE becomes competitive at larger
scales ($\geq$50,000 samples), while FourierKAN-AE consistently underperforms.
The OAE baseline improves gradually but requires substantially more data to
match top KAN-AE performance. These results highlight the ability of KAN-AEs to
combine data efficiency with strong fault detection performance. Their use of
structured basis functions suggests potential for improved model transparency,
making them promising candidates for deployment in data-constrained industrial
settings.

</details>


### [158] [Beyond Least Squares: Robust Regression Transformer (R2T)](https://arxiv.org/abs/2508.02874)
*Roman Gutierrez,Tony Kai Tang,Isabel Gutierrez*

Main category: cs.LG

TL;DR: 提出了一种混合神经符号架构，用于在非对称结构化噪声下进行鲁棒回归，并在合成可穿戴设备数据上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 稳健回归技术依赖于最小二乘优化，该优化在存在高斯噪声时效果良好，但在存在不对称结构化噪声时会失效。

Method: 一种混合神经符号架构，其中 Transformer 编码器处理数值序列，压缩 NN 预测符号参数，固定符号方程重建原始序列。

Result: 该模型在合成数据上，经过添加非对称结构噪声后，训练目标是恢复原始序列，从而有效地学习由神经参数估计引导的符号拟合。

Conclusion: 该模型在合成可穿戴设备数据上实现了 6e-6 到 3.5e-5 的中值回归 MSE，与普通最小二乘法和 Huber 损失或 SoftL1 等稳健回归技术相比，提高了 10-300 倍。

Abstract: Robust regression techniques rely on least-squares optimization, which works
well for Gaussian noise but fails in the presence of asymmetric structured
noise. We propose a hybrid neural-symbolic architecture where a transformer
encoder processes numerical sequences, a compression NN predicts symbolic
parameters, and a fixed symbolic equation reconstructs the original sequence.
Using synthetic data, the training objective is to recover the original
sequence after adding asymmetric structured noise, effectively learning a
symbolic fit guided by neural parameter estimation. Our model achieves a median
regression MSE of 6e-6 to 3.5e-5 on synthetic wearable data, which is a 10-300
times improvement when compared with ordinary least squares fit and robust
regression techniques such as Huber loss or SoftL1.

</details>


### [159] [CauKer: classification time series foundation models can be pretrained on synthetic data only](https://arxiv.org/abs/2508.02879)
*Shifeng Xie,Vasilii Feofanov,Marius Alonso,Ambroise Odonnat,Jianfeng Zhang,Themis Palpanas,Ievgen Redko*

Main category: cs.LG

TL;DR: CauKer: a novel algorithm designed to generate diverse, causally coherent synthetic time series with realistic trends, seasonality, and nonlinear interactions for sample-efficient pretraining of TSFMs.


<details>
  <summary>Details</summary>
Motivation: To allow for a sample-efficient pretraining of TSFMs.

Method: CauKer combines Gaussian Process (GP) kernel composition with Structural Causal Models (SCM) to produce data for sample-efficient pretraining of state-of-the-art classification TSFMs having different architectures and following different pretraining approaches.

Result: CauKer enables sample-efficient pretraining of state-of-the-art classification TSFMs.

Conclusion: CauKer-generated datasets exhibit clear scaling laws for both dataset size (10K to 10M samples) and model capacity (1M to 783M parameters), unlike real-world datasets, which display irregular scaling behavior.

Abstract: Time series foundation models (TSFMs) have recently gained significant
attention due to their strong zero-shot capabilities and widespread real-world
applications. Such models typically require a computationally costly
pretraining on large-scale, carefully curated collections of real-world
sequences. To allow for a sample-efficient pretraining of TSFMs, we propose
CauKer, a novel algorithm designed to generate diverse, causally coherent
synthetic time series with realistic trends, seasonality, and nonlinear
interactions. CauKer combines Gaussian Process (GP) kernel composition with
Structural Causal Models (SCM) to produce data for sample-efficient pretraining
of state-of-the-art classification TSFMs having different architectures and
following different pretraining approaches. Additionally, our experiments
reveal that CauKer-generated datasets exhibit clear scaling laws for both
dataset size (10K to 10M samples) and model capacity (1M to 783M parameters),
unlike real-world datasets, which display irregular scaling behavior.

</details>


### [160] [Neural Networks with Orthogonal Jacobian](https://arxiv.org/abs/2508.02882)
*Alex Massucco,Davide Murari,Carola-Bibiane Schönlieb*

Main category: cs.LG

TL;DR: 介绍了具有完美动态等距和高效训练的深度神经网络。


<details>
  <summary>Details</summary>
Motivation: 通过反向传播训练非常深的神经网络通常会受到梯度消失或爆炸的阻碍。现有的补救措施，如正交或方差保持初始化和残差架构，允许更稳定的梯度传播和更深模型的训练。

Method: 引入了一个统一的数学框架，该框架描述了广泛的非线性前馈和残差网络，这些网络的输入到输出雅可比矩阵几乎在所有地方都是完全正交的。

Result: 完美雅可比正交性在初始化时足以稳定训练并获得有竞争力的性能。将其与正则化为保持雅可比正交性的网络进行比较，并获得相当的结果。此外，将分析扩展到一类可以用正交雅可比矩阵很好地近似的网络，并引入具有表示部分等距的雅可比矩阵的网络。然后证明这些广义模型可以保持良好的可训练性。

Conclusion: 雅可比正交性足以稳定训练并获得有竞争力的性能。将这种策略与正则化网络进行比较，以保持雅可比正交性并获得相当的结果。将分析扩展到一类可以用正交雅可比矩阵的网络很好地近似的网络，并引入具有表示部分等距的雅可比矩阵的网络。这些广义模型随后被证明可以保持良好的可训练性。

Abstract: Very deep neural networks achieve state-of-the-art performance by extracting
rich, hierarchical features. Yet, training them via backpropagation is often
hindered by vanishing or exploding gradients. Existing remedies, such as
orthogonal or variance-preserving initialisation and residual architectures,
allow for a more stable gradient propagation and the training of deeper models.
In this work, we introduce a unified mathematical framework that describes a
broad class of nonlinear feedforward and residual networks, whose
input-to-output Jacobian matrices are exactly orthogonal almost everywhere.
Such a constraint forces the resulting networks to achieve perfect dynamical
isometry and train efficiently despite being very deep. Our formulation not
only recovers standard architectures as particular cases but also yields new
designs that match the trainability of residual networks without relying on
conventional skip connections. We provide experimental evidence that perfect
Jacobian orthogonality at initialisation is sufficient to stabilise training
and achieve competitive performance. We compare this strategy to networks
regularised to maintain the Jacobian orthogonality and obtain comparable
results. We further extend our analysis to a class of networks
well-approximated by those with orthogonal Jacobians and introduce networks
with Jacobians representing partial isometries. These generalized models are
then showed to maintain the favourable trainability properties.

</details>


### [161] [Physics-Embedded Neural ODEs for Sim2Real Edge Digital Twins of Hybrid Power Electronics Systems](https://arxiv.org/abs/2508.02887)
*Jialin Zheng,Haoyu Wang,Yangbin Zeng,Di Mou,Xin Zhang,Hong Li,Sergio Vazquez,Leopoldo G. Franquelo*

Main category: cs.LG

TL;DR: 本文提出了一种物理嵌入神经 ODE (PENODE)，用于提高电力电子系统边缘数字孪生的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 边缘数字孪生 (EDT) 对于电力电子系统 (PES) 的监控至关重要。然而，现有的建模方法难以持续捕捉 PES 中固有的不断演变的混合动力学，从而降低了资源受限的边缘设备上的 Sim-to-Real 泛化能力。

Method: 本文提出了一种物理嵌入神经 ODE (PENODE)，它 (i) 嵌入混合操作机制作为事件自动机，以显式地控制离散切换，并且 (ii) 将已知的控制 ODE 分量直接注入到未建模动力学的神经参数化中。

Result: PENODE 在白盒、灰盒和黑盒场景的基准测试中实现了明显更高的精度，神经元数量减少了 75%。

Conclusion: PENODE在白盒、灰盒和黑盒场景的基准测试中实现了更高的精度，神经元数量减少了 75%，验证了所提出的 PENODE 保持了物理可解释性、高效的边缘部署和实时控制增强。

Abstract: Edge Digital Twins (EDTs) are crucial for monitoring and control of Power
Electronics Systems (PES). However, existing modeling approaches struggle to
consistently capture continuously evolving hybrid dynamics that are inherent in
PES, degrading Sim-to-Real generalization on resource-constrained edge devices.
To address these challenges, this paper proposes a Physics-Embedded Neural ODEs
(PENODE) that (i) embeds the hybrid operating mechanism as an event automaton
to explicitly govern discrete switching and (ii) injects known governing ODE
components directly into the neural parameterization of unmodeled dynamics.
This unified design yields a differentiable end-to-end trainable architecture
that preserves physical interpretability while reducing redundancy, and it
supports a cloud-to-edge toolchain for efficient FPGA deployment. Experimental
results demonstrate that PENODE achieves significantly higher accuracy in
benchmarks in white-box, gray-box, and black-box scenarios, with a 75%
reduction in neuron count, validating that the proposed PENODE maintains
physical interpretability, efficient edge deployment, and real-time control
enhancement.

</details>


### [162] [Clus-UCB: A Near-Optimal Algorithm for Clustered Bandits](https://arxiv.org/abs/2508.02909)
*Aakash Gore,Prasanna Chaporkar*

Main category: cs.LG

TL;DR: 本文研究了一个具有集群结构的随机 multi-armed bandit setting，提出了一种名为 Clus-UCB 的高效算法，并导出了关于遗憾的渐近下界。


<details>
  <summary>Details</summary>
Motivation: 本文研究了一个随机 multi-armed bandit setting，其中 arms 被划分为已知的集群，因此一个集群内的 arm 的平均奖励最多相差一个已知的阈值。

Method: 该论文提出了一种名为 Clus-UCB 的高效算法，该算法旨在利用聚类结构，并引入了一个新的指标来评估一个 arm，该指标取决于集群中的其他 arm。

Result: 推导了关于遗憾的渐近下界，该下界改进了 Lai & Robbins (1985) 的经典界限。Clus-UCB 算法在渐近线上与这个下界非常吻合。模拟结果表明，该算法的性能优于 KL-UCB 和其他众所周知的 dependent arms bandits 算法。

Conclusion: 这篇论文总结了研究的局限性，并提出了未来可能的研究方向。

Abstract: We study a stochastic multi-armed bandit setting where arms are partitioned
into known clusters, such that the mean rewards of arms within a cluster differ
by at most a known threshold. While the clustering structure is known a priori,
the arm means are unknown. This framework models scenarios where outcomes
depend on multiple factors -- some with significant and others with minor
influence -- such as online advertising, clinical trials, and wireless
communication. We derive asymptotic lower bounds on the regret that improve
upon the classical bound of Lai & Robbins (1985). We then propose Clus-UCB, an
efficient algorithm that closely matches this lower bound asymptotically.
Clus-UCB is designed to exploit the clustering structure and introduces a new
index to evaluate an arm, which depends on other arms within the cluster. In
this way, arms share information among each other. We present simulation
results of our algorithm and compare its performance against KL-UCB and other
well-known algorithms for bandits with dependent arms. Finally, we address some
limitations of this work and conclude by mentioning possible future research.

</details>


### [163] [Neural Approximators for Low-Thrust Trajectory Transfer Cost and Reachability](https://arxiv.org/abs/2508.02911)
*Zhong Zhang,Francesco Topputo*

Main category: cs.LG

TL;DR: 这篇论文提出了一种通用的预训练神经网络，用于预测低推力任务的燃料消耗和轨迹可达性，并在各种任务场景中验证了其泛化能力、预测准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 在轨道设计中，燃料消耗和轨迹可达性是低推力任务的两个关键性能指标。

Method: 该论文提出了一种通用的预训练神经网络来预测低推力任务的燃料消耗和轨迹可达性指标。该方法基于适用于低推力轨迹逼近的标度律，并使用同伦射线法构建了最大的数据集。数据被转换成自相似空间，使神经网络能够适应任意的半长轴、倾角和中心体。

Result: 该神经网络在预测速度增量方面的相对误差为0.78%，在最小传输时间估计方面的相对误差为0.63%。

Conclusion: 这篇论文提出了目前最通用、最准确的低推力轨道逼近器，其预测速度增量的相对误差为0.78%，最小传输时间估计的相对误差为0.63%。该模型已在第三方数据集、多飞行任务设计问题和任务分析场景中得到验证。

Abstract: In trajectory design, fuel consumption and trajectory reachability are two
key performance indicators for low-thrust missions. This paper proposes
general-purpose pretrained neural networks to predict these metrics. The
contributions of this paper are as follows: Firstly, based on the confirmation
of the Scaling Law applicable to low-thrust trajectory approximation, the
largest dataset is constructed using the proposed homotopy ray method, which
aligns with mission-design-oriented data requirements. Secondly, the data are
transformed into a self-similar space, enabling the neural network to adapt to
arbitrary semi-major axes, inclinations, and central bodies. This extends the
applicability beyond existing studies and can generalize across diverse mission
scenarios without retraining. Thirdly, to the best of our knowledge, this work
presents the current most general and accurate low-thrust trajectory
approximator, with implementations available in C++, Python, and MATLAB. The
resulting neural network achieves a relative error of 0.78% in predicting
velocity increments and 0.63% in minimum transfer time estimation. The models
have also been validated on a third-party dataset, multi-flyby mission design
problem, and mission analysis scenario, demonstrating their generalization
capability, predictive accuracy, and computational efficiency.

</details>


### [164] [BoostTransformer: Enhancing Transformer Models with Subgrid Selection and Importance Sampling](https://arxiv.org/abs/2508.02924)
*Biyi Fang,Jean Utke,Truong Vo,Diego Klabjan*

Main category: cs.LG

TL;DR: BoostTransformer通过boosting原则增强了transformers，实现了更高效的训练和更高的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在现代NLP中占据主导地位，但通常需要大量的计算资源和复杂的超参数调整。为了缓解这些挑战。

Method: 通过子网格令牌选择和重要性加权采样，使用boosting原则来增强transformers。

Result: BoostTransformer展示了更快的收敛速度和更高的准确率。

Conclusion: BoostTransformer在多个细粒度文本分类基准测试中表现出更快的收敛速度和更高的准确率，超过了标准transformers，同时最大限度地减少了架构搜索开销。

Abstract: Transformer architectures dominate modern NLP but often demand heavy
computational resources and intricate hyperparameter tuning. To mitigate these
challenges, we propose a novel framework, BoostTransformer, that augments
transformers with boosting principles through subgrid token selection and
importance-weighted sampling. Our method incorporates a least square boosting
objective directly into the transformer pipeline, enabling more efficient
training and improved performance. Across multiple fine-grained text
classification benchmarks, BoostTransformer demonstrates both faster
convergence and higher accuracy, surpassing standard transformers while
minimizing architectural search overhead.

</details>


### [165] [GrandJury: A Collaborative Machine Learning Model Evaluation Protocol for Dynamic Quality Rubrics](https://arxiv.org/abs/2508.02926)
*Arthur Cho*

Main category: cs.LG

TL;DR: GrandJury introduces a new evaluation protocol for machine learning outputs, addressing the limitations of static benchmarks by incorporating dynamic user needs and evolving realities.


<details>
  <summary>Details</summary>
Motivation: standard evaluation regimes still rely on static, benchmark-style tests, incentivizing optimization toward leaderboard scores rather than alignment with dynamic user needs or evolving realities

Method: a formal evaluation protocol combining time-decayed aggregation, complete traceability, with the support of dynamic, transparent task rubric attribution, and multi-rater human judgment

Result: enable pluralistic, accountable evaluation that captures evolving consensus and surfaces disagreement. We provide an open-source implementation (grandjury PyPI package) and a public collection of Large Language Model (LLM) inference outputs to illustrate the need and method.

Conclusion: GrandJury provides a new paradigm for AI practitioners when evaluating machine learning outputs without absolute ground truth.

Abstract: Generative Machine Learning models have become central to modern systems,
powering applications in creative writing, summarization, multi-hop reasoning,
and context-aware dialogue. These models underpin large-scale AI assistants,
workflow automation, and autonomous decision-making. In such domains,
acceptable response is rarely absolute or static, but plural and highly
context-dependent. Yet standard evaluation regimes still rely on static,
benchmark-style tests, incentivizing optimization toward leaderboard scores
rather than alignment with dynamic user needs or evolving realities. GrandJury
introduces a formal evaluation protocol combining time-decayed aggregation,
complete traceability, with the support of dynamic, transparent task rubric
attribution, and multi-rater human judgment. Together, these elements enable
pluralistic, accountable evaluation that captures evolving consensus and
surfaces disagreement. We provide an open-source implementation (grandjury PyPI
package) and a public collection of Large Language Model (LLM) inference
outputs to illustrate the need and method. GrandJury provides a new paradigm
for AI practitioners when evaluating machine learning outputs without absolute
ground truth.

</details>


### [166] [PLoRA: Efficient LoRA Hyperparameter Tuning for Large Models](https://arxiv.org/abs/2508.02932)
*Minghao Yan,Zhuang Wang,Zhen Jia,Shivaram Venkataraman,Yida Wang*

Main category: cs.LG

TL;DR: PLoRA improves LoRA fine-tuning efficiency by orchestrating concurrent jobs and developing performant kernels.


<details>
  <summary>Details</summary>
Motivation: Current training paradigms do not utilize hardware resources efficiently and require high overhead to obtain a performant LoRA.

Method: PLoRA automatically orchestrates concurrent LoRA fine-tuning jobs and develops performant kernels.

Result: PLoRA reduces the makespan of LoRA fine-tuning over a given hyperparameter search space by up to 7.52x and improves training throughput by up to 12.8x.

Conclusion: PLoRA reduces the makespan of LoRA fine-tuning and improves training throughput.

Abstract: Low-rank Adaptation (LoRA) has gained popularity as a fine-tuning approach
for Large Language Models (LLMs) due to its low resource requirements and good
performance. While a plethora of work has investigated improving LoRA serving
efficiency by serving multiple LoRAs concurrently, existing methods assume that
a wide range of LoRA adapters are available for serving. In our work, we
conduct extensive empirical studies to identify that current training paradigms
do not utilize hardware resources efficiently and require high overhead to
obtain a performant LoRA. Leveraging these insights, we propose PLoRA, which
automatically orchestrates concurrent LoRA fine-tuning jobs under given
hardware and model constraints and develops performant kernels to improve
training efficiency. Our experimental studies show that PLoRA reduces the
makespan of LoRA fine-tuning over a given hyperparameter search space by up to
7.52x and improves training throughput by up to 12.8x across a range of
state-of-the-art LLMs.

</details>


### [167] [Online Robust Multi-Agent Reinforcement Learning under Model Uncertainties](https://arxiv.org/abs/2508.02948)
*Zain Ulabedeen Farhat,Debamita Ghosh,George K. Atia,Yue Wang*

Main category: cs.LG

TL;DR: 该论文研究了在线DRMGs学习，提出了RONAVI算法，并提供了首个理论保证，为开发真正鲁棒的多智能体系统建立了一条新的实用路径。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在实际部署中会因训练和部署环境的模型失配而失效，这种失配是由噪声或对抗攻击等环境不确定性引起的。Distributionally Robust Markov Games (DRMGs) 通过优化定义的环境不确定性集合上的最坏情况性能来增强系统弹性。然而，当前的方法依赖于模拟器或大型离线数据集，而这些通常是不可用的。

Method: 提出Robust Optimistic Nash Value Iteration (RONAVI)算法。

Result: 该算法实现了低遗憾值，并有效地找到了不确定性集合（通过Total Variation divergence和Kullback-Leibler divergence测量）的最优鲁棒策略。

Conclusion: 该论文为在线DRMGs学习提供首个理论保证，证明了RONAVI算法在Total Variation divergence和Kullback-Leibler divergence下能实现低遗憾值并高效找到最优鲁棒策略。

Abstract: Well-trained multi-agent systems can fail when deployed in real-world
environments due to model mismatches between the training and deployment
environments, caused by environment uncertainties including noise or
adversarial attacks. Distributionally Robust Markov Games (DRMGs) enhance
system resilience by optimizing for worst-case performance over a defined set
of environmental uncertainties. However, current methods are limited by their
dependence on simulators or large offline datasets, which are often
unavailable. This paper pioneers the study of online learning in DRMGs, where
agents learn directly from environmental interactions without prior data. We
introduce the {\it Robust Optimistic Nash Value Iteration (RONAVI)} algorithm
and provide the first provable guarantees for this setting. Our theoretical
analysis demonstrates that the algorithm achieves low regret and efficiently
finds the optimal robust policy for uncertainty sets measured by Total
Variation divergence and Kullback-Leibler divergence. These results establish a
new, practical path toward developing truly robust multi-agent systems.

</details>


### [168] [Injecting Measurement Information Yields a Fast and Noise-Robust Diffusion-Based Inverse Problem Solver](https://arxiv.org/abs/2508.02964)
*Jonathan Patsenker,Henry Li,Myeongseob Ko,Ruoxi Jia,Yuval Kluger*

Main category: cs.LG

TL;DR: 提出估计条件后验均值 E [x_0 | x_t, y]，它可以被表述为轻量级的单参数最大似然估计问题的解，从而产生快速且内存高效的逆求解器。


<details>
  <summary>Details</summary>
Motivation: 扩散模型已牢固地确立为线性和非线性逆问题的有原则的零样本求解器，这归功于其强大的图像先验和迭代采样算法。这些方法通常依赖于 Tweedie 公式，该公式将扩散变量 x_t 与后验均值 E [x_0 | x_t] 相关联，以便通过最终去噪样本 x_0 的估计来指导扩散轨迹。但是，这没有考虑来自测量 y 的信息，然后必须将其下游集成。

Method: 我们建议估计条件后验均值 E [x_0 | x_t, y]，它可以被表述为轻量级的单参数最大似然估计问题的解。

Result: 由此产生的预测可以集成到任何标准采样器中，从而产生快速且内存高效的逆求解器。

Conclusion: 该优化器适用于对 y 中测量噪声具有鲁棒性的、基于噪声感知似然的停止标准。我们证明了在多个数据集和任务中，针对各种当代逆求解器，具有可比或改进的性能。

Abstract: Diffusion models have been firmly established as principled zero-shot solvers
for linear and nonlinear inverse problems, owing to their powerful image prior
and iterative sampling algorithm. These approaches often rely on Tweedie's
formula, which relates the diffusion variate $\mathbf{x}_t$ to the posterior
mean $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t]$, in order to guide the
diffusion trajectory with an estimate of the final denoised sample
$\mathbf{x}_0$. However, this does not consider information from the
measurement $\mathbf{y}$, which must then be integrated downstream. In this
work, we propose to estimate the conditional posterior mean $\mathbb{E}
[\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$, which can be formulated as the
solution to a lightweight, single-parameter maximum likelihood estimation
problem. The resulting prediction can be integrated into any standard sampler,
resulting in a fast and memory-efficient inverse solver. Our optimizer is
amenable to a noise-aware likelihood-based stopping criteria that is robust to
measurement noise in $\mathbf{y}$. We demonstrate comparable or improved
performance against a wide selection of contemporary inverse solvers across
multiple datasets and tasks.

</details>


### [169] [Scalable Varied-Density Clustering via Graph Propagation](https://arxiv.org/abs/2508.02989)
*Ninh Pham,Yingtao Zheng,Hugo Phibbs*

Main category: cs.LG

TL;DR: Density-based clustering via efficient graph propagation techniques.


<details>
  <summary>Details</summary>
Motivation: varied-density clustering for high-dimensional data

Method: a label propagation process in neighborhood graphs that adapt to local density variations

Result: significantly reduces computational cost while preserving clustering quality

Conclusion: The proposed method scales to datasets with millions of points in minutes and achieves competitive accuracy compared to existing baselines.

Abstract: We propose a novel perspective on varied-density clustering for
high-dimensional data by framing it as a label propagation process in
neighborhood graphs that adapt to local density variations. Our method formally
connects density-based clustering with graph connectivity, enabling the use of
efficient graph propagation techniques developed in network science. To ensure
scalability, we introduce a density-aware neighborhood propagation algorithm
and leverage advanced random projection methods to construct approximate
neighborhood graphs. Our approach significantly reduces computational cost
while preserving clustering quality. Empirically, it scales to datasets with
millions of points in minutes and achieves competitive accuracy compared to
existing baselines.

</details>


### [170] [On the Fast Adaptation of Delayed Clients in Decentralized Federated Learning: A Centroid-Aligned Distillation Approach](https://arxiv.org/abs/2508.02993)
*Jiahui Bai,Hai Dong,A. K. Qin*

Main category: cs.LG

TL;DR: DFedCAD通过中心对齐蒸馏实现快速适应，从而解决了分散联邦学习中延迟加入的客户端和高通信成本问题。


<details>
  <summary>Details</summary>
Motivation: 分散联邦学习(DFL)在异步环境中，难以适应延迟加入的客户端和高通信成本。这些限制严重阻碍了整体性能。

Method: DFedCAD首先采用加权聚类剪枝(WCP)将模型压缩成具有代表性的中心点，从而大大减少了通信开销。然后，它使用一种新的结构距离度量和一个可微的k-means蒸馏模块，使延迟加入的客户端能够智能地权衡和对齐对等知识，从而促进高效的端到端知识转移。

Result: 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的大量实验表明，DFedCAD始终如一地实现了最先进的性能，在所有评估的设置中都获得了最高的精度，同时将通信开销降低了86%以上。

Conclusion: DFedCAD在动态、真实世界的场景中，为高效的去中心化学习提供了一个可扩展的、实用的解决方案。

Abstract: Decentralized Federated Learning (DFL) struggles with the slow adaptation of
late-joining delayed clients and high communication costs in asynchronous
environments. These limitations significantly hinder overall performance. To
address this, we propose DFedCAD, a novel framework for rapid adaptation via
Centroid-Aligned Distillation. DFedCAD first employs Weighted Cluster Pruning
(WCP) to compress models into representative centroids, drastically reducing
communication overhead. It then enables delayed clients to intelligently weigh
and align with peer knowledge using a novel structural distance metric and a
differentiable k-means distillation module, facilitating efficient end-to-end
knowledge transfer. Extensive experiments on CIFAR-10, CIFAR-100, and
Tiny-ImageNet show that DFedCAD consistently achieves state-of-the-art
performance, attaining the highest accuracy across all evaluated settings while
reducing communication overhead by over 86%. Our framework provides a scalable
and practical solution for efficient decentralized learning in dynamic,
real-world scenarios.

</details>


### [171] [Where and How to Enhance: Discovering Bit-Width Contribution for Mixed Precision Quantization](https://arxiv.org/abs/2508.03002)
*Haidong Kang,Lianbo Ma,Guo Yu,Shangce Gao*

Main category: cs.LG

TL;DR: 提出了一种基于 Shapley 的 MPQ (SMPQ) 方法，该方法衡量了位宽操作对 MPQ 任务的直接贡献。


<details>
  <summary>Details</summary>
Motivation: 现有 MPQ 方法的典型方法是以梯度下降的方式优化量化策略（即，位宽分配），称为可微（DMPQ）。在搜索结束时，与具有最大值的量化参数相关联的位宽将被选择以形成最终的混合精度量化策略，其隐含的假设是量化参数的值反映了操作对精度提高的贡献。虽然关于 MPQ 改进已经讨论了很多，但位宽选择过程受到的关注很少。我们研究了这个问题，并认为量化参数的大小不一定反映位宽对任务性能的实际贡献。

Method: 提出了一种基于 Shapley 的 MPQ (SMPQ) 方法，该方法衡量了位宽操作对 MPQ 任务的直接贡献。为了降低计算成本，为 Shapley 计算提出了一种基于蒙特卡罗采样的近似策略。

Result: 我们的 SMPQ 在主流基准测试中始终优于基于梯度的竞争对手，实现了最先进的性能。

Conclusion: SMPQ在主流基准测试中始终优于基于梯度的竞争对手，实现了最先进的性能。

Abstract: Mixed precision quantization (MPQ) is an effective quantization approach to
achieve accuracy-complexity trade-off of neural network, through assigning
different bit-widths to network activations and weights in each layer. The
typical way of existing MPQ methods is to optimize quantization policies (i.e.,
bit-width allocation) in a gradient descent manner, termed as Differentiable
(DMPQ). At the end of the search, the bit-width associated to the quantization
parameters which has the largest value will be selected to form the final mixed
precision quantization policy, with the implicit assumption that the values of
quantization parameters reflect the operation contribution to the accuracy
improvement. While much has been discussed about the MPQ improvement, the
bit-width selection process has received little attention. We study this
problem and argue that the magnitude of quantization parameters does not
necessarily reflect the actual contribution of the bit-width to the task
performance. Then, we propose a Shapley-based MPQ (SMPQ) method, which measures
the bit-width operation direct contribution on the MPQ task. To reduce
computation cost, a Monte Carlo sampling-based approximation strategy is
proposed for Shapley computation. Extensive experiments on mainstream
benchmarks demonstrate that our SMPQ consistently achieves state-of-the-art
performance than gradient-based competitors.

</details>


### [172] [Urban In-Context Learning: Bridging Pretraining and Inference through Masked Diffusion for Urban Profiling](https://arxiv.org/abs/2508.03042)
*Ruixing Zhang,Bo Wang,Tongyu Zhu,Leilei Sun,Weifeng Lv*

Main category: cs.LG

TL;DR: 提出 Urban In-Context Learning 框架，用单阶段方法优于现有两阶段城市剖面分析方法。


<details>
  <summary>Details</summary>
Motivation: 现有城市剖面分析方法通常采用两阶段范式，依赖于 BERT 时代的线性探测，且城市数据结构与语言存在根本差异，难以设计统一预训练和推理的单阶段模型。

Method: 提出 Urban In-Context Learning 框架，通过城市掩码扩散 Transformer 实现区域预测的分布表示，并提出 Urban Representation Alignment Mechanism 以稳定扩散训练。

Result: 在两个城市的三个指标上，该单阶段方法始终优于最先进的两阶段方法。消融研究和案例研究进一步验证了每个模块的有效性，特别是扩散建模的应用。

Conclusion: 该研究提出了一种名为 Urban In-Context Learning 的框架，通过对城市区域的掩码自动编码过程统一预训练和推理。实验结果表明，该方法在两个城市的三个指标上始终优于最先进的两阶段方法。

Abstract: Urban profiling aims to predict urban profiles in unknown regions and plays a
critical role in economic and social censuses. Existing approaches typically
follow a two-stage paradigm: first, learning representations of urban areas;
second, performing downstream prediction via linear probing, which originates
from the BERT era. Inspired by the development of GPT style models, recent
studies have shown that novel self-supervised pretraining schemes can endow
models with direct applicability to downstream tasks, thereby eliminating the
need for task-specific fine-tuning. This is largely because GPT unifies the
form of pretraining and inference through next-token prediction. However, urban
data exhibit structural characteristics that differ fundamentally from
language, making it challenging to design a one-stage model that unifies both
pretraining and inference. In this work, we propose Urban In-Context Learning,
a framework that unifies pretraining and inference via a masked autoencoding
process over urban regions. To capture the distribution of urban profiles, we
introduce the Urban Masked Diffusion Transformer, which enables each region' s
prediction to be represented as a distribution rather than a deterministic
value. Furthermore, to stabilize diffusion training, we propose the Urban
Representation Alignment Mechanism, which regularizes the model's intermediate
features by aligning them with those from classical urban profiling methods.
Extensive experiments on three indicators across two cities demonstrate that
our one-stage method consistently outperforms state-of-the-art two-stage
approaches. Ablation studies and case studies further validate the
effectiveness of each proposed module, particularly the use of diffusion
modeling.

</details>


### [173] [A Novel Multimodal Framework for Early Detection of Alzheimers Disease Using Deep Learning](https://arxiv.org/abs/2508.03046)
*Tatwadarshi P Nagarhalli,Sanket Patil,Vishal Pande,Uday Aswalekar,Prafulla Patil*

Main category: cs.LG

TL;DR: 本文提出了一个用于AD早期检测的新型多模态框架，该框架集成了来自三个主要来源的数据：MRI成像、认知评估和生物标志物。


<details>
  <summary>Details</summary>
Motivation: 传统诊断方法通常依赖于单一数据模态，无法捕捉疾病的多方面性质，对早期诊断构成重大挑战，经常导致延误治疗和患者预后较差。

Method: 利用卷积神经网络（CNN）分析MRI图像，利用长短期记忆（LSTM）网络处理认知和生物标志物数据。通过使用加权平均等先进技术汇总来自这些不同模态的结果，即使在不完整的数据中，该系统也能提高诊断准确性和可靠性。

Result: 多模态方法不仅提高了检测过程的稳健性，而且能够在最早阶段识别AD，与传统方法相比具有显着优势。生物标志物和认知测试的整合尤为重要，因为它们可以在临床症状出现之前很久就检测到阿尔茨海默病，从而促进更早的干预并可能改变疾病的进程。

Conclusion: 提出的框架有彻底改变AD早期检测的潜力，为更及时有效的治疗铺平道路。

Abstract: Alzheimers Disease (AD) is a progressive neurodegenerative disorder that
poses significant challenges in its early diagnosis, often leading to delayed
treatment and poorer outcomes for patients. Traditional diagnostic methods,
typically reliant on single data modalities, fall short of capturing the
multifaceted nature of the disease. In this paper, we propose a novel
multimodal framework for the early detection of AD that integrates data from
three primary sources: MRI imaging, cognitive assessments, and biomarkers. This
framework employs Convolutional Neural Networks (CNN) for analyzing MRI images
and Long Short-Term Memory (LSTM) networks for processing cognitive and
biomarker data. The system enhances diagnostic accuracy and reliability by
aggregating results from these distinct modalities using advanced techniques
like weighted averaging, even in incomplete data. The multimodal approach not
only improves the robustness of the detection process but also enables the
identification of AD at its earliest stages, offering a significant advantage
over conventional methods. The integration of biomarkers and cognitive tests is
particularly crucial, as these can detect Alzheimer's long before the onset of
clinical symptoms, thereby facilitating earlier intervention and potentially
altering the course of the disease. This research demonstrates that the
proposed framework has the potential to revolutionize the early detection of
AD, paving the way for more timely and effective treatments

</details>


### [174] [VRPO: Rethinking Value Modeling for Robust RL Training under Noisy Supervision](https://arxiv.org/abs/2508.03058)
*Dingwei Zhu,Shihan Dou,Zhiheng Xi,Senjie Jin,Guoqiang Zhang,Jiazheng Zhang,Junjie Ye,Mingxu Chai,Enyu Zhou,Ming Zhang,Caishuang Huang,Yunke Zhang,Yuran Wang,Tao Gui*

Main category: cs.LG

TL;DR: VRPO 是一种以价值为中心的框架，用于在嘈杂的监督下进行稳健的 PPO 训练，通过增强价值模型过滤噪声的能力来提高性能。


<details>
  <summary>Details</summary>
Motivation: 来自人类反馈的强化学习 (RLHF) 经常在现实环境中受到嘈杂或不完善的奖励监督的影响，这会损害策略稳定性和泛化性。这种噪声可能导致模型在优势估计期间失去对关键词的注意。

Method: VRPO 结合了两个核心设计：(1) 由冻结语言模型的熵和困惑度引导的辅助损失，以及 (2) 变分信息瓶颈。

Result: VRPO 增强了价值模型在优势估计期间过滤噪声和捕获上下文中关键词的能力，将其从被动预测器转变为噪声的主动调节器。

Conclusion: VRPO在噪声环境下的数学推理、科学问答和多轮对话实验中始终优于 PPO 和 GRPO 基线。

Abstract: Reinforcement Learning from Human Feedback (RLHF) often suffers from noisy or
imperfect reward supervision in real-world settings, which undermines policy
stability and generalization. Such noise may cause models to lose attention on
key words during advantage estimation. While prior work focuses on reward
denoising or filtering poor data, it often overlooks the critical role of the
value model in policy optimization. In this work, we show that a strong value
model is essential for mitigating noise by absorbing unstable signals and
enabling more reliable advantage estimation. We propose VRPO, a value-centric
framework for robust PPO training under noisy supervision. VRPO combines two
core designs: (1) an auxiliary loss guided by entropy and perplexity from a
frozen language model, and (2) a variational information bottleneck. These
mechanisms enhance the value model's ability to filter out noise and capture
key words from the context during advantage estimation, transforming it from a
passive predictor into an active regulator of noise. Experiments on math
reasoning, science QA, and multi-turn dialogue, under both rule-based and
model-based noisy rewards, show that VRPO consistently outperforms PPO and GRPO
baselines. Our findings underscore the often-overlooked importance of the value
model in RLHF and offer a principled and practical approach to robust policy
optimization in noisy real-world environments.

</details>


### [175] [Achieving Limited Adaptivity for Multinomial Logistic Bandits](https://arxiv.org/abs/2508.03072)
*Sukruta Prakash Midigeshi,Tanmay Goyal,Gaurav Sinha*

Main category: cs.LG

TL;DR: This paper introduces two algorithms for multinomial logistic bandits with limited adaptivity, achieving optimal regret with a small number of policy updates, and demonstrates their practical applicability.


<details>
  <summary>Details</summary>
Motivation: There is a need to develop algorithms with limited adaptivity, allowing only M policy updates, due to real-world challenges and practicality in multinomial logistic bandits.

Method: The paper presents two algorithms: B-MNL-CB, which extends distributional optimal designs to the multinomial setting, and RS-MNL, which works with adversarially generated contexts.

Result: B-MNL-CB achieves $\tilde{O}(\sqrt{T})$ regret with $\Omega(\\log \\log T)$ update rounds assuming stochastic contexts. RS-MNL achieves $\tilde{O}(\sqrt{T})$ regret with $\tilde{O}(\log T)$ policy updates with adversarial contexts.

Conclusion: The paper's algorithms, B-MNL-CB and RS-MNL, are competitive and often better than state-of-the-art baselines with a fixed number of policy updates, demonstrating their applicability in various practical scenarios.

Abstract: Multinomial Logistic Bandits have recently attracted much attention due to
their ability to model problems with multiple outcomes. In this setting, each
decision is associated with many possible outcomes, modeled using a multinomial
logit function. Several recent works on multinomial logistic bandits have
simultaneously achieved optimal regret and computational efficiency. However,
motivated by real-world challenges and practicality, there is a need to develop
algorithms with limited adaptivity, wherein we are allowed only $M$ policy
updates. To address these challenges, we present two algorithms, B-MNL-CB and
RS-MNL, that operate in the batched and rarely-switching paradigms,
respectively. The batched setting involves choosing the $M$ policy update
rounds at the start of the algorithm, while the rarely-switching setting can
choose these $M$ policy update rounds in an adaptive fashion. Our first
algorithm, B-MNL-CB extends the notion of distributional optimal designs to the
multinomial setting and achieves $\tilde{O}(\sqrt{T})$ regret assuming the
contexts are generated stochastically when presented with $\Omega(\log \log T)$
update rounds. Our second algorithm, RS-MNL works with adversarially generated
contexts and can achieve $\tilde{O}(\sqrt{T})$ regret with $\tilde{O}(\log T)$
policy updates. Further, we conducted experiments that demonstrate that our
algorithms (with a fixed number of policy updates) are extremely competitive
(and often better) than several state-of-the-art baselines (which update their
policy every round), showcasing the applicability of our algorithms in various
practical scenarios.

</details>


### [176] [HiTeC: Hierarchical Contrastive Learning on Text-Attributed Hypergraph with Semantic-Aware Augmentation](https://arxiv.org/abs/2508.03104)
*Mengting Pan,Fan Li,Xiaoyang Wang,Wenjie Zhang,Xuemin Lin*

Main category: cs.LG

TL;DR: HiTeC is introduced to address the limitations of applying CL-based methods to text-attributed hypergraphs (TAHGs).


<details>
  <summary>Details</summary>
Motivation: node entities in real-world hypergraphs are often associated with rich textual information, which is overlooked in prior works. Directly applying existing CL-based methods to such text-attributed hypergraphs (TAHGs) leads to three key limitations: (1) The common use of graph-agnostic text encoders overlooks the correlations between textual content and hypergraph topology, resulting in suboptimal representations. (2) Their reliance on random data augmentations introduces noise and weakens the contrastive objective. (3) The primary focus on node- and hyperedge-level contrastive signals limits the ability to capture long-range dependencies, which is essential for expressive representation learning.

Method: a two-stage hierarchical contrastive learning framework with semantic-aware augmentation

Result: HiTeC, a two-stage hierarchical contrastive learning framework with semantic-aware augmentation for scalable and effective self-supervised learning on TAHGs

Conclusion: Extensive experiments confirm the effectiveness of HiTeC.

Abstract: Contrastive learning (CL) has become a dominant paradigm for self-supervised
hypergraph learning, enabling effective training without costly labels.
However, node entities in real-world hypergraphs are often associated with rich
textual information, which is overlooked in prior works. Directly applying
existing CL-based methods to such text-attributed hypergraphs (TAHGs) leads to
three key limitations: (1) The common use of graph-agnostic text encoders
overlooks the correlations between textual content and hypergraph topology,
resulting in suboptimal representations. (2) Their reliance on random data
augmentations introduces noise and weakens the contrastive objective. (3) The
primary focus on node- and hyperedge-level contrastive signals limits the
ability to capture long-range dependencies, which is essential for expressive
representation learning. Although HyperBERT pioneers CL on TAHGs, its
co-training paradigm suffers from poor scalability. To fill the research gap,
we introduce HiTeC, a two-stage hierarchical contrastive learning framework
with semantic-aware augmentation for scalable and effective self-supervised
learning on TAHGs. In the first stage, we pre-train the text encoder with a
structure-aware contrastive objective to overcome the graph-agnostic nature of
conventional methods. In the second stage, we introduce two semantic-aware
augmentation strategies, including prompt-enhanced text augmentation and
semantic-aware hyperedge drop, to facilitate informative view generation.
Furthermore, we propose a multi-scale contrastive loss that extends existing
objectives with an $s$-walk-based subgraph-level contrast to better capture
long-range dependencies. By decoupling text encoder pretraining from hypergraph
contrastive learning, this two-stage design enhances scalability without
compromising representation quality. Extensive experiments confirm the
effectiveness of HiTeC.

</details>


### [177] [Accelerating SGDM via Learning Rate and Batch Size Schedules: A Lyapunov-Based Analysis](https://arxiv.org/abs/2508.03105)
*Yuichi Kondo,Hideaki Iiduka*

Main category: cs.LG

TL;DR: Analyzed SGDM convergence with dynamic schedules, found increasing batch size with increasing learning rate converges fastest, and warm-up schedule performs best empirically.


<details>
  <summary>Details</summary>
Motivation: challenging convergence analysis of SGDM and a unified analysis across various dynamic schedules

Method: introducing a novel Lyapunov function to analyze the convergence behavior of SGDM under dynamic learning rate and batch size schedules

Result: reveal a clear hierarchy in convergence behavior: (i) does not guarantee convergence of the expected gradient norm, both (ii) and (iii) do. Moreover, (iii) achieves a provably faster decay rate than (i) and (ii)

Conclusion: Dynamically scheduled SGDM significantly outperforms fixed-hyperparameter baselines and a warm-up schedule achieves best convergence.

Abstract: We analyze the convergence behavior of stochastic gradient descent with
momentum (SGDM) under dynamic learning rate and batch size schedules by
introducing a novel Lyapunov function. This Lyapunov function has a simpler
structure compared with existing ones, facilitating the challenging convergence
analysis of SGDM and a unified analysis across various dynamic schedules.
Specifically, we extend the theoretical framework to cover three practical
scheduling strategies commonly used in deep learning: (i) constant batch size
with a decaying learning rate, (ii) increasing batch size with a decaying
learning rate, and (iii) increasing batch size with an increasing learning
rate. Our theoretical results reveal a clear hierarchy in convergence behavior:
while (i) does not guarantee convergence of the expected gradient norm, both
(ii) and (iii) do. Moreover, (iii) achieves a provably faster decay rate than
(i) and (ii), demonstrating theoretical acceleration even in the presence of
momentum. Empirical results validate our theory, showing that dynamically
scheduled SGDM significantly outperforms fixed-hyperparameter baselines in
convergence speed. We also evaluated a warm-up schedule in experiments, which
empirically outperformed all other strategies in convergence behavior. These
findings provide a unified theoretical foundation and practical guidance for
designing efficient and stable training procedures in modern deep learning.

</details>


### [178] [Pseudo-label Induced Subspace Representation Learning for Robust Out-of-Distribution Detection](https://arxiv.org/abs/2508.03108)
*Tarhib Al Azad,Faizul Rakib Sayem,Shahana Ibrahim*

Main category: cs.LG

TL;DR: 本文提出了一个新颖的OOD检测框架，该框架在更宽松的假设下工作，与现有的基于特征的技术相比，具有更好的ID-OOD可分离性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于对特征空间的限制性假设，限制了ID和OOD样本之间的可分离性。

Method: 基于伪标签诱导子空间表示的OOD检测框架

Result: 大量的实验验证了我们框架的有效性。

Conclusion: 本文提出了一个新颖的基于伪标签诱导子空间表示的OOD检测框架，该框架在更宽松和自然的假设下工作，与现有的基于特征的技术相比，具有更好的ID-OOD可分离性。

Abstract: Out-of-distribution (OOD) detection lies at the heart of robust artificial
intelligence (AI), aiming to identify samples from novel distributions beyond
the training set. Recent approaches have exploited feature representations as
distinguishing signatures for OOD detection. However, most existing methods
rely on restrictive assumptions on the feature space that limit the
separability between in-distribution (ID) and OOD samples. In this work, we
propose a novel OOD detection framework based on a pseudo-label-induced
subspace representation, that works under more relaxed and natural assumptions
compared to existing feature-based techniques. In addition, we introduce a
simple yet effective learning criterion that integrates a cross-entropy-based
ID classification loss with a subspace distance-based regularization loss to
enhance ID-OOD separability. Extensive experiments validate the effectiveness
of our framework.

</details>


### [179] [GEDAN: Learning the Edit Costs for Graph Edit Distance](https://arxiv.org/abs/2508.03111)
*Francesco Leonardi,Markus Orsi,Jean-Louis Reymond,Kaspar Riesen*

Main category: cs.LG

TL;DR: 提出了一种新的图神经网络框架，该框架使用监督和非监督训练来逼近GED，并且允许灵活和可解释的上下文感知编辑成本学习。


<details>
  <summary>Details</summary>
Motivation: 图编辑距离（GED）被定义为将一个图转换为另一个图的最小成本转换，是一种广泛采用的测量图之间差异的指标。GED的主要问题是它的计算是NP-hard，这反过来导致了各种近似方法的发展，包括基于神经网络（NN）的方法。大多数基于神经网络的模型通过假设单位成本编辑操作来简化GED问题，这是实际应用中一个相当不切实际的约束。

Method: 提出了一种新的图神经网络框架，该框架使用监督和非监督训练来逼近GED。在无监督环境下，它采用了一种仅梯度的自组织机制，可以在没有地面真实距离的情况下进行优化。此外，我们架构的一个核心组成部分是集成了一个广义加性模型，该模型允许灵活和可解释的上下文感知编辑成本学习。

Result: 该方法与最先进的参考方法取得了相似的结果，但在适应性和可解释性方面都有了显著的提高。

Conclusion: 该方法与最先进的参考方法取得了相似的结果，但在适应性和可解释性方面都有了显著的提高。学习到的成本函数可以深入了解复杂的图形结构，使其在分子分析和结构模式发现等领域特别有价值。

Abstract: Graph Edit Distance (GED) is defined as the minimum cost transformation of
one graph into another and is a widely adopted metric for measuring the
dissimilarity between graphs. The major problem of GED is that its computation
is NP-hard, which has in turn led to the development of various approximation
methods, including approaches based on neural networks (NN). Most of these
NN-based models simplify the problem of GED by assuming unit-cost edit
operations, a rather unrealistic constraint in real-world applications. In this
work, we present a novel Graph Neural Network framework that approximates GED
using both supervised and unsupervised training. In the unsupervised setting,
it employs a gradient-only self-organizing mechanism that enables optimization
without ground-truth distances. Moreover, a core component of our architecture
is the integration of a Generalized Additive Model, which allows the flexible
and interpretable learning of context-aware edit costs. Experimental results
show that the proposed method achieves similar results as state-of-the-art
reference methods, yet significantly improves both adaptability and
interpretability. That is, the learned cost function offers insights into
complex graph structures, making it particularly valuable in domains such as
molecular analysis and structural pattern discovery.

</details>
