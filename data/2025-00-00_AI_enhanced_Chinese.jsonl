{"id": "2506.15120", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15120", "abs": "https://arxiv.org/abs/2506.15120", "authors": ["Shengjia Zhang", "Jiawei Chen", "Changdong Li", "Sheng Zhou", "Qihao Shi", "Yan Feng", "Chun Chen", "Can Wang"], "title": "Advancing Loss Functions in Recommender Systems: A Comparative Study with a R\u00e9nyi Divergence-Based Solution", "comment": "AAAI 2025", "summary": "Loss functions play a pivotal role in optimizing recommendation models. Among\nvarious loss functions, Softmax Loss (SL) and Cosine Contrastive Loss (CCL) are\nparticularly effective. Their theoretical connections and differences warrant\nin-depth exploration. This work conducts comprehensive analyses of these\nlosses, yielding significant insights: 1) Common strengths -- both can be\nviewed as augmentations of traditional losses with Distributional Robust\nOptimization (DRO), enhancing robustness to distributional shifts; 2)\nRespective limitations -- stemming from their use of different distribution\ndistance metrics in DRO optimization, SL exhibits high sensitivity to false\nnegative instances, whereas CCL suffers from low data utilization. To address\nthese limitations, this work proposes a new loss function, DrRL, which\ngeneralizes SL and CCL by leveraging R\\'enyi-divergence in DRO optimization.\nDrRL incorporates the advantageous structures of both SL and CCL, and can be\ndemonstrated to effectively mitigate their limitations. Extensive experiments\nhave been conducted to validate the superiority of DrRL on both recommendation\naccuracy and robustness.", "AI": {"tldr": "\u6df1\u5165\u5206\u6790\u4e86Softmax Loss (SL) \u548c Cosine Contrastive Loss (CCL) \u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u635f\u5931\u51fd\u6570DrRL\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "Softmax Loss (SL) \u548c Cosine Contrastive Loss (CCL) \u5728\u4f18\u5316\u63a8\u8350\u6a21\u578b\u4e2d\u975e\u5e38\u6709\u6548\uff0c\u4f46\u5b83\u4eec\u7684\u7406\u8bba\u8054\u7cfb\u548c\u5dee\u5f02\u503c\u5f97\u6df1\u5165\u7814\u7a76\u3002SL\u5bf9\u5047\u9634\u6027\u5b9e\u4f8b\u8868\u73b0\u51fa\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u800cCCL\u5b58\u5728\u6570\u636e\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u5bf9Softmax Loss (SL) \u548c Cosine Contrastive Loss (CCL) \u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570DrRL\u3002", "result": "SL\u548cCCL\u90fd\u53ef\u4ee5\u770b\u4f5c\u662f\u4f20\u7edf\u635f\u5931\u7684\u589e\u5f3a\uff0c\u5177\u6709\u5206\u5e03\u9c81\u68d2\u4f18\u5316(DRO)\uff0c\u589e\u5f3a\u4e86\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002SL\u5bf9\u5047\u9634\u6027\u5b9e\u4f8b\u8868\u73b0\u51fa\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u800cCCL\u5b58\u5728\u6570\u636e\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "conclusion": "\u63d0\u51fa\u4e86\u65b0\u7684\u635f\u5931\u51fd\u6570DrRL\uff0c\u901a\u8fc7\u5728DRO\u4f18\u5316\u4e2d\u5229\u7528R'enyi\u6563\u5ea6\u6765\u63a8\u5e7fSL\u548cCCL\uff0c\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u5b83\u4eec\u7684\u5c40\u9650\u6027\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DrRL\u5728\u63a8\u8350\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.15267", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.15267", "abs": "https://arxiv.org/abs/2506.15267", "authors": ["Yu-Ting Lan", "Yang Huo", "Yi Shen", "Xiao Yang", "Zuotao Liu"], "title": "Next-User Retrieval: Enhancing Cold-Start Recommendations via Generative Next-User Modeling", "comment": null, "summary": "The item cold-start problem is critical for online recommendation systems, as\nthe success of this phase determines whether high-quality new items can\ntransition to popular ones, receive essential feedback to inspire creators, and\nthus lead to the long-term retention of creators. However, modern\nrecommendation systems still struggle to address item cold-start challenges due\nto the heavy reliance on item and historical interactions, which are\nnon-trivial for cold-start items lacking sufficient exposure and feedback.\nLookalike algorithms provide a promising solution by extending feedback for new\nitems based on lookalike users. Traditional lookalike algorithms face such\nlimitations: (1) failing to effectively model the lookalike users and further\nimprove recommendations with the existing rule- or model-based methods; and (2)\nstruggling to utilize the interaction signals and incorporate diverse features\nin modern recommendation systems.\n  Inspired by lookalike algorithms, we propose Next-User Retrieval, a novel\nframework for enhancing cold-start recommendations via generative next-user\nmodeling. Specifically, we employ a transformer-based model to capture the\nunidirectional relationships among recently interacted users and utilize these\nsequences to generate the next potential user who is most likely to interact\nwith the item. The additional item features are also integrated as prefix\nprompt embeddings to assist the next-user generation. The effectiveness of\nNext-User Retrieval is evaluated through both offline experiments and online\nA/B tests. Our method achieves significant improvements with increases of\n0.0142% in daily active users and +0.1144% in publications in Douyin,\nshowcasing its practical applicability and scalability.", "AI": {"tldr": "Next-User Retrieval, a novel framework using generative next-user modeling, enhances cold-start recommendations by predicting the next potential user, leading to improvements in user engagement and content publication.", "motivation": "Modern recommendation systems struggle with item cold-start challenges due to their reliance on item and historical interactions, which are lacking for new items. Traditional lookalike algorithms have limitations in modeling lookalike users and utilizing interaction signals.", "method": "A transformer-based model is used to capture unidirectional relationships among recently interacted users and generate the next potential user. Additional item features are integrated as prefix prompt embeddings.", "result": "The Next-User Retrieval method achieves significant improvements with increases of 0.0142% in daily active users and +0.1144% in publications in Douyin.", "conclusion": "The proposed Next-User Retrieval framework significantly improves cold-start recommendations, as demonstrated by offline experiments and online A/B tests with increases in daily active users and publications in Douyin."}}
{"id": "2506.15284", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.15284", "abs": "https://arxiv.org/abs/2506.15284", "authors": ["Zihao Li", "Qiang Chen", "Lixin Zou", "Aixin Sun", "Chenliang Li"], "title": "Multi-Interest Recommendation: A Survey", "comment": null, "summary": "Existing recommendation methods often struggle to model users' multifaceted\npreferences due to the diversity and volatility of user behavior, as well as\nthe inherent uncertainty and ambiguity of item attributes in practical\nscenarios. Multi-interest recommendation addresses this challenge by extracting\nmultiple interest representations from users' historical interactions, enabling\nfine-grained preference modeling and more accurate recommendations. It has\ndrawn broad interest in recommendation research. However, current\nrecommendation surveys have either specialized in frontier recommendation\nmethods or delved into specific tasks and downstream applications. In this\nwork, we systematically review the progress, solutions, challenges, and future\ndirections of multi-interest recommendation by answering the following three\nquestions: (1) Why is multi-interest modeling significantly important for\nrecommendation? (2) What aspects are focused on by multi-interest modeling in\nrecommendation? and (3) How can multi-interest modeling be applied, along with\nthe technical details of the representative modules? We hope that this survey\nestablishes a fundamental framework and delivers a preliminary overview for\nresearchers interested in this field and committed to further exploration. The\nimplementation of multi-interest recommendation summarized in this survey is\nmaintained at https://github.com/WHUIR/Multi-Interest-Recommendation-A-Survey.", "AI": {"tldr": "This paper surveys multi-interest recommendation, addressing its importance, key aspects, applications, and technical details. It provides a framework for researchers in the field.", "motivation": "Existing recommendation methods often struggle to model users' multifaceted preferences due to the diversity and volatility of user behavior, as well as the inherent uncertainty and ambiguity of item attributes in practical scenarios.", "method": "systematically review the progress, solutions, challenges, and future directions of multi-interest recommendation", "result": "review the progress, solutions, challenges, and future directions of multi-interest recommendation by answering the following three questions: (1) Why is multi-interest modeling significantly important for recommendation? (2) What aspects are focused on by multi-interest modeling in recommendation? and (3) How can multi-interest modeling be applied, along with the technical details of the representative modules?", "conclusion": "This survey establishes a fundamental framework and delivers a preliminary overview for researchers interested in multi-interest recommendation."}}
{"id": "2506.15120", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.15120", "abs": "https://arxiv.org/abs/2506.15120", "authors": ["Shengjia Zhang", "Jiawei Chen", "Changdong Li", "Sheng Zhou", "Qihao Shi", "Yan Feng", "Chun Chen", "Can Wang"], "title": "Advancing Loss Functions in Recommender Systems: A Comparative Study with a R\u00e9nyi Divergence-Based Solution", "comment": "AAAI 2025", "summary": "Loss functions play a pivotal role in optimizing recommendation models. Among\nvarious loss functions, Softmax Loss (SL) and Cosine Contrastive Loss (CCL) are\nparticularly effective. Their theoretical connections and differences warrant\nin-depth exploration. This work conducts comprehensive analyses of these\nlosses, yielding significant insights: 1) Common strengths -- both can be\nviewed as augmentations of traditional losses with Distributional Robust\nOptimization (DRO), enhancing robustness to distributional shifts; 2)\nRespective limitations -- stemming from their use of different distribution\ndistance metrics in DRO optimization, SL exhibits high sensitivity to false\nnegative instances, whereas CCL suffers from low data utilization. To address\nthese limitations, this work proposes a new loss function, DrRL, which\ngeneralizes SL and CCL by leveraging R\\'enyi-divergence in DRO optimization.\nDrRL incorporates the advantageous structures of both SL and CCL, and can be\ndemonstrated to effectively mitigate their limitations. Extensive experiments\nhave been conducted to validate the superiority of DrRL on both recommendation\naccuracy and robustness.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86Softmax Loss (SL) \u548c Cosine Contrastive Loss (CCL)\u7684\u4f18\u7f3a\u70b9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570DrRL\uff0c\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DrRL\u7684\u6709\u6548\u6027", "motivation": "\u6df1\u5165\u7814\u7a76Softmax Loss (SL) \u548c Cosine Contrastive Loss (CCL)\u7684\u7406\u8bba\u8054\u7cfb\u548c\u5dee\u5f02\u3002SL\u548cCCL\u90fd\u53ef\u88ab\u89c6\u4e3a\u4f7f\u7528\u5206\u5e03\u9c81\u68d2\u4f18\u5316 (DRO) \u5bf9\u4f20\u7edf\u635f\u5931\u7684\u589e\u5f3a\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002SL\u5bf9\u5047\u9634\u6027\u5b9e\u4f8b\u8868\u73b0\u51fa\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u800cCCL\u5b58\u5728\u6570\u636e\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570DrRL\uff0c\u5b83\u63a8\u5e7f\u4e86SL\u548cCCL\uff0c\u5e76\u901a\u8fc7\u5229\u7528R'enyi\u6563\u5ea6\u5728DRO\u4e2d\u8fdb\u884c\u4f18\u5316", "result": "SL\u548cCCL\u90fd\u53ef\u88ab\u89c6\u4e3a\u4f7f\u7528\u5206\u5e03\u9c81\u68d2\u4f18\u5316 (DRO) \u5bf9\u4f20\u7edf\u635f\u5931\u7684\u589e\u5f3a\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u5bf9\u5206\u5e03\u504f\u79fb\u7684\u9c81\u68d2\u6027\u3002SL\u5bf9\u5047\u9634\u6027\u5b9e\u4f8b\u8868\u73b0\u51fa\u9ad8\u5ea6\u654f\u611f\u6027\uff0c\u800cCCL\u5b58\u5728\u6570\u636e\u5229\u7528\u7387\u4f4e\u7684\u95ee\u9898\u3002DrRL\u5728\u63a8\u8350\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u635f\u5931\u51fd\u6570DrRL\uff0c\u5b83\u63a8\u5e7f\u4e86SL\u548cCCL\uff0c\u5e76\u901a\u8fc7\u5229\u7528DRO\u4f18\u5316\u4e2d\u7684R'enyi\u6563\u5ea6\uff0c\u7ed3\u5408\u4e86SL\u548cCCL\u7684\u4f18\u52bf\u7ed3\u6784\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5b83\u4eec\u7684\u5c40\u9650\u6027\u3002\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86DrRL\u5728\u63a8\u8350\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4f18\u8d8a\u6027\u3002"}}
{"id": "2506.15267", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.15267", "abs": "https://arxiv.org/abs/2506.15267", "authors": ["Yu-Ting Lan", "Yang Huo", "Yi Shen", "Xiao Yang", "Zuotao Liu"], "title": "Next-User Retrieval: Enhancing Cold-Start Recommendations via Generative Next-User Modeling", "comment": null, "summary": "The item cold-start problem is critical for online recommendation systems, as\nthe success of this phase determines whether high-quality new items can\ntransition to popular ones, receive essential feedback to inspire creators, and\nthus lead to the long-term retention of creators. However, modern\nrecommendation systems still struggle to address item cold-start challenges due\nto the heavy reliance on item and historical interactions, which are\nnon-trivial for cold-start items lacking sufficient exposure and feedback.\nLookalike algorithms provide a promising solution by extending feedback for new\nitems based on lookalike users. Traditional lookalike algorithms face such\nlimitations: (1) failing to effectively model the lookalike users and further\nimprove recommendations with the existing rule- or model-based methods; and (2)\nstruggling to utilize the interaction signals and incorporate diverse features\nin modern recommendation systems.\n  Inspired by lookalike algorithms, we propose Next-User Retrieval, a novel\nframework for enhancing cold-start recommendations via generative next-user\nmodeling. Specifically, we employ a transformer-based model to capture the\nunidirectional relationships among recently interacted users and utilize these\nsequences to generate the next potential user who is most likely to interact\nwith the item. The additional item features are also integrated as prefix\nprompt embeddings to assist the next-user generation. The effectiveness of\nNext-User Retrieval is evaluated through both offline experiments and online\nA/B tests. Our method achieves significant improvements with increases of\n0.0142% in daily active users and +0.1144% in publications in Douyin,\nshowcasing its practical applicability and scalability.", "AI": {"tldr": "Next-User Retrieval, a novel framework using generative next-user modeling, enhances cold-start recommendations and shows significant improvements in user engagement and content generation on Douyin.", "motivation": "Modern recommendation systems struggle with item cold-start challenges due to a heavy reliance on item and historical interactions, which are non-trivial for cold-start items. Traditional lookalike algorithms also have limitations in modeling lookalike users and utilizing interaction signals.", "method": "A transformer-based model is used to capture unidirectional relationships among recently interacted users to generate the next potential user. Additional item features are integrated as prefix prompt embeddings.", "result": "The Next-User Retrieval method achieves significant improvements with increases of 0.0142% in daily active users and +0.1144% in publications in Douyin.", "conclusion": "The Next-User Retrieval method demonstrates practical applicability and scalability with significant improvements in daily active users and publications on Douyin."}}
{"id": "2506.15284", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2506.15284", "abs": "https://arxiv.org/abs/2506.15284", "authors": ["Zihao Li", "Qiang Chen", "Lixin Zou", "Aixin Sun", "Chenliang Li"], "title": "Multi-Interest Recommendation: A Survey", "comment": null, "summary": "Existing recommendation methods often struggle to model users' multifaceted\npreferences due to the diversity and volatility of user behavior, as well as\nthe inherent uncertainty and ambiguity of item attributes in practical\nscenarios. Multi-interest recommendation addresses this challenge by extracting\nmultiple interest representations from users' historical interactions, enabling\nfine-grained preference modeling and more accurate recommendations. It has\ndrawn broad interest in recommendation research. However, current\nrecommendation surveys have either specialized in frontier recommendation\nmethods or delved into specific tasks and downstream applications. In this\nwork, we systematically review the progress, solutions, challenges, and future\ndirections of multi-interest recommendation by answering the following three\nquestions: (1) Why is multi-interest modeling significantly important for\nrecommendation? (2) What aspects are focused on by multi-interest modeling in\nrecommendation? and (3) How can multi-interest modeling be applied, along with\nthe technical details of the representative modules? We hope that this survey\nestablishes a fundamental framework and delivers a preliminary overview for\nresearchers interested in this field and committed to further exploration. The\nimplementation of multi-interest recommendation summarized in this survey is\nmaintained at https://github.com/WHUIR/Multi-Interest-Recommendation-A-Survey.", "AI": {"tldr": "A survey on multi-interest recommendation, addressing its importance, focused aspects, and applications.", "motivation": "Existing recommendation methods often struggle to model users' multifaceted preferences due to the diversity and volatility of user behavior, as well as the inherent uncertainty and ambiguity of item attributes in practical scenarios.", "method": "systematically review the progress, solutions, challenges, and future directions of multi-interest recommendation", "result": "Helps answer the questions: (1) Why is multi-interest modeling significantly important for recommendation? (2) What aspects are focused on by multi-interest modeling in recommendation? and (3) How can multi-interest modeling be applied, along with the technical details of the representative modules?", "conclusion": "This survey establishes a fundamental framework and delivers a preliminary overview for researchers interested in multi-interest recommendation."}}
