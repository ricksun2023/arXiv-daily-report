<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

Main category: cs.CL

TL;DR: This paper evaluates how well LLMs align with human ratings on psycholinguistic datasets. LLMs align better with abstract features than sensory associations, possibly due to lack of embodied cognition.


<details>
  <summary>Details</summary>
Motivation: LLMs are typically evaluated on tasks with objective metrics, but other language features like arousal, concreteness, or gender are not easily quantified. Psycholinguistic studies offer human ratings for these features, providing an opportunity to evaluate how well LLMs align with human perception.

Method: Evaluate the alignment of a representative group of LLMs with human ratings on two psycholinguistic datasets: the Glasgow and Lancaster norms, which cover thirteen features over thousands of words.

Result: Alignment is generally better in the Glasgow norms than on the Lancaster norms, suggesting a potential limitation of current LLMs in aligning with human sensory associations for words.

Conclusion: LLMs align better with human ratings on Glasgow norms (arousal, valence, dominance, concreteness, imageability, familiarity, and gender) than on Lancaster norms (introceptive, gustatory, olfactory, haptic, auditory, and visual), suggesting a limitation in aligning with human sensory associations, potentially due to lack of embodied cognition.

Abstract: The evaluation of LLMs has so far focused primarily on how well they can
perform different tasks such as reasoning, question-answering, paraphrasing, or
translating. For most of these tasks, performance can be measured with
objective metrics, such as the number of correct answers. However, other
language features are not easily quantified. For example, arousal,
concreteness, or gender associated with a given word, as well as the extent to
which we experience words with senses and relate them to a specific sense.
Those features have been studied for many years by psycholinguistics,
conducting large-scale experiments with humans to produce ratings for thousands
of words. This opens an opportunity to evaluate how well LLMs align with human
ratings on these word features, taking advantage of existing studies that cover
many different language features in a large number of words. In this paper, we
evaluate the alignment of a representative group of LLMs with human ratings on
two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets
cover thirteen features over thousands of words. The results show that
alignment is \textcolor{black}{generally} better in the Glasgow norms evaluated
(arousal, valence, dominance, concreteness, imageability, familiarity, and
gender) than on the Lancaster norms evaluated (introceptive, gustatory,
olfactory, haptic, auditory, and visual). This suggests a potential limitation
of current LLMs in aligning with human sensory associations for words, which
may be due to their lack of embodied cognition present in humans and
illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.

</details>


### [2] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
*Sudip Dasgupta,Himanshu Shankar*

Main category: cs.CL

TL;DR: 本研究提出了一个AI代理系统，用于自动审查企业文档，在准确性、速度和一致性方面优于人工审查，但仍需人工监督。


<details>
  <summary>Details</summary>
Motivation: 与以往专注于非结构化文本或有限合规性检查的解决方案不同，本研究提出了一个模块化的多代理系统，用于使用AI代理自动审查高度结构化的企业业务文档。

Method: 该框架利用LangChain、CrewAI、TruLens和Guidance等现代编排工具，对文档进行逐节评估，以确保准确性、一致性、完整性和清晰度。

Result: AI Agent-as-Judge系统在关键领域接近或超过了人类的表现：实现了99%的信息一致性（人类为92%），误差和偏差率降低了一半，平均审查时间从每份文档30分钟减少到2.5分钟，AI和专家人类判断之间的一致率为95%。

Conclusion: 该系统为企业环境中AI驱动的文档质量保证提供了一个灵活、可审计和可扩展的基础。

Abstract: This study presents a modular, multi-agent system for the automated review of
highly structured enterprise business documents using AI agents. Unlike prior
solutions focused on unstructured texts or limited compliance checks, this
framework leverages modern orchestration tools such as LangChain, CrewAI,
TruLens, and Guidance to enable section-by-section evaluation of documents for
accuracy, consistency, completeness, and clarity. Specialized agents, each
responsible for discrete review criteria such as template compliance or factual
correctness, operate in parallel or sequence as required. Evaluation outputs
are enforced to a standardized, machine-readable schema, supporting downstream
analytics and auditability. Continuous monitoring and a feedback loop with
human reviewers allow for iterative system improvement and bias mitigation.
  Quantitative evaluation demonstrates that the AI Agent-as-Judge system
approaches or exceeds human performance in key areas: achieving 99% information
consistency (vs. 92% for humans), halving error and bias rates, and reducing
average review time from 30 to 2.5 minutes per document, with a 95% agreement
rate between AI and expert human judgment. While promising for a wide range of
industries, the study also discusses current limitations, including the need
for human oversight in highly specialized domains and the operational cost of
large-scale LLM usage. The proposed system serves as a flexible, auditable, and
scalable foundation for AI-driven document quality assurance in the enterprise
context.

</details>


### [3] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
*Ming Cheung*

Main category: cs.CL

TL;DR: 该论文提出了一种使用多个小型语言模型来检测大型语言模型响应中幻觉的框架，实验表明该框架可以有效提高检测正确响应的准确率。


<details>
  <summary>Details</summary>
Motivation: 响应中的幻觉会破坏大型语言模型在实际应用中的可靠性，并且在没有真实数据的情况下不容易检测到，尤其是在问答场景中。

Method: 该论文提出了一个框架，该框架集成了多个小型语言模型，以验证大型语言模型使用从矢量化数据库检索到的上下文生成的响应。通过将响应分解为单独的句子，并利用多个模型针对给定的一组问题、响应和相关上下文生成“是”令牌的概率，可以检测到幻觉。

Result: 结果表明，在检测正确响应方面，F1 分数提高了 10%，与幻觉相比。

Conclusion: 多个小型语言模型可以有效地用于答案验证，为学术和实际应用提供可扩展且高效的解决方案。

Abstract: Since the introduction of ChatGPT, large language models (LLMs) have
demonstrated significant utility in various tasks, such as answering questions
through retrieval-augmented generation. Context can be retrieved using a
vectorized database, serving as a foundation for LLMs to generate responses.
However, hallucinations in responses can undermine the reliability of LLMs in
practical applications, and they are not easily detectable in the absence of
ground truth, particularly in question-and-answer scenarios. This paper
proposes a framework that integrates multiple small language models to verify
responses generated by LLMs using the retrieved context from a vectorized
database. By breaking down the responses into individual sentences and
utilizing the probability of generating "Yes" tokens from the outputs of
multiple models for a given set of questions, responses, and relevant context,
hallucinations can be detected. The proposed framework is validated through
experiments with real datasets comprising over 100 sets of questions, answers,
and contexts, including responses with fully and partially correct sentences.
The results demonstrate a 10\% improvement in F1 scores for detecting correct
responses compared to hallucinations, indicating that multiple small language
models can be effectively employed for answer verification, providing a
scalable and efficient solution for both academic and practical applications.

</details>


### [4] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

Main category: cs.CL

TL;DR: PromptAug, an LLM-based data augmentation method, improves accuracy and F1-score on conflict and emotion datasets by 2%.


<details>
  <summary>Details</summary>
Motivation: High-quality labelled data for identifying conflict behaviours is limited, expensive, and difficult to obtain. Social media platforms increasingly restrict access to research data, text data augmentation is gaining attention as an alternative to generate training data. Augmenting conflict-related data poses unique challenges due to Large Language Model (LLM) guardrails that prevent generation of offensive content.

Method: an innovative LLM-based data augmentation method called PromptAug

Result: PromptAug achieves statistically significant improvements of 2% in both accuracy and F1-score on conflict and emotion datasets. The thematic analysis identifies four problematic patterns in augmented text: Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and Augmented Content Misinterpretation.

Conclusion: This work presents PromptAug as an effective method for augmenting data in sensitive tasks like conflict detection.

Abstract: Given the rise of conflicts on social media, effective classification models
to detect harmful behaviours are essential. Following the
garbage-in-garbage-out maxim, machine learning performance depends heavily on
training data quality. However, high-quality labelled data, especially for
nuanced tasks like identifying conflict behaviours, is limited, expensive, and
difficult to obtain. Additionally, as social media platforms increasingly
restrict access to research data, text data augmentation is gaining attention
as an alternative to generate training data. Augmenting conflict-related data
poses unique challenges due to Large Language Model (LLM) guardrails that
prevent generation of offensive content. This paper introduces PromptAug, an
innovative LLM-based data augmentation method. PromptAug achieves statistically
significant improvements of 2% in both accuracy and F1-score on conflict and
emotion datasets. To thoroughly evaluate PromptAug against other data
augmentation methods we conduct a robust evaluation using extreme data scarcity
scenarios, quantitative diversity analysis and a qualitative thematic analysis.
The thematic analysis identifies four problematic patterns in augmented text:
Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and
Augmented Content Misinterpretation.
  Overall, this work presents PromptAug as an effective method for augmenting
data in sensitive tasks like conflict detection, offering a unique,
interdisciplinary evaluation grounded in both natural language processing and
social science methodology.

</details>


### [5] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: The paper introduces AgentStealth, a self-reinforcing LLM anonymization framework that uses locally deployed smaller-scale language models (SLMs) to improve anonymization effectiveness and utility while avoiding cloud reliance and privacy risks.


<details>
  <summary>Details</summary>
Motivation: Existing text anonymization methods either damage utility or rely on costly and privacy-risky cloud-based LLMs. Training effective smaller-scale language models (SLMs) for anonymization is challenging due to limited high-quality supervision.

Method: The paper proposes AgentStealth, a self-reinforcing LLM anonymization framework that includes an adversarial anonymization workflow enhanced by In-context Contrastive Learning and Adaptive Utility-Aware Control. It performs supervised adaptation of SLMs using high-quality data collected from the workflow, and applies online reinforcement learning.

Result: Experiments on two datasets show that AgentStealth outperforms baselines in both anonymization effectiveness (+12.3%) and utility (+6.8%).

Conclusion: The proposed AgentStealth framework outperforms baselines in both anonymization effectiveness and utility. The lightweight design supports direct deployment on edge devices, avoiding cloud reliance and communication-based privacy risks.

Abstract: In today's digital world, casual user-generated content often contains subtle
cues that may inadvertently expose sensitive personal attributes. Such risks
underscore the growing importance of effective text anonymization to safeguard
individual privacy. However, existing methods either rely on rigid replacements
that damage utility or cloud-based LLMs that are costly and pose privacy risks.
To address these issues, we explore the use of locally deployed smaller-scale
language models (SLMs) for anonymization. Yet training effective SLMs remains
challenging due to limited high-quality supervision. To address the challenge,
we propose AgentStealth, a self-reinforcing LLM anonymization framework.First,
we introduce an adversarial anonymization workflow enhanced by In-context
Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform
supervised adaptation of SLMs using high-quality data collected from the
workflow, which includes both anonymization and attack signals. Finally, we
apply online reinforcement learning where the model leverages its internal
adversarial feedback to iteratively improve anonymization performance.
Experiments on two datasets show that our method outperforms baselines in both
anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight
design supports direct deployment on edge devices, avoiding cloud reliance and
communication-based privacy risks. Our code is open-source at
https://github.com/tsinghua-fib-lab/AgentStealth.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的图像对齐框架，用于更准确地监测建筑物裂缝，即使在具有挑战性的现实条件下也是如此。


<details>
  <summary>Details</summary>
Motivation: 精确的图像对齐对于监测结构健康监测 (SHM) 中的裂缝演变至关重要，尤其是在涉及透视畸变、遮挡和低对比度的真实条件下。然而，传统的特征检测器（例如 SIFT 和 SURF）依赖于基于高斯的尺度空间，往往会抑制高频边缘，使其不适合于细裂纹定位。轻量级二值替代方案（如 ORB 和 BRISK）虽然计算效率高，但通常在纹理或阴影表面上的关键点重复性较差。

Method: 该研究提出了一种基于物理信息的对齐框架，该框架采用开放的KAZE架构来应对SHM的特定挑战。通过利用非线性各向异性扩散来构建裂缝保持尺度空间，并集成基于RANSAC的单应性估计，该框架无需训练、参数调整或事先校准即可实现精确的几何校正。

Result: 与经典检测器相比，所提出的框架可将裂纹面积和脊柱长度误差分别降低高达 70% 和 90%，同时在关键指标中保持低于 5% 的对齐误差。该方法是无监督的、可解释的且计算量轻，支持通过无人机和移动平台进行可扩展部署。

Conclusion: 该研究通过定制非线性尺度空间建模来适应SHM图像对齐，为跟踪真实裂缝演变提供了一种稳健且物理基础的替代方案，优于传统技术。

Abstract: Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [7] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

TL;DR: This paper presents a new method for evaluating the confidence of pest counting in images, using image analysis and a regression model, leading to more reliable results.


<details>
  <summary>Details</summary>
Motivation: Existing pest counting models lack reliability assessment in real-world scenarios due to the absence of ground truth data.

Method: The method involves pest detection, image quality assessment, image complexity assessment, pest distribution uniformity assessment using adaptive DBSCAN, and a regression model to predict pest counting confidence.

Result: The proposed method reduces MSE by 31.7% and improves R2 by 15.2% on the pest counting confidence test set.

Conclusion: This paper introduces a method to comprehensively evaluate pest counting confidence by considering counting results and external environmental conditions, achieving improved MSE and R2 scores compared to the baseline.

Abstract: Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [8] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

TL;DR: This paper combines natural language and drag-and-drop interfaces for robot task specification, finding that larger language models perform better but smaller ones are still satisfactory.


<details>
  <summary>Details</summary>
Motivation: Robot end users require accessible means of specifying tasks. Natural language and drag-and-drop interfaces are two common end-user programming paradigms.  This paper investigates combining both approaches.

Method: Construct a large language model (LLM)-based pipeline that accepts natural language as input and produces human-like action sequences as output, specified at a level of granularity that a human would produce.  Compare these generated action sequences to another dataset of hand-specified action sequences.

Result: Larger models tend to outperform smaller ones in the production of human-like action sequences.

Conclusion: Smaller models achieve satisfactory performance, while larger models outperform smaller ones in producing human-like action sequences.

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [9] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

TL;DR: Ludax, a domain-specific language for board games, compiles into hardware-accelerated code, combining the generality of game description languages with the speed of modern parallel processing hardware. It accelerates games research and is open-source.


<details>
  <summary>Details</summary>
Motivation: Games have long been used as benchmarks and testing environments for research in artificial intelligence. Libraries like JAX allow practitioners to take full advantage of cutting-edge computing hardware, often speeding up training and testing by orders of magnitude.

Method: A domain-specific language for board games which automatically compiles into hardware-accelerated code.

Result: The paper presents a detailed breakdown of Ludax's description language and technical notes on the compilation process, along with speed benchmarking and a demonstration of training RL agents.

Conclusion: The Ludax framework accelerates games research, from RL to cognitive science, by enabling rapid simulation and providing a flexible representation scheme. The Ludax framework, along with implementations of existing board games, is open-source and freely available.

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [10] [GaussMaster: An LLM-based Database Copilot System](https://arxiv.org/abs/2506.23322)
*Wei Zhou,Ji Sun,Xuanhe Zhou,Guoliang Li,Luyang Liu,Hao Wu,Tianyuan Wang*

Main category: cs.DB

TL;DR: GaussMaster, an LLM-based database copilot, automates database maintenance with zero human intervention in banking scenarios, outperforming existing platforms.


<details>
  <summary>Details</summary>
Motivation: Existing autonomous database platforms are limited in their capabilities, primarily addressing single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual intervention remains a necessity for comprehensive database maintenance.

Method: Employing a Tree-of-thought approach to identify root causes, and invoking appropriate tools to resolve issues by analyzing hundreds of metrics and logs.

Result: GaussMaster assists developers in writing efficient SQL queries and provides comprehensive care for database services. It has achieved zero human intervention for over 34 database maintenance scenarios in the banking industry.

Conclusion: GaussMaster, an LLM-based database copilot system, achieves zero human intervention for over 34 database maintenance scenarios in the banking industry.

Abstract: In the financial industry, data is the lifeblood of operations, and DBAs
shoulder significant responsibilities for SQL tuning, database deployment,
diagnosis, and service repair. In recent years, both database vendors and
customers have increasingly turned to autonomous database platforms in an
effort to alleviate the heavy workload of DBAs. However, existing autonomous
database platforms are limited in their capabilities, primarily addressing
single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual
intervention remains a necessity for comprehensive database maintenance.
GaussMaster aims to revolutionize this landscape by introducing an LLM-based
database copilot system. This innovative solution is designed not only to
assist developers in writing efficient SQL queries but also to provide
comprehensive care for database services. When database instances exhibit
abnormal behavior, GaussMaster is capable of orchestrating the entire
maintenance process automatically. It achieves this by analyzing hundreds of
metrics and logs, employing a Tree-of-thought approach to identify root causes,
and invoking appropriate tools to resolve issues. We have successfully
implemented GaussMaster in real-world scenarios, such as the banking industry,
where it has achieved zero human intervention for over 34 database maintenance
scenarios. In this paper, we present significant improvements in these tasks
with code at https://gitcode.com/opengauss/openGauss-GaussMaster.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [11] [Interact2Vec -- An efficient neural network-based model for simultaneously learning users and items embeddings in recommender systems](https://arxiv.org/abs/2506.22648)
*Pedro R. Pires,Tiago A. Almeida*

Main category: cs.IR

TL;DR: Interact2Vec 是一种新颖的神经网络模型，可同时学习用户和项目的嵌入，从而在推荐任务中实现有竞争力的结果，并且与其他基于嵌入的模型相比，训练时间减少了 274%。


<details>
  <summary>Details</summary>
Motivation: 推荐系统面临着具有挑战性的问题，例如高数据维度和稀疏性。将用户和项目表示为通过神经网络学习的低维嵌入已成为一种领先的解决方案。然而，虽然最近的研究显示出有希望的结果，但许多方法依赖于复杂的架构或需要内容数据，而内容数据可能并不总是可用的。

Method: Interact2Vec，一种新颖的基于神经网络的模型，它同时学习用户和项目的分布式嵌入，同时仅需要隐式反馈。该模型采用了自然语言处理模型常用的最新策略来优化训练阶段并增强最终嵌入。

Result: Interact2Vec 在 30% 的数据集中取得了第二或第三好的结果，与其他推荐器相比具有竞争力，并且已被证明非常有效，与其他基于嵌入的模型相比，平均训练时间减少了 274%。

Conclusion: Interact2Vec 能够取得有希望的结果，特别是在外在任务上，并且对于计算资源稀缺的场景来说，是一种极好的嵌入生成模型，能够同时有效地学习项目和用户嵌入。

Abstract: Over the past decade, recommender systems have experienced a surge in
popularity. Despite notable progress, they grapple with challenging issues,
such as high data dimensionality and sparseness. Representing users and items
as low-dimensional embeddings learned via neural networks has become a leading
solution. However, while recent studies show promising results, many approaches
rely on complex architectures or require content data, which may not always be
available. This paper presents Interact2Vec, a novel neural network-based model
that simultaneously learns distributed embeddings for users and items while
demanding only implicit feedback. The model employs state-of-the-art strategies
that natural language processing models commonly use to optimize the training
phase and enhance the final embeddings. Two types of experiments were conducted
regarding the extrinsic and intrinsic quality of the model. In the former, we
benchmarked the recommendations generated by Interact2Vec's embeddings in a
top-$N$ ranking problem, comparing them with six other recommender algorithms.
The model achieved the second or third-best results in 30\% of the datasets,
being competitive with other recommenders, and has proven to be very efficient
with an average training time reduction of 274\% compared to other
embedding-based models. Later, we analyzed the intrinsic quality of the
embeddings through similarity tables. Our findings suggest that Interact2Vec
can achieve promising results, especially on the extrinsic task, and is an
excellent embedding-generator model for scenarios of scarce computing
resources, enabling the learning of item and user embeddings simultaneously and
efficiently.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [12] [Latent Factorization of Tensors with Threshold Distance Weighted Loss for Traffic Data Estimation](https://arxiv.org/abs/2506.22441)
*Lei Yang*

Main category: cs.LG

TL;DR: 提出了一种新的TDW-LFT模型，通过对样本进行加权来减少离群值的影响，实验表明，该模型在预测精度和计算效率方面优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统 (ITS) 严重依赖完整且高质量的时空交通数据来实现最佳性能。然而，在实际的交通数据收集过程中，通信故障和传感器故障等问题经常导致数据集不完整或损坏，从而对 ITS 的发展构成重大挑战。

Method: 提出了一种结合阈值距离加权（TDW）损失的张量潜在因子分解（TDWLFT）模型。

Result: 在来自不同城市环境的两个交通速度数据集上进行的大量实验证实

Conclusion: TDWLFT模型在预测精度和计算效率方面始终优于最先进的方法。

Abstract: Intelligent transportation systems (ITS) rely heavily on complete and
high-quality spatiotemporal traffic data to achieve optimal performance.
Nevertheless, in real-word traffic data collection processes, issues such as
communication failures and sensor malfunctions often lead to incomplete or
corrupted datasets, thereby posing significant challenges to the advancement of
ITS. Among various methods for imputing missing spatiotemporal traffic data,
the latent factorization of tensors (LFT) model has emerged as a widely adopted
and effective solution. However, conventional LFT models typically employ the
standard L2-norm in their learning objective, which makes them vulnerable to
the influence of outliers. To overcome this limitation, this paper proposes a
threshold distance weighted (TDW) loss-incorporated Latent Factorization of
Tensors (TDWLFT) model. The proposed loss function effectively reduces the
model's sensitivity to outliers by assigning differentiated weights to
individual samples. Extensive experiments conducted on two traffic speed
datasets sourced from diverse urban environments confirm that the proposed
TDWLFT model consistently outperforms state-of-the-art approaches in terms of
both in both prediction accuracy and computational efficiency.

</details>


### [13] [Features-based embedding or Feature-grounding](https://arxiv.org/abs/2506.22442)
*Piotr Makarevich*

Main category: cs.LG

TL;DR: This paper introduces a feature-grounded embedding approach to reproduce knowledge-based structured thinking in deep learning models.


<details>
  <summary>Details</summary>
Motivation: Reproducing knowledge-based structured thinking in deep learning models using feature based embeddings.

Method: an specific approach to build feature-grounded embedding

Result: The paper investigates how knowledge-based structured thinking can be reproduced in deep learning models.

Conclusion: This paper introduces a feature-grounded embedding approach to align shareable representations of operable dictionary with interpretable domain-specific conceptual features.

Abstract: In everyday reasoning, when we think about a particular object, we associate
it with a unique set of expected properties such as weight, size, or more
abstract attributes like density or horsepower. These expectations are shaped
by our prior knowledge and the conceptual categories we have formed through
experience. This paper investigates how such knowledge-based structured
thinking can be reproduced in deep learning models using features based
embeddings. Specially, it introduces an specific approach to build
feature-grounded embedding, aiming to align shareable representations of
operable dictionary with interpretable domain-specific conceptual features.

</details>


### [14] [Task-Agnostic Contrastive Pretraining for Relational Deep Learning](https://arxiv.org/abs/2506.22530)
*Jakub Peleška,Gustav Šír*

Main category: cs.LG

TL;DR: propose a novel task-agnostic contrastive pretraining approach for RDL that enables database-wide representation learning


<details>
  <summary>Details</summary>
Motivation: existing RDL models typically rely on task-specific supervised learning, requiring training separate models for each predictive task, which may hamper scalability and reuse.

Method: a novel task-agnostic contrastive pretraining approach for RDL that enables database-wide representation learning. For that aim, we introduce three levels of contrastive objectives$-$row-level, link-level, and context-level$-$designed to capture the structural and semantic heterogeneity inherent to relational data. We implement the respective pretraining approach through a modular RDL architecture and an efficient sampling strategy tailored to the heterogeneous database setting.

Result: preliminary results on standard RDL benchmarks demonstrate that fine-tuning the pretrained models measurably outperforms training from scratch

Conclusion: fine-tuning the pretrained models measurably outperforms training from scratch, validating the promise of the proposed methodology in learning transferable representations for relational data.

Abstract: Relational Deep Learning (RDL) is an emerging paradigm that leverages Graph
Neural Network principles to learn directly from relational databases by
representing them as heterogeneous graphs. However, existing RDL models
typically rely on task-specific supervised learning, requiring training
separate models for each predictive task, which may hamper scalability and
reuse.
  In this work, we propose a novel task-agnostic contrastive pretraining
approach for RDL that enables database-wide representation learning. For that
aim, we introduce three levels of contrastive objectives$-$row-level,
link-level, and context-level$-$designed to capture the structural and semantic
heterogeneity inherent to relational data. We implement the respective
pretraining approach through a modular RDL architecture and an efficient
sampling strategy tailored to the heterogeneous database setting. Our
preliminary results on standard RDL benchmarks demonstrate that fine-tuning the
pretrained models measurably outperforms training from scratch, validating the
promise of the proposed methodology in learning transferable representations
for relational data.

</details>
