<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 44]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.IR](#cs.IR) [Total: 12]
- [cs.LG](#cs.LG) [Total: 43]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Novel Differential Feature Learning for Effective Hallucination Detection and Classification](https://arxiv.org/abs/2509.21357)
*Wenkai Wang,Vincent Lee,Yizhen Zheng*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）的幻觉问题是一个挑战，因为其输出会因训练数据中的分布偏差而偏离事实准确性。该研究旨在精确定位层内幻觉信号的位置，从而开发高效的检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，特定隐藏层在幻觉内容和事实内容之间存在差异，但层内幻觉信号的具体位置仍不清楚，这限制了高效检测方法的发展。

Method: 该论文提出了一种双模型架构，该架构集成了用于自适应层间特征加权的投影融合（PF）模块和差分特征学习（DFL）机制，该机制通过计算并行编码器之间的差异来识别判别特征，这些并行编码器从相同的输入中学习互补的表示。

Result: 实验表明，幻觉信号集中在高度稀疏的特征子集中，从而显著提高了问答和对话任务的准确性。浅层表现出高特征多样性，而深层表现出集中使用，仅使用 1% 的特征维度即可维持检测性能。

Conclusion: 研究结果表明，幻觉信号比以前认为的更集中，这为计算高效的检测系统提供了一条途径，该系统可以降低推理成本，同时保持准确性。

Abstract: Large language model hallucination represents a critical challenge where
outputs deviate from factual accuracy due to distributional biases in training
data. While recent investigations establish that specific hidden layers exhibit
differences between hallucinatory and factual content, the precise localization
of hallucination signals within layers remains unclear, limiting the
development of efficient detection methods. We propose a dual-model
architecture integrating a Projected Fusion (PF) block for adaptive inter-layer
feature weighting and a Differential Feature Learning (DFL) mechanism that
identifies discriminative features by computing differences between parallel
encoders learning complementary representations from identical inputs. Through
systematic experiments across HaluEval's question answering, dialogue, and
summarization datasets, we demonstrate that hallucination signals concentrate
in highly sparse feature subsets, achieving significant accuracy improvements
on question answering and dialogue tasks. Notably, our analysis reveals a
hierarchical "funnel pattern" where shallow layers exhibit high feature
diversity while deep layers demonstrate concentrated usage, enabling detection
performance to be maintained with minimal degradation using only 1\% of feature
dimensions. These findings suggest that hallucination signals are more
concentrated than previously assumed, offering a pathway toward computationally
efficient detection systems that could reduce inference costs while maintaining
accuracy.

</details>


### [2] [Influence Guided Context Selection for Effective Retrieval-Augmented Generation](https://arxiv.org/abs/2509.21359)
*Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的上下文选择方法，通过评估移除每个上下文后性能的下降来量化上下文质量，从而提高检索增强生成（RAG）的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文选择方法在全面利用可用信息进行质量评估方面存在局限性，导致RAG效果提升有限。

Method: 该论文将上下文质量评估重新定义为推理时的数据估值问题，并引入上下文影响值（CI值）。CI值通过测量移除每个上下文后性能的下降来量化上下文质量，并使用参数化的代理模型进行CI值预测。

Result: 在8个NLP任务和多个LLM上的大量实验表明，该上下文选择方法显著优于现有技术水平的基线。

Conclusion: 该方法通过有效过滤低质量上下文并保留关键信息，显著提高了RAG的性能。

Abstract: Retrieval-Augmented Generation (RAG) addresses large language model (LLM)
hallucinations by grounding responses in external knowledge, but its
effectiveness is compromised by poor-quality retrieved contexts containing
irrelevant or noisy information. While existing approaches attempt to improve
performance through context selection based on predefined context quality
assessment metrics, they show limited gains over standard RAG. We attribute
this limitation to their failure in holistically utilizing available
information (query, context list, and generator) for comprehensive quality
assessment. Inspired by recent advances in data selection, we reconceptualize
context quality assessment as an inference-time data valuation problem and
introduce the Contextual Influence Value (CI value). This novel metric
quantifies context quality by measuring the performance degradation when
removing each context from the list, effectively integrating query-aware
relevance, list-aware uniqueness, and generator-aware alignment. Moreover, CI
value eliminates complex selection hyperparameter tuning by simply retaining
contexts with positive CI values. To address practical challenges of label
dependency and computational overhead, we develop a parameterized surrogate
model for CI value prediction during inference. The model employs a
hierarchical architecture that captures both local query-context relevance and
global inter-context interactions, trained through oracle CI value supervision
and end-to-end generator feedback. Extensive experiments across 8 NLP tasks and
multiple LLMs demonstrate that our context selection method significantly
outperforms state-of-the-art baselines, effectively filtering poor-quality
contexts while preserving critical information. Code is available at
https://github.com/SJTU-DMTai/RAG-CSM.

</details>


### [3] [Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs](https://arxiv.org/abs/2509.21361)
*Norman Paulsen*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)的最大有效上下文窗口(MECW)远小于其宣称的最大上下文窗口(MCW)，并且MECW因问题类型而异。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型上下文窗口的实际使用情况，因为提供商通常宣传很大的数字，但实际效果可能不佳。

Method: 1) 定义最大有效上下文窗口的概念；2) 制定测试方法，评估不同大小和问题类型下上下文窗口的有效性；3) 创建标准化方法，比较模型在越来越大的上下文窗口大小下的功效，以找到失效点。

Result: 发现报告的最大上下文窗口(MCW)大小和最大有效上下文窗口(MECW)大小之间存在显著差异。一些顶级模型在上下文中只有100个token时就失败了；大多数模型在上下文中1000个token时，准确性严重下降。所有模型都远未达到其最大上下文窗口，差距高达99%。

Conclusion: 最大有效上下文窗口因提供的问题类型而异，这为如何提高模型准确性并降低模型幻觉率提供了清晰且可操作的见解。

Abstract: Large language model (LLM) providers boast big numbers for maximum context
window sizes. To test the real world use of context windows, we 1) define a
concept of maximum effective context window, 2) formulate a testing method of a
context window's effectiveness over various sizes and problem types, and 3)
create a standardized way to compare model efficacy for increasingly larger
context window sizes to find the point of failure. We collected hundreds of
thousands of data points across several models and found significant
differences between reported Maximum Context Window (MCW) size and Maximum
Effective Context Window (MECW) size. Our findings show that the MECW is, not
only, drastically different from the MCW but also shifts based on the problem
type. A few top of the line models in our test group failed with as little as
100 tokens in context; most had severe degradation in accuracy by 1000 tokens
in context. All models fell far short of their Maximum Context Window by as
much as 99 percent. Our data reveals the Maximum Effective Context Window
shifts based on the type of problem provided, offering clear and actionable
insights into how to improve model accuracy and decrease model hallucination
rates.

</details>


### [4] [How Large Language Models Need Symbolism](https://arxiv.org/abs/2509.21404)
*Xiaotie Deng,Hanyu Li*

Main category: cs.CL

TL;DR: AI需要超越扩展，利用人工设计的符号来指导其直觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要人类设计的符号来引导，以实现真正的发现。

Method: 探讨大型语言模型结合人工符号的方法。

Result: AI的未来需要更多，需要人类设计的符号。

Conclusion: 为了实现真正的发现，大型语言模型需要人工设计的符号来引导其直觉。

Abstract: We argue that AI's future requires more than scaling. To unlock genuine
discovery, large language models need a compass: human-crafted symbols to guide
their powerful but blind intuition.

</details>


### [5] [A State-of-the-Art SQL Reasoning Model using RLVR](https://arxiv.org/abs/2509.21459)
*Alnur Ali,Ashutosh Baheti,Jonathan Chang,Ta-Chung Chi,Brandon Cui,Andrew Drozdov,Jonathan Frankle,Abhay Gupta,Pallavi Koppol,Sean Kulinski,Jonathan Li,Dipendra Misra,Krista Opsahl-Ong,Jose Javier Gonzalez Ortiz,Matei Zaharia,Yue Zhang*

Main category: cs.CL

TL;DR: 使用强化学习（RL）开发定制推理模型，结合组织特定知识，有潜力解决企业客户面临的问题。将RL与可验证奖励（RLVR）应用于BIRD，这是一个衡量AI代理将自然语言查询转换为SQL执行能力的流行数据科学基准。在没有额外训练数据和专有模型的情况下，我们的模型在BIRD排行榜上达到了最先进的准确率：不使用自我一致性为73.56%，使用自我一致性为75.68%。


<details>
  <summary>Details</summary>
Motivation: 企业客户面临的问题可以使用结合组织特定知识的定制推理模型来解决。许多问题具有可验证的奖励函数，可以使用RLVR。

Method: 应用RLVR到一个流行的数据科学基准BIRD。使用一个简单通用的训练方法，包括提示和模型选择，使用离线RL方法TAO的预热阶段，以及严格的在线RLVR训练。

Result: 在BIRD排行榜上达到了最先进的准确率：不使用自我一致性为73.56%，使用自我一致性为75.68%。

Conclusion: 该框架的简单性使其广泛适用于商业智能、数据科学和编码等企业领域。

Abstract: Developing custom reasoning models via Reinforcement Learning (RL) that can
incorporate organization-specific knowledge has great potential to address
problems faced by enterprise customers. In many of these problems, the reward
function is verifiable, a setting termed RL with Verifiable Rewards (RLVR). We
apply RLVR to a popular data science benchmark called BIRD that measures the
ability of an AI agent to convert a natural language query for a database to
SQL executions. We apply a simple and general-purpose training recipe involving
careful prompt and model selection, a warm-up stage using our offline RL
approach called TAO, followed by rigorous online RLVR training. With no
additional training data beyond the BIRD training set and no use of proprietary
models, our very first submission to the BIRD leaderboard reached
state-of-the-art accuracy on the private test set: 73.56% without
self-consistency and 75.68% with self-consistency. In the latter case, our
model also required fewer generations than the second-best approach. While BIRD
is only a proxy task, the simplicity of our framework makes it broadly
applicable to enterprise domains such as business intelligence, data science,
and coding.

</details>


### [6] [One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning](https://arxiv.org/abs/2509.21443)
*Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens*

Main category: cs.CL

TL;DR: LLMs在道德推理方面存在跨语言和文化的不一致性。


<details>
  <summary>Details</summary>
Motivation: LLMs主要在英语数据上进行预训练，这引发了它们在不同语言和文化背景下泛化判断能力的担忧。

Method: 将两个已建立的道德推理基准翻译成五种文化和类型上不同的语言，从而实现多语言零样本评估。

Result: LLMs的道德判断在不同语言之间存在显着不一致，通常反映出文化上的不一致。

Conclusion: 论文总结了一个道德推理错误结构化类型，呼吁更多具有文化意识的AI。

Abstract: Large Language Models (LLMs) are increasingly deployed in multilingual and
multicultural environments where moral reasoning is essential for generating
ethically appropriate responses. Yet, the dominant pretraining of LLMs on
English-language data raises critical concerns about their ability to
generalize judgments across diverse linguistic and cultural contexts. In this
work, we systematically investigate how language mediates moral decision-making
in LLMs. We translate two established moral reasoning benchmarks into five
culturally and typologically diverse languages, enabling multilingual zero-shot
evaluation. Our analysis reveals significant inconsistencies in LLMs' moral
judgments across languages, often reflecting cultural misalignment. Through a
combination of carefully constructed research questions, we uncover the
underlying drivers of these disparities, ranging from disagreements to
reasoning strategies employed by LLMs. Finally, through a case study, we link
the role of pretraining data in shaping an LLM's moral compass. Through this
work, we distill our insights into a structured typology of moral reasoning
errors that calls for more culturally-aware AI.

</details>


### [7] [LLM-Based Support for Diabetes Diagnosis: Opportunities, Scenarios, and Challenges with GPT-5](https://arxiv.org/abs/2509.21450)
*Gaurav Kumar Gupta,Nirajan Acharya,Pranal Pande*

Main category: cs.CL

TL;DR: 本研究探讨了使用 GPT-5 协助糖尿病诊断和管理


<details>
  <summary>Details</summary>
Motivation: 糖尿病诊断面临挑战，现有方法难以有效识别早期病例

Method: 利用模拟框架，基于 ADA 标准和公共数据集对 GPT-5 进行了评估

Result: GPT-5 在多种糖尿病相关场景中表现出与 ADA 标准的高度一致性

Conclusion: GPT-5 有潜力成为临床医生和患者的双重工具，同时强调了在医疗保健领域负责任地评估 LLM 的重要性

Abstract: Diabetes mellitus is a major global health challenge, affecting over half a
billion adults worldwide with prevalence projected to rise. Although the
American Diabetes Association (ADA) provides clear diagnostic thresholds, early
recognition remains difficult due to vague symptoms, borderline laboratory
values, gestational complexity, and the demands of long-term monitoring.
Advances in large language models (LLMs) offer opportunities to enhance
decision support through structured, interpretable, and patient-friendly
outputs. This study evaluates GPT-5, the latest generative pre-trained
transformer, using a simulation framework built entirely on synthetic cases
aligned with ADA Standards of Care 2025 and inspired by public datasets
including NHANES, Pima Indians, EyePACS, and MIMIC-IV. Five representative
scenarios were tested: symptom recognition, laboratory interpretation,
gestational diabetes screening, remote monitoring, and multimodal complication
detection. For each, GPT-5 classified cases, generated clinical rationales,
produced patient explanations, and output structured JSON summaries. Results
showed strong alignment with ADA-defined criteria, suggesting GPT-5 may
function as a dual-purpose tool for clinicians and patients, while underscoring
the importance of reproducible evaluation frameworks for responsibly assessing
LLMs in healthcare.

</details>


### [8] [Diagnosing the Performance Trade-off in Moral Alignment: A Case Study on Gender Stereotypes](https://arxiv.org/abs/2509.21456)
*Guangliang Liu,Bocheng Chen,Xitong Zhang,Kristen Marie Johnson*

Main category: cs.CL

TL;DR: 道德对齐通常会降低PLM的下游任务性能。本文研究了在减轻性别歧视的背景下，性能权衡的潜在机制，通过遗忘和公平性目标进行分析。


<details>
  <summary>Details</summary>
Motivation: 道德对齐作为一种调节PLM行为的方法被广泛采用，但通常会降低下游任务的性能。

Method: 通过遗忘和公平性目标的角度，研究在减轻性别歧视的情况下，性能权衡的潜在机制。

Result: 下游任务的性能主要由整体遗忘水平驱动；选择性遗忘刻板印象会增加整体遗忘；缓解遗忘的通用解决方案无法减少整体遗忘，也无法提高下游任务的性能。

Conclusion: 目前的公平性目标在实现权衡方面存在局限性。

Abstract: Moral alignment has emerged as a widely adopted approach for regulating the
behavior of pretrained language models (PLMs), typically through fine-tuning or
model editing on curated datasets. However, this process often comes at the
cost of degraded downstream task performance. Prior studies commonly aim to
achieve a performance trade-off by encouraging PLMs to selectively forget
stereotypical knowledge through carefully designed fairness objectives, while
preserving their helpfulness. In this short paper, we investigate the
underlying mechanisms of the performance trade-off in the context of mitigating
gender stereotypes, through the lens of forgetting and the fairness objective.
Our analysis reveals the limitations of current fairness objective in achieving
trade-off by demonstrating that: (1) downstream task performance is primarily
driven by the overall forgetting level; (2) selective forgetting of stereotypes
tends to increase overall forgetting; and (3) general solutions for mitigating
forgetting are ineffective at reducing overall forgetting and fail to improve
downstream task performance.

</details>


### [9] [Learning to Reason with Mixture of Tokens](https://arxiv.org/abs/2509.21482)
*Adit Jain,Brendan Rappazzo*

Main category: cs.CL

TL;DR: 本文提出了一种在可验证奖励的强化学习（RLVR）中利用混合token生成（MoT-G）的方法，以提升大型语言模型（LLM）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法在推理的每一步都采样离散token，忽略了模型概率分布中丰富的分布信息，限制了推理搜索空间。

Method: 提出了一个统一的框架，推广了现有的MoT-G方法，并扩展了RLVR，使其能够直接在这个连续混合空间中生成思维链。

Result: 在Reasoning-Gym上的评估表明，MoT-G方法在10个任务中的7个上取得了显著的改进（5-35%的提升），并且达到相当的精度所需的轨迹数量减半，表明训练效率得到提高。

Conclusion: MoT-G的优势可能源于其在整个推理过程中维持更高的隐藏状态熵以及促进token空间中的探索的能力。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a leading
approach for improving large language model (LLM) reasoning capabilities. Most
current methods follow variants of Group Relative Policy Optimization, which
samples multiple reasoning completions, scores them relative to each other, and
adjusts the policy accordingly. However, these approaches invariably sample
discrete tokens at each reasoning step, discarding the rich distributional
information in the model's probability distribution over candidate tokens.
While preserving and utilizing this distributional information has proven
beneficial in non-RL settings, current RLVR methods seem to be unnecessarily
constraining the reasoning search space by not using this information. To
address this limitation, we investigate mixture-of-token generation (MoT-G) in
RLVR. We present a unified framework that generalizes existing MoT-G
approaches, including existing training-free methods that construct mixture
embeddings as weighted sums over token embeddings, and extend RLVR to operate
directly in this continuous mixture space for generating chain-of-thought.
Evaluating two MoT-G variants on Reasoning-Gym, a suite of reasoning-intensive
language tasks, we find that MoT--G methods achieve substantial improvements
(5--35 \% gains on 7 out of 10 tasks) compared to standard decoding with the
Qwen2.5-1.5B model, while reaching comparable accuracy with half the number of
trajectories, suggesting improved training efficiency. Through comprehensive
hidden-state and token-level analyses, we provide evidence that MoT--G's
benefits may stem from its ability to maintain higher hidden-state entropy
throughout the reasoning process and promote exploration in token space.

</details>


### [10] [FoodSEM: Large Language Model Specialized in Food Named-Entity Linking](https://arxiv.org/abs/2509.22125)
*Ana Gjorgjevikj,Matej Martinc,Gjorgjina Cenikj,Sašo Džeroski,Barbara Koroušić Seljak,Tome Eftimov*

Main category: cs.CL

TL;DR: FoodSEM 是一个用于食品相关命名实体链接 (NEL) 的微调开源大型语言模型 (LLM)，在某些本体和数据集上的 F1 分数甚至达到 98%。


<details>
  <summary>Details</summary>
Motivation: 现有的通用或领域特定模型无法准确解决食品 NEL 任务。

Method: 通过指令-响应 (IR) 场景，FoodSEM 将文本中提到的食品相关实体链接到多个本体，包括 FoodOn、SNOMED-CT 和 Hansard 分类法。

Result: FoodSEM 模型与相关模型/系统相比，实现了最先进的性能，在某些本体和数据集上的 F1 分数甚至达到 98%。

Conclusion: 发布食品注释语料库、强大的模型和食品 NEL 基准，以促进食品领域文本的语义理解。

Abstract: This paper introduces FoodSEM, a state-of-the-art fine-tuned open-source
large language model (LLM) for named-entity linking (NEL) to food-related
ontologies. To the best of our knowledge, food NEL is a task that cannot be
accurately solved by state-of-the-art general-purpose (large) language models
or custom domain-specific models/systems. Through an instruction-response (IR)
scenario, FoodSEM links food-related entities mentioned in a text to several
ontologies, including FoodOn, SNOMED-CT, and the Hansard taxonomy. The FoodSEM
model achieves state-of-the-art performance compared to related models/systems,
with F1 scores even reaching 98% on some ontologies and datasets. The presented
comparative analyses against zero-shot, one-shot, and few-shot LLM prompting
baselines further highlight FoodSEM's superior performance over its
non-fine-tuned version. By making FoodSEM and its related resources publicly
available, the main contributions of this article include (1) publishing a
food-annotated corpora into an IR format suitable for LLM
fine-tuning/evaluation, (2) publishing a robust model to advance the semantic
understanding of text in the food domain, and (3) providing a strong baseline
on food NEL for future benchmarking.

</details>


### [11] [Dual-Head Reasoning Distillation: Improving Classifier Accuracy with Train-Time-Only Reasoning](https://arxiv.org/abs/2509.21487)
*Jillian Xu,Dylan Zhou,Vinay Shukla,Yang Yang,Junrui Ruan,Shuhuai Lin,Wenfei Zou,Yinxiao Liu,Karthik Lakshmanan*

Main category: cs.CL

TL;DR: 提出了一种名为 Dual-Head Reasoning Distillation (DHRD) 的训练方法，旨在解决 CoT 推理带来的吞吐量瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: CoT 推理可以提高分类精度，但会降低吞吐量。为了解决这一trade-off问题。

Method: DHRD 方法为仅解码器语言模型 (LM) 增加了一个在训练和推理期间使用的池化分类头，以及一个仅在训练期间使用的、由教师理由监督的推理头。使用标签交叉熵和输入加理由序列上的token-level LM损失的加权和作为损失函数进行训练。

Result: 在七个 SuperGLUE 任务上，DHRD 相对于 pooled 基线获得了 0.65-5.47% 的相对收益，在 entailment/causal 任务上收益更大。在测试时禁用推理头，因此推理吞吐量与 pooled 分类器相匹配，并且在 QPS 中超过了相同 backbone 上的 CoT 解码 96-142 倍。

Conclusion: DHRD 是一种有效的训练方法，可以在不牺牲推理速度的情况下，提高模型的分类精度，尤其是在 entailment/causal 任务上。

Abstract: Chain-of-Thought (CoT) prompting often improves classification accuracy, but
it introduces a significant throughput penalty with rationale generation (Wei
et al., 2022; Cheng and Van Durme, 2024). To resolve this trade-off, we
introduce Dual-Head Reasoning Distillation (DHRD), a simple training method for
decoder-only language models (LMs) that adds (i) a pooled classification head
used during training and inference and (ii) a reasoning head supervised by
teacher rationales used only in training. We train with a loss function that is
a weighted sum of label cross-entropy and token-level LM loss over
input-plus-rationale sequences. On seven SuperGLUE tasks, DHRD yields relative
gains of 0.65-5.47% over pooled baselines, with notably larger gains on
entailment/causal tasks. Since we disable the reasoning head at test time,
inference throughput matches pooled classifiers and exceeds CoT decoding on the
same backbones by 96-142 times in QPS.

</details>


### [12] [On Code-Induced Reasoning in LLMs](https://arxiv.org/abs/2509.21499)
*Abdul Waheed,Zhen Wu,Carolyn Rosé,Daphne Ippolito*

Main category: cs.CL

TL;DR: 研究表明，代码数据可以提高大型语言模型 (LLM) 的推理能力，但目前尚不清楚代码的哪些方面对此影响最大。本文通过一个以数据为中心的系统框架来研究这个问题，通过构建十种编程语言的并行指令数据集，并应用选择性扰动来破坏代码的结构或语义属性。然后，在每个变体上对来自五个模型系列和八个规模的 LLM 进行微调，并评估它们在自然语言、数学和代码任务中的性能。结果表明，LLM 更容易受到结构扰动的影响，而不是语义扰动，尤其是在数学和代码任务中。伪代码和流程图等适当的抽象可以像代码一样有效，而使用更少的 token 编码相同的信息，而不遵守原始语法，通常可以保持甚至提高性能。即使是带有误导性信号的损坏代码，当表面层面的规律性持续存在时，仍然具有竞争力。句法风格也会影响特定于任务的收益，其中 Python 有利于自然语言推理，而 Java 和 Rust 等较低级语言则有利于数学。通过本文的系统框架，旨在深入了解代码的不同属性如何影响推理，并为增强 LLM 推理能力的训练数据设计提供信息。


<details>
  <summary>Details</summary>
Motivation: 探讨代码的哪些方面最能增强大型语言模型 (LLM) 的推理能力。

Method: 构建十种编程语言的并行指令数据集，并应用选择性扰动来破坏代码的结构或语义属性。然后，在每个变体上对来自五个模型系列和八个规模的 LLM 进行微调，并评估它们在自然语言、数学和代码任务中的性能。

Result: LLM 更容易受到结构扰动的影响，而不是语义扰动，尤其是在数学和代码任务中。伪代码和流程图等适当的抽象可以像代码一样有效，而使用更少的 token 编码相同的信息，而不遵守原始语法，通常可以保持甚至提高性能。即使是带有误导性信号的损坏代码，当表面层面的规律性持续存在时，仍然具有竞争力。句法风格也会影响特定于任务的收益，其中 Python 有利于自然语言推理，而 Java 和 Rust 等较低级语言则有利于数学。

Conclusion: 代码的结构比语义更重要，适当的抽象可以像代码一样有效，即使是损坏的代码，当表面层面的规律性持续存在时，仍然具有竞争力。句法风格也会影响特定于任务的收益。

Abstract: Code data has been shown to enhance the reasoning capabilities of large
language models (LLMs), but it remains unclear which aspects of code are most
responsible. We investigate this question with a systematic, data-centric
framework. We construct parallel instruction datasets in ten programming
languages and apply controlled perturbations that selectively disrupt
structural or semantic properties of code. We then finetune LLMs from five
model families and eight scales on each variant and evaluate their performance
on natural language, math, and code tasks. Across 3,331 experiments, our
results show that LLMs are more vulnerable to structural perturbations than
semantic ones, particularly on math and code tasks. Appropriate abstractions
like pseudocode and flowcharts can be as effective as code, while encoding the
same information with fewer tokens without adhering to original syntax can
often retain or even improve performance. Remarkably, even corrupted code with
misleading signals remains competitive when surface-level regularities persist.
Finally, syntactic styles also shape task-specific gains with Python favoring
natural language reasoning and lower-level languages such as Java and Rust
favoring math. Through our systematic framework, we aim to provide insight into
how different properties of code influence reasoning and inform the design of
training data for enhancing LLM reasoning capabilities.

</details>


### [13] [Agribot: agriculture-specific question answer system](https://arxiv.org/abs/2509.21535)
*Naman Jain,Pranjali Jain,Pratik Kayal,Jayakrishna Sahit,Soham Pachpande,Jayesh Choudhari*

Main category: cs.CL

TL;DR: An agricultural chatbot was built to answer farmer queries based on the Kisan Call Center dataset.


<details>
  <summary>Details</summary>
Motivation: Proper information about agricultural practices is the key to optimal agricultural growth and output in India's agro-based economy.

Method: A sentence embedding model was used, with accuracy improved by eliminating synonyms and incorporating entity extraction.

Result: The chatbot achieved 56% accuracy initially, which jumped to 86% after improvements.

Conclusion: The chatbot can provide farmers with easier access to information, improve agricultural output, and redirect call center workforce efforts.

Abstract: India is an agro-based economy and proper information about agricultural
practices is the key to optimal agricultural growth and output. In order to
answer the queries of the farmer, we have build an agricultural chatbot based
on the dataset from Kisan Call Center. This system is robust enough to answer
queries related to weather, market rates, plant protection and government
schemes. This system is available 24* 7, can be accessed through any electronic
device and the information is delivered with the ease of understanding. The
system is based on a sentence embedding model which gives an accuracy of 56%.
After eliminating synonyms and incorporating entity extraction, the accuracy
jumps to 86%. With such a system, farmers can progress towards easier
information about farming related practices and hence a better agricultural
output. The job of the Call Center workforce would be made easier and the hard
work of various such workers can be redirected to a better goal.

</details>


### [14] [Retrieval-Augmented Guardrails for AI-Drafted Patient-Portal Messages: Error Taxonomy Construction and Large-Scale Evaluation](https://arxiv.org/abs/2509.22565)
*Wenyuan Chen,Fateme Nateghi Haredasht,Kameron C. Black,Francois Grolleau,Emily Alsentzer,Jonathan H. Chen,Stephen P. Ma*

Main category: cs.CL

TL;DR: 该论文研究了使用大型语言模型辅助临床医生回复电子健康记录 (EHR) 门户上的患者消息，并提出了一种新的评估框架来检测LLM输出中的错误。


<details>
  <summary>Details</summary>
Motivation: 异步患者-临床医生消息传递增加了临床医生的工作量，因此需要使用大型语言模型来辅助草拟回复。然而，LLM的输出可能包含临床错误、遗漏或语调不匹配，因此需要进行可靠的评估。

Method: 该论文提出了一种检索增强评估流程 (RAEC)，该流程利用语义相似的历史消息-回复对来提高判断质量，并开发了一个使用 DSPy 的两阶段提示架构，以实现可扩展、可解释和分层的错误检测。

Result: 检索上下文改进了临床完整性和工作流程适当性等领域的错误识别。在 100 条消息上进行的人工验证表明，上下文增强标签与基线相比，具有更好的一致性和性能。

Conclusion: 该研究支持使用 RAEC 流程作为患者消息传递的 AI 防护措施。

Abstract: Asynchronous patient-clinician messaging via EHR portals is a growing source
of clinician workload, prompting interest in large language models (LLMs) to
assist with draft responses. However, LLM outputs may contain clinical
inaccuracies, omissions, or tone mismatches, making robust evaluation
essential. Our contributions are threefold: (1) we introduce a clinically
grounded error ontology comprising 5 domains and 59 granular error codes,
developed through inductive coding and expert adjudication; (2) we develop a
retrieval-augmented evaluation pipeline (RAEC) that leverages semantically
similar historical message-response pairs to improve judgment quality; and (3)
we provide a two-stage prompting architecture using DSPy to enable scalable,
interpretable, and hierarchical error detection. Our approach assesses the
quality of drafts both in isolation and with reference to similar past
message-response pairs retrieved from institutional archives. Using a two-stage
DSPy pipeline, we compared baseline and reference-enhanced evaluations on over
1,500 patient messages. Retrieval context improved error identification in
domains such as clinical completeness and workflow appropriateness. Human
validation on 100 messages demonstrated superior agreement (concordance = 50%
vs. 33%) and performance (F1 = 0.500 vs. 0.256) of context-enhanced labels vs.
baseline, supporting the use of our RAEC pipeline as AI guardrails for patient
messaging.

</details>


### [15] [Domain-Aware Speaker Diarization On African-Accented English](https://arxiv.org/abs/2509.21554)
*Chibuzor Okocha,Kelechi Ezema,Christan Grant*

Main category: cs.CL

TL;DR: 本研究调查了非洲口音英语的说话人日志中的领域效应，发现临床语音存在一致的领域惩罚，这主要是由于虚惊和漏检造成的。通过在口音匹配数据上微调分割模块进行轻量级领域自适应可以减少错误，但不能消除差距。研究结果表明，下一步应采取有重叠意识的分割和平衡的临床资源。


<details>
  <summary>Details</summary>
Motivation: 说话人日志在非洲口音英语中存在领域效应。

Method: 在通用和临床对话中评估多个生产和开放系统，采用严格的 DER 协议对重叠进行评分；通过在口音匹配数据上微调分割模块进行轻量级领域自适应。

Result: 临床语音存在一致的领域惩罚，这主要是由于虚惊和漏检造成的；轻量级领域自适应可以减少错误，但不能消除差距。

Conclusion: 重叠感知分割和平衡的临床资源是实际的下一步。

Abstract: This study examines domain effects in speaker diarization for
African-accented English. We evaluate multiple production and open systems on
general and clinical dialogues under a strict DER protocol that scores overlap.
A consistent domain penalty appears for clinical speech and remains significant
across models. Error analysis attributes much of this penalty to false alarms
and missed detections, aligning with short turns and frequent overlap. We test
lightweight domain adaptation by fine-tuning a segmentation module on
accent-matched data; it reduces error but does not eliminate the gap. Our
contributions include a controlled benchmark across domains, a concise approach
to error decomposition and conversation-level profiling, and an adaptation
recipe that is easy to reproduce. Results point to overlap-aware segmentation
and balanced clinical resources as practical next steps.

</details>


### [16] [Generation-Time vs. Post-hoc Citation: A Holistic Evaluation of LLM Attribution](https://arxiv.org/abs/2509.21557)
*Yash Saxena,Raviteja Bommireddy,Ankur Padia,Manas Gaur*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型(LLMs)在医疗、法律等高风险领域引用人类可验证来源的问题，提出了两种引用范式：生成时引用(G-Cite)和事后引用(P-Cite)，并进行了对比评估。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，LLMs需要引用可信来源，但如何在生成答案时添加或验证引用是一个问题。

Method: 通过零样本到高级检索增强方法，在四个常用数据集上对G-Cite和P-Cite两种范式进行了全面评估。

Result: 结果表明，覆盖率和引用正确性之间存在权衡。检索是两种范式中归因质量的主要驱动因素。P-Cite方法在适度延迟下实现了高覆盖率和有竞争力的正确性，而G-Cite方法优先考虑精度，但牺牲了覆盖率和速度。

Conclusion: 建议在高风险应用中采用以检索为中心的P-Cite优先方法，而将G-Cite保留用于严格声明验证等精度至关重要的设置。

Abstract: Trustworthy Large Language Models (LLMs) must cite human-verifiable sources
in high-stakes domains such as healthcare, law, academia, and finance, where
even small errors can have severe consequences. Practitioners and researchers
face a choice: let models generate citations during decoding, or let models
draft answers first and then attach appropriate citations. To clarify this
choice, we introduce two paradigms: Generation-Time Citation (G-Cite), which
produces the answer and citations in one pass, and Post-hoc Citation (P-Cite),
which adds or verifies citations after drafting. We conduct a comprehensive
evaluation from zero-shot to advanced retrieval-augmented methods across four
popular attribution datasets and provide evidence-based recommendations that
weigh trade-offs across use cases. Our results show a consistent trade-off
between coverage and citation correctness, with retrieval as the main driver of
attribution quality in both paradigms. P-Cite methods achieve high coverage
with competitive correctness and moderate latency, whereas G-Cite methods
prioritize precision at the cost of coverage and speed. We recommend a
retrieval-centric, P-Cite-first approach for high-stakes applications,
reserving G-Cite for precision-critical settings such as strict claim
verification. Our codes and human evaluation results are available at
https://anonymous.4open.science/r/Citation_Paradigms-BBB5/

</details>


### [17] [Comparative Personalization for Multi-document Summarization](https://arxiv.org/abs/2509.21562)
*Haoyuan Li,Snigdha Chaturvedi*

Main category: cs.CL

TL;DR: 提出了一种个性化的多文档摘要框架ComPSum，该框架通过比较用户偏好之间的细微差异来生成个性化摘要。


<details>
  <summary>Details</summary>
Motivation: 为了满足用户在写作风格和内容重点方面的个性化偏好，论文提出了个性化多文档摘要（MDS）的重要性，并通过比较用户偏好来识别细粒度的差异。

Method: 该框架首先通过比较用户偏好与其他用户偏好来生成结构化分析，然后利用生成的结构化分析来指导个性化摘要的生成。

Result: 在PerMSum数据集上，使用AuthorMap评估ComPSum的性能，结果表明ComPSum优于强大的基线。

Conclusion: 论文提出了ComPSum框架和AuthorMap评估框架，并在PerMSum数据集上验证了ComPSum的有效性。

Abstract: Personalized multi-document summarization (MDS) is essential for meeting
individual user preferences of writing style and content focus for summaries.
In this paper, we propose that for effective personalization, it is important
to identify fine-grained differences between users' preferences by comparing
the given user's preferences with other users' preferences.Motivated by this,
we propose ComPSum, a personalized MDS framework. It first generates a
structured analysis of a user by comparing their preferences with other users'
preferences. The generated structured analysis is then used to guide the
generation of personalized summaries. To evaluate the performance of ComPSum,
we propose AuthorMap, a fine-grained reference-free evaluation framework for
personalized MDS. It evaluates the personalization of a system based on the
authorship attribution between two personalized summaries generated for
different users. For robust evaluation of personalized MDS, we construct
PerMSum, a personalized MDS dataset in the review and news domain. We evaluate
the performance of ComPSum on PerMSum using AuthorMap, showing that it
outperforms strong baselines.

</details>


### [18] [Vision Language Models Cannot Plan, but Can They Formalize?](https://arxiv.org/abs/2509.21576)
*Muyu He,Yuxi Zheng,Yuchen Liu,Zijian An,Bill Cai,Jiani Huang,Lifeng Zhou,Feng Liu,Ziyang Li,Li Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种使用视觉语言模型 (VLM) 作为形式化器的多模态规划方法，用于解决具身智能体中的长程规划任务。与直接生成动作序列不同，该方法利用 VLM 将规划领域和问题转换为形式化的规划语言（如 PDDL），然后调用形式化求解器来导出可验证的计划。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理需要长序列动作的长程规划任务时存在不足。在纯文本模拟中，LLM 通过将规划领域转换为形式化语言并调用求解器，已在长程规划中取得显著进展。然而，在多模态环境中，VLM 作为形式化器的研究仍然有限。

Method: 本文提出了一套五个 VLM 作为形式化器的流程，用于解决一次性、开放词汇和多模态 PDDL 形式化问题。该方法利用 VLM 将视觉信息转换为 PDDL 格式，然后使用求解器生成计划。

Result: 实验结果表明，VLM 作为形式化器的方法优于端到端计划生成方法。视觉是瓶颈，因为 VLM 经常无法捕获所有必要的对象关系。生成中间的文本表示（如字幕或场景图）可以部分弥补性能，但收益并不稳定。

Conclusion: VLM 作为形式化器在多模态规划中具有潜力，但视觉理解是关键瓶颈。未来的研究可以集中在改进 VLM 的视觉理解能力，以提高多模态规划的性能。

Abstract: The advancement of vision language models (VLMs) has empowered embodied
agents to accomplish simple multimodal planning tasks, but not long-horizon
ones requiring long sequences of actions. In text-only simulations,
long-horizon planning has seen significant improvement brought by repositioning
the role of LLMs. Instead of directly generating action sequences, LLMs
translate the planning domain and problem into a formal planning language like
the Planning Domain Definition Language (PDDL), which can call a formal solver
to derive the plan in a verifiable manner. In multimodal environments, research
on VLM-as-formalizer remains scarce, usually involving gross simplifications
such as predefined object vocabulary or overly similar few-shot examples. In
this work, we present a suite of five VLM-as-formalizer pipelines that tackle
one-shot, open-vocabulary, and multimodal PDDL formalization. We evaluate those
on an existing benchmark while presenting another two that for the first time
account for planning with authentic, multi-view, and low-quality images. We
conclude that VLM-as-formalizer greatly outperforms end-to-end plan generation.
We reveal the bottleneck to be vision rather than language, as VLMs often fail
to capture an exhaustive set of necessary object relations. While generating
intermediate, textual representations such as captions or scene graphs
partially compensate for the performance, their inconsistent gain leaves
headroom for future research directions on multimodal planning formalization.

</details>


### [19] ["Be My Cheese?": Assessing Cultural Nuance in Multilingual LLM Translations](https://arxiv.org/abs/2509.21577)
*Madison Van Doren,Cory Holland*

Main category: cs.CL

TL;DR: 本研究探讨了多语言AI模型在翻译英语中的比喻语言（如习语和双关语）时的本地化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM翻译研究和行业基准强调语法准确性和token级别正确性，但忽略了文化适当性和整体本地化质量，而这些对于营销和电子商务等实际应用至关重要。

Method: 该项目评估了87个LLM生成的电子商务营销电子邮件翻译样本，涵盖20种语言的24种区域方言。以母语为目标语言的人工审核员对翻译的语气、意义和目标受众的忠实度进行了定量评级和定性反馈。

Result: 研究表明，虽然领先的模型通常产生语法正确的翻译，但具有文化细微差别的语言仍然是一个明显的改进领域，通常需要大量的人工润色。即使是高资源全球语言，也经常错误地翻译比喻表达和文字游戏。

Conclusion: 这项工作挑战了数据量是机器翻译质量最可靠预测指标的假设，并将文化适当性作为多语言LLM性能的关键决定因素。结果表明，目前的多语言AI系统在实际本地化用例中存在局限性，并支持更大规模的扩展研究，以提供可推广的见解，并为文化多样性环境中的可靠机器翻译工作流程的部署提供信息。

Abstract: This pilot study explores the localisation capabilities of state-of-the-art
multilingual AI models when translating figurative language, such as idioms and
puns, from English into a diverse range of global languages. It expands on
existing LLM translation research and industry benchmarks, which emphasise
grammatical accuracy and token-level correctness, by focusing on cultural
appropriateness and overall localisation quality - critical factors for
real-world applications like marketing and e-commerce.
  To investigate these challenges, this project evaluated a sample of 87
LLM-generated translations of e-commerce marketing emails across 24 regional
dialects of 20 languages. Human reviewers fluent in each target language
provided quantitative ratings and qualitative feedback on faithfulness to the
original's tone, meaning, and intended audience. Findings suggest that, while
leading models generally produce grammatically correct translations, culturally
nuanced language remains a clear area for improvement, often requiring
substantial human refinement. Notably, even high-resource global languages,
despite topping industry benchmark leaderboards, frequently mistranslated
figurative expressions and wordplay.
  This work challenges the assumption that data volume is the most reliable
predictor of machine translation quality and introduces cultural
appropriateness as a key determinant of multilingual LLM performance - an area
currently underexplored in existing academic and industry benchmarks. As a
proof of concept, this pilot highlights limitations of current multilingual AI
systems for real-world localisation use cases. Results of this pilot support
the opportunity for expanded research at greater scale to deliver generalisable
insights and inform deployment of reliable machine translation workflows in
culturally diverse contexts.

</details>


### [20] [Multi-Objective Reinforcement Learning for Large Language Model Optimization: Visionary Perspective](https://arxiv.org/abs/2509.21613)
*Lingxiao Kong,Cong Yang,Oya Deniz Beyan,Zeyd Boukhers*

Main category: cs.CL

TL;DR: 本文提出了一个针对大型语言模型(llm)的多目标强化学习(morl)基准框架的愿景，并着重于元策略morl的开发，以提高效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型(llm)中，多目标强化学习(morl)为优化多个目标提供了重要的挑战和机遇。本文旨在研究各种morl方法在应用于llm优化时的优缺点，并确定对高效和灵活的方法的需求，以适应个性化功能以及llm和rl中固有的复杂性。

Method: 本文介绍了一种morl分类法，并提出了一个morl基准框架的愿景，该框架解决了不同方法对不同目标关系的影响。重点关注元策略morl的开发，该方法可以通过其双层学习范例提高效率和灵活性。

Result: 本文重点介绍了关键的研究问题和改进llm性能的潜在解决方案。

Conclusion: 本文确定了在llm优化中应用morl方法的需求，并提出了未来研究方向，重点关注元策略morl的开发，以提高效率和灵活性。

Abstract: Multi-Objective Reinforcement Learning (MORL) presents significant challenges
and opportunities for optimizing multiple objectives in Large Language Models
(LLMs). We introduce a MORL taxonomy and examine the advantages and limitations
of various MORL methods when applied to LLM optimization, identifying the need
for efficient and flexible approaches that accommodate personalization
functionality and inherent complexities in LLMs and RL. We propose a vision for
a MORL benchmarking framework that addresses the effects of different methods
on diverse objective relationships. As future research directions, we focus on
meta-policy MORL development that can improve efficiency and flexibility
through its bi-level learning paradigm, highlighting key research questions and
potential solutions for improving LLM performance.

</details>


### [21] [OjaKV: Context-Aware Online Low-Rank KV Cache Compression with Oja's Rule](https://arxiv.org/abs/2509.21623)
*Yuxuan Zhu,David H. Yang,Mohammad Mohammadi Amiri,Keerthiram Murugesan,Tejaswini Pedapati,Pin-Yu Chen*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为OjaKV的新框架，用于压缩大型语言模型的KV缓存，从而提高长文本处理的效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理长文本时，KV缓存会消耗大量内存，成为瓶颈。现有的低秩投影压缩方法在数据分布变化时效果不佳。

Method: OjaKV采用混合存储策略，对重要token（首尾token）进行全秩保存，对中间token采用低秩压缩。使用Oja算法进行在线子空间自适应，以应对上下文变化。

Result: 实验表明，OjaKV在高压缩率下保持甚至提高了zero-shot准确率，尤其在需要复杂推理的长文本基准测试中表现出色。

Conclusion: OjaKV是一个实用的、即插即用的解决方案，无需模型微调即可实现内存高效的长文本推理。

Abstract: The expanding long-context capabilities of large language models are
constrained by a significant memory bottleneck: the key-value (KV) cache
required for autoregressive generation. This bottleneck is substantial; for
instance, a Llama-3.1-8B model processing a 32K-token prompt at a batch size of
4 requires approximately 16GB for its KV cache, a size exceeding the model's
weights. While KV-cache compression via low-rank projection is a promising
direction, existing methods rely on a static, offline-learned subspace that
performs poorly under data distribution shifts. To overcome these limitations,
we introduce OjaKV, a novel framework that integrates a strategic hybrid
storage policy with online subspace adaptation. First, OjaKV recognizes that
not all tokens are equally important for compression; it preserves the crucial
first and most recent tokens in full-rank, maintaining high-fidelity anchors
for attention. Second, for the vast majority of intermediate tokens, it applies
low-rank compression by incrementally adapting the projection basis using Oja's
algorithm for online principal component analysis. This adaptation involves a
comprehensive update during prompt prefilling and lightweight periodic updates
during decoding, ensuring the subspace remains aligned with the evolving
context. Crucially, our framework is fully compatible with modern attention
modules like FlashAttention. Experiments demonstrate that OjaKV maintains or
even improves zero-shot accuracy at high compression ratios. In particular,
OjaKV achieves its strongest gains on very long-context benchmarks that require
complex reasoning, highlighting the importance of online subspace adaptation in
dynamically tracking context shifts. These results establish our hybrid
framework as a practical, plug-and-play solution for memory-efficient
long-context inference without requiring model fine-tuning.

</details>


### [22] [Towards Transparent AI: A Survey on Explainable Language Models](https://arxiv.org/abs/2509.21631)
*Avash Palikhe,Zichong Wang,Zhipeng Yin,Rui Guo,Qiang Duan,Jie Yang,Wenbin Zhang*

Main category: cs.CL

TL;DR: 本文全面回顾了可解释人工智能 (XAI) 技术，特别强调了语言模型 (LM)，根据其底层 Transformer 架构（仅编码器、仅解码器和编码器-解码器）组织这些技术，并分析了如何调整方法以适应每种架构，同时评估其各自的优势和局限性。


<details>
  <summary>Details</summary>
Motivation: 语言模型的黑盒性质引发了对其内部机制和决策过程的可解释性的严重担忧。这种缺乏透明度对于高风险领域的采用尤其成问题，在这些领域，利益相关者需要理解模型输出背后的基本原理以确BAO证责任。

Method: 本文根据语言模型的底层 Transformer 架构（仅编码器、仅解码器和编码器-解码器）组织 XAI 技术，并分析了如何调整方法以适应每种架构，同时评估其各自的优势和局限性。此外，我们通过合理性和忠实性的双重角度评估这些技术，从而对其有效性提供了一个结构化的视角。

Result: 本文全面回顾了 XAI 技术，特别强调了 LM，并根据其底层 Transformer 架构对其进行了组织。

Conclusion: 本文旨在指导人们不断努力开发用于 LM 的强大、透明且可解释的 XAI 方法，从而确定开放的研究挑战并概述有希望的未来方向。

Abstract: Language Models (LMs) have significantly advanced natural language processing
and enabled remarkable progress across diverse domains, yet their black-box
nature raises critical concerns about the interpretability of their internal
mechanisms and decision-making processes. This lack of transparency is
particularly problematic for adoption in high-stakes domains, where
stakeholders need to understand the rationale behind model outputs to ensure
accountability. On the other hand, while explainable artificial intelligence
(XAI) methods have been well studied for non-LMs, they face many limitations
when applied to LMs due to their complex architectures, considerable training
corpora, and broad generalization abilities. Although various surveys have
examined XAI in the context of LMs, they often fail to capture the distinct
challenges arising from the architectural diversity and evolving capabilities
of these models. To bridge this gap, this survey presents a comprehensive
review of XAI techniques with a particular emphasis on LMs, organizing them
according to their underlying transformer architectures: encoder-only,
decoder-only, and encoder-decoder, and analyzing how methods are adapted to
each while assessing their respective strengths and limitations. Furthermore,
we evaluate these techniques through the dual lenses of plausibility and
faithfulness, offering a structured perspective on their effectiveness.
Finally, we identify open research challenges and outline promising future
directions, aiming to guide ongoing efforts toward the development of robust,
transparent, and interpretable XAI methods for LMs.

</details>


### [23] [ReviewScore: Misinformed Peer Review Detection with Large Language Models](https://arxiv.org/abs/2509.21679)
*Hyun Ryu,Doohyuk Jang,Hyemin S. Lee,Joonhyun Jeong,Gyeongman Kim,Donghyeon Cho,Gyouk Chu,Minyeong Hwang,Hyeongwon Jang,Changhun Kim,Haechan Kim,Jina Kim,Joowon Kim,Yoonjeon Kim,Kwanhyung Lee,Chanjae Park,Heecheol Yun,Gregor Betz,Eunho Yang*

Main category: cs.CL

TL;DR: 论文提出ReviewScore来检测低质量的AI会议评论，通过识别评论中的错误前提或论文已回答的问题来评估评论质量。


<details>
  <summary>Details</summary>
Motivation: 随着AI会议投稿数量激增，评审质量下降，需要可靠的方法检测低质量评论。

Method: 定义Misinformed Review Points (包含不正确前提的weakness，或论文已回答的question)，并提出自动引擎重构weakness的前提，构建ReviewScore数据集，用LLM评估。

Result: 发现15.2%的weakness和26.4%的question是错误的。LLM在ReviewScore评估上与人类专家达成中等程度一致，评估前提层面的事实性比评估weakness层面的一致性更高。

Conclusion: 研究表明全自动化的ReviewScore评估具有潜力。

Abstract: Peer review serves as a backbone of academic research, but in most AI
conferences, the review quality is degrading as the number of submissions
explodes. To reliably detect low-quality reviews, we define misinformed review
points as either "weaknesses" in a review that contain incorrect premises, or
"questions" in a review that can be already answered by the paper. We verify
that 15.2% of weaknesses and 26.4% of questions are misinformed and introduce
ReviewScore indicating if a review point is misinformed. To evaluate the
factuality of each premise of weaknesses, we propose an automated engine that
reconstructs every explicit and implicit premise from a weakness. We build a
human expert-annotated ReviewScore dataset to check the ability of LLMs to
automate ReviewScore evaluation. Then, we measure human-model agreements on
ReviewScore using eight current state-of-the-art LLMs and verify moderate
agreements. We also prove that evaluating premise-level factuality shows
significantly higher agreements than evaluating weakness-level factuality. A
thorough disagreement analysis further supports a potential of fully automated
ReviewScore evaluation.

</details>


### [24] [GRAB: A Risk Taxonomy--Grounded Benchmark for Unsupervised Topic Discovery in Financial Disclosures](https://arxiv.org/abs/2509.21698)
*Ying Li,Tiejun Ma*

Main category: cs.CL

TL;DR: 本文提出了一个名为 GRAB 的金融专用基准，用于评估无监督主题模型在 10-K 风险披露中的风险分类表现。


<details>
  <summary>Details</summary>
Motivation: 现有的风险分类缺乏公开基准来评估无监督主题模型。

Method: 该基准包含 161 万个句子，通过 FinBERT token attention、YAKE 关键词信号和 taxonomy-aware collocation matching 结合生成 span-grounded 句子标签，无需手动标注。标签基于风险分类，将 193 个术语映射到 21 个细粒度类型，嵌套在 5 个宏类下。

Result: GRAB 通过固定数据集分割和鲁棒的指标（准确率、Macro-F1、Topic BERTScore 和基于熵的有效主题数）统一了评估。

Conclusion: 该数据集、标签和代码支持在金融披露上对经典、基于嵌入、神经和混合主题模型进行可重复、标准化的比较。

Abstract: Risk categorization in 10-K risk disclosures matters for oversight and
investment, yet no public benchmark evaluates unsupervised topic models for
this task. We present GRAB, a finance-specific benchmark with 1.61M sentences
from 8,247 filings and span-grounded sentence labels produced without manual
annotation by combining FinBERT token attention, YAKE keyphrase signals, and
taxonomy-aware collocation matching. Labels are anchored in a risk taxonomy
mapping 193 terms to 21 fine-grained types nested under five macro classes; the
21 types guide weak supervision, while evaluation is reported at the macro
level. GRAB unifies evaluation with fixed dataset splits and robust
metrics--Accuracy, Macro-F1, Topic BERTScore, and the entropy-based Effective
Number of Topics. The dataset, labels, and code enable reproducible,
standardized comparison across classical, embedding-based, neural, and hybrid
topic models on financial disclosures.

</details>


### [25] [Think-on-Graph 3.0: Efficient and Adaptive LLM Reasoning on Heterogeneous Graphs via Multi-Agent Dual-Evolving Context Retrieval](https://arxiv.org/abs/2509.21710)
*Xiaojun Wu,Cehao Yang,Xueyuan Lin,Chengjin Xu,Xuhui Jiang,Yuanliang Sun,Hui Xiong,Jia Li,Jian Guo*

Main category: cs.CL

TL;DR: This paper introduces Think-on-Graph 3.0 (ToG-3), a novel framework that introduces Multi-Agent Context Evolution and Retrieval (MACER) mechanism to overcome the limitations of existing RAG approaches. It dynamically constructs and refines a Chunk-Triplets-Community heterogeneous graph index, which pioneeringly incorporates a dual-evolution mechanism of Evolving Query and Evolving Sub-Graph for precise evidence retrieval.


<details>
  <summary>Details</summary>
Motivation: Existing graph-based RAG methods face a trade-off between relying on high-quality graph structures and the limitations of manually constructed or automatically extracted graphs, especially when using smaller LLMs.

Method: The paper presents a multi-agent system (Constructor, Retriever, Reflector, and Responser) that collaboratively engages in an iterative process of evidence retrieval, answer generation, sufficiency reflection, and, crucially, evolving query and subgraph. This dual-evolving multi-agent system allows ToG-3 to adaptively build a targeted graph index during reasoning.

Result: ToG-3 outperforms compared baselines on both deep and broad reasoning benchmarks.

Conclusion: The dual-evolving multi-agent system in ToG-3 mitigates the inherent drawbacks of static, one-time graph construction and enables deep, precise reasoning even with lightweight LLMs.

Abstract: Retrieval-Augmented Generation (RAG) and Graph-based RAG has become the
important paradigm for enhancing Large Language Models (LLMs) with external
knowledge. However, existing approaches face a fundamental trade-off. While
graph-based methods are inherently dependent on high-quality graph structures,
they face significant practical constraints: manually constructed knowledge
graphs are prohibitively expensive to scale, while automatically extracted
graphs from corpora are limited by the performance of the underlying LLM
extractors, especially when using smaller, local-deployed models. This paper
presents Think-on-Graph 3.0 (ToG-3), a novel framework that introduces
Multi-Agent Context Evolution and Retrieval (MACER) mechanism to overcome these
limitations. Our core innovation is the dynamic construction and refinement of
a Chunk-Triplets-Community heterogeneous graph index, which pioneeringly
incorporates a dual-evolution mechanism of Evolving Query and Evolving
Sub-Graph for precise evidence retrieval. This approach addresses a critical
limitation of prior Graph-based RAG methods, which typically construct a static
graph index in a single pass without adapting to the actual query. A
multi-agent system, comprising Constructor, Retriever, Reflector, and Responser
agents, collaboratively engages in an iterative process of evidence retrieval,
answer generation, sufficiency reflection, and, crucially, evolving query and
subgraph. This dual-evolving multi-agent system allows ToG-3 to adaptively
build a targeted graph index during reasoning, mitigating the inherent
drawbacks of static, one-time graph construction and enabling deep, precise
reasoning even with lightweight LLMs. Extensive experiments demonstrate that
ToG-3 outperforms compared baselines on both deep and broad reasoning
benchmarks, and ablation studies confirm the efficacy of the components of
MACER framework.

</details>


### [26] [ProPerSim: Developing Proactive and Personalized AI Assistants through User-Assistant Simulation](https://arxiv.org/abs/2509.21730)
*Jiho Kim,Junseong Choi,Woosog Chay,Daeun Kyung,Yeonsu Kwon,Yohan Jo,Edward Choi*

Main category: cs.CL

TL;DR: ProPerSim是一个新的任务和模拟框架，旨在开发能够在现实家庭场景中提出及时、个性化建议的 AI 助手。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）日益融入日常生活，人们对不仅反应灵敏，而且积极主动和个性化的 AI 助手需求不断增长。虽然最近的进展推动了个性化和主动性，但它们的结合仍未得到充分探索。

Method: 构建在 ProPerSim 之上，我们提出了 ProPerAssistant，一种检索增强的、偏好对齐的助手，它通过用户反馈不断学习和适应。

Result: 跨 32 种不同角色的实验表明，ProPerAssistant 调整了其策略并稳步提高了用户满意度，突出了统一主动性和个性化的前景。

Conclusion: ProPerSim 模拟环境允许用户代理与助手交互，提供关于每个建议与其偏好和上下文的对齐程度的评分。

Abstract: As large language models (LLMs) become increasingly integrated into daily
life, there is growing demand for AI assistants that are not only reactive but
also proactive and personalized. While recent advances have pushed forward
proactivity and personalization individually, their combination remains
underexplored. To bridge this gap, we introduce ProPerSim, a new task and
simulation framework for developing assistants capable of making timely,
personalized recommendations in realistic home scenarios. In our simulation
environment, a user agent with a rich persona interacts with the assistant,
providing ratings on how well each suggestion aligns with its preferences and
context. The assistant's goal is to use these ratings to learn and adapt to
achieve higher scores over time. Built on ProPerSim, we propose
ProPerAssistant, a retrieval-augmented, preference-aligned assistant that
continually learns and adapts through user feedback. Experiments across 32
diverse personas show that ProPerAssistant adapts its strategy and steadily
improves user satisfaction, highlighting the promise of uniting proactivity and
personalization.

</details>


### [27] [How Accurate Are LLMs at Multi-Question Answering on Conversational Transcripts?](https://arxiv.org/abs/2509.21732)
*Xiliang Zhu,Shi Zong,David Rossouw*

Main category: cs.CL

TL;DR: 大型语言模型在冗长上下文中进行问答面临挑战，工业界受限于高计算成本和延迟。研究探讨了LLM在相同会话上下文中回答多个问题的能力，并对一系列模型进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 在工业环境中，基于相同上下文回答多个问题时，计算成本高和延迟是一个显著的障碍。

Method: 进行了广泛的实验，并对一系列商业和开源模型进行了基准测试。

Result: GPT-4o等强大的商业LLM表现最佳，但微调后的80亿参数开源LLM在准确性方面可以超越GPT-4o。

Conclusion: 微调后的开源LLM在实际应用中具有透明和成本效益的部署潜力。

Abstract: Deploying Large Language Models (LLMs) for question answering (QA) over
lengthy contexts is a significant challenge. In industrial settings, this
process is often hindered by high computational costs and latency, especially
when multiple questions must be answered based on the same context. In this
work, we explore the capabilities of LLMs to answer multiple questions based on
the same conversational context. We conduct extensive experiments and benchmark
a range of both proprietary and public models on this challenging task. Our
findings highlight that while strong proprietary LLMs like GPT-4o achieve the
best overall performance, fine-tuned public LLMs with up to 8 billion
parameters can surpass GPT-4o in accuracy, which demonstrates their potential
for transparent and cost-effective deployment in real-world applications.

</details>


### [28] [Self-Speculative Biased Decoding for Faster Live Translation](https://arxiv.org/abs/2509.21740)
*Linxiao Zeng,Haoyun Deng,Kangyuan Shu,Shizhen Wang*

Main category: cs.CL

TL;DR: 提出了一种新的推理解码范式，用于避免在流式应用中重复生成输出，同时保持合理的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在流式应用中面临挑战，因为它们需要在输入上下文扩展时不断更新输出，同时满足延迟需求。

Method: 提出了自推测偏置解码方法，该方法使用最近的输出作为当前增长输入上下文的草稿，并在验证阶段偏向于草稿token以提高草稿接受率。

Result: 在同步文本到文本重翻译的实验结果表明，该方法与传统的自回归重翻译相比，速度提高了1.7倍，并且通过结合显示mask-k技术，显著减少了80%的闪烁。

Conclusion: 该方法无需草稿计算，是一种模型无关的即插即用解决方案，可加速对延迟敏感的流式应用。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in various text generation tasks. However, it remains challenging
to use them off-the-shelf in streaming applications (such as live translation),
where the output must continually update as the input context expands, while
still maintaining a reasonable computational cost to meet the latency
requirement.
  In this work, we reexamine the re-translation approach to simultaneous
translation and propose Self-Speculative Biased Decoding, a novel inference
paradigm designed to avoid repeatedly generating output from scratch for a
consistently growing input stream. We propose using the most recent output as a
draft for the current growing input context. During the verification stage, the
output will be biased towards the draft token for a higher draft acceptance
rate. This strategy not only minimizes flickering that might distract users but
also leads to higher speedups. Conventional decoding may take charge from the
point of divergence after draft verification and continue until the end
condition is met.
  Unlike existing speculative decoding strategies, our approach eliminates the
need for draft computations, making it a model-agnostic and plug-and-play
solution for accelerating latency-sensitive streaming applications.
Experimental results on simultaneous text-to-text re-translation demonstrate
that our approach achieves up to 1.7x speedup compared to conventional
auto-regressive re-translation without compromising quality. Additionally, it
significantly reduces flickering by 80% by incorporating the display-only
mask-k technique.

</details>


### [29] [Thinking with Sound: Audio Chain-of-Thought Enables Multimodal Reasoning in Large Audio-Language Models](https://arxiv.org/abs/2509.21749)
*Zhen Xiong,Yujun Cai,Zhecheng Li,Junsong Yuan,Yiwei Wang*

Main category: cs.CL

TL;DR: 提出 Thinking-with-Sound (TwS) 框架，通过结合语言推理和音频域分析，使 LALMs 具备 Audio CoT 能力，从而提升在复杂声学场景下的音频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有 LALMs 在复杂声学场景下的音频推理任务中表现出明显局限性，缺乏利用噪声抑制、源分离和精确时间对齐等声学工具的能力。

Method: 构建 MELD-Hard1k 基准测试，通过引入各种声学扰动来评估模型的鲁棒性。TwS 框架通过多模态推理，使模型能够主动地处理音频信号，进行数值分析和数字操作。

Result: 实验表明，现有 LALMs 在 MELD-Hard1k 上性能显著下降，而 TwS 框架能够显著提高鲁棒性，小模型的准确率提升 24.73%，大模型提升 36.61%。

Conclusion: Audio CoT 能够显著提高鲁棒性，无需重新训练，为开发更强大的音频理解系统开辟了新的方向。

Abstract: Recent Large Audio-Language Models (LALMs) have shown strong performance on
various audio understanding tasks such as speech translation and Audio Q\&A.
However, they exhibit significant limitations on challenging audio reasoning
tasks in complex acoustic scenarios. These situations would greatly benefit
from the use of acoustic tools like noise suppression, source separation, and
precise temporal alignment, but current LALMs lack access to such tools. To
address this limitation, we introduce Thinking-with-Sound (TwS), a framework
that equips LALMs with Audio CoT by combining linguistic reasoning with
on-the-fly audio-domain analysis. Unlike existing approaches that treat audio
as static input, TwS enables models to actively think with audio signals,
performing numerical analysis and digital manipulation through multimodal
reasoning. To evaluate this approach, we construct MELD-Hard1k, a new
robustness benchmark created by introducing various acoustic perturbations.
Experiments reveal that state-of-the-art LALMs suffer dramatic performance
degradation on MELD-Hard1k, with accuracy dropping by more than $50\%$ compared
to clean audio. TwS achieves substantial improvements in robustness,
demonstrating both effectiveness and scalability: small models gain $24.73\%$
absolute accuracy, with improvements scaling consistently up to $36.61\%$ for
larger models. Our findings demonstrate that Audio CoT can significantly
enhance robustness without retraining, opening new directions for developing
more robust audio understanding systems.

</details>


### [30] [SynerGen: Contextualized Generative Recommender for Unified Search and Recommendation](https://arxiv.org/abs/2509.21777)
*Vianne R. Gao,Chen Xue,Marc Versage,Xie Zhou,Zhongruo Wang,Chao Li,Yeon Seonwoo,Nan Chen,Zhen Ge,Gourab Kundu,Weiqi Zhang,Tian Wang,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: 提出了一种新的生成式推荐模型SynerGen，它使用单个生成式骨干网络同时进行个性化搜索和推荐，并在检索和排序任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模推荐系统中的检索-排序pipeline存在mis-calibration和工程开销问题，并且现有的生成式序列模型在统一检索和排序方面存在性能权衡。

Method: decoder-only Transformer利用InfoNCE进行检索的联合优化，并利用混合pointwise-pairwise损失进行排序。还提出了一种新的时间感知旋转位置嵌入，以有效地将时间信息合并到注意力机制中。

Result: 在广泛采用的推荐和搜索基准上，与强大的生成式推荐和联合搜索和推荐基线相比，SynerGen取得了显着改进。

Conclusion: 这项工作证明了单个生成式基础模型在工业规模统一信息访问中的可行性。

Abstract: The dominant retrieve-then-rank pipeline in large-scale recommender systems
suffers from mis-calibration and engineering overhead due to its architectural
split and differing optimization objectives. While recent generative sequence
models have shown promise in unifying retrieval and ranking by
auto-regressively generating ranked items, existing solutions typically address
either personalized search or query-free recommendation, often exhibiting
performance trade-offs when attempting to unify both. We introduce
\textit{SynerGen}, a novel generative recommender model that bridges this
critical gap by providing a single generative backbone for both personalized
search and recommendation, while simultaneously excelling at retrieval and
ranking tasks. Trained on behavioral sequences, our decoder-only Transformer
leverages joint optimization with InfoNCE for retrieval and a hybrid
pointwise-pairwise loss for ranking, allowing semantic signals from search to
improve recommendation and vice versa. We also propose a novel time-aware
rotary positional embedding to effectively incorporate time information into
the attention mechanism. \textit{SynerGen} achieves significant improvements on
widely adopted recommendation and search benchmarks compared to strong
generative recommender and joint search and recommendation baselines. This work
demonstrates the viability of a single generative foundation model for
industrial-scale unified information access.

</details>


### [31] [Navigating the Impact of Structured Output Format on Large Language Models through the Compass of Causal Inference](https://arxiv.org/abs/2509.21791)
*Han Yuan,Yue Zhao,Li Zhang,Wuqiong Luo,Zheng Ma*

Main category: cs.CL

TL;DR: 这篇论文研究了结构化输出对大型语言模型生成质量的影响，并使用因果推断进行了分析。


<details>
  <summary>Details</summary>
Motivation: 先前研究对结构化输出的影响存在争议，且评估方法可能存在局限性。

Method: 通过因果推断，作者提出了五种潜在的因果结构，并分析了结构化输出对LLM生成的影响。

Result: 粗略的指标显示结构化输出对GPT-4o的生成有正面、负面或中性的影响，但因果推断显示在大多数情况下没有因果关系。

Conclusion: 因果推断表明，结构化输出对LLM生成的影响在很大程度上是不存在的，少数情况下受到具体指令的影响。

Abstract: Structured output from large language models (LLMs) has enhanced efficiency
in processing generated information and is increasingly adopted in industrial
applications. Prior studies have investigated the impact of structured output
on LLMs' generation quality, often presenting one-way findings. Some suggest
that structured format enhances completeness and factual accuracy, while others
argue that it restricts the reasoning capacity of LLMs and leads to reductions
in standard evaluation metrics. Potential limitations of these assessments
include restricted testing scenarios, weakly controlled comparative settings,
and reliance on coarse metrics. In this work, we present a refined analysis
using causal inference. Based on one assumed and two guaranteed constraints, we
derive five potential causal structures characterizing the influence of
structured output on LLMs' generation: (1) collider without m-bias, (2)
collider with m-bias, (3) single cause from instruction, (4) single cause from
output format, and (5) independence. Across seven public and one developed
reasoning tasks, we find that coarse metrics report positive, negative, or
neutral effects of structured output on GPT-4o's generation. However, causal
inference reveals no causal impact in 43 out of 48 scenarios. In the remaining
5, 3 involve multifaceted causal structures influenced by concrete
instructions.

</details>


### [32] [Evaluating and Improving Cultural Awareness of Reward Models for LLM Alignment](https://arxiv.org/abs/2509.21798)
*Hongbin Zhang,Kehai Chen,Xuefeng Bai,Yang Xiang,Min Zhang*

Main category: cs.CL

TL;DR: 本文提出了文化意识奖励建模基准（CARB），揭示了现有奖励模型在文化意识建模方面的不足，并提出了Think-as-Locals方法来解决这些问题。


<details>
  <summary>Details</summary>
Motivation: 评估奖励模型（RM）的文化意识对于推进大型语言模型（LLM）的全球对齐至关重要，但现有的RM评估缺乏文化相关的评估数据集。

Method: 1. 构建了包含10种不同文化、跨越4个文化领域的文化意识奖励建模基准（CARB）。
2. 通过对现有先进RM的广泛评估，揭示了它们在文化意识建模方面的缺陷。
3. 提出了Think-as-Locals方法，通过从可验证奖励的强化学习（RLVR）来激发生成式RM更深层次的文化推理。
4. 采用精心设计的奖励来确保准确的偏好判断和高质量的结构化评估标准生成。

Result: 实验结果验证了Think-as-Locals在减轻虚假特征干扰和推进文化意识奖励建模方面的有效性，同时也表明CARB的性能与下游多语言文化对齐任务之间存在正相关关系。

Conclusion: 本文提出的CARB基准和Think-as-Locals方法能够有效提升奖励模型在文化意识方面的能力，为LLM的全球对齐做出贡献。

Abstract: Reward models (RMs) are crucial for aligning large language models (LLMs)
with diverse cultures. Consequently, evaluating their cultural awareness is
essential for further advancing global alignment of LLMs. However, existing RM
evaluations fall short in assessing cultural awareness due to the scarcity of
culturally relevant evaluation datasets. To fill this gap, we propose Cultural
Awareness Reward modeling Benchmark (CARB), covering 10 distinct cultures
across 4 cultural domains. Our extensive evaluation of state-of-the-art RMs
reveals their deficiencies in modeling cultural awareness and demonstrates a
positive correlation between performance on CARB and downstream multilingual
cultural alignment tasks. Further analysis identifies the spurious correlations
within culture-aware reward modeling, wherein RM's scoring relies predominantly
on surface-level features rather than authentic cultural nuance understanding.
To address these, we propose Think-as-Locals to elicit deeper culturally
grounded reasoning from generative RMs via reinforcement learning from
verifiable rewards (RLVR) and employ well-designed rewards to ensure accurate
preference judgments and high-quality structured evaluation criteria
generation. Experimental results validate its efficacy in mitigating spurious
features interference and advancing culture-aware reward modeling.

</details>


### [33] [Redefining Machine Simultaneous Interpretation: From Incremental Translation to Human-Like Strategies](https://arxiv.org/abs/2509.21801)
*Qianen Zhang,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 本文提出了一种基于LLM的同步机器翻译（SiMT）框架，通过扩展动作空间，引入了SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION和PRONOMINALIZATION等自适应动作，以在保证语义忠实度的前提下实现实时重构、省略和简化。


<details>
  <summary>Details</summary>
Motivation: 传统的encoder-decoder策略无法完全满足SiMT对高质量和严格实时性的要求。

Method: 在decoder-only的LLM框架中实现了这些动作，并通过action-aware prompting构建训练参考。

Result: 在ACL60/60英汉和英德benchmark上的实验表明，该框架在语义指标（如COMET-KIWI）上持续提升，并实现了更低的延迟（通过Average Lagging衡量）。DROP和SENTENCE_CUT的结合在流畅性和延迟之间取得了最佳平衡。

Conclusion: 扩展基于LLM的SiMT的动作空间为弥合人类和机器翻译之间的差距提供了一个有希望的方向。

Abstract: Simultaneous Machine Translation (SiMT) requires high-quality translations
under strict real-time constraints, which traditional encoder-decoder policies
with only READ/WRITE actions cannot fully address. We extend the action space
of SiMT with four adaptive actions: SENTENCE_CUT, DROP, PARTIAL_SUMMARIZATION
and PRONOMINALIZATION, which enable real-time restructuring, omission, and
simplification while preserving semantic fidelity. We implement these actions
in a decoder-only large language model (LLM) framework and construct training
references through action-aware prompting. To evaluate both quality and
latency, we further develop a latency-aware TTS pipeline that maps textual
outputs to speech with realistic timing. Experiments on the ACL60/60
English-Chinese and English-German benchmarks show that our framework
consistently improves semantic metrics (e.g., COMET-KIWI) and achieves lower
delay (measured by Average Lagging) compared to reference translations and
salami-based baselines. Notably, combining DROP and SENTENCE_CUT yields the
best overall balance between fluency and latency. These results demonstrate
that enriching the action space of LLM-based SiMT provides a promising
direction for bridging the gap between human and machine interpretation.

</details>


### [34] [Towards Minimal Causal Representations for Human Multimodal Language Understanding](https://arxiv.org/abs/2509.21805)
*Menghua Jiang,Yuncheng Jiang,Haifeng Hu,Sijie Mai*

Main category: cs.CL

TL;DR: 提出了一种新的多模态语言理解模型，通过因果推断提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态语言理解模型容易受到数据集偏差的影响，导致模型泛化能力下降。

Method: 提出了一种因果多模态信息瓶颈模型（CaMIB），该模型利用因果原则来过滤噪声，解耦因果和shortcut特征，并通过工具变量约束和后门调整来稳定因果估计。

Result: 在多模态情感分析、幽默检测和讽刺检测等任务上的大量实验表明，CaMIB模型的有效性。

Conclusion: CaMIB模型具有良好的可解释性和合理性，能够有效提高多模态语言理解模型的泛化能力。

Abstract: Human Multimodal Language Understanding (MLU) aims to infer human intentions
by integrating related cues from heterogeneous modalities. Existing works
predominantly follow a ``learning to attend" paradigm, which maximizes mutual
information between data and labels to enhance predictive performance. However,
such methods are vulnerable to unintended dataset biases, causing models to
conflate statistical shortcuts with genuine causal features and resulting in
degraded out-of-distribution (OOD) generalization. To alleviate this issue, we
introduce a Causal Multimodal Information Bottleneck (CaMIB) model that
leverages causal principles rather than traditional likelihood. Concretely, we
first applies the information bottleneck to filter unimodal inputs, removing
task-irrelevant noise. A parameterized mask generator then disentangles the
fused multimodal representation into causal and shortcut subrepresentations. To
ensure global consistency of causal features, we incorporate an instrumental
variable constraint, and further adopt backdoor adjustment by randomly
recombining causal and shortcut features to stabilize causal estimation.
Extensive experiments on multimodal sentiment analysis, humor detection, and
sarcasm detection, along with OOD test sets, demonstrate the effectiveness of
CaMIB. Theoretical and empirical analyses further highlight its
interpretability and soundness.

</details>


### [35] [Can LLMs Solve and Generate Linguistic Olympiad Puzzles?](https://arxiv.org/abs/2509.21820)
*Neh Majmudar,Elena Filatova*

Main category: cs.CL

TL;DR: 本文介绍了一种新颖的任务组合：语言谜题的解决和生成。关注高中生语言奥林匹克竞赛中使用的谜题。扩展了现有基准，探索大型语言模型（LLM）在解决语言谜题中的应用，并分析了它们在各种语言主题中的表现。结果表明，LLM 在大多数谜题类型上优于人类，但在以书写系统为中心以及针对研究不足的语言的谜题上除外。利用解谜实验的见解来指导谜题生成任务。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自动化谜题生成来扩大人们对语言学的兴趣，并将该领域介绍给更广泛的受众。强调语言谜题生成作为一项研究任务的重要性，因为这些谜题不仅可以推广语言学，还可以支持传播关于稀有和研究不足的语言的知识。

Method: 扩展现有基准，使用大型语言模型（LLM）解决语言谜题，并分析其性能。利用解谜实验的见解来指导谜题生成。

Result: LLM 在大多数谜题类型上优于人类，但在以书写系统为中心以及针对研究不足的语言的谜题上除外。

Conclusion: 自动化谜题生成具有潜力，可以扩大人们对语言学的兴趣，并将该领域介绍给更广泛的受众。语言谜题生成可以推广语言学，并支持传播关于稀有和研究不足的语言的知识。

Abstract: In this paper, we introduce a combination of novel and exciting tasks: the
solution and generation of linguistic puzzles. We focus on puzzles used in
Linguistic Olympiads for high school students. We first extend the existing
benchmark for the task of solving linguistic puzzles. We explore the use of
Large Language Models (LLMs), including recent state-of-the-art models such as
OpenAI's o1, for solving linguistic puzzles, analyzing their performance across
various linguistic topics. We demonstrate that LLMs outperform humans on most
puzzles types, except for those centered on writing systems, and for the
understudied languages. We use the insights from puzzle-solving experiments to
direct the novel task of puzzle generation. We believe that automating puzzle
generation, even for relatively simple puzzles, holds promise for expanding
interest in linguistics and introducing the field to a broader audience. This
finding highlights the importance of linguistic puzzle generation as a research
task: such puzzles can not only promote linguistics but also support the
dissemination of knowledge about rare and understudied languages.

</details>


### [36] [ResT: Reshaping Token-Level Policy Gradients for Tool-Use Large Language Models](https://arxiv.org/abs/2509.21826)
*Zihan Lin,Xiaohan Wang,Jie Cao,Jiajun Chai,Guojun Yin,Wei Lin,Ran He*

Main category: cs.CL

TL;DR: ResT: A new reinforcement learning method for tool-use tasks that reshapes policy gradients through entropy-informed token reweighting.


<details>
  <summary>Details</summary>
Motivation: Existing reinforcement learning methods for tool-use tasks rely on sparse outcome rewards and lack consideration of the particularity of tool-use tasks, leading to inefficient training.

Method: ResT reshapes the policy gradient through entropy-informed token reweighting, progressively upweighting reasoning tokens as training proceeds.

Result: ResT achieves state-of-the-art results on BFCL and API-Bank, outperforming prior methods by up to 8.76%. When fine-tuned on a 4B base LLM, ResT further surpasses GPT-4o by 4.11% on single-turn tasks and 1.50% on multi-turn base tasks.

Conclusion: ResT is an effective method for training LLMs to use tools.

Abstract: Large language models (LLMs) transcend passive generation and act as
goal-directed agents by invoking external tools. Reinforcement learning (RL)
offers a principled framework for optimizing these emergent tool-use policies,
yet the prevailing paradigm relies exclusively on sparse outcome rewards and
lacks consideration of the particularity of tool-use tasks, inflating
policy-gradient variance and resulting in inefficient training. To better
understand and address these challenges, we first establish a theoretical link
between policy entropy and training stability of tool-use tasks, which reveals
that structured, low-entropy tokens are primary determinants of rewards.
Motivated by this insight, we propose \textbf{Res}haped \textbf{T}oken-level
policy gradients (\textbf{ResT}) for tool-use tasks. ResT reshapes the policy
gradient through entropy-informed token reweighting, progressively upweighting
reasoning tokens as training proceeds. This entropy-aware scheme enables a
smooth shift from structural correctness to semantic reasoning and stabilizes
convergence in multi-turn tool-use tasks. Evaluation on BFCL and API-Bank shows
that ResT achieves state-of-the-art results, outperforming prior methods by up
to $8.76\%$. When fine-tuned on a 4B base LLM, ResT further surpasses GPT-4o by
$4.11\%$ on single-turn tasks and $1.50\%$ on multi-turn base tasks.

</details>


### [37] [Semantic Agreement Enables Efficient Open-Ended LLM Cascades](https://arxiv.org/abs/2509.21837)
*Duncan Soiffer,Steven Kolawole,Virginia Smith*

Main category: cs.CL

TL;DR: 语义级联是一种有前景的LLM部署方法，它可以在成本和质量之间取得平衡。它通过在多个模型输出在语义上一致时，将请求路由到较小的模型，并在必要时推迟到较大的模型。


<details>
  <summary>Details</summary>
Motivation: 开放式文本生成面临着一个根本性的挑战：当生成质量位于连续频谱上时，确定输出的可靠性，通常有多个有效的响应。

Method: 我们提出了语义一致性——集成输出之间的意义层面的共识——作为可靠推迟的免训练信号。

Result: 我们发现，当不同的模型输出在语义上一致时，它们的共识比token-level的置信度更强的可靠性信号。从500M到70B参数模型的评估表明，语义级联以40%的成本匹配或超过目标模型的质量，并将延迟降低高达60%。

Conclusion: 我们的方法不需要模型内部结构，可以在黑盒API上工作，并且对模型更新保持鲁棒性，使其成为实际LLM部署的实用基线。

Abstract: Cascade systems route computational requests to smaller models when possible
and defer to larger models only when necessary, offering a promising approach
to balance cost and quality in LLM deployment. However, they face a fundamental
challenge in open-ended text generation: determining output reliability when
generation quality lies on a continuous spectrum, often with multiple valid
responses. To address this, we propose semantic agreement -- meaning-level
consensus between ensemble outputs -- as a training-free signal for reliable
deferral. We show that when diverse model outputs agree semantically, their
consensus is a stronger reliability signal than token-level confidence.
Evaluated from 500M to 70B-parameter models, we find that semantic cascades
match or surpass target-model quality at 40% of the cost and reduce latency by
up to 60%. Our method requires no model internals, works across black-box APIs,
and remains robust to model updates, making it a practical baseline for
real-world LLM deployment.

</details>


### [38] [Following the TRACE: A Structured Path to Empathetic Response Generation with Multi-Agent Models](https://arxiv.org/abs/2509.21849)
*Ziqi Liu,Ziyang Zhou,Yilin Li,Haiyang Zhang,Yangbin Chen*

Main category: cs.CL

TL;DR: TRACE框架通过分解任务来模拟共情，从而 объединяет 深度分析和表达生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在专业模型的分析深度和大型语言模型的生成流畅性之间面临权衡。

Method: 提出TRACE，一个用于情感交流和共情的任务分解推理框架，将任务分解为分析和综合的管道，从而将共情建模为一个结构化的认知过程。

Result: 实验结果表明，TRACE框架在自动和基于LLM的评估中显著优于强大的基线模型。

Conclusion: 结构化分解是创建更强大和可解释的共情代理的一个有希望的范例。

Abstract: Empathetic response generation is a crucial task for creating more human-like
and supportive conversational agents. However, existing methods face a core
trade-off between the analytical depth of specialized models and the generative
fluency of Large Language Models (LLMs). To address this, we propose TRACE,
Task-decomposed Reasoning for Affective Communication and Empathy, a novel
framework that models empathy as a structured cognitive process by decomposing
the task into a pipeline for analysis and synthesis. By building a
comprehensive understanding before generation, TRACE unites deep analysis with
expressive generation. Experimental results show that our framework
significantly outperforms strong baselines in both automatic and LLM-based
evaluations, confirming that our structured decomposition is a promising
paradigm for creating more capable and interpretable empathetic agents. Our
code is available at https://anonymous.4open.science/r/TRACE-18EF/README.md.

</details>


### [39] [KnowMT-Bench: Benchmarking Knowledge-Intensive Long-Form Question Answering in Multi-Turn Dialogues](https://arxiv.org/abs/2509.21856)
*Junhao Chen,Yu Huang,Siyuan Li,Rui Yao,Hanqian Li,Hanyu Zhang,Jungang Li,Jian Chen,Bowen Wang,Xuming Hu*

Main category: cs.CL

TL;DR: KnowMT-Bench：首个多轮长文本问答基准，评估LLM在知识密集领域的表现，如医疗、金融和法律。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要集中在单轮对话或评估其他能力，缺乏针对知识密集型领域的多轮长文本问答的系统评估。

Method: 构建KnowMT-Bench基准，采用动态评估设置，模型生成多轮对话历史，并通过人工验证的自动流程评估最终答案的事实性和信息传递效率。

Result: 实验表明，多轮上下文会降低性能：自生成历史记录中的上下文噪声导致事实能力下降，对话长度增加导致信息效率下降。检索增强生成（RAG）可以有效缓解甚至逆转这种事实退化。

Conclusion: KnowMT-Bench对于评估和提高LLM在实际知识密集型应用中的对话事实能力至关重要。

Abstract: Multi-Turn Long-Form Question Answering (MT-LFQA) is a key application
paradigm of Large Language Models (LLMs) in knowledge-intensive domains.
However, existing benchmarks are limited to single-turn dialogue, while
multi-turn dialogue benchmarks typically assess other orthogonal capabilities
rather than knowledge-intensive factuality. To bridge this critical gap, we
introduce \textbf{KnowMT-Bench}, the \textit{first-ever} benchmark designed to
systematically evaluate MT-LFQA for LLMs across knowledge-intensive fields,
including medicine, finance, and law. To faithfully assess the model's
real-world performance, KnowMT-Bench employs a dynamic evaluation setting where
models generate their own multi-turn dialogue histories given logically
progressive question sequences. The factual capability and information delivery
efficiency of the \textit{final-turn} answer are then evaluated using a
human-validated automated pipeline. Our experiments reveal that multi-turn
contexts degrade performance: factual capability declines due to the contextual
noise from self-generated histories, while information efficiency drops as
models become more verbose with increasing dialogue length. We then investigate
mitigation strategies, demonstrating that retrieval-augmented generation (RAG)
can effectively alleviate and even reverse this factual degradation. These
findings underscore the importance of our benchmark in evaluating and enhancing
the conversational factual capabilities of LLMs in real-world
knowledge-intensive applications. Code is available at
\href{https://github.com/hardenyu21/KnowMT-Bench}{\textcolor{cyan}{\texttt{KnowMT-Bench}}}.

</details>


### [40] [Enhancing Low-Rank Adaptation with Structured Nonlinear Transformations](https://arxiv.org/abs/2509.21870)
*Guanzhi Deng,Mingyang Liu,Dapeng Wu,Yinqiao Li,Linqi Song*

Main category: cs.CL

TL;DR: LoRAN: A non-linear extension of LoRA with a sine-based activation (Sinter).


<details>
  <summary>Details</summary>
Motivation: The linear nature of LoRA limits expressiveness.

Method: Proposes LoRAN, a non-linear extension of LoRA, and introduces Sinter, a sine-based activation.

Result: LoRAN consistently improves over QLoRA in summarization and classification tasks. Sinter outperforms standard activations.

Conclusion: Activation design is important in low-rank tuning.

Abstract: Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient
fine-tuning method for large language models. However, its linear nature limits
expressiveness. We propose LoRAN, a non-linear extension of LoRA that applies
lightweight transformations to the low-rank updates. We further introduce
Sinter, a sine-based activation that adds structured perturbations without
increasing parameter count. Experiments across summarization and classification
tasks show that LoRAN consistently improves over QLoRA. Ablation studies reveal
that Sinter outperforms standard activations such as Sigmoid, ReLU, and Tanh,
highlighting the importance of activation design in lowrank tuning.

</details>


### [41] [LUMINA: Detecting Hallucinations in RAG System with Context-Knowledge Signals](https://arxiv.org/abs/2509.21875)
*Min-Hsuan Yeh,Yixuan Li,Tanwi Mallick*

Main category: cs.CL

TL;DR: LUMINA是一个用于检测RAG系统中幻觉的新框架，它通过上下文-知识信号来量化外部上下文和内部知识的利用率。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG模型即使在提供正确和充分的上下文时仍然存在幻觉问题，这源于模型使用外部上下文和内部知识之间的不平衡。现有的幻觉检测方法需要大量的超参数调整，限制了其泛化能力。

Method: LUMINA通过分布距离量化外部上下文利用率，并通过跟踪Transformer层中预测的tokens的演变来衡量内部知识利用率。此外，还引入了一个用于统计验证这些测量的框架。

Result: 在常见的RAG幻觉基准和四个开源LLM上的实验表明，LUMINA实现了持续的高AUROC和AUPRC分数，在HalluRAG上比以前的基于利用率的方法高出高达+13%的AUROC。

Conclusion: LUMINA在检索质量和模型匹配的宽松假设下仍然保持稳健，兼具有效性和实用性。

Abstract: Retrieval-Augmented Generation (RAG) aims to mitigate hallucinations in large
language models (LLMs) by grounding responses in retrieved documents. Yet,
RAG-based LLMs still hallucinate even when provided with correct and sufficient
context. A growing line of work suggests that this stems from an imbalance
between how models use external context and their internal knowledge, and
several approaches have attempted to quantify these signals for hallucination
detection. However, existing methods require extensive hyperparameter tuning,
limiting their generalizability. We propose LUMINA, a novel framework that
detects hallucinations in RAG systems through context-knowledge signals:
external context utilization is quantified via distributional distance, while
internal knowledge utilization is measured by tracking how predicted tokens
evolve across transformer layers. We further introduce a framework for
statistically validating these measurements. Experiments on common RAG
hallucination benchmarks and four open-source LLMs show that LUMINA achieves
consistently high AUROC and AUPRC scores, outperforming prior utilization-based
methods by up to +13% AUROC on HalluRAG. Moreover, LUMINA remains robust under
relaxed assumptions about retrieval quality and model matching, offering both
effectiveness and practicality.

</details>


### [42] [No Prompt Left Behind: Exploiting Zero-Variance Prompts in LLM Reinforcement Learning via Entropy-Guided Advantage Shaping](https://arxiv.org/abs/2509.21880)
*Thanh-Long V. Le,Myeongho Jeon,Kim Vu,Viet Lai,Eunho Yang*

Main category: cs.CL

TL;DR: 本研究提出了一种新的强化学习算法，RL-ZVP，该算法利用零方差提示中的学习信号来提升大型语言模型在数学推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法忽略了零方差提示，而本文认为这些提示包含有意义的反馈，可以用于策略优化。

Method: RL-ZVP算法直接奖励正确性并惩罚错误，即使在没有对比响应的情况下，也能通过token-level特征来调整反馈，从而保留信息量丰富的细微信号。

Result: 在六个数学推理基准测试中，RL-ZVP相比GRPO取得了显著的改进，准确率提高了8.61个百分点，通过率提高了7.77个百分点，并且始终优于其他过滤掉零方差提示的基线方法。

Conclusion: 研究结果表明，在RLVR中，从零方差提示中学习具有未开发的潜力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) is a powerful framework
for improving the reasoning abilities of Large Language Models (LLMs). However,
current methods such as GRPO rely only on problems where the model responses to
the same input differ in correctness, while ignoring those where all responses
receive the same reward - so-called zero-variance prompts. In this work, we
argue that such prompts are not useless but can, in fact, provide meaningful
feedback for policy optimization. To this end, we introduce RL with
Zero-Variance Prompts (RL-ZVP), a novel algorithm that extract learning signals
from zero-variance prompts. RL-ZVP directly rewards correctness and penalizes
errors even without contrasting responses, modulating feedback with token-level
characteristics to preserve informative, nuanced signals. Across six math
reasoning benchmarks, RL-ZVP achieves significant improvements of up to 8.61
points in accuracy and 7.77 points in pass rate over GRPO, while consistently
outperforming other baselines that filter out zero-variance prompts. These
results highlight the untapped potential of learning from zero-variance prompts
in RLVR.

</details>


### [43] [QoNext: Towards Next-generation QoE for Foundation Models](https://arxiv.org/abs/2509.21889)
*Yijin Guo,Ye Shen,Farong Wen,Junying Wang,Zicheng Zhang,Qi Jia,Guangtao Zhai*

Main category: cs.CL

TL;DR: 现有的基础模型评估方法忽略了用户体验中交互的重要性。本文提出了QoNext框架，该框架通过控制实验和人类评估来评估用户体验，并根据可测量的系统参数训练预测模型。实验结果表明，QoNext能够进行主动和细粒度的评估，并为实际应用中优化基础模型提供可操作的指导。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法只关注输出的正确性，忽略了用户满意度来自于响应质量和交互之间的相互作用，限制了它们解释用户体验背后机制的能力。

Method: 本文提出了QoNext框架，该框架将来自网络和多媒体的体验质量（QoE）原则应用于基础模型的评估。QoNext识别影响用户体验的体验因素，并将它们纳入受控实验中，在不同的配置下收集人类评分。然后，从这些研究中构建一个面向QoE的数据库，并训练预测模型，以根据可测量的系统参数估计感知到的用户体验。

Result: 实验结果表明，QoNext不仅能够进行主动和细粒度的评估，而且为实际应用中优化基础模型的产品化服务提供可操作的指导。

Conclusion: QoNext框架能够更全面地评估基础模型，并为优化用户体验提供指导。

Abstract: Existing evaluations of foundation models, including recent human-centric
approaches, fail to capture what truly matters: user's experience during
interaction. Current methods treat evaluation as a matter of output correctness
alone, overlooking that user satisfaction emerges from the interplay between
response quality and interaction, which limits their ability to account for the
mechanisms underlying user experience. To address this gap, we introduce
QoNext, the first framework that adapts Quality of Experience (QoE) principles
from networking and multimedia to the assessment of foundation models. QoNext
identifies experiential factors that shape user experience and incorporates
them into controlled experiments, where human ratings are collected under
varied configurations. From these studies we construct a QoE-oriented database
and train predictive models that estimate perceived user experience from
measurable system parameters. Our results demonstrate that QoNext not only
enables proactive and fine-grained evaluation but also provides actionable
guidance for productized services of optimizing foundation models in practice.

</details>


### [44] [Elastic MoE: Unlocking the Inference-Time Scalability of Mixture-of-Experts](https://arxiv.org/abs/2509.21892)
*Naibin Gu,Zhenyu Zhang,Yuchen Feng,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang*

Main category: cs.CL

TL;DR: 提出了一种新的 MoE 训练框架 EMoE，允许 MoE 模型在推理时扩展激活专家的数量，而不会产生额外的训练开销。


<details>
  <summary>Details</summary>
Motivation: MoE 模型通常在训练和推理时固定激活专家的数量 k。直觉上，在推理时激活更多专家 k'（其中 k'> k）意味着参与计算的更大的模型参数集，因此有望提高性能。然而，与这种直觉相反，我们发现缩放范围非常窄，以至于在专家数量略有增加后，性能开始迅速下降。

Method: 通过同时训练专家以不同的组合进行协作，并鼓励路由器进行高质量的选择，EMoE 确保在推理时跨计算预算的强大性能。

Result: 我们的结果表明，EMoE 显着扩大了有效的性能缩放范围，将其扩展到训练时 k 的 2-3 倍，同时也将模型的峰值性能推向了更高的水平。

Conclusion: EMoE 是一种新颖的训练框架，它使 MoE 模型能够在推理时扩展激活专家的数量，而不会产生额外的训练开销，并且可以提高模型的性能。

Abstract: Mixture-of-Experts (MoE) models typically fix the number of activated experts
$k$ at both training and inference. Intuitively, activating more experts at
inference $k'$ (where $k'> k$) means engaging a larger set of model parameters
for the computation and thus is expected to improve performance. However,
contrary to this intuition, we find the scaling range to be so narrow that
performance begins to degrade rapidly after only a slight increase in the
number of experts. Further investigation reveals that this degradation stems
from a lack of learned collaboration among experts. To address this, we
introduce Elastic Mixture-of-Experts (EMoE), a novel training framework that
enables MoE models to scale the number of activated experts at inference
without incurring additional training overhead. By simultaneously training
experts to collaborate in diverse combinations and encouraging the router for
high-quality selections, EMoE ensures robust performance across computational
budgets at inference. We conduct extensive experiments on various MoE settings.
Our results show that EMoE significantly expands the effective
performance-scaling range, extending it to as much as 2-3$\times$ the
training-time $k$, while also pushing the model's peak performance to a higher
level.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [45] [Random Direct Preference Optimization for Radiography Report Generation](https://arxiv.org/abs/2509.21351)
*Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev*

Main category: cs.CV

TL;DR: 本文提出了一种使用直接偏好优化（DPO）来提高放射影像报告生成（RRG）准确性的模型无关框架，无需额外数据或人工标注。


<details>
  <summary>Details</summary>
Motivation: 现有放射影像报告生成方法在临床应用中质量仍有不足。大型视觉语言模型（VLMs）在通用领域取得了显著进展。

Method: 利用随机对比采样构建训练对，使用直接偏好优化（DPO）训练RRG模型。

Result: 实验表明，该方法在不使用额外训练数据的情况下，临床性能指标提高了5%。

Conclusion: 该方法能有效提高RRG准确性，且无需额外数据或人工标注。

Abstract: Radiography Report Generation (RRG) has gained significant attention in
medical image analysis as a promising tool for alleviating the growing workload
of radiologists. However, despite numerous advancements, existing methods have
yet to achieve the quality required for deployment in real-world clinical
settings. Meanwhile, large Visual Language Models (VLMs) have demonstrated
remarkable progress in the general domain by adopting training strategies
originally designed for Large Language Models (LLMs), such as alignment
techniques. In this paper, we introduce a model-agnostic framework to enhance
RRG accuracy using Direct Preference Optimization (DPO). Our approach leverages
random contrastive sampling to construct training pairs, eliminating the need
for reward models or human preference annotations. Experiments on supplementing
three state-of-the-art models with our Random DPO show that our method improves
clinical performance metrics by up to 5%, without requiring any additional
training data.

</details>


### [46] [Improving Autism Detection with Multimodal Behavioral Analysis](https://arxiv.org/abs/2509.21352)
*William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla*

Main category: cs.CV

TL;DR: 本文提出了一种新的基于视频的自闭症诊断方法，通过分析面部表情、语音、头部运动、心率和眼动等多模态数据，提高了诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的自闭症诊断方法复杂且资源密集，且在实际应用中泛化性不足，尤其是在眼动特征方面表现不佳。

Method: 本文构建了一个包含168名自闭症患者和157名非自闭症患者的大型平衡数据集，并提出了一种新的统计描述符来量化眼动角度的变化，从而改进了基于眼动的分类准确率。然后，使用后期融合方法整合多模态行为标记。

Result: 通过改进的眼动模型，基于眼动的分类准确率从64%提高到69%。多模态融合后的分类准确率达到74%。

Conclusion: 研究结果表明，基于视频的筛查工具在自闭症评估方面具有潜力。

Abstract: Due to the complex and resource-intensive nature of diagnosing Autism
Spectrum Condition (ASC), several computer-aided diagnostic support methods
have been proposed to detect autism by analyzing behavioral cues in patient
video data. While these models show promising results on some datasets, they
struggle with poor gaze feature performance and lack of real-world
generalizability. To tackle these challenges, we analyze a standardized video
dataset comprising 168 participants with ASC (46% female) and 157 non-autistic
participants (46% female), making it, to our knowledge, the largest and most
balanced dataset available. We conduct a multimodal analysis of facial
expressions, voice prosody, head motion, heart rate variability (HRV), and gaze
behavior. To address the limitations of prior gaze models, we introduce novel
statistical descriptors that quantify variability in eye gaze angles, improving
gaze-based classification accuracy from 64% to 69% and aligning computational
findings with clinical research on gaze aversion in ASC. Using late fusion, we
achieve a classification accuracy of 74%, demonstrating the effectiveness of
integrating behavioral markers across multiple modalities. Our findings
highlight the potential for scalable, video-based screening tools to support
autism assessment.

</details>


### [47] [KV-Efficient VLA: A Method of Speed up Vision Language Model with RNN-Gated Chunked KV Cache](https://arxiv.org/abs/2509.21354)
*Wanshun Xu,Long Zhuang*

Main category: cs.CV

TL;DR: KV-Efficient VLA通过选择性地保留高实用性上下文来压缩KV内存，从而提高VLA模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: VLA模型在扩展性方面受限于注意力的二次成本和KV内存的无界增长，这阻碍了实时部署。

Method: 该方法将KV缓存分成固定大小的块，并使用循环门控模块来总结和过滤历史上下文，根据学习到的效用分数来选择性保留信息。

Result: KV-Efficient VLA在理论上可以实现高达1.21倍的推理加速和36%的KV内存减少，同时对任务成功率的影响很小。

Conclusion: KV-Efficient VLA可以无缝集成到现有的自回归和混合VLA堆栈中，无需修改训练管道或下游控制逻辑即可实现可扩展的推理。

Abstract: Vision-Language-Action (VLA) models promise unified robotic perception and
control, yet their scalability is constrained by the quadratic cost of
attention and the unbounded growth of key-value (KV) memory during long-horizon
inference. While recent methods improve generalization through scaling backbone
architectures, they often neglect the inference inefficiencies critical to
real-time deployment. In this work, we present KV-Efficient VLA, a
model-agnostic memory compression framework that addresses these limitations by
introducing a lightweight, training-friendly mechanism to selectively retain
high-utility context. Our method partitions the KV cache into fixed size chunks
and employs a recurrent gating module to summarize and filter historical
context according to learned utility scores. This design preserves recent
fine-grained detail while aggressively pruning stale, low-relevance memory, all
while maintaining causality. Theoretically, KV-Efficient VLA yields up to 1.21x
inference speedup and 36% KV memory reduction, with minimal impact on task
success. Our method integrates seamlessly into existing autoregressive and
hybrid VLA stacks, enabling scalable inference without modifying training
pipelines or downstream control logic.

</details>


### [48] [Phrase-grounded Fact-checking for Automatically Generated Chest X-ray Reports](https://arxiv.org/abs/2509.21356)
*Razi Mahmood,Diego Machado-Reyes,Joy Wu,Parisa Kaviani,Ken C. L. Wong,Niharika D'Souza,Mannudeep Kalra,Ge Wang,Pingkun Yan,Tanveer Syeda-Mahmood*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的基于短语定位的事实核查模型（FC模型），用于检测自动生成的胸部放射学报告中的错误。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLM）可以为胸部X光图像生成逼真的放射学报告，但临床应用受到推理过程中产生的描述中的事实错误和幻觉的阻碍。

Method: 通过扰动真实报告中的发现及其位置，形成真实和虚假的发现-位置对，从而模拟报告中的错误。然后，在这个数据集上训练一个新的多标签跨模态对比回归网络。

Result: 该方法在多个X射线数据集上展示了其在发现验证预测和定位准确性方面的稳健性。它在多个数据集上对SOTA报告生成器的报告中的错误检测的有效性，与基于地面实况的验证实现了0.997的concordance correlation coefficient。

Conclusion: 该模型在放射学工作流程中的临床推断中具有实用性。

Abstract: With the emergence of large-scale vision language models (VLM), it is now
possible to produce realistic-looking radiology reports for chest X-ray images.
However, their clinical translation has been hampered by the factual errors and
hallucinations in the produced descriptions during inference. In this paper, we
present a novel phrase-grounded fact-checking model (FC model) that detects
errors in findings and their indicated locations in automatically generated
chest radiology reports.
  Specifically, we simulate the errors in reports through a large synthetic
dataset derived by perturbing findings and their locations in ground truth
reports to form real and fake findings-location pairs with images. A new
multi-label cross-modal contrastive regression network is then trained on this
dataset. We present results demonstrating the robustness of our method in terms
of accuracy of finding veracity prediction and localization on multiple X-ray
datasets. We also show its effectiveness for error detection in reports of SOTA
report generators on multiple datasets achieving a concordance correlation
coefficient of 0.997 with ground truth-based verification, thus pointing to its
utility during clinical inference in radiology workflows.

</details>


### [49] [MDF-MLLM: Deep Fusion Through Cross-Modal Feature Alignment for Contextually Aware Fundoscopic Image Classification](https://arxiv.org/abs/2509.21358)
*Jason Jordan,Mohammadreza Akbari Lor,Peter Koulen,Mei-Ling Shyu,Shu-Ching Chen*

Main category: cs.CV

TL;DR: This paper introduces a new multimodal deep learning architecture (MDF-MLLM) for improved disease classification accuracy from retinal fundus images.


<details>
  <summary>Details</summary>
Motivation: Existing MLLMs struggle to capture low-level spatial details critical for diagnosing retinal diseases.

Method: The MDF-MLLM integrates skip features from U-Net encoder layers into cross-attention blocks within a LLaMA 3.2 11B MLLM. Vision features are patch-wise projected and fused using scaled cross-attention and FiLM-based U-Net modulation.

Result: MDF-MLLM achieved 94% accuracy, a 56% improvement over the baseline MLLM's 60% accuracy. Recall and F1-scores also improved significantly.

Conclusion: MDF-MLLM presents a generalizable, interpretable, and modular framework for fundus image classification, outperforming traditional MLLM baselines. It holds promise for real-world deployment in clinical decision support systems.

Abstract: This study aimed to enhance disease classification accuracy from retinal
fundus images by integrating fine-grained image features and global textual
context using a novel multimodal deep learning architecture. Existing
multimodal large language models (MLLMs) often struggle to capture low-level
spatial details critical for diagnosing retinal diseases such as glaucoma,
diabetic retinopathy, and retinitis pigmentosa. This model development and
validation study was conducted on 1,305 fundus image-text pairs compiled from
three public datasets (FIVES, HRF, and StoneRounds), covering acquired and
inherited retinal diseases, and evaluated using classification accuracy and
F1-score. The MDF-MLLM integrates skip features from four U-Net encoder layers
into cross-attention blocks within a LLaMA 3.2 11B MLLM. Vision features are
patch-wise projected and fused using scaled cross-attention and FiLM-based
U-Net modulation. Baseline MLLM achieved 60% accuracy on the dual-type disease
classification task. MDF-MLLM, with both U-Net and MLLM components fully
fine-tuned during training, achieved a significantly higher accuracy of 94%,
representing a 56% improvement. Recall and F1-scores improved by as much as 67%
and 35% over baseline, respectively. Ablation studies confirmed that the
multi-depth fusion approach contributed to substantial gains in spatial
reasoning and classification, particularly for inherited diseases with rich
clinical text. MDF-MLLM presents a generalizable, interpretable, and modular
framework for fundus image classification, outperforming traditional MLLM
baselines through multi-scale feature fusion. The architecture holds promise
for real-world deployment in clinical decision support systems. Future work
will explore synchronized training techniques, a larger pool of diseases for
more generalizability, and extending the model for segmentation tasks.

</details>


### [50] [Multimodal Prompt Decoupling Attack on the Safety Filters in Text-to-Image Models](https://arxiv.org/abs/2509.21360)
*Xingkai Peng,Jun Jiang,Meng Tong,Shuai Li,Weiming Zhang,Nenghai Yu,Kejiang Chen*

Main category: cs.CV

TL;DR: 本文提出了一种多模态提示解耦攻击（MPDA），利用图像模态分离原始不安全提示中的有害语义成分，以生成NSFW内容。


<details>
  <summary>Details</summary>
Motivation: 现有的攻击方法主要集中在文本提示上，忽略了图像输入中的潜在漏洞，并且文本方法难以绕过模型的安全过滤器。

Method: 1. 使用LLM将不安全提示解耦为伪安全提示和有害提示。
2. LLM将有害提示重写为自然的对抗性提示，以绕过安全过滤器，并指导T2I模型将基本图像修改为NSFW输出。
3. 视觉语言模型生成图像标题，以确保生成的NSFW图像与原始不安全提示之间的语义一致性，并指导LLM迭代重写和改进生成的内容。

Result: 通过图像模态分离有害语义成分，实现了NSFW内容的生成。

Conclusion: 该研究揭示了T2I模型在图像输入方面的潜在安全漏洞，并提出了一种有效的攻击方法。

Abstract: Text-to-image (T2I) models have been widely applied in generating
high-fidelity images across various domains. However, these models may also be
abused to produce Not-Safe-for-Work (NSFW) content via jailbreak attacks.
Existing jailbreak methods primarily manipulate the textual prompt, leaving
potential vulnerabilities in image-based inputs largely unexplored. Moreover,
text-based methods face challenges in bypassing the model's safety filters. In
response to these limitations, we propose the Multimodal Prompt Decoupling
Attack (MPDA), which utilizes image modality to separate the harmful semantic
components of the original unsafe prompt. MPDA follows three core steps:
firstly, a large language model (LLM) decouples unsafe prompts into pseudo-safe
prompts and harmful prompts. The former are seemingly harmless sub-prompts that
can bypass filters, while the latter are sub-prompts with unsafe semantics that
trigger filters. Subsequently, the LLM rewrites the harmful prompts into
natural adversarial prompts to bypass safety filters, which guide the T2I model
to modify the base image into an NSFW output. Finally, to ensure semantic
consistency between the generated NSFW images and the original unsafe prompts,
the visual language model generates image captions, providing a new pathway to
guide the LLM in iterative rewriting and refining the generated content.

</details>


### [51] [A Mutual Learning Method for Salient Object Detection with intertwined Multi-Supervision--Revised](https://arxiv.org/abs/2509.21363)
*Runmin Wu,Mengyang Feng,Wenlong Guan,Dong Wang,Huchuan Lu,Errui Ding*

Main category: cs.CV

TL;DR: 本文提出了一种新的显著目标检测方法，该方法利用显著目标检测、前景轮廓检测和边缘检测的监督来训练显著性检测网络。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习显著目标检测方法预测的显著性图由于对象的内部复杂性和卷积和池化操作中的步幅导致的不准确边界，仍然存在不完整的预测。

Method: 该方法以相互交织的方式利用显著目标检测和前景轮廓检测任务来生成具有均匀高光的显著性图。 其次，前景轮廓和边缘检测任务同时相互指导，从而导致精确的前景轮廓预测并减少边缘预测的局部噪声。 此外，我们开发了一种新颖的互学习模块 (MLM)，该模块用作我们方法的构建块。 每个 MLM 由以互学习方式训练的多个网络分支组成，从而大大提高了性能。

Result: 在七个具有挑战性的数据集上的大量实验表明，所提出的方法在显着目标检测和边缘检测方面都提供了最先进的结果。

Conclusion: 本文提出的方法在显着目标检测和边缘检测方面都取得了最先进的结果。

Abstract: Though deep learning techniques have made great progress in salient object
detection recently, the predicted saliency maps still suffer from incomplete
predictions due to the internal complexity of objects and inaccurate boundaries
caused by strides in convolution and pooling operations. To alleviate these
issues, we propose to train saliency detection networks by exploiting the
supervision from not only salient object detection, but also foreground contour
detection and edge detection. First, we leverage salient object detection and
foreground contour detection tasks in an intertwined manner to generate
saliency maps with uniform highlight. Second, the foreground contour and edge
detection tasks guide each other simultaneously, thereby leading to precise
foreground contour prediction and reducing the local noises for edge
prediction. In addition, we develop a novel mutual learning module (MLM) which
serves as the building block of our method. Each MLM consists of multiple
network branches trained in a mutual learning manner, which improves the
performance by a large margin. Extensive experiments on seven challenging
datasets demonstrate that the proposed method has delivered state-of-the-art
results in both salient object detection and edge detection.

</details>


### [52] [MAJORScore: A Novel Metric for Evaluating Multimodal Relevance via Joint Representation](https://arxiv.org/abs/2509.21365)
*Zhicheng Du,Qingyang Shi,Jiasheng Lu,Yingshan Liang,Xinyu Zhang,Yiran Wang,Peiwu Qin*

Main category: cs.CV

TL;DR: 提出了一种新的多模态相关性评估指标MAJORScore，用于评估多个模态之间的相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估指标只适用于两种模态之间的关联分析，限制了多模态相似性的评估。

Method: 通过多模态联合表示，将多个模态整合到同一潜在空间，从而在同一尺度上准确表示不同的模态。

Result: 与现有方法相比，对于一致的模态，MAJORScore提高了26.03%-64.29%，对于不一致的模态，MAJORScore降低了13.28%-20.54%。

Conclusion: MAJORScore是一种更可靠的评估大规模多模态数据集相似性和多模态模型性能的指标。

Abstract: The multimodal relevance metric is usually borrowed from the embedding
ability of pretrained contrastive learning models for bimodal data, which is
used to evaluate the correlation between cross-modal data (e.g., CLIP).
However, the commonly used evaluation metrics are only suitable for the
associated analysis between two modalities, which greatly limits the evaluation
of multimodal similarity. Herein, we propose MAJORScore, a brand-new evaluation
metric for the relevance of multiple modalities ($N$ modalities, $N\ge3$) via
multimodal joint representation for the first time. The ability of multimodal
joint representation to integrate multiple modalities into the same latent
space can accurately represent different modalities at one scale, providing
support for fair relevance scoring. Extensive experiments have shown that
MAJORScore increases by 26.03%-64.29% for consistent modality and decreases by
13.28%-20.54% for inconsistence compared to existing methods. MAJORScore serves
as a more reliable metric for evaluating similarity on large-scale multimodal
datasets and multimodal model performance evaluation.

</details>


### [53] [Safety Assessment of Scaffolding on Construction Site using AI](https://arxiv.org/abs/2509.21368)
*Sameer Prabhu,Amit Patwardhan,Ramin Karim*

Main category: cs.CV

TL;DR: 本文提出了一种基于人工智能的脚手架自动监测方法，旨在提高建筑工地的安全性。


<details>
  <summary>Details</summary>
Motivation: 目前脚手架检测主要依靠人工目测，耗时且容易出错，可能导致不安全情况。

Method: 开发了一个基于云的人工智能平台，用于处理和分析脚手架结构的点云数据，通过比较参考数据与最新的点云数据来检测结构修改。

Result: 该方法能够自动监测脚手架，减少人工检测所需的时间和精力。

Conclusion: 该研究可以通过自动化监测脚手架，减少人工检测的时间和精力，从而提高建筑工地的安全性。

Abstract: In the construction industry, safety assessment is vital to ensure both the
reliability of assets and the safety of workers. Scaffolding, a key structural
support asset requires regular inspection to detect and identify alterations
from the design rules that may compromise the integrity and stability. At
present, inspections are primarily visual and are conducted by site manager or
accredited personnel to identify deviations. However, visual inspection is
time-intensive and can be susceptible to human errors, which can lead to unsafe
conditions. This paper explores the use of Artificial Intelligence (AI) and
digitization to enhance the accuracy of scaffolding inspection and contribute
to the safety improvement. A cloud-based AI platform is developed to process
and analyse the point cloud data of scaffolding structure. The proposed system
detects structural modifications through comparison and evaluation of certified
reference data with the recent point cloud data. This approach may enable
automated monitoring of scaffolding, reducing the time and effort required for
manual inspections while enhancing the safety on a construction site.

</details>


### [54] [Automated Prompt Generation for Creative and Counterfactual Text-to-image Synthesis](https://arxiv.org/abs/2509.21375)
*Aleksa Jelaca,Ying Jiao,Chang Tian,Marie-Francine Moens*

Main category: cs.CV

TL;DR: 该论文提出了一种用于生成违反常识模式图像（例如，巨型按钮旁边的微型海象）的自动提示工程框架。


<details>
  <summary>Details</summary>
Motivation: 现有文图生成技术在生成具有精细可控性的图像方面存在挑战，尤其是在反事实可控性方面。

Method: 该框架包含图像评估器（用于指导数据集构建）、监督提示重写器（用于生成修改后的提示）和 DPO 训练的排序器（用于选择最佳修改提示）。

Result: 该方法在反事实大小文图数据集上优于现有技术水平的基线模型和 ChatGPT-4o。

Conclusion: 该研究为未来反事实可控性研究奠定了基础。

Abstract: Text-to-image generation has advanced rapidly with large-scale multimodal
training, yet fine-grained controllability remains a critical challenge.
Counterfactual controllability, defined as the capacity to deliberately
generate images that contradict common-sense patterns, remains a major
challenge but plays a crucial role in enabling creativity and exploratory
applications. In this work, we address this gap with a focus on counterfactual
size (e.g., generating a tiny walrus beside a giant button) and propose an
automatic prompt engineering framework that adapts base prompts into revised
prompts for counterfactual images. The framework comprises three components: an
image evaluator that guides dataset construction by identifying successful
image generations, a supervised prompt rewriter that produces revised prompts,
and a DPO-trained ranker that selects the optimal revised prompt. We construct
the first counterfactual size text-image dataset and enhance the image
evaluator by extending Grounded SAM with refinements, achieving a 114 percent
improvement over its backbone. Experiments demonstrate that our method
outperforms state-of-the-art baselines and ChatGPT-4o, establishing a
foundation for future research on counterfactual controllability.

</details>


### [55] [Joint graph entropy knowledge distillation for point cloud classification and robustness against corruptions](https://arxiv.org/abs/2509.22150)
*Zhiqiang Tian,Weigang Li,Junwei Hu,Chunhua Deng*

Main category: cs.CV

TL;DR: 提出了一种名为JGEKD的分类策略，适用于非独立同分布的3D点云数据，通过知识蒸馏实现类相关性的知识转移。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云分类任务通常假设类别之间独立同分布，忽略了类别之间的相关性。

Method: 构建基于联合图熵的损失函数，利用联合图捕获类别间的隐藏关系，并通过计算图的熵来实现知识蒸馏。同时，构建孪生结构，提出自知识蒸馏和教师知识蒸馏框架，促进相同数据的不同变换形式之间的信息传递。此外，还实现了点云与其损坏形式之间的知识转移，提高模型对损坏的鲁棒性。

Result: 在ScanObject, ModelNet40, ScanntV2_cls和ModelNet-C等数据集上进行了大量实验，证明了该策略能够取得有竞争力的结果。

Conclusion: JGEKD策略在非独立同分布的3D点云数据分类任务中表现出色，并通过知识蒸馏有效利用了类别相关性。

Abstract: Classification tasks in 3D point clouds often assume that class events
\replaced{are }{follow }independent and identically distributed (IID), although
this assumption destroys the correlation between classes. This \replaced{study
}{paper }proposes a classification strategy, \textbf{J}oint \textbf{G}raph
\textbf{E}ntropy \textbf{K}nowledge \textbf{D}istillation (JGEKD), suitable for
non-independent and identically distributed 3D point cloud data,
\replaced{which }{the strategy } achieves knowledge transfer of class
correlations through knowledge distillation by constructing a loss function
based on joint graph entropy. First\deleted{ly}, we employ joint graphs to
capture add{the }hidden relationships between classes\replaced{ and}{,}
implement knowledge distillation to train our model by calculating the entropy
of add{add }graph.\replaced{ Subsequently}{ Then}, to handle 3D point clouds
\deleted{that is }invariant to spatial transformations, we construct
\replaced{S}{s}iamese structures and develop two frameworks, self-knowledge
distillation and teacher-knowledge distillation, to facilitate information
transfer between different transformation forms of the same data. \replaced{In
addition}{ Additionally}, we use the above framework to achieve knowledge
transfer between point clouds and their corrupted forms, and increase the
robustness against corruption of model. Extensive experiments on ScanObject,
ModelNet40, ScanntV2\_cls and ModelNet-C demonstrate that the proposed strategy
can achieve competitive results.

</details>


### [56] [In silico Deep Learning Protocols for Label-Free Super-Resolution Microscopy: A Comparative Study of Network Architectures and SNR Dependence](https://arxiv.org/abs/2509.21376)
*Shiraz S Kaderuppan,Jonathan Mar,Andrew Irvine,Anurag Sharma,Muhammad Ramadan Saifuddin,Wai Leong Eugene Wong,Wai Lok Woo*

Main category: cs.CV

TL;DR: 本研究旨在评估一种经济的超分辨率光学显微镜方法，该方法涉及非荧光相位调制显微镜模式，如 Zernike 相位对比 (PCM) 和微分干涉对比 (DIC) 显微镜。


<details>
  <summary>Details</summary>
Motivation: 光学显微镜在各个行业和研究领域都有应用，但其横向分辨率的限制是一个关键问题。传统的解决方案成本高昂或需要专门技术，普通用户难以使用。

Method: 使用两种深度神经网络 (DNN) 架构（O-Net 和 Theta-Net）来解析包含通过原子力显微镜 (AFM) 校准的纳米级特征的定制测试目标。

Result: O-Net 和 Theta-Net 在超分辨率图像方面表现良好，但它们是互补的方法，尤其是在不同的图像信噪比 (SNR) 下。高图像 SNR 倾向于使用 O-Net 模型，而低 SNR 倾向于使用 Theta-Net 模型。

Conclusion: 模型架构（结合源图像 SNR）对模型性能和生成的图像的 SR 质量非常重要，即使在使用相同的训练数据集和 epoch 数的情况下，对于用于非荧光光学纳米显微镜的 DNN 模型也是如此。

Abstract: The field of optical microscopy spans across numerous industries and research
domains, ranging from education to healthcare, quality inspection and analysis.
Nonetheless, a key limitation often cited by optical microscopists refers to
the limit of its lateral resolution (typically defined as ~200nm), with
potential circumventions involving either costly external modules (e.g.
confocal scan heads, etc) and/or specialized techniques [e.g. super-resolution
(SR) fluorescent microscopy]. Addressing these challenges in a normal
(non-specialist) context thus remains an aspect outside the scope of most
microscope users & facilities. This study thus seeks to evaluate an alternative
& economical approach to achieving SR optical microscopy, involving
non-fluorescent phase-modulated microscopical modalities such as Zernike phase
contrast (PCM) and differential interference contrast (DIC) microscopy. Two in
silico deep neural network (DNN) architectures which we developed previously
(termed O-Net and Theta-Net) are assessed on their abilities to resolve a
custom-fabricated test target containing nanoscale features calibrated via
atomic force microscopy (AFM). The results of our study demonstrate that
although both O-Net and Theta-Net seemingly performed well when super-resolving
these images, they were complementary (rather than competing) approaches to be
considered for image SR, particularly under different image signal-to-noise
ratios (SNRs). High image SNRs favoured the application of O-Net models, while
low SNRs inclined preferentially towards Theta-Net models. These findings
demonstrate the importance of model architectures (in conjunction with the
source image SNR) on model performance and the SR quality of the generated
images where DNN models are utilized for non-fluorescent optical nanoscopy,
even where the same training dataset & number of epochs are being used.

</details>


### [57] [Dynamic Multi-Target Fusion for Efficient Audio-Visual Navigation](https://arxiv.org/abs/2509.21377)
*Yinfeng Yu,Hailong Zhang,Meiling Zhu*

Main category: cs.CV

TL;DR: 提出了一种新的视听导航方法DMTF-AVN，该方法使用多目标架构和改进的Transformer机制来融合跨模态信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用多模态线索引导导航时，通常忽略了更深层次的感知背景。

Method: 使用多目标架构和改进的Transformer机制来过滤和选择性地融合跨模态信息。

Result: 在Replica和Matterport3D数据集上，DMTF-AVN在成功率（SR）、路径效率（SPL）和场景适应性（SNA）方面均优于现有方法，达到state-of-the-art的性能。

Conclusion: DMTF-AVN模型具有强大的可扩展性和泛化性，为机器人导航中高级多模态融合策略铺平了道路。

Abstract: Audiovisual embodied navigation enables robots to locate audio sources by
dynamically integrating visual observations from onboard sensors with the
auditory signals emitted by the target. The core challenge lies in effectively
leveraging multimodal cues to guide navigation. While prior works have explored
basic fusion of visual and audio data, they often overlook deeper perceptual
context. To address this, we propose the Dynamic Multi-Target Fusion for
Efficient Audio-Visual Navigation (DMTF-AVN). Our approach uses a multi-target
architecture coupled with a refined Transformer mechanism to filter and
selectively fuse cross-modal information. Extensive experiments on the Replica
and Matterport3D datasets demonstrate that DMTF-AVN achieves state-of-the-art
performance, outperforming existing methods in success rate (SR), path
efficiency (SPL), and scene adaptation (SNA). Furthermore, the model exhibits
strong scalability and generalizability, paving the way for advanced multimodal
fusion strategies in robotic navigation. The code and videos are available at
  https://github.com/zzzmmm-svg/DMTF.

</details>


### [58] [SAEmnesia: Erasing Concepts in Diffusion Models with Sparse Autoencoders](https://arxiv.org/abs/2509.21379)
*Enrico Cassano,Riccardo Renzulli,Marco Nurisso,Mirko Zaffaroni,Alan Perotti,Marco Grangetto*

Main category: cs.CV

TL;DR: SAEmnesia，一种有监督的稀疏自编码器训练方法，通过系统 Concept 标注促进一对一的 Concept-神经元映射，减少特征分裂并促进特征集中化。


<details>
  <summary>Details</summary>
Motivation: 在文本到图像扩散模型中，有效的 Concept Unlearning 需要精确定位模型潜在空间内的 Concept 表示。虽然稀疏自编码器成功降低了神经元的多义性，但单个 Concept 表示仍然可以分布在多个潜在特征中，需要广泛的搜索程序来进行 Concept Unlearning。

Method: 引入 SAEmnesia，一种有监督的稀疏自编码器训练方法，通过系统 Concept 标注促进一对一的 Concept-神经元映射，减少特征分裂并促进特征集中化。

Result: 与无监督基线相比，我们的方法学习了具有明显更强的 Concept 关联的专用神经元。在推理时，这种可解释的表示将超参数搜索减少了 96.67%。在 UnlearnCanvas 基准测试中，SAEmnesia 比最先进水平提高了 9.22%。在顺序 Unlearning 任务中，我们展示了卓越的可扩展性，在 9 个对象移除的 Unlearning 准确率方面提高了 28.4%。

Conclusion: SAEmnesia 是一种有效的 Concept Unlearning 方法，它通过有监督的稀疏自编码器训练，实现了 Concept-神经元的一对一映射，从而提高了 Unlearning 的准确性和效率。

Abstract: Effective concept unlearning in text-to-image diffusion models requires
precise localization of concept representations within the model's latent
space. While sparse autoencoders successfully reduce neuron polysemanticity
(i.e., multiple concepts per neuron) compared to the original network,
individual concept representations can still be distributed across multiple
latent features, requiring extensive search procedures for concept unlearning.
We introduce SAEmnesia, a supervised sparse autoencoder training method that
promotes one-to-one concept-neuron mappings through systematic concept
labeling, mitigating feature splitting and promoting feature centralization.
Our approach learns specialized neurons with significantly stronger concept
associations compared to unsupervised baselines. The only computational
overhead introduced by SAEmnesia is limited to cross-entropy computation during
training. At inference time, this interpretable representation reduces
hyperparameter search by 96.67% with respect to current approaches. On the
UnlearnCanvas benchmark, SAEmnesia achieves a 9.22% improvement over the
state-of-the-art. In sequential unlearning tasks, we demonstrate superior
scalability with a 28.4% improvement in unlearning accuracy for 9-object
removal.

</details>


### [59] [Coreset selection based on Intra-class diversity](https://arxiv.org/abs/2509.21380)
*Imran Ashraf,Mukhtar Ullah,Muhammad Faisal Nadeem,Muhammad Nouman Noor*

Main category: cs.CV

TL;DR: 提出了一种智能轻量级的coreset选择机制，以解决深度学习模型训练中计算资源需求大的问题。


<details>
  <summary>Details</summary>
Motivation: 在生物医学图像分类中，从头开始训练和迁移学习深度学习模型需要大量的计算时间和资源。随机抽样选择coreset会损害原始数据集的代表性，并且无法捕获类内多样性。

Method: 提出了一种提取类内多样性的方法，形成用于最终采样的每个类别的聚类。

Result: 在生物医学图像数据集上进行了广泛的分类实验，结果表明该方案在多种性能指标上优于随机抽样方法。

Conclusion: 该研究提出了一种有效的coreset选择机制，可以减少深度学习模型训练所需的计算资源。

Abstract: Deep Learning models have transformed various domains, including the
healthcare sector, particularly biomedical image classification by learning
intricate features and enabling accurate diagnostics pertaining to complex
diseases. Recent studies have adopted two different approaches to train DL
models: training from scratch and transfer learning. Both approaches demand
substantial computational time and resources due to the involvement of massive
datasets in model training. These computational demands are further increased
due to the design-space exploration required for selecting optimal
hyperparameters, which typically necessitates several training rounds. With the
growing sizes of datasets, exploring solutions to this problem has recently
gained the research community's attention. A plausible solution is to select a
subset of the dataset for training and hyperparameter search. This subset,
referred to as the corset, must be a representative set of the original
dataset. A straightforward approach to selecting the coreset could be employing
random sampling, albeit at the cost of compromising the representativeness of
the original dataset. A critical limitation of random sampling is the bias
towards the dominant classes in an imbalanced dataset. Even if the dataset has
inter-class balance, this random sampling will not capture intra-class
diversity. This study addresses this issue by introducing an intelligent,
lightweight mechanism for coreset selection. Specifically, it proposes a method
to extract intra-class diversity, forming per-class clusters that are utilized
for the final sampling. We demonstrate the efficacy of the proposed methodology
by conducting extensive classification experiments on a well-known biomedical
imaging dataset. Results demonstrate that the proposed scheme outperforms the
random sampling approach on several performance metrics for uniform conditions.

</details>


### [60] [The LongiMam model for improved breast cancer risk prediction using longitudinal mammograms](https://arxiv.org/abs/2509.21383)
*Manel Rakez,Thomas Louis,Julien Guillaumin,Foucauld Chamming's,Pierre Fillard,Brice Amadeo,Virginie Rondeau*

Main category: cs.CV

TL;DR: LongiMam是一个深度学习模型，它集成了当前和最多四个先前的乳房X光照片，以提高乳腺癌预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型通常只使用单一或有限的先前乳房X光照片，并且缺乏对实际情况的适应性，实际情况的特点是不平衡的结果分布和异构的随访。

Method: LongiMam结合了卷积神经网络和循环神经网络，以捕捉预测乳腺癌的空间和时间模式。

Result: 在不同数量和组成的先前检查的多种情况下，当包含先前的乳房X光照片时，LongiMam始终提高了预测的准确性。此外，该模型在乳房密度高的女性和55岁或以上的女性等关键风险群体中表现最佳。

Conclusion: 纵向建模增强了乳腺癌的预测，并支持使用重复的乳房X光照片来改进筛查计划中的风险分层。LongiMam可以作为开源软件公开使用。

Abstract: Risk-adapted breast cancer screening requires robust models that leverage
longitudinal imaging data. Most current deep learning models use single or
limited prior mammograms and lack adaptation for real-world settings marked by
imbalanced outcome distribution and heterogeneous follow-up. We developed
LongiMam, an end-to-end deep learning model that integrates both current and up
to four prior mammograms. LongiMam combines a convolutional and a recurrent
neural network to capture spatial and temporal patterns predictive of breast
cancer. The model was trained and evaluated using a large, population-based
screening dataset with disproportionate case-to-control ratio typical of
clinical screening. Across several scenarios that varied in the number and
composition of prior exams, LongiMam consistently improved prediction when
prior mammograms were included. The addition of prior and current visits
outperformed single-visit models, while priors alone performed less well,
highlighting the importance of combining historical and recent information.
Subgroup analyses confirmed the model's efficacy across key risk groups,
including women with dense breasts and those aged 55 years or older. Moreover,
the model performed best in women with observed changes in mammographic density
over time. These findings demonstrate that longitudinal modeling enhances
breast cancer prediction and support the use of repeated mammograms to refine
risk stratification in screening programs. LongiMam is publicly available as
open-source software.

</details>


### [61] [Assessing the Alignment of Popular CNNs to the Brain for Valence Appraisal](https://arxiv.org/abs/2509.21384)
*Laurent Mertens,Elahe' Yargholi,Laura Van Hove,Hans Op de Beeck,Jan Van den Stock,Joost Vennekens*

Main category: cs.CV

TL;DR: 本文研究了卷积神经网络（CNN）在图像情感评估任务中与人类行为和fMRI数据的对应关系，发现CNN难以超越简单的视觉处理，未能反映更高阶的脑部处理过程。


<details>
  <summary>Details</summary>
Motivation: 研究CNN与人类大脑在社会认知这一复杂过程中的对应程度，填补了以往研究主要集中于一般视觉感知的空白。

Method: 通过相关性分析，评估了流行的CNN架构与人类行为和fMRI数据在图像情感评估任务中的一致性。提出了Object2Brain框架，结合GradCAM和目标检测，研究不同目标类别对CNN与人类相关性的影响。

Result: CNN在此任务中难以超越简单的视觉处理，未能反映更高阶的脑部处理过程。不同的CNN架构表现出不同的目标类别敏感性，但相关性趋势相似。

Conclusion: CNN在图像情感评估任务中与人类大脑的对应关系有限，Object2Brain框架为研究CNN内部机制提供了新视角。

Abstract: Convolutional Neural Networks (CNNs) are a popular type of computer model
that have proven their worth in many computer vision tasks. Moreover, they form
an interesting study object for the field of psychology, with shown
correspondences between the workings of CNNs and the human brain. However,
these correspondences have so far mostly been studied in the context of general
visual perception. In contrast, this paper explores to what extent this
correspondence also holds for a more complex brain process, namely social
cognition. To this end, we assess the alignment between popular CNN
architectures and both human behavioral and fMRI data for image valence
appraisal through a correlation analysis. We show that for this task CNNs
struggle to go beyond simple visual processing, and do not seem to reflect
higher-order brain processing. Furthermore, we present Object2Brain, a novel
framework that combines GradCAM and object detection at the CNN-filter level
with the aforementioned correlation analysis to study the influence of
different object classes on the CNN-to-human correlations. Despite similar
correlation trends, different CNN architectures are shown to display different
object class sensitivities.

</details>


### [62] [Debugging Concept Bottleneck Models through Removal and Retraining](https://arxiv.org/abs/2509.21385)
*Eric Enouen,Sainyam Galhotra*

Main category: cs.CV

TL;DR: 本文提出了一种针对概念瓶颈模型（CBMs）的通用可解释调试框架，该框架通过移除不期望的概念并在概念层面上引入用户反馈，转化为样本级别的辅助标签，从而减少模型对不期望概念的依赖。


<details>
  <summary>Details</summary>
Motivation: CBMs虽然可以通过人类可解释的概念来预测任务标签，但无法解决CBM与专家推理之间的系统性偏差，例如模型从偏差数据中学习捷径。

Method: 该框架包括两个步骤：移除（Removal），专家移除不期望的概念；以及重训练（Retraining），引入CBDebug方法，将概念级别的用户反馈转换为样本级别的辅助标签，用于有监督的偏差缓解和目标增强。

Result: 在真实和自动专家反馈的评估中，CBDebug在多种CBM架构和基准测试中显著优于之前的重训练方法。

Conclusion: CBDebug方法能够有效减少模型对不期望概念的依赖，提高模型的性能。

Abstract: Concept Bottleneck Models (CBMs) use a set of human-interpretable concepts to
predict the final task label, enabling domain experts to not only validate the
CBM's predictions, but also intervene on incorrect concepts at test time.
However, these interventions fail to address systemic misalignment between the
CBM and the expert's reasoning, such as when the model learns shortcuts from
biased data. To address this, we present a general interpretable debugging
framework for CBMs that follows a two-step process of Removal and Retraining.
In the Removal step, experts use concept explanations to identify and remove
any undesired concepts. In the Retraining step, we introduce CBDebug, a novel
method that leverages the interpretability of CBMs as a bridge for converting
concept-level user feedback into sample-level auxiliary labels. These labels
are then used to apply supervised bias mitigation and targeted augmentation,
reducing the model's reliance on undesired concepts. We evaluate our framework
with both real and automated expert feedback, and find that CBDebug
significantly outperforms prior retraining methods across multiple CBM
architectures (PIP-Net, Post-hoc CBM) and benchmarks with known spurious
correlations.

</details>


### [63] [ShipwreckFinder: A QGIS Tool for Shipwreck Detection in Multibeam Sonar Data](https://arxiv.org/abs/2509.21386)
*Anja Sheppard,Tyler Smithline,Andrew Scheffer,David Smith,Advaith V. Sethuraman,Ryan Bird,Sabrina Lin,Katherine A. Skinner*

Main category: cs.CV

TL;DR: 本文介绍了一个名为ShipwreckFinder的开源QGIS插件，用于从多波束声纳数据中检测沉船。


<details>
  <summary>Details</summary>
Motivation: 人工检查测深数据以发现沉船非常耗时，通常需要专家分析。本工具旨在解决这个问题。

Method: 该工具使用深度学习模型，该模型在来自大湖区和爱尔兰海岸的各种沉船数据上进行训练。此外，我们采用合成数据生成来增加数据集的大小和多样性。

Result: 与基于深度学习的ArcGIS工具包和更经典的逆向汇水坑检测方法相比，我们的开源工具和训练管道表现出卓越的分割性能。

Conclusion: 该开源工具可在https://github.com/umfieldrobotics/ShipwreckFinderQGISPlugin找到。

Abstract: In this paper, we introduce ShipwreckFinder, an open-source QGIS plugin that
detects shipwrecks from multibeam sonar data. Shipwrecks are an important
historical marker of maritime history, and can be discovered through manual
inspection of bathymetric data. However, this is a time-consuming process and
often requires expert analysis. Our proposed tool allows users to automatically
preprocess bathymetry data, perform deep learning inference, threshold model
outputs, and produce either pixel-wise segmentation masks or bounding boxes of
predicted shipwrecks. The backbone of this open-source tool is a deep learning
model, which is trained on a variety of shipwreck data from the Great Lakes and
the coasts of Ireland. Additionally, we employ synthetic data generation in
order to increase the size and diversity of our dataset. We demonstrate
superior segmentation performance with our open-source tool and training
pipeline as compared to a deep learning-based ArcGIS toolkit and a more
classical inverse sinkhole detection method. The open-source tool can be found
at https://github.com/umfieldrobotics/ShipwreckFinderQGISPlugin.

</details>


### [64] [Do Sparse Subnetworks Exhibit Cognitively Aligned Attention? Effects of Pruning on Saliency Map Fidelity, Sparsity, and Concept Coherence](https://arxiv.org/abs/2509.21387)
*Sanish Suwal,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 研究了剪枝对模型可解释性的影响


<details>
  <summary>Details</summary>
Motivation: 先前的工作表明，神经网络可以在保持性能的同时被大量修剪，但修剪对模型可解释性的影响仍不清楚

Method: 使用在 ImageNette 上训练的 ResNet-18，我们比较了来自 Vanilla Gradients (VG) 和 Integrated Gradients (IG) 的事后解释跨修剪级别，评估稀疏性和忠实度。我们进一步应用基于 CRAFT 的概念提取来跟踪学习概念的语义一致性的变化。

Result: 我们的结果表明，轻度到中度的修剪提高了显着性图的焦点和忠实度，同时保留了不同的、语义上有意义的概念。相比之下，激进的修剪会合并异构特征，降低显着性图稀疏性和概念一致性，尽管保持了准确性。

Conclusion: 这些发现表明，虽然修剪可以将内部表示塑造为更符合人类的注意力模式，但过度修剪会破坏可解释性。

Abstract: Prior works have shown that neural networks can be heavily pruned while
preserving performance, but the impact of pruning on model interpretability
remains unclear. In this work, we investigate how magnitude-based pruning
followed by fine-tuning affects both low-level saliency maps and high-level
concept representations. Using a ResNet-18 trained on ImageNette, we compare
post-hoc explanations from Vanilla Gradients (VG) and Integrated Gradients (IG)
across pruning levels, evaluating sparsity and faithfulness. We further apply
CRAFT-based concept extraction to track changes in semantic coherence of
learned concepts. Our results show that light-to-moderate pruning improves
saliency-map focus and faithfulness while retaining distinct, semantically
meaningful concepts. In contrast, aggressive pruning merges heterogeneous
features, reducing saliency map sparsity and concept coherence despite
maintaining accuracy. These findings suggest that while pruning can shape
internal representations toward more human-aligned attention patterns,
excessive pruning undermines interpretability.

</details>


### [65] [TUN3D: Towards Real-World Scene Understanding from Unposed Images](https://arxiv.org/abs/2509.21388)
*Anton Konushin,Nikita Drozdov,Bulat Gabdullin,Alexey Zakharov,Anna Vorontsova,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: TUN3D是第一个仅使用多视图图像作为输入，在真实扫描中解决联合布局估计和3D对象检测的方法，不需要真值相机姿势或深度监督。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于点云输入，但大多数消费级相机缺乏深度传感器，并且纯视觉数据仍然更为常见，这构成了一个主要的限制。

Method: 该方法建立在轻量级稀疏卷积骨干网络的基础上，并采用两个专用头：一个用于3D对象检测，一个用于布局估计，利用了一种新颖有效的参数化墙表示。

Result: 广泛的实验表明，TUN3D在三个具有挑战性的场景理解基准测试中取得了最先进的性能：(i) 使用真值点云，(ii) 使用姿势图像，以及 (iii) 使用未姿势图像。在性能上与专门的3D对象检测方法相当的同时，TUN3D显著提升了布局估计，在整体室内场景理解中设定了一个新的基准。

Conclusion: TUN3D在整体室内场景理解中设定了一个新的基准。

Abstract: Layout estimation and 3D object detection are two fundamental tasks in indoor
scene understanding. When combined, they enable the creation of a compact yet
semantically rich spatial representation of a scene. Existing approaches
typically rely on point cloud input, which poses a major limitation since most
consumer cameras lack depth sensors and visual-only data remains far more
common. We address this issue with TUN3D, the first method that tackles joint
layout estimation and 3D object detection in real scans, given multi-view
images as input, and does not require ground-truth camera poses or depth
supervision. Our approach builds on a lightweight sparse-convolutional backbone
and employs two dedicated heads: one for 3D object detection and one for layout
estimation, leveraging a novel and effective parametric wall representation.
Extensive experiments show that TUN3D achieves state-of-the-art performance
across three challenging scene understanding benchmarks: (i) using ground-truth
point clouds, (ii) using posed images, and (iii) using unposed images. While
performing on par with specialized 3D object detection methods, TUN3D
significantly advances layout estimation, setting a new benchmark in holistic
indoor scene understanding. Code is available at
https://github.com/col14m/tun3d .

</details>


### [66] [Large AI Model-Enabled Generative Semantic Communications for Image Transmission](https://arxiv.org/abs/2509.21394)
*Qiyu Ma,Wanli Ni,Zhijin Qin*

Main category: cs.CV

TL;DR: 提出了一种新颖的生成语义通信系统，该系统通过将图像分割成关键和非关键区域来优化语义粒度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽略图像不同区域重要性的差异，可能损害视觉关键内容的重建质量。

Method: 该系统采用面向图像的语义编码器处理包含重要视觉信息的关键区域，同时通过图像到文本建模方法有效压缩非关键区域。此外，为了减轻大型AI模型带来的巨大存储和计算需求，该系统采用了轻量级部署策略，包括模型量化和低秩适应微调技术。

Result: 仿真结果表明，该系统在语义保真度和视觉质量方面均优于传统方法。

Conclusion: 证明了该系统在图像传输任务中的有效性。

Abstract: The rapid development of generative artificial intelligence (AI) has
introduced significant opportunities for enhancing the efficiency and accuracy
of image transmission within semantic communication systems. Despite these
advancements, existing methodologies often neglect the difference in importance
of different regions of the image, potentially compromising the reconstruction
quality of visually critical content. To address this issue, we introduce an
innovative generative semantic communication system that refines semantic
granularity by segmenting images into key and non-key regions. Key regions,
which contain essential visual information, are processed using an image
oriented semantic encoder, while non-key regions are efficiently compressed
through an image-to-text modeling approach. Additionally, to mitigate the
substantial storage and computational demands posed by large AI models, the
proposed system employs a lightweight deployment strategy incorporating model
quantization and low-rank adaptation fine-tuning techniques, significantly
boosting resource utilization without sacrificing performance. Simulation
results demonstrate that the proposed system outperforms traditional methods in
terms of both semantic fidelity and visual quality, thereby affirming its
effectiveness for image transmission tasks.

</details>


### [67] [mmHSense: Multi-Modal and Distributed mmWave ISAC Datasets for Human Sensing](https://arxiv.org/abs/2509.21396)
*Nabeel Nisar Bhat,Maksim Karnaukh,Stein Vandenbroeke,Wouter Lemoine,Jakob Struye,Jesus Omar Lacruz,Siddhartha Kumar,Mohammad Hossein Moghaddam,Joerg Widmer,Rafael Berkvens,Jeroen Famaey*

Main category: cs.CV

TL;DR: 本文介绍了一个开放的毫米波数据集mmHSense，用于支持集成传感与通信(ISAC)系统中的人体感知研究。


<details>
  <summary>Details</summary>
Motivation: 该数据集旨在推动毫米波ISAC在手势识别、人员识别、姿态估计和定位等各种终端应用中的探索，并促进毫米波ISAC的信号处理和深度学习研究。

Method: 文章描述了每个数据集的测试平台、实验设置和信号特征。通过在一个特定的下游任务上进行验证，展示了数据集的效用。此外，还展示了使用参数高效微调来调整ISAC模型以适应不同任务，从而显著降低计算复杂性，同时保持先前任务的性能。

Result: 通过在一个特定的下游任务上进行验证，展示了数据集的效用。此外，还展示了使用参数高效微调来调整ISAC模型以适应不同任务，从而显著降低计算复杂性，同时保持先前任务的性能。

Conclusion: 该研究为毫米波ISAC领域提供了一个有价值的资源，并通过实验验证了其有效性，为未来的研究奠定了基础。

Abstract: This article presents mmHSense, a set of open labeled mmWave datasets to
support human sensing research within Integrated Sensing and Communication
(ISAC) systems. The datasets can be used to explore mmWave ISAC for various end
applications such as gesture recognition, person identification, pose
estimation, and localization. Moreover, the datasets can be used to develop and
advance signal processing and deep learning research on mmWave ISAC. This
article describes the testbed, experimental settings, and signal features for
each dataset. Furthermore, the utility of the datasets is demonstrated through
validation on a specific downstream task. In addition, we demonstrate the use
of parameter-efficient fine-tuning to adapt ISAC models to different tasks,
significantly reducing computational complexity while maintaining performance
on prior tasks.

</details>


### [68] [Skeleton Sparsification and Densification Scale-Spaces](https://arxiv.org/abs/2509.21398)
*Julia Gierke,Pascal Peter*

Main category: cs.CV

TL;DR: 本文提出了一种新的骨骼化尺度空间方法，通过稀疏化中间轴来实现形状的层次简化，并具有可控简化和几何变换等变性等特点。


<details>
  <summary>Details</summary>
Motivation: 传统的中间轴对噪声敏感，容易受到边界变化的影响。

Method: 结合骨骼化和尺度空间的思想，通过稀疏化中间轴来实现形状的层次简化。

Result: 通过实验证明了该框架在鲁棒骨骼化、形状压缩和增材制造刚度增强等实际任务中的有效性。

Conclusion: 本文提出的骨骼化尺度空间框架能够有效地简化形状，并具有良好的理论基础和实际应用价值。

Abstract: The Hamilton-Jacobi skeleton, also known as the medial axis, is a powerful
shape descriptor that represents binary objects in terms of the centres of
maximal inscribed discs. Despite its broad applicability, the medial axis
suffers from sensitivity to noise: minor boundary variations can lead to
disproportionately large and undesirable expansions of the skeleton. Classical
pruning methods mitigate this shortcoming by systematically removing extraneous
skeletal branches. This sequential simplification of skeletons resembles the
principle of sparsification scale-spaces that embed images into a family of
reconstructions from increasingly sparse pixel representations.
  We combine both worlds by introducing skeletonisation scale-spaces: They
leverage sparsification of the medial axis to achieve hierarchical
simplification of shapes. Unlike conventional pruning, our framework inherently
satisfies key scale-space properties such as hierarchical architecture,
controllable simplification, and equivariance to geometric transformations. We
provide a rigorous theoretical foundation in both continuous and discrete
formulations and extend the concept further with densification. This allows
inverse progression from coarse to fine scales and can even reach beyond the
original skeleton to produce overcomplete shape representations with relevancy
for practical applications.
  Through proof-of-concept experiments, we demonstrate the effectiveness of our
framework for practical tasks including robust skeletonisation, shape
compression, and stiffness enhancement for additive manufacturing.

</details>


### [69] [Downscaling climate projections to 1 km with single-image super resolution](https://arxiv.org/abs/2509.21399)
*Petr Košťál,Pavel Kordík,Ondřej Podsztavek*

Main category: cs.CV

TL;DR: 利用单图像超分辨率模型将气候预测数据统计降尺度到1公里分辨率，解决现有气候预测空间分辨率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的气候预测空间分辨率低（例如12.5公里），限制了它们的可用性，因此需要高分辨率的气候预测。

Method: 利用单图像超分辨率模型，在高分辨率观测网格数据集上训练模型，并将其应用于低分辨率气候预测。

Result: 实验表明，单图像超分辨率模型可以降低气候预测的尺度，而不会增加气候指标的误差。

Conclusion: 单图像超分辨率模型可用于气候预测的降尺度。

Abstract: High-resolution climate projections are essential for local decision-making.
However, available climate projections have low spatial resolution (e.g. 12.5
km), which limits their usability. We address this limitation by leveraging
single-image super-resolution models to statistically downscale climate
projections to 1-km resolution. Since high-resolution climate projections are
unavailable for training, we train models on a high-resolution observational
gridded data set and apply them to low-resolution climate projections. We
propose a climate indicator-based assessment using observed climate indices
computed at weather station locations to evaluate the downscaled climate
projections without ground-truth high-resolution climate projections.
Experiments on daily mean temperature demonstrate that single-image
super-resolution models can downscale climate projections without increasing
the error of climate indicators compared to low-resolution climate projections.

</details>


### [70] [JaiLIP: Jailbreaking Vision-Language Models via Loss Guided Image Perturbation](https://arxiv.org/abs/2509.21401)
*Md Jueal Mia,M. Hadi Amini*

Main category: cs.CV

TL;DR: 本文提出了一种新的图像空间jailbreak攻击方法，通过最小化clean图像和对抗图像之间的均方误差(MSE)损失与模型的有害输出损失的联合目标来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型(VLM)在生成多模态推理任务方面具有显著的能力，但也带来了潜在的误用或安全对齐问题。基于图像的扰动攻击特别有效，但现有技术存在性能不稳定和扰动明显的问题。

Method: 提出了基于损失引导图像扰动的Jailbreaking方法(JaiLIP)，该方法最小化clean图像和对抗图像之间的均方误差(MSE)损失与模型的有害输出损失的联合目标。

Result: 实验结果表明，该方法生成的对抗图像非常有效且难以察觉，在产生毒性方面优于现有方法。在交通运输领域的评估也证明了该攻击在特定领域超越毒性文本生成的实用性。

Conclusion: 研究结果强调了基于图像的jailbreak攻击的实际挑战，以及对VLM的有效防御机制的需求。

Abstract: Vision-Language Models (VLMs) have remarkable abilities in generating
multimodal reasoning tasks. However, potential misuse or safety alignment
concerns of VLMs have increased significantly due to different categories of
attack vectors. Among various attack vectors, recent studies have demonstrated
that image-based perturbations are particularly effective in generating harmful
outputs. In the literature, many existing techniques have been proposed to
jailbreak VLMs, leading to unstable performance and visible perturbations. In
this study, we propose Jailbreaking with Loss-guided Image Perturbation
(JaiLIP), a jailbreaking attack in the image space that minimizes a joint
objective combining the mean squared error (MSE) loss between clean and
adversarial image with the models harmful-output loss. We evaluate our proposed
method on VLMs using standard toxicity metrics from Perspective API and
Detoxify. Experimental results demonstrate that our method generates highly
effective and imperceptible adversarial images, outperforming existing methods
in producing toxicity. Moreover, we have evaluated our method in the
transportation domain to demonstrate the attacks practicality beyond toxic text
generation in specific domain. Our findings emphasize the practical challenges
of image-based jailbreak attacks and the need for efficient defense mechanisms
for VLMs.

</details>


### [71] [Overview of ExpertLifeCLEF 2018: how far automated identification systems are from the best experts?](https://arxiv.org/abs/2509.21419)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 本文介绍了 LifeCLEF 2018 ExpertCLEF 挑战赛，旨在比较人类专家和自动化系统在动植物识别方面的表现。


<details>
  <summary>Details</summary>
Motivation: 量化动植物识别的不确定性，并将其与自动化系统的性能进行比较，对计算机科学家和专家都非常重要。

Method: 通过 LifeCLEF 2018 ExpertCLEF 挑战赛，评估了 4 个研究团队的 19 个深度学习系统，并与 9 位法国植物学专家的表现进行比较。

Result: 最先进的深度学习模型的性能现在接近最先进的人类专业知识。

Conclusion: 本文展示了挑战赛的资源和评估，总结了参与研究小组采用的方法和系统，并分析了主要结果。

Abstract: Automated identification of plants and animals has improved considerably in
the last few years, in particular thanks to the recent advances in deep
learning. The next big question is how far such automated systems are from the
human expertise. Indeed, even the best experts are sometimes confused and/or
disagree between each others when validating visual or audio observations of
living organism. A picture actually contains only a partial information that is
usually not sufficient to determine the right species with certainty.
Quantifying this uncertainty and comparing it to the performance of automated
systems is of high interest for both computer scientists and expert
naturalists. The LifeCLEF 2018 ExpertCLEF challenge presented in this paper was
designed to allow this comparison between human experts and automated systems.
In total, 19 deep-learning systems implemented by 4 different research teams
were evaluated with regard to 9 expert botanists of the French flora. The main
outcome of this work is that the performance of state-of-the-art deep learning
models is now close to the most advanced human expertise. This paper presents
more precisely the resources and assessments of the challenge, summarizes the
approaches and systems employed by the participating research groups, and
provides an analysis of the main outcomes.

</details>


### [72] [QuadGPT: Native Quadrilateral Mesh Generation with Autoregressive Models](https://arxiv.org/abs/2509.21420)
*Jian Liu,Chunshi Wang,Song Guo,Haohan Weng,Zhen Zhou,Zhiqi Li,Jiaao Yu,Yiling Zhu,Jing Xu,Biwen Lei,Zhuo Chen,Chunchao Guo*

Main category: cs.CV

TL;DR: QuadGPT: 首次端到端四边形网格生成框架，胜过传统三角网格转换方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法先生成三角网格再合并为四边形，导致拓扑质量差。

Method: 提出QuadGPT，一个自回归框架，通过统一的tokenization方法处理三角形和四边形的混合拓扑，并使用专门的强化学习微调方法tDPO来提高生成质量。

Result: QuadGPT在几何精度和拓扑质量上显著优于以往的三角网格到四边形网格的转换流程。

Conclusion: QuadGPT为原生四边形网格生成建立了一个新的基准，展示了大型自回归模型与拓扑感知RL细化相结合在创建结构化3D资产方面的强大能力。

Abstract: The generation of quadrilateral-dominant meshes is a cornerstone of
professional 3D content creation. However, existing generative models generate
quad meshes by first generating triangle meshes and then merging triangles into
quadrilaterals with some specific rules, which typically produces quad meshes
with poor topology. In this paper, we introduce QuadGPT, the first
autoregressive framework for generating quadrilateral meshes in an end-to-end
manner. QuadGPT formulates this as a sequence prediction paradigm,
distinguished by two key innovations: a unified tokenization method to handle
mixed topologies of triangles and quadrilaterals, and a specialized
Reinforcement Learning fine-tuning method tDPO for better generation quality.
Extensive experiments demonstrate that QuadGPT significantly surpasses previous
triangle-to-quad conversion pipelines in both geometric accuracy and
topological quality. Our work establishes a new benchmark for native quad-mesh
generation and showcases the power of combining large-scale autoregressive
models with topology-aware RL refinement for creating structured 3D assets.

</details>


### [73] [DyME: Dynamic Multi-Concept Erasure in Diffusion Models with Bi-Level Orthogonal LoRA Adaptation](https://arxiv.org/abs/2509.21433)
*Jiaqi Liu,Lan Zhang,Xiaoyong Yuan*

Main category: cs.CV

TL;DR: 提出了一个按需擦除框架 DyME，用于解决文本到图像扩散模型中存在的版权和伦理问题，特别是对于多个和可能冲突的概念擦除。


<details>
  <summary>Details</summary>
Motivation: 现有的概念擦除方法无法扩展到实际场景，因为它们依赖于静态擦除，即使用单个检查点来删除所有目标概念，这导致擦除效果不佳，并且降低了非目标内容的保真度。

Method: DyME 框架训练轻量级的、特定于概念的 LoRA 适配器，并在推理时动态组合所需的适配器。为了解决适配器之间的干扰问题，引入了双层正交性约束，并在特征和参数级别上解耦表示变化，并强制执行正交适配器子空间。

Result: 在 ErasureBench-H 和标准数据集上的实验表明，DyME 始终优于最先进的基线，以最小的 collateral degradation 实现了更高的多概念擦除保真度。

Conclusion: DyME 框架有效地解决了文本到图像扩散模型中多概念擦除的问题，提高了擦除保真度，并减少了对非目标内容的影响。

Abstract: Text-to-image diffusion models (DMs) inadvertently reproduce copyrighted
styles and protected visual concepts, raising legal and ethical concerns.
Concept erasure has emerged as a safeguard, aiming to selectively suppress such
concepts through fine-tuning. However, existing methods do not scale to
practical settings where providers must erase multiple and possibly conflicting
concepts. The core bottleneck is their reliance on static erasure: a single
checkpoint is fine-tuned to remove all target concepts, regardless of the
actual erasure needs at inference. This rigid design mismatches real-world
usage, where requests vary per generation, leading to degraded erasure success
and reduced fidelity for non-target content. We propose DyME, an on-demand
erasure framework that trains lightweight, concept-specific LoRA adapters and
dynamically composes only those needed at inference. This modular design
enables flexible multi-concept erasure, but naive composition causes
interference among adapters, especially when many or semantically related
concepts are suppressed. To overcome this, we introduce bi-level orthogonality
constraints at both the feature and parameter levels, disentangling
representation shifts and enforcing orthogonal adapter subspaces. We further
develop ErasureBench-H, a new hierarchical benchmark with
brand-series-character structure, enabling principled evaluation across
semantic granularities and erasure set sizes. Experiments on ErasureBench-H and
standard datasets (e.g., CIFAR-100, Imagenette) demonstrate that DyME
consistently outperforms state-of-the-art baselines, achieving higher
multi-concept erasure fidelity with minimal collateral degradation.

</details>


### [74] [VideoJudge: Bootstrapping Enables Scalable Supervision of MLLM-as-a-Judge for Video Understanding](https://arxiv.org/abs/2509.21451)
*Abdul Waheed,Zhen Wu,Dareen Alharthi,Seungone Kim,Bhiksha Raj*

Main category: cs.CV

TL;DR: 本文介绍了一种名为VideoJudge的MLLM，用于评估视频理解模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型的评估指标不够精确，人工评估成本高昂。

Method: 通过生成器和评估器的相互作用训练VideoJudge，生成器根据目标评分生成响应，评估器丢弃不匹配的响应。

Result: VideoJudge-7B在四个meta-evaluation基准测试中的三个上优于更大的MLLM judge基线。

Conclusion: 视频输入对于视频理解任务的评估至关重要。LLM judge不如MLLM judge，且长链思维推理并不能提高性能。

Abstract: Precisely evaluating video understanding models remains challenging: commonly
used metrics such as BLEU, ROUGE, and BERTScore fail to capture the fineness of
human judgment, while obtaining such judgments through manual evaluation is
costly. Recent work has explored using large language models (LLMs) or
multimodal LLMs (MLLMs) as evaluators, but their extension to video
understanding remains relatively unexplored. In this work, we introduce
VideoJudge, a 3B and 7B-sized MLLM judge specialized to evaluate outputs from
video understanding models (\textit{i.e.}, text responses conditioned on
videos). To train VideoJudge, our recipe builds on the interplay between a
generator and an evaluator: the generator is prompted to produce responses
conditioned on a target rating, and responses not matching the evaluator's
rating are discarded. Across three out of four meta-evaluation benchmarks,
VideoJudge-7B outperforms larger MLLM judge baselines such as Qwen2.5-VL (32B
and 72B). Notably, we find that LLM judges (Qwen3) models perform worse than
MLLM judges (Qwen2.5-VL) and long chain-of-thought reasoning does not improve
performance, indicating that providing video inputs is crucial for evaluation
of video understanding tasks.

</details>


### [75] [Residual Vector Quantization For Communication-Efficient Multi-Agent Perception](https://arxiv.org/abs/2509.21464)
*Dereje Shenkut,B. V. K Vijaya Kumar*

Main category: cs.CV

TL;DR: ReVQom是一种用于多智能体协同感知(CP)的特征编解码器，通过压缩中间特征来减少通信带宽的限制。


<details>
  <summary>Details</summary>
Motivation: 多智能体协同感知(CP)通过共享信息来提高场景理解，但通信带宽限制了其可扩展性。

Method: ReVQom是一种端到端的方法，通过瓶颈网络和多阶段残差向量量化(RVQ)来压缩特征维度，只传输像素代码索引。

Result: 在DAIR-V2X真实世界CP数据集上，ReVQom实现了273x到1365x的压缩率，并且在18 bpp时性能优于原始特征CP。

Conclusion: ReVQom实现了高效准确的多智能体协同感知，是迈向实际V2X部署的一步。

Abstract: Multi-agent collaborative perception (CP) improves scene understanding by
sharing information across connected agents such as autonomous vehicles,
unmanned aerial vehicles, and robots. Communication bandwidth, however,
constrains scalability. We present ReVQom, a learned feature codec that
preserves spatial identity while compressing intermediate features. ReVQom is
an end-to-end method that compresses feature dimensions via a simple bottleneck
network followed by multi-stage residual vector quantization (RVQ). This allows
only per-pixel code indices to be transmitted, reducing payloads from 8192 bits
per pixel (bpp) of uncompressed 32-bit float features to 6-30 bpp per agent
with minimal accuracy loss. On DAIR-V2X real-world CP dataset, ReVQom achieves
273x compression at 30 bpp to 1365x compression at 6 bpp. At 18 bpp (455x),
ReVQom matches or outperforms raw-feature CP, and at 6-12 bpp it enables
ultra-low-bandwidth operation with graceful degradation. ReVQom allows
efficient and accurate multi-agent collaborative perception with a step toward
practical V2X deployment.

</details>


### [76] [Gender Stereotypes in Professional Roles Among Saudis: An Analytical Study of AI-Generated Images Using Language Models](https://arxiv.org/abs/2509.21466)
*Khaloud S. AlKhalifah,Malak Mashaabi,Hend Al-Khalifa*

Main category: cs.CV

TL;DR: 研究调查了当今文本到图像人工智能 (AI) 模型在生成沙特阿拉伯专业人士的图像时，在多大程度上延续了性别刻板印象和文化不准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨文本到图像模型在描绘沙特专业人士时，是否存在性别偏见和文化不准确问题。

Method: 使用 ImageFX、DALL-E V3 和 Grok 三种模型生成 56 种沙特职业的 1006 张图像，由两位沙特注释员评估每张图像的五个维度：性别、服装和外貌、背景和环境、活动和互动以及年龄。如有分歧，由第三位高级研究员进行裁决。

Result: 结果显示出强烈的性别失衡，文化不准确现象也很常见。DALL-E V3 的性别刻板印象最为严重。反刻板印象的图像通常源于文化误解。

Conclusion: 目前的模型反映了训练数据中嵌入的社会偏见，未能充分反映沙特劳动力市场的性别动态和文化细微差别。迫切需要更多样化的训练数据、更公平的算法和对文化敏感的评估框架，以确保公平和真实的视觉输出。

Abstract: This study investigates the extent to which contemporary Text-to-Image
artificial intelligence (AI) models perpetuate gender stereotypes and cultural
inaccuracies when generating depictions of professionals in Saudi Arabia. We
analyzed 1,006 images produced by ImageFX, DALL-E V3, and Grok for 56 diverse
Saudi professions using neutral prompts. Two trained Saudi annotators evaluated
each image on five dimensions: perceived gender, clothing and appearance,
background and setting, activities and interactions, and age. A third senior
researcher adjudicated whenever the two primary raters disagreed, yielding
10,100 individual judgements. The results reveal a strong gender imbalance,
with ImageFX outputs being 85\% male, Grok 86.6\% male, and DALL-E V3 96\%
male, indicating that DALL-E V3 exhibited the strongest overall gender
stereotyping. This imbalance was most evident in leadership and technical
roles. Moreover, cultural inaccuracies in clothing, settings, and depicted
activities were frequently observed across all three models.
Counter-stereotypical images often arise from cultural misinterpretations
rather than genuinely progressive portrayals. We conclude that current models
mirror societal biases embedded in their training data, generated by humans,
offering only a limited reflection of the Saudi labour market's gender dynamics
and cultural nuances. These findings underscore the urgent need for more
diverse training data, fairer algorithms, and culturally sensitive evaluation
frameworks to ensure equitable and authentic visual outputs.

</details>


### [77] [Reasoning-Enhanced Domain-Adaptive Pretraining of Multimodal Large Language Models for Short Video Content Moderation](https://arxiv.org/abs/2509.21486)
*Zixuan Wang,Yu Sun,Hongwei Wang,Baoyu Jing,Xiang Shen,Xin Dong,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 提出了一种用于统一不当内容检测的、具有推理增强的多模态大型语言模型 (MLLM) 预训练范例。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常为每种问题类型训练单独的小型分类模型，这需要大量人工标注数据，并且缺乏跨问题泛化能力。

Method: 引入了三个有针对性的预训练任务：(1) Caption，以增强 MLLM 对视频细节的感知；(2) Visual Question Answering (VQA)，以加深 MLLM 对问题定义和标注指南的理解；(3) Chain-of-Thought (CoT)，以增强 MLLM 的推理能力。

Result: 实验结果表明，所提出的预训练方法显著提高了 MLLM 在零样本和监督微调 (SFT) 设置中的性能。

Conclusion: 预训练模型展示了对新兴的、以前未见过的问题的强大泛化能力。

Abstract: Short video platforms are evolving rapidly, making the identification of
inappropriate content increasingly critical. Existing approaches typically
train separate and small classification models for each type of issue, which
requires extensive human-labeled data and lacks cross-issue generalization. We
propose a reasoning-enhanced multimodal large language model (MLLM) pretraining
paradigm for unified inappropriate content detection. To address the
distribution gap between short video content and the original pretraining data
of MLLMs, as well as the complex issue definitions, we introduce three targeted
pretraining tasks: (1) \textit{Caption}, to enhance the MLLM's perception of
video details; (2) \textit{Visual Question Answering (VQA)}, to deepen the
MLLM's understanding of issue definitions and annotation guidelines; (3)
\textit{Chain-of-Thought (CoT)}, to enhance the MLLM's reasoning capability.
Experimental results show that our pretraining approach significantly improves
the MLLM's performance in both zero-shot and supervised fine-tuning (SFT)
settings. In addition, our pretrained model demonstrates strong generalization
capabilities to emergent, previously unseen issues.

</details>


### [78] [Learning GUI Grounding with Spatial Reasoning from Visual Feedback](https://arxiv.org/abs/2509.21552)
*Yu Zhao,Wei-Ning Chen,Huseyin Atahan Inan,Samuel Kessler,Lu Wang,Lukas Wutschitz,Fangkai Yang,Chaoyun Zhang,Pasquale Minervini,Saravan Rajmohan,Robert Sim*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的GUI定位方法，将坐标预测任务重新定义为交互式搜索任务，通过模拟光标在GUI上的移动来定位UI元素。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在处理高分辨率、复杂布局的GUI图像时，难以准确预测坐标。

Method: 该方法使用多步在线强化学习训练GUI-Cursor模型，通过光标的视觉反馈来帮助模型对齐预测位置。

Result: 实验结果表明，GUI-Cursor在ScreenSpot-v2和ScreenSpot-Pro数据集上取得了最先进的结果。

Conclusion: 该模型能够在少数步骤内解决大部分问题，并能自适应地处理更困难的例子。

Abstract: Graphical User Interface (GUI) grounding is commonly framed as a coordinate
prediction task -- given a natural language instruction, generate on-screen
coordinates for actions such as clicks and keystrokes. However, recent Vision
Language Models (VLMs) often fail to predict accurate numeric coordinates when
processing high-resolution GUI images with complex layouts. To address this
issue, we reframe GUI grounding as an \emph{interactive search task}, where the
VLM generates actions to move a cursor in the GUI to locate UI elements. At
each step, the model determines the target object, evaluates the spatial
relations between the cursor and the target, and moves the cursor closer to the
target conditioned on the movement history. In this interactive process, the
rendered cursor provides visual feedback to help the model align its
predictions with the corresponding on-screen locations. We train our GUI
grounding model, GUI-Cursor, using multi-step online reinforcement learning
with a dense trajectory-based reward function. Our experimental results show
that GUI-Cursor, based on Qwen2.5-VL-7B, improves the GUI grounding accuracy
and achieves state-of-the-art results on ScreenSpot-v2 ($88.8\% \rightarrow
93.9\%$) and ScreenSpot-Pro ($26.8\% \rightarrow 56.5\%$). Moreover, we observe
that GUI-Cursor learns to solve the problem within two steps for 95\% of
instances and can adaptively conduct more steps on more difficult examples.

</details>


### [79] [X-CoT: Explainable Text-to-Video Retrieval via LLM-based Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.21559)
*Prasanna Reddy Pulakurthi,Jiamian Wang,Majid Rabbani,Sohail Dianat,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的文本到视频检索框架X-CoT，它使用LLM CoT推理来代替基于嵌入模型的相似度排序，以提高检索性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频检索系统存在两个局限性：低质量的文本-视频数据对会影响检索效果，并且余弦相似度无法解释排序结果。

Method: 该论文提出了X-CoT框架，该框架包含pairwise比较步骤，产生详细的推理和完整的排序。同时，该论文还通过额外的视频注释来扩展现有的基准，以支持语义理解并减少数据偏差。

Result: X-CoT在经验上提高了检索性能，并产生了详细的理由。它还有助于模型行为和数据质量分析。

Conclusion: X-CoT框架可以解释排序结果，从而评估检索模型并检查文本-视频数据。

Abstract: Prevalent text-to-video retrieval systems mainly adopt embedding models for
feature extraction and compute cosine similarities for ranking. However, this
design presents two limitations. Low-quality text-video data pairs could
compromise the retrieval, yet are hard to identify and examine. Cosine
similarity alone provides no explanation for the ranking results, limiting the
interpretability. We ask that can we interpret the ranking results, so as to
assess the retrieval models and examine the text-video data? This work proposes
X-CoT, an explainable retrieval framework upon LLM CoT reasoning in place of
the embedding model-based similarity ranking. We first expand the existing
benchmarks with additional video annotations to support semantic understanding
and reduce data bias. We also devise a retrieval CoT consisting of pairwise
comparison steps, yielding detailed reasoning and complete ranking. X-CoT
empirically improves the retrieval performance and produces detailed
rationales. It also facilitates the model behavior and data quality analysis.
Code and data are available at: https://github.com/PrasannaPulakurthi/X-CoT.

</details>


### [80] [Unsupervised Defect Detection for Surgical Instruments](https://arxiv.org/abs/2509.21561)
*Joseph Huang,Yichi Zhang,Jingxi Yu,Wei Chen,Seunghyun Hwang,Qiang Qiu,Amy R. Reibman,Edward J. Delp,Fengqing Zhu*

Main category: cs.CV

TL;DR: 现有的缺陷检测方法无法有效地转移到手术器械领域。我们提出了一种通用方法，该方法专门用于调整无监督缺陷检测方法，以检测手术器械中的细微缺陷。


<details>
  <summary>Details</summary>
Motivation: 人工检测容易出错，现有的自动缺陷检测方法无法有效转移到手术领域。

Method: 通过整合背景屏蔽、基于补丁的分析策略和有效的领域适应，来调整无监督缺陷检测方法。

Result: 能够可靠地检测手术器械图像中的细微缺陷。

Conclusion: 该方法克服了现有方法的局限性，能够可靠地检测手术器械图像中的细微缺陷。

Abstract: Ensuring the safety of surgical instruments requires reliable detection of
visual defects. However, manual inspection is prone to error, and existing
automated defect detection methods, typically trained on natural/industrial
images, fail to transfer effectively to the surgical domain. We demonstrate
that simply applying or fine-tuning these approaches leads to issues: false
positive detections arising from textured backgrounds, poor sensitivity to
small, subtle defects, and inadequate capture of instrument-specific features
due to domain shift. To address these challenges, we propose a versatile method
that adapts unsupervised defect detection methods specifically for surgical
instruments. By integrating background masking, a patch-based analysis
strategy, and efficient domain adaptation, our method overcomes these
limitations, enabling the reliable detection of fine-grained defects in
surgical instrument imagery.

</details>


### [81] [No Alignment Needed for Generation: Learning Linearly Separable Representations in Diffusion Models](https://arxiv.org/abs/2509.21565)
*Junno Yun,Yaşar Utku Alçalar,Mehmet Akçakaya*

Main category: cs.CV

TL;DR: 本文提出了一种新的扩散模型训练正则化方法，通过提升中间层表示的线性可分性（LSEP）来提高训练效率和生成质量，无需依赖大型预训练编码器。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模扩散模型训练策略强调改进判别特征表示的重要性，但依赖于大型预训练编码器的表征对齐方法计算成本高昂。

Method: 提出了一种基于提升中间层表示线性可分性（LSEP）的训练正则化方法，将线性探测直接融入网络的学习动态中。

Result: 在基于流的Transformer架构（如SiTs）上，训练效率和生成质量都得到了显著提高，在256x256 ImageNet数据集上实现了1.46的FID。

Conclusion: LSEP消除了对辅助编码器和表征对齐的需求，同时将线性探测直接整合到网络的学习动态中，从而提高了训练效率和生成质量。

Abstract: Efficient training strategies for large-scale diffusion models have recently
emphasized the importance of improving discriminative feature representations
in these models. A central line of work in this direction is representation
alignment with features obtained from powerful external encoders, which
improves the representation quality as assessed through linear probing.
Alignment-based approaches show promise but depend on large pretrained
encoders, which are computationally expensive to obtain. In this work, we
propose an alternative regularization for training, based on promoting the
Linear SEParability (LSEP) of intermediate layer representations. LSEP
eliminates the need for an auxiliary encoder and representation alignment,
while incorporating linear probing directly into the network's learning
dynamics rather than treating it as a simple post-hoc evaluation tool. Our
results demonstrate substantial improvements in both training efficiency and
generation quality on flow-based transformer architectures such as SiTs,
achieving an FID of 1.46 on $256 \times 256$ ImageNet dataset.

</details>


### [82] [Enhancing Contrastive Learning for Geolocalization by Discovering Hard Negatives on Semivariograms](https://arxiv.org/abs/2509.21573)
*Boyi Chen,Zhangyu Wang,Fabian Deuser,Johann Maximilian Zollner,Martin Werner*

Main category: cs.CV

TL;DR: 本文提出了一种新的空间正则化对比学习策略，以提高基于图像的地理定位性能，尤其是在更精细的粒度上。


<details>
  <summary>Details</summary>
Motivation: 现有的对比学习方法忽略了地理空间中潜在的空间依赖性，导致难以解决假阴性和区分难负样本的问题。

Method: 该方法集成了半方差函数，这是一种用于建模空间相关性如何随距离变化的地统计工具。通过将图像在特征空间中的距离与其地理距离相关联来拟合半方差函数，从而捕获空间相关性中的预期视觉内容。利用拟合的半方差函数，定义给定空间距离下的预期视觉差异作为参考，以识别难负样本和假阴性。

Result: 在OSV5M数据集上进行了评估，证明了显式建模空间先验知识可以提高基于图像的地理定位性能。

Conclusion: 该研究表明，显式建模空间先验知识可以提高基于图像的地理定位性能，尤其是在更精细的粒度上。

Abstract: Accurate and robust image-based geo-localization at a global scale is
challenging due to diverse environments, visually ambiguous scenes, and the
lack of distinctive landmarks in many regions. While contrastive learning
methods show promising performance by aligning features between street-view
images and corresponding locations, they neglect the underlying spatial
dependency in the geographic space. As a result, they fail to address the issue
of false negatives -- image pairs that are both visually and geographically
similar but labeled as negatives, and struggle to effectively distinguish hard
negatives, which are visually similar but geographically distant. To address
this issue, we propose a novel spatially regularized contrastive learning
strategy that integrates a semivariogram, which is a geostatistical tool for
modeling how spatial correlation changes with distance. We fit the
semivariogram by relating the distance of images in feature space to their
geographical distance, capturing the expected visual content in a spatial
correlation. With the fitted semivariogram, we define the expected visual
dissimilarity at a given spatial distance as reference to identify hard
negatives and false negatives. We integrate this strategy into GeoCLIP and
evaluate it on the OSV5M dataset, demonstrating that explicitly modeling
spatial priors improves image-based geo-localization performance, particularly
at finer granularity.

</details>


### [83] [X-Streamer: Unified Human World Modeling with Audiovisual Interaction](https://arxiv.org/abs/2509.21574)
*You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Guoxian Song,Xiaochen Zhao,Chao Liang,Jianwen Jiang,Hongyi Xu,Linjie Luo*

Main category: cs.CV

TL;DR: X-Streamer是一个端到端的多模态框架，用于构建能够在文本、语音和视频中进行无限交互的数字人代理。


<details>
  <summary>Details</summary>
Motivation: 构建能够进行无限交互的数字人代理。

Method: 使用Thinker-Actor双transformer架构，Thinker模块感知和推理流式用户输入，Actor模块将Thinker的隐藏状态转化为同步的多模态流。

Result: X-Streamer在两个A100 GPU上实时运行，能够从任意肖像维持数小时一致的视频聊天体验。

Conclusion: X-Streamer为交互式数字人的统一世界建模铺平了道路。

Abstract: We introduce X-Streamer, an end-to-end multimodal human world modeling
framework for building digital human agents capable of infinite interactions
across text, speech, and video within a single unified architecture. Starting
from a single portrait, X-Streamer enables real-time, open-ended video calls
driven by streaming multimodal inputs. At its core is a Thinker-Actor
dual-transformer architecture that unifies multimodal understanding and
generation, turning a static portrait into persistent and intelligent
audiovisual interactions. The Thinker module perceives and reasons over
streaming user inputs, while its hidden states are translated by the Actor into
synchronized multimodal streams in real time. Concretely, the Thinker leverages
a pretrained large language-speech model, while the Actor employs a chunk-wise
autoregressive diffusion model that cross-attends to the Thinker's hidden
states to produce time-aligned multimodal responses with interleaved discrete
text and audio tokens and continuous video latents. To ensure long-horizon
stability, we design inter- and intra-chunk attentions with time-aligned
multimodal positional embeddings for fine-grained cross-modality alignment and
context retention, further reinforced by chunk-wise diffusion forcing and
global identity referencing. X-Streamer runs in real time on two A100 GPUs,
sustaining hours-long consistent video chat experiences from arbitrary
portraits and paving the way toward unified world modeling of interactive
digital humans.

</details>


### [84] [What Happens Next? Anticipating Future Motion by Generating Point Trajectories](https://arxiv.org/abs/2509.21592)
*Gabrijel Boduljak,Laurynas Karazija,Iro Laina,Christian Rupprecht,Andrea Vedaldi*

Main category: cs.CV

TL;DR: 本文研究了仅根据单张图像预测物体运动轨迹的问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在单图预测运动方面表现不佳，因为生成像素的开销过大，忽略了直接建模运动。

Method: 提出了一种生成密集轨迹网格的模型，该模型架构与现代视频生成器类似，但输出的是运动轨迹而不是像素。

Result: 在模拟数据上进行了广泛评估，并在机器人等下游应用中展示了其有效性，在现实世界的直观物理数据集上显示出良好的准确性。

Conclusion: 该方法能够捕捉场景范围内的动态和不确定性，产生比现有回归器和生成器更准确和多样的预测。

Abstract: We consider the problem of forecasting motion from a single image, i.e.,
predicting how objects in the world are likely to move, without the ability to
observe other parameters such as the object velocities or the forces applied to
them. We formulate this task as conditional generation of dense trajectory
grids with a model that closely follows the architecture of modern video
generators but outputs motion trajectories instead of pixels. This approach
captures scene-wide dynamics and uncertainty, yielding more accurate and
diverse predictions than prior regressors and generators. We extensively
evaluate our method on simulated data, demonstrate its effectiveness on
downstream applications such as robotics, and show promising accuracy on
real-world intuitive physics datasets. Although recent state-of-the-art video
generators are often regarded as world models, we show that they struggle with
forecasting motion from a single image, even in simple physical scenarios such
as falling blocks or mechanical object interactions, despite fine-tuning on
such data. We show that this limitation arises from the overhead of generating
pixels rather than directly modeling motion.

</details>


### [85] [Temporal vs. Spatial: Comparing DINOv3 and V-JEPA2 Feature Representations for Video Action Analysis](https://arxiv.org/abs/2509.21595)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.CV

TL;DR: DINOv3和V-JEPA2是两种用于视频动作识别的自监督学习架构。DINOv3擅长空间特征提取，而V-JEPA2采用跨视频序列的联合时间建模。该研究在UCF Sports数据集上评估了这两种方法，发现DINOv3在聚类和区分姿势可识别的动作方面表现更好，而V-JEPA2在所有动作类型中表现出一致的可靠性。


<details>
  <summary>Details</summary>
Motivation: 了解视频分析系统中架构设计选择，并为基于任务需求和可靠性约束选择合适的特征提取方法提供经验指导。

Method: 在UCF Sports数据集上评估DINOv3和V-JEPA2，通过分类准确率、聚类性能、类内一致性和类间区分等多个维度检查特征质量。

Result: DINOv3在聚类性能和区分能力方面表现更优，尤其是在姿势可识别的动作方面。V-JEPA2在所有动作类型中表现出一致的可靠性，性能方差较低。DINOv3擅长静态姿势识别，但在运动相关动作上的性能下降，而V-JEPA2的时间建模在不同的动作类别中提供了平衡的表示质量。

Conclusion: DINOv3的空间处理架构擅长静态姿势识别，但V-JEPA2的时间建模在不同的动作类别中提供了平衡的表示质量。这些发现有助于理解视频分析系统中的架构设计选择，并为基于任务需求和可靠性约束选择合适的特征提取方法提供经验指导。

Abstract: This study presents a comprehensive comparative analysis of two prominent
self-supervised learning architectures for video action recognition: DINOv3,
which processes frames independently through spatial feature extraction, and
V-JEPA2, which employs joint temporal modeling across video sequences. We
evaluate both approaches on the UCF Sports dataset, examining feature quality
through multiple dimensions including classification accuracy, clustering
performance, intra-class consistency, and inter-class discrimination. Our
analysis reveals fundamental architectural trade-offs: DINOv3 achieves superior
clustering performance (Silhouette score: 0.31 vs 0.21) and demonstrates
exceptional discrimination capability (6.16x separation ratio) particularly for
pose-identifiable actions, while V-JEPA2 exhibits consistent reliability across
all action types with significantly lower performance variance (0.094 vs
0.288). Through action-specific evaluation, we identify that DINOv3's spatial
processing architecture excels at static pose recognition but shows degraded
performance on motion-dependent actions, whereas V-JEPA2's temporal modeling
provides balanced representation quality across diverse action categories.
These findings contribute to the understanding of architectural design choices
in video analysis systems and provide empirical guidance for selecting
appropriate feature extraction methods based on task requirements and
reliability constraints.

</details>


### [86] [VLCE: A Knowledge-Enhanced Framework for Image Description in Disaster Assessment](https://arxiv.org/abs/2509.21609)
*Md. Mahfuzur Rahman,Kishor Datta Gupta,Marufa Kamal,Fahad Rahman,Sunzida Siddique,Ahmed Rafi Hasan,Mohd Ariful Haque,Roy George*

Main category: cs.CV

TL;DR: 提出了一种名为VLCE的多模态系统，用于生成灾难图像的详细、上下文相关的描述，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统人工评估方法在自然灾害后效率低且危险，而现有的计算机视觉方法无法提供全面的情境理解。

Method: 采用双架构：CNN-LSTM模型（ResNet50骨干，EuroSat预训练）和Vision Transformer模型（ViT，RescueNet预训练），利用ConceptNet和WordNet扩展词汇覆盖并提高描述准确性。

Result: VLCE在InfoMetIC指标上显著超过基线模型，最高达到95.33%，同时保持了有竞争力的语义对齐。

Conclusion: 该双架构系统在自动化生成卫星和无人机照片的信息密集描述方面具有显著潜力，可改进灾害损失评估。

Abstract: Immediate damage assessment is essential after natural catastrophes; yet,
conventional hand evaluation techniques are sluggish and perilous. Although
satellite and unmanned aerial vehicle (UAV) photos offer extensive perspectives
of impacted regions, current computer vision methodologies generally yield just
classification labels or segmentation masks, so constraining their capacity to
deliver a thorough situational comprehension. We introduce the Vision Language
Caption Enhancer (VLCE), a multimodal system designed to produce comprehensive,
contextually-informed explanations of disaster imagery. VLCE employs a
dual-architecture approach: a CNN-LSTM model with a ResNet50 backbone
pretrained on EuroSat satellite imagery for the xBD dataset, and a Vision
Transformer (ViT) model pretrained on UAV pictures for the RescueNet dataset.
Both systems utilize external semantic knowledge from ConceptNet and WordNet to
expand vocabulary coverage and improve description accuracy. We assess VLCE in
comparison to leading vision-language models (LLaVA and QwenVL) utilizing
CLIPScore for semantic alignment and InfoMetIC for caption informativeness.
Experimental findings indicate that VLCE markedly surpasses baseline models,
attaining a maximum of 95.33% on InfoMetIC while preserving competitive
semantic alignment. Our dual-architecture system demonstrates significant
potential for improving disaster damage assessment by automating the production
of actionable, information-dense descriptions from satellite and drone photos.

</details>


### [87] [A Data-driven Typology of Vision Models from Integrated Representational Metrics](https://arxiv.org/abs/2509.21628)
*Jialin Wu,Shreya Saha,Yiqing Bo,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 本文研究了大型视觉模型表征的共性和差异，发现几何结构和参数调整具有家族特异性，而线性可解码信息更广泛地共享。通过融合多种相似性度量，实现了更清晰的模型家族分离，并揭示了模型架构和训练目标共同塑造表征结构的现象。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏有效手段来判断不同架构和训练范式的大型视觉模型之间，哪些表征是共享的，哪些反映了独特的计算策略。

Method: 本文利用一系列表征相似性度量（包括几何、参数调整和线性可解码性），并采用多种互补的度量方法来评估家族可分离性。此外，还借鉴了多组学整合的思路，采用了相似性网络融合（SNF）方法。

Result: 几何结构或参数调整相关的度量方法能够有效区分模型家族，而线性预测等灵活映射方法区分度较弱。SNF方法能够显著提高家族分离效果，并产生稳健的组合特征。聚类结果显示，有监督的ResNets和ViTs形成不同的簇，而所有自监督模型跨架构边界聚集在一起。混合架构（ConvNeXt、Swin）与掩码自动编码器聚类，表明架构现代化和基于重构的训练之间存在收敛性。

Conclusion: 研究表明，涌现的计算策略（由架构和训练目标共同塑造）定义了表征结构，超越了表面设计类别。

Abstract: Large vision models differ widely in architecture and training paradigm, yet
we lack principled methods to determine which aspects of their representations
are shared across families and which reflect distinctive computational
strategies. We leverage a suite of representational similarity metrics, each
capturing a different facet-geometry, unit tuning, or linear decodability-and
assess family separability using multiple complementary measures. Metrics
preserving geometry or tuning (e.g., RSA, Soft Matching) yield strong family
discrimination, whereas flexible mappings such as Linear Predictivity show
weaker separation. These findings indicate that geometry and tuning carry
family-specific signatures, while linearly decodable information is more
broadly shared. To integrate these complementary facets, we adapt Similarity
Network Fusion (SNF), a method inspired by multi-omics integration. SNF
achieves substantially sharper family separation than any individual metric and
produces robust composite signatures. Clustering of the fused similarity matrix
recovers both expected and surprising patterns: supervised ResNets and ViTs
form distinct clusters, yet all self-supervised models group together across
architectural boundaries. Hybrid architectures (ConvNeXt, Swin) cluster with
masked autoencoders, suggesting convergence between architectural modernization
and reconstruction-based training. This biology-inspired framework provides a
principled typology of vision models, showing that emergent computational
strategies-shaped jointly by architecture and training objective-define
representational structure beyond surface design categories.

</details>


### [88] [FantasyWorld: Geometry-Consistent World Modeling via Unified Video and 3D Prediction](https://arxiv.org/abs/2509.21657)
*Yixiang Dai,Fan Jiang,Chiyu Wang,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyWorld是一个增强视频基础模型的框架，使其具有3D感知能力，从而改善空间一致性和3D推理任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视频基础模型缺乏明确的3D基础能力，限制了它们在空间一致性和下游3D推理任务中的应用。

Method: 该框架通过可训练的几何分支增强冻结的视频基础模型，从而能够以单次前向传递方式联合建模视频潜在空间和隐式3D场。引入了跨分支监督，其中几何线索指导视频生成，视频先验正则化3D预测。

Result: FantasyWorld有效地桥接了视频想象和3D感知，在多视角一致性和风格一致性方面优于最近的几何一致性基线。

Conclusion: 统一的骨干网络和跨分支信息交换带来了性能提升。几何分支产生的潜在空间可以作为下游3D任务的多功能表示，例如新视角合成和导航，而无需每次场景优化或微调。

Abstract: High-quality 3D world models are pivotal for embodied intelligence and
Artificial General Intelligence (AGI), underpinning applications such as AR/VR
content creation and robotic navigation. Despite the established strong
imaginative priors, current video foundation models lack explicit 3D grounding
capabilities, thus being limited in both spatial consistency and their utility
for downstream 3D reasoning tasks. In this work, we present FantasyWorld, a
geometry-enhanced framework that augments frozen video foundation models with a
trainable geometric branch, enabling joint modeling of video latents and an
implicit 3D field in a single forward pass. Our approach introduces
cross-branch supervision, where geometry cues guide video generation and video
priors regularize 3D prediction, thus yielding consistent and generalizable
3D-aware video representations. Notably, the resulting latents from the
geometric branch can potentially serve as versatile representations for
downstream 3D tasks such as novel view synthesis and navigation, without
requiring per-scene optimization or fine-tuning. Extensive experiments show
that FantasyWorld effectively bridges video imagination and 3D perception,
outperforming recent geometry-consistent baselines in multi-view coherence and
style consistency. Ablation studies further confirm that these gains stem from
the unified backbone and cross-branch information exchange.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [Towards mitigating information leakage when evaluating safety monitors](https://arxiv.org/abs/2509.21344)
*Gerard Boxo,Aman Neelappa,Shivam Raval*

Main category: cs.AI

TL;DR: 这篇论文研究了在大型语言模型中检测有害行为的白盒监控器的评估方法，并提出了缓解数据泄露的三种策略。


<details>
  <summary>Details</summary>
Motivation: 现有的监控器评估方法容易受到数据泄露的影响，导致评估结果虚高。

Method: 提出了一个系统性的框架，用于评估监控器检测真实模型行为的能力，并提出了内容过滤、分数过滤和prompt distilled fine-tuned model organisms三种策略。

Result: 实验结果表明，内容过滤是一种有效的缓解策略，可以显著降低监控器的AUROC值。分数过滤也能降低AUROC值，但效果不如内容过滤。Finetuned model organism可以改进监控器评估，但也会降低其性能。

Conclusion: 论文揭示了数据泄露对监控器性能评估的影响，并为缓解这些问题提供了可行的策略。

Abstract: White box monitors that analyze model internals offer promising advantages
for detecting potentially harmful behaviors in large language models, including
lower computational costs and integration into layered defense systems.However,
training and evaluating these monitors requires response exemplars that exhibit
the target behaviors, typically elicited through prompting or fine-tuning. This
presents a challenge when the information used to elicit behaviors inevitably
leaks into the data that monitors ingest, inflating their effectiveness. We
present a systematic framework for evaluating a monitor's performance in terms
of its ability to detect genuine model behavior rather than superficial
elicitation artifacts. Furthermore, we propose three novel strategies to
evaluate the monitor: content filtering (removing deception-related text from
inputs), score filtering (aggregating only over task-relevant tokens), and
prompt distilled fine-tuned model organisms (models trained to exhibit
deceptive behavior without explicit prompting). Using deception detection as a
representative case study, we identify two forms of leakage that inflate
monitor performance: elicitation leakage from prompts that explicitly request
harmful behavior, and reasoning leakage from models that verbalize their
deceptive actions. Through experiments on multiple deception benchmarks, we
apply our proposed mitigation strategies and measure performance retention. Our
evaluation of the monitors reveal three crucial findings: (1) Content filtering
is a good mitigation strategy that allows for a smooth removal of elicitation
signal and can decrease probe AUROC by 30\% (2) Score filtering was found to
reduce AUROC by 15\% but is not as straightforward to attribute to (3) A
finetuned model organism improves monitor evaluations but reduces their
performance by upto 40\%, even when re-trained.

</details>


### [90] [Correct Reasoning Paths Visit Shared Decision Pivots](https://arxiv.org/abs/2509.21549)
*Dongkyu Cho,Amy B. Z. Zhang,Bilel Fehri,Sheng Wang,Rumi Chunara,Rui Song,Hengrui Cai*

Main category: cs.AI

TL;DR: 本文提出了一种通过决策枢纽来验证大规模语言模型(llm)中间思维过程的方法。


<details>
  <summary>Details</summary>
Motivation: 验证llm中间思维过程的现有方法存在不足。

Method: 该方法包括:(i)采样不同的推理路径并挖掘共享的决策枢纽;(ii)使用辅助验证器将每个跟踪压缩为以枢纽为中心的短路径推理;(iii)使用其自我生成的输出对模型进行后训练。

Result: 在LogiQA、MedQA和MATH500等标准基准测试中，该方法的有效性得到了验证。

Conclusion: 该方法无需ground truth推理数据或外部指标即可对齐推理。

Abstract: Chain-of-thought (CoT) reasoning exposes the intermediate thinking process of
large language models (LLMs), yet verifying those traces at scale remains
unsolved. In response, we introduce the idea of decision pivots-minimal,
verifiable checkpoints that any correct reasoning path must visit. We
hypothesize that correct reasoning, though stylistically diverse, converge on
the same pivot set, while incorrect ones violate at least one pivot. Leveraging
this property, we propose a self-training pipeline that (i) samples diverse
reasoning paths and mines shared decision pivots, (ii) compresses each trace
into pivot-focused short-path reasoning using an auxiliary verifier, and (iii)
post-trains the model using its self-generated outputs. The proposed method
aligns reasoning without ground truth reasoning data or external metrics.
Experiments on standard benchmarks such as LogiQA, MedQA, and MATH500 show the
effectiveness of our method.

</details>


### [91] [AutoClimDS: Climate Data Science Agentic AI -- A Knowledge Graph is All You Need](https://arxiv.org/abs/2509.21553)
*Ahmed Jaber,Wangshu Zhu,Karthick Jayavelu,Justin Downes,Sameer Mohamed,Candace Agonafir,Linnia Hawkins,Tian Zheng*

Main category: cs.AI

TL;DR: 知识图谱和人工智能代理可以降低气候数据科学的技术门槛，使非专业用户也能识别和分析相关数据集。


<details>
  <summary>Details</summary>
Motivation: 气候数据科学面临数据来源分散、格式异构以及需要深厚技术专业知识等障碍，限制了参与，减缓了发现，并降低了科学工作流程的可重复性。

Method: 通过集成一个精选的知识图谱（KG）与专为云原生科学工作流程设计的人工智能代理来解决这些障碍。

Result: 利用现有的云就绪API数据门户，证明了“知识图谱是你所需要的一切”来解锁可扩展的和具有代理性的科学探究工作流程。

Conclusion: 我们的结果展示了一条 democratizing 气候数据访问的途径，并建立了一个可重复的、可扩展的框架，用于科学研究中的人-机协作。

Abstract: Climate data science faces persistent barriers stemming from the fragmented
nature of data sources, heterogeneous formats, and the steep technical
expertise required to identify, acquire, and process datasets. These challenges
limit participation, slow discovery, and reduce the reproducibility of
scientific workflows. In this paper, we present a proof of concept for
addressing these barriers through the integration of a curated knowledge graph
(KG) with AI agents designed for cloud-native scientific workflows. The KG
provides a unifying layer that organizes datasets, tools, and workflows, while
AI agents -- powered by generative AI services -- enable natural language
interaction, automated data access, and streamlined analysis. Together, these
components drastically lower the technical threshold for engaging in climate
data science, enabling non-specialist users to identify and analyze relevant
datasets. By leveraging existing cloud-ready API data portals, we demonstrate
that "a knowledge graph is all you need" to unlock scalable and agentic
workflows for scientific inquiry. The open-source design of our system further
supports community contributions, ensuring that the KG and associated tools can
evolve as a shared commons. Our results illustrate a pathway toward
democratizing access to climate data and establishing a reproducible,
extensible framework for human--AI collaboration in scientific research.

</details>


### [92] [EEG-Based Consumer Behaviour Prediction: An Exploration from Classical Machine Learning to Graph Neural Networks](https://arxiv.org/abs/2509.21567)
*Mohammad Parsa Afshar,Aryan Azimi*

Main category: cs.AI

TL;DR: 本文利用脑电图（EEG）数据预测消费者行为，通过比较不同的机器学习模型，包括经典模型和图神经网络（GNN），发现GNN模型在某些基本标准上表现更好。


<details>
  <summary>Details</summary>
Motivation: 利用脑电图数据分析决策过程，从而预测消费者行为。

Method: 提取和清洗NeuMa数据集的脑电图数据特征，构建大脑连接特征，并比较不同的机器学习模型，包括经典模型和图神经网络。

Result: GNN模型在某些基本标准上表现优于经典模型，但总体差异不显著。

Conclusion: 结合脑电图信号分析和机器学习模型可以更深入地理解消费者行为，并全面比较了脑电图神经营销中常用的机器学习模型（如支持向量机）和较少使用的模型（如图神经网络）。

Abstract: Prediction of consumer behavior is one of the important purposes in
marketing, cognitive neuroscience, and human-computer interaction. The
electroencephalography (EEG) data can help analyze the decision process by
providing detailed information about the brain's neural activity. In this
research, a comparative approach is utilized for predicting consumer behavior
by EEG data. In the first step, the features of the EEG data from the NeuMa
dataset were extracted and cleaned. For the Graph Neural Network (GNN) models,
the brain connectivity features were created. Different machine learning
models, such as classical models and Graph Neural Networks, are used and
compared. The GNN models with different architectures are implemented to have a
comprehensive comparison; furthermore, a wide range of classical models, such
as ensemble models, are applied, which can be very helpful to show the
difference and performance of each model on the dataset. Although the results
did not show a significant difference overall, the GNN models generally
performed better in some basic criteria where classical models were not
satisfactory. This study not only shows that combining EEG signal analysis and
machine learning models can provide an approach to deeper understanding of
consumer behavior, but also provides a comprehensive comparison between the
machine learning models that have been widely used in previous studies in the
EEG-based neuromarketing such as Support Vector Machine (SVM), and the models
which are not used or rarely used in the field, like Graph Neural Networks.

</details>


### [93] [GeoEvolve: Automating Geospatial Model Discovery via Multi-Agent Large Language Models](https://arxiv.org/abs/2509.21593)
*Peng Luo,Xiayin Lou,Yu Zheng,Zhuo Zheng,Stefano Ermon*

Main category: cs.AI

TL;DR: GeoEvolve is a multi-agent LLM framework that uses evolutionary search and a geospatial knowledge base to automatically design and refine geospatial algorithms.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-based algorithm discovery frameworks lack the domain knowledge and multi-step reasoning required for complex geospatial problems.

Method: GeoEvolve uses a code evolver in an inner loop and an agentic controller with a GeoKnowRAG module in an outer loop to generate, mutate, and evaluate geospatial algorithms.

Result: GeoEvolve improves and discovers new algorithms, reducing spatial interpolation error by 13-21% and enhancing uncertainty estimation performance by 17%.

Conclusion: GeoEvolve provides a scalable path toward automated, knowledge-driven geospatial modeling.

Abstract: Geospatial modeling provides critical solutions for pressing global
challenges such as sustainability and climate change. Existing large language
model (LLM)-based algorithm discovery frameworks, such as AlphaEvolve, excel at
evolving generic code but lack the domain knowledge and multi-step reasoning
required for complex geospatial problems. We introduce GeoEvolve, a multi-agent
LLM framework that couples evolutionary search with geospatial domain knowledge
to automatically design and refine geospatial algorithms. GeoEvolve operates in
two nested loops: an inner loop leverages a code evolver to generate and mutate
candidate solutions, while an outer agentic controller evaluates global elites
and queries a GeoKnowRAG module -- a structured geospatial knowledge base that
injects theoretical priors from geography. This knowledge-guided evolution
steers the search toward theoretically meaningful and computationally efficient
algorithms. We evaluate GeoEvolve on two fundamental and classical tasks:
spatial interpolation (kriging) and spatial uncertainty quantification
(geospatial conformal prediction). Across these benchmarks, GeoEvolve
automatically improves and discovers new algorithms, incorporating geospatial
theory on top of classical models. It reduces spatial interpolation error
(RMSE) by 13-21% and enhances uncertainty estimation performance by 17\%.
Ablation studies confirm that domain-guided retrieval is essential for stable,
high-quality evolution. These results demonstrate that GeoEvolve provides a
scalable path toward automated, knowledge-driven geospatial modeling, opening
new opportunities for trustworthy and efficient AI-for-Science discovery.

</details>


### [94] [Automated and Interpretable Survival Analysis from Multimodal Data](https://arxiv.org/abs/2509.21600)
*Mafalda Malafaia,Peter A. N. Bosman,Coen Rasch,Tanja Alderliesten*

Main category: cs.AI

TL;DR: 提出了一种可解释的多模态人工智能框架MultiFIX，用于自动化生存分析，集成了临床变量和CT成像。


<details>
  <summary>Details</summary>
Motivation: 在肿瘤学中，准确和可解释的生存分析仍然是一个核心挑战。随着多模态数据的增长和对透明模型以支持验证和信任的临床需求，这一挑战的复杂性也在增加。

Method: 该框架使用深度学习来推断生存相关的特征，并通过Grad-CAM解释成像特征，同时通过遗传编程将临床变量建模为符号表达式。风险估计采用透明的Cox回归。

Result: 在头颈癌的RADCURE数据集上，MultiFIX实现了0.838的C-index（预测）和0.826（分层），优于临床和学术基线方法，并与已知的预后标志物对齐。

Conclusion: 这些结果突出了可解释的多模态人工智能在精准肿瘤学中MultiFIX的应用前景。

Abstract: Accurate and interpretable survival analysis remains a core challenge in
oncology. With growing multimodal data and the clinical need for transparent
models to support validation and trust, this challenge increases in complexity.
We propose an interpretable multimodal AI framework to automate survival
analysis by integrating clinical variables and computed tomography imaging. Our
MultiFIX-based framework uses deep learning to infer survival-relevant features
that are further explained: imaging features are interpreted via Grad-CAM,
while clinical variables are modeled as symbolic expressions through genetic
programming. Risk estimation employs a transparent Cox regression, enabling
stratification into groups with distinct survival outcomes. Using the
open-source RADCURE dataset for head and neck cancer, MultiFIX achieves a
C-index of 0.838 (prediction) and 0.826 (stratification), outperforming the
clinical and academic baseline approaches and aligning with known prognostic
markers. These results highlight the promise of interpretable multimodal AI for
precision oncology with MultiFIX.

</details>


### [95] [Semantic F1 Scores: Fair Evaluation Under Fuzzy Class Boundaries](https://arxiv.org/abs/2509.21633)
*Georgios Chochlakis,Jackson Trager,Vedant Jhaveri,Nikhil Ravichandran,Alexandros Potamianos,Shrikanth Narayanan*

Main category: cs.AI

TL;DR: 提出了语义F1分数，用于评估主观或模糊的多标签分类，量化预测标签和真实标签之间的语义相关性。


<details>
  <summary>Details</summary>
Motivation: 传统F1指标将语义相关的预测视为完全失败，为了解决这个问题。

Method: 引入标签相似度矩阵来计算软精确率和召回率，从而得出语义F1分数。采用新颖的两步精确率-召回率公式，能够比较任意大小的标签集，而无需丢弃标签或强制匹配不相似的标签。

Result: 通过理论验证和在合成数据和真实数据上的大量实证验证，表明语义F1具有更好的可解释性和生态有效性。

Conclusion: 语义F1只需要一个适合领域的相似度矩阵，该矩阵对错误指定具有鲁棒性，并且不依赖于严格的本体，因此它适用于各种任务和模式。

Abstract: We propose Semantic F1 Scores, novel evaluation metrics for subjective or
fuzzy multi-label classification that quantify semantic relatedness between
predicted and gold labels. Unlike the conventional F1 metrics that treat
semantically related predictions as complete failures, Semantic F1 incorporates
a label similarity matrix to compute soft precision-like and recall-like
scores, from which the Semantic F1 scores are derived. Unlike existing
similarity-based metrics, our novel two-step precision-recall formulation
enables the comparison of label sets of arbitrary sizes without discarding
labels or forcing matches between dissimilar labels. By granting partial credit
for semantically related but nonidentical labels, Semantic F1 better reflects
the realities of domains marked by human disagreement or fuzzy category
boundaries. In this way, it provides fairer evaluations: it recognizes that
categories overlap, that annotators disagree, and that downstream decisions
based on similar predictions lead to similar outcomes. Through theoretical
justification and extensive empirical validation on synthetic and real data, we
show that Semantic F1 demonstrates greater interpretability and ecological
validity. Because it requires only a domain-appropriate similarity matrix,
which is robust to misspecification, and not a rigid ontology, it is applicable
across tasks and modalities.

</details>


### [96] [Can AI Perceive Physical Danger and Intervene?](https://arxiv.org/abs/2509.21651)
*Abhishek Jindal,Dmitry Kalashnikov,Oscar Chang,Divya Garikapati,Anirudha Majumdar,Pierre Sermanet,Vikas Sindhwani*

Main category: cs.AI

TL;DR: 该论文研究了具身人工智能系统中的物理安全问题，并提出了一个可扩展的基准测试方法。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能在与物理世界交互时，存在潜在的物理伤害风险，需要评估现有模型对物理安全常识的理解程度。

Method: 1. 开发了一个可扩展的基准测试方法，基于真实世界的伤害叙述和操作安全约束，利用生成模型生成照片级图像和视频。
2. 全面分析了主流基础模型感知风险、推理安全和触发干预的能力。
3. 开发了一种后训练范式，教导模型显式地推理具身安全约束。

Result: 对主要基础模型进行了多方面的分析，获得了关于它们在安全关键应用中部署准备情况的深入见解。通过后训练，模型能够生成可解释和透明的推理过程，并在约束满足评估中达到最佳性能。

Conclusion: 该研究提出了一个用于评估和提高具身人工智能系统物理安全性的有效方法。

Abstract: When AI interacts with the physical world -- as a robot or an assistive agent
-- new safety challenges emerge beyond those of purely ``digital AI". In such
interactions, the potential for physical harm is direct and immediate. How well
do state-of-the-art foundation models understand common-sense facts about
physical safety, e.g. that a box may be too heavy to lift, or that a hot cup of
coffee should not be handed to a child? In this paper, our contributions are
three-fold: first, we develop a highly scalable approach to continuous physical
safety benchmarking of Embodied AI systems, grounded in real-world injury
narratives and operational safety constraints. To probe multi-modal safety
understanding, we turn these narratives and constraints into photorealistic
images and videos capturing transitions from safe to unsafe states, using
advanced generative models. Secondly, we comprehensively analyze the ability of
major foundation models to perceive risks, reason about safety, and trigger
interventions; this yields multi-faceted insights into their deployment
readiness for safety-critical agentic applications. Finally, we develop a
post-training paradigm to teach models to explicitly reason about
embodiment-specific safety constraints provided through system instructions.
The resulting models generate thinking traces that make safety reasoning
interpretable and transparent, achieving state of the art performance in
constraint satisfaction evaluations. The benchmark will be released at
https://asimov-benchmark.github.io/v2

</details>


### [97] [Align2Speak: Improving TTS for Low Resource Languages via ASR-Guided Online Preference Optimization](https://arxiv.org/abs/2509.21718)
*Shehzeen Hussain,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Subhankar Ghosh,Roy Fejgin,Ryan Langman,Mikyas Desta,Leili Tavabi,Jason Li*

Main category: cs.AI

TL;DR: 提出了一种基于Group Relative Policy Optimization (GRPO)的框架，用于将多语言TTS模型适应到新的语言，尤其是在低资源语言环境下。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏配对的文本和语音数据，为低资源语言开发高质量的文本到语音（TTS）系统具有挑战性。而自动语音识别（ASR）模型因大规模多语言预训练而更容易获得。

Method: 首先，通过使用国际音标（IPA）token训练多语言基线，为TTS合成建立与语言无关的基础。然后，在新的语言的有限配对数据上微调该模型，以捕获目标语言的韵律特征。最后，应用GRPO，仅使用未配对的文本和说话者提示来优化模型，并通过来自预训练的ASR、说话者验证和音频质量估计模型的多目标奖励进行指导。

Result: 实验表明，该流程可以在低资源语言中生成清晰且说话者一致的语音，大大优于单独的微调。此外，我们的基于GRPO的框架还提高了高资源语言的TTS性能，超过了离线对齐方法，例如直接偏好优化（DPO），从而产生更高的可理解性、说话者相似性和音频质量。

Conclusion: 该研究提出了一种有效的框架，利用GRPO优化多语言TTS模型在低资源和高资源语言上的表现，实验结果表明该方法在可理解性、说话人相似度和音频质量方面均有提升。

Abstract: Developing high-quality text-to-speech (TTS) systems for low-resource
languages is challenging due to the scarcity of paired text and speech data. In
contrast, automatic speech recognition (ASR) models for such languages are
often more accessible, owing to large-scale multilingual pre-training efforts.
We propose a framework based on Group Relative Policy Optimization (GRPO) to
adapt an autoregressive, multilingual TTS model to new languages. Our method
first establishes a language-agnostic foundation for TTS synthesis by training
a multilingual baseline with International Phonetic Alphabet (IPA) tokens.
Next, we fine-tune this model on limited paired data of the new languages to
capture the target language's prosodic features. Finally, we apply GRPO to
optimize the model using only unpaired text and speaker prompts, guided by a
multi-objective reward from pretrained ASR, speaker verification, and audio
quality estimation models. Experiments demonstrate that this pipeline produces
intelligible and speaker-consistent speech in low-resource languages,
substantially outperforming fine-tuning alone. Furthermore, our GRPO-based
framework also improves TTS performance in high-resource languages, surpassing
offline alignment methods such as Direct Preference Optimization (DPO) yielding
superior intelligibility, speaker similarity, and audio quality.

</details>


### [98] [Retrieval-of-Thought: Efficient Reasoning via Reusing Thoughts](https://arxiv.org/abs/2509.21743)
*Ammar Ahmed,Azal Ahmad Khan,Ayaan Ahmad,Sheng Di,Zirui Liu,Ali Anwar*

Main category: cs.AI

TL;DR: 这篇论文提出了一种名为 Retrieval-of-Thought (RoT) 的方法，旨在提高大型推理模型的推理效率，同时保持准确性。RoT 通过检索和重用先前的推理步骤来指导新问题，从而减少冗余探索，降低输出 tokens，并提高推理速度。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过生成长的推理过程来提高准确性，但这会增加延迟和成本，因此需要提高推理效率。

Method: RoT 构建了一个思想图，其中包含顺序和语义边，以实现快速检索和灵活重组。在推理时，RoT 检索与查询相关的节点，并应用奖励引导的遍历来组装一个特定于问题的模板，该模板指导生成。

Result: 实验结果表明，RoT 能够减少高达 40% 的输出 tokens，降低 82% 的推理延迟和 59% 的成本，同时保持准确性。

Conclusion: RoT 建立了一种可扩展的范例，通过检索动态模板构建来实现高效的 LRM 推理。

Abstract: Large reasoning models improve accuracy by producing long reasoning traces,
but this inflates latency and cost, motivating inference-time efficiency. We
propose Retrieval-of-Thought (RoT), which reuses prior reasoning as composable
``thought" steps to guide new problems. RoT organizes steps into a thought
graph with sequential and semantic edges to enable fast retrieval and flexible
recombination. At inference, RoT retrieves query-relevant nodes and applies
reward-guided traversal to assemble a problem-specific template that guides
generation. This dynamic template reuse reduces redundant exploration and,
therefore, reduces output tokens while preserving accuracy. We evaluate RoT on
reasoning benchmarks with multiple models, measuring accuracy, token usage,
latency, and memory overhead. Findings show small prompt growth but substantial
efficiency gains, with RoT reducing output tokens by up to 40%, inference
latency by 82%, and cost by 59% while maintaining accuracy. RoT establishes a
scalable paradigm for efficient LRM reasoning via dynamic template construction
through retrieval.

</details>


### [99] [Lifelong Learning with Behavior Consolidation for Vehicle Routing](https://arxiv.org/abs/2509.21765)
*Jiyuan Pei,Yi Mei,Jialin Liu,Mengjie Zhang,Xin Yao*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的终身学习范式，用于解决神经车辆路径问题 (VRP) 求解器中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有的神经求解器通常在预定义的单一或一组问题分布和规模上进行一次性训练。当出现新任务时，它们要么依赖于零样本泛化，要么对预训练的求解器进行微调，这可能导致灾难性遗忘。

Method: 该论文提出了一个名为 LLR-BC 的新框架，通过对齐在新任务上训练的求解器的行为与缓冲的行为来有效地巩固先前的知识。为了鼓励更多地关注关键经验，LLR-BC 为置信度较低的决策分配更大的权重。

Result: 在车辆路径问题和旅行商问题上的大量实验表明，LLR-BC 在终身学习环境中训练高性能神经求解器方面是有效的，解决了灾难性遗忘问题，保持了它们的可塑性，并提高了零样本泛化能力。

Conclusion: LLR-BC 框架有效地解决了终身学习环境中神经 VRP 求解器的灾难性遗忘问题，并提高了零样本泛化能力。

Abstract: Recent neural solvers have demonstrated promising performance in learning to
solve routing problems. However, existing studies are primarily based on
one-off training on one or a set of predefined problem distributions and
scales, i.e., tasks. When a new task arises, they typically rely on either
zero-shot generalization, which may be poor due to the discrepancies between
the new task and the training task(s), or fine-tuning the pretrained solver on
the new task, which possibly leads to catastrophic forgetting of knowledge
acquired from previous tasks. This paper explores a novel lifelong learning
paradigm for neural VRP solvers, where multiple tasks with diverse
distributions and scales arise sequentially over time. Solvers are required to
effectively and efficiently learn to solve new tasks while maintaining their
performance on previously learned tasks. Consequently, a novel framework called
Lifelong Learning Router with Behavior Consolidation (LLR-BC) is proposed.
LLR-BC consolidates prior knowledge effectively by aligning behaviors of the
solver trained on a new task with the buffered ones in a decision-seeking way.
To encourage more focus on crucial experiences, LLR-BC assigns greater
consolidated weights to decisions with lower confidence. Extensive experiments
on capacitated vehicle routing problems and traveling salesman problems
demonstrate LLR-BC's effectiveness in training high-performance neural solvers
in a lifelong learning setting, addressing the catastrophic forgetting issue,
maintaining their plasticity, and improving zero-shot generalization ability.

</details>


### [100] [UltraHorizon: Benchmarking Agent Capabilities in Ultra Long-Horizon Scenarios](https://arxiv.org/abs/2509.21766)
*Haotian Luo,Huaisong Zhang,Xuelin Zhang,Haoyu Wang,Zeyu Qin,Wenjie Lu,Guozheng Ma,Haiying He,Yingsha Xie,Qiyang Zhou,Zixuan Hu,Hongze Mi,Yibo Wang,Naiqiang Tan,Hong Chen,Yi R. Fung,Chun Yuan,Li Shen*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为UltraHorizon的新基准，用于评估自主agent在长程、部分可观察场景下的能力，例如软件开发、商业投资和科学发现。


<details>
  <summary>Details</summary>
Motivation: 现有基准很少能捕捉到长程挑战，导致系统评估存在差距。为了弥合这一差距，我们引入了UltraHorizon。

Method: 使用探索作为统一任务，在三个不同的环境中进行验证。

Result: LLM-agent在这些设置中表现不佳，而人类参与者获得了更高的分数，这表明agent的长期能力仍然存在差距。

Conclusion: 简单的扩展无法解决agent在长程任务中的失败。我们通过深入分析收集到的轨迹，确定了八种类型的错误，并将它们归因于两个主要原因：上下文锁定和功能性基本能力差距。

Abstract: Autonomous agents have recently achieved remarkable progress across diverse
domains, yet most evaluations focus on short-horizon, fully observable tasks.
In contrast, many critical real-world tasks, such as large-scale software
development, commercial investment, and scientific discovery, unfold in
long-horizon and partially observable scenarios where success hinges on
sustained reasoning, planning, memory management, and tool use. Existing
benchmarks rarely capture these long-horizon challenges, leaving a gap in
systematic evaluation. To bridge this gap, we introduce \textbf{UltraHorizon} a
novel benchmark that measures the foundational capabilities essential for
complex real-world challenges. We use exploration as a unifying task across
three distinct environments to validate these core competencies. Agents are
designed in long-horizon discovery tasks where they must iteratively uncover
hidden rules through sustained reasoning, planning, memory and tools
management, and interaction with environments. Under the heaviest scale
setting, trajectories average \textbf{200k+} tokens and \textbf{400+} tool
calls, whereas in standard configurations they still exceed \textbf{35k} tokens
and involve more than \textbf{60} tool calls on average. Our extensive
experiments reveal that LLM-agents consistently underperform in these settings,
whereas human participants achieve higher scores, underscoring a persistent gap
in agents' long-horizon abilities. We also observe that simple scaling fails in
our task. To better illustrate the failure of agents, we conduct an in-depth
analysis of collected trajectories. We identify eight types of errors and
attribute them to two primary causes: in-context locking and functional
fundamental capability gaps.
\href{https://github.com/StarDewXXX/UltraHorizon}{Our code will be available
here.}

</details>


### [101] [Benchmarking MLLM-based Web Understanding: Reasoning, Robustness and Safety](https://arxiv.org/abs/2509.21782)
*Junliang Liu,Jingyu Xiao,Wenxin Tang,Wenxuan Wang,Zhixian Wang,Minrui Zhang,Shuanghe Yu*

Main category: cs.AI

TL;DR: WebRSSBench是一个综合性的网络理解基准，用于评估MLLM在网络应用中的推理、鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准在评估MLLM在构建复杂网络应用（如GUI代理和前端代码生成）所需的推理、鲁棒性和安全性方面不足。

Method: 提出了WebRSSBench基准，它包含8个任务，涵盖位置关系推理、颜色鲁棒性和安全关键检测等方面。该基准包含来自729个网站的3799个问答对，用于探测页面结构、文本、组件和安全关键交互上的多步骤推理。

Result: 对12个MLLM在WebRSSBench上进行了评估，结果表明模型在组合和跨元素推理、鲁棒性以及识别和避免安全关键或不可逆操作方面存在显著差距。

Conclusion: MLLM在处理实际布局上的组合推理和跨元素推理仍然面临挑战，在面对用户界面和内容中的扰动时鲁棒性有限，并且在识别和避免安全关键或不可逆操作方面表现保守。

Abstract: Multimodal large language models (MLLMs) are increasingly positioned as AI
collaborators for building complex web-related applications like GUI agents and
front-end code generation. However, existing benchmarks largely emphasize
visual perception or UI code generation, showing insufficient evaluation on the
reasoning, robustness and safety capability required for end-to-end web
applications. To bridge the gap, we introduce a comprehensive web understanding
benchmark, named WebRSSBench, that jointly evaluates Reasoning, Robustness, and
Safety across eight tasks, such as position relationship reasoning, color
robustness, and safety critical detection, etc. The benchmark is constructed
from 729 websites and contains 3799 question answer pairs that probe multi-step
inference over page structure, text, widgets, and safety-critical interactions.
To ensure reliable measurement, we adopt standardized prompts, deterministic
evaluation scripts, and multi-stage quality control combining automatic checks
with targeted human verification. We evaluate 12 MLLMs on WebRSSBench. The
results reveal significant gaps, models still struggle with compositional and
cross-element reasoning over realistic layouts, show limited robustness when
facing perturbations in user interfaces and content such as layout
rearrangements or visual style shifts, and are rather conservative in
recognizing and avoiding safety critical or irreversible actions. Our code is
available at https://github.com/jinliang-byte/webssrbench.

</details>


### [102] [D-Artemis: A Deliberative Cognitive Framework for Mobile GUI Multi-Agents](https://arxiv.org/abs/2509.21799)
*Hongze Mi,Yibo Feng,Wenjie Lu,Yuqi Wang,Jinyuan Li,Song Cao,He Cui,Tengfei Tian,Xuelin Zhang,Haotian Luo,Di Sun,Naiqiang Tan,Gang Pan*

Main category: cs.AI

TL;DR: D-Artemis是一个新的GUI代理框架，它通过模仿人类的认知循环来自动化任务，无需在复杂的数据集上训练即可实现强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理方法存在数据瓶颈、错误检测成本高以及指导冲突的风险。

Method: D-Artemis利用细粒度的应用特定提示检索机制，并通过预执行对齐阶段、思想-行动一致性检查模块和行动校正代理来降低执行失败的风险。后执行状态反射代理完成认知循环，从而能够从经验中进行战略学习。

Result: D-Artemis在AndroidWorld上实现了75.8%的成功率，在ScreenSpot-V2上实现了96.8%的成功率，建立了新的最先进水平。

Conclusion: D-Artemis通过增强通用多模态大型语言模型（MLLM）的能力，无需在复杂的轨迹数据集上进行训练，即可在GUI任务中实现强大的泛化能力。

Abstract: Graphical User Interface (GUI) agents aim to automate a wide spectrum of
human tasks by emulating user interaction. Despite rapid advancements, current
approaches are hindered by several critical challenges: data bottleneck in
end-to-end training, high cost of delayed error detection, and risk of
contradictory guidance. Inspired by the human cognitive loop of Thinking,
Alignment, and Reflection, we present D-Artemis -- a novel deliberative
framework in this paper. D-Artemis leverages a fine-grained, app-specific tip
retrieval mechanism to inform its decision-making process. It also employs a
proactive Pre-execution Alignment stage, where Thought-Action Consistency (TAC)
Check module and Action Correction Agent (ACA) work in concert to mitigate the
risk of execution failures. A post-execution Status Reflection Agent (SRA)
completes the cognitive loop, enabling strategic learning from experience.
Crucially, D-Artemis enhances the capabilities of general-purpose Multimodal
large language models (MLLMs) for GUI tasks without the need for training on
complex trajectory datasets, demonstrating strong generalization. D-Artemis
establishes new state-of-the-art (SOTA) results across both major benchmarks,
achieving a 75.8% success rate on AndroidWorld and 96.8% on ScreenSpot-V2.
Extensive ablation studies further demonstrate the significant contribution of
each component to the framework.

</details>


### [103] [ProRe: A Proactive Reward System for GUI Agents via Reasoner-Actor Collaboration](https://arxiv.org/abs/2509.21823)
*Gaole Dai,Shiqi Jiang,Ting Cao,Yuqing Yang,Yuanchun Li,Rui Tan,Mo Li,Lili Qiu*

Main category: cs.AI

TL;DR: ProRe是一种主动奖励系统，它利用通用推理器和特定领域评估器代理来提高奖励的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则或基于模型的奖励方法难以推广到GUI代理，因为通常无法访问ground-truth轨迹或应用程序数据库，并且静态的基于轨迹的LLM-as-a-Judge方法受到有限的准确性限制。

Method: 提出了一种主动奖励系统ProRe，该系统利用通用推理器和领域特定的评估器代理（actor）。推理器调度有针对性的状态探测任务，评估器代理通过主动与环境交互来执行这些任务以收集额外的观察结果。

Result: 在超过3K条轨迹上的经验结果表明，ProRe将奖励准确率和F1得分分别提高了5.3%和19.4%。

Conclusion: 将ProRe与最先进的策略代理集成后，成功率提高了22.4%。

Abstract: Reward is critical to the evaluation and training of large language models
(LLMs). However, existing rule-based or model-based reward methods struggle to
generalize to GUI agents, where access to ground-truth trajectories or
application databases is often unavailable, and static trajectory-based
LLM-as-a-Judge approaches suffer from limited accuracy. To address these
challenges, we propose ProRe, a proactive reward system that leverages a
general-purpose reasoner and domain-specific evaluator agents (actors). The
reasoner schedules targeted state probing tasks, which the evaluator agents
then execute by actively interacting with the environment to collect additional
observations. This enables the reasoner to assign more accurate and verifiable
rewards to GUI agents. Empirical results on over 3K trajectories demonstrate
that ProRe improves reward accuracy and F1 score by up to 5.3% and 19.4%,
respectively. Furthermore, integrating ProRe with state-of-the-art policy
agents yields a success rate improvement of up to 22.4%.

</details>


### [104] [DS-STAR: Data Science Agent via Iterative Planning and Verification](https://arxiv.org/abs/2509.21825)
*Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Tomas Pfister*

Main category: cs.AI

TL;DR: DS-STAR: A data science agent that automates data analysis by exploring data, verifying analysis plan sufficiency, and iteratively refining the plan.


<details>
  <summary>Details</summary>
Motivation: Automating complex data science tasks is challenging due to heterogeneous data formats and difficulty in verifying analysis plan sufficiency.

Method: DS-STAR incorporates a data file analysis module, an LLM-based judge for plan verification, and a sequential planning mechanism for iterative refinement.

Result: DS-STAR achieves state-of-the-art performance on DABStep, KramaBench, and DA-Code benchmarks, especially on tasks with heterogeneous data formats.

Conclusion: DS-STAR reliably navigates complex analyses involving diverse data sources through iterative refinement.

Abstract: Data science, which transforms raw data into actionable insights, is critical
for data-driven decision-making. However, these tasks are often complex,
involving steps for exploring multiple data sources and synthesizing findings
to deliver insightful answers. While large language models (LLMs) show
significant promise in automating this process, they often struggle with
heterogeneous data formats and generate sub-optimal analysis plans, as
verifying plan sufficiency is inherently difficult without ground-truth labels
for such open-ended tasks. To overcome these limitations, we introduce DS-STAR,
a novel data science agent. Specifically, DS-STAR makes three key
contributions: (1) a data file analysis module that automatically explores and
extracts context from diverse data formats, including unstructured types; (2) a
verification step where an LLM-based judge evaluates the sufficiency of the
analysis plan at each stage; and (3) a sequential planning mechanism that
starts with a simple, executable plan and iteratively refines it based on the
DS-STAR's feedback until its sufficiency is verified. This iterative refinement
allows DS-STAR to reliably navigate complex analyses involving diverse data
sources. Our experiments show that DS-STAR achieves state-of-the-art
performance across three challenging benchmarks: DABStep, KramaBench, and
DA-Code. Moreover, DS-STAR particularly outperforms baselines on hard tasks
that require processing multiple data files with heterogeneous formats.

</details>


### [105] [Axiomatic Choice and the Decision-Evaluation Paradox](https://arxiv.org/abs/2509.21836)
*Ben Abramowitz,Nicholas Mattei*

Main category: cs.AI

TL;DR: 提出一个使用公理建模决策的框架，并定义了决策公理的分类。


<details>
  <summary>Details</summary>
Motivation: 探讨使用公理进行决策和评估决策之间的矛盾。

Method: 建立一个决策公理的分类框架，并分析它们的结构性质。

Result: 揭示了在实际的公理结构中存在决策评估悖论。

Conclusion: 强调在训练决策数据模型或应用公理进行决策和评估时需要格外小心。

Abstract: We introduce a framework for modeling decisions with axioms that are
statements about decisions, e.g., ethical constraints. Using our framework we
define a taxonomy of decision axioms based on their structural properties and
demonstrate a tension between the use of axioms to make decisions and the use
of axioms to evaluate decisions which we call the Decision-Evaluation Paradox.
We argue that the Decision-Evaluation Paradox arises with realistic axiom
structures, and the paradox illuminates why one must be exceptionally careful
when training models on decision data or applying axioms to make and evaluate
decisions.

</details>


### [106] [DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents](https://arxiv.org/abs/2509.21842)
*Yansong Ning,Rui Liu,Jun Wang,Kai Chen,Wei Li,Jun Fang,Kan Zheng,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: DeepTravel是一个端到端的agent强化学习框架，用于构建自主旅行规划agent。它通过缓存数据构建沙盒环境，采用分层奖励建模系统，并提出回复增强强化学习方法，以提高agent的自主性和性能。在DiDi Enterprise Solutions App上的实验表明，DeepTravel能使小型LLM在旅行规划任务中胜过现有的先进LLM。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖手工提示和固定agent工作流程，阻碍了更灵活和自主的旅行规划agent的发展。

Method: 提出DeepTravel框架，包括构建沙盒环境、开发分层奖励建模系统和回复增强强化学习方法。

Result: DeepTravel使小型LLM（如Qwen3 32B）在旅行规划任务中显著优于OpenAI o1, o3和DeepSeek R1等现有先进LLM。

Conclusion: DeepTravel框架能够有效提升旅行规划agent的自主性和性能，并在实际应用中取得了显著成果。

Abstract: Travel planning (TP) agent has recently worked as an emerging building block
to interact with external tools and resources for travel itinerary generation,
ensuring enjoyable user experience. Despite its benefits, existing studies rely
on hand craft prompt and fixed agent workflow, hindering more flexible and
autonomous TP agent. This paper proposes DeepTravel, an end to end agentic
reinforcement learning framework for building autonomous travel planning agent,
capable of autonomously planning, executing tools, and reflecting on tool
responses to explore, verify, and refine intermediate actions in multi step
reasoning. To achieve this, we first construct a robust sandbox environment by
caching transportation, accommodation and POI data, facilitating TP agent
training without being constrained by real world APIs limitations (e.g.,
inconsistent outputs). Moreover, we develop a hierarchical reward modeling
system, where a trajectory level verifier first checks spatiotemporal
feasibility and filters unsatisfied travel itinerary, and then the turn level
verifier further validate itinerary detail consistency with tool responses,
enabling efficient and precise reward service. Finally, we propose the reply
augmented reinforcement learning method that enables TP agent to periodically
replay from a failures experience buffer, emerging notable agentic capacity. We
deploy trained TP agent on DiDi Enterprise Solutions App and conduct
comprehensive online and offline evaluations, demonstrating that DeepTravel
enables small size LLMs (e.g., Qwen3 32B) to significantly outperform existing
frontier LLMs such as OpenAI o1, o3 and DeepSeek R1 in travel planning tasks.

</details>


### [107] [Reimagining Agent-based Modeling with Large Language Model Agents via Shachi](https://arxiv.org/abs/2509.21862)
*So Kuroki,Yingtao Tian,Kou Misaki,Takashi Ikegami,Takuya Akiba,Yujin Tang*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种名为 Shachi 的形式化方法和模块化框架，用于研究大型语言模型驱动的多智能体系统中出现的行为。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型驱动的多智能体系统中涌现行为的研究缺乏有原则的实验方法。

Method: 该方法将智能体的策略分解为核心认知组件：配置、记忆和工具，所有这些都由 LLM 推理引擎协调。

Result: 该方法在一个包含 10 个任务的综合基准上进行了验证，并通过建模真实的美国关税冲击证明了其有效性。

Conclusion: 这项工作为构建和评估 LLM 智能体提供了一个严谨的开源基础，旨在促进更具累积性和科学依据的研究。

Abstract: The study of emergent behaviors in large language model (LLM)-driven
multi-agent systems is a critical research challenge, yet progress is limited
by a lack of principled methodologies for controlled experimentation. To
address this, we introduce Shachi, a formal methodology and modular framework
that decomposes an agent's policy into core cognitive components: Configuration
for intrinsic traits, Memory for contextual persistence, and Tools for expanded
capabilities, all orchestrated by an LLM reasoning engine. This principled
architecture moves beyond brittle, ad-hoc agent designs and enables the
systematic analysis of how specific architectural choices influence collective
behavior. We validate our methodology on a comprehensive 10-task benchmark and
demonstrate its power through novel scientific inquiries. Critically, we
establish the external validity of our approach by modeling a real-world U.S.
tariff shock, showing that agent behaviors align with observed market reactions
only when their cognitive architecture is appropriately configured with memory
and tools. Our work provides a rigorous, open-source foundation for building
and evaluating LLM agents, aimed at fostering more cumulative and
scientifically grounded research.

</details>


### [108] [TRACE: Learning to Compute on Graphs](https://arxiv.org/abs/2509.21886)
*Ziyang Zheng,Jiaying Zhu,Jingyi Zhou,Qiang Xu*

Main category: cs.AI

TL;DR: TRACE: A new graph representation learning paradigm for modeling computational graphs.


<details>
  <summary>Details</summary>
Motivation: Existing MPNNs and Transformers are not well-suited for capturing the position-aware, hierarchical nature of computation in computational graphs.

Method: TRACE uses a Hierarchical Transformer and a function shift learning objective.

Result: TRACE outperforms existing architectures on electronic circuit benchmarks.

Conclusion: TRACE's architecture and learning objective provide a more robust paradigm for learning to compute on graphs.

Abstract: Learning to compute, the ability to model the functional behavior of a
computational graph, is a fundamental challenge for graph representation
learning. Yet, the dominant paradigm is architecturally mismatched for this
task. This flawed assumption, central to mainstream message passing neural
networks (MPNNs) and their conventional Transformer-based counterparts,
prevents models from capturing the position-aware, hierarchical nature of
computation. To resolve this, we introduce \textbf{TRACE}, a new paradigm built
on an architecturally sound backbone and a principled learning objective.
First, TRACE employs a Hierarchical Transformer that mirrors the step-by-step
flow of computation, providing a faithful architectural backbone that replaces
the flawed permutation-invariant aggregation. Second, we introduce
\textbf{function shift learning}, a novel objective that decouples the learning
problem. Instead of predicting the complex global function directly, our model
is trained to predict only the \textit{function shift}, the discrepancy between
the true global function and a simple local approximation that assumes input
independence. We validate this paradigm on electronic circuits, one of the most
complex and economically critical classes of computational graphs. Across a
comprehensive suite of benchmarks, TRACE substantially outperforms all prior
architectures. These results demonstrate that our architecturally-aligned
backbone and decoupled learning objective form a more robust paradigm for the
fundamental challenge of learning to compute on graphs.

</details>


### [109] [GenesisGeo: Technical Report](https://arxiv.org/abs/2509.21896)
*Minfeng Zhu,Zi Wang,Sizhe Ji,Zhengtong Du,Junming Ke,Xiao Deng,Zanlang Yin,Xiuqi Huang,Heyu Wang,Wei Chen*

Main category: cs.AI

TL;DR: GenesisGeo是一个欧几里得几何中的自动定理证明器，开源了一个大规模的几何数据集。


<details>
  <summary>Details</summary>
Motivation: 为了解决欧几里得几何问题，特别是提高定理证明的效率和准确性。

Method: 通过定理匹配显著加速了符号演绎引擎DDARN，并结合了C++实现。构建了神经符号证明器GenesisGeo，基于Qwen3-0.6B-Base。

Result: 在IMO-AG-30基准测试中，单个模型解决了24个问题（IMO银牌水平），双模型集成解决了26个问题（IMO金牌水平）。

Conclusion: GenesisGeo在解决几何问题方面表现出色，尤其是在IMO基准测试中达到了很高的水平。

Abstract: We present GenesisGeo, an automated theorem prover in Euclidean geometry. We
have open-sourced a large-scale geometry dataset of 21.8 million geometric
problems, over 3 million of which contain auxiliary constructions. Specially,
we significantly accelerate the symbolic deduction engine DDARN by 120x through
theorem matching, combined with a C++ implementation of its core components.
Furthermore, we build our neuro-symbolic prover, GenesisGeo, upon
Qwen3-0.6B-Base, which solves 24 of 30 problems (IMO silver medal level) in the
IMO-AG-30 benchmark using a single model, and achieves 26 problems (IMO gold
medal level) with a dual-model ensemble.

</details>


### [110] [DyRo-MCTS: A Robust Monte Carlo Tree Search Approach to Dynamic Job Shop Scheduling](https://arxiv.org/abs/2509.21902)
*Ruiqi Chen,Yi Mei,Fangfang Zhang,Mengjie Zhang*

Main category: cs.AI

TL;DR: 提出了一种新的动态鲁棒蒙特卡洛树搜索（DyRo-MCTS）方法，以解决动态作业车间调度问题中新作业到达引起的频繁中断问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法离线学习调度策略，但这些策略往往不完善，需要使用蒙特卡洛树搜索（MCTS）等规划技术来提高在线决策时的性能。然而，新作业到达的不可预测性使得在线规划变得复杂。

Method: 将行动鲁棒性估计整合到MCTS中，引导生产环境朝着不仅产生良好调度结果，而且易于适应未来作业到达的状态发展。

Result: 大量实验表明，DyRo-MCTS 显着提高了离线学习策略的性能，且额外的在线规划时间可忽略不计。此外，DyRo-MCTS 在各种调度场景中始终优于普通 MCTS。

Conclusion: DyRo-MCTS 能够做出稳健的调度决策，从而在扰动下实现长期、可持续的性能提升。

Abstract: Dynamic job shop scheduling, a fundamental combinatorial optimisation problem
in various industrial sectors, poses substantial challenges for effective
scheduling due to frequent disruptions caused by the arrival of new jobs.
State-of-the-art methods employ machine learning to learn scheduling policies
offline, enabling rapid responses to dynamic events. However, these offline
policies are often imperfect, necessitating the use of planning techniques such
as Monte Carlo Tree Search (MCTS) to improve performance at online decision
time. The unpredictability of new job arrivals complicates online planning, as
decisions based on incomplete problem information are vulnerable to
disturbances. To address this issue, we propose the Dynamic Robust MCTS
(DyRo-MCTS) approach, which integrates action robustness estimation into MCTS.
DyRo-MCTS guides the production environment toward states that not only yield
good scheduling outcomes but are also easily adaptable to future job arrivals.
Extensive experiments show that DyRo-MCTS significantly improves the
performance of offline-learned policies with negligible additional online
planning time. Moreover, DyRo-MCTS consistently outperforms vanilla MCTS across
various scheduling scenarios. Further analysis reveals that its ability to make
robust scheduling decisions leads to long-term, sustainable performance gains
under disturbances.

</details>


### [111] [Outlier Detection in Plantar Pressure: Human-Centered Comparison of Statistical Parametric Mapping and Explainable Machine Learning](https://arxiv.org/abs/2509.21943)
*Carlo Dindorf,Jonas Dully,Steven Simon,Dennis Perchthaler,Stephan Becker,Hannah Ehmann,Kjell Heitmann,Bernd Stetter,Christian Diers,Michael Fröhlich*

Main category: cs.AI

TL;DR: 本文研究了使用统计参数映射（SPM）和可解释机器学习（ML）方法，用于足底压力数据的自动异常检测。


<details>
  <summary>Details</summary>
Motivation: 足底压力映射在临床诊断和运动科学中至关重要，但大型异构数据集常包含因技术错误或程序不一致导致的异常值。SPM虽然可解释，但对齐敏感，且异常值检测能力不明确。

Method: 比较了非参数、依赖配准的SPM方法和卷积神经网络（CNN），并使用SHAP进行解释。使用嵌套交叉验证评估性能，并通过语义差异调查评估解释质量。

Result: ML模型达到了高精度，优于SPM，SPM错误分类了临床上有意义的变异，并错过了真正的异常值。专家认为SPM和SHAP解释清晰、有用且值得信赖，但SPM的复杂度较低。

Conclusion: 研究结果强调了SPM和可解释ML作为足底压力数据自动异常检测方法的互补潜力，并强调了可解释性在将复杂模型输出转化为可解释的见解中的重要性，这些见解可以有效地为决策提供信息。

Abstract: Plantar pressure mapping is essential in clinical diagnostics and sports
science, yet large heterogeneous datasets often contain outliers from technical
errors or procedural inconsistencies. Statistical Parametric Mapping (SPM)
provides interpretable analyses but is sensitive to alignment and its capacity
for robust outlier detection remains unclear. This study compares an SPM
approach with an explainable machine learning (ML) approach to establish
transparent quality-control pipelines for plantar pressure datasets. Data from
multiple centers were annotated by expert consensus and enriched with synthetic
anomalies resulting in 798 valid samples and 2000 outliers. We evaluated (i) a
non-parametric, registration-dependent SPM approach and (ii) a convolutional
neural network (CNN), explained using SHapley Additive exPlanations (SHAP).
Performance was assessed via nested cross-validation; explanation quality via a
semantic differential survey with domain experts. The ML model reached high
accuracy and outperformed SPM, which misclassified clinically meaningful
variations and missed true outliers. Experts perceived both SPM and SHAP
explanations as clear, useful, and trustworthy, though SPM was assessed less
complex. These findings highlight the complementary potential of SPM and
explainable ML as approaches for automated outlier detection in plantar
pressure data, and underscore the importance of explainability in translating
complex model outputs into interpretable insights that can effectively inform
decision-making.

</details>


### [112] [CoBel-World: Harnessing LLM Reasoning to Build a Collaborative Belief World for Optimizing Embodied Multi-Agent Collaboration](https://arxiv.org/abs/2509.21981)
*Zhimin Wang,Shaokang He,Duo Wu,Jinghe Wang,Linjia Kang,Jing Yu,Zhi Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为CoBel-World的新框架，该框架通过让LLM agent 具备协作信念世界（collaborative belief world）来提高多智能体协作效率，从而能够进行动态意图推断，减少不一致的计划和冗余的通信。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM协作框架忽略了LLM在动态意图推断方面的推理潜力，导致计划不一致和通信冗余，降低了协作效率。

Method: 该框架通过符号信念语言将开放世界的任务知识解析为结构化信念，并通过LLM推理执行zero-shot贝叶斯风格的信念更新。

Result: 在具身基准测试中，CoBel-World 相比最强的基线，通信成本降低了22-60%，任务完成效率提高了4-28%。

Conclusion: 显式的、意图感知的信念建模对于基于LLM的多智能体系统中高效且类似人类的协作至关重要。

Abstract: Effective real-world multi-agent collaboration requires not only accurate
planning but also the ability to reason about collaborators' intents -- a
crucial capability for avoiding miscoordination and redundant communication
under partial observable environments. Due to their strong planning and
reasoning capabilities, large language models (LLMs) have emerged as promising
autonomous agents for collaborative task solving. However, existing
collaboration frameworks for LLMs overlook their reasoning potential for
dynamic intent inference, and thus produce inconsistent plans and redundant
communication, reducing collaboration efficiency. To bridge this gap, we
propose CoBel-World, a novel framework that equips LLM agents with a
collaborative belief world -- an internal representation jointly modeling the
physical environment and collaborators' mental states. CoBel-World enables
agents to parse open-world task knowledge into structured beliefs via a
symbolic belief language, and perform zero-shot Bayesian-style belief updates
through LLM reasoning. This allows agents to proactively detect potential
miscoordination (e.g., conflicting plans) and communicate adaptively. Evaluated
on challenging embodied benchmarks (i.e., TDW-MAT and C-WAH), CoBel-World
significantly reduces communication costs by 22-60% and improves task
completion efficiency by 4-28% compared to the strongest baseline. Our results
show that explicit, intent-aware belief modeling is essential for efficient and
human-like collaboration in LLM-based multi-agent systems.

</details>


### [113] [RISK: A Framework for GUI Agents in E-commerce Risk Management](https://arxiv.org/abs/2509.21982)
*Renqi Chen,Zeyin Tao,Jianming Guo,Jingzhe Zhu,Yiheng Peng,Qingqing Sun,Tianyi Zhang,Shuai Chen*

Main category: cs.AI

TL;DR: RISK是一个用于构建和部署GUI代理的框架，专门用于电商风险管理，能够处理传统方法难以处理的多步骤、有状态的Web数据交互。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI代理无法有效管理动态交互内容，难以进行有效的风险评估，因此需要新的解决方案。

Method: RISK框架包含三个组件：RISK-Data（包含单步和多步交互轨迹的数据集），RISK-Bench（包含单步和多步轨迹的基准测试），以及RISK-R1（一种R1风格的强化微调框架，考虑了输出格式、单步水平、多步水平和任务水平四个方面）。

Result: RISK-R1在离线单步和多步任务上分别取得了6.8%和8.8%的性能提升，在线评估中达到了70.5%的任务成功率。

Conclusion: RISK为自动化复杂Web交互提供了一个可扩展的、特定于领域的解决方案，提升了电商风险管理的技术水平。

Abstract: E-commerce risk management requires aggregating diverse, deeply embedded web
data through multi-step, stateful interactions, which traditional scraping
methods and most existing Graphical User Interface (GUI) agents cannot handle.
These agents are typically limited to single-step tasks and lack the ability to
manage dynamic, interactive content critical for effective risk assessment. To
address this challenge, we introduce RISK, a novel framework designed to build
and deploy GUI agents for this domain. RISK integrates three components: (1)
RISK-Data, a dataset of 8,492 single-step and 2,386 multi-step interaction
trajectories, collected through a high-fidelity browser framework and a
meticulous data curation process; (2) RISK-Bench, a benchmark with 802
single-step and 320 multi-step trajectories across three difficulty levels for
standardized evaluation; and (3) RISK-R1, a R1-style reinforcement fine-tuning
framework considering four aspects: (i) Output Format: Updated format reward to
enhance output syntactic correctness and task comprehension, (ii) Single-step
Level: Stepwise accuracy reward to provide granular feedback during early
training stages, (iii) Multi-step Level: Process reweight to emphasize critical
later steps in interaction sequences, and (iv) Task Level: Level reweight to
focus on tasks of varying difficulty. Experiments show that RISK-R1 outperforms
existing baselines, achieving a 6.8% improvement in offline single-step and an
8.8% improvement in offline multi-step. Moreover, it attains a top task success
rate of 70.5% in online evaluation. RISK provides a scalable, domain-specific
solution for automating complex web interactions, advancing the state of the
art in e-commerce risk management.

</details>


### [114] [Bilinear relational structure fixes reversal curse and enables consistent model editing](https://arxiv.org/abs/2509.21993)
*Dong-Kyum Kim,Minsung Kim,Jea Kwon,Nakyeong Yang,Meeyoung Cha*

Main category: cs.AI

TL;DR: 语言模型无法从已知的“A是B”推断出未知的“B是A”，这被称为反转诅咒。本文表明，这并非模型固有的缺陷，而是模型编码知识的方式造成的。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决语言模型中普遍存在的“反转诅咒”问题，即模型无法从已学习的事实推断出其逆向关系。作者认为这不是模型固有的缺陷，而是知识编码方式的问题。

Method: 通过在一个合成的关系知识图数据集上从头开始训练语言模型，作者观察模型隐藏层表征中双线性关系结构。并通过实验验证了这种结构对缓解反转诅咒和实现一致的模型编辑的关键作用。

Result: 研究结果表明，在关系知识数据集上训练可以使语言模型产生双线性内部表征，从而使模型在编辑后以符合逻辑的方式运行。拥有这种结构的语言模型能够推断出未知的逆向事实，并在模型编辑时正确地将编辑传播到其逆向和其他逻辑上相关的事实。

Conclusion: 论文表明，模型编辑的成功不仅取决于编辑算法，还取决于被修改知识的底层表征几何结构。在关系型知识数据集上训练可以诱导双线性内部表征的出现，从而使语言模型在编辑后表现出逻辑上一致的行为。

Abstract: The reversal curse -- a language model's (LM) inability to infer an unseen
fact ``B is A'' from a learned fact ``A is B'' -- is widely considered a
fundamental limitation. We show that this is not an inherent failure but an
artifact of how models encode knowledge. By training LMs from scratch on a
synthetic dataset of relational knowledge graphs, we demonstrate that bilinear
relational structure emerges in their hidden representations. This structure
substantially alleviates the reversal curse, enabling LMs to infer unseen
reverse facts. Crucially, we also find that this bilinear structure plays a key
role in consistent model editing. When a fact is updated in a LM with this
structure, the edit correctly propagates to its reverse and other logically
dependent facts. In contrast, models lacking this representation not only
suffer from the reversal curse but also fail to generalize edits, further
introducing logical inconsistencies. Our results establish that training on a
relational knowledge dataset induces the emergence of bilinear internal
representations, which in turn enable LMs to behave in a logically consistent
manner after editing. This implies that the success of model editing depends
critically not just on editing algorithms but on the underlying
representational geometry of the knowledge being modified.

</details>


### [115] [GSM-Agent: Understanding Agentic Reasoning Using Controllable Environments](https://arxiv.org/abs/2509.21998)
*Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao*

Main category: cs.AI

TL;DR: 构建了一个新的基准测试GSM-Agent，用于评估LLM agent的agentic reasoning能力，该基准测试要求agent解决小学水平的推理问题，但需要主动使用工具收集必要信息。


<details>
  <summary>Details</summary>
Motivation: 现有的agent基准测试通常将agentic reasoning与具有挑战性的数学推理、专家级知识和其他高级能力混合在一起，难以有效评估agentic reasoning能力。

Method: 提出了agentic reasoning graph的概念，通过将环境的文档嵌入聚类成节点，并将每个工具调用映射到其最近的节点来构建推理路径。

Result: 即使是GPT-5等先进模型，在该基准测试上也仅达到67%的准确率。研究发现，许多模型在agentic reasoning中常常缺乏重新访问先前访问过的节点的能力。

Conclusion: 提出了一种工具增强的测试时缩放方法，通过添加工具来鼓励模型重新访问节点，从而提高LLM的agentic reasoning性能。

Abstract: As LLMs are increasingly deployed as agents, agentic reasoning - the ability
to combine tool use, especially search, and reasoning - becomes a critical
skill. However, it is hard to disentangle agentic reasoning when evaluated in
complex environments and tasks. Current agent benchmarks often mix agentic
reasoning with challenging math reasoning, expert-level knowledge, and other
advanced capabilities. To fill this gap, we build a novel benchmark, GSM-Agent,
where an LLM agent is required to solve grade-school-level reasoning problems,
but is only presented with the question in the prompt without the premises that
contain the necessary information to solve the task, and needs to proactively
collect that information using tools. Although the original tasks are
grade-school math problems, we observe that even frontier models like GPT-5
only achieve 67% accuracy. To understand and analyze the agentic reasoning
patterns, we propose the concept of agentic reasoning graph: cluster the
environment's document embeddings into nodes, and map each tool call to its
nearest node to build a reasoning path. Surprisingly, we identify that the
ability to revisit a previously visited node, widely taken as a crucial pattern
in static reasoning, is often missing for agentic reasoning for many models.
Based on the insight, we propose a tool-augmented test-time scaling method to
improve LLM's agentic reasoning performance by adding tools to encourage models
to revisit. We expect our benchmark and the agentic reasoning framework to aid
future studies of understanding and pushing the boundaries of agentic
reasoning.

</details>


### [116] [The Thinking Spectrum: An Emperical Study of Tunable Reasoning in LLMs through Model Merging](https://arxiv.org/abs/2509.22034)
*Xiaochong Lan,Yu Zheng,Shiteng Cao,Yong Li*

Main category: cs.AI

TL;DR: 研究了模型合并技术，以在推理精度和计算成本之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: 现实应用中对具有可调推理能力的大型语言模型的需求日益增长，需要能够有效生成平衡推理深度和计算成本的模型的方法。

Method: 通过系统地改变合并强度，评估了一系列模型合并技术在多个推理基准上的表现，构建了精度-效率曲线。

Result: 模型合并提供了一种有效且可控的方法，用于校准推理精度和token效率之间的权衡。发现了帕累托改进的实例，即合并后的模型比其父模型之一实现了更高的准确性和更低的token消耗。

Conclusion: 该研究提供了对该可调空间的全面分析，为创建具有特定推理profile的LLM以满足不同的应用需求提供了实用的指导。

Abstract: The growing demand for large language models (LLMs) with tunable reasoning
capabilities in many real-world applications highlights a critical need for
methods that can efficiently produce a spectrum of models balancing reasoning
depth and computational cost. Model merging has emerged as a promising,
training-free technique to address this challenge by arithmetically combining
the weights of a general-purpose model with a specialized reasoning model.
While various merging techniques exist, their potential to create a spectrum of
models with fine-grained control over reasoning abilities remains largely
unexplored. This work presents a large-scale empirical study evaluating a range
of model merging techniques across multiple reasoning benchmarks. We
systematically vary merging strengths to construct accuracy-efficiency curves,
providing the first comprehensive view of the tunable performance landscape.
Our findings reveal that model merging offers an effective and controllable
method for calibrating the trade-off between reasoning accuracy and token
efficiency, even when parent models have highly divergent weight spaces.
Crucially, we identify instances of Pareto Improvement, where a merged model
achieves both higher accuracy and lower token consumption than one of its
parents. Our study provides the first comprehensive analysis of this tunable
space, offering practical guidelines for creating LLMs with specific reasoning
profiles to meet diverse application demands.

</details>


### [117] [A2R: An Asymmetric Two-Stage Reasoning Framework for Parallel Reasoning](https://arxiv.org/abs/2509.22044)
*Ziqi Wang,Boye Niu,Zhongli Li,Linghui Meng,Jing Liu,Zhi Zheng,Tong Xu,Hua Wu,Haifeng Wang,Enhong Chen*

Main category: cs.AI

TL;DR: This paper introduces A2R, a two-stage reasoning framework that improves model performance by generating multiple potential solutions in parallel and then refining them. It achieves significant performance gains and cost efficiency.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the gap between a model's single-attempt performance and its potential, which is often revealed across multiple solution paths.

Method: The method involves an "explorer" model generating potential solutions in parallel, followed by a "synthesizer" model integrating these references for a refined reasoning stage. A key innovation is an asymmetric scaling paradigm, leading to a "small-to-big" variant.

Result: The Qwen3-8B-distill model achieves a 75% performance improvement using A2R compared to its self-consistency baseline. A2R-Efficient, combining a Qwen3-4B explorer with a Qwen3-8B synthesizer, surpasses the average performance of a monolithic Qwen3-32B model at a nearly 30% lower cost.

Conclusion: A2R is a performance-boosting, efficient, and practical solution for real-world applications.

Abstract: Recent Large Reasoning Models have achieved significant improvements in
complex task-solving capabilities by allocating more computation at the
inference stage with a "thinking longer" paradigm. Even as the foundational
reasoning capabilities of models advance rapidly, the persistent gap between a
model's performance in a single attempt and its latent potential, often
revealed only across multiple solution paths, starkly highlights the disparity
between its realized and inherent capabilities. To address this, we present
A2R, an Asymmetric Two-Stage Reasoning framework designed to explicitly bridge
the gap between a model's potential and its actual performance. In this
framework, an "explorer" model first generates potential solutions in parallel
through repeated sampling. Subsequently,a "synthesizer" model integrates these
references for a more refined, second stage of reasoning. This two-stage
process allows computation to be scaled orthogonally to existing sequential
methods. Our work makes two key innovations: First, we present A2R as a
plug-and-play parallel reasoning framework that explicitly enhances a model's
capabilities on complex questions. For example, using our framework, the
Qwen3-8B-distill model achieves a 75% performance improvement compared to its
self-consistency baseline. Second, through a systematic analysis of the
explorer and synthesizer roles, we identify an effective asymmetric scaling
paradigm. This insight leads to A2R-Efficient, a "small-to-big" variant that
combines a Qwen3-4B explorer with a Qwen3-8B synthesizer. This configuration
surpasses the average performance of a monolithic Qwen3-32B model at a nearly
30% lower cost. Collectively, these results show that A2R is not only a
performance-boosting framework but also an efficient and practical solution for
real-world applications.

</details>


### [118] [Generalizing Multi-Objective Search via Objective-Aggregation Functions](https://arxiv.org/abs/2509.22085)
*Hadar Peer,Eyal Weiss,Ron Alterovitz,Oren Salzman*

Main category: cs.AI

TL;DR: 这篇论文提出了一种广义的问题公式，通过隐藏（搜索）目标的聚合函数来优化解决方案目标。


<details>
  <summary>Details</summary>
Motivation: 现实世界的机器人系统需要同时平衡多个通常相互冲突的目标，因此多目标搜索（MOS）至关重要。目前的工作探索了目标之间复杂的相互作用，导致问题公式不允许使用现成的最先进的MOS算法。

Method: 该方法优化解决方案目标，通过隐藏（搜索）目标的聚合函数，并适当扩展几个核心操作以反映所采用的特定聚合函数，从而支持标准MOS算法的应用。

Result: 在不同的机器人规划问题中证明了该方法，包括导航、操作和医疗系统的运动规划，以及在障碍不确定性下的检查规划和具有不同道路类型的路线规划。在适当扩展其核心操作后，使用最先进的MOS算法解决了这些问题，并提供了经验证据，表明它们比应用于相同问题但没有目标聚合的算法的原始版本高出几个数量级。

Conclusion: 提出的方法优于现有方法。

Abstract: Multi-objective search (MOS) has become essential in robotics, as real-world
robotic systems need to simultaneously balance multiple, often conflicting
objectives. Recent works explore complex interactions between objectives,
leading to problem formulations that do not allow the usage of out-of-the-box
state-of-the-art MOS algorithms. In this paper, we suggest a generalized
problem formulation that optimizes solution objectives via aggregation
functions of hidden (search) objectives. We show that our formulation supports
the application of standard MOS algorithms, necessitating only to properly
extend several core operations to reflect the specific aggregation functions
employed. We demonstrate our approach in several diverse robotics planning
problems, spanning motion-planning for navigation, manipulation and planning fr
medical systems under obstacle uncertainty as well as inspection planning, and
route planning with different road types. We solve the problems using
state-of-the-art MOS algorithms after properly extending their core operations,
and provide empirical evidence that they outperform by orders of magnitude the
vanilla versions of the algorithms applied to the same problems but without
objective aggregation.

</details>


### [119] [Ground-Truthing AI Energy Consumption: Validating CodeCarbon Against External Measurements](https://arxiv.org/abs/2509.22092)
*Raphael Fischer*

Main category: cs.AI

TL;DR: 评估用于估算 AI 模型能耗和碳排放的工具的可靠性，发现这些工具存在高达 40% 的误差。


<details>
  <summary>Details</summary>
Motivation: 机器学习和人工智能的快速发展对环境产生重大影响，因此需要关注资源消耗问题。

Method: 通过与数百个 AI 实验的实际测量结果进行比较，系统地评估静态和动态能量估计方法的可靠性。

Result: 现有的估计方法通常遵循 AI 能源消耗的模式，但始终存在高达 40% 的误差。

Conclusion: 该研究提供了关于能源估计质量和误差的经验证据，从而为可持续 AI 发展建立了透明度，验证了广泛使用的工具，并为改进技术水平制定了指导方针。

Abstract: Although machine learning (ML) and artificial intelligence (AI) present
fascinating opportunities for innovation, their rapid development is also
significantly impacting our environment. In response to growing
resource-awareness in the field, quantification tools such as the ML Emissions
Calculator and CodeCarbon were developed to estimate the energy consumption and
carbon emissions of running AI models. They are easy to incorporate into AI
projects, however also make pragmatic assumptions and neglect important
factors, raising the question of estimation accuracy. This study systematically
evaluates the reliability of static and dynamic energy estimation approaches
through comparisons with ground-truth measurements across hundreds of AI
experiments. Based on the proposed validation framework, investigative insights
into AI energy demand and estimation inaccuracies are provided. While generally
following the patterns of AI energy consumption, the established estimation
approaches are shown to consistently make errors of up to 40%. By providing
empirical evidence on energy estimation quality and errors, this study
establishes transparency and validates widely used tools for sustainable AI
development. It moreover formulates guidelines for improving the
state-of-the-art and offers code for extending the validation to other domains
and tools, thus making important contributions to resource-aware ML and AI
sustainability research.

</details>


### [120] [Log2Plan: An Adaptive GUI Automation Framework Integrated with Task Mining Approach](https://arxiv.org/abs/2509.22137)
*Seoyoung Lee,Seonbin Yoon,Seongbeen Lee,Hyesoo Kim,Joo Yong Sim*

Main category: cs.AI

TL;DR: Log2Plan通过结合结构化的双层规划框架和用户行为日志的任务挖掘方法，实现了稳健且适应性强的GUI自动化。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM或VLM的规划-执行代理在GUI任务自动化中存在泛化能力差、延迟高和长程连贯性有限的问题，并且在UI更改或复杂任务下脆弱。

Method: Log2Plan通过将用户命令映射到结构化任务字典来构建高层计划，并通过解释实时GUI上下文将这些计划转化为底层动作序列。此外，它还采用任务挖掘方法从用户行为日志中识别用户特定模式。

Result: Log2Plan在200个真实任务上的评估显示，任务成功率和执行时间都得到了显著提高。即使在长程任务序列中，它也能保持超过60.0%的成功率。

Conclusion: Log2Plan在复杂的、多步骤工作流程中表现出稳健性。

Abstract: GUI task automation streamlines repetitive tasks, but existing LLM or
VLM-based planner-executor agents suffer from brittle generalization, high
latency, and limited long-horizon coherence. Their reliance on single-shot
reasoning or static plans makes them fragile under UI changes or complex tasks.
Log2Plan addresses these limitations by combining a structured two-level
planning framework with a task mining approach over user behavior logs,
enabling robust and adaptable GUI automation. Log2Plan constructs high-level
plans by mapping user commands to a structured task dictionary, enabling
consistent and generalizable automation. To support personalization and reuse,
it employs a task mining approach from user behavior logs that identifies
user-specific patterns. These high-level plans are then grounded into low-level
action sequences by interpreting real-time GUI context, ensuring robust
execution across varying interfaces. We evaluated Log2Plan on 200 real-world
tasks, demonstrating significant improvements in task success rate and
execution time. Notably, it maintains over 60.0% success rate even on
long-horizon task sequences, highlighting its robustness in complex, multi-step
workflows.

</details>


### [121] [Clinical Uncertainty Impacts Machine Learning Evaluations](https://arxiv.org/abs/2509.22242)
*Simone Lionetti,Fabian Gröger,Philippe Gottfrois,Alvaro Gonzalez-Jimenez,Ludovic Amruthalingam,Alexander A. Navarini,Marc Pouly*

Main category: cs.AI

TL;DR: 临床数据集标签通常不确定，因为注释者意见不一，且不同案例的置信度不一致。多数投票等常见聚合程序掩盖了这种可变性。在医学成像基准的简单实验中，考虑二元标签的置信度会显著影响模型排名。因此，我们认为机器学习评估应明确考虑注释不确定性，使用直接对分布进行操作的概率指标。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分析中，临床数据集标签的不确定性是一个重要问题，传统的多数投票方法无法充分解决。

Method: 提出使用概率指标来评估模型，这些指标可以直接处理标签的分布情况，并且计算效率高。

Result: 在医学成像基准的简单实验中，考虑二元标签的置信度会显著影响模型排名。

Conclusion: 研究建议发布数据集的原始注释，并采用考虑不确定性的评估方法，以便性能估计可以更好地反映临床数据。

Abstract: Clinical dataset labels are rarely certain as annotators disagree and
confidence is not uniform across cases. Typical aggregation procedures, such as
majority voting, obscure this variability. In simple experiments on medical
imaging benchmarks, accounting for the confidence in binary labels
significantly impacts model rankings. We therefore argue that machine-learning
evaluations should explicitly account for annotation uncertainty using
probabilistic metrics that directly operate on distributions. These metrics can
be applied independently of the annotations' generating process, whether
modeled by simple counting, subjective confidence ratings, or probabilistic
response models. They are also computationally lightweight, as closed-form
expressions have linear-time implementations once examples are sorted by model
score. We thus urge the community to release raw annotations for datasets and
to adopt uncertainty-aware evaluation so that performance estimates may better
reflect clinical data.

</details>


### [122] [Evaluating LLMs for Combinatorial Optimization: One-Phase and Two-Phase Heuristics for 2D Bin-Packing](https://arxiv.org/abs/2509.22255)
*Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Rajesh Mojumder*

Main category: cs.AI

TL;DR: 本文提出了一个评估大型语言模型（LLM）在组合优化（特别是二维装箱问题）中能力的框架。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在组合优化中的能力。

Method: 结合LLM与进化算法，迭代生成和改进启发式解决方案。

Result: GPT-4o在两次迭代内实现了最优解，平均bin使用量从16减少到15，空间利用率从0.76-0.78提高到0.83。

Conclusion: 这项工作有助于理解LLM在特定领域的评估，并为评估LLM在组合优化任务中的性能建立了基准。

Abstract: This paper presents an evaluation framework for assessing Large Language
Models' (LLMs) capabilities in combinatorial optimization, specifically
addressing the 2D bin-packing problem. We introduce a systematic methodology
that combines LLMs with evolutionary algorithms to generate and refine
heuristic solutions iteratively. Through comprehensive experiments comparing
LLM generated heuristics against traditional approaches (Finite First-Fit and
Hybrid First-Fit), we demonstrate that LLMs can produce more efficient
solutions while requiring fewer computational resources. Our evaluation reveals
that GPT-4o achieves optimal solutions within two iterations, reducing average
bin usage from 16 to 15 bins while improving space utilization from 0.76-0.78
to 0.83. This work contributes to understanding LLM evaluation in specialized
domains and establishes benchmarks for assessing LLM performance in
combinatorial optimization tasks.

</details>


### [123] [InfiMed-Foundation: Pioneering Advanced Multimodal Medical Models with Compute-Efficient Pre-Training and Multi-Stage Fine-Tuning](https://arxiv.org/abs/2509.22261)
*Guanghao Zhu,Zhitian Hou,Zeyu Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.AI

TL;DR: 这篇论文介绍了InfiMed-Foundation-1.7B和InfiMed-Foundation-4B，这两个医学专用多模态大型语言模型(MLLM)，旨在提供最先进的医疗应用性能。


<details>
  <summary>Details</summary>
Motivation: 通用MLLM缺乏医学领域的专业知识，导致不确定或虚假的反应。从高级模型中进行知识提炼难以捕捉放射学和药理学中的领域特定知识。使用大规模医疗数据进行持续预训练的计算成本带来了巨大的效率挑战。

Method: 该研究结合了高质量的通用和医学多模态数据，并提出了一个新的五维质量评估框架来管理高质量的多模态医学数据集。采用了由低到高的图像分辨率和多模态序列打包来提高训练效率，从而能够整合广泛的医学数据。此外，一个三阶段的监督微调过程确保了复杂医疗任务的有效知识提取。

Result: 在MedEvalKit框架上进行评估，InfiMed-Foundation-1.7B优于Qwen2.5VL-3B，而InfiMed-Foundation-4B超过了HuatuoGPT-V-7B和MedGemma-27B-IT，在医学视觉问答和诊断任务中表现出卓越的性能。

Conclusion: 通过解决数据质量、训练效率和领域特定知识提取方面的关键挑战，这项工作为医疗保健领域中更可靠和有效的AI驱动解决方案铺平了道路。

Abstract: Multimodal large language models (MLLMs) have shown remarkable potential in
various domains, yet their application in the medical field is hindered by
several challenges. General-purpose MLLMs often lack the specialized knowledge
required for medical tasks, leading to uncertain or hallucinatory responses.
Knowledge distillation from advanced models struggles to capture
domain-specific expertise in radiology and pharmacology. Additionally, the
computational cost of continual pretraining with large-scale medical data poses
significant efficiency challenges. To address these issues, we propose
InfiMed-Foundation-1.7B and InfiMed-Foundation-4B, two medical-specific MLLMs
designed to deliver state-of-the-art performance in medical applications. We
combined high-quality general-purpose and medical multimodal data and proposed
a novel five-dimensional quality assessment framework to curate high-quality
multimodal medical datasets. We employ low-to-high image resolution and
multimodal sequence packing to enhance training efficiency, enabling the
integration of extensive medical data. Furthermore, a three-stage supervised
fine-tuning process ensures effective knowledge extraction for complex medical
tasks. Evaluated on the MedEvalKit framework, InfiMed-Foundation-1.7B
outperforms Qwen2.5VL-3B, while InfiMed-Foundation-4B surpasses HuatuoGPT-V-7B
and MedGemma-27B-IT, demonstrating superior performance in medical visual
question answering and diagnostic tasks. By addressing key challenges in data
quality, training efficiency, and domain-specific knowledge extraction, our
work paves the way for more reliable and effective AI-driven solutions in
healthcare. InfiMed-Foundation-4B model is available at
\href{https://huggingface.co/InfiX-ai/InfiMed-Foundation-4B}{InfiMed-Foundation-4B}.

</details>


### [124] [Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models](https://arxiv.org/abs/2509.22284)
*Aleksandar Terzić,Nicolas Menet,Michael Hersche,Thomas Hofmann,Abbas Rahimi*

Main category: cs.AI

TL;DR: 提出了一种结构化的稀疏参数化状态空间模型（PD-SSM），该模型在计算成本与对角SSM相当的同时，能够以最佳状态大小和深度进行FSA状态跟踪。


<details>
  <summary>Details</summary>
Motivation: 现代状态空间模型(SSM)通常使用过渡矩阵，这虽然能实现高效计算，但限制了模型的表达能力(以模拟有限状态自动机(FSA)的能力来衡量)。

Method: PD-SSM将转移矩阵参数化为列单热矩阵($P$)和复值对角矩阵($D$)的乘积。

Result: 在各种FSA状态跟踪任务中，该模型显著优于各种现代SSM变体。在多类时间序列分类中，其性能与神经控制微分方程相当。将PD-SSM集成到混合Transformer-SSM架构中，并证明该模型可以有效地跟踪复杂FSA的状态，其中转换被编码为一组可变长度的英语句子。

Conclusion: 该模型是BIBO稳定的，可以用一层维度$N$和大小为$N \times N$的线性读出模拟任何$N$状态FSA，显著改进了所有当前的结构化SSM保证。

Abstract: Modern state-space models (SSMs) often utilize transition matrices which
enable efficient computation but pose restrictions on the model's expressivity,
as measured in terms of the ability to emulate finite-state automata (FSA).
While unstructured transition matrices are optimal in terms of expressivity,
they come at a prohibitively high compute and memory cost even for moderate
state sizes. We propose a structured sparse parametrization of transition
matrices in SSMs that enables FSA state tracking with optimal state size and
depth, while keeping the computational cost of the recurrence comparable to
that of diagonal SSMs. Our method, PD-SSM, parametrizes the transition matrix
as the product of a column one-hot matrix ($P$) and a complex-valued diagonal
matrix ($D$). Consequently, the computational cost of parallel scans scales
linearly with the state size. Theoretically, the model is BIBO-stable and can
emulate any $N$-state FSA with one layer of dimension $N$ and a linear readout
of size $N \times N$, significantly improving on all current structured SSM
guarantees. Experimentally, the model significantly outperforms a wide
collection of modern SSM variants on various FSA state tracking tasks. On
multiclass time-series classification, the performance is comparable to that of
neural controlled differential equations, a paradigm explicitly built for
time-series analysis. Finally, we integrate PD-SSM into a hybrid
Transformer-SSM architecture and demonstrate that the model can effectively
track the states of a complex FSA in which transitions are encoded as a set of
variable-length English sentences. The code is available at
https://github.com/IBM/expressive-sparse-state-space-model

</details>


### [125] [Large Language Models as Nondeterministic Causal Models](https://arxiv.org/abs/2509.22297)
*Sander Beckers*

Main category: cs.AI

TL;DR: 本文提出了一种更简单的生成反事实的方法，该方法基于将LLM表示为非确定性因果模型。


<details>
  <summary>Details</summary>
Motivation: 现有的生成反事实的方法对LLM的解释不明确，并且需要修改LLM的抽样过程。

Method: 将LLM表示为非确定性因果模型，提出一种更简单的生成反事实的方法。

Result: 该方法可以直接应用于任何黑盒LLM，无需修改，并且与现有方法在理论上相关。

Conclusion: 本文为基于LLM的预期语义推理反事实奠定了基础，为新的特定应用的反事实生成方法奠定了基础。

Abstract: Recent work by Chatzi et al. and Ravfogel et al. has developed, for the first
time, a method for generating counterfactuals of probabilistic Large Language
Models. Such counterfactuals tell us what would - or might - have been the
output of an LLM if some factual prompt ${\bf x}$ had been ${\bf x}^*$ instead.
The ability to generate such counterfactuals is an important necessary step
towards explaining, evaluating, and comparing, the behavior of LLMs. I argue,
however, that the existing method rests on an ambiguous interpretation of LLMs:
it does not interpret LLMs literally, for the method involves the assumption
that one can change the implementation of an LLM's sampling process without
changing the LLM itself, nor does it interpret LLMs as intended, for the method
involves explicitly representing a nondeterministic LLM as a deterministic
causal model. I here present a much simpler method for generating
counterfactuals that is based on an LLM's intended interpretation by
representing it as a nondeterministic causal model instead. The advantage of my
simpler method is that it is directly applicable to any black-box LLM without
modification, as it is agnostic to any implementation details. The advantage of
the existing method, on the other hand, is that it directly implements the
generation of a specific type of counterfactuals that is useful for certain
purposes, but not for others. I clarify how both methods relate by offering a
theoretical foundation for reasoning about counterfactuals in LLMs based on
their intended semantics, thereby laying the groundwork for novel
application-specific methods for generating counterfactuals.

</details>


### [126] [PRIME: Planning and Retrieval-Integrated Memory for Enhanced Reasoning](https://arxiv.org/abs/2509.22315)
*Hieu Tran,Zonghai Yao,Nguyen Luong Tran,Zhichao Yang,Feiyun Ouyang,Shuo Han,Razieh Rahimi,Hong Yu*

Main category: cs.AI

TL;DR: PRIME: A multi-agent reasoning framework integrating fast, intuitive (System 1) and slow, deliberate (System 2) thinking.


<details>
  <summary>Details</summary>
Motivation: Inspired by the dual-process theory of human cognition, the paper aims to improve LLMs' reasoning capabilities by mimicking human cognitive processes.

Method: PRIME employs a Quick Thinking Agent (System 1) and a structured System 2 reasoning pipeline with specialized agents for planning, hypothesis generation, retrieval, information integration, and decision-making.

Result: PRIME enables open-source LLMs to perform competitively with state-of-the-art closed-source models on benchmarks requiring multi-hop and knowledge-grounded reasoning.

Conclusion: PRIME is a scalable solution for improving LLMs in domains requiring complex, knowledge-intensive reasoning.

Abstract: Inspired by the dual-process theory of human cognition from \textit{Thinking,
Fast and Slow}, we introduce \textbf{PRIME} (Planning and Retrieval-Integrated
Memory for Enhanced Reasoning), a multi-agent reasoning framework that
dynamically integrates \textbf{System 1} (fast, intuitive thinking) and
\textbf{System 2} (slow, deliberate thinking). PRIME first employs a Quick
Thinking Agent (System 1) to generate a rapid answer; if uncertainty is
detected, it then triggers a structured System 2 reasoning pipeline composed of
specialized agents for \textit{planning}, \textit{hypothesis generation},
\textit{retrieval}, \textit{information integration}, and
\textit{decision-making}. This multi-agent design faithfully mimics human
cognitive processes and enhances both efficiency and accuracy. Experimental
results with LLaMA 3 models demonstrate that PRIME enables open-source LLMs to
perform competitively with state-of-the-art closed-source models like GPT-4 and
GPT-4o on benchmarks requiring multi-hop and knowledge-grounded reasoning. This
research establishes PRIME as a scalable solution for improving LLMs in domains
requiring complex, knowledge-intensive reasoning.

</details>


### [127] [Do LLM Agents Know How to Ground, Recover, and Assess? A Benchmark for Epistemic Competence in Information-Seeking Agents](https://arxiv.org/abs/2509.22391)
*Jiaqi Shao,Yuxiang Lin,Munish Prasad Lohani,Yufeng Miao,Bing Luo*

Main category: cs.AI

TL;DR: SeekBench is introduced to evaluate the reasoning process of LLM search agents, not just final accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing evaluations of LLM search agents focus only on final answer accuracy, neglecting the reasoning process and interaction with external evidence.

Method: A new benchmark, SeekBench, is introduced, containing 190 expert-annotated traces with over 1,800 response steps.

Result: SeekBench enables granular analysis of whether agents generate reasoning steps grounded in evidence, adaptively reformulate searches, and are properly calibrated.

Conclusion: SeekBench is the first benchmark for evaluating the epistemic competence of LLM search agents through step-level analysis.

Abstract: Recent work has explored training Large Language Model (LLM) search agents
with reinforcement learning (RL) for open-domain question answering (QA).
However, most evaluations focus solely on final answer accuracy, overlooking
how these agents reason with and act on external evidence. We introduce
SeekBench, the first benchmark for evaluating the \textit{epistemic competence}
of LLM search agents through step-level analysis of their response traces.
SeekBench comprises 190 expert-annotated traces with over 1,800 response steps
generated by LLM search agents, each enriched with evidence annotations for
granular analysis of whether agents (1) generate reasoning steps grounded in
observed evidence, (2) adaptively reformulate searches to recover from
low-quality results, and (3) have proper calibration to correctly assess
whether the current evidence is sufficient for providing an answer.

</details>


### [128] [EMMA: Generalizing Real-World Robot Manipulation via Generative Visual Transfer](https://arxiv.org/abs/2509.22407)
*Zhehao Dong,Xiaofeng Wang,Zheng Zhu,Yirui Wang,Yang Wang,Yukun Zhou,Boyuan Wang,Chaojun Ni,Runqi Ouyang,Wenkang Qin,Xinze Chen,Yun Ye,Guan Huang*

Main category: cs.AI

TL;DR: 提出EMMA框架，结合生成数据引擎和训练流程来增强VLA策略，解决机器人操作数据收集难题。


<details>
  <summary>Details</summary>
Motivation: 收集大规模真实机器人操作数据成本高昂。

Method: 提出DreamTransfer，一个基于扩散Transformer的框架，用于生成多视角一致、几何合理的机器人操作视频。同时提出AdaMix，一种感知和运动学难样本的训练策略。

Result: DreamTransfer生成的视频在多视角一致性、几何保真度和文本条件精度方面优于现有方法。使用生成数据训练的VLA使机器人能够推广到未见过的物体类别和新的视觉领域。在真实机器人操作任务中，与仅在真实数据上训练相比，该方法实现了超过200%的相对性能提升，并通过AdaMix进一步提高了13%。

Conclusion: EMMA框架能有效提升策略的泛化能力。

Abstract: Vision-language-action (VLA) models increasingly rely on diverse training
data to achieve robust generalization. However, collecting large-scale
real-world robot manipulation data across varied object appearances and
environmental conditions remains prohibitively time-consuming and expensive. To
overcome this bottleneck, we propose Embodied Manipulation Media Adaptation
(EMMA), a VLA policy enhancement framework that integrates a generative data
engine with an effective training pipeline. We introduce DreamTransfer, a
diffusion Transformer-based framework for generating multi-view consistent,
geometrically grounded embodied manipulation videos. DreamTransfer enables
text-controlled visual editing of robot videos, transforming foreground,
background, and lighting conditions without compromising 3D structure or
geometrical plausibility. Furthermore, we explore hybrid training with real and
generated data, and introduce AdaMix, a hard-sample-aware training strategy
that dynamically reweights training batches to focus optimization on
perceptually or kinematically challenging samples. Extensive experiments show
that videos generated by DreamTransfer significantly outperform prior video
generation methods in multi-view consistency, geometric fidelity, and
text-conditioning accuracy. Crucially, VLAs trained with generated data enable
robots to generalize to unseen object categories and novel visual domains using
only demonstrations from a single appearance. In real-world robotic
manipulation tasks with zero-shot visual domains, our approach achieves over a
200% relative performance gain compared to training on real data alone, and
further improves by 13% with AdaMix, demonstrating its effectiveness in
boosting policy generalization.

</details>


### [129] [Guiding Evolution of Artificial Life Using Vision-Language Models](https://arxiv.org/abs/2509.22447)
*Nikhil Baid,Hannah Erlebach,Paul Hellegouarch,Frederico Wieser*

Main category: cs.AI

TL;DR: ASAL++方法使用多模态FMs引导开放式搜索，通过视觉历史提出新的进化目标，从而产生具有日益复杂目标的进化轨迹。


<details>
  <summary>Details</summary>
Motivation: 利用FMs自动化搜索ALife模拟，将ALife模拟与自然语言目标提示对齐。

Method: 引入ASAL++方法，使用Gemma-3在Lenia基质上进行实验，探索了演化模拟以匹配单个新提示（EST）和演化模拟以匹配整个生成提示序列（ETT）两种策略。

Result: EST促进了更大的视觉新颖性，而ETT培养了更连贯和可解释的进化序列。

Conclusion: ASAL++为FM驱动的具有开放式特征的ALife发现指明了新的方向。

Abstract: Foundation models (FMs) have recently opened up new frontiers in the field of
artificial life (ALife) by providing powerful tools to automate search through
ALife simulations. Previous work aligns ALife simulations with natural language
target prompts using vision-language models (VLMs). We build on Automated
Search for Artificial Life (ASAL) by introducing ASAL++, a method for
open-ended-like search guided by multimodal FMs. We use a second FM to propose
new evolutionary targets based on a simulation's visual history. This induces
an evolutionary trajectory with increasingly complex targets.
  We explore two strategies: (1) evolving a simulation to match a single new
prompt at each iteration (Evolved Supervised Targets: EST) and (2) evolving a
simulation to match the entire sequence of generated prompts (Evolved Temporal
Targets: ETT). We test our method empirically in the Lenia substrate using
Gemma-3 to propose evolutionary targets, and show that EST promotes greater
visual novelty, while ETT fosters more coherent and interpretable evolutionary
sequences.
  Our results suggest that ASAL++ points towards new directions for FM-driven
ALife discovery with open-ended characteristics.

</details>


### [130] [GeoSketch: A Neural-Symbolic Approach to Geometric Multimodal Reasoning with Auxiliary Line Construction and Affine Transformation](https://arxiv.org/abs/2509.22460)
*Shichao Weng,Zhiqiang Wang,Yuhua Zhou,Rui Lu,Ting Liu,Zhiyang Teng,Xiaozhang Liu,Hanmeng Liu*

Main category: cs.AI

TL;DR: GeoSketch是一个神经符号框架，它将几何推理重铸为一个交互式的感知-推理-行动循环，通过动态操作图表来解决几何问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型（MLLM）在处理几何问题时，缺乏动态操作能力，无法进行辅助线构造和仿射变换。

Method: GeoSketch集成了感知模块（将图表抽象为结构化逻辑形式）、符号推理模块（应用几何定理来决定下一步的推导步骤）和草图行动模块（执行绘制辅助线或应用变换等操作）。

Result: GeoSketch在逐步推理准确性和问题解决成功率方面显著优于静态感知方法。

Conclusion: GeoSketch通过统一分层决策、可执行的视觉动作和符号验证，将多模态推理从静态解释提升到动态、可验证的交互，为解决复杂的视觉空间问题奠定了新的基础。

Abstract: Geometric Problem Solving (GPS) poses a unique challenge for Multimodal Large
Language Models (MLLMs), requiring not only the joint interpretation of text
and diagrams but also iterative visuospatial reasoning. While existing
approaches process diagrams as static images, they lack the capacity for
dynamic manipulation - a core aspect of human geometric reasoning involving
auxiliary line construction and affine transformations. We present GeoSketch, a
neural-symbolic framework that recasts geometric reasoning as an interactive
perception-reasoning-action loop. GeoSketch integrates: (1) a Perception module
that abstracts diagrams into structured logic forms, (2) a Symbolic Reasoning
module that applies geometric theorems to decide the next deductive step, and
(3) a Sketch Action module that executes operations such as drawing auxiliary
lines or applying transformations, thereby updating the diagram in a closed
loop. To train this agent, we develop a two-stage pipeline: supervised
fine-tuning on 2,000 symbolic-curated trajectories followed by reinforcement
learning with dense, symbolic rewards to enhance robustness and strategic
exploration. To evaluate this paradigm, we introduce the GeoSketch Benchmark, a
high-quality set of 390 geometry problems requiring auxiliary construction or
affine transformations. Experiments on strong MLLM baselines demonstrate that
GeoSketch significantly improves stepwise reasoning accuracy and
problem-solving success over static perception methods. By unifying
hierarchical decision-making, executable visual actions, and symbolic
verification, GeoSketch advances multimodal reasoning from static
interpretation to dynamic, verifiable interaction, establishing a new
foundation for solving complex visuospatial problems.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [131] [QueryGym: Step-by-Step Interaction with Relational Databases](https://arxiv.org/abs/2509.21674)
*Haritha Ananthakrishanan,Harsha Kokel,Kelsey Sikes,Debarun Bhattacharjya,Michael Katz,Shirin Sohrabi,Kavitha Srinivas*

Main category: cs.DB

TL;DR: QueryGym是一个交互式环境，用于构建、测试和评估基于LLM的查询规划代理。


<details>
  <summary>Details</summary>
Motivation: 现有的框架通常将代理与特定的查询语言方言联系起来，或者模糊它们的推理；QueryGym需要代理构建关系代数操作的显式序列，确保引擎不可知的评估和透明的逐步规划。

Method: 该环境被实现为一个Gymnasium接口，该接口提供观察结果（包括模式细节、中间结果和执行反馈），并接收表示数据库探索（例如，预览表、采样列值、检索唯一值）以及关系代数操作（例如，过滤、项目、连接）的动作。

Result: 通过将QueryGym与查询数据库的当代LLM进行对比，展示了该环境的实用性。

Conclusion: QueryGym可以作为查询生成中错误修复、透明性和强化学习研究的实践试验台。

Abstract: We introduce QueryGym, an interactive environment for building, testing, and
evaluating LLM-based query planning agents. Existing frameworks often tie
agents to specific query language dialects or obscure their reasoning; QueryGym
instead requires agents to construct explicit sequences of relational algebra
operations, ensuring engine-agnostic evaluation and transparent step-by-step
planning. The environment is implemented as a Gymnasium interface that supplies
observations -- including schema details, intermediate results, and execution
feedback -- and receives actions that represent database exploration (e.g.,
previewing tables, sampling column values, retrieving unique values) as well as
relational algebra operations (e.g., filter, project, join). We detail the
motivation and the design of the environment. In the demo, we showcase the
utility of the environment by contrasting it with contemporary LLMs that query
databases. QueryGym serves as a practical testbed for research in error
remediation, transparency, and reinforcement learning for query generation. For
the associated demo, see https://ibm.biz/QueryGym.

</details>


### [132] [Unbiased Binning: Fairness-aware Attribute Representation](https://arxiv.org/abs/2509.21785)
*Abolfazl Asudeh,Zeinab,Asoodeh,Bita Asoodeh,Omid Asudeh*

Main category: cs.DB

TL;DR: 提出了一种无偏分箱问题，旨在找到最接近等大小分箱的离散化方法，以满足不同桶之间的群体均等性。


<details>
  <summary>Details</summary>
Motivation: 分箱是共享数据集之前的常见步骤，但会导致数据偏差并加剧下游任务中的不公平性。

Method: 1. 定义了一小组边界候选，证明无偏分箱必须从此集合中选择其边界。2. 在边界候选的基础上，开发了一种高效的动态规划算法来解决无偏分箱问题。3. 针对 epsilon-biased 分箱问题，首先开发了一个动态规划解决方案 DP，该方案在二次时间内找到最优分箱。然后，提出了一种基于局部搜索 (LS) 的、实际可扩展的 epsilon-biased 分箱算法。LS 算法的关键组成部分是一种分而治之 (D&C) 算法，该算法以接近线性的时间为问题找到接近最优的解决方案。

Result: 开发了动态规划算法和局部搜索算法，以解决无偏分箱和 epsilon-biased 分箱问题。

Conclusion: 研究了无偏分箱问题，并提出了相应的解决方案，包括动态规划和局部搜索算法。

Abstract: Discretizing raw features into bucketized attribute representations is a
popular step before sharing a dataset. It is, however, evident that this step
can cause significant bias in data and amplify unfairness in downstream tasks.
  In this paper, we address this issue by introducing the unbiased binning
problem that, given an attribute to bucketize, finds its closest discretization
to equal-size binning that satisfies group parity across different buckets.
Defining a small set of boundary candidates, we prove that unbiased binning
must select its boundaries from this set. We then develop an efficient dynamic
programming algorithm on top of the boundary candidates to solve the unbiased
binning problem.
  Finding an unbiased binning may sometimes result in a high price of fairness,
or it may not even exist, especially when group values follow different
distributions. Considering that a small bias in the group ratios may be
tolerable in such settings, we introduce the epsilon-biased binning problem
that bounds the group disparities across buckets to a small value epsilon. We
first develop a dynamic programming solution, DP, that finds the optimal
binning in quadratic time. The DP algorithm, while polynomial, does not scale
to very large settings. Therefore, we propose a practically scalable algorithm,
based on local search (LS), for epsilon-biased binning. The key component of
the LS algorithm is a divide-and-conquer (D&C) algorithm that finds a
near-optimal solution for the problem in near-linear time. We prove that D&C
finds a valid solution for the problem unless none exists. The LS algorithm
then initiates a local search, using the D&C solution as the upper bound, to
find the optimal solution.

</details>


### [133] [The system of processing and analysis of customer tracking data for customer journey research on the base of RFID technology](https://arxiv.org/abs/2509.22162)
*Marina Kholod*

Main category: cs.DB

TL;DR: 本文研究了基于RFID技术的零售客户旅程跟踪数据处理和分析系统。


<details>
  <summary>Details</summary>
Motivation: 利用RFID技术改进零售业的库存管理、防损和客户体验，实现数据驱动的精准零售。

Method: 采用ETL方法将原始RFID和POS数据转换为结构化的分析数据仓库，并提出了详细的逻辑数据库模型。

Result: 通过集成跟踪和交易数据，零售业可以前所未有地了解产品流动和消费者行为。

Conclusion: RFID技术的应用为零售业转变为精确的数据驱动科学奠定了基础。

Abstract: The article focuses on researching a system for processing and analyzing
tracking data based on RFID technology to study the customer journey in retail.
It examines the evolution of RFID technology, its key operating principles, and
modern applications in retail that extend beyond logistics to include precise
inventory management, loss prevention, and customer experience improvement.
Particular attention is paid to the architecture for data collection,
processing, and integration, specifically the ETL (extract, transform, load)
methodology for transforming raw RFID and POS data into a structured analytical
data warehouse. A detailed logical database model is proposed, designed for
comprehensive analysis that combines financial sales metrics with behavioral
patterns of customer movement. The article also analyzes the expected business
benefits of RFID implementation through the lens of the Balanced Scorecard
(BSC), which evaluates financial performance, customer satisfaction, and
internal process optimization. It is concluded that the integration of tracking
and transactional data creates a foundation for transforming retail into a
precise, data-driven science, providing unprecedented visibility into physical
product flows and consumer behavior.

</details>


### [134] [I-ETL: an interoperability-aware health (meta) data pipeline to enable federated analyses](https://arxiv.org/abs/2509.22351)
*Nelly Barret,Anna Bernasconi,Boris Bikbov,Pietro Pinoli*

Main category: cs.DB

TL;DR: 本研究提出了一种名为I-ETL的框架，用于整合医院中高度异构的医疗保健数据集到可互操作的数据库中。


<details>
  <summary>Details</summary>
Motivation: 临床医生有兴趣更好地了解复杂疾病，因此他们需要生成和交换数据以互助资源并联合力量。在实践中，医疗机构通常使用不同的表示和原始数据单独工作，他们没有办法标准化他们的数据，更不用说跨中心进行标准化。

Method: 我们设计并实现了一个名为I-ETL的框架，用于在互操作数据库中集成医院的高度异构医疗保健数据集。我们的建议是双重的：（i）我们设计了两个通用且可扩展的概念模型，用于建模数据和元数据，以及（ii）我们提出了一个提取-转换-加载（ETL）管道，从一开始就确保和评估互操作性。

Result: 通过在开源数据集上进行实验，我们表明I-ETL成功地以统一的方式表示各种健康数据集，这要归功于我们的两个通用概念模型。

Conclusion: 我们证明了在集成管道中将互操作性作为一等公民进行混合的重要性，从而确保不同中心之间可能的协作。

Abstract: Clinicians are interested in better understanding complex diseases, such as
cancer or rare diseases, so they need to produce and exchange data to mutualize
sources and join forces. To do so and ensure privacy, a natural way consists in
using a decentralized architecture and Federated Learning algorithms. This
ensures that data stays in the organization in which it has been collected, but
requires data to be collected in similar settings and similar models. In
practice, this is often not the case because healthcare institutions work
individually with different representations and raw data; they do not have
means to normalize their data, and even less to do so across centers. For
instance, clinicians have at hand phenotypic, clinical, imaging and genomic
data (each individually collected) and want to better understand some diseases
by analyzing them together. This example highlights the needs and challenges
for a cooperative use of this wealth of information. We designed and
implemented a framework, named I-ETL, for integrating highly heterogeneous
healthcare datasets of hospitals in interoperable databases. Our proposal is
twofold: (i) we devise two general and extensible conceptual models for
modeling both data and metadata and (ii) we propose an Extract-Transform-Load
(ETL) pipeline ensuring and assessing interoperability from the start. By
conducting experiments on open-source datasets, we show that I-ETL succeeds in
representing various health datasets in a unified way thanks to our two general
conceptual models. Next, we demonstrate the importance of blending
interoperability as a first-class citizen in integration pipelines, ensuring
possible collaboration between different centers.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [135] [SPELUNKER: Item Similarity Search Using Large Language Models and Custom K-Nearest Neighbors](https://arxiv.org/abs/2509.21323)
*Ana Rodrigues,João Mata,Rui Rego*

Main category: cs.IR

TL;DR: 提出了一种结合大型语言模型（LLM）和自定义K近邻（KNN）算法的混合系统，用于直观的物品相似性搜索。


<details>
  <summary>Details</summary>
Motivation: 为了解决黑盒密集向量系统缺乏可解释性的问题，并弥合人类语言和机器可理解的物品表示之间的差距。

Method: 首先使用LLM将自然语言查询转换为基于属性的结构化搜索，然后将其输入到具有BallTree搜索策略的自定义KNN算法中，该算法使用异构距离度量来保留不同的数据类型。此外，还采用了基于LLM的重排序来提升搜索结果。

Result: 在500条葡萄酒评论数据集上的评估表明，LLM在信息提取方面达到了0.9779的F1分数，并具有0.9321的Jaro字符串相似度。通过LLM重排序增强KNN算法后，召回率得到了显著提高（p=0.013）。

Conclusion: 该方法有效地弥合了人类语言和机器可理解的物品表示之间的差距，提供了一种透明且细致的搜索能力。

Abstract: This paper presents a hybrid system for intuitive item similarity search that
combines a Large Language Model (LLM) with a custom K-Nearest Neighbors (KNN)
algorithm. Unlike black-box dense vector systems, this architecture provides
superior interpretability by first using an LLM to convert natural language
queries into structured, attribute-based searches. This structured query then
serves as input to a custom KNN algorithm with a BallTree search strategy,
which uses a heterogeneous distance metric to preserve distinct data types. Our
evaluation, conducted on a dataset of 500 wine reviews, demonstrates the
system's effectiveness. The LLM achieved an F1-score of 0.9779 in information
extraction, while also demonstrating high fidelity with a Jaro string
similarity of 0.9321. When we augmented the KNN algorithm with LLM-based
re-ranking, we observed a statistically significant improvement in recall
(p=0.013), indicating the LLM's ability to identify and promote relevant items
that align with nuanced user intent. This approach effectively bridges the gap
between human language and machine-understandable item representations,
offering a transparent and nuanced search capability.

</details>


### [136] [From Search to Reasoning: A Five-Level RAG Capability Framework for Enterprise Data](https://arxiv.org/abs/2509.21324)
*Gurbinder Gill,Ritvik Gupta,Denis Lusson,Anand Chandrashekar,Donald Nguyen*

Main category: cs.IR

TL;DR: 论文提出了一个新的分类框架 (L1-L5) 用于根据数据模态和底层问答问题的任务复杂性对系统进行分类。


<details>
  <summary>Details</summary>
Motivation: 传统的 RAG 集中于基于文本的语义搜索和重新排序。然而，当处理超出数据摘要或非文本数据的问题时，这种方法就显得不足。

Method: 提出了一个新的分类框架 (L1-L5) ，并引入了与这些级别对齐的基准，并评估了四个最先进的平台：LangChain、Azure AI Search、OpenAI 和 Corvic AI。

Result: 实验强调了多空间检索和动态编排对于实现 L1-L4 能力的价值。我们使用指示企业用例的各种数据集对我们的发现进行了实证验证。

Conclusion: 当代 RAG 是一系列技术而不是一个定义的实现，从面向问题的理解中受益。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as the standard paradigm for
answering questions on enterprise data. Traditionally, RAG has centered on
text-based semantic search and re-ranking. However, this approach falls short
when dealing with questions beyond data summarization or non-text data. This
has led to various attempts to supplement RAG to bridge the gap between RAG,
the implementation paradigm, and the question answering problem that enterprise
users expect it to solve. Given that contemporary RAG is a collection of
techniques rather than a defined implementation, discussion of RAG and related
question-answering systems benefits from a problem-oriented understanding.
  We propose a new classification framework (L1-L5) to categorize systems based
on data modalities and task complexity of the underlying question answering
problems: L1 (Surface Knowledge of Unstructured Data) through L4 (Reflective
and Reasoned Knowledge) and the aspirational L5 (General Intelligence). We also
introduce benchmarks aligned with these levels and evaluate four
state-of-the-art platforms: LangChain, Azure AI Search, OpenAI, and Corvic AI.
Our experiments highlight the value of multi-space retrieval and dynamic
orchestration for enabling L1-L4 capabilities. We empirically validate our
findings using diverse datasets indicative of enterprise use cases.

</details>


### [137] [PIR-RAG: A System for Private Information Retrieval in Retrieval-Augmented Generation](https://arxiv.org/abs/2509.21325)
*Baiqiang Wang,Qian Lou,Mengxin Zheng,Dongfang Zhao*

Main category: cs.IR

TL;DR: PIR-RAG: A privacy-preserving RAG system using semantic clustering and lattice-based PIR.


<details>
  <summary>Details</summary>
Motivation: Addressing privacy risks in RAG systems by preventing exposure of user queries.

Method: Utilizes coarse-grained semantic clustering to prune the search space, combined with a fast, lattice-based Private Information Retrieval (PIR) protocol for efficient document cluster retrieval.

Result: PIR-RAG demonstrates scalability and superior performance compared to baseline architectures in terms of RAG-Ready Latency.

Conclusion: PIR-RAG is a viable and efficient solution for privacy in large-scale AI systems.

Abstract: Retrieval-Augmented Generation (RAG) has become a foundational component of
modern AI systems, yet it introduces significant privacy risks by exposing user
queries to service providers. To address this, we introduce PIR-RAG, a
practical system for privacy-preserving RAG. PIR-RAG employs a novel
architecture that uses coarse-grained semantic clustering to prune the search
space, combined with a fast, lattice-based Private Information Retrieval (PIR)
protocol. This design allows for the efficient retrieval of entire document
clusters, uniquely optimizing for the end-to-end RAG workflow where full
document content is required. Our comprehensive evaluation against strong
baseline architectures, including graph-based PIR and Tiptoe-style private
scoring, demonstrates PIR-RAG's scalability and its superior performance in
terms of "RAG-Ready Latency"-the true end-to-end time required to securely
fetch content for an LLM. Our work establishes PIR-RAG as a viable and highly
efficient solution for privacy in large-scale AI systems.

</details>


### [138] [HetaRAG: Hybrid Deep Retrieval-Augmented Generation across Heterogeneous Data Stores](https://arxiv.org/abs/2509.21336)
*Guohang Yan,Yue Zhang,Pinlong Cai,Ding Wang,Song Mao,Hongwei Zhang,Yaoze Zhang,Hairong Zhang,Xinyu Cai,Botian Shi*

Main category: cs.IR

TL;DR: 本论文介绍了一种名为HetaRAG的混合深度检索增强生成框架，旨在整合向量索引、知识图谱、全文引擎和结构化数据库等多种数据存储方式，以提高检索的召回率、精确性和上下文保真度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）存在知识幻觉和过时问题，同时需要保证数据安全。检索增强生成（RAG）通过从私有领域语料库中检索相关证据并将其注入到精心设计的提示中，可以在不进行微调的情况下提供可信的响应。

Method: 提出了一种混合的、深度检索增强生成框架HetaRAG，该框架可以协调来自异构数据存储的跨模态证据，将向量索引、知识图谱、全文引擎和结构化数据库统一到一个检索平面中，动态地路由和融合证据。

Result: 构建了一个初步的RAG管道，并提供了部分代码。

Conclusion: 异构检索范式是互补的，提出的融合方案可以协同地协调它们，从而减轻任何单一模态的弱点。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for
mitigating knowledge hallucination and staleness in large language models
(LLMs) while preserving data security. By retrieving relevant evidence from
private, domain-specific corpora and injecting it into carefully engineered
prompts, RAG delivers trustworthy responses without the prohibitive cost of
fine-tuning. Traditional retrieval-augmented generation (RAG) systems are
text-only and often rely on a single storage backend, most commonly a vector
database. In practice, this monolithic design suffers from unavoidable
trade-offs: vector search captures semantic similarity yet loses global
context; knowledge graphs excel at relational precision but struggle with
recall; full-text indexes are fast and exact yet semantically blind; and
relational engines such as MySQL provide strong transactional guarantees but no
semantic understanding. We argue that these heterogeneous retrieval paradigms
are complementary, and propose a principled fusion scheme to orchestrate them
synergistically, mitigating the weaknesses of any single modality. In this work
we introduce HetaRAG, a hybrid, deep-retrieval augmented generation framework
that orchestrates cross-modal evidence from heterogeneous data stores. We plan
to design a system that unifies vector indices, knowledge graphs, full-text
engines, and structured databases into a single retrieval plane, dynamically
routing and fusing evidence to maximize recall, precision, and contextual
fidelity. To achieve this design goal, we carried out preliminary explorations
and constructed an initial RAG pipeline; this technical report provides a brief
overview. The partial code is available at
https://github.com/KnowledgeXLab/HetaRAG.

</details>


### [139] [Cross-Modal Retrieval with Cauchy-Schwarz Divergence](https://arxiv.org/abs/2509.21339)
*Jiahao Zhang,Wenzhe Yin,Shujian Yu*

Main category: cs.IR

TL;DR: 提出了一种新的无超参数的Cauchy-Schwarz (CS) 散度，并将其扩展为广义CS (GCS) 散度，用于多模态检索任务。


<details>
  <summary>Details</summary>
Motivation: 现有的跨模态检索方法存在数值不稳定、对超参数敏感以及无法捕捉底层分布的完整结构等局限性。

Method: 提出了Cauchy-Schwarz (CS) 散度和广义CS (GCS) 散度，通过双向循环比较方案直接对齐三种或更多模态。

Result: 在六个基准数据集上的大量实验表明，该方法在双模态和三模态检索任务中均有效。

Conclusion: 提出的CS/GCS散度能够提升训练稳定性和检索性能，代码已公开。

Abstract: Effective cross-modal retrieval requires robust alignment of heterogeneous
data types. Most existing methods focus on bi-modal retrieval tasks and rely on
distributional alignment techniques such as Kullback-Leibler divergence,
Maximum Mean Discrepancy, and correlation alignment. However, these methods
often suffer from critical limitations, including numerical instability,
sensitivity to hyperparameters, and their inability to capture the full
structure of the underlying distributions. In this paper, we introduce the
Cauchy-Schwarz (CS) divergence, a hyperparameter-free measure that improves
both training stability and retrieval performance. We further propose a novel
Generalized CS (GCS) divergence inspired by H\"older's inequality. This
extension enables direct alignment of three or more modalities within a unified
mathematical framework through a bidirectional circular comparison scheme,
eliminating the need for exhaustive pairwise comparisons. Extensive experiments
on six benchmark datasets demonstrate the effectiveness of our method in both
bi-modal and tri-modal retrieval tasks. The code of our CS/GCS divergence is
publicly available at https://github.com/JiahaoZhang666/CSD.

</details>


### [140] [ReGeS: Reciprocal Retrieval-Generation Synergy for Conversational Recommender Systems](https://arxiv.org/abs/2509.21371)
*Dayu Yang,Hui Fang*

Main category: cs.IR

TL;DR: ReGeS框架通过检索和生成协同，从对话中提取用户意图，区分项目特征，提高推荐准确率，且无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 现有对话推荐系统依赖领域知识或大型语言模型，存在灵活性不足和幻觉问题。

Method: 提出ReGeS框架，利用生成增强检索提炼用户意图，利用检索增强生成区分项目特征。

Result: 在多个对话推荐系统基准测试中，ReGeS取得了state-of-the-art的推荐准确率。

Conclusion: 提出的相互协同方法有效提升了知识密集型对话推荐系统的性能。

Abstract: Connecting conversation with external domain knowledge is vital for
conversational recommender systems (CRS) to correctly understand user
preferences. However, existing solutions either require domain-specific
engineering, which limits flexibility, or rely solely on large language models,
which increases the risk of hallucination. While Retrieval-Augmented Generation
(RAG) holds promise, its naive use in CRS is hindered by noisy dialogues that
weaken retrieval and by overlooked nuances among similar items. We propose
ReGeS, a reciprocal Retrieval-Generation Synergy framework that unifies
generation-augmented retrieval to distill informative user intent from
conversations and retrieval-augmented generation to differentiate subtle item
features. This synergy obviates the need for extra annotations, reduces
hallucinations, and simplifies continuous updates. Experiments on multiple CRS
benchmarks show that ReGeS achieves state-of-the-art performance in
recommendation accuracy, demonstrating the effectiveness of reciprocal synergy
for knowledge-intensive CRS tasks.

</details>


### [141] [MIXRAG : Mixture-of-Experts Retrieval-Augmented Generation for Textual Graph Understanding and Question Answering](https://arxiv.org/abs/2509.21391)
*Lihui Liu,Carl J. Yang*

Main category: cs.IR

TL;DR: MIXRAG: A Mixture-of-Experts Graph-RAG framework with multiple specialized graph retrievers and a dynamic routing controller to handle diverse query intents.


<details>
  <summary>Details</summary>
Motivation: LLMs hallucinate in knowledge-intensive domains due to reliance on static pretraining corpora. Existing graph-based RAG systems use a single retriever, limiting their ability to capture diverse query aspects and struggling with irrelevant noise.

Method: Proposes MIXRAG, a Mixture-of-Experts Graph-RAG framework. It introduces multiple specialized graph retrievers focusing on different aspects of graph semantics and a dynamic routing controller. A query-aware GraphEncoder reduces noise by analyzing relationships within retrieved subgraphs.

Result: Achieves state-of-the-art performance and consistently outperforms baselines across a wide range of graph-based tasks in different domains.

Conclusion: MIXRAG effectively addresses limitations of existing graph-based RAG systems by using a mixture of specialized retrievers and a noise-reduction mechanism, leading to improved performance.

Abstract: Large Language Models (LLMs) have achieved impressive performance across a
wide range of applications. However, they often suffer from hallucinations in
knowledge-intensive domains due to their reliance on static pretraining
corpora. To address this limitation, Retrieval-Augmented Generation (RAG)
enhances LLMs by incorporating external knowledge sources during inference.
Among these sources, textual graphs provide structured and semantically rich
information that supports more precise and interpretable reasoning. This has
led to growing interest in graph-based RAG systems. Despite their potential,
most existing approaches rely on a single retriever to identify relevant
subgraphs, which limits their ability to capture the diverse aspects of complex
queries. Moreover, these systems often struggle to accurately judge the
relevance of retrieved content, making them prone to distraction by irrelevant
noise. To address these challenges, in this paper, we propose MIXRAG, a
Mixture-of-Experts Graph-RAG framework that introduces multiple specialized
graph retrievers and a dynamic routing controller to better handle diverse
query intents. Each retriever is trained to focus on a specific aspect of graph
semantics, such as entities, relations, or subgraph topology. A
Mixture-of-Experts module adaptively selects and fuses relevant retrievers
based on the input query. To reduce noise in the retrieved information, we
introduce a query-aware GraphEncoder that carefully analyzes relationships
within the retrieved subgraphs, highlighting the most relevant parts while
down-weighting unnecessary noise. Empirical results demonstrate that our method
achieves state-of-the-art performance and consistently outperforms various
baselines. MIXRAG is effective across a wide range of graph-based tasks in
different domains. The code will be released upon paper acceptance.

</details>


### [142] [Effect of Model Merging in Domain-Specific Ad-hoc Retrieval](https://arxiv.org/abs/2509.21966)
*Taiga Sasaki,Takehiro Yamamoto,Hiroaki Ohshima,Sumio Fujita*

Main category: cs.IR

TL;DR: 本文研究了模型合并在ad-hoc检索任务中的效果，通过线性插值方法合并源检索模型和领域特定模型，无需额外微调。


<details>
  <summary>Details</summary>
Motivation: 假设模型合并可以提高领域特定ad-hoc检索任务的检索效果。

Method: 使用线性插值方法合并源检索模型和领域特定（非检索）模型的权重。

Result: 模型合并比源检索模型更有效，并且可以作为LoRA微调的替代方案，尤其是在数据量有限的情况下。

Conclusion: 模型合并具有产生比源检索模型更有效的领域特定检索模型的潜力，并且可以作为LoRA微调的实用替代方案，尤其是在只有少量数据可用时。

Abstract: In this study, we evaluate the effect of model merging in ad-hoc retrieval
tasks. Model merging is a technique that combines the diverse characteristics
of multiple models. We hypothesized that applying model merging to
domain-specific ad-hoc retrieval tasks could improve retrieval effectiveness.
To verify this hypothesis, we merged the weights of a source retrieval model
and a domain-specific (non-retrieval) model using a linear interpolation
approach. A key advantage of our approach is that it requires no additional
fine-tuning of the models. We conducted two experiments each in the medical and
Japanese domains. The first compared the merged model with the source retrieval
model, and the second compared it with a LoRA fine-tuned model under both full
and limited data settings for model construction. The experimental results
indicate that model merging has the potential to produce more effective
domain-specific retrieval models than the source retrieval model, and may serve
as a practical alternative to LoRA fine-tuning, particularly when only a
limited amount of data is available.

</details>


### [143] [GoalRank: Group-Relative Optimization for a Large Ranking Model](https://arxiv.org/abs/2509.22046)
*Kaike Zhang,Xiaobei Wang,Shuchang Liu,Hailan Yang,Xiang Li,Lantao Hu,Han Li,Qi Cao,Fei Sun,Kun Gai*

Main category: cs.IR

TL;DR: 提出了一个名为GoalRank的仅生成器排序框架，该框架优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统排序方法效果有限，而大型推荐模型显示出端到端单阶段模型的潜力。

Method: 从理论上证明了仅生成器模型可以实现更小的近似误差，并利用奖励模型构建参考策略。

Result: 在公共基准和大规模在线 A/B 测试中，GoalRank 始终优于现有方法。

Conclusion: GoalRank 是一个有效的单阶段排序框架。

Abstract: Mainstream ranking approaches typically follow a Generator-Evaluator
two-stage paradigm, where a generator produces candidate lists and an evaluator
selects the best one. Recent work has attempted to enhance performance by
expanding the number of candidate lists, for example, through multi-generator
settings. However, ranking involves selecting a recommendation list from a
combinatorially large space. Simply enlarging the candidate set remains
ineffective, and performance gains quickly saturate. At the same time, recent
advances in large recommendation models have shown that end-to-end one-stage
models can achieve promising performance with the expectation of scaling laws.
Motivated by this, we revisit ranking from a generator-only one-stage
perspective. We theoretically prove that, for any (finite
Multi-)Generator-Evaluator model, there always exists a generator-only model
that achieves strictly smaller approximation error to the optimal ranking
policy, while also enjoying scaling laws as its size increases. Building on
this result, we derive an evidence upper bound of the one-stage optimization
objective, from which we find that one can leverage a reward model trained on
real user feedback to construct a reference policy in a group-relative manner.
This reference policy serves as a practical surrogate of the optimal policy,
enabling effective training of a large generator-only ranker. Based on these
insights, we propose GoalRank, a generator-only ranking framework. Extensive
offline experiments on public benchmarks and large-scale online A/B tests
demonstrate that GoalRank consistently outperforms state-of-the-art methods.

</details>


### [144] [Does Generative Retrieval Overcome the Limitations of Dense Retrieval?](https://arxiv.org/abs/2509.22116)
*Yingchen Zhang,Ruqing Zhang,Jiafeng Guo,Maarten de Rijke,Yixing Fan,Xueqi Cheng*

Main category: cs.IR

TL;DR: 生成式检索 (GR) 通过直接生成相关文档的标识符，为神经信息检索提供了一种新范式，作为密集检索 (DR) 的替代方案。本文从理论和实证角度研究了 GR 在学习目标和表征能力上与 DR 的根本区别。


<details>
  <summary>Details</summary>
Motivation: GR 执行全局归一化最大似然优化，并将语料库和相关性信息直接编码在模型参数中，而 DR 采用局部归一化目标，并在通过双线性交互计算相似度之前用外部嵌入表示语料库。

Method: 通过在 Natural Questions 和 MS MARCO 数据集上进行受控实验，验证这些理论见解，实验涵盖不同的负采样策略、嵌入维度和模型规模。

Result: 分析表明，在扩展时，GR 可以克服 DR 的固有局限性，从而产生两个主要优势。首先，对于较大的语料库，GR 避免了由 DR 的局部归一化引起的优化漂移导致的性能急剧下降。其次，对于较大的模型，GR 的表征能力随参数大小而扩展，不受限制 DR 的全局低秩结构。

Conclusion: 尽管 GR 具有理论优势，但在实践中并未普遍优于 DR。我们概述了弥合 GR 的理论潜力和实际性能之间差距的方向，为可扩展和稳健的生成式检索的未来研究提供指导。

Abstract: Generative retrieval (GR) has emerged as a new paradigm in neural information
retrieval, offering an alternative to dense retrieval (DR) by directly
generating identifiers of relevant documents. In this paper, we theoretically
and empirically investigate how GR fundamentally diverges from DR in both
learning objectives and representational capacity. GR performs globally
normalized maximum-likelihood optimization and encodes corpus and relevance
information directly in the model parameters, whereas DR adopts locally
normalized objectives and represents the corpus with external embeddings before
computing similarity via a bilinear interaction. Our analysis suggests that,
under scaling, GR can overcome the inherent limitations of DR, yielding two
major benefits. First, with larger corpora, GR avoids the sharp performance
degradation caused by the optimization drift induced by DR's local
normalization. Second, with larger models, GR's representational capacity
scales with parameter size, unconstrained by the global low-rank structure that
limits DR. We validate these theoretical insights through controlled
experiments on the Natural Questions and MS MARCO datasets, across varying
negative sampling strategies, embedding dimensions, and model scales. But
despite its theoretical advantages, GR does not universally outperform DR in
practice. We outline directions to bridge the gap between GR's theoretical
potential and practical performance, providing guidance for future research in
scalable and robust generative retrieval.

</details>


### [145] [Can Synthetic Query Rewrites Capture User Intent Better than Humans in Retrieval-Augmented Generation?](https://arxiv.org/abs/2509.22325)
*JiaYing Zheng,HaiNan Zhang,Liang Pang,YongXin Tong,ZhiMing Zheng*

Main category: cs.IR

TL;DR: 提出了SynRewrite，一个由合成数据驱动的查询重写模型，以生成与用户意图更一致的高质量合成重写。


<details>
  <summary>Details</summary>
Motivation: 传统查询重写依赖人工标注，但人工重写查询常偏离真实RAG系统所需，导致用户意图和系统响应之间存在差距。

Method: 利用GPT-4o生成高质量合成重写，并用Flan-T5模型进行微调，再通过DPO算法使用生成器的反馈来增强重写器。

Result: 在TopiOCQA和QRECC数据集上的实验表明，SynRewrite在检索和生成任务中始终优于人工重写。

Conclusion: 合成重写可以作为人工标注的可扩展且有效的替代方案。

Abstract: Multi-turn RAG systems often face queries with colloquial omissions and
ambiguous references, posing significant challenges for effective retrieval and
generation. Traditional query rewriting relies on human annotators to clarify
queries, but due to limitations in annotators' expressive ability and depth of
understanding, manually rewritten queries often diverge from those needed in
real-world RAG systems, resulting in a gap between user intent and system
response. We observe that high-quality synthetic queries can better bridge this
gap, achieving superior performance in both retrieval and generation compared
to human rewrites. This raises an interesting question: Can rewriting models
trained on synthetic queries better capture user intent than human annotators?
In this paper, we propose SynRewrite, a synthetic data-driven query rewriting
model to generate high-quality synthetic rewrites more aligned with user
intent. To construct training data, we prompt GPT-4o with dialogue history,
current queries, positive documents, and answers to synthesize high-quality
rewrites. A Flan-T5 model is then finetuned on this dataset to map dialogue
history and queries to synthetic rewrites. Finally, we further enhance the
rewriter using the generator's feedback through the DPO algorithm to boost
end-task performance. Experiments on TopiOCQA and QRECC datasets show that
SynRewrite consistently outperforms human rewrites in both retrieval and
generation tasks. Our results demonstrate that synthetic rewrites can serve as
a scalable and effective alternative to human annotations.

</details>


### [146] [Your RAG is Unfair: Exposing Fairness Vulnerabilities in Retrieval-Augmented Generation via Backdoor Attacks](https://arxiv.org/abs/2509.22486)
*Gaurav Bagwe,Saket S. Chaturvedi,Xiaolong Ma,Xiaoyong Yuan,Kuang-Ching Wang,Lan Zhang*

Main category: cs.IR

TL;DR: 这篇论文介绍了一种名为BiasRAG的框架，用于揭示RAG模型中的公平性漏洞，通过两阶段后门攻击实现。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在RAG模型中的虚假信息威胁，而对公平性漏洞的探索不足。与依赖直接触发-目标映射的传统后门不同，公平性驱动的攻击利用检索和生成模型之间的交互，操纵目标群体和社会偏见之间的语义关系，从而对内容生成产生持久和隐蔽的影响。

Method: 该论文提出了BiasRAG框架，它通过两阶段后门攻击来暴露RAG中的公平性漏洞。在预训练阶段，查询编码器受到攻击，以使目标群体与预期的社会偏见对齐，从而确保长期持久性。在部署后阶段，对抗性文档被注入到知识库中，以加强后门，巧妙地影响检索到的内容，同时在标准公平性评估下保持无法检测。

Result: 实验评估表明，BiasRAG实现了高攻击成功率，同时保持了上下文相关性和效用，从而对RAG中的公平性构成了持久且不断演变的威胁。

Conclusion: BiasRAG 框架能够确保精确的目标对齐、隐蔽的执行和弹性，从而对 RAG 模型的公平性构成持续威胁。

Abstract: Retrieval-augmented generation (RAG) enhances factual grounding by
integrating retrieval mechanisms with generative models but introduces new
attack surfaces, particularly through backdoor attacks. While prior research
has largely focused on disinformation threats, fairness vulnerabilities remain
underexplored. Unlike conventional backdoors that rely on direct
trigger-to-target mappings, fairness-driven attacks exploit the interaction
between retrieval and generation models, manipulating semantic relationships
between target groups and social biases to establish a persistent and covert
influence on content generation.
  This paper introduces BiasRAG, a systematic framework that exposes fairness
vulnerabilities in RAG through a two-phase backdoor attack. During the
pre-training phase, the query encoder is compromised to align the target group
with the intended social bias, ensuring long-term persistence. In the
post-deployment phase, adversarial documents are injected into knowledge bases
to reinforce the backdoor, subtly influencing retrieved content while remaining
undetectable under standard fairness evaluations. Together, BiasRAG ensures
precise target alignment over sensitive attributes, stealthy execution, and
resilience. Empirical evaluations demonstrate that BiasRAG achieves high attack
success rates while preserving contextual relevance and utility, establishing a
persistent and evolving threat to fairness in RAG.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [147] [Discovering and Analyzing Stochastic Processes to Reduce Waste in Food Retail](https://arxiv.org/abs/2509.21322)
*Anna Kalenkova,Lu Xia,Dirk Neumann*

Main category: cs.LG

TL;DR: 本文提出了一种新的方法，通过结合面向对象的流程挖掘（OCPM）与随机过程发现和分析，来分析食品零售过程，重点是减少食物浪费。


<details>
  <summary>Details</summary>
Motivation: 研究动机是减少食品浪费，并优化食品零售过程中的库存管理。

Method: 该方法首先从食品杂货店的销售数据中发现一个连续时间马尔可夫链形式的随机过程，然后用供应活动扩展该模型。最后，进行假设分析，以评估商店中产品的数量随时间的变化。

Result: 通过这种方法，能够识别客户购买行为和供应策略之间的最佳平衡点。

Conclusion: 该方法有助于防止因供应过剩和产品短缺造成的食物浪费。

Abstract: This paper proposes a novel method for analyzing food retail processes with a
focus on reducing food waste. The approach integrates object-centric process
mining (OCPM) with stochastic process discovery and analysis. First, a
stochastic process in the form of a continuous-time Markov chain is discovered
from grocery store sales data. This model is then extended with supply
activities. Finally, a what-if analysis is conducted to evaluate how the
quantity of products in the store evolves over time. This enables the
identification of an optimal balance between customer purchasing behavior and
supply strategies, helping to prevent both food waste due to oversupply and
product shortages.

</details>


### [148] [Impact of Loss Weight and Model Complexity on Physics-Informed Neural Networks for Computational Fluid Dynamics](https://arxiv.org/abs/2509.21393)
*Yi En Chou,Te Hsin Liu,Chao An Lin*

Main category: cs.LG

TL;DR: PINNs are sensitive to loss weights. This paper introduces two weighting schemes for more balanced training.


<details>
  <summary>Details</summary>
Motivation: PINNs, a mesh-free framework for solving PDEs, are highly sensitive to loss weight selection.

Method: Two weighting schemes are proposed: one based on quantifiable terms, and another incorporating unquantifiable terms.

Result: The second scheme improves stability and accuracy over equal weighting. Achieved stable, accurate predictions in high Peclet number convection diffusion.

Conclusion: The proposed scheme enhances robustness and generalizability of PINNs in CFD problems.

Abstract: Physics Informed Neural Networks offer a mesh free framework for solving PDEs
but are highly sensitive to loss weight selection. We propose two dimensional
analysis based weighting schemes, one based on quantifiable terms, and another
also incorporating unquantifiable terms for more balanced training. Benchmarks
on heat conduction, convection diffusion, and lid driven cavity flows show that
the second scheme consistently improves stability and accuracy over equal
weighting. Notably, in high Peclet number convection diffusion, where
traditional solvers fail, PINNs with our scheme achieve stable, accurate
predictions, highlighting their robustness and generalizability in CFD
problems.

</details>


### [149] [LLMs for Bayesian Optimization in Scientific Domains: Are We There Yet?](https://arxiv.org/abs/2509.21403)
*Rushil Gupta,Jason Hartford,Bang Liu*

Main category: cs.LG

TL;DR: 大型语言模型（LLM）在实验设计中被认为具有通用性，但评估表明它们对实验反馈不敏感，表现不如传统方法。提出了一种混合方法LLMNN，它结合了LLM先验知识和最近邻采样，取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）是否能像通用代理一样进行实验设计。

Method: 使用开放和封闭源指令调整的LLM，应用于遗传扰动和分子性质发现任务。同时，提出了LLM引导的最近邻（LLMNN）抽样方法。

Result: LLM对实验反馈没有敏感性，传统方法优于LLM。LLMNN在多个领域表现出竞争力或更优越的性能，且不需要显著的上下文适应。

Conclusion: 目前的LLM在实践中无法进行上下文实验设计，需要混合框架将基于先验的推理与批量采集分离。

Abstract: Large language models (LLMs) have recently been proposed as general-purpose
agents for experimental design, with claims that they can perform in-context
experimental design. We evaluate this hypothesis using both open- and
closed-source instruction-tuned LLMs applied to genetic perturbation and
molecular property discovery tasks. We find that LLM-based agents show no
sensitivity to experimental feedback: replacing true outcomes with randomly
permuted labels has no impact on performance. Across benchmarks, classical
methods such as linear bandits and Gaussian process optimization consistently
outperform LLM agents. We further propose a simple hybrid method, LLM-guided
Nearest Neighbour (LLMNN) sampling, that combines LLM prior knowledge with
nearest-neighbor sampling to guide the design of experiments. LLMNN achieves
competitive or superior performance across domains without requiring
significant in-context adaptation. These results suggest that current open- and
closed-source LLMs do not perform in-context experimental design in practice
and highlight the need for hybrid frameworks that decouple prior-based
reasoning from batch acquisition with updated posteriors.

</details>


### [150] [Object Identification Under Known Dynamics: A PIRNN Approach for UAV Classification](https://arxiv.org/abs/2509.21405)
*Nyi Nyi Aung,Neil Muralles,Adrian Stein*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息的残差神经网络，用于无人机应用中已知动力学下的物体识别。


<details>
  <summary>Details</summary>
Motivation: 在无人机应用中，结合学习和分类来实现物体识别。

Method: 该框架利用物理信息学习进行状态映射和状态导数预测，同时使用softmax层实现多类置信度估计。考虑四旋翼、固定翼和直升机无人机作为案例研究。

Result: 结果表明，该方法具有较高的分类精度和较短的训练时间。

Conclusion: 该方法为底层动力学 хорошо известны 的领域中的系统识别问题提供了一个有希望的解决方案。

Abstract: This work addresses object identification under known dynamics in unmanned
aerial vehicle applications, where learning and classification are combined
through a physics-informed residual neural network. The proposed framework
leverages physics-informed learning for state mapping and state-derivative
prediction, while a softmax layer enables multi-class confidence estimation.
Quadcopter, fixed-wing, and helicopter aerial vehicles are considered as case
studies. The results demonstrate high classification accuracy with reduced
training time, offering a promising solution for system identification problems
in domains where the underlying dynamics are well understood.

</details>


### [151] [Null-Space Filtering for Data-Free Continual Model Merging: Preserving Transparency, Promoting Fidelity](https://arxiv.org/abs/2509.21413)
*Zihuan Qiu,Lei Wang,Yang Cao,Runtong Zhang,Bing Su,Yi Xu,Fanman Meng,Linfeng Xu,Qingbo Wu,Hongliang Li*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为NUFILT的data-free continual model merging (DFCMM)框架，用于将独立微调的模型融合到单个主干中，使其能够随着传入的任务演变，而无需访问任务数据。


<details>
  <summary>Details</summary>
Motivation: 现有的DFCMM方法无法在缺乏任务数据的情况下，将数据层面的需求与参数空间优化联系起来，以确保透明性和保真度。本文旨在解决如何在没有任务数据的情况下，保证模型融合的透明性和保真度。

Method: 本文提出NUFILT框架，该框架通过设计一个零空间投影器来保留先前的响应，并通过轻量级的LoRA适配器来注入互补的特定于任务的信号。适配器使用基于投影的代理损失进行训练，以保持与先前知识的一致性，同时引入新的方向。

Result: NUFILT在视觉和NLP基准测试中实现了最先进的性能，并且遗忘最少，平均准确率比OPCM和WUDI-Merging提高了4-7%。

Conclusion: 本文提出的联合过滤-适应过程允许主干吸收新的知识，同时保留现有的行为，并且更新以分层线性方式融合回主干，而无需额外的参数或推理成本。

Abstract: Data-free continual model merging (DFCMM) aims to fuse independently
fine-tuned models into a single backbone that evolves with incoming tasks
without accessing task data. This paper formulate two fundamental desiderata
for DFCMM: transparency, avoiding interference with earlier tasks, and
fidelity, adapting faithfully to each new task. This poses a challenge that
existing approaches fail to address: how to bridge data-level desiderata with
parameter-space optimization to ensure transparency and fidelity in the absence
of task data. To this end, we propose NUFILT (NUll-space FILTering), a
data-free framework that directly links these desiderata to optimization. Our
key observation is that task vectors approximately align with representation
subspaces, providing structural surrogates for enforcing transparency and
fidelity. Accordingly, we design a null-space projector that preserves prior
responses by filtering out overlapping components of new task vectors, thereby
ensuring transparency, and a lightweight LoRA adapter that injects
complementary task-specific signals, enabling fidelity in adapting to new
tasks. The adapter is trained with a projection-based surrogate loss to retain
consistency with previous knowledge while introducing novel directions. This
joint filtering-adaptation process allows the backbone to absorb new knowledge
while retaining existing behaviors, and the updates are finally fused back in a
layer-wise linear fashion without extra parameters or inference cost.
Theoretically, we establish approximate subspace alignment guarantees that
justify null-space filtering. Empirically, NUFILT achieves state-of-the-art
performance with minimal forgetting on both vision and NLP benchmarks,
improving average accuracy by 4-7% over OPCM and WUDI-Merging, while narrowing
the gap to fine-tuning and reducing computation overhead.

</details>


### [152] [Forecasting Seismic Waveforms: A Deep Learning Approach for Einstein Telescope](https://arxiv.org/abs/2509.21446)
*Waleed Esmail,Alexander Kappes,Stuart Russell,Christine Thomas*

Main category: cs.LG

TL;DR: SeismoGPT: A transformer model for forecasting seismic waveforms for future gravitational wave detectors.


<details>
  <summary>Details</summary>
Motivation: Support Newtonian noise mitigation and real-time observatory control.

Method: Transformer-based model trained in an autoregressive setting to learn temporal and spatial dependencies from waveform data.

Result: Accurate short-term forecasts, with performance degrading further ahead as expected in autoregressive systems.

Conclusion: Lays the groundwork for data-driven seismic forecasting.

Abstract: We introduce \textit{SeismoGPT}, a transformer-based model for forecasting
three-component seismic waveforms in the context of future gravitational wave
detectors like the Einstein Telescope. The model is trained in an
autoregressive setting and can operate on both single-station and array-based
inputs. By learning temporal and spatial dependencies directly from waveform
data, SeismoGPT captures realistic ground motion patterns and provides accurate
short-term forecasts. Our results show that the model performs well within the
immediate prediction window and gradually degrades further ahead, as expected
in autoregressive systems. This approach lays the groundwork for data-driven
seismic forecasting that could support Newtonian noise mitigation and real-time
observatory control.

</details>


### [153] [Talking Trees: Reasoning-Assisted Induction of Decision Trees for Tabular Data](https://arxiv.org/abs/2509.21465)
*George Yakushev,Alina Shutova,Ivan Rubachev,Renat Sergazinov,Artem Babenko*

Main category: cs.LG

TL;DR: 本文提出了一种使用具有推理能力的LLM来归纳决策树的方法，以解决低资源表格数据问题。


<details>
  <summary>Details</summary>
Motivation: 现有的表格基础模型虽然性能优越，但存在难以解释和推理成本高的问题。

Method: 设计了一套最小的工具集，用于构建、分析和操作决策树，使LLM能够结合先验知识和数据学习来创建轻量级决策树。

Result: 实验结果表明，该方法在低资源表格数据问题上优于传统CART算法，并且具有人可读的推理过程，可以检查偏差和数据泄露。

Conclusion: 该方法允许人工干预，纠正偏差或整合领域知识，为解决低资源表格数据问题提供了一种可解释的替代方案。

Abstract: Tabular foundation models are becoming increasingly popular for low-resource
tabular problems. These models make up for small training datasets by
pretraining on large volumes of synthetic data. The prior knowledge obtained
via pretraining provides the exceptional performance, but the resulting model
becomes a black box that is difficult to interpret and costly to inference. In
this work, we explore an alternative strategy: using reasoning-capable LLMs to
induce decision trees for small tabular datasets in agentic setup. We design a
minimal set of tools for constructing, analyzing and manipulating decision
trees. By using these tools, LLMs combine their prior knowledge with learning
from data to create a lightweight decision tree that outperforms traditional
CART on low-resource tabular problems. While a single decision tree does not
outperform state-of-the-art black box models, it comes with a human-readable
reasoning trace that can be checked for biases and data leaks. Furthermore, the
reasoning-based LLM's creation process allows for additional human input:
correcting biases or incorporating domain-specific intuition that is not
captured in the data.

</details>


### [154] [Score-based Idempotent Distillation of Diffusion Models](https://arxiv.org/abs/2509.21470)
*Shehtab Zaman,Chengyan Liu,Kenneth Chiu*

Main category: cs.LG

TL;DR: 提出了一种新的生成模型，称为SIGN，它结合了扩散模型和IGNs的优点，实现了稳定训练和高效推理。


<details>
  <summary>Details</summary>
Motivation: 传统的IGNs训练不稳定且容易出现模式崩溃，而扩散模型计算成本高昂。因此，需要一种既稳定又高效的生成模型。

Method: 通过从扩散模型的分数中提炼出idempotent模型，实现了一种新的生成模型SIGN。

Result: SIGN在多个图像数据集上取得了state-of-the-art的结果，尤其在CIFAR和CelebA数据集上。

Conclusion: SIGN模型具有稳定、高效和支持多步采样的优点，可以在质量和效率之间进行权衡。此外，SIGN可以直接在源域上操作，实现对输入的zero-shot编辑。

Abstract: Idempotent generative networks (IGNs) are a new line of generative models
based on idempotent mapping to a target manifold. IGNs support both single-and
multi-step generation, allowing for a flexible trade-off between computational
cost and sample quality. But similar to Generative Adversarial Networks (GANs),
conventional IGNs require adversarial training and are prone to training
instabilities and mode collapse. Diffusion and score-based models are popular
approaches to generative modeling that iteratively transport samples from one
distribution, usually a Gaussian, to a target data distribution. These models
have gained popularity due to their stable training dynamics and high-fidelity
generation quality. However, this stability and quality come at the cost of
high computational cost, as the data must be transported incrementally along
the entire trajectory. New sampling methods, model distillation, and
consistency models have been developed to reduce the sampling cost and even
perform one-shot sampling from diffusion models. In this work, we unite
diffusion and IGNs by distilling idempotent models from diffusion model scores,
called SIGN. Our proposed method is highly stable and does not require
adversarial losses. We provide a theoretical analysis of our proposed
score-based training methods and empirically show that IGNs can be effectively
distilled from a pre-trained diffusion model, enabling faster inference than
iterative score-based models. SIGNs can perform multi-step sampling, allowing
users to trade off quality for efficiency. These models operate directly on the
source domain; they can project corrupted or alternate distributions back onto
the target manifold, enabling zero-shot editing of inputs. We validate our
models on multiple image datasets, achieving state-of-the-art results for
idempotent models on the CIFAR and CelebA datasets.

</details>


### [155] [Are Hallucinations Bad Estimations?](https://arxiv.org/abs/2509.21473)
*Hude Liu,Jerry Yao-Chieh Hu,Jennifer Yuntong Zhang,Zhao Song,Han Liu*

Main category: cs.LG

TL;DR: 将生成模型中的幻觉形式化为未能将估计与任何可能的成因联系起来的失败


<details>
  <summary>Details</summary>
Motivation: 即使是损失最小化的最优估计器仍然会出现幻觉

Method: 通过对通用数据分布的幻觉率的一般高概率下界来确认这一点

Result: 将幻觉重新定义为损失最小化与人类可接受的输出之间的结构错位，以及由错误校准引起的估计误差

Conclusion: 在硬币聚合、开放式问答和文本到图像上的实验支持了我们的理论

Abstract: We formalize hallucinations in generative models as failures to link an
estimate to any plausible cause. Under this interpretation, we show that even
loss-minimizing optimal estimators still hallucinate. We confirm this with a
general high probability lower bound on hallucinate rate for generic data
distributions. This reframes hallucination as structural misalignment between
loss minimization and human-acceptable outputs, and hence estimation errors
induced by miscalibration. Experiments on coin aggregation, open-ended QA, and
text-to-image support our theory.

</details>


### [156] [d2: Improved Techniques for Training Reasoning Diffusion Language Models](https://arxiv.org/abs/2509.21474)
*Guanghan Wang,Yair Schiff,Gilad Turok,Volodymyr Kuleshov*

Main category: cs.LG

TL;DR: 提出了一种名为d2的、专为掩码扩散语言模型设计的推理框架。


<details>
  <summary>Details</summary>
Motivation: 利用强化学习提高扩散语言模型在文本生成方面的推理能力是一个活跃的研究领域。

Method: 一种新的策略梯度算法，它依赖于掩码的属性来准确估计采样轨迹的可能性。该算法在计算和近似精度之间进行权衡。

Result: d2 显著优于以前仅使用强化学习的扩散推理框架，并在逻辑推理任务（Countdown 和 Sudoku）和数学推理基准（GSM8K 和 MATH500）上为 DLM 建立了新的最先进的性能。

Conclusion: 该框架特别适用于支持任意阶似然估计的 DLM，并且对于基于扩散的有效推理至关重要。

Abstract: While diffusion language models (DLMs) have achieved competitive performance
in text generation, improving their reasoning ability with reinforcement
learning remains an active research area. Here, we introduce d2, a reasoning
framework tailored for masked DLMs. Central to our framework is a new policy
gradient algorithm that relies on properties of masking to accurately estimate
the likelihoods of sampling trajectories. Our estimators trade off computation
for approximation accuracy in an analytically tractable manner, and are
particularly effective for DLMs that support any-order likelihood estimation.
We characterize and study this property in popular DLMs and show that it is key
for efficient diffusion-based reasoning. Empirically, d2 significantly improves
over previous diffusion reasoning frameworks using only RL (without relying on
supervised fine-tuning), and sets a new state-of-the-art performance for DLMs
on logical reasoning tasks (Countdown and Sudoku) and math reasoning benchmarks
(GSM8K and MATH500).

</details>


### [157] [VISION: Prompting Ocean Vertical Velocity Reconstruction from Incomplete Observations](https://arxiv.org/abs/2509.21477)
*Yuan Gao,Hao Wu,Qingsong Wen,Kun Wang,Xian Wu,Xiaomeng Huang*

Main category: cs.LG

TL;DR: 本研究构建并发布了一个高分辨率的海洋动力学基准KD48，并提出了一个名为VISION的新型重建范例，该范例基于动态提示，旨在解决真实观测中数据缺失的核心问题。VISION在KD48基准上表现出色，并在极端数据缺失情况下表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 从不完整的表面观测重建地下海洋动力学（如垂直速度场）是地球科学中的一项关键挑战，该领域长期以来一直受到缺乏标准化、可用于分析的基准的阻碍。

Method: 该研究引入了一种基于动态提示的新型重建范例VISION，它可以根据任何可用的观测子集生成一个动态视觉提示，并设计了一个状态条件提示模块，将该提示注入到一个具有几何和尺度感知算子的通用骨干网络中，以指导其自适应调整计算策略。

Result: 在KD48基准上的大量实验表明，VISION不仅大大优于最先进的模型，而且在极端数据缺失情况下表现出强大的泛化能力。

Conclusion: 该研究通过提供高质量的基准和强大的模型，为数据不确定性下的海洋科学研究建立了坚实的基础设施。

Abstract: Reconstructing subsurface ocean dynamics, such as vertical velocity fields,
from incomplete surface observations poses a critical challenge in Earth
science, a field long hampered by the lack of standardized, analysis-ready
benchmarks. To systematically address this issue and catalyze research, we
first build and release KD48, a high-resolution ocean dynamics benchmark
derived from petascale simulations and curated with expert-driven denoising.
Building on this benchmark, we introduce VISION, a novel reconstruction
paradigm based on Dynamic Prompting designed to tackle the core problem of
missing data in real-world observations. The essence of VISION lies in its
ability to generate a visual prompt on-the-fly from any available subset of
observations, which encodes both data availability and the ocean's physical
state. More importantly, we design a State-conditioned Prompting module that
efficiently injects this prompt into a universal backbone, endowed with
geometry- and scale-aware operators, to guide its adaptive adjustment of
computational strategies. This mechanism enables VISION to precisely handle the
challenges posed by varying input combinations. Extensive experiments on the
KD48 benchmark demonstrate that VISION not only substantially outperforms
state-of-the-art models but also exhibits strong generalization under extreme
data missing scenarios. By providing a high-quality benchmark and a robust
model, our work establishes a solid infrastructure for ocean science research
under data uncertainty. Our codes are available at:
https://github.com/YuanGao-YG/VISION.

</details>


### [158] [Filtering with Confidence: When Data Augmentation Meets Conformal Prediction](https://arxiv.org/abs/2509.21479)
*Zixuan Wu,So Won Jeong,Yating Liu,Yeo Jin Jung,Claire Donnat*

Main category: cs.LG

TL;DR: 本文提出了一种名为一致数据增强的框架，用于过滤低质量的合成数据，同时保证风险可控。


<details>
  <summary>Details</summary>
Motivation: 合成数据增强可以有效解决数据稀缺问题，但其有效性取决于控制偏差。有效的数据增强应从与训练集相同的潜在分布生成不同的样本，并尽量减少偏移。

Method: 本文提出了一种一致数据增强方法，该方法利用一致预测的能力来生成不同的合成数据，同时过滤掉质量差的生成数据。

Result: 在主题预测、情感分析、图像分类和欺诈检测等多个任务中，本文的方法在F1得分上比未增强的基线提高了高达40%，比其他过滤增强基线提高了4%。

Conclusion: 本文提出的一致数据增强方法简单易行，无需访问内部模型logits，也无需大规模模型再训练，即可在多个任务中实现一致的性能提升。

Abstract: With promising empirical performance across a wide range of applications,
synthetic data augmentation appears a viable solution to data scarcity and the
demands of increasingly data-intensive models. Its effectiveness lies in
expanding the training set in a way that reduces estimator variance while
introducing only minimal bias. Controlling this bias is therefore critical:
effective data augmentation should generate diverse samples from the same
underlying distribution as the training set, with minimal shifts. In this
paper, we propose conformal data augmentation, a principled data filtering
framework that leverages the power of conformal prediction to produce diverse
synthetic data while filtering out poor-quality generations with provable risk
control. Our method is simple to implement, requires no access to internal
model logits, nor large-scale model retraining. We demonstrate the
effectiveness of our approach across multiple tasks, including topic
prediction, sentiment analysis, image classification, and fraud detection,
showing consistent performance improvements of up to 40% in F1 score over
unaugmented baselines, and 4% over other filtered augmentation baselines.

</details>


### [159] [High-Probability Analysis of Online and Federated Zero-Order Optimisation](https://arxiv.org/abs/2509.21484)
*Arya Akhavan,David Janz,El-Mahdi El-Mhamdi*

Main category: cs.LG

TL;DR: 提出了联邦零阶优化算法FedZero，具有很强的理论保证。


<details>
  <summary>Details</summary>
Motivation: 研究梯度自由零阶优化中的分布式学习。

Method: FedZero采用基于$\\ell_1$-球面随机化的梯度估计器。

Result: FedZero在联邦凸设置中实现了接近最优的优化误差界限，并在单worker机制中建立了凸零阶优化的高概率收敛保证。

Conclusion: 开发了在$\\ell_1$-球面上均匀测度下Lipschitz函数的新集中不等式，可能具有独立的意义。

Abstract: We study distributed learning in the setting of gradient-free zero-order
optimization and introduce FedZero, a federated zero-order algorithm that
delivers sharp theoretical guarantees. Specifically, FedZero: (1) achieves
near-optimal optimization error bounds with high probability in the federated
convex setting; and (2) in the single-worker regime-where the problem reduces
to the standard zero-order framework, establishes the first high-probability
convergence guarantees for convex zero-order optimization, thereby
strengthening the classical expectation-based results. At its core, FedZero
employs a gradient estimator based on randomization over the $\ell_1$-sphere.
To analyze it, we develop new concentration inequalities for Lipschitz
functions under the uniform measure on the $\ell_1$-sphere, with explicit
constants. These concentration tools are not only central to our
high-probability guarantees but may also be of independent interest.

</details>


### [160] [Neural Operators for Mathematical Modeling of Transient Fluid Flow in Subsurface Reservoir Systems](https://arxiv.org/abs/2509.21485)
*Daniil D. Sirota,Sergey A. Khan,Sergey L. Kostikov,Kirill A. Butov*

Main category: cs.LG

TL;DR: 本文提出了一种基于神经算子架构（TFNO-opt）的地下储层系统中瞬态流体建模方法，该方法通过傅里叶神经算子在无限维函数空间中逼近PDE解，具有离散不变性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统数值方法虽然精度高，但计算耗时，限制了其在控制和决策支持问题中的应用。TFNO-opt旨在加速计算并提高控制效果。

Method: 该架构基于傅里叶神经算子，并进行了一系列改进，包括可调节的内部时间分辨率、谱域中参数的张量分解、在误差函数中使用Sobolev范数，以及分离近似误差和重建初始条件。

Result: 计算实验证实了所提出改进的有效性，与传统方法相比，计算速度提高了六个数量级。

Conclusion: 该方法为复杂储层系统的有效控制开辟了新的机会，并通过地下储气库的水动力建模问题验证了其应用前景。

Abstract: This paper presents a method for modeling transient fluid flow in subsurface
reservoir systems based on the developed neural operator architecture
(TFNO-opt). Reservoir systems are complex dynamic objects with distributed
parameters described by systems of partial differential equations (PDEs).
Traditional numerical methods for modeling such systems, despite their high
accuracy, are characterized by significant time costs for performing
calculations, which limits their applicability in control and decision support
problems. The proposed architecture (TFNO-opt) is based on Fourier neural
operators, which allow approximating PDE solutions in infinite-dimensional
functional spaces, providing invariance to discretization and the possibility
of generalization to various implementations of equations. The developed
modifications are aimed at increasing the accuracy and stability of the trained
neural operator, which is especially important for control problems. These
include adjustable internal time resolution of the integral Fourier operator,
tensor decomposition of parameters in the spectral domain, use of the Sobolev
norm in the error function, and separation of approximation errors and
reconstruction of initial conditions for more accurate reproduction of physical
processes. The effectiveness of the proposed improvements is confirmed by
computational experiments. The practical significance is confirmed by
computational experiments using the example of the problem of hydrodynamic
modeling of an underground gas storage (UGS), where the acceleration of
calculations by six orders of magnitude was achieved, compared to traditional
methods. This opens up new opportunities for the effective control of complex
reservoir systems.

</details>


### [161] [GraphPFN: A Prior-Data Fitted Graph Foundation Model](https://arxiv.org/abs/2509.21489)
*Dmitry Eremeev,Oleg Platonov,Gleb Bazhenov,Artem Babenko,Liudmila Prokhorenkova*

Main category: cs.LG

TL;DR: GraphPFN: a prior-data fitted network for node-level prediction


<details>
  <summary>Details</summary>
Motivation: Existing graph foundation models rely on hand-crafted graph features, limiting their ability to learn complex graph-specific patterns.

Method: design a prior distribution of synthetic attributed graphs and augment the tabular foundation model LimiX with attention-based graph neighborhood aggregation layers and train it on synthetic graphs sampled from our prior

Result: GraphPFN shows strong in-context learning performance and achieves state-of-the-art results after finetuning

Conclusion: pretraining on synthetic graphs from a well-designed prior distribution is an effective strategy for building graph foundation models.

Abstract: Foundation models pretrained on large-scale datasets have transformed such
fields as natural language processing and computer vision, but their
application to graph data remains limited. Recently emerged graph foundation
models, such as G2T-FM, utilize tabular foundation models for graph tasks and
were shown to significantly outperform prior attempts to create GFMs. However,
these models primarily rely on hand-crafted graph features, limiting their
ability to learn complex graph-specific patterns. In this work, we propose
GraphPFN: a prior-data fitted network for node-level prediction. First, we
design a prior distribution of synthetic attributed graphs. For graph structure
generation, we use a novel combination of multiple stochastic block models and
a preferential attachment process. We then apply graph-aware structured causal
models to generate node attributes and targets. This procedure allows us to
efficiently generate a wide range of realistic graph datasets. Then, we augment
the tabular foundation model LimiX with attention-based graph neighborhood
aggregation layers and train it on synthetic graphs sampled from our prior,
allowing the model to capture graph structural dependencies not present in
tabular data. On diverse real-world graph datasets with up to 50,000 nodes,
GraphPFN shows strong in-context learning performance and achieves
state-of-the-art results after finetuning, outperforming both G2T-FM and
task-specific GNNs trained from scratch on most datasets. More broadly, our
work demonstrates that pretraining on synthetic graphs from a well-designed
prior distribution is an effective strategy for building graph foundation
models.

</details>


### [162] [SlimDiff: Training-Free, Activation-Guided Hands-free Slimming of Diffusion Models](https://arxiv.org/abs/2509.21498)
*Arani Roy,Shristi Das Biswas,Kaushik Roy*

Main category: cs.LG

TL;DR: SlimDiff是一种无需训练的激活感知结构压缩框架，用于减少扩散模型中的参数和计算量。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型压缩方法依赖于微调或重新训练来恢复性能，计算成本高昂。

Method: SlimDiff将DM压缩转化为谱近似任务，通过激活协方差定义低秩子空间，指导固定压缩预算下的动态剪枝。

Result: SlimDiff实现了高达35%的加速和约1亿的参数减少，生成质量与未压缩模型相当，且无需反向传播。

Conclusion: SlimDiff是第一个完全免训练的激活引导的DM结构压缩方法，提供了理论清晰性和实际效率。

Abstract: Diffusion models (DMs), lauded for their generative performance, are
computationally prohibitive due to their billion-scale parameters and iterative
denoising dynamics. Existing efficiency techniques, such as quantization,
timestep reduction, or pruning, offer savings in compute, memory, or runtime
but are strictly bottlenecked by reliance on fine-tuning or retraining to
recover performance. In this work, we introduce SlimDiff, an automated
activation-informed structural compression framework that reduces both
attention and feedforward dimensionalities in DMs, while being entirely
gradient-free. SlimDiff reframes DM compression as a spectral approximation
task, where activation covariances across denoising timesteps define low-rank
subspaces that guide dynamic pruning under a fixed compression budget. This
activation-aware formulation mitigates error accumulation across timesteps by
applying module-wise decompositions over functional weight groups: query--key
interactions, value--output couplings, and feedforward projections, rather than
isolated matrix factorizations, while adaptively allocating sparsity across
modules to respect the non-uniform geometry of diffusion trajectories. SlimDiff
achieves up to 35\% acceleration and $\sim$100M parameter reduction over
baselines, with generation quality on par with uncompressed models without any
backpropagation. Crucially, our approach requires only about 500 calibration
samples, over 70$\times$ fewer than prior methods. To our knowledge, this is
the first closed-form, activation-guided structural compression of DMs that is
entirely training-free, providing both theoretical clarity and practical
efficiency.

</details>


### [163] [Chasing the Tail: Effective Rubric-based Reward Modeling for Large Language Model Post-Training](https://arxiv.org/abs/2509.21500)
*Junkai Zhang,Zihao Wang,Lin Gui,Swarnashree Mysore Sathyendra,Jaehwan Jeong,Victor Veitch,Wei Wang,Yunzhong He,Bing Liu,Lifeng Jin*

Main category: cs.LG

TL;DR: 强化微调（RFT）经常受到奖励过度优化的问题的影响，即策略模型通过攻击奖励信号来获得高分，同时产生低质量的输出。


<details>
  <summary>Details</summary>
Motivation: 研究表明，关键在于高奖励尾部的奖励错误指定：无法可靠地区分优秀响应和仅仅是好的响应。这促使我们专注于高奖励区域。

Method: 我们研究了基于规则的奖励。通过设计，规则可以利用非策略示例，同时对它们的伪影不敏感。为了引出能够捕捉高奖励尾部的规则，我们强调了区分优秀和多样化响应的重要性，并引入了一个工作流程来实现这个想法。

Result: 经验表明，基于规则的奖励大大减轻了奖励过度优化，并提供了有效的LLM后训练改进。

Conclusion: 基于规则的奖励可以有效缓解奖励过度优化，并实现LLM的有效改进。

Abstract: Reinforcement fine-tuning (RFT) often suffers from \emph{reward
over-optimization}, where a policy model hacks the reward signals to achieve
high scores while producing low-quality outputs. Our theoretical analysis shows
that the key lies in reward misspecification at the high-reward tail: the
inability to reliably distinguish Excellent responses from merely Great ones.
This motivate us to focus on the high-reward region. However, such tail
examples are scarce under the base LLM. While off-policy exemplars (e.g. from
stronger models or rewrites) are easier to obtain, naively training on them
yields a misspecified reward for the policy we aim to align. To address this,
we study rubric-based rewards. By design, rubrics can leverage off-policy
examples while remaining insensitive to their artifacts. To elicit rubrics that
capture the high-reward tail, we highlight the importance of distinguishing
among great and diverse responses, and introduce a workflow to implement this
idea. We empirically demonstrate that rubric-based rewards substantially
mitigate reward over-optimization and deliver effective LLM post-training
improvements. Our code can be accessed at
https://github.com/Jun-Kai-Zhang/rubrics.git .

</details>


### [164] [Contrastive Mutual Information Learning: Toward Robust Representations without Positive-Pair Augmentations](https://arxiv.org/abs/2509.21511)
*Micha Livne*

Main category: cs.LG

TL;DR: 提出了对比互信息机 (cMIM)，这是一种概率框架，它使用对比目标扩展了互信息机 (MIM)。


<details>
  <summary>Details</summary>
Motivation: 学习能够很好地转移到各种下游任务的表征仍然是表征学习中的一个中心挑战。现有的范例——对比学习、自监督掩蔽和去噪自动编码器——以不同的权衡来平衡这一挑战。

Method: 提出了 cMIM，它是 MIM 的对比扩展，无需正数据增强，并且对批量大小的敏感度远低于 InfoNCE。引入了信息丰富的嵌入，这是一种从编码器-解码器模型中提取丰富特征的通用技术，可在不进行额外训练的情况下提高判别性能，并广泛应用于 MIM 之外。

Result: 在视觉和分子基准测试中提供的经验证据表明，cMIM 在分类和回归任务上优于 MIM 和 InfoNCE，同时保持了具有竞争力的重建质量。

Conclusion: 这些结果将 cMIM 定位为表示学习的统一框架，从而推进了有效服务于判别和生成应用程序的模型的 ​​目标。

Abstract: Learning representations that transfer well to diverse downstream tasks
remains a central challenge in representation learning. Existing paradigms --
contrastive learning, self-supervised masking, and denoising auto-encoders --
balance this challenge with different trade-offs. We introduce the {contrastive
Mutual Information Machine} (cMIM), a probabilistic framework that extends the
Mutual Information Machine (MIM) with a contrastive objective. While MIM
maximizes mutual information between inputs and latents and promotes clustering
of codes, it falls short on discriminative tasks. cMIM addresses this gap by
imposing global discriminative structure while retaining MIM's generative
fidelity. Our contributions are threefold. First, we propose cMIM, a
contrastive extension of MIM that removes the need for positive data
augmentation and is substantially less sensitive to batch size than InfoNCE.
Second, we introduce {informative embeddings}, a general technique for
extracting enriched features from encoder-decoder models that boosts
discriminative performance without additional training and applies broadly
beyond MIM. Third, we provide empirical evidence across vision and molecular
benchmarks showing that cMIM outperforms MIM and InfoNCE on classification and
regression tasks while preserving competitive reconstruction quality. These
results position cMIM as a unified framework for representation learning,
advancing the goal of models that serve both discriminative and generative
applications effectively.

</details>


### [165] [DistillKac: Few-Step Image Generation via Damped Wave Equations](https://arxiv.org/abs/2509.21513)
*Weiqiao Han,Chenlin Meng,Christopher D. Manning,Stefano Ermon*

Main category: cs.LG

TL;DR: DistillKac: a fast image generator using damped wave equation and stochastic Kac representation for finite speed probability mass movement.


<details>
  <summary>Details</summary>
Motivation: Diffusion models have unbounded propagation speed. Kac dynamics enforce finite speed transport and yield globally bounded kinetic energy.

Method: Introduce classifier-free guidance in velocity space and endpoint only distillation.

Result: DistillKac delivers high quality samples with very few function evaluations.

Conclusion: DistillKac retains the numerical stability benefits of finite speed probability flows.

Abstract: We present DistillKac, a fast image generator that uses the damped wave
equation and its stochastic Kac representation to move probability mass at
finite speed. In contrast to diffusion models whose reverse time velocities can
become stiff and implicitly allow unbounded propagation speed, Kac dynamics
enforce finite speed transport and yield globally bounded kinetic energy.
Building on this structure, we introduce classifier-free guidance in velocity
space that preserves square integrability under mild conditions. We then
propose endpoint only distillation that trains a student to match a frozen
teacher over long intervals. We prove a stability result that promotes
supervision at the endpoints to closeness along the entire path. Experiments
demonstrate DistillKac delivers high quality samples with very few function
evaluations while retaining the numerical stability benefits of finite speed
probability flows.

</details>


### [166] [Uncertainty-Aware Knowledge Tracing Models](https://arxiv.org/abs/2509.21514)
*Joshua Mitton,Prarthana Bhattacharyya,Ralph Abboud,Simon Woodhead*

Main category: cs.LG

TL;DR: 知识追踪模型的研究重点是模型开发，目的是提高预测准确性。我们提出了一种通过捕捉预测不确定性来为 KT 模型添加新功能的方法，并证明较大的预测不确定性与模型的不正确预测相一致。


<details>
  <summary>Details</summary>
Motivation: 大多数知识追踪模型在学生选择干扰因素时会做出最不正确的预测，从而导致学生错误未被发现。理解学生能力是必要的。

Method: 通过捕捉预测不确定性来为 KT 模型添加新功能

Result: 知识追踪模型中的不确定性是有信息的，并且该信号在教育学习平台中的应用在教学上是有用的

Conclusion: 知识追踪模型中的不确定性是有信息的，并且该信号在教育学习平台中的应用在教学上是有用的

Abstract: The main focus of research on Knowledge Tracing (KT) models is on model
developments with the aim of improving predictive accuracy. Most of these
models make the most incorrect predictions when students choose a distractor,
leading to student errors going undetected. We present an approach to add new
capabilities to KT models by capturing predictive uncertainty and demonstrate
that a larger predictive uncertainty aligns with model incorrect predictions.
We show that uncertainty in KT models is informative and that this signal would
be pedagogically useful for application in an educational learning platform
that can be used in a limited resource setting where understanding student
ability is necessary.

</details>


### [167] [$\mathbf{Li_2}$: A Framework on Dynamics of Feature Emergence and Delayed Generalization](https://arxiv.org/abs/2509.21519)
*Yuandong Tian*

Main category: cs.LG

TL;DR: 这篇论文提出了一个名为Li_2的新框架，用于捕捉2层非线性网络中grokking行为的三个关键阶段。


<details>
  <summary>Details</summary>
Motivation: 研究grokking现象，并探究是否存在一个数学框架来描述复杂结构化输入中出现的特征类型、方式和条件。

Method: 通过反向传播梯度GF的结构来表征grokking行为的三个阶段：惰性学习、独立特征学习和交互特征学习。

Result: 研究了局部最优诱导特征是否具有泛化性，其表示能力，以及它们如何在群运算任务中随样本大小变化。

Conclusion: 该研究阐明了权重衰减、学习率和样本大小等关键超参数在grokking中的作用，推导了记忆和泛化的可证明的缩放定律，并揭示了Muon等最新优化器有效的根本原因。

Abstract: While the phenomenon of grokking, i.e., delayed generalization, has been
studied extensively, it remains an open question whether there is a
mathematical framework to characterize what kind of features emerge, how and in
which conditions it happens from training, for complex structured inputs. We
propose a novel framework, named $\mathbf{Li_2}$, that captures three key
stages for the grokking behavior of 2-layer nonlinear networks: (I) Lazy
learning, (II) independent feature learning and (III) interactive feature
learning, characterized by the structure of backpropagated gradient $G_F$
across layers. In (I), $G_F$ is random, and top layer overfits to random hidden
representation. In (II), the gradient of each node (column of $G_F$) only
depends on its own activation, and thus each hidden node learns their
representation independently from $G_F$, which now carries information about
target labels, thanks to weight decay. Interestingly, the independent dynamics
follows exactly the gradient ascent of an energy function $E$, and its local
maxima are precisely the emerging features. We study whether these local-optima
induced features are generalizable, their representation power, and how they
change on sample size, in group arithmetic tasks. Finally, in (III), we
provably show how hidden nodes interact, and how $G_F$ changes to focus on
missing features that need to be learned. Our study sheds lights on roles
played by key hyperparameters such as weight decay, learning rate and sample
sizes in grokking, leads to provable scaling laws of memorization and
generalization, and reveals the underlying cause why recent optimizers such as
Muon can be effective, from the first principles of gradient dynamics. Our
analysis can be extended to multi-layer architectures.

</details>


### [168] [TRiCo: Triadic Game-Theoretic Co-Training for Robust Semi-Supervised Learning](https://arxiv.org/abs/2509.21526)
*Hongyang He,Xinyuan Song,Yangfan He,Zeyu Zhang,Yanshu Li,Haochen You,Lifan Sun,Wenqiao Zhang*

Main category: cs.LG

TL;DR: TRiCo: A novel triadic game-theoretic co-training framework for semi-supervised learning (SSL).


<details>
  <summary>Details</summary>
Motivation: Addresses limitations in existing SSL frameworks like static view interactions, unreliable pseudo-labels, and lack of hard sample modeling.

Method: Incorporates a teacher, two students, and an adversarial generator into a unified training paradigm. Uses mutual information for pseudo-label selection and formulates the interaction as a Stackelberg game.

Result: Achieves state-of-the-art performance in low-label regimes on CIFAR-10, SVHN, STL-10, and ImageNet.

Conclusion: TRiCo provides a principled and generalizable SSL solution that is architecture-agnostic and compatible with frozen vision backbones.

Abstract: We introduce TRiCo, a novel triadic game-theoretic co-training framework that
rethinks the structure of semi-supervised learning by incorporating a teacher,
two students, and an adversarial generator into a unified training paradigm.
Unlike existing co-training or teacher-student approaches, TRiCo formulates SSL
as a structured interaction among three roles: (i) two student classifiers
trained on frozen, complementary representations, (ii) a meta-learned teacher
that adaptively regulates pseudo-label selection and loss balancing via
validation-based feedback, and (iii) a non-parametric generator that perturbs
embeddings to uncover decision boundary weaknesses. Pseudo-labels are selected
based on mutual information rather than confidence, providing a more robust
measure of epistemic uncertainty. This triadic interaction is formalized as a
Stackelberg game, where the teacher leads strategy optimization and students
follow under adversarial perturbations. By addressing key limitations in
existing SSL frameworks, such as static view interactions, unreliable
pseudo-labels, and lack of hard sample modeling, TRiCo provides a principled
and generalizable solution. Extensive experiments on CIFAR-10, SVHN, STL-10,
and ImageNet demonstrate that TRiCo consistently achieves state-of-the-art
performance in low-label regimes, while remaining architecture-agnostic and
compatible with frozen vision backbones.

</details>


### [169] [Preemptive Detection and Steering of LLM Misalignment via Latent Reachability](https://arxiv.org/abs/2509.21528)
*Sathwik Karnik,Somil Bansal*

Main category: cs.LG

TL;DR: BRT-Align: A reachability-based framework for safe LLM inference, addressing the lack of inference-time safeguards in RLHF.


<details>
  <summary>Details</summary>
Motivation: The widespread use of LLMs raises safety concerns about harmful content generation, which RLHF doesn't fully address at inference time.

Method: Models autoregressive generation as a dynamical system, learns a safety value function via backward reachability, and uses a steering filter to redirect generation away from unsafe regions.

Result: BRT-Align detects unsafe continuations more accurately and earlier than baselines, reduces unsafe generations, and preserves diversity and coherence. It also produces less violent, profane, offensive, and politically biased responses.

Conclusion: Reachability analysis offers a practical foundation for inference-time LLM safety.

Abstract: Large language models (LLMs) are now ubiquitous in everyday tools, raising
urgent safety concerns about their tendency to generate harmful content. The
dominant safety approach -- reinforcement learning from human feedback (RLHF)
-- effectively shapes model behavior during training but offers no safeguards
at inference time, where unsafe continuations may still arise. We propose
BRT-Align, a reachability-based framework that brings control-theoretic safety
tools to LLM inference. BRT-Align models autoregressive generation as a
dynamical system in latent space and learn a safety value function via backward
reachability, estimating the worst-case evolution of a trajectory. This enables
two complementary mechanisms: (1) a runtime monitor that forecasts unsafe
completions several tokens in advance, and (2) a least-restrictive steering
filter that minimally perturbs latent states to redirect generation away from
unsafe regions. Experiments across multiple LLMs and toxicity benchmarks
demonstrate that BRT-Align provides more accurate and earlier detection of
unsafe continuations than baselines. Moreover, for LLM safety alignment,
BRT-Align substantially reduces unsafe generations while preserving sentence
diversity and coherence. Qualitative results further highlight emergent
alignment properties: BRT-Align consistently produces responses that are less
violent, less profane, less offensive, and less politically biased. Together,
these findings demonstrate that reachability analysis provides a principled and
practical foundation for inference-time LLM safety.

</details>


### [170] [Expert-guided Clinical Text Augmentation via Query-Based Model Collaboration](https://arxiv.org/abs/2509.21530)
*Dongkyu Cho,Miao Zhang,Rumi Chunara*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的基于查询的模型协作框架，该框架集成了专家级领域知识，以指导数据增强过程，从而在临床预测任务中提高模型安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健等高风险领域，使用大型语言模型 (LLM) 进行数据增强存在生成临床上不正确或误导性信息的风险。

Method: 该方法提出了一种新颖的基于查询的模型协作框架，该框架集成了专家级领域知识来指导增强过程，以保留关键的医疗信息。

Result: 在临床预测任务上的实验表明，该方法优于现有的 LLM 增强方法，并通过减少事实错误来提高安全性。

Conclusion: 该框架弥合了 LLM 增强潜力与专业领域安全要求之间的差距。

Abstract: Data augmentation is a widely used strategy to improve model robustness and
generalization by enriching training datasets with synthetic examples. While
large language models (LLMs) have demonstrated strong generative capabilities
for this purpose, their applications in high-stakes domains like healthcare
present unique challenges due to the risk of generating clinically incorrect or
misleading information. In this work, we propose a novel query-based model
collaboration framework that integrates expert-level domain knowledge to guide
the augmentation process to preserve critical medical information. Experiments
on clinical prediction tasks demonstrate that our lightweight
collaboration-based approach consistently outperforms existing LLM augmentation
methods while improving safety through reduced factual errors. This framework
addresses the gap between LLM augmentation potential and the safety
requirements of specialized domains.

</details>


### [171] [A circuit for predicting hierarchical structure in-context in Large Language Models](https://arxiv.org/abs/2509.21534)
*Tankred Saanum,Can Demircan,Samuel J. Gershman,Eric Schulz*

Main category: cs.LG

TL;DR: 该研究调查了大型语言模型（LLMs）如何在上下文中学习更复杂的重复模式，这些模式具有层次结构，类似于自然语言中的结构。研究发现，自适应归纳头能够通过学习上下文中需要关注的内容来进行预测，并且这些归纳头通过发现一组潜在的上下文来支持学习，从而确定不同的token转换关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在上下文学习方面表现出色，但目前尚不清楚它们是否能够支持具有层次结构的更复杂的重复模式的上下文学习。自然语言中充满了这样的情况，例如英语中的“the”通常在一个文本中引导多个名词。当预测哪个token会接替特定的“the”实例时，我们需要整合文本中进一步的上下文线索来预测正确的名词。如果归纳头以不依赖上下文的方式天真地关注“the”的所有过去后继token实例，它们就无法支持这种程度的上下文信息整合。

Method: 该研究设计了一个合成的上下文学习任务，其中token以层次依赖关系重复。然后，在这些token序列和自然语言类似物上评估了一系列LLM。研究人员寻找支持预测的自适应归纳头，并通过学习上下文中需要关注的内容来进行预测。接下来，研究调查了归纳头本身如何在上下文中学习。研究人员寻找证据表明，学习由发现一组潜在上下文的注意力头支持，从而确定不同的token转换关系。

Result: 研究发现自适应归纳头能够通过学习上下文中需要关注的内容来进行预测。此外，研究发现学习是由发现一组潜在上下文的注意力头支持的，这些注意力头确定了不同的token转换关系。

Conclusion: 该研究表明，大型语言模型具有可以学习的归纳头，并提供了一个完整的机制解释，说明大型语言模型如何在上下文中学习预测高阶重复模式。

Abstract: Large Language Models (LLMs) excel at in-context learning, the ability to use
information provided as context to improve prediction of future tokens.
Induction heads have been argued to play a crucial role for in-context learning
in Transformer Language Models. These attention heads make a token attend to
successors of past occurrences of the same token in the input. This basic
mechanism supports LLMs' ability to copy and predict repeating patterns.
However, it is unclear if this same mechanism can support in-context learning
of more complex repetitive patterns with hierarchical structure. Natural
language is teeming with such cases: The article "the" in English usually
prefaces multiple nouns in a text. When predicting which token succeeds a
particular instance of "the", we need to integrate further contextual cues from
the text to predict the correct noun. If induction heads naively attend to all
past instances of successor tokens of "the" in a context-independent manner,
they cannot support this level of contextual information integration. In this
study, we design a synthetic in-context learning task, where tokens are
repeated with hierarchical dependencies. Here, attending uniformly to all
successor tokens is not sufficient to accurately predict future tokens.
Evaluating a range of LLMs on these token sequences and natural language
analogues, we find adaptive induction heads that support prediction by learning
what to attend to in-context. Next, we investigate how induction heads
themselves learn in-context. We find evidence that learning is supported by
attention heads that uncover a set of latent contexts, determining the
different token transition relationships. Overall, we not only show that LLMs
have induction heads that learn, but offer a complete mechanistic account of
how LLMs learn to predict higher-order repetitive patterns in-context.

</details>


### [172] [Evidence for Limited Metacognition in LLMs](https://arxiv.org/abs/2509.21545)
*Christopher Ackerman*

Main category: cs.LG

TL;DR: 该论文提出了一种新的方法来定量评估LLM中的元认知能力，通过实验证明，自2024年初以来推出的前沿LLM在评估和利用自身回答事实和推理问题的信心以及预测答案的能力方面表现出越来越强的元认知能力。


<details>
  <summary>Details</summary>
Motivation: 衡量LLM的自我意识和感知能力的科学还处于初期阶段，但其可能性正受到越来越多的公众关注，并具有重大的安全和政策影响。

Method: 该研究借鉴了非人类动物的元认知研究，避免了模型自我报告，而是测试模型在多大程度上可以战略性地部署内部状态知识。使用了两种实验范式。

Result: 研究表明，自2024年初以来推出的前沿LLM在某些元认知能力方面表现出越来越强的证据，即评估和利用自身回答事实和推理问题的信心以及预测答案并适当利用该信息的能力。对模型返回的token概率的分析表明，存在一个上游内部信号，可以为元认知提供基础。这些能力在分辨率上是有限的，以依赖于上下文的方式出现，并且似乎与人类的能力有质的不同。

Conclusion: LLM的后训练可能在发展元认知能力方面具有作用。

Abstract: The possibility of LLM self-awareness and even sentience is gaining
increasing public attention and has major safety and policy implications, but
the science of measuring them is still in a nascent state. Here we introduce a
novel methodology for quantitatively evaluating metacognitive abilities in
LLMs. Taking inspiration from research on metacognition in nonhuman animals,
our approach eschews model self-reports and instead tests to what degree models
can strategically deploy knowledge of internal states. Using two experimental
paradigms, we demonstrate that frontier LLMs introduced since early 2024 show
increasingly strong evidence of certain metacognitive abilities, specifically
the ability to assess and utilize their own confidence in their ability to
answer factual and reasoning questions correctly and the ability to anticipate
what answers they would give and utilize that information appropriately. We
buttress these behavioral findings with an analysis of the token probabilities
returned by the models, which suggests the presence of an upstream internal
signal that could provide the basis for metacognition. We further find that
these abilities 1) are limited in resolution, 2) emerge in context-dependent
manners, and 3) seem to be qualitatively different from those of humans. We
also report intriguing differences across models of similar capabilities,
suggesting that LLM post-training may have a role in developing metacognitive
abilities.

</details>


### [173] [Machine Learning. The Science of Selection under Uncertainty](https://arxiv.org/abs/2509.21547)
*Yevgeny Seldin*

Main category: cs.LG

TL;DR: 本书提供了在不确定性选择下获得理论保证的统计工具，研究了离线和在线学习的泛化界限和遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 机器学习是一种选择过程，但由于数据抽样的随机性，经验估计存在噪声，导致在不确定性下进行选择。

Method: 本书涵盖了集中不等式、Occam剃刀、Vapnik-Chervonenkis分析和PAC-贝叶斯分析等统计工具，并应用于推导泛化界限和遗憾界限。

Result: 本书为在随机和对抗环境中，以及在完整信息和bandit反馈下，推导遗憾界限提供了工具。

Conclusion: 本书研究了在不确定性选择下的机器学习理论保证，包括离线和在线学习的泛化和遗憾界限。

Abstract: Learning, whether natural or artificial, is a process of selection. It starts
with a set of candidate options and selects the more successful ones. In the
case of machine learning the selection is done based on empirical estimates of
prediction accuracy of candidate prediction rules on some data. Due to
randomness of data sampling the empirical estimates are inherently noisy,
leading to selection under uncertainty. The book provides statistical tools to
obtain theoretical guarantees on the outcome of selection under uncertainty. We
start with concentration of measure inequalities, which are the main
statistical instrument for controlling how much an empirical estimate of
expectation of a function deviates from the true expectation. The book covers a
broad range of inequalities, including Markov's, Chebyshev's, Hoeffding's,
Bernstein's, Empirical Bernstein's, Unexpected Bernstein's, kl, and split-kl.
We then study the classical (offline) supervised learning and provide a range
of tools for deriving generalization bounds, including Occam's razor,
Vapnik-Chervonenkis analysis, and PAC-Bayesian analysis. The latter is further
applied to derive generalization guarantees for weighted majority votes. After
covering the offline setting, we turn our attention to online learning. We
present the space of online learning problems characterized by environmental
feedback, environmental resistance, and structural complexity. A common
performance measure in online learning is regret, which compares performance of
an algorithm to performance of the best prediction rule in hindsight, out of a
restricted set of prediction rules. We present tools for deriving regret bounds
in stochastic and adversarial environments, and under full information and
bandit feedback.

</details>


### [174] [Interpretable time series analysis with Gumbel dynamics](https://arxiv.org/abs/2509.21578)
*Yiliu Wang,Timothy Doyeon Kim,Eric Shea-Brown,Uygar Sümbül*

Main category: cs.LG

TL;DR: Gumbel Dynamical Model (GDM)通过引入连续松弛的离散状态和Gumbel分布定义的噪声模型，扩展了可用状态动态集，从而更忠实地近似平滑和非平稳的ground-truth动态。


<details>
  <summary>Details</summary>
Motivation: 传统的切换动态系统模型难以捕捉平滑、变速的转换以及重叠状态的随机混合，并且推断的动态通常在真实世界数据集中显示出虚假快速切换。

Method: 提出了Gumbel动态模型（GDM），它通过连续松弛离散状态和在松弛离散状态空间上定义不同的噪声模型来实现。

Result: 在标准仿真数据集上验证了该方法，并突出了其在随机环境中建模软、粘性状态和转换的能力。在两个真实世界数据集上的应用表明，该模型能够在具有多个动态的随机时间序列中推断出可解释的状态。

Conclusion: GDM模型能够在具有多个动态的随机时间序列中推断出可解释的状态，而传统方法通常会失败。

Abstract: Switching dynamical systems can model complicated time series data while
maintaining interpretability by inferring a finite set of dynamics primitives
and explaining different portions of the observed time series with one of these
primitives. However, due to the discrete nature of this set, such models
struggle to capture smooth, variable-speed transitions, as well as stochastic
mixtures of overlapping states, and the inferred dynamics often display
spurious rapid switching on real-world datasets. Here, we propose the Gumbel
Dynamical Model (GDM). First, by introducing a continuous relaxation of
discrete states and a different noise model defined on the relaxed-discrete
state space via the Gumbel distribution, GDM expands the set of available state
dynamics, allowing the model to approximate smoother and non-stationary
ground-truth dynamics more faithfully. Second, the relaxation makes the model
fully differentiable, enabling fast and scalable training with standard
gradient descent methods. We validate our approach on standard simulation
datasets and highlight its ability to model soft, sticky states and transitions
in a stochastic setting. Furthermore, we apply our model to two real-world
datasets, demonstrating its ability to infer interpretable states in stochastic
time series with multiple dynamics, a setting where traditional methods often
fail.

</details>


### [175] [Leveraging Big Data Frameworks for Spam Detection in Amazon Reviews](https://arxiv.org/abs/2509.21579)
*Mst Eshita Khatun,Halima Akter,Tasnimul Rehan,Toufiq Ahmed*

Main category: cs.LG

TL;DR: 该研究利用大数据分析和机器学习方法检测亚马逊产品评论中的虚假评论。


<details>
  <summary>Details</summary>
Motivation: 虚假评论会误导消费者并损害卖家声誉，因此需要检测和分类垃圾评论以增强评论的真实性。

Method: 采用先进的大数据分析和机器学习方法，处理和分析大规模的评论数据，提取关键特征。

Result: Logistic Regression 模型实现了 90.35% 的准确率。

Conclusion: 该研究展示了机器学习分类器在检测垃圾评论中的效用，有助于建立更值得信赖和透明的在线购物环境。

Abstract: In this digital era, online shopping is common practice in our daily lives.
Product reviews significantly influence consumer buying behavior and help
establish buyer trust. However, the prevalence of fraudulent reviews undermines
this trust by potentially misleading consumers and damaging the reputations of
the sellers. This research addresses this pressing issue by employing advanced
big data analytics and machine learning approaches on a substantial dataset of
Amazon product reviews. The primary objective is to detect and classify spam
reviews accurately so that it enhances the authenticity of the review. Using a
scalable big data framework, we efficiently process and analyze a large scale
of review data, extracting key features indicative of fraudulent behavior. Our
study illustrates the utility of various machine learning classifiers in
detecting spam reviews, with Logistic Regression achieving an accuracy of
90.35%, thus contributing to a more trustworthy and transparent online shopping
environment.

</details>


### [176] [GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks](https://arxiv.org/abs/2509.21605)
*Tian Yu Yen,Reese E. Jones,Ravi G. Patel*

Main category: cs.LG

TL;DR: 本文介绍了一种名为GenUQ的度量理论方法，用于量化算子学习中的不确定性，避免构建似然函数，通过生成超网络模型生成与观测数据一致的参数分布。


<details>
  <summary>Details</summary>
Motivation: 算子学习可以将偏微分方程的数值积分简化为函数状态之间的快速映射，从而实现替代和降阶建模。将不确定性量化整合到算子模型中的现有方法依赖于基于似然的方法，但随机算子可能产生难以构建似然结果。因此本文提出了GenUQ。

Method: 提出了一种生成超网络模型，该模型生成与观测数据一致的参数分布。

Result: GenUQ在三个示例问题中优于其他不确定性量化方法，包括恢复制造的算子，学习随机椭圆偏微分方程的解算子以及模拟多孔钢在张力下的失效位置。

Conclusion: GenUQ是一种有效的算子学习不确定性量化方法，它避免了构建似然函数，并且在各种示例问题中都表现出色。

Abstract: Operator learning is a recently developed generalization of regression to
mappings between functions. It promises to drastically reduce expensive
numerical integration of PDEs to fast evaluations of mappings between
functional states of a system, i.e., surrogate and reduced-order modeling.
Operator learning has already found applications in several areas such as
modeling sea ice, combustion, and atmospheric physics. Recent approaches
towards integrating uncertainty quantification into the operator models have
relied on likelihood based methods to infer parameter distributions from noisy
data. However, stochastic operators may yield actions from which a likelihood
is difficult or impossible to construct. In this paper, we introduce, GenUQ, a
measure-theoretic approach to UQ that avoids constructing a likelihood by
introducing a generative hyper-network model that produces parameter
distributions consistent with observed data. We demonstrate that GenUQ
outperforms other UQ methods in three example problems, recovering a
manufactured operator, learning the solution operator to a stochastic elliptic
PDE, and modeling the failure location of porous steel under tension.

</details>


### [177] [Task-Agnostic Federated Continual Learning via Replay-Free Gradient Projection](https://arxiv.org/abs/2509.21606)
*Seohyeon Cha,Huancheng Chen,Haris Vikalo*

Main category: cs.LG

TL;DR: 联邦持续学习(FCL) 允许分布式客户端设备从跨不同和演进任务的流数据中学习。


<details>
  <summary>Details</summary>
Motivation: 在去中心化环境中，数据异构性、受限的通信和隐私问题加剧了持续学习中的一个主要挑战，即灾难性遗忘。

Method: 我们提出了基于联邦梯度投影的持续学习与任务身份预测(FedProTIP)，这是一个新的FCL框架，通过将客户端更新投影到由全局模型先前学习的表示所跨越的子空间的正交补空间上，来减轻遗忘。

Result: 在标准FCL基准上的大量实验表明，FedProTIP在平均精度方面显著优于最先进的方法，特别是在任务身份先验未知的情况下。

Conclusion: 总结：FedProTIP通过梯度投影和任务身份预测，有效缓解了联邦持续学习中的灾难性遗忘问题，并在任务身份未知的情况下表现出色。

Abstract: Federated continual learning (FCL) enables distributed client devices to
learn from streaming data across diverse and evolving tasks. A major challenge
to continual learning, catastrophic forgetting, is exacerbated in decentralized
settings by the data heterogeneity, constrained communication and privacy
concerns. We propose Federated gradient Projection-based Continual Learning
with Task Identity Prediction (FedProTIP), a novel FCL framework that mitigates
forgetting by projecting client updates onto the orthogonal complement of the
subspace spanned by previously learned representations of the global model.
This projection reduces interference with earlier tasks and preserves
performance across the task sequence. To further address the challenge of
task-agnostic inference, we incorporate a lightweight mechanism that leverages
core bases from prior tasks to predict task identity and dynamically adjust the
global model's outputs. Extensive experiments across standard FCL benchmarks
demonstrate that FedProTIP significantly outperforms state-of-the-art methods
in average accuracy, particularly in settings where task identities are a
priori unknown.

</details>


### [178] [Causal Abstraction Inference under Lossy Representations](https://arxiv.org/abs/2509.21607)
*Kevin Xia,Elias Bareinboim*

Main category: cs.LG

TL;DR: 本文提出了一种新的抽象类型，称为投影抽象，它可以推广现有的定义以适应有损表示。


<details>
  <summary>Details</summary>
Motivation: 研究因果抽象弥合了人类智能的两个组成部分：确定因果关系的能力，以及将复杂模式解释为抽象概念的能力。

Method: 从低层模型构建投影抽象，并展示了它如何将等效的观察性、干预性和反事实因果查询从低层翻译到高层。此外，还证明了一种新的图形标准，用于从有限的低层数据中识别和估计高层因果查询。

Result: 在实验中表明了投影抽象模型在高维图像环境中的有效性。

Conclusion: 投影抽象概括了现有的定义以适应有损表示，并为识别和估计高层因果查询提供了一种新的图形标准。

Abstract: The study of causal abstractions bridges two integral components of human
intelligence: the ability to determine cause and effect, and the ability to
interpret complex patterns into abstract concepts. Formally, causal abstraction
frameworks define connections between complicated low-level causal models and
simple high-level ones. One major limitation of most existing definitions is
that they are not well-defined when considering lossy abstraction functions in
which multiple low-level interventions can have different effects while mapping
to the same high-level intervention (an assumption called the abstract
invariance condition). In this paper, we introduce a new type of abstractions
called projected abstractions that generalize existing definitions to
accommodate lossy representations. We show how to construct a projected
abstraction from the low-level model and how it translates equivalent
observational, interventional, and counterfactual causal queries from low to
high-level. Given that the true model is rarely available in practice we prove
a new graphical criteria for identifying and estimating high-level causal
queries from limited low-level data. Finally, we experimentally show the
effectiveness of projected abstraction models in high-dimensional image
settings.

</details>


### [179] [LANCE: Low Rank Activation Compression for Efficient On-Device Continual Learning](https://arxiv.org/abs/2509.21617)
*Marco Paul E. Apolinario,Kaushik Roy*

Main category: cs.LG

TL;DR: LANCE通过一次高阶SVD获得可重用的低秩子空间用于激活投影，减少了内存和计算开销，并实现了设备上的持续学习。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中，设备上的学习对于个性化、隐私和长期适应至关重要。然而，存储激活的高内存成本限制了微调现有模型和不断获取新任务。

Method: LANCE框架执行一次高阶奇异值分解（SVD）以获得可重用的低秩子空间用于激活投影。

Result: LANCE减少了高达250倍的激活存储，同时保持了与CIFAR-10/100等数据集上完整反向传播相当的准确性。在持续学习基准测试中，它以一小部分内存成本实现了与正交梯度投影方法相当的性能。

Conclusion: LANCE是一种实用的、可扩展的解决方案，可在边缘设备上进行高效的微调和持续学习。

Abstract: On-device learning is essential for personalization, privacy, and long-term
adaptation in resource-constrained environments. Achieving this requires
efficient learning, both fine-tuning existing models and continually acquiring
new tasks without catastrophic forgetting. Yet both settings are constrained by
high memory cost of storing activations during backpropagation. Existing
activation compression methods reduce this cost but relying on repeated
low-rank decompositions, introducing computational overhead. Also, such methods
have not been explored for continual learning. We propose LANCE (Low-rank
Activation Compression), a framework that performs one-shot higher-order
Singular Value Decompsoition (SVD) to obtain a reusable low-rank subspace for
activation projection. This eliminates repeated decompositions, reducing both
memory and computation. Moreover, fixed low-rank subspaces further enable
on-device continual learning by allocating tasks to orthogonal subspaces
without storing large task-specific matrices. Experiments show that LANCE
reduces activation storage up to 250$\times$ while maintaining accuracy
comparable to full backpropagation on CIFAR-10/100, Oxford-IIIT Pets,
Flowers102, and CUB-200 datasets. On continual learning benchmarks (Split
CIFAR-100, Split MiniImageNet, 5-Datasets), it achieves performance competitive
with orthogonal gradient projection methods at a fraction of the memory cost.
These results position LANCE as a practical and scalable solution for efficient
fine-tuning and continual learning on edge devices.

</details>


### [180] [PreLoRA: Hybrid Pre-training of Vision Transformers with Full Training and Low-Rank Adapters](https://arxiv.org/abs/2509.21619)
*Krishu K Thapa,Reet Barik,Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.LG

TL;DR: 提出了一种动态切换到低秩适应(LoRA)的方法，以减少训练大型模型的资源消耗。


<details>
  <summary>Details</summary>
Motivation: 训练大型模型需要大量资源，并且大部分学习发生在训练的早期阶段。随着训练的进行，这些变化会稳定下来，因此可以使用低秩矩阵来捕获它们。

Method: 该方法基于用户定义的超参数来确定切换点，并根据每个模块层的收敛程度为其分配特定的秩。

Result: 实验结果表明，该方法在保持模型精度的同时，将可训练参数的数量减少到原始大小的10%，从而使吞吐量提高了3倍，每个epoch的平均训练时间减少了1.5倍，同时减少了20%的GPU内存消耗。

Conclusion: 该方法可以有效地减少训练大型模型的资源消耗，同时保持模型精度。

Abstract: Training large models ranging from millions to billions of parameters is
highly resource-intensive, requiring significant time, compute, and memory. It
is observed that most of the learning (higher change in weights) takes place in
the earlier stage of the training loop. These changes stabilize as training
continues, enabling them to be captured by matrices of a low intrinsic rank.
Therefore, we propose an approach to identify such states of partial
convergence and dynamically switch from full parameter training to Low-Rank
Adaptation (LoRA) on the ViT-Large model. We introduce a flexible approach that
leverages user-defined hyperparameters to determine the switching point and
assign a rank specific to each module layer based on its level of convergence.
Experimental results show that this approach preserves model accuracy while
reducing the number of trainable parameters to 10% of its original size,
resulting in a 3x improvement in throughput, and a 1.5x reduction in average
training time per epoch while also reducing GPU memory consumption by 20%

</details>


### [181] [Shoot from the HIP: Hessian Interatomic Potentials without derivatives](https://arxiv.org/abs/2509.21624)
*Andreas Burger,Luca Thiede,Nikolaj Rønne,Varinia Bernales,Nandita Vijaykumar,Tejs Vegge,Arghya Bhowmik,Alan Aspuru-Guzik*

Main category: cs.LG

TL;DR: 本研究展示了一种直接从深度学习模型预测Hessians的方法，无需依赖自动微分或有限差分。


<details>
  <summary>Details</summary>
Motivation: 分子Hessians在计算化学中至关重要，但计算成本高且随系统尺寸扩展性差。

Method: 利用图神经网络中消息传递计算的不可约表示特征构建SE(3)-equivariant对称Hessians。

Result: HIP Hessians的速度提高了一到两个数量级，同时提高了准确性、内存效率，更易于训练，并实现了更优的系统尺寸扩展性。

Conclusion: 通过广泛的下游任务验证，证明了该方法在过渡态搜索、加速几何优化、零点能量校正和振动分析基准测试中具有持续优越的性能。

Abstract: Fundamental tasks in computational chemistry, from transition state search to
vibrational analysis, rely on molecular Hessians, which are the second
derivatives of the potential energy. Yet, Hessians are computationally
expensive to calculate and scale poorly with system size, with both quantum
mechanical methods and neural networks. In this work, we demonstrate that
Hessians can be predicted directly from a deep learning model, without relying
on automatic differentiation or finite differences. We observe that one can
construct SE(3)-equivariant, symmetric Hessians from irreducible
representations (irrep) features up to degree $l$=2 computed during message
passing in graph neural networks. This makes HIP Hessians one to two orders of
magnitude faster, more accurate, more memory efficient, easier to train, and
enables more favorable scaling with system size. We validate our predictions
across a wide range of downstream tasks, demonstrating consistently superior
performance for transition state search, accelerated geometry optimization,
zero-point energy corrections, and vibrational analysis benchmarks. We
open-source the HIP codebase and model weights to enable further development of
the direct prediction of Hessians at https://github.com/BurgerAndreas/hip

</details>


### [182] [Blockwise Hadamard high-Rank Adaptation for Parameter-Efficient LLM Fine-Tuning](https://arxiv.org/abs/2509.21637)
*Feng Yu,Jia Hu,Geyong Min*

Main category: cs.LG

TL;DR: 提出了一种新的参数高效微调方法BHRA，它通过分块 Hadamard 结构实现局部秩放大，优于全局调制的 HiRA 和全学习的 ABBA。


<details>
  <summary>Details</summary>
Motivation: 现有 PEFT 方法需要在资源效率和处理异构推理转换之间权衡，LoRA 受限于秩 r，HiRA 耦合全局能量模式，ABBA 则完全学习密集中间层。

Method: 将权重矩阵分块，在每个块内独立应用 HiRA 风格的乘性调制，实现局部秩放大。

Result: 在 Llama-3.2 1B/3B、Mistral-7B 和 Gemma-2 9B 上的常识推理和算术任务中，BHRA 始终优于其他 PEFT 基线。

Conclusion: BHRA 能够在保持 PEFT 参数规模的同时，通过分块设计保持丰富的谱，缓解全局调制引起的崩溃。

Abstract: Parameter-efficient fine-tuning (PEFT) methods must be resource-efficient yet
handle heterogeneous reasoning transformations, and classical low-rank
adaptation (LoRA) is constrained by the nominal rank $r$. Hadamard-style
extensions like HiRA raise the nominal rank but couple every update to the
global energy pattern of the frozen weight matrix, while ABBA trades this
inductive bias for fully learned dense intermediates. To address the limitation
of global modulation, we propose Block Hadamard high-Rank Adaptation (BHRA),
which partitions each weight matrix and applies HiRA-style multiplicative
modulation independently within every block, preserving the PEFT parameter
footprint while unlocking localized rank amplification. Our empirical analyses
reveal that this blockwise design maintains rich spectra across rank budgets,
mitigating the collapse induced by global modulation. Across eight commonsense
reasoning tasks and two arithmetic benchmarks with Llama-3.2 1B/3B, Mistral-7B,
and Gemma-2 9B, BHRA consistently surpasses strong PEFT baselines under matched
parameter budgets.

</details>


### [183] [Understanding and Enhancing Mask-Based Pretraining towards Universal Representations](https://arxiv.org/abs/2509.21650)
*Mingze Dong,Leda Wang,Yuval Kluger*

Main category: cs.LG

TL;DR: 本文提出了R^2MAE，一种新的mask策略，通过在视觉、语言和生物学任务上的实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 探究基于mask的预训练在学习数据表征中的作用和局限性。

Method: 通过高维最小范数线性回归中的测试风险来表征基于mask的预训练行为，并提出了Randomly Random Mask AutoEncoding (R^2MAE) 预训练方案。

Result: R^2MAE在视觉、语言、DNA序列和单细胞模型中始终优于标准和更复杂的mask策略，并改进了当前最优模型。

Conclusion: R^2MAE通过强制捕获数据的多尺度特征，在各种任务上都表现出优越的性能。

Abstract: Mask-based pretraining has become a cornerstone of modern large-scale models
across language, vision, and recently biology. Despite its empirical success,
its role and limits in learning data representations have been unclear. In this
work, we show that the behavior of mask-based pretraining can be directly
characterized by test risk in high-dimensional minimum-norm ("ridge-less")
linear regression, without relying on further model specifications. Further
analysis of linear models uncovers several novel aspects of mask-based
pretraining. The theoretical framework and its implications have been validated
across diverse neural architectures (including MLPs, CNNs, and Transformers)
applied to both vision and language tasks. Guided by our theory, we propose an
embarrassingly simple yet overlooked pretraining scheme named Randomly Random
Mask AutoEncoding (R$^2$MAE), which enforces capturing multi-scale features
from data and is able to outperform optimal fixed mask ratio settings in our
linear model framework. We implement R$^2$MAE in vision, language, DNA
sequence, and single-cell models, where it consistently outperforms standard
and more complicated masking schemes, leading to improvements for
state-of-the-art models. Our code is available at:
https://github.com/MingzeDong/r2mae

</details>


### [184] [Limitations on Safe, Trusted, Artificial General Intelligence](https://arxiv.org/abs/2509.21654)
*Rina Panigrahy,Vatsal Sharan*

Main category: cs.LG

TL;DR: 本文提出了安全性、信任和通用人工智能（AGI）的严格数学定义，并证明了它们之间的根本不相容性。一个安全和可信的AI系统不能是一个AGI系统。


<details>
  <summary>Details</summary>
Motivation: 探讨人工智能系统中安全性、信任和通用人工智能（AGI）的目标，并指出这些概念存在多种非正式的解释。

Method: 通过对安全性、信任和AGI进行严格的数学定义，然后证明它们之间的不相容性。具体研究了程序验证、规划和图可达性问题。

Result: 证明了一个安全且可信的AI系统不能成为AGI系统，因为对于这种系统，存在人类可以轻松解决但系统无法解决的任务实例。

Conclusion: 对于安全性与信任的严格数学定义，安全和可信的AI系统无法达到通用人工智能。该结论与哥德尔不完备性定理和图灵停机问题的不可判定性证明存在相似之处。

Abstract: Safety, trust and Artificial General Intelligence (AGI) are aspirational
goals in artificial intelligence (AI) systems, and there are several informal
interpretations of these notions. In this paper, we propose strict,
mathematical definitions of safety, trust, and AGI, and demonstrate a
fundamental incompatibility between them. We define safety of a system as the
property that it never makes any false claims, trust as the assumption that the
system is safe, and AGI as the property of an AI system always matching or
exceeding human capability. Our core finding is that -- for our formal
definitions of these notions -- a safe and trusted AI system cannot be an AGI
system: for such a safe, trusted system there are task instances which are
easily and provably solvable by a human but not by the system. We note that we
consider strict mathematical definitions of safety and trust, and it is
possible for real-world deployments to instead rely on alternate, practical
interpretations of these notions. We show our results for program verification,
planning, and graph reachability. Our proofs draw parallels to G\"odel's
incompleteness theorems and Turing's proof of the undecidability of the halting
problem, and can be regarded as interpretations of G\"odel's and Turing's
results.

</details>


### [185] [DriftLite: Lightweight Drift Control for Inference-Time Scaling of Diffusion Models](https://arxiv.org/abs/2509.21655)
*Yinuo Ren,Wenhao Gao,Lexing Ying,Grant M. Rotskoff,Jiequn Han*

Main category: cs.LG

TL;DR: 提出 DriftLite，一种轻量级的、无需训练的基于粒子的方法，用于在推理时调整扩散模型，具有最优稳定性控制。


<details>
  <summary>Details</summary>
Motivation: 现有的基于指导的方法很简单，但会引入偏差，而基于粒子的校正存在权重退化和计算成本高的问题。

Method: 利用 Fokker-Planck 方程中漂移和粒子势之间先前未被探索的自由度，产生两种实用的实例化：方差控制指导 (VCG) 和能量控制指导 (ECG)，以最小的开销逼近最优漂移。

Result: 在 Gaussian 混合模型、粒子系统和大规模蛋白质-配体共折叠问题中，DriftLite 始终如一地降低了方差，并提高了样本质量。

Conclusion: DriftLite 为扩散模型的可扩展推理时自适应提供了一条有原则的、高效的途径。

Abstract: We study inference-time scaling for diffusion models, where the goal is to
adapt a pre-trained model to new target distributions without retraining.
Existing guidance-based methods are simple but introduce bias, while
particle-based corrections suffer from weight degeneracy and high computational
cost. We introduce DriftLite, a lightweight, training-free particle-based
approach that steers the inference dynamics on the fly with provably optimal
stability control. DriftLite exploits a previously unexplored degree of freedom
in the Fokker-Planck equation between the drift and particle potential, and
yields two practical instantiations: Variance- and Energy-Controlling Guidance
(VCG/ECG) for approximating the optimal drift with minimal overhead. Across
Gaussian mixture models, particle systems, and large-scale protein-ligand
co-folding problems, DriftLite consistently reduces variance and improves
sample quality over pure guidance and sequential Monte Carlo baselines. These
results highlight a principled, efficient route toward scalable inference-time
adaptation of diffusion models.

</details>


### [186] [Differentiable Structure Learning for General Binary Data](https://arxiv.org/abs/2509.21658)
*Chang Deng,Bryon Aragam*

Main category: cs.LG

TL;DR: 提出了一种用于离散数据中可微结构学习的通用框架，可以捕捉变量之间的任意依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设数据来自特定的结构方程模型，但这些假设可能与真实的数据生成过程不符，限制了方法的通用性。此外，当前方法通常忽略离散数据中固有的复杂依赖结构，只考虑线性效应。

Method: 将学习问题表述为最一般形式的单个可微优化任务，避免了先前方法采用的不切实际的简化。

Result: 经验结果表明，该方法能够有效地捕捉离散数据中的复杂关系。

Conclusion: 即使一般离散模型无法从纯观察数据中识别，也可以表征完整的兼容参数和结构集。此外，在温和的假设下，可以建立马尔可夫等价的识别性。

Abstract: Existing methods for differentiable structure learning in discrete data
typically assume that the data are generated from specific structural equation
models. However, these assumptions may not align with the true data-generating
process, which limits the general applicability of such methods. Furthermore,
current approaches often ignore the complex dependence structure inherent in
discrete data and consider only linear effects. We propose a differentiable
structure learning framework that is capable of capturing arbitrary
dependencies among discrete variables. We show that although general discrete
models are unidentifiable from purely observational data, it is possible to
characterize the complete set of compatible parameters and structures.
Additionally, we establish identifiability up to Markov equivalence under mild
assumptions. We formulate the learning problem as a single differentiable
optimization task in the most general form, thereby avoiding the unrealistic
simplifications adopted by previous methods. Empirical results demonstrate that
our approach effectively captures complex relationships in discrete data.

</details>


### [187] [RED-DiffEq: Regularization by denoising diffusion models for solving inverse PDE problems with application to full waveform inversion](https://arxiv.org/abs/2509.21659)
*Siming Shan,Min Zhu,Youzuo Lin,Lu Lu*

Main category: cs.LG

TL;DR: 提出了一种新的计算框架RED-DiffEq，通过整合物理驱动反演和数据驱动学习来解决偏微分方程控制的反问题。


<details>
  <summary>Details</summary>
Motivation: 偏微分方程控制的反问题由于非线性、不适定性和对噪声的敏感性而面临重大挑战。

Method: 利用预训练的扩散模型作为偏微分方程控制反问题的正则化机制。

Result: 该方法在地球物理学中的全波形反演问题中表现出更高的精度和鲁棒性，并且对扩散模型未训练的更复杂速度模型具有强大的泛化能力。

Conclusion: 该框架可以直接应用于各种偏微分方程控制的反问题。

Abstract: Partial differential equation (PDE)-governed inverse problems are fundamental
across various scientific and engineering applications; yet they face
significant challenges due to nonlinearity, ill-posedness, and sensitivity to
noise. Here, we introduce a new computational framework, RED-DiffEq, by
integrating physics-driven inversion and data-driven learning. RED-DiffEq
leverages pretrained diffusion models as a regularization mechanism for
PDE-governed inverse problems. We apply RED-DiffEq to solve the full waveform
inversion problem in geophysics, a challenging seismic imaging technique that
seeks to reconstruct high-resolution subsurface velocity models from seismic
measurement data. Our method shows enhanced accuracy and robustness compared to
conventional methods. Additionally, it exhibits strong generalization ability
to more complex velocity models that the diffusion model is not trained on. Our
framework can also be directly applied to diverse PDE-governed inverse
problems.

</details>


### [188] [A Systematic Review of Conformal Inference Procedures for Treatment Effect Estimation: Methods and Challenges](https://arxiv.org/abs/2509.21660)
*Pascal Memmesheimer,Vincent Heuveline,Jürgen Hesser*

Main category: cs.LG

TL;DR: 本文综述了使用共形预测进行治疗效果估计的方法。


<details>
  <summary>Details</summary>
Motivation: 在医疗、经济和公共政策等领域，治疗效果估计对于明智的决策至关重要。虽然灵活的机器学习模型已被广泛应用于估计异质性治疗效果，但量化其点预测的内在不确定性仍然是一个问题。

Method: 本文对治疗效果估计的共形预测方法进行了系统回顾，并提供了必要的理论背景。通过系统的筛选过程，选择了 11 篇关键论文进行分析，识别并描述了该领域当前最先进的方法。

Result: 本文识别并描述了该领域当前最先进的方法。

Conclusion: 本文提出了未来研究的方向。

Abstract: Treatment effect estimation is essential for informed decision-making in many
fields such as healthcare, economics, and public policy. While flexible machine
learning models have been widely applied for estimating heterogeneous treatment
effects, quantifying the inherent uncertainty of their point predictions
remains an issue. Recent advancements in conformal prediction address this
limitation by allowing for inexpensive computation, as well as distribution
shifts, while still providing frequentist, finite-sample coverage guarantees
under minimal assumptions for any point-predictor model. This advancement holds
significant potential for improving decision-making in especially high-stakes
environments. In this work, we perform a systematic review regarding conformal
prediction methods for treatment effect estimation and provide for both the
necessary theoretical background. Through a systematic filtering process, we
select and analyze eleven key papers, identifying and describing current
state-of-the-art methods in this area. Based on our findings, we propose
directions for future research.

</details>


### [189] [MMPlanner: Zero-Shot Multimodal Procedural Planning with Chain-of-Thought Object State Reasoning](https://arxiv.org/abs/2509.21662)
*Afrina Tabassum,Bin Guo,Xiyao Ma,Hoda Eldardiry,Ismini Lourentzou*

Main category: cs.LG

TL;DR: MMPlanner是一个零样本多模态程序规划框架，通过引入对象状态推理链式思考（OSR-CoT）提示来显式建模对象状态转换，从而生成准确的多模态计划。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常利用大型语言模型（LLM）来改进文本步骤；然而，视觉对象状态对齐和系统评估在很大程度上未被探索。

Method: 提出了MMPlanner，一个零样本MPP框架，它引入了对象状态推理链式思考（OSR-CoT）提示来显式地建模对象状态转换并生成准确的多模态计划。为了评估计划质量，我们设计了LLM-as-a-judge协议，用于计划准确性和跨模态对齐，并进一步提出了一个视觉步骤重新排序任务来测量时间连贯性。

Result: 在RECIPEPLAN和WIKIPLAN上的实验表明，MMPlanner实现了最先进的性能，文本规划提高了+6.8%，跨模态对齐提高了+11.9%，视觉步骤排序提高了+26.7%。

Conclusion: MMPlanner通过显式建模对象状态转换，显著提升了多模态程序规划的性能，并在多个数据集上取得了最先进的结果。

Abstract: Multimodal Procedural Planning (MPP) aims to generate step-by-step
instructions that combine text and images, with the central challenge of
preserving object-state consistency across modalities while producing
informative plans. Existing approaches often leverage large language models
(LLMs) to refine textual steps; however, visual object-state alignment and
systematic evaluation are largely underexplored. We present MMPlanner, a
zero-shot MPP framework that introduces Object State Reasoning Chain-of-Thought
(OSR-CoT) prompting to explicitly model object-state transitions and generate
accurate multimodal plans. To assess plan quality, we design LLM-as-a-judge
protocols for planning accuracy and cross-modal alignment, and further propose
a visual step-reordering task to measure temporal coherence. Experiments on
RECIPEPLAN and WIKIPLAN show that MMPlanner achieves state-of-the-art
performance, improving textual planning by +6.8%, cross-modal alignment by
+11.9%, and visual step ordering by +26.7%

</details>
