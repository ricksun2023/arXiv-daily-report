<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.CV](#cs.CV) [Total: 55]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IR](#cs.IR) [Total: 17]
- [cs.LG](#cs.LG) [Total: 53]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 本文提出了一种利用文档级知识图谱来改进ICD编码的方法。


<details>
  <summary>Details</summary>
Motivation: 人工临床文档编码既困难又耗时，难以大规模应用。自动化编码可以减轻这一负担，但将文档映射到高维目标空间（如ICD）具有挑战性。以往研究较少利用外部资源来表示输入文档。

Method: 本文计算输入文档的结构化表示，利用文档级知识图谱提供患者病情的全面结构化视图。知识图谱以原始文本23%的量有效表示以患者为中心的输入文档，同时保留90%的信息。将其集成到PLM-ICD中。

Result: 实验表明，在流行的基准测试中，Macro-F1分数提高了3.20%，同时提高了训练效率。归因于KG中不同类型的实体和关系。

Conclusion: 该方法具有改进的可解释性潜力。

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [2] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为Cross-Layer Attention Probing (CLAP) 的激活探测技术，用于检测大型语言模型 (LLM) 生成的不准确文本，即幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 在各种应用中被大规模采用，但由于它们容易生成不准确的文本，因此其可靠性问题日益严重。

Method: 该方法处理整个残差流中的LLM激活，作为一个联合序列。

Result: 在五个LLM和三个任务上的实验评估表明，与基线相比，CLAP提高了幻觉检测能力，无论是在贪婪解码的响应还是在较高温度下采样的响应中。这使得能够进行细粒度的检测，即区分给定提示的不同采样响应中的幻觉和非幻觉的能力。这允许我们提出一种使用CLAP的检测-然后-缓解策略，以减少幻觉并提高LLM的可靠性，与直接缓解方法相比。

Conclusion: 结果表明，即使在分布外应用时，CLAP也能保持较高的可靠性。

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [3] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 本文研究了端到端语音到文本翻译中配对数据稀缺的问题，并利用机器翻译（MT）任务中的双语文本数据执行多任务学习（MTL）。


<details>
  <summary>Details</summary>
Motivation: 端到端语音到文本翻译通常受到配对语音文本数据稀缺的限制。为了克服这个缺点，一种方法是利用来自机器翻译（MT）任务的双语文本数据并执行多任务学习（MTL）。

Method: 本文从正则化的角度构建MTL，并探讨如何在模态内部和跨模态正则化序列。通过彻底研究一致性正则化（不同模态）和R-drop（相同模态）的效果，我们展示了它们如何分别对总正则化做出贡献。我们还证明了MT损失的系数在MTL设置中充当正则化的另一个来源。

Result: 通过这三个正则化来源，我们引入了高维空间中的最优正则化轮廓，称为正则化范围。实验表明，在正则化范围内调整超参数可以在MuST-C数据集上实现接近最先进的性能。

Conclusion: 通过探索一致性正则化、R-drop以及MT损失系数对模型性能的影响，并在正则化范围内调整超参数，最终在MuST-C数据集上实现了接近SOTA的性能。

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [4] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: 提出了一个营销创意评估框架，用于评估大型语言模型（LLM）的创造力。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型在营销创意方面的能力。

Method: 构建了一个包含100个品牌和三种提示类型的评估框架，并通过人工 pairwise 偏好分析模型性能。

Result: 模型性能紧密聚集，没有模型在所有品牌或提示类型中占据主导地位。自动评估无法替代人工评估。

Conclusion: 强调了专家人工评估和多样性感知工作流程的必要性。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [5] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为CTCC的新的规则驱动的指纹识别框架，用于保护大型语言模型的知识产权。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的广泛应用使得模型盗窃和未经授权的重新分发变得越来越容易，因此需要模型指纹识别技术来嵌入可验证的所有权追踪。

Method: CTCC通过编码多个对话轮次之间的上下文相关性来实现指纹识别，而不是依赖于token级别或单轮触发器。

Result: 实验结果表明，CTCC在隐蔽性和鲁棒性方面始终优于先前的工作。

Conclusion: CTCC是一种可靠且实用的解决方案，适用于真实世界LLM部署场景中的所有权验证。

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [6] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 本研究探讨了语言模型在跨期选择中是否表现出未来或现在的偏好，以及这些偏好是否可以被系统地操纵。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在跨期选择中的偏好，以及这些偏好是否可以被操纵。

Method: 使用改编的人类实验协议，评估多个语言模型在时间权衡任务中的表现，并以人类决策者样本作为基准。引入可操作性指标，即时间方向的可操纵性（MTO）。

Result: 在测试中，以推理为中心的模型在面向未来的提示下选择稍后的选项，但仅部分地跨身份或地理位置个性化决策。此外，正确推理时间方向的模型为自己作为 AI 决策者内化了未来方向。

Conclusion: 讨论了 AI 助手的设计意义，这些助手应与异构的长期目标保持一致，并概述了个性化情境校准和社会意识部署的研究议程。

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [7] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 研究小型语言模型在多次回答相同问题时的一致性。


<details>
  <summary>Details</summary>
Motivation: 探索小型LLM在重复回答问题时的一致性，并研究不同因素的影响。

Method: 对开源LLM在MMLU-Redux和MedQA基准上进行多次提问，并分析不同温度、模型大小和微调情况下的回答。

Result: 小型模型在低温度下的一致性在50%-80%之间，一致答案的准确性与总体准确性相关。中型模型表现出更高的一致性。

Conclusion: 研究表明模型的一致性因模型而异，且与准确性相关。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [8] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 本研究旨在通过研究大型语言模型（LLM）的内部机制，理解并利用其对有害提示的拒绝行为。通过稀疏自编码器（SAE）在残差流激活上进行训练，并在Gemma-2-2B-IT和LLaMA-3.1-8B-IT模型上进行研究，寻找能够使模型从拒绝转为服从的关键特征集合，从而实现越狱。


<details>
  <summary>Details</summary>
Motivation: 当前对指令调整的大型语言模型（LLM）拒绝有害提示这一关键安全行为的内部原因理解不足。

Method: 使用稀疏自编码器（SAE）在残差流激活上训练，并通过三个阶段搜索潜在空间中的特征集合：(1) 拒绝方向：找到拒绝介导方向并收集附近的SAE特征；(2) 贪婪过滤：精简到最小集合；(3) 交互发现：拟合分解机（FM），捕捉剩余活跃特征和最小集合之间的非线性交互。

Result: 找到了大量越狱关键特征，揭示了拒绝行为的机制基础；发现了冗余特征，这些特征在早期特征被抑制时才会激活。

Conclusion: 通过操纵可解释的潜在空间，可以对安全行为进行细粒度的审计和有针对性的干预。

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [9] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: 本研究旨在解决大型语言模型（LLM）在学术写作中存在的参考文献不准确和内容质量评估主观性问题。


<details>
  <summary>Details</summary>
Motivation: 当前学术写作中LLM的使用面临参考文献错误和内容质量评估主观性的挑战。

Method: 提出了内容质量和参考文献有效性两个关键评估指标，以及一种基于这些指标得分的迭代提示方法。

Result: 实验表明，所提出的指标提供了一个客观、定量的框架来评估ChatGPT的写作性能。迭代提示显著提高了内容质量，同时减少了参考文献的不准确性和捏造。

Conclusion: 该研究提出的方法能够有效提升LLM在学术写作中的内容质量，并减少参考文献错误，从而解决学术伦理问题。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [10] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究提出了一种使用大型语言模型（LLM）在基于代理的交通模型中生成个人旅行日记的方案。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于大量的专有家庭旅行调查，而本研究旨在使用LLM通过开放的ACS和SLD数据随机生成角色，并通过直接提示合成日记。

Method: 本研究提出了一种新颖的one-to-cohort现实性评分，该评分由四个指标（出行次数评分、间隔评分、目的评分和模式评分）组成，并根据康涅狄格州全州交通研究（CSTS）日记进行验证，并在人口统计变量之间进行匹配。验证采用Jensen-Shannon散度来衡量生成日记和真实日记之间的分布相似性。

Result: 与使用经典方法生成的日记相比，LLM生成的日记具有相当的整体真实性（LLM平均值：0.485 vs. 0.455）。LLM在确定出行目的方面表现出色，并表现出更高的一致性，而经典模型在出行次数和活动持续时间的数值估计方面处于领先地位。总体验证证实了LLM的统计代表性（LLM平均值：0.612 vs. 0.435）。

Conclusion: LLM展示了zero-shot可行性，并为未来的合成日记评估系统建立了日记真实性的可量化指标。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [11] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: 论文介绍了一个新的精神病学基准测试 PsychiatryBench，用于评估大型语言模型（LLM）在精神健康应用中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估资源依赖于小型临床访谈语料库、社交媒体帖子或合成对话，限制了临床有效性，无法捕捉精神病学推理的完整复杂性。

Method: 构建了一个基于权威、专家验证的精神病学教科书和案例集的基准测试 PsychiatryBench，包含 11 个不同的问答任务，涵盖诊断推理、治疗计划、纵向随访、管理计划、临床方法、序列案例分析和多项选择/扩展匹配格式。

Result: 评估了包括 Google Gemini、DeepSeek、LLaMA 3 和 QWQ-32 在内的 LLM，以及领先的开源医疗模型，结果表明在临床一致性和安全性方面存在显著差距，尤其是在多轮随访和管理任务中。

Conclusion: PsychiatryBench 提供了一个模块化、可扩展的平台，用于对高风险精神健康应用中的 LLM 性能进行基准测试和改进，表明需要专门的模型调整和更强大的评估范例。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [12] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 本研究探讨了后训练方法和显式推理对小型LLM提供ACT能力的影响。使用50组合成ACT记录，我们训练了Llama-3.2-3b-Instruct，采用了监督微调（SFT）和优势比策略优化（ORPO）两种方法，每种方法都有或没有显式的思维链（COT）推理步骤。通过比较这四种后训练变体与基础Instruct模型来评估性能。结果表明，ORPO训练的模型在ACT保真度和治疗共情方面显著优于SFT和Instruct模型。COT的效果是条件性的，因为它为SFT模型提供了显著的优势，但对ORPO或instruct调整的变体没有明显优势。本研究表明，偏好对齐策略优化可以有效地将ACT能力灌输到小型LLM中，并且显式推理的效用高度依赖于底层训练范式。


<details>
  <summary>Details</summary>
Motivation: 研究ACT在精神疾病中的有效性，并探索LLM提供ACT的可能性。

Method: 使用Mistral-Large生成的50组合成ACT记录，训练Llama-3.2-3b-Instruct，采用SFT和ORPO两种方法，每种方法都有或没有显式的COT推理步骤。使用ACT Fidelity Measure (ACT-FM)和Therapist Empathy Scale (TES)评估性能。

Result: ORPO训练的模型在ACT保真度和治疗共情方面显著优于SFT和Instruct模型。COT对SFT模型有显著的优势，但对ORPO或instruct调整的变体没有明显优势。

Conclusion: 偏好对齐策略优化可以有效地将ACT能力灌输到小型LLM中，并且显式推理的效用高度依赖于底层训练范式。

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [13] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: HANRAG: A novel heuristic-based RAG framework that routes queries, decomposes them into sub-queries, and filters noise from retrieved documents to enhance adaptability and noise resistance.


<details>
  <summary>Details</summary>
Motivation: Current RAG methods face challenges with multi-hop queries, such as iterative retrieval and noisy content.

Method: Introducing HANRAG, a heuristic-based framework with a powerful revelator to route queries, decompose them, and filter noise.

Result: HANRAG achieves superior performance in both single-hop and multi-hop question-answering tasks compared to other leading methods.

Conclusion: HANRAG enhances system adaptability and noise resistance, making it highly capable of handling diverse queries.

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [14] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 该研究评估了不同方法在衡量语义相似度方面的效果，这对于各种软件工程应用至关重要。研究发现常用指标存在显著问题，并揭示了嵌入方法和基于Transformer的方法在区分语义差异方面的一些局限性。


<details>
  <summary>Details</summary>
Motivation: 评估不同方法测量语义相似度的能力，因为这对于代码搜索、API推荐等软件工程应用至关重要。同时，探讨大型语言模型是否真正理解语义关系，还是仅仅识别表面模式。

Method: 研究人员创建了一个系统化的测试框架，该框架通过对文本和代码应用受控更改来评估每种方法处理不同类型语义关系的能力。研究测试了18种不同的相似度测量方法，包括基于词的方法、嵌入技术、基于LLM的系统和结构感知算法。

Result: 研究结果表明，常用的语义相似度测量指标存在显著问题。例如，一些基于嵌入的方法错误地将语义对立的内容识别为相似，高达99.9%的时间。某些基于Transformer的方法有时会将相反的含义评为比同义词更相似。嵌入方法的性能不佳通常源于它们计算距离的方式；从欧几里德距离切换到余弦相似度将结果提高了24%到66%。

Conclusion: 基于LLM的方法在区分语义差异方面表现更好，对于真正不同的含义产生较低的相似度得分（0.00到0.29），而嵌入方法错误地为不相似的内容分配了较高的得分（0.82到0.99）。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [15] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）中的幻觉是一个经过充分研究的问题。这项研究旨在识别和描述导致 LLM 容易产生幻觉的关键属性。


<details>
  <summary>Details</summary>
Motivation: 确定LLM内在容易产生幻觉的属性，并研究这些属性。

Method: 利用HaluEval和TruthfulQA两个已建立的数据集，并将它们现有的问答格式转换为各种其他格式，以缩小这些属性作为幻觉原因的范围。

Result: Gemma-2-2B 的符号属性幻觉百分比非常高，平均任务和数据集为 79.0%。随着模型规模的增加，Gemma-2-9B 的幻觉率降至 73.6%，Gemma-2-27B 的幻觉率降至 63.9%，总体下降了 15 个百分点。修饰符（84.76% 到 94.98%）和命名实体（83.87% 到 93.96%）的幻觉率仍然很高。

Conclusion: 符号元素继续混淆模型，表明这些 LLM 如何处理此类输入存在根本缺陷——无论其规模如何。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [16] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: 本研究介绍了一种名为ALIGNS的基于大型语言模型的系统，用于构建概念验证的理论图，以解决心理测量中的验证难题。


<details>
  <summary>Details</summary>
Motivation: 验证是心理测量中的一个挑战，它会影响临床试验和公共政策。

Method: 使用经过验证的问卷测量训练大型语言模型ALIGNS，以生成包含超过55万个指标的综合概念验证网络。

Result: ALIGNS提供了三个概念验证网络。通过分类准确性测试和三个评估验证了模型的有效性。评估表明，NIH PROMIS的焦虑和抑郁量表可以合并为单一的情绪困扰维度，并识别了儿童气质测量中未被现有框架捕获的四个潜在维度。

Conclusion: ALIGNS通过大规模的概念验证分析补充了传统的验证方法，可免费使用。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [17] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 该论文提出了一个基于技术之间的时间关系的框架，用于识别新兴技术机会。


<details>
  <summary>Details</summary>
Motivation: 为技术、产业和创新进步奠定基础的关键信息是技术机会。

Method: 该框架从专利数据集中提取文本，然后映射基于文本的主题以发现技术间的关系。通过跟踪这些主题随时间的变化来识别技术机会。为了提高效率，该框架利用大型语言模型来提取主题，并使用prompt来支持技术机会的发现。

Result: 实验结果表明，人工智能技术正在发展成促进日常可访问性的形式。

Conclusion: 该方法论证了所提出的框架在识别未来技术机会方面的潜力。

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [18] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 本文提出了一个轻量级的生物医学实体链接（EL）流水线，用于处理嵌套和多语言提及，在BioNNE 2025比赛中排名第三。


<details>
  <summary>Details</summary>
Motivation: 现有的生物医学文本实体链接主要集中在英语语料库上，忽略了嵌套和多语言提及的实际情况。

Method: 该方法包括：1) 两阶段检索排序，使用相同的编码器模型，但在排序阶段进行领域特定微调；2) 边界线索，在排序阶段使用可学习的[Ms]/[Me]标签标记提及范围；3) 数据集增强，自动扩展排序训练语料库。

Result: 在BioNNE 2025多语言赛道中排名第三，证明了该方法的有效性和竞争力。

Conclusion: 该研究表明，通过最小但有原则的修改，可以有效地处理生物医学文本中嵌套和多语言的实体链接问题。

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [19] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: 论文提出 DocExplainerV0，一个即插即用的边界框预测模块，用于提高 VLM 在文档中定位答案的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 VLM 在文档理解方面表现出色，但在文档中准确定位答案仍然是一个主要挑战，限制了解释性和实际应用。

Method: 提出 DocExplainerV0 模块，将答案生成与空间定位解耦，适用于现有 VLM 系统。

Result: 通过系统评估，量化了文本准确性和空间定位之间的差距，表明正确的答案通常缺乏可靠的定位。

Conclusion: 建立了一个标准化框架，用于突出这些缺点，并为未来研究更可解释和鲁棒的文档信息提取 VLM 建立基准。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [20] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: 本文提出了一种自然语言翻译方法，用于机器可验证的形式化证明，该方法利用了LLM的非形式化（形式语言证明步骤的口头化）和总结能力。


<details>
  <summary>Details</summary>
Motivation: 为了方便人们理解机器可验证的形式化证明

Method: 利用LLM的非形式化和总结能力，将形式化证明翻译成自然语言。

Result: 将该方法应用于根据本科教材中的自然语言证明创建的形式化证明数据，并将生成的自然语言证明的质量与原始自然语言证明进行了比较分析。此外，通过将其应用于Lean proof assistant的现有形式化证明库，证明了该方法可以输出高度可读和准确的自然语言证明。

Conclusion: 该方法在将机器可验证的形式化证明翻译为自然语言方面是有效的。

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [21] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: 提出了一种多智能体框架，通过角色扮演提示来提高特定领域 QA 的性能，该框架包括基本生成器、证据检索器和专家审查器代理，它们以单次迭代工作以生成 refined 的答案。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 方法通常无法捕捉金融问题解决所需的细微和专业的推理。金融领域需要多步骤定量推理、熟悉特定领域的术语以及理解真实世界的场景。

Method: 利用基于角色的提示的多智能体框架，该框架包括基本生成器、证据检索器和专家审查器代理，它们以单次迭代工作以生成 refined 的答案。我们利用检索增强生成 (RAG) 从 6 本金融教科书中获取上下文证据，并为领域专家审查员提供提示策略。

Result: 基于批评的改进将答案准确率提高了 6.6-8.3%，并且使 GPT-4o-mini 能够达到与 FinGPT-mt_Llama3-8B_LoRA 相当的性能。

Conclusion: 结果表明，这是一种经济高效的增强金融 QA 的方法，并为多智能体金融 LLM 系统的进一步研究提供了见解。

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [22] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: 本研究对推特数据情感分析中的机器学习性能进行了荟萃分析。


<details>
  <summary>Details</summary>
Motivation: 旨在评估平均性能，评估研究之间和内部的异质性，并分析研究特征如何影响模型性能。

Method: 使用PRISMA指南，检索学术数据库，选择了20项研究中的195个试验，这些研究具有12个研究特征。使用双反正弦变换和三级随机效应模型分析了报告最多的性能指标总体准确性。

Result: AIC优化模型的平均总体准确度为0.80 [0.76，0.84]。

Conclusion: 总体准确率被广泛使用，但由于其对类不平衡和情感类数量的敏感性，通常具有误导性，这突出了规范化的必要性。模型性能的标准化报告对于跨研究可靠地比较ML分类器至关重要，包括报告独立测试集的混淆矩阵，但这似乎远非普遍做法。

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [23] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: MultimodalHugs 是一个基于 Hugging Face 的框架，旨在促进更多样的数据模式和任务，同时继承 Hugging Face 生态系统的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的工具不够灵活，无法无缝集成手语实验，导致低再现性和不公平的比较。

Method: 构建于 Hugging Face 之上，添加了一层抽象，使其更广泛地适用于不符合 Hugging Face 标准模板的其他用例。

Result: 通过定量实验，展示了 MultimodalHugs 如何适应不同的模式，例如手语的姿势估计数据或文本字符的像素数据。

Conclusion: MultimodalHugs 解决了手语处理研究中工具不够灵活的问题，并为其他不符合 Hugging Face 标准模板的用例提供了更广泛的适用性。

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [24] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: 提出了首个针对中国古代文献的基准测试 AncientDoc，以评估视觉语言模型 (VLM) 在 OCR 和知识推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文档基准主要关注英文印刷文本或简体中文，缺乏针对古代中文文献的 VLM 评估。

Method: 构建了包含五个任务（页面级 OCR、白话翻译、基于推理的 QA、基于知识的 QA、语言变体 QA）的 AncientDoc 基准测试，涵盖 14 种文档类型、100 多本书籍和约 3,000 页。

Result: 使用 AncientDoc 评估了主流 VLM，并使用与人类对齐的大型语言模型进行评分。

Conclusion: AncientDoc 填补了古代中文文献 VLM 评估的空白，为该领域的研究提供了新的资源。

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [25] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: MCP-AgentBench is introduced to address the limitations of existing benchmarks in evaluating language agent performance within the Model Context Protocol (MCP) framework.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks fail to capture real-world agent performance within the MCP paradigm, leading to a distorted perception of their true operational value.

Method: A comprehensive benchmark called MCP-AgentBench is engineered to assess language agent capabilities in MCP-mediated tool interactions. It comprises a robust MCP testbed, a benchmark featuring systematically designed queries, and a novel outcome-oriented evaluation methodology.

Result: Extensive empirical evaluation of leading language agents provides foundational insights.

Conclusion: MCP-AgentBench equips the research community with a standardized and reliable framework to build, validate, and advance agents capable of fully leveraging MCP's transformative benefits.

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [26] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: This paper investigates biases in LLMs (GPT-3.5 and GPT-4o) concerning background, gender, and age in decision-making and summarization tasks, also examining cross-lingual bias propagation and mitigation strategies.


<details>
  <summary>Details</summary>
Motivation: The motivation is the concern about societal inequalities and information bias introduced by the rapid integration of LLMs into various domains.

Method: The method involves using an adapted version of a dataset translated into Dutch to create prompts for decision-making and summarization tasks. Various demographic variables, instructions, salience levels, and languages were tested on GPT-3.5 and GPT-4o.

Result: The results showed significant biases in decision-making, favoring female gender, younger ages, and certain backgrounds. Summarization showed minimal bias. Cross-lingual analysis showed similar bias patterns. Mitigation instructions reduced biases, and GPT-4o displayed reduced biases in English.

Conclusion: The conclusion underscores the importance of cautious adoption of LLMs, context-specific bias testing, and continued development of effective mitigation strategies.

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [27] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: 提出了一种新的参数高效微调策略HEFT，通过在权重空间和表示空间分层组合PEFT方法，提高了LLM在推理任务上的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法在模型权重空间或表示空间中独立运行，计算资源受限。

Method: 提出HEFT，一种分层微调策略，先使用LoRA在权重空间进行粗略的基础适配，再使用ReFT对内部激活进行精确的细化。

Result: 在BoolQ基准测试中，使用HEFT微调Llama-2-7B模型仅3个epoch，准确率达到85.17%，超过了单独使用LoRA或ReFT训练20个epoch的模型。

Conclusion: PEFT方法的巧妙组合是一种有效的算法创新，能够以更少的计算成本提高语言模型的推理能力。

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [28] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 本文提出了一个通过语言和互动姿势之间的关联来建模多模态会话轮次组织的框架。


<details>
  <summary>Details</summary>
Motivation: 会话轮次组织已被多个领域的研究人员研究过，但沟通者使用的具体策略（尤其是姿势）尚未被编码到可用于机器学习的数据集中。

Method: 我们开发了一种注释方法，以使用建模会话轮次组织的语用框架来丰富多模态数据集（已针对语义框架进行注释）。

Result: 我们的结果证实，参与面对面交流的沟通者使用手势作为传递、获取和保持会话轮次的工具，并且还揭示了一些以前未记录的手势变体。

Conclusion: 我们认为，这些手势的使用源于语用框架的概念化，涉及心理空间、混合和概念隐喻。此外，我们的数据表明，语用框架的注释有助于更深入地理解人类认知和语言。

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [29] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 本文提出了一种基于主题引导的强化学习方法，以改进多文档摘要中的内容选择。


<details>
  <summary>Details</summary>
Motivation: 多文档摘要的一个关键挑战是如何有效地整合来自多个来源的信息，同时保持连贯性和主题相关性。虽然大型语言模型在单文档摘要中表现出了令人印象深刻的结果，但它们在多文档摘要中的性能仍有改进空间。

Method: 我们首先表明，用主题标签显式地提示模型可以提高生成摘要的信息量。在此基础上，我们提出了一种新的主题奖励，在群体相对策略优化（GRPO）框架内，衡量生成摘要和源文档之间的主题一致性。

Result: 在Multi-News和Multi-XScience数据集上的实验结果表明，我们的方法始终优于强大的基线。

Conclusion: 强调了在多文档摘要中利用主题线索的有效性

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [30] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)通过使用合成受访者来模仿人类答案和行为，为调查研究中的方法和应用创新提供了有希望的途径，可能减轻测量和表示误差。然而，LLM恢复聚合项目分布的程度仍不确定，下游应用程序可能重现从训练数据继承的社会刻板印象和偏见。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的合成调查回答相对于智利公众意见概率调查的真实人类回答的可靠性。

Method: 基准测试128个提示-模型-问题三元组，生成189,696个合成配置文件，并在128个问题-子样本对的meta分析中汇集性能指标（即，准确率、精确率、召回率和F1分数），以测试沿关键社会人口维度存在的偏差。

Result: 1. 合成回答在信任项目上取得了优异的性能（F1分数和准确率>0.90）。2. GPT-4o、GPT-4o-mini和Llama 4 Maverick在这个任务上的表现相当。3. 合成-人类对齐在45-59岁的受访者中最高。

Conclusion: 基于LLM的合成样本近似于来自概率样本的回答，但项目层面存在很大的异质性。捕捉公众意见的全部细微差别仍然具有挑战性，需要仔细校准和额外的分布测试，以确保算法的保真度并减少误差。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [31] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: 本文全面回顾了法律领域的大型语言模型（LLM），包括模型系列、框架、基准和数据集。


<details>
  <summary>Details</summary>
Motivation: 旨在促进法律人工智能领域中基于LLM方法的研究和应用，提高法律任务的效率和准确性。

Method: 通过综述16个法律LLM系列和47个基于LLM的法律任务框架，并收集15个基准和29个数据集来评估不同的法律能力。

Result: 分析了基于LLM的法律领域方法所面临的挑战。

Conclusion: 为初学者提供系统的介绍，并鼓励未来在该领域的研究。

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [32] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 论文介绍了一个新的中文少数民族语言头条生成数据集（CMHG），包含藏语、维吾尔语和蒙古语。


<details>
  <summary>Details</summary>
Motivation: 由于独特的书写系统与国际标准不同，中国少数民族语言（如藏语、维吾尔语和传统蒙古语）面临着语料库严重缺乏的挑战，特别是对于诸如头条生成之类的监督任务。

Method: 论文构建了一个包含 10 万条藏语条目以及维吾尔语和蒙古语各 5 万条条目的 CMHG 数据集，专门用于头条生成任务。此外，论文还提出了一个由母语人士注释的高质量测试集，旨在作为该领域未来研究的基准。

Result: 论文发布了一个新的数据集，为中文少数民族语言的头条生成任务提供资源。

Conclusion: 该数据集将成为推进中文少数民族语言头条生成并为相关基准发展做出贡献的宝贵资源。

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [33] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为IRIS的无监督幻觉检测框架，用于识别大型语言模型生成的幻觉内容，无需依赖标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法依赖于与事实正确性无关的代理信号，导致检测偏差，泛化能力受限。

Method: IRIS框架利用内部表示，提示LLM仔细验证给定陈述的真实性，并获得其上下文嵌入作为训练的信息特征；同时，将每个响应的不确定性视为真实性的软伪标签。

Result: 实验结果表明，IRIS始终优于现有的无监督方法。

Conclusion: IRIS方法是完全无监督的，计算成本低，即使在少量训练数据下也能很好地工作，适合实时检测。

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [34] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文使用大型语言模型对多标签意图分类进行了广泛的分析，这些模型是开源的、公开可用的，并且可以在消费硬件中运行。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究三种流行的开源预训练LLM（LLama2-7B-hf、Mistral-7B-v0.1 和 Yi-6B）在多标签意图分类任务中的有效性。

Method: 本文在few-shot设置中执行分类任务，在提示中给出20个示例和一些指令。通过在多标签意图分类任务上有条不紊地评估这些模型，重点关注这些模型在几个性能指标上的性能差异。此外，将基于指令的微调方法与使用较小的transformer模型BertForSequenceClassification作为基线的监督学习进行比较。

Result: Mistral-7B-v0.1 在 14 个意图类别中的 11 个上优于其他两个生成模型，加权平均 F-Score 为 0.50。它还具有相对较低的 Humming Loss 和较高的 Jaccard 相似性，使其成为few-shot环境中的获胜模型。发现基于 BERT 的监督分类器具有优于性能最佳的few-shot生成LLM的性能。

Conclusion: 该研究为小型开源LLM检测复杂的多意图对话提供了一个框架，从而增强了面向任务的聊天机器人的自然语言理解能力。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [35] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 本研究利用社交媒体数据，分析了双相情感障碍（BD）患者在诊断前后长达24年的语言变化。


<details>
  <summary>Details</summary>
Motivation: 现有临床评估手段在规模上受限，而社交媒体语言分析具有高时间分辨率和长期范围的优势，因此被重视。

Method: 提出了一种确定用户诊断时间的方法，并分析了BD患者、单相抑郁症（UD）患者和健康对照组（HC）的语言轨迹。

Result: BD诊断伴随着广泛的语言变化，反映了情绪障碍、精神疾病、药物滥用、住院、医学合并症、异常思维内容和思维紊乱。诊断后20年内，情绪相关的语言变化反复出现，并具有明显的12个月周期性，提示季节性情绪发作。女性用户的情绪周期性增加。

Conclusion: 研究结果为BD急性期和慢性期的语言变化提供了证据，验证并扩展了利用社交媒体进行精神健康监测的努力。

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [36] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: MSAs在BAREC 2025阿拉伯语可读性评估比赛中，通过集成多种Transformer模型并采用数据增强等技术，在所有六个赛道中均获得第一名。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语可读性评估中存在的类别不平衡和数据稀缺问题。

Method: 采用加权训练、高级预处理、使用最强模型重新标注SAMER语料库，并通过Gemini 2.5 Flash生成合成数据等方法。

Result: 在句子层面达到87.5% QWK，在文档层面达到87.4% QWK。

Conclusion: 模型和损失多样性、置信度融合以及智能增强技术对于鲁棒的阿拉伯语可读性预测非常有效。

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [37] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 对比研究了传统心理测量问卷和生态学有效问卷在评估大型语言模型（LLM）人格特质和价值观方面的差异，发现传统问卷存在生态效度不足、测量不稳定、产生误导性印象以及夸大prompt效果等问题，不建议用于LLM。


<details>
  <summary>Details</summary>
Motivation: 现有的心理测量问卷被用于评估LLM，但其应用于LLM的合理性受到质疑，尤其是在生态效度方面。研究旨在对比传统问卷和生态学有效问卷在LLM评估中的差异。

Method: 对两种问卷进行了综合对比分析。

Result: 传统问卷与生态学有效问卷对LLM的评估结果差异显著，传统问卷无法准确反映LLM在用户查询上下文中的心理特征，且测量不稳定，容易误导人们认为LLM具有稳定的人格结构，并会夸大角色扮演prompt的效果。

Conclusion: 不建议使用传统的心理问卷来评估LLM。

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [38] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 构建气候科学知识图谱，以改善气候知识的访问和使用。


<details>
  <summary>Details</summary>
Motivation: 气候科学文献的复杂性和数量不断增长，研究人员越来越难以找到跨模型、数据集、区域和变量的相关信息。

Method: 构建一个特定领域的知识图谱，该图谱构建自气候出版物和更广泛的科学文本。

Result: 该知识图谱支持结构化、语义查询，可帮助研究人员发现精确的连接，例如哪些模型已在特定区域得到验证，或者哪些数据集通常与某些遥相关模式一起使用。使用 Cypher 查询展示了 KG 如何回答此类问题，并概述了其与 RAG 系统中大型语言模型的集成，以提高与气候相关的问题解答的透明度和可靠性。

Conclusion: 这项工作超越了 KG 构建，展示了其对气候研究人员、模型开发人员以及其他依赖准确、情境化科学信息的人员的实际价值。

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [39] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: This study fine-tunes large language models (LLMs) for Arabic medical text generation to improve hospital management systems.


<details>
  <summary>Details</summary>
Motivation: Existing hospital management systems (HMS) often lack the ability to provide accurate, real-time medical advice, particularly for irregular inputs and underrepresented languages.

Method: Fine-tuned state-of-the-art generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2 Medium, using a unique dataset from social media platforms, capturing real-world medical conversations between patients and doctors.

Result: The fine-tuned Mistral-7B model outperformed the other models, achieving average BERT Score values in precision, recall, and F1-scores of 68.5%, 69.08%, and 68.5%, respectively.

Conclusion: This study highlights the potential of generative artificial intelligence (AI) in advancing HMS, offering a scalable and adaptable solution for global healthcare challenges, especially in linguistically and culturally diverse environments.

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [40] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展的合成数据增强策略，用于扩展阿拉伯医疗聊天机器人的训练语料库。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯医疗聊天机器人数据集规模小、质量不高，限制了模型的可扩展性和泛化能力。

Method: 利用ChatGPT-4o和Gemini 2.5 Pro生成80,000条医学相关的合成问答对，经过语义过滤和人工验证后整合到训练流程中，并进行了消融研究。

Result: ChatGPT-4o生成的数据在所有模型中都获得了更高的F1分数和更少的幻觉。

Conclusion: 合成数据增强是增强低资源医疗NLP领域特定语言模型的有效方法，为更具包容性、可扩展性和准确性的阿拉伯医疗聊天机器人系统铺平了道路。

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [41] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 本文研究了通过结合突显检测和语音识别来进行会话奥地利德语的突显感知自动语音识别 (ASR)。


<details>
  <summary>Details</summary>
Motivation: 开发突显检测器，通过微调 wav2vec2 模型来分类词级突显。

Method: 我们训练了新的突显感知 ASR 系统，该系统同时转录单词及其突显级别。

Result: 与我们的基线 ASR 系统相比，突显信息的集成并没有改变性能，同时对于识别的单词序列正确的语 音，突显检测准确率达到了 85.53%。

Conclusion: 本文表明，基于 Transformer 的模型可以有效地编码韵律信息，并且代表了对韵律增强 ASR 的新颖贡献，具有语言研究和韵律知情对话系统的潜在应用。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [42] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: 本文提出了一种系统框架，用于合成高质量、人口对齐的 LLM 驱动的社会模拟角色集。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽略了角色生成和非代表性角色集引入的潜在偏差。

Method: 该方法首先利用 LLM 从长期社交媒体数据生成叙事角色，然后进行严格的质量评估以滤除低质量的配置文件。然后，我们应用重要性抽样来实现与参考心理测量分布（例如，大五人格特质）的全局对齐。为了满足特定模拟环境的需求，我们进一步引入了一个任务特定的模块，该模块将全局对齐的角色集调整为目标亚群。

Result: 实验表明，该方法显著降低了人口水平的偏差，并为广泛的研究和政策应用实现了准确、灵活的社会模拟。

Conclusion: 该方法能够为 LLM 驱动的社会模拟合成高质量、人口对齐的角色集，从而减少偏差并提高模拟的准确性和灵活性。

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [43] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 该研究调查了人类和大型语言模型(llm)所撰写的文本的注册变量。Biber的多维分析(MDA)被应用于人类文本和人工智能生成的文本样本，以发现llm与人类差异最大和最系统的维度。作为文本材料，一个新的llm生成的语料库ai-brown被使用，它与be-21(代表当代英国英语的布朗家族语料库)相当。由于除英语外的所有语言在frontier llm的训练数据中都占少数，因此使用ai-koditex语料库和捷克多维模型对捷克语进行了类似的分析。在不同的设置和提示下，检查了16个前沿模型，重点是基本模型和指令调优模型之间的差异。在此基础上，创建了一个基准，通过该基准，模型可以在可解释的维度上相互比较和排序。


<details>
  <summary>Details</summary>
Motivation: 研究人类和大型语言模型（LLM）在文本写作上的注册变量差异。

Method: 应用Biber的多维分析（MDA）方法，对比分析人类书写文本和AI生成文本，使用AI-Brown和AI-Koditex语料库。

Result: 创建了一个基准，用于比较和排序不同模型在可解释维度上的表现。

Conclusion: 该研究旨在通过多维分析，系统地评估LLM在文本生成方面与人类的差异，并为模型比较提供基准。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [44] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: 论文研究了情感支持对话中不协调的积极性问题，尤其是在高风险情况下，大型语言模型（LLM）更容易产生不切实际的积极回应。


<details>
  <summary>Details</summary>
Motivation: 研究动机是发现情感支持对话中，过度或不恰当的积极性表达可能会适得其反，导致回应显得轻视或不真实。

Method: 通过收集Reddit上的用户-助手对话数据，并使用大型语言模型生成额外的回应。将对话按情感强度分为轻度和重度两类，并对不同情感强度下的支持性回应进行比较分析。此外，还通过在具有强烈和微弱情感反应的数据集上微调LLM，并开发了一个弱监督多标签分类器集成来检测不协调的积极性类型。

Result: 研究结果表明，LLM更倾向于通过轻视和最小化的语气来表达不切实际的积极性，尤其是在高风险情境下。所开发的多标签分类器集成了改进了对不协调积极性类型的检测。

Conclusion: 研究强调了在生成支持性回应时，需要超越泛化的积极回应，并研究协调一致的支持措施，以平衡积极情感和情感认可。这有助于使大型语言模型与在线支持性对话中的情感期望保持一致，为开发 context-aware 且保持信任的在线对话系统铺平道路。

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [45] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 本研究探讨了处理长文本的法律和草案分类任务中，XLM-RoBERTa、Longformer、GPT-3.5和GPT-4等模型的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理长文本输入方面存在限制，这对于需要处理长篇法律和草案等分类任务来说是一个紧迫的问题。

Method: 使用XLM-RoBERTa、Longformer、GPT-3.5和GPT-4模型，对比较议程项目的多类分类任务进行了实验，该项目包含21个政策主题标签。

Result: 实验结果表明，专门为处理长输入而预训练的Longformer模型没有明显的优势，GPT变体与表现最佳的开放模型之间的比较显示后者更具优势。

Conclusion: 类别层面的分析表明，在处理长文本输入时，特定类别之间的支持和实质性重叠非常重要。

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [46] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SI FACT 的自提升框架，旨在解决大型语言模型在知识密集型任务中由于知识冲突而产生不忠实回应的问题。该框架利用自指令机制生成高质量的对比学习数据，并通过对比学习训练模型，提高其上下文忠实度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在知识密集型任务中，倾向于依赖内部参数知识而非提供的上下文，导致生成不忠实的回应。

Method: 提出一种自提升框架 SI FACT，使用自指令机制自动生成对比学习数据，包括锚样本、语义等价正样本和模拟不忠实场景的负样本。然后，应用对比学习训练模型，使忠实回应更接近，不忠实回应更远。

Result: 在知识冲突评估基准 ECARE KRE 和 COSE KRE 上，基于 Llama3 8B Instruct 的 SI FACT 模型比最佳基线方法提高了 6.2% 的上下文召回率，并显著降低了对内部记忆的依赖。

Conclusion: SI FACT 在增强大型语言模型的上下文忠实度方面具有很强的有效性和高数据效率，为构建更积极和值得信赖的语言模型提供了一条实用途径。

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [47] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: 提出了一种名为DERN的专家剪枝和重构框架，用于解决SMoE模型部署中的内存使用问题。


<details>
  <summary>Details</summary>
Motivation: SMoE模型虽然计算效率高，但需要加载所有专家参数，导致内存占用高，部署困难。以往工作主要集中在专家层面的操作，忽略了神经元层面的结构。

Method: DERN框架首先使用路由器统计信息剪枝冗余专家，然后将专家分解为神经元级别的专家片段，并将每个片段分配给最兼容的保留专家，最后合并每个保留专家中的片段以构建紧凑的表示。

Result: 在Mixtral、Qwen和DeepSeek SMoE模型上的实验表明，在50%的专家稀疏性下，DERN在常识推理和MMLU基准测试中将性能提高了5%以上，且无需额外训练。它还大大减少了专家数量和内存使用。

Conclusion: DERN框架可以有效提高SMoE模型的性能，减少内存使用，使其更易于实际部署。

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [48] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: 本文分析了上下文学习（ICL）的能力，发现它在学习和泛化到未见过的任务方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 研究ICL是否真正构成学习，以及其学习和泛化能力的限制。

Method: 通过大规模实验分析，消融或考虑了记忆、预训练、分布偏移、提示风格和措辞等因素。

Result: ICL是一种有效的学习范式，但其学习和泛化能力有限。当样本数量增多时，准确率对样本分布、模型、提示风格和输入语言特征不敏感。模型从提示中的规律推断模式，导致分布敏感性。

Conclusion: 自回归的Ad-hoc编码不是一种鲁棒的机制，暗示了有限的通用泛化能力。

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [49] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: Transformer语言模型有长度限制，会影响作文评分。


<details>
  <summary>Details</summary>
Motivation: 高年级学生的文章通常超过了流行的开源模型的最大允许长度。为了解决这个问题，通常的做法是截断输入文本，但这会影响模型捕捉和评估文章组织元素的能力。

Method: 我们评估了几种改进了Transformer架构的模型，以克服长度限制。我们使用了Kaggle ASAP 2.0数据集。

Result: 我们研究了XLNet、Longformer、ModernBERT、Mamba和Llama模型的微调版本。

Conclusion: 我们评估了几种可以克服transformer架构长度限制的模型。

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [50] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 提出了一种新的云边协作架构，以优化大型语言模型 (LLM) 的推理和问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 为了优化大型语言模型 (LLM) 的推理和问题解决能力。现有的基准测试的局限性。

Method: 该框架包括三个专门的组件：GuideLLM、SolverLLM 和 JudgeLLM。引入 RefactorCoderQA，这是一个综合基准，旨在评估和提高大型语言模型 (LLM) 在多领域编码任务中的性能。

Result: RefactorCoder-MoE 实现了最先进的性能，总体准确率达到 76.84%，显着优于领先的开源和商业基线。

Conclusion: 验证了所生成解决方案的可解释性、准确性和实际相关性。此外，我们评估了吞吐量和延迟等系统级指标，以更深入地了解所提出的架构的性能特征和权衡。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [51] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive通过增强LLM的浏览工具来改进深度搜索，但现有开放LLM在这方面表现不佳。DeepDive通过合成复杂问题和应用多轮强化学习来解决这些挑战。


<details>
  <summary>Details</summary>
Motivation: 开放LLM在复杂、真实世界的任务中表现不佳，因为它们在浏览工具方面的长期推理能力有限，并且缺乏足够的监督数据。

Method: 1. 提出了一种自动合成复杂、难以找到的问题的策略，这些问题来自开放知识图谱。2. 应用端到端多轮强化学习（RL）来增强LLM的长期推理能力与深度搜索。

Result: DeepDive-32B在BrowseComp上取得了新的开源竞争结果，优于WebSailor、DeepSeek-R1-Browse和Search-o1。多轮RL训练提高了深度搜索能力，并显著提高了多个基准测试的性能。

Conclusion: DeepDive通过测试时工具调用的扩展和并行采样，提高了深度搜索能力。所有数据集、模型和代码均已公开。

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [52] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE: A text-only adaptation method for ASR models that uses a VAE to model encoder outputs and fine-tunes the decoder.


<details>
  <summary>Details</summary>
Motivation: Pretrained ASR models need domain adaptation for unseen vocabulary, but collecting speech data is often impractical.

Method: Trains a VAE to model encoder outputs from text and fine-tunes the decoder using the learned text-to-latent encoder, optionally combined with TTS adaptation.

Result: WhisTLE with TTS reduces WER by 12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines in 27 of 32 scenarios.

Conclusion: WhisTLE is an effective text-only adaptation method for ASR models.

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [53] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: 介绍了澳大利亚超市物品集（ASOS），一个包含50种易于获得的超市物品的综合数据集，具有高质量的3D纹理网格，专为机器人和计算机视觉应用中的基准测试而设计。


<details>
  <summary>Details</summary>
Motivation: 与依赖合成模型或具有有限可访问性的专用对象的现有数据集不同，ASOS提供了一个经济高效的常见家用物品集合，这些物品可以从澳大利亚的主要连锁超市采购。该数据集跨越10个不同的类别，具有不同的形状、大小和重量。3D网格是通过运动结构技术和高分辨率成像获得的，以生成防水网格。该数据集强调可访问性和实际应用，使其对于基准测试对象检测、姿态估计和机器人应用非常有价值。

Method: 通过运动结构技术和高分辨率成像获取3D网格，以生成防水网格。

Result: 该数据集包含50个易于获得的超市物品，具有高质量的3D纹理网格，跨越10个不同的类别，具有不同的形状、大小和重量。

Conclusion: 该数据集对于基准测试对象检测、姿态估计和机器人应用非常有价值。

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [54] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态检索增强生成 (MM-RAG) 框架，用于自然灾害后房屋损坏评估。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后，对房屋损坏的准确评估对于保险理赔响应和资源规划非常重要。

Method: 该框架设计了一个双分支多模态编码器结构，图像分支采用由 ResNet 和 Transformer 组成的视觉编码器，以提取灾后建筑物损坏的特征，文本分支利用 BERT 检索器对帖子和保险单进行文本向量化，并构建可检索的修复索引。为了实现跨模态语义对齐，该模型集成了一个跨模态交互模块，以通过多头注意力桥接图像和文本之间的语义表示。同时，在生成模块中，引入的模态注意力门控机制动态地控制视觉证据和文本先验信息在生成过程中的作用。

Result: 在损坏严重程度的检索准确率和分类指标方面表现出卓越的性能，其中 Top-1 检索准确率提高了 9.6%。

Conclusion: MM-RAG 框架通过协作学习实现了图像理解和策略匹配，并在灾后房屋损坏评估方面取得了显著成果。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [55] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 提出了一种新的集成框架，通过 Gemini 2.0 Flash 转录图像的多个增强变体，并使用 Needleman Wunsch 风格的对齐器融合这些输出，从而稳定从嘈杂的历史文档中提取基于 LLM 的文本。


<details>
  <summary>Details</summary>
Motivation: 从嘈杂的历史文档中提取基于 LLM 的文本。

Method: 使用 Gemini 2.0 Flash 转录图像的多个增强变体，并使用 Needleman Wunsch 风格的对齐器融合这些输出。

Result: 在一个包含 622 份宾夕法尼亚州死亡记录的新数据集上，该方法比单次基线提高了 4 个百分点的转录准确率。填充和模糊最有利于提高准确率，而网格扭曲扰动最适合区分高置信度和低置信度的情况。

Conclusion: 该方法简单、可扩展，并且可以立即部署到其他文档集合和转录模型。

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [56] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: This paper introduces MITS, a new large-scale multimodal dataset for Intelligent Traffic Surveillance (ITS).


<details>
  <summary>Details</summary>
Motivation: Existing large multimodal models (LMMs) have limited performance in the ITS domain due to the lack of dedicated datasets.

Method: The authors collected 170,400 real-world ITS images and generated image captions and 5 million instruction-following visual question-answer pairs. They then fine-tuned mainstream LMMs on this dataset.

Result: MITS significantly improves LMM performance in ITS applications, with substantial gains observed for LLaVA-1.5, LLaVA-1.6, Qwen2-VL, and Qwen2.5-VL.

Conclusion: The authors release the dataset, code, and models as open-source, providing valuable resources for advancing ITS and LMM research.

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [57] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 该论文研究了基于树结构的推理是否可以提高视觉语言模型（VLM）在细粒度任务和大型分层标签空间中的性能。结果表明，尽管模型在理解树结构知识方面表现出色，但基于树的推理始终不如标准的零样本提示。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型（VLM）在细粒度任务和大型分层标签空间中的性能，并探讨结构化、基于树的推理是否可以提高VLM的性能。

Method: 引入一个框架，该框架使用决策树将分类分解为可解释的决策，并在细粒度（GTSRB）和粗粒度（CIFAR-10）数据集上进行评估。还探索了使用LLM生成的类和图像描述来增强树提示以改善对齐。

Result: 模型在理解树结构知识方面达到了98.2%的准确率，但基于树的推理始终不如标准的零样本提示。添加的描述增强了基于树的方法和零样本方法的性能。

Conclusion: 研究结果突出了结构化推理在视觉分类中的局限性，并为设计更易于解释的VLM系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [58] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI: A system for learning controllable and promptable world models from data.


<details>
  <summary>Details</summary>
Motivation: Learning richly controllable and flexibly promptable world models from data.

Method: A three-step cycle: Probabilistic prediction, Structure extraction via causal inference, and Integration of structures as new token types.

Result: Trained PSI on 1.4 trillion tokens of internet video data, achieving state-of-the-art optical flow, self-supervised depth and object segmentation.

Conclusion: Each cycle augments PSI's capabilities, improving data modeling and creating new control handles.

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [59] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 本文首次分析了联邦学习中视频数据在梯度反演攻击下的泄露情况，实验表明使用预训练特征提取器可以提高对梯度反演攻击的抵抗力，但如果分类器不够复杂，仍然可能发生泄露。


<details>
  <summary>Details</summary>
Motivation: 联邦学习(FL) 允许多个实体协作训练共享模型，其核心是保护隐私，但梯度反演攻击威胁着这种机制的安全性，它可以直接从共享梯度中逆向工程出私有训练数据。虽然这些攻击对图像、文本和表格数据的影响是已知的，但它们对视频数据的影响仍然是一个未研究的领域。

Method: 本文评估了两种常见的视频分类方法：一种采用预训练特征提取器，另一种处理具有简单转换的原始视频帧。使用了图像超分辨率技术来增强通过梯度反演攻击提取的帧，从而重建更高质量的视频。

Result: 初始结果表明，使用特征提取器可以更好地抵抗梯度反演攻击。图像超分辨率技术可以增强通过梯度反演攻击提取的帧，从而使攻击者能够重建更高质量的视频。即使攻击者可以访问来自目标环境的零个、一个或多个参考帧，我们的实验也验证了这一点。

Conclusion: 视频数据在联邦学习中的泄露是一种可行的威胁，值得进一步调查。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [60] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 提出了一种半监督协同训练框架，用于在密集零售环境中进行物体检测。


<details>
  <summary>Details</summary>
Motivation: 在有限的标记数据和复杂条件下，零售环境中的物体检测面临重大挑战。

Method: 该框架结合了 Faster R-CNN 和 YOLO，实现相互伪标签交换，并采用 XGBoost、随机森林和 SVM 的集成来加强分类。使用元启发式驱动的算法优化超参数。

Result: 在 SKU-110k 数据集上的实验表明，该方法具有强大的性能。

Conclusion: 该方法减少了对人工标注的依赖，并能有效适应零售中频繁的产品和布局变化，适用于自动化库存跟踪、产品监控和结账系统等实际零售应用。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [61] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出了一种名为 Token Purging (PG) 的新方法，用于解决 3D 点云分类中测试时适应 (TTA) 的问题，该方法无需反向传播即可移除受域偏移影响较大的 tokens。


<details>
  <summary>Details</summary>
Motivation: 解决 3D 点云分类中由于分布偏移导致的性能下降问题。

Method: 提出 Token Purging (PG) 方法，通过移除受域偏移影响较大的 tokens 来实现鲁棒的适应，包含 PG-SP (利用源统计) 和 PG-SF (完全无源) 两个变体。

Result: 在 ModelNet40-C、ShapeNet-C 和 ScanObjectNN-C 数据集上，PG-SP 比现有最佳无反向传播方法平均高出 +10.3% 的准确率，PG-SF 为无源适应设置了新的基准。PG 比基线方法快 12.4 倍，内存效率高 5.5 倍。

Conclusion: Token Purging 方法在 3D 点云分类的测试时适应方面表现出色，具有更高的准确率、更快的速度和更高的内存效率，适合实际部署。

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [62] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 提出了一种精确且高度可解释的细粒度跨视角定位方法，通过将地面图像的局部特征与参考航拍图像匹配来估计地面图像的 3 自由度姿势。


<details>
  <summary>Details</summary>
Motivation: 先前的方法通常将地面图像转换为鸟瞰图 (BEV) 表示，然后将其与航拍图像对齐以进行定位。但是，由于透视失真或高度信息的压缩，这种转换通常会导致信息丢失，从而降低与航拍视图的对齐质量。

Method: 我们的方法直接建立地面图像和航拍图像之间的对应关系，并仅使用单眼深度先验将匹配的关键点提升到 BEV 空间。该方法支持度量深度和相对深度，并采用尺度感知 Procrustes 对齐来估计相机姿势，并可在使用相对深度时选择性地恢复尺度。

Result: 实验结果表明，仅在相机姿势的弱监督下，我们的方法可以学习准确的局部特征对应关系，并在具有挑战性的条件下实现卓越的定位性能，例如跨区域泛化和未知方向。

Conclusion: 该方法与各种相对深度模型兼容，无需每个模型进行微调。这种灵活性以及强大的定位性能使其非常适合实际部署。

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [63] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 本研究介绍了一款名为 KidsVisionCheck 的免费应用程序，该程序使用红眼反射图像在移动设备上进行视力筛查。


<details>
  <summary>Details</summary>
Motivation: 在红眼反射图像中可以检测到许多儿童的视觉障碍。传统的 Bruckner 测试由眼科医生在临床环境中进行。由于智能手机和人工智能的最新技术进步，现在可以使用移动设备重新创建 Bruckner 测试。

Method: 该模型依赖于在儿童瞳孔图像上训练的深度神经网络，这些图像由眼科医生收集和标记。

Result: 在未见过的测试数据上，我们的模型具有 90% 的准确率，无需专业设备即可提供高度可靠的性能。

Conclusion: 这项工作标志着朝着实现可访问的儿童视力筛查和全球范围内对视力异常的早期干预迈出的第一步。

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [64] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 提出了一种新的深度引导多模态融合方法，通过整合深度信息来升级条件感知融合，从而实现鲁棒的语义感知。


<details>
  <summary>Details</summary>
Motivation: 现有的语义感知传感器融合方法通常在输入的空间范围内统一处理传感器数据，这在面对具有挑战性的条件时会阻碍性能。

Method: 将多模态分割作为一个多任务问题，利用激光雷达测量数据作为模型的输入和学习深度的 ground truth。利用对应的辅助深度头来学习深度感知特征，这些特征被编码成空间变化的局部深度 tokens，从而调节注意力跨模态融合。此外，还提出了一种鲁棒的深度损失。

Result: 在具有挑战性的 MUSES 和 DELIVER 数据集上实现了最先进的全景和语义分割性能。

Conclusion: DGFusion 是一种有效的深度引导多模态融合方法，能够在具有挑战性的条件下提升语义感知性能。

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [65] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 提出了一种基于ResNet-18的新的基于patch的自动玫瑰痤疮检测策略。


<details>
  <summary>Details</summary>
Motivation: 为了提高治疗效果，通常需要精确和早期地检测玫瑰痤疮，这是一种慢性炎症性皮肤病，表现为面部发红、丘疹和可见的血管。

Method: 从不同大小、形状和位置的人脸图像中提取各种图像块，并进行大量调查研究，以评估局部视觉信息如何影响深度学习模型的性能。

Result: 几个基于patch的自动玫瑰痤疮检测策略比基于全图像的方法具有竞争力或更高的准确性和灵敏度。提出的基于patch的策略只使用局部patch，通过从数据中排除任何可识别的面部特征，固有地保护患者隐私。

Conclusion: 实验结果表明，提出的基于patch的策略引导深度学习模型关注临床相关区域，增强鲁棒性和可解释性，并保护患者隐私。因此，该策略为改进自动皮肤病学诊断提供了实用的见解。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [66] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文提出了一种新的保护隐私的玫瑰痤疮自动检测方法，该方法使用完全在合成数据上训练的模型。


<details>
  <summary>Details</summary>
Motivation: 由于玫瑰痤疮症状的弥散性、标记数据集的稀缺性以及与使用可识别面部图像相关的隐私问题，因此自动检测仍然具有挑战性。

Method: 该方法首先构建一个固定的、以红色为信息的掩模，选择面部图像中红色通道强度始终较高的区域。然后，使用在带掩模的合成图像上训练的 ResNet-18 深度学习方法。

Result: 该方法在真实世界测试数据上进行评估时，与全脸基线相比，在准确率、召回率和 F1 分数方面取得了显著提升。

Conclusion: 实验结果表明，合成数据和临床先验可以共同实现准确且合乎道德的皮肤病人工智能系统，特别是在远程医疗和大规模筛查等隐私敏感应用中。

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [67] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文对用于腹腔镜图像去烟的ULW框架进行了全面的消融研究，旨在评估各个组件的有效性和必要性。


<details>
  <summary>Details</summary>
Motivation: 评估ULW框架中各个组件的有效性和必要性。

Method: 通过系统地去除ULW框架中的各个组件（可学习维纳滤波器、复合损失函数中的单个损失项），来评估每个组件对整体性能的贡献。在公开的配对腹腔镜图像数据集上，使用定量指标（SSIM、PSNR、MSE和CIEDE-2000）和定性视觉比较对所有变体进行基准测试。

Result: 通过消融实验，评估了ULW框架中各个组件对整体性能的贡献。

Conclusion: 通过消融研究，确定了ULW框架中每个组件的有效性和必要性。

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [68] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: 本文提出了一种多模态无人机检测器WAVE-DETR，它结合了可见光RGB和声学信号，用于鲁棒的真实无人机目标检测。该方法在统一的目标检测器模型中融合了视觉和声学特征，依赖于Deformable DETR和Wav2Vec2架构，在具有挑战性的环境条件下实现了强大的性能。


<details>
  <summary>Details</summary>
Motivation: 在现实环境中，无人机目标检测面临挑战，需要结合多种模态的信息来提高检测的鲁棒性。

Method: 该方法融合了Deformable DETR的视觉特征和Wav2Vec2的声学嵌入，并开发、训练和测试了四种不同的融合配置，包括门控机制、线性层、MLP和交叉注意力。

Result: 门控融合方法在ARDrone数据集上将Deformable DETR目标检测器的mAP提高了11.1%到15.3%（针对小型无人机），中型和大型无人机的mAP也有所提高，所有无人机尺寸的总体增益范围为3.27%到5.84%。

Conclusion: 声学信息可以有效提高Deformable DETR目标检测器在真实ARDrone数据集上的性能。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [69] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 本文提出了一种新的训练范式，称为代理监督，以提高配准网络的鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的可变形图像配准对输入图像特征的变化敏感，例如伪影、视场不匹配或模态差异。

Method: 通过将估计的空间变换应用于代理图像，将输入域与监督域分离。这允许在异构输入上进行训练，同时确保在相似性明确定义的域中计算监督。

Result: 在各种任务中，代理监督表现出对输入变化的强大恢复能力，同时保持了在精心管理的数据上的高性能。

Conclusion: 代理监督提供了一个原则性的框架，用于训练鲁棒和可泛化的基于深度学习的配准模型，而不会增加复杂性。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [70] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 本研究旨在提高牙齿年龄估计等高风险法医应用中深度学习模型的性能和透明度。


<details>
  <summary>Details</summary>
Motivation: 法医应用中深度学习模型的“黑盒”性质限制了其应用。本研究旨在解决这个问题。

Method: 结合卷积自编码器 (AE) 和 Vision Transformer (ViT) 的框架。

Result: 对于牙齿 37，分类准确率从 0.712 提高到 0.815；对于牙齿 38，从 0.462 提高到 0.543。分析表明，剩余的性能差距是数据中心的，提示牙齿 38 数据集中较高的类内形态变异性是主要的限制因素。

Conclusion: 该框架通过提高准确性并提供模型不确定原因的证据，为法医年龄估计中的专家决策提供更强大的支持。

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [71] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: 本文提出了一种新的Source-Free Domain Adaptation (SFDA)方法，名为Self-supervised Continual Domain Adaptation (SCoDA)，该方法避免了对监督预训练的依赖，并利用几何流形对齐原理。


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法依赖于cosine相似度，忽略了源模型潜在流形的关键几何信息。

Method: SCoDA使用自监督预训练初始化模型，并采用结合实例级特征匹配和空间相似性损失的复合目标训练学生模型。教师模型参数通过学生模型参数的指数移动平均(EMA)更新，以对抗灾难性遗忘。

Result: 在基准数据集上的大量实验表明，SCoDA显著优于最先进的SFDA方法。

Conclusion: SCoDA是一种有效的SFDA方法，它通过避免监督预训练和利用几何流形对齐原理，提高了模型在目标域上的性能。

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [72] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 提出了一种新的细胞追踪框架，该框架不需要任何手动标记的数据集进行训练，并且可以推广到不同的显微镜数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的方法依赖于手动标记的数据集进行训练，这既昂贵又耗时，而且由于显微镜数据的巨大多样性，它们对未见数据集的泛化能力仍然有限。

Method: 通过将 Segment Anything 2 (SAM2) 集成到跟踪流程中，我们提出了一个 zero-shot 细胞跟踪框架。

Result: 我们的方法在 2D 和大规模 3D 延时显微镜视频中都实现了具有竞争力的准确性，同时消除了对数据集特定调整的需要。

Conclusion: 我们提出的方法是一种完全无监督的方法，它不依赖于或继承来自任何特定训练数据集的偏差，使其能够推广到不同的显微镜数据集，而无需进行微调。

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [73] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 本论文提出了一种将现有的2D多摄像头跟踪系统扩展到3D空间的方法，利用深度信息重建点云空间中的目标，并通过聚类和偏航细化恢复其3D框。


<details>
  <summary>Details</summary>
Motivation: 现有的MTMC系统难以直接在3D空间进行跟踪，因为需要从头开始替换所有2D跟踪组件。

Method: 利用深度信息重建点云空间中的目标，并通过聚类和偏航细化恢复其3D框；引入增强的在线数据关联机制，利用目标的局部ID一致性来跨帧分配全局ID。

Result: 在2025 AI City Challenge的3D MTMC数据集上取得了第三名的成绩。

Conclusion: 该框架在3D MTMC任务上表现良好。

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [74] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: 本文提出了一种零样本的指代表达式理解(REC)方法，无需任何REC特定的训练，即可实现有竞争力甚至更优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的REC方法通常使用任务训练的 grounding 模型。本文旨在探索一种无需特定训练的零样本方法，以实现更好的性能。

Method: 该方法将REC重构为box-wise视觉-语言验证：给定来自COCO-clean通用检测器(YOLO-World)的提议，通用VLM独立地回答每个区域的True/False查询。 

Result: 在RefCOCO、RefCOCO+和RefCOCOg上，该方法不仅超过了零样本GroundingDINO基线，而且超过了在REC上训练的GroundingDINO和GroundingDINO+CRG的报告结果。

Conclusion: 工作流程设计，而不是特定于任务的预训练，驱动了强大的零样本REC性能。

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [75] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 本文提出了一种随机投影复制粘贴（RPCP）的增强技术，以解决小麦叶面病虫害分割中像素不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 有效的小麦作物管理和病虫害防治需要准确分割叶面病虫害，但昆虫损害通常只占注释像素的很小一部分。这种极端的像素级不平衡对分割性能提出了重大挑战。

Method: 从带注释的训练图像中提取罕见的虫害斑块，并应用随机几何变换来模拟变化。然后将变换后的斑块粘贴在适当的区域，同时避免与病变或现有损坏区域重叠。此外，我们对粘贴区域应用随机投影滤波器，细化局部特征，并确保与新背景的自然融合。

Result: 实验表明，该方法显著提高了昆虫损害类别的分割性能，同时保持甚至略微提高了其他类别的准确性。

Conclusion: 我们的结果强调了有针对性的增强在减轻极端像素不平衡方面的有效性，为农业分割问题提供了一种简单而有效的解决方案。

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [76] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 提出了一种新的框架，结合不确定的身份和跟踪，使用隐马尔可夫模型（HMM）公式，以解决长期多目标跟踪（MOT）的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于需要分析跨越几分钟的视频中的个体行为，对长期多目标跟踪（MOT）的需求正在增长。现有的 MOT 方法的跟踪性能会随着时间的推移而降低，使其难以应用于长期跟踪。在许多实际应用中，例如在畜牧业中，可以从饲养器等来源获得一些动物的零星识别。

Method: 结合不确定的身份和跟踪，使用隐马尔可夫模型（HMM）公式。

Result: 在 10 分钟的猪跟踪数据集上，即使使用重新识别，我们的 HMM 框架也提高了 ByteTrack 的 F1 分数，在围栏的喂食站有 21 个识别。我们的方法对身份的不确定性具有鲁棒性，随着身份提供频率的增加，性能也会提高。使用 ByteTrack 和 FairMOT 在 MOT17 和 MOT20 基准数据集上验证了我们的 HMM 框架的改进性能。

Conclusion: 该论文提出了一个新框架，该框架结合了不确定的身份和跟踪，使用隐马尔可夫模型公式，以解决长期多目标跟踪的挑战。

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [77] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 本研究探讨了事件相机与传统帧捕获融合的演变，重点介绍了这种协同作用如何显着地促进各种视频恢复和3D重建任务。


<details>
  <summary>Details</summary>
Motivation: 事件相机传感器是一种仿生传感器，它可以异步捕获每个像素的亮度变化，并输出一个包含这些变化的极性、位置和时间的事件流。由于其低延迟、低功耗和超高捕获率，这些系统正在作为一个新兴领域迅速发展。

Method: 本文系统地回顾了图像/视频增强和恢复领域的主要深度学习成果，重点关注两个维度：时间增强（如帧插值和运动去模糊）和空间增强（包括超分辨率、弱光和HDR增强以及伪影减少）。

Result: 本文还探讨了3D重建领域如何随着事件驱动融合的进步而发展。涵盖了不同的主题，并深入讨论了在具有挑战性的条件下提高视觉质量的最新工作。此外，本调查还编制了一个全面的公开数据集列表，从而能够进行可重复的研究和基准测试。

Conclusion: 通过巩固最近的进展和见解，本调查旨在激发人们对利用事件相机系统（尤其是与深度学习相结合）进行高级视觉媒体修复和增强的进一步研究。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [78] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: 提出了一种新的基于Transformer的ANN-SNN混合跟踪器，名为ISTASTrack，用于RGB-Event跟踪，该跟踪器配备了ISTA适配器。


<details>
  <summary>Details</summary>
Motivation: 现有的ANN难以充分利用事件流的稀疏性和异步性，而现有的混合架构在融合异构范式特征方面存在挑战。

Method: 该模型采用视觉Transformer提取RGB输入的空间上下文，并采用Spiking Transformer捕获事件流的时空动态。设计了一个基于模型的ISTA适配器，用于ANN和SNN分支之间的双向特征交互，并结合了一个时间下采样注意力模块，以对齐多步SNN特征与单步ANN特征。

Result: 在FE240hz、VisEvent、COESOT和FELT等RGB-Event跟踪基准测试中，ISTASTrack取得了最先进的性能，同时保持了较高的能源效率。

Conclusion: 混合ANN-SNN设计对于鲁棒视觉跟踪是有效和实用的。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [79] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 本文提出了一种新的太阳耀斑预测模型，该模型基于多个深度状态空间模型，并引入了频率和局部边界感知可靠性损失（FLARE 损失），以提高在类别不平衡情况下的预测性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前太阳耀斑预测的准确性和可靠性不足，无法充分应对耀斑类别之间的严重类别不平衡问题。

Method: 提出了一种基于多个深度状态空间模型的太阳耀斑预测模型，并引入了 FLARE 损失。

Result: 该方法在 Gandin-Murphy-Gerrity 分数和真技能统计方面优于基线方法。

Conclusion: 该方法在性能和可靠性方面均优于现有方法，可用于太阳耀斑预测。

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [80] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: 提出了一种名为TUNI的RGB-T语义分割模型，该模型通过多模态特征提取和跨模态融合来提高自主平台在复杂环境下的环境感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在RGB-T语义分割中存在热特征提取有限、跨模态融合不佳以及编码器冗余导致实时效率降低的问题。

Method: 设计了一个RGB-T编码器，该编码器包含多个堆叠块，可以同时执行多模态特征提取和跨模态融合。此外，还引入了一个RGB-T局部模块，以增强编码器进行跨模态局部特征融合的能力。

Result: TUNI在FMB、PST900和CART数据集上取得了与最先进模型相当的性能，同时具有更少的参数和更低的计算成本。在Jetson Orin NX上实现了27 FPS的推理速度。

Conclusion: TUNI模型具有实时部署能力，并在RGB-T语义分割任务上表现出竞争力。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [81] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的少样本字体生成模型，该模型基于一组局部设计元素（即局部形状）设计整个字体。


<details>
  <summary>Details</summary>
Motivation: 传统的小样本字体生成需要一些字符类的完整字符形状，但该方法只需要局部形状作为输入。该模型提高了字体创建的效率，并提供了关于局部设计细节如何影响单个字符的整体结构的见解。

Method: 设计了一种基于局部设计元素的少样本字体生成模型。

Result: 该模型提高了字体创建的效率。

Conclusion: 局部设计细节影响单个字符的整体结构

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [82] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 本论文提出了一种高效且准确的VIO流水线，专为微型和纳米无人机应用而优化。


<details>
  <summary>Details</summary>
Motivation: 当前VIO流水线难以在超低功耗芯片上实现高精度和实时性。

Method: 该设计结合了最先进的特征检测和跟踪方法（SuperPoint，PX4FLOW，ORB），并针对RISC-V架构的超低功耗并行SoC进行了优化和量化。采用了刚体运动模型以减少估计误差。

Result: 在GAP9低功耗SoC上，优化后的流水线在使用ORB特征跟踪器时，RMSE平均降低了高达3.65倍。PX4FLOW在低于24像素/帧的移动速度下，实现了与ORB相当的跟踪精度，但运行时间更短。

Conclusion: 该设计弥合了传统上运行在计算能力强大的系统上的高精度VIO流水线与适用于微控制器的轻量级实现之间的差距。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [83] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 本文提出了一种基于卷积神经网络的 Hierarchical Multi-Level Attention Network (MLANet)，用于从单张真实图像重建 3D 人脸模型。


<details>
  <summary>Details</summary>
Motivation: 从 2D 真实图像中恢复 3D 人脸模型因其广泛的潜在应用而备受关注。然而，缺乏 ground-truth 标记数据集和现实世界环境的复杂性仍然是巨大的挑战。

Method: 该模型预测来自单个图像的详细面部几何形状、纹理、姿势和光照参数。具体来说，我们采用预训练的分层骨干网络，并在 2D 人脸图像特征提取的不同阶段引入多层次注意力机制。采用半监督训练策略，结合来自公开数据集的 3D Morphable Model (3DMM) 参数以及可微渲染器，从而实现端到端训练过程。

Result: 在两个基准数据集 AFLW2000-3D 和 MICC Florence 上进行了广泛的实验，包括比较研究和消融研究，重点关注 3D 人脸重建和 3D 人脸对齐任务。对所提出方法的有效性进行了定量和定性评估。

Conclusion: 提出的 MLANet 在 3D 人脸重建和对齐任务上表现有效。

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [84] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是一个多语言视觉CoT框架，通过多方面奖励优化，提高多语言VQA的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多语言多模态推理方面的支持有限，限制了它们在实际应用中的部署。

Method: 引入LaV-CoT，包含文本摘要与边界框、语言识别、空间对象级字幕和逐步逻辑推理等多个阶段。采用结合监督微调（SFT）和语言感知组相对策略优化（GRPO）的两阶段训练模式。

Result: 在MMMB、Multilingual MMBench和MTVQA等公共数据集上，LaV-CoT的准确率比类似规模的开源基线提高了高达9.5％，甚至超过了规模大2倍的模型的2.6％。优于GPT-4o-0513和Gemini-2.5-flash等先进的专有模型。

Conclusion: LaV-CoT在真实世界数据上的在线A/B测试验证了其有效性，突出了其在工业部署方面的潜力。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [85] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 当前文本到图像 (T2I) 生成模型在颜色对齐方面存在问题，尤其是在处理细微和复合颜色术语时。该论文提出了一个无需训练的框架，利用大型语言模型 (LLM) 来消除颜色相关提示的歧义，并通过在文本嵌入空间中直接指导颜色混合操作来提高颜色保真度。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在文本到图像生成中难以处理细微和复合颜色术语，导致生成的图像与人类意图不符。现有方法无法系统地解决歧义颜色描述。

Method: 该方法利用大型语言模型 (LLM) 来消除文本提示中歧义颜色术语，并根据 CIELAB 颜色空间中生成的颜色术语的空间关系来优化文本嵌入。

Result: 实验结果表明，该框架提高了颜色对齐的准确性，且不影响图像质量。

Conclusion: 该方法在不进行额外训练或使用外部参考图像的情况下，提高了颜色准确性，弥合了文本语义和视觉生成之间的差距。

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [86] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: 提出了AVI-Math，一个用于评估无人机图像中多模态数学推理能力的新基准。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型(VLMs)在无人机遥感领域中进行精确距离和面积计算、轨迹估计和空间分析等任务时，缺乏足够的数学推理能力测试。

Method: 构建了一个包含3773个高质量、与车辆相关的问题的数据集，这些问题来自无人机视角，涵盖6个数学主题和20个话题。通过综合评估，对14个著名的VLMs进行了基准测试。

Result: 结果表明，尽管这些模型在之前的多模态基准测试中取得了成功，但在AVI-Math的推理任务中却表现不佳。通过思维链提示和微调技术，在解决AVI-Math中的推理挑战方面显示出希望。

Conclusion: 揭示了VLMs在数学推理方面的局限性，并为推进基于无人机的、值得信赖的VLMs在实际应用中提供了有价值的见解。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [87] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: 提出了一种名为BEVTraj的新轨迹预测框架，该框架直接在鸟瞰图（BEV）空间中运行，利用实时传感器数据，无需任何预先构建的地图。


<details>
  <summary>Details</summary>
Motivation: 为了提高预测精度，最近的方法通常依赖于预先构建的高清（HD）地图或实时局部地图构建模块来合并静态环境信息。然而，预先构建的HD地图仅限于特定区域，无法适应瞬时变化。此外，仅识别预定义元素的局部地图构建模块可能无法捕获关键场景细节或引入降低预测性能的错误。

Method: BEVTraj利用可变形注意力来有效地从密集的BEV特征中提取相关上下文。此外，我们还引入了一个稀疏目标候选提议（SGCP）模块，该模块支持完全端到端的预测，而无需任何后处理步骤。

Result: BEVTraj的性能与最先进的基于HD地图的模型相当，同时通过消除对预构建地图的依赖性，提供了更大的灵活性。

Conclusion: BEVTraj在没有预构建地图的情况下，实现了与基于高清地图的模型相媲美的性能，且更灵活。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [88] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 该论文提出了一种新的训练框架，利用多视角信息来改进遮挡情况下的多人解析模型。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在分割身体重叠的人时效果不佳。

Method: 该方法集成了多视角知识，提出了一种基于弱监督和多视角一致性损失的新方法。此外，还提出了一种半自动标注策略，用于从多视角 RGB+D 数据和 3D 人体骨骼生成人体实例分割 mask。

Result: 该方法在遮挡场景下，人体解析的性能相对于基线模型有高达 4.20% 的相对提升。

Conclusion: 该论文提出了一种有效的多视角训练框架，可以提高在遮挡场景下多人解析的性能。

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [89] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0 is a bilingual (Korean/English) vision-language model (VLM) with improved capabilities compared to its predecessor. It supports multi-image understanding, layout-aware OCR, and achieves strong spatial grounding.


<details>
  <summary>Details</summary>
Motivation: To advance the development of bilingual VLMs and their practical applications.

Method: Trained with a four-stage curriculum using memory-efficient techniques and preference optimization.

Result: Achieves enhanced multimodal alignment, preserves core language abilities, improves safety, and demonstrates strong spatial grounding. The 14B model achieves 8th place on the OpenCompass VLM leaderboard among models of comparable scale.

Conclusion: The release of both a 14B-scale and a 1.7B version of VARCO-VISION-2.0 advances bilingual VLMs and their applications.

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [90] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 提出了一种轻量级高效的用于人脸图像质量评估 (FIQA) 的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法捕捉到人脸特有的退化，并且计算量大，限制了它们的实际应用。

Method: 集成了两个紧凑的卷积神经网络 MobileNetV3-Small 和 ShuffleNetV2，通过简单平均进行预测级别的融合。采用了一种 correlation-aware loss (MSECorrLoss)，将均方误差 (MSE) 与 Pearson 相关正则化器相结合。

Result: 在 VQualA FIQA 基准测试中，Spearman 等级相关系数 (SRCC) 达到 0.9829，Pearson 线性相关系数 (PLCC) 达到 0.9894。

Conclusion: 该方法在准确性和计算成本之间取得了很好的平衡，适用于实际部署。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [91] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种用于真实图像超分辨率 (Real-ISR) 的 Realism Controlled One-step Diffusion (RCOD) 框架，该框架通过潜在域分组策略、降级感知采样策略和视觉提示注入模块，实现了保真度和真实感之间的灵活控制，并在计算效率上优于现有的单步扩散 (OSD) 方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单步扩散 (OSD) 方法在平衡真实感和保真度方面存在局限性，缺乏灵活的控制机制来适应不同的场景。

Method: 提出了一种 Realism Controlled One-step Diffusion (RCOD) 框架，包括潜在域分组策略、降级感知采样策略和视觉提示注入模块。

Result: RCOD 在定量指标和视觉质量上均优于现有的 OSD 方法，并具有灵活的真实感控制能力。

Conclusion: RCOD 框架能够有效地平衡真实感和保真度，并在 Real-ISR 任务中取得了优异的性能。

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [92] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: 提出了一种名为 Grad-CL 的新颖的无源域适应框架，用于解决视盘和视杯分割模型在不同成像条件下性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 在一种数据集上训练的分割模型在应用于不同成像协议或条件下获取的目标数据时，通常会出现显著的性能下降。因此，论文旨在解决跨域眼底图像分割问题。

Method: Grad-CL 结合了梯度引导的伪标签细化模块和基于余弦相似度的对比学习策略。首先，通过基于梯度的机制提取显著的类别特定特征，从而实现更准确的不确定性量化和稳健的原型估计，以细化嘈杂的伪标签。其次，采用基于余弦相似度的对比损失来明确地加强视杯和视盘的梯度信息特征之间的类间可分离性。

Result: 在具有挑战性的跨域眼底图像数据集上进行的大量实验表明，Grad-CL 优于最先进的无监督和无源域适应方法，实现了卓越的分割精度和改进的边界划分。

Conclusion: Grad-CL 是一种有效的无源域适应框架，可以提高视盘和视杯分割的准确性和鲁棒性。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [93] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为VQBridge的改进型向量量化（VQ）方法，旨在解决VQ训练中的不稳定问题，提高codebook的利用率和重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VQ训练方法存在straight-through估计偏差、单步更新和稀疏codebook梯度等问题，导致重建性能不佳和codebook利用率低。

Method: 论文提出了VQBridge，一个基于映射函数方法的投影器，通过压缩-处理-恢复流程优化code向量，实现稳定有效的codebook训练。结合学习退火策略，提出的VQN实现了100%的codebook利用率，称为FVQ。

Result: 实验表明，FVQ在各种codebook配置下都能达到100%的codebook利用率，实现了最先进的重建性能，并且可以随着更大的codebook、更高的向量通道或更长的训练时间而持续改进。与LlamaGen集成后，FVQ显著提高了图像生成性能，超过了视觉自回归模型（VAR）和扩散模型（DiT）。

Conclusion: FVQ是一种有效、可扩展和通用的VQ方法，它能够提高图像生成性能，并强调了高质量tokenizer对于强大的自回归图像生成的重要性。

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [94] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock: A method for self-supervised visual representation learning using progressive layer freezing.


<details>
  <summary>Details</summary>
Motivation: Accelerate MAE training by freezing layers based on their convergence speed.

Method: Progressively freeze ViT layers during video MAE training according to a schedule.

Result: LayerLock outperforms non-latent masked prediction on the 4DS perception suite with models up to 4B parameters.

Conclusion: LayerLock is a simple and scalable approach to latent prediction that avoids representation collapse.

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [95] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文对基于空间的 3D 对象重建的隐式和显式 Novel View Synthesis 方法进行了首次系统比较，评估了外观嵌入的作用。


<details>
  <summary>Details</summary>
Motivation: 虽然嵌入通过建模光照变化提高了光度保真度，但我们表明它们不会转化为几何精度方面的有意义的提高，而几何精度是空间机器人应用的关键要求。

Method: 使用 SPEED+ 数据集，我们比较了 K-Planes、Gaussian Splatting 和 Convex Splatting。

Result: 嵌入主要减少了显式方法所需的基元数量，而不是提高了几何保真度。此外，凸溅射比高斯溅射实现了更紧凑和整洁的表示。

Conclusion: 我们的研究结果阐明了外观嵌入在以几何为中心任务中的局限性，并强调了空间场景中重建质量和表示效率之间的权衡。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [96] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种新的训练框架GAMMA，旨在减少领域偏差并增强语义对齐，以提高AI生成图像检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在分布内生成图像上表现良好，但对未见过的生成模型的泛化能力有限，这主要是因为它们依赖于特定于生成的伪影。

Method: GAMMA引入了多种操作策略，如基于修复的操作和语义保留扰动，以确保操作内容和真实内容之间的一致性。采用具有双分割头和分类头的多任务监督，实现跨多个生成域的像素级源属性。此外，还引入了反向交叉注意力机制，以允许分割头指导和纠正分类分支中的偏差表示。

Result: 该方法在GenImage基准测试中实现了最先进的泛化性能，准确率提高了5.8%，并且在新发布的生成模型（如GPT-4o）上保持了强大的鲁棒性。

Conclusion: GAMMA框架有效地提高了AI生成图像检测的泛化能力和鲁棒性。

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [97] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 本研究比较了三种超分辨率重建（SRR）方法在胎儿脑MRI中的应用，包括NiftyMIC、SVRTK和NeSVoR，评估了它们在健康对照组（HC）和脑室扩大（VM）病理病例中的性能。


<details>
  <summary>Details</summary>
Motivation: 胎儿脑MRI受限于运动伪影和低分辨率，SRR重建旨在通过结合slice-to-volume配准和超分辨率技术来生成高分辨率3D体积。目前缺乏对不同SRR方法在病理情况下性能的比较研究，以及它们对下游体积分析和诊断任务的影响。

Method: 对140例胎儿脑MRI扫描（包括HC和VM病例）应用三种SRR方法，使用BoUNTi算法分割重建后的图像，提取九个主要脑结构的体积。评估了视觉质量、SRR成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在HC和PC组中均表现出最高且最一致的重建成功率（>90%）。不同SRR方法在体积估计上存在显著差异，但VM的分类性能未受到SRR方法选择的影响。

Conclusion: NeSVoR表现出稳健性，并且尽管SRR引入了体积变异性，但诊断性能仍具有弹性。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [98] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 本文提出了一种新的训练策略，Mask Consistency Regularization (MCR)，用于解决图像修复中的物体移除问题，该方法通过引入mask扰动，包括膨胀和重塑，来增强模型输出与周围内容的一致性，从而减少幻觉和mask形状偏差。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的图像修复方法在物体移除方面存在mask幻觉和mask形状偏差的问题。

Method: 提出Mask Consistency Regularization (MCR) 训练策略，通过引入膨胀和重塑两种mask扰动，强制模型在扰动分支和原始mask之间保持输出一致性。

Result: 实验结果表明，MCR能显著减少幻觉和mask形状偏差，从而提高物体移除的性能。

Conclusion: MCR是一种有效的物体移除训练策略，它通过mask一致性正则化来提高修复结果的鲁棒性和上下文连贯性。

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [99] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: 这篇论文介绍了MagicMirror，一个用于评估文本到图像生成模型中伪影的综合框架。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型生成的图像存在物理伪影，严重降低了感知质量和应用，并且缺乏细粒度的评估框架。

Method: 1. 建立了一个生成的图像伪影的详细分类法。2. 手动注释了MagicData340K，这是一个包含340K生成图像和细粒度伪影标签的大规模数据集。3. 训练了一个视觉语言模型（VLM），MagicAssessor，它可以提供详细的评估和相应的标签。4. 设计了一种新颖的数据抽样策略和用于Group Relative Policy Optimization (GRPO)的多级奖励系统。5. 利用MagicAssessor构建了一个自动化基准MagicBench，用于评估当前T2I模型的图像伪影。

Result: 使用MagicBench进行的评估表明，即使是像GPT-image-1这样的顶级模型也一直受到显著伪影的困扰。

Conclusion: 伪影减少是未来T2I发展的关键前沿。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [100] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: 本文提出了一种新的手语翻译框架SignClip，它融合了手势和口型等手动和非手动线索，并通过分层对比学习框架确保语义一致性。


<details>
  <summary>Details</summary>
Motivation: 目前的手语翻译方法主要关注手动信号（手势），往往忽略了非手动线索（如口型），而口型在传达重要的语言信息和消除视觉上相似的符号的歧义方面起着关键作用。

Method: SignClip融合了手动和非手动线索，特别是空间手势和唇部运动特征。此外，SignClip引入了一个具有多层次对齐目标的分层对比学习框架，确保了符号-唇部和视觉-文本模式之间的语义一致性。

Result: 在PHOENIX14T和How2Sign两个基准数据集上的大量实验表明，该方法具有优越性。例如，在PHOENIX14T上，在无Gloss设置下，SignClip超过了之前的最先进模型SpaMo，BLEU-4从24.32提高到24.71，ROUGE从46.57提高到48.38。

Conclusion: 本文提出的SignClip框架能够有效提升手语翻译的准确率，并在实验中取得了优异的结果。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [101] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 本文研究了大型视觉语言模型（VLMs 或 LVLMs）在文本篡改检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在图像篡改检测，而忽略了文本篡改检测。本文旨在填补这一知识空白。

Method: 通过在不同的文本篡改数据集上分析闭源和开源的 VLMs。

Result: 结果表明，开源模型正在接近闭源模型（如 GPT-4o），但仍有差距。 此外，针对图像篡改检测的 VLMs 在文本篡改检测中存在泛化问题。

Conclusion: 本文对 VLM 在文本篡改检测中的性能进行了基准测试，并揭示了现有模型的局限性。

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [102] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的零样本3D异常检测框架MCL-AD，该框架利用跨点云、RGB图像和文本语义的多模态协作学习。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了来自互补模态（如RGB图像和文本先验）的丰富语义线索，而本文旨在解决数据稀缺、隐私或高注释成本约束下的3D对象缺陷识别问题。

Method: 本文提出多模态提示学习机制（MPLM），通过引入对象无关的解耦文本提示和多模态对比损失来增强模内表示能力和模间协作学习。此外，还提出了一种协作调制机制（CMM），通过联合调制RGB图像引导和点云引导的分支来充分利用点云和RGB图像的互补表示。

Result: 实验结果表明，所提出的MCL-AD框架在零样本3D异常检测中取得了最先进的性能。

Conclusion: 本文提出的MCL-AD框架有效地利用了多模态信息，并在零样本3D异常检测任务上取得了显著的成果。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [103] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出了一种Lipschitz引导的随机深度（DropPath）方法，以提高深度神经网络和Vision Transformers的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers在计算机视觉中表现出色，但容易受到对抗扰动的影响，并且标准防御方法计算成本高或缺乏形式保证。

Method: 所提出的方法通过增加深度来控制网络的有效Lipschitz常数，从而正则化更深层。

Result: 在CIFAR-10上使用ViT-Tiny的实验表明，该方法在保持近乎基线精度的同时，提高了FGSM、PGD-20和AutoAttack下的鲁棒性，并显著减少了FLOPs。

Conclusion: 该方法能够在提高鲁棒性的同时，保持清洁准确率并减少计算量。

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [104] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 本文提出了一种基于能量图的概率框架，用于在复杂的城市环境中精确定位街道设施。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂城市环境中精确定位街道设施的问题，这对于地方当局和私人利益相关者有效监测和维护公共基础设施至关重要。

Method: 提出了一种基于能量图的概率框架，该框架以地图为基础，对物体位置的空间可能性进行编码。引入了一种随机生灭优化算法来推断最可能的资产配置。

Result: 使用在都柏林市中心街道照明基础设施的地理定位数据集上进行的实际模拟评估了该方法，证明了其在可扩展和准确的城市资产测绘方面的潜力。

Conclusion: 该算法的实现将在GitHub存储库中提供。

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [105] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为ClusCa的聚类驱动特征缓存方法，以加速扩散Transformer模型，通过在每个时间步对token进行空间聚类并减少token数量来实现。


<details>
  <summary>Details</summary>
Motivation: 扩散Transformer模型因其迭代去噪过程而计算成本高昂；现有特征缓存方法忽略了空间维度上的相似性。

Method: 对每个时间步的token进行空间聚类，仅计算每个集群中的一个token，并将其信息传播到所有其他token，从而减少token数量。

Result: 在DiT、FLUX和HunyuanVideo上进行了大量实验，证明了其在文本到图像和文本到视频生成方面的有效性。在FLUX上实现了4.96倍的加速，ImageReward为99.49%，超过了原始模型0.51%。

Conclusion: ClusCa作为一种正交和互补的视角，可以直接应用于任何扩散Transformer，无需训练。

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [106] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter是一个全整数的ViT分割框架，旨在提高资源受限设备上的部署效率。


<details>
  <summary>Details</summary>
Motivation: ViT在语义分割中表现出色，但由于内存占用和计算成本高，在资源受限设备上的部署受到限制。量化是一种提高效率的有效策略，但基于ViT的分割模型在低精度下非常脆弱，因为量化误差会在深度编码器-解码器管道中累积。

Method: 该论文提出了I-Segmenter，它系统地用纯整数操作替换浮点操作。为了进一步稳定训练和推理，论文提出了一种新的激活函数λ-ShiftGELU，该函数缓解了均匀量化在处理长尾激活分布方面的局限性。此外，论文还删除了L2归一化层，并用最近邻上采样代替解码器中的双线性插值，确保在整个计算图中执行纯整数操作。

Result: 实验表明，I-Segmenter在合理范围内实现了与其FP32基线相当的精度（平均5.1%），同时将模型大小减少了高达3.8倍，并通过优化的运行时实现了高达1.2倍的更快推理。即使使用单个校准图像进行一次性PTQ，I-Segmenter也能提供具有竞争力的精度，突显了其在实际部署中的实用性。

Conclusion: I-Segmenter可以在精度损失不大的情况下，有效减小模型大小并提高推理速度，适用于资源受限设备的部署。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [107] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种新的深度学习方法，用于OCT图像去噪，利用扩散概率模型。


<details>
  <summary>Details</summary>
Motivation: OCT图像受到散斑噪声的影响，这会妨碍准确的解释。许多现有的去噪方法难以平衡噪声降低与关键解剖结构的保存。

Method: GARD采用去噪扩散Gamma模型，以更准确地反映散斑的统计特性。此外，引入了一种降噪保真项，该项利用预处理的、噪声较小的图像来指导去噪过程。

Result: 在具有配对的噪声和较少噪声的OCT B扫描的数据集上的实验表明，GARD在PSNR、SSIM和MSE方面明显优于传统的去噪方法和最先进的深度学习模型。

Conclusion: GARD产生更清晰的边缘，并更好地保留精细的解剖细节。

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [108] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND, an LLM platform, can significantly reduce the time it takes to draft IND submissions, but human regulatory writers are still needed to ensure quality.


<details>
  <summary>Details</summary>
Motivation: Preparing Investigational New Drug (IND) applications is slow and requires expertise, which delays early clinical development.

Method: The study compared the drafting times of IND nonclinical summaries generated by AutoIND with manual drafting times. The quality of the summaries was assessed by a blinded regulatory writing assessor using seven categories.

Result: AutoIND reduced initial drafting time by approximately 97%. Quality scores were 69.6% and 77.9% for the two INDs tested. No critical regulatory errors were found, but there were issues with emphasis, conciseness, and clarity.

Conclusion: AutoIND can speed up IND drafting, but expert writers are still necessary. The identified deficiencies offer guidance for improving the model.

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [109] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: boldsea: executable ontologies for dynamic systems, overcoming BPM and object-oriented semantic tech limits.


<details>
  <summary>Details</summary>
Motivation: limitations of traditional Business Process Management (BPM) systems and object-oriented semantic technologies.

Method: formal BSL (boldsea Semantic Language) and the boldsea-engine's architecture.

Result: modification of event models at runtime, ensures temporal transparency, and seamlessly merges data and business logic within a unified semantic framework.

Conclusion: integrating event semantics with a dataflow architecture addresses the limitations of traditional BPM systems and object-oriented semantic technologies.

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [110] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 大型语言模型和视觉语言模型可以为规划提供高质量的反馈，减少策略学习所需的奖励设计和演示。


<details>
  <summary>Details</summary>
Motivation: 在具身环境中进行规划通常需要精心设计的奖励函数或高质量的带注释的演示。最近的研究表明，预训练的基础模型，如大型语言模型（LLM）和视觉语言模型（VLM），可以捕捉有助于规划的背景知识，从而减少策略学习所需的奖励设计和演示。

Method: 我们评估了LLM和VLM在符号、语言和连续控制环境中提供反馈的程度。我们考虑了用于规划的各种突出反馈类型，包括二元反馈、偏好反馈、行动建议、目标建议和增量行动反馈。我们还考虑了影响反馈性能的推理方法，包括上下文学习、思维链和访问环境动态。

Result: 我们发现基础模型可以在各个领域提供多样化的高质量反馈。此外，更大和更具推理能力的模型始终提供更准确的反馈，表现出更少的偏差，并从增强的推理方法中获益更多。

Conclusion: 反馈质量在具有复杂动力学或连续状态空间和动作空间的环境中会下降。

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [111] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个使用生成式人工智能（AI）从公开可用的住宅信息和图像中生成能源建模数据的模块化多模态框架。


<details>
  <summary>Details</summary>
Motivation: 现有的能源建模研究依赖大量数据，但这些数据获取困难、成本高昂或涉及隐私问题。

Method: 论文提出了一个模块化的多模态框架，利用生成式AI从公开数据中生成所需的能源建模数据。

Result: 实验表明，该框架使用AI避免了生成模型的常见问题，并生成了逼真的、带有标签的数据。

Conclusion: 该框架通过减少对昂贵或受限数据源的依赖，为更易于访问和复现的研究铺平了道路。

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [112] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 本文旨在回顾和统一各种自动形式化的实例，并提出了一个统一的框架，以促进不同领域之间的交叉融合，从而加速下一代人工智能系统的发展。


<details>
  <summary>Details</summary>
Motivation: 现有研究领域在将非正式语言转换为正式表示方面缺乏共享的方法、基准和理论框架，这限制了进一步发展。

Method: 回顾各种自动形式化的实例，并提出了一个统一的框架。

Result: 提出了一个统一的框架，以促进不同领域之间的交叉融合。

Conclusion: 通过统一的框架，可以促进不同领域之间的交叉融合，从而加速下一代人工智能系统的发展。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [113] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本研究介绍了一种智能知识助手系统，旨在支持山羊养殖中的健康管理，通过检索增强生成（RAG）技术和两种结构化知识处理方法，即表格文本化和决策树文本化，来增强大型语言模型对异构数据格式的理解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业中的应用受限于知识来源的可获得性、多样性和复杂性。

Method: 利用检索增强生成（RAG），提出了表格文本化和决策树文本化两种结构化知识处理方法，并建立了领域特定的山羊养殖知识库，集成了在线搜索模块。

Result: 异构知识融合方法取得了最佳效果，在验证集上的平均准确率为87.90%，在测试集上的平均准确率为84.22%。

Conclusion: 该系统在山羊养殖的实际应用中具有稳健性和可靠性。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [114] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）旨在协助人类完成各种任务，但其在实际协助他人达成目标方面的能力尚不清楚。本研究通过让LLM参与UNO牌游戏，并要求其帮助另一位玩家获胜来测试这一问题。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型能否作为积极参与者，帮助他人实现目标。

Method: 构建了一个工具，使仅解码器的LLM能够作为代理参与RLCard游戏环境。这些模型接收完整的游戏状态信息，并使用两种不同的提示策略进行响应。评估了从小型（10亿参数）到大型（700亿参数）的模型，并探讨了模型规模如何影响性能。

Result: 所有模型在玩UNO时都能成功超越随机基线，但很少有模型能够显著帮助另一位玩家。

Conclusion: 虽然LLM在UNO游戏中表现出一定的游戏能力，但其在协助他人获胜方面的能力有限。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [115] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 提出了一个概念框架，通过工作流在智能和组成两个维度上的演变，实现从现有工作流管理系统到完全自主的分布式科学实验室的演进路径。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式设施和异构资源，研究人员被迫成为手动工作流协调员，而不是科学家。人工智能的进步为加速科学发现带来了令人兴奋的新机会，但尚不清楚这种新能力将如何实现和整合到现实世界中。

Method: 提出了一个概念框架，其中工作流沿着智能（从静态到智能）和组成（从单一到集群）两个维度演变，以规划从当前工作流管理系统到完全自主的分布式科学实验室的演进路径。

Result: 提出了一个架构蓝图，可以帮助社区朝着自主科学的方向发展，并有可能实现 100 倍的发现加速和变革性的科学工作流。

Conclusion: 自主科学具有巨大的潜力，可以加速科学发现并改变科学工作流。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [116] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 这篇论文提出了一种将 WaveFunctionCollapse (WFC) 重新表述为马尔可夫决策过程 (MDP) 的方法，以解决程序内容生成中同时优化设计者目标和邻接约束的挑战。


<details>
  <summary>Details</summary>
Motivation: 程序内容生成通常需要同时满足设计者指定的目标和底层图块集隐式施加的邻接约束，这给优化带来了挑战。

Method: 将 WFC 重新表述为马尔可夫决策过程 (MDP)，允许外部优化算法专注于目标最大化，同时利用 WFC 的传播机制来强制满足约束。

Result: 在多个具有不同难度的领域中，联合优化方法的性能随着任务复杂度的增加而下降，并且始终不如基于 WFC-MDP 的优化方法。

Conclusion: 将局部约束满足与全局目标优化分离具有优势。

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [117] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本研究专注于表格数据，针对AI模型预测布尔函数值的情况，评估可解释AI（XAI）方法。


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI（XAI）方法通常具有挑战性。本文旨在解决这个问题。

Method: 提出了一种基于实际因果关系的变量重要性的正式和精确的度量方法，并使用该方法评估了当前最好的XAI工具。此外，还提出了一种新的XAI工具B-ReX。

Result: B-ReX在大规模基准测试中优于其他黑盒XAI工具。在随机的10值布尔公式上，B-ReX实现了0.072 $\pm$ 0.012的Jensen-Shannon散度。

Conclusion: B-ReX是一种优于其他黑盒XAI工具的新型XAI工具，并在大规模基准测试中得到了验证。

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [118] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: 提出了一种名为GAMA的通用匿名多智能体系统，旨在解决多智能体系统在处理隐私数据时安全利用高性能LLM的问题。


<details>
  <summary>Details</summary>
Motivation: 当任务涉及隐私数据时，多智能体系统无法安全地利用这些LLM，因此需要隐私保护机制。

Method: 将智能体的工作空间划分为私有和公共空间，并通过匿名化机制保护隐私。GAMA包含两个关键模块：基于领域规则的知识增强（DRKE）和基于反证的逻辑增强（DLE），以减轻匿名化造成的语义损失。

Result: 在两个公共问答数据集和两个新的隐私保护数据集上评估GAMA，结果表明GAMA具有优于现有模型的性能，并在任务处理和隐私保护方面表现出色。

Conclusion: GAMA系统在任务处理和隐私保护方面都非常有效。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [119] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个多智能体协同框架，旨在解决复杂任务中智能体任务规划和不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在处理复杂任务时，面临着任务规划和不确定性方面的挑战，导致输出结果不准确，阻碍任务执行。

Method: 提出了XAgents，一个统一的多智能体协同框架，它基于多极任务处理图和IF-THEN规则，实现动态任务规划和处理任务不确定性。在子任务处理过程中，集成了领域特定的IF-THEN规则来约束智能体行为，同时全局规则增强智能体间的协作。

Result: 在三个不同的数据集上评估了XAgents的性能，结果表明，在知识型和逻辑型问答任务中，XAgents始终优于最先进的单智能体和多智能体方法。

Conclusion: XAgents通过多极任务处理图和IF-THEN规则，有效地提升了多智能体系统在复杂任务中的任务规划和处理不确定性的能力。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [120] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了一个以人为本的、危害严重程度自适应的方法，基于经验事件数据。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能风险评估模型侧重于内部合规，经常忽略不同的利益相关者视角和现实世界的后果。人工智能的绝对统治带来了前所未有的社会危害和风险。

Method: 提出了AI Harmonics，包括一种新的人工智能危害评估指标（AIH），该指标利用序数严重程度数据来捕获相对影响，而无需精确的数值估计。AI Harmonics结合了稳健的、通用的方法和数据驱动的、利益相关者意识框架，用于探索和优先排序人工智能危害。

Result: 在带注释的事件数据上的实验证实，政治和人身伤害表现出最高的集中度，因此需要紧急缓解：政治伤害会侵蚀公众信任，而人身伤害会构成严重的，甚至是危及生命的风险，突出了我们方法的现实意义。

Conclusion: AI Harmonics始终如一地识别出不均衡的危害分布，使决策者和组织能够有效地确定其缓解工作的目标。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [121] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 本文提出了“沙盒经济”框架，用于分析自主AI代理的新兴经济系统。


<details>
  <summary>Details</summary>
Motivation: 自主AI代理的快速发展正在形成一个超越人类直接监督的经济层，需要对其进行分析和引导。

Method: 通过起源（涌现 vs. 预设）和与人类经济的隔离程度（可渗透 vs. 不可渗透）两个维度来描述“沙盒经济”框架。

Result: 当前趋势指向一个庞大且高度可渗透的AI代理经济的自发涌现，这既带来了前所未有的协调机会，也带来了系统性经济风险和不平等加剧等重大挑战。

Conclusion: 本文讨论了多种可能的设计选择，以安全地引导AI代理市场，确保技术变革与人类的长期共同繁荣相一致。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [122] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了一种新的在线规划算法，Robust Sparse Sampling (RSS)，用于解决在模型不确定性下的马尔可夫决策过程 (RMDP) 问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模型的在线规划方法在实际应用中，由于生成模型是从有限数据中学习的，会引入近似误差，导致性能下降或不安全行为。Robust MDPs (RMDPs) 提供了一个在模型不确定性下进行规划的框架，但现有方法计算密集，不适合实时使用。

Method: 提出 Robust Sparse Sampling (RSS)，利用 Sample Average Approximation (SAA) 的效率和理论性质来计算鲁棒价值函数，从而实现在线环境中的易于处理的鲁棒策略计算。

Result: RSS 在具有不确定动态的环境中优于标准 Sparse Sampling，并提供了理论性能保证。

Conclusion: RSS 是第一个具有有限样本理论性能保证的 RMDP 在线规划算法，适用于无限或连续状态空间，并且其样本和计算复杂度与状态空间大小无关。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [123] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 提出一个多智能体框架，该框架使用基于 LLM 的智能体自主理解表征任务，计划适当的模拟，组装相关的力场，执行它们并解释它们的结果以指导后续步骤，从而自动表征多孔材料


<details>
  <summary>Details</summary>
Motivation: 自动表征多孔材料有可能加速材料发现，但它仍然受到模拟设置和力场选择的复杂性的限制

Method: 提出了一个多智能体框架，其中基于 LLM 的智能体可以自主地理解表征任务，计划适当的模拟，组装相关的力场，执行它们并解释它们的结果以指导后续步骤

Result: 初步评估表明具有很高的正确性和可重复性

Conclusion: 该方法具有实现完全自主、可扩展的材料表征的潜力

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [124] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: 本研究探讨了大型语言模型在临床自然语言推理（NLI）中的表现，并引入了CARENLI框架，该框架通过分离知识访问和推理过程来提高模型的可信度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设数据和参数的扩展能够提高内部表征的结构化和泛化能力。本文旨在检验这一假设在临床自然语言推理（NLI）中的有效性。

Method: 本文采用包含四个推理家族（因果归因、组合基础、认知验证和风险状态抽象）的基准，并引入CARENLI框架，该框架将知识访问与推理过程分离，并通过规划器、验证器和改进器来执行可审计的程序。

Result: CARENLI框架在四个大型语言模型上将保真度提高了高达42个百分点，在因果归因方面达到了98.0%，在风险状态抽象方面达到了81.2%。验证器能够以接近上限的可靠性标记违规行为，而改进器能够纠正大部分认知错误。

Conclusion: 研究结果表明，大型语言模型通常保留相关事实，但在推理不明确时会默认使用启发式方法。CARENLI框架通过明确区分知识访问和推理过程，并提供了一个更安全、可审计的推理框架，解决了这一问题。

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [125] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 本研究调查了在推理任务中结合形式化方法对小型语言模型 (SLM) 性能的影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理方面存在不足，尤其是在本体工程领域。本研究旨在探索使用 SLM 来引导本体构建。

Method: 通过一系列初步实验，确定用不同语法表达逻辑问题对 SLM 在预定义推理任务上的性能的影响。

Result: 研究结果表明，可以用更紧凑的逻辑语言代替自然语言 (NL)，同时保持推理任务的强大性能。

Conclusion: 希望利用这些结果进一步改进 SLM 在本体工程中的作用。

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [126] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 探讨了大型语言模型（LLM）在面对道德困境时的道德价值观偏好，以及模型架构、文化背景和可解释性如何影响这些偏好。


<details>
  <summary>Details</summary>
Motivation: 人工智能的快速发展引发了关于如何使机器决策与人类道德价值观相一致的问题。

Method: 对六个大型语言模型进行了定量实验，对18个困境中的结果进行排序和评分，这些困境代表了五个道德框架。

Result: 所有模型都表现出惊人一致的价值偏见，关怀和美德价值观的结果被评为最具道德性，而自由主义选择一直受到惩罚。具有推理能力的模型对背景更敏感，而非推理模型则产生更统一但模糊的判断。

Conclusion: 强调了可解释性和文化意识作为指导人工智能走向透明、一致和共生未来的关键设计原则。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [127] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra: a novel algebraic framework for propositional logic.


<details>
  <summary>Details</summary>
Motivation: To represent and manipulate propositional logic using algebraic methods.

Method: A hierarchy of three representations: Set, Coordinate, and Row Decomposition.

Result: Demonstrates flexibility in representation and the ability to obtain a unique canonical form with a fixed variable order.

Conclusion: Provides tools for search-based and knowledge compilation algorithms and extends to probabilistic logic and Weighted Model Counting.

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [128] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种名为 Abduct-Act-Predict (A2P) Scaffolding 的新框架，用于解决多智能体系统中失败归因的问题。该框架通过因果推理来确定纠正单个动作是否可以避免任务失败，从而显著提高了步骤级别的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的多智能体系统失败归因方法在步骤级别准确性方面表现不佳，无法进行稳健的反事实推理，难以调试复杂系统。

Method: 论文提出 A2P Scaffolding 框架，该框架通过三个步骤进行因果推理：(1) 推理智能体行为背后的隐藏根本原因；(2) 定义最小的纠正干预；(3) 模拟后续轨迹并验证干预是否解决了失败。

Result: 在 Who&When 基准测试中，A2P 在 Algorithm-Generated 数据集上实现了 47.46% 的步骤级别准确性，比基线提高了 2.85 倍。在更复杂的 Hand-Crafted 数据集上，它实现了 29.31% 的步骤准确性，比基线提高了 2.43 倍。

Conclusion: A2P Scaffolding 通过因果推理提供了一种稳健、可验证且更准确的自动失败归因解决方案。

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [129] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 本文提出了一种信息论框架，用于检测和诊断现实环境中强化学习 (RL) 智能体的故障。


<details>
  <summary>Details</summary>
Motivation: 现实环境中部署的强化学习 (RL) 智能体面临传感器故障、执行器磨损和环境变化导致的性能下降，但缺乏检测和诊断这些故障的内在机制。

Method: 通过分析机器人控制任务中的状态-动作互信息模式，揭示了成功学习表现出的特征信息签名。

Result: 研究表明，状态和动作之间的互信息稳步增加，状态、动作和下一状态的联合互信息遵循倒 U 型曲线。此外，信息指标可以区分系统故障：状态噪声导致所有信息通道的广泛崩溃，而动作噪声选择性地破坏动作-结果的可预测性，同时保持状态-动作关系。

Conclusion: 通过建立信息模式作为学习的签名和系统健康的诊断，为能够基于信息论原理进行自主故障检测和策略调整的自适应 RL 系统奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [130] [Space-Time Tradeoffs for Spatial Conjunctive Queries](https://arxiv.org/abs/2509.10050)
*Aryan Esmailpour,Xiao Hu,Stavros Sintos*

Main category: cs.DB

TL;DR: This paper develops an index for efficiently answering spatial queries on the results of conjunctive queries, such as range emptiness, range count, and nearest neighbor queries.


<details>
  <summary>Details</summary>
Motivation: Known approaches are inefficient or unrealistic in practice, as they either have to spend $\tilde{O}(N)$ query time or use space as large as the number of query results. The goal is to construct an index that answers spatial conjunctive queries in both time- and space-efficient ways.

Method: The paper establishes lower bounds on the tradeoff between answering time and space usage. It constructs optimal indexes for answering range emptiness and range counting problems over $k$-star and $k$-path queries. It builds an index for hierarchical queries and extends it to arbitrary conjunctive queries for supporting spatial conjunctive queries by resorting to the generalized hypertree decomposition.

Result: The paper establishes lower bounds on the tradeoff between answering time and space usage for $k$-star and $k$-path queries. It also constructs optimal indexes for answering range emptiness and range counting problems over $k$-star and $k$-path queries. Finally, it shows how the new indexes can be used to improve the running time of known algorithms in the relational setting.

Conclusion: The paper develops indexes for spatial conjunctive queries that are both time- and space-efficient.

Abstract: Given a conjunctive query and a database instance, we aim to develop an index
that can efficiently answer spatial queries on the results of a conjunctive
query. We are interested in some commonly used spatial queries, such as range
emptiness, range count, and nearest neighbor queries. These queries have
essential applications in data analytics, such as filtering relational data
based on attribute ranges and temporal graph analysis for counting graph
structures like stars, paths, and cliques. Furthermore, this line of research
can accelerate relational algorithms that incorporate spatial queries in their
workflow, such as relational clustering. Known approaches either have to spend
$\tilde{O}(N)$ query time or use space as large as the number of query results,
which are inefficient or unrealistic to employ in practice. Hence, we aim to
construct an index that answers spatial conjunctive queries in both time- and
space-efficient ways.
  In this paper, we establish lower bounds on the tradeoff between answering
time and space usage. For $k$-star (resp. $k$-path) queries, we show that any
index for range emptiness, range counting or nearest neighbor queries with $T$
answering time requires $\Omega\left(N+\frac{N^k}{T^k}\right)$ (resp.
$\Omega\left(N+\frac{N^2}{T^{2/(k-1)}}\right)$) space. Then, we construct
optimal indexes for answering range emptiness and range counting problems over
$k$-star and $k$-path queries. Extending this result, we build an index for
hierarchical queries. By resorting to the generalized hypertree decomposition,
we can extend our index to arbitrary conjunctive queries for supporting spatial
conjunctive queries. Finally, we show how our new indexes can be used to
improve the running time of known algorithms in the relational setting.

</details>


### [131] [Semi-interval Comparison Constraints in Query Containment and Their Impact on Certain Answer Computation](https://arxiv.org/abs/2509.10138)
*Foto N. Afrati,Matthew Damigos*

Main category: cs.DB

TL;DR: 本文研究了带算术比较的合取查询(CQAC)的包含问题和计算确定答案的复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究CQAC查询包含问题的计算复杂性，以及在CQAC视图下回答带半区间比较的CQAC查询框架中计算确定答案的复杂性。

Method: 通过研究包含查询中具有半区间算术比较的查询类，以及使用最大包含重写来计算确定答案。

Result: 发现包含查询中具有半区间算术比较的查询类使得问题可以在NP中解决。证明了在某些简单情况下，问题仍然是$\Pi_2 ^p$-完全的。证明了CQACs联合语言中的最大包含重写总是精确地计算所有确定答案。发现可以使用最大包含重写在多项式时间内计算确定答案的情况。

Conclusion: 本文研究了带算术比较的合取查询的包含问题和计算确定答案的复杂性，并对相关问题进行了分析和证明。

Abstract: We consider conjunctive queries with arithmetic comparisons (CQAC) and
investigate the computational complexity of the problem: Given two CQAC
queries, $Q$ and $Q'$, is $Q'$ contained in $Q$? We know that, for CQAC
queries, the problem of testing containment is $\Pi_2 ^p$ -complete. However,
there are broad classes of queries with semi-interval arithmetic comparisons in
the containing query that render the problem solvable in NP. In all cases
examined the contained query is allowed to be any CQAC. Interestingly, we also
prove that there are simple cases where the problem remains $\Pi_2 ^p$
-complete.
  We also investigate the complexity of computing certain answers in the
framework of answering CQAC queries with semi-interval comparisons using any
CQAC views. We prove that maximally contained rewritings in the language of
union of CQACs always compute exactly all certain answers. We find cases where
we can compute certain answers in polynomial time using maximally contained
rewritings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [132] [Text-to-SQL Oriented to the Process Mining Domain: A PT-EN Dataset for Query Translation](https://arxiv.org/abs/2509.09684)
*Bruno Yui Yamate,Thais Rodrigues Neubauer,Marcelo Fantinato,Sarajane Marques Peres*

Main category: cs.IR

TL;DR: 本文介绍了一个名为 text-2-SQL-4-PM 的双语（葡萄牙语-英语）基准数据集，专为过程挖掘领域的 text-to-SQL 任务设计。


<details>
  <summary>Details</summary>
Motivation: 该数据集旨在解决过程挖掘的独特挑战，例如专业词汇和来自事件日志的单表关系结构，提高用户访问数据库的便利性。

Method: 该数据集通过专家手动管理、专业翻译和详细的注释过程构建。

Result: 使用 GPT-3.5 Turbo 的基线研究表明了该数据集在 text-to-SQL 应用中的可行性和实用性。

Conclusion: text-2-SQL-4-PM 支持 text-to-SQL 实现的评估，并为语义解析和其他自然语言处理任务提供更广泛的适用性。

Abstract: This paper introduces text-2-SQL-4-PM, a bilingual (Portuguese-English)
benchmark dataset designed for the text-to-SQL task in the process mining
domain. Text-to-SQL conversion facilitates natural language querying of
databases, increasing accessibility for users without SQL expertise and
productivity for those that are experts. The text-2-SQL-4-PM dataset is
customized to address the unique challenges of process mining, including
specialized vocabularies and single-table relational structures derived from
event logs. The dataset comprises 1,655 natural language utterances, including
human-generated paraphrases, 205 SQL statements, and ten qualifiers. Methods
include manual curation by experts, professional translations, and a detailed
annotation process to enable nuanced analyses of task complexity. Additionally,
a baseline study using GPT-3.5 Turbo demonstrates the feasibility and utility
of the dataset for text-to-SQL applications. The results show that
text-2-SQL-4-PM supports evaluation of text-to-SQL implementations, offering
broader applicability for semantic parsing and other natural language
processing tasks.

</details>


### [133] [Wave-Based Semantic Memory with Resonance-Based Retrieval: A Phase-Aware Alternative to Vector Embedding Stores](https://arxiv.org/abs/2509.09691)
*Aleksandr Listopad*

Main category: cs.IR

TL;DR: 提出了一种新的基于波的语义记忆框架，该框架通过基于共振的干涉来检索知识，保留了幅度和相位信息，从而实现了更具表现力和鲁棒性的语义相似性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于向量的记忆系统依赖于实值嵌入空间中的余弦或内积相似性，但这种方法本质上对相位不敏感，并且在捕获对意义表示至关重要的共振现象方面的能力有限。

Method: 将知识建模为波模式，并通过基于共振的干涉来检索知识。该方法保留了幅度和相位信息。

Result: 基于共振的检索在向量方法失败的情况下实现了更高的区分能力，包括相移、否定和组合查询。ResonanceDB 的实现表明，它可以扩展到数百万种模式，延迟为毫秒级。

Conclusion: 基于波的记忆是面向 AGI 的推理和知识表示的向量存储的可行替代方案。

Abstract: Conventional vector-based memory systems rely on cosine or inner product
similarity within real-valued embedding spaces. While computationally
efficient, such approaches are inherently phase-insensitive and limited in
their ability to capture resonance phenomena crucial for meaning
representation. We propose Wave-Based Semantic Memory, a novel framework that
models knowledge as wave patterns $\psi(x) = A(x) e^{i\phi(x)}$ and retrieves
it through resonance-based interference. This approach preserves both amplitude
and phase information, enabling more expressive and robust semantic similarity.
We demonstrate that resonance-based retrieval achieves higher discriminative
power in cases where vector methods fail, including phase shifts, negations,
and compositional queries. Our implementation, ResonanceDB, shows scalability
to millions of patterns with millisecond latency, positioning wave-based memory
as a viable alternative to vector stores for AGI-oriented reasoning and
knowledge representation.

</details>


### [134] [DB3 Team's Solution For Meta KDD Cup' 25](https://arxiv.org/abs/2509.09681)
*Yikuan Xia,Jiazun Chen,Yirui Zhan,Suifeng Zhao,Weipeng Jiang,Chaorui Zhang,Wei Han,Bo Bai,Jun Gao*

Main category: cs.IR

TL;DR: db3 团队在 KDD Cup'25 的 Meta CRAG-MM 挑战赛中获胜的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决多模态、多轮问答基准测试 (CRAG-MM) 的挑战。

Method: 集成了为不同任务定制的检索管道，并采用统一的 LLM 调整方法来控制幻觉。

Result: 在 Task 1 中获得第二名，在 Task 2 中获得第二名，在 Task 3 中获得第一名，确保了通过卓越地处理第一人称视角挑战来获得以自我为中心的查询的特等奖。

Conclusion: 该系统通过卓越地处理第一人称视角挑战，在以自我为中心的查询方面表现出色。

Abstract: This paper presents the db3 team's winning solution for the Meta CRAG-MM
Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal,
multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive
framework that integrates tailored retrieval pipelines for different tasks with
a unified LLM-tuning approach for hallucination control. Our solution features
(1) domain-specific retrieval pipelines handling image-indexed knowledge
graphs, web sources, and multi-turn conversations; and (2) advanced refusal
training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd
place in Task 2, and 1st place in Task 3, securing the grand prize for
excellence in ego-centric queries through superior handling of first-person
perspective challenges.

</details>


### [135] [Faster and Memory-Efficient Training of Sequential Recommendation Models for Large Catalogs](https://arxiv.org/abs/2509.09682)
*Maxim Zhelnin,Dmitry Redko,Volkov Daniil,Anna Volodkevich,Petr Sokerin,Valeriy Shevchenko,Egor Shvetsov,Alexey Vasilev,Darya Denisova,Ruslan Izmailov,Alexey Zaytsev*

Main category: cs.IR

TL;DR: 这篇论文提出了一种名为 CCE- 的方法，旨在解决基于 Transformer 的序列推荐模型在训练过程中因项目目录庞大而导致的高计算成本问题。该方法通过高效的负采样交叉熵损失实现，能显著减少内存消耗并加速训练。


<details>
  <summary>Details</summary>
Motivation: 现有的序列推荐模型需要频繁重新训练以适应不断变化的用户偏好。然而，基于 Transformer 的模型训练成本高昂，尤其是在处理大量项目时，内存消耗成为瓶颈。

Method: 论文提出了 CCE- 方法，这是一种 GPU 高效的交叉熵损失负采样实现。同时，作者还发布了一个 Triton kernel，以方便 CCE- 方法的进一步应用。

Result: 实验结果表明，CCE- 方法能将训练速度提升高达两倍，同时减少内存消耗超过 10 倍。使用 CCE- 训练的模型在大型项目目录数据集上表现出更高的准确性。

Conclusion: 论文强调了在平衡负样本数量和批次大小等关键超参数的重要性，并证明同时扩展这两个参数比仅最大化其中一个参数能获得更好的结果。

Abstract: Sequential recommendations (SR) with transformer-based architectures are
widely adopted in real-world applications, where SR models require frequent
retraining to adapt to ever-changing user preferences. However, training
transformer-based SR models often encounters a high computational cost
associated with scoring extensive item catalogs, often exceeding thousands of
items. This occurs mainly due to the use of cross-entropy loss, where peak
memory scales proportionally to catalog size, batch size, and sequence length.
Recognizing this, practitioners in the field of recommendation systems
typically address memory consumption by integrating the cross-entropy (CE) loss
with negative sampling, thereby reducing the explicit memory demands of the
final layer. However, a small number of negative samples would degrade model
performance, and as we demonstrate in our work, increasing the number of
negative samples and the batch size further improves the model's performance,
but rapidly starts to exceed industrial GPUs' size (~40Gb).
  In this work, we introduce the CCE- method, which offers a GPU-efficient
implementation of the CE loss with negative sampling. Our method accelerates
training by up to two times while reducing memory consumption by more than 10
times. Leveraging the memory savings afforded by using CCE- for model training,
it becomes feasible to enhance its accuracy on datasets with a large item
catalog compared to those trained with original PyTorch-implemented loss
functions. Finally, we perform an analysis of key memory-related
hyperparameters and highlight the necessity of a delicate balance among these
factors. We demonstrate that scaling both the number of negative samples and
batch size leads to better results rather than maximizing only one of them. To
facilitate further adoption of CCE-, we release a Triton kernel that
efficiently implements the proposed method.

</details>


### [136] [Forecasting Clicks in Digital Advertising: Multimodal Inputs and Interpretable Outputs](https://arxiv.org/abs/2509.09683)
*Briti Gangopadhyay,Zhao Wang,Shingo Takamatsu*

Main category: cs.IR

TL;DR: 提出了一种多模态预测框架，该框架结合了点击数据和文本日志，并生成了人类可解释的解释以及数值预测。


<details>
  <summary>Details</summary>
Motivation: 预测点击量是数字广告中的一项关键任务，影响收入和广告系列策略。传统的时间序列模型仅依赖于数值数据，通常忽略嵌入在文本元素（如关键字更新）中的丰富上下文信息。

Method: 使用强化学习来提高对文本信息的理解，并增强模态融合。

Result: 在一个大规模工业数据集上的实验表明，该方法在准确性和推理质量方面均优于基线。

Conclusion: 该论文提出了一个多模态预测框架，结合点击数据和文本日志，利用强化学习提高文本理解和模态融合，实验结果表明该方法在准确性和推理质量方面均优于基线。

Abstract: Forecasting click volume is a key task in digital advertising, influencing
both revenue and campaign strategy. Traditional time series models rely solely
on numerical data, often overlooking rich contextual information embedded in
textual elements, such as keyword updates. We present a multimodal forecasting
framework that combines click data with textual logs from real-world ad
campaigns and generates human-interpretable explanations alongside numeric
predictions. Reinforcement learning is used to improve comprehension of textual
information and enhance fusion of modalities. Experiments on a large-scale
industry dataset show that our method outperforms baselines in both accuracy
and reasoning quality.

</details>


### [137] [TalkPlayData 2: An Agentic Synthetic Data Pipeline for Multimodal Conversational Music Recommendation](https://arxiv.org/abs/2509.09685)
*Keunwoo Choi,Seungheon Doh,Juhan Nam*

Main category: cs.IR

TL;DR: TalkPlayData 2是一个用于多模态会话音乐推荐的合成数据集，通过模拟LLM智能体的对话生成。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个多模态会话音乐推荐系统，需要一个包含音频、图像和对话的训练数据集。

Method: 构建了一个agentic数据管道，其中多个LLM智能体扮演不同的角色，通过记录Listener LLM和Recsys LLM之间的对话来获取数据。Listener LLM根据微调的对话目标进行调节，所有LLM都具备处理音频和图像的能力。

Result: TalkPlayData 2在LLM-as-a-judge和主观评估实验中达到了预期目标，适用于训练生成式音乐推荐模型。

Conclusion: TalkPlayData 2是一个有价值的合成数据集，可以促进多模态会话音乐推荐系统的研究和开发，并且已经开源。

Abstract: We present TalkPlayData 2, a synthetic dataset for multimodal conversational
music recommendation generated by an agentic data pipeline. In TalkPlayData 2
pipeline, multiple large language model (LLM) agents are created under various
roles with specialized prompts and access to different parts of information,
and the chat data is acquired by logging the conversation between the Listener
LLM and the Recsys LLM. To cover various conversation scenarios, for each
conversation, the Listener LLM is conditioned on a finetuned conversation goal.
Finally, all the LLMs are multimodal with audio and images, allowing a
simulation of multimodal recommendation and conversation. In the LLM-as-a-judge
and subjective evaluation experiments, TalkPlayData 2 achieved the proposed
goal in various aspects related to training a generative recommendation model
for music. TalkPlayData 2 and its generation code are open-sourced at
https://talkpl.ai/talkplaydata2.html.

</details>


### [138] [GeoGPT.RAG Technical Report](https://arxiv.org/abs/2509.09686)
*Fei Huang,Fan Wu,Zeqing Zhang,Qihao Wang,Long Zhang,Grant Michael Boquet,Hongyang Chen*

Main category: cs.IR

TL;DR: GeoGPT是一个开源的大型语言模型系统，旨在推进地球科学的研究。它通过检索增强生成（RAG）技术，利用GeoGPT库和用户上传的知识库，生成准确的、特定语境的答案。为了提高检索质量和领域对齐，该系统对嵌入模型和排序模型进行了微调。GeoGPT致力于开放科学，并开源了两个核心RAG组件。


<details>
  <summary>Details</summary>
Motivation: 为了推进地球科学领域的研究，构建一个领域特定的大型语言模型系统。

Method: 采用了检索增强生成（RAG）技术，并对嵌入模型和排序模型进行了微调。

Result: GeoGPT能够生成准确的、特定语境的答案，并且提高了检索质量和领域对齐。

Conclusion: GeoGPT是一个强大的、可访问的AI工具，通过开放科学的方式，支持全球的地球科学家、研究人员和专业人士。

Abstract: GeoGPT is an open large language model system built to advance research in
the geosciences. To enhance its domain-specific capabilities, we integrated
Retrieval Augmented Generation(RAG), which augments model outputs with relevant
information retrieved from an external knowledge source. GeoGPT uses RAG to
draw from the GeoGPT Library, a specialized corpus curated for geoscientific
content, enabling it to generate accurate, context-specific answers. Users can
also create personalized knowledge bases by uploading their own publication
lists, allowing GeoGPT to retrieve and respond using user-provided materials.
To further improve retrieval quality and domain alignment, we fine-tuned both
the embedding model and a ranking model that scores retrieved passages by
relevance to the query. These enhancements optimize RAG for geoscience
applications and significantly improve the system's ability to deliver precise
and trustworthy outputs. GeoGPT reflects a strong commitment to open science
through its emphasis on collaboration, transparency, and community driven
development. As part of this commitment, we have open-sourced two core RAG
components-GeoEmbedding and GeoReranker-to support geoscientists, researchers,
and professionals worldwide with powerful, accessible AI tools.

</details>


### [139] [Demonstrating Narrative Pattern Discovery from Biomedical Literature](https://arxiv.org/abs/2509.09687)
*Hermann Kroll,Pascal Sackhoff,Bill Matthias Thang,Christin Katharina Kreutz,Wolf-Tilo Balke*

Main category: cs.IR

TL;DR: 本文介绍了一种新的搜索功能，称为叙事模式挖掘，允许用户探索上下文相关的实体和实体交互。


<details>
  <summary>Details</summary>
Motivation: 德国的药学专业信息服务 PubPharm 需要为其用户提供有效的知识访问路径。PubPharm 支持传统的关键词搜索、化学结构搜索以及新的基于图的发现工作流程。

Method: 通过叙事模式挖掘，允许用户探索上下文相关的实体和实体交互。

Result: 与五位领域专家进行了访谈，以验证我们原型的有用性。

Conclusion: 本文介绍了一种新的搜索功能，称为叙事模式挖掘。

Abstract: Digital libraries maintain extensive collections of knowledge and need to
provide effective access paths for their users. For instance, PubPharm, the
specialized information service for Pharmacy in Germany, provides and develops
access paths to their underlying biomedical document collection. In brief,
PubPharm supports traditional keyword-based search, search for chemical
structures, as well as novel graph-based discovery workflows, e.g., listing or
searching for interactions between different pharmaceutical entities. This
paper introduces a new search functionality, called narrative pattern mining,
allowing users to explore context-relevant entities and entity interactions. We
performed interviews with five domain experts to verify the usefulness of our
prototype.

</details>


### [140] [AI-Powered Assistant for Long-Term Access to RHIC Knowledge](https://arxiv.org/abs/2509.09688)
*Mohammad Atif,Vincent Garonne,Eric Lancon,Jerome Lauret,Alexandr Prozorov,Michal Vranovsky*

Main category: cs.IR

TL;DR: RHIC的数据和分析保存计划(DAPP)引入了一个人工智能助手系统，该系统提供对文档、工作流和软件的自然语言访问，以支持可重复性、教育和未来发现。


<details>
  <summary>Details</summary>
Motivation: 在布鲁克海文国家实验室的相对论重离子对撞机(RHIC)结束了25年的运行之际，保存其巨大的数据存储(约1艾字节)以及嵌入的科学知识成为一个至关重要的优先事项。

Method: 利用大型语言模型，使用检索增强生成和模型上下文协议，该助手对RHIC实验的结构化和非结构化内容进行索引，并实现领域自适应交互。

Result: 我们报告了为可持续和可解释的长期人工智能访问而设计的部署、计算性能、正在进行的多实验集成和架构特性。

Conclusion: 我们的经验表明，现代人工智能/机器学习工具可以改变科学遗产数据的可用性和可发现性。

Abstract: As the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National
Laboratory concludes 25 years of operation, preserving not only its vast data
holdings ($\sim$1 ExaByte) but also the embedded scientific knowledge becomes a
critical priority. The RHIC Data and Analysis Preservation Plan (DAPP)
introduces an AI-powered assistant system that provides natural language access
to documentation, workflows, and software, with the aim of supporting
reproducibility, education, and future discovery. Built upon Large Language
Models using Retrieval-Augmented Generation and the Model Context Protocol,
this assistant indexes structured and unstructured content from RHIC
experiments and enables domain-adapted interaction. We report on the
deployment, computational performance, ongoing multi-experiment integration,
and architectural features designed for a sustainable and explainable long-term
AI access. Our experience illustrates how modern AI/ML tools can transform the
usability and discoverability of scientific legacy data.

</details>


### [141] [Personas within Parameters: Fine-Tuning Small Language Models with Low-Rank Adapters to Mimic User Behaviors](https://arxiv.org/abs/2509.09689)
*Himanshu Thakur,Eshani Agrawal,Smruthi Mukund*

Main category: cs.IR

TL;DR: 本研究提出了一种新的方法，利用冻结的大型语言模型提取文本用户表示，并通过微调小型语言模型来模拟用户行为，从而经济高效地创建用户代理。


<details>
  <summary>Details</summary>
Motivation: 准确推荐模型的长期挑战在于模拟用户行为，这主要是由于用户交互的复杂性和随机性。现有方法难以有效地解析大规模表格用户-项目交互数据，克服预训练带来的归纳偏差，并大规模地学习用户特定知识。

Method: 该方法使用冻结的LLM提取鲁棒的文本用户表示，并使用微调的SLM来模拟经济高效的用户代理。此外，还展示了一种为用户或“角色”群体训练多个低秩适配器的方法。

Result: 实验结果表明，使用该方法开发的用户代理具有缩小离线指标与推荐系统真实性能之间差距的潜力。

Conclusion: 该研究证明了所提出方法的有效性，并表明其有潜力弥合离线指标与推荐系统真实性能之间的差距。

Abstract: A long-standing challenge in developing accurate recommendation models is
simulating user behavior, mainly due to the complex and stochastic nature of
user interactions. Towards this, one promising line of work has been the use of
Large Language Models (LLMs) for simulating user behavior. However, aligning
these general-purpose large pre-trained models with user preferences
necessitates: (i) effectively and continously parsing large-scale tabular
user-item interaction data, (ii) overcoming pre-training-induced inductive
biases to accurately learn user specific knowledge, and (iii) achieving the
former two at scale for millions of users. While most previous works have
focused on complex methods to prompt an LLM or fine-tune it on tabular
interaction datasets, our approach shifts the focus to extracting robust
textual user representations using a frozen LLM and simulating cost-effective,
resource-efficient user agents powered by fine-tuned Small Language Models
(SLMs). Further, we showcase a method for training multiple low-rank adapters
for groups of users or \textit{persona}, striking an optimal balance between
scalability and performance of user behavior agents. Our experiments provide
compelling empirical evidence of the efficacy of our methods, demonstrating
that user agents developed using our approach have the potential to bridge the
gap between offline metrics and real-world performance of recommender systems.

</details>


### [142] [Powering Job Search at Scale: LLM-Enhanced Query Understanding in Job Matching Systems](https://arxiv.org/abs/2509.09690)
*Ping Liu,Jianqiang Shen,Qianqi Shen,Chunnan Yao,Kevin Kao,Dan Xu,Rajat Arora,Baofen Zheng,Caleb Johnson,Liangjie Hong,Jingwei Wu,Wenjing Zhang*

Main category: cs.IR

TL;DR: 这篇论文提出了一个基于大型语言模型（LLM）的统一查询理解框架，以解决传统方法在处理现代搜索查询时面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于多个特定任务的命名实体识别模型，这种架构脆弱、维护成本高且难以适应变化。本文旨在克服这些局限性。

Method: 利用大型语言模型（LLM）联合建模用户查询和上下文信号（如个人资料属性），以生成结构化的解释。

Result: 在线A/B测试表明，该框架提高了相关性质量，同时显著降低了系统复杂性和运营开销。

Conclusion: 该解决方案为动态Web应用中的查询理解提供了一个可扩展和适应性强的基础。

Abstract: Query understanding is essential in modern relevance systems, where user
queries are often short, ambiguous, and highly context-dependent. Traditional
approaches often rely on multiple task-specific Named Entity Recognition models
to extract structured facets as seen in job search applications. However, this
fragmented architecture is brittle, expensive to maintain, and slow to adapt to
evolving taxonomies and language patterns. In this paper, we introduce a
unified query understanding framework powered by a Large Language Model (LLM),
designed to address these limitations. Our approach jointly models the user
query and contextual signals such as profile attributes to generate structured
interpretations that drive more accurate and personalized recommendations. The
framework improves relevance quality in online A/B testing while significantly
reducing system complexity and operational overhead. The results demonstrate
that our solution provides a scalable and adaptable foundation for query
understanding in dynamic web applications.

</details>


### [143] [A Research Vision for Web Search on Emerging Topics](https://arxiv.org/abs/2509.10212)
*Alisa Rieger,Stefan Dietze,Ran Yu*

Main category: cs.IR

TL;DR: 本文概述了关于搜索系统和界面的研究构想，旨在支持有效的知识获取、了解主题的动态性质以及在网络上搜索新兴主题信息的人们形成负责任的观点。


<details>
  <summary>Details</summary>
Motivation: 现有新兴主题的信息稀疏且动态演变，质量和可信度不确定，容易受到操纵、误导和偏见的影响。

Method: 本文提出了三个总体研究问题，旨在了解现状，确定与我们的愿景相符的系统要求，并构建这些系统。

Result: 针对这三个问题，本文重点介绍了相关文献，包括如何解决这些问题的指导。

Conclusion: 本文讨论了在追求拟议愿景时可能出现的挑战。

Abstract: We regularly encounter information on novel, emerging topics for which the
body of knowledge is still evolving, which can be linked, for instance, to
current events. A primary way to learn more about such topics is through web
search. However, information on emerging topics is sparse and evolves
dynamically as knowledge grows, making it uncertain and variable in quality and
trustworthiness and prone to deliberate or accidental manipulation,
misinformation, and bias. In this paper, we outline a research vision towards
search systems and interfaces that support effective knowledge acquisition,
awareness of the dynamic nature of topics, and responsible opinion formation
among people searching the web for information on emerging topics. To realize
this vision, we propose three overarching research questions, aimed at
understanding the status quo, determining requirements of systems aligned with
our vision, and building these systems. For each of the three questions, we
highlight relevant literature, including pointers on how they could be
addressed. Lastly, we discuss the challenges that will potentially arise in
pursuing the proposed vision.

</details>


### [144] [Model-agnostic post-hoc explainability for recommender systems](https://arxiv.org/abs/2509.10245)
*Irina Arévalo,Jose L Salmeron*

Main category: cs.IR

TL;DR: 本文提出了一种在推荐系统中使用删除诊断的系统方法，以提高模型的可解释性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统往往依赖复杂的特征嵌入和深度学习算法，但这降低了系统的可解释性和透明度。

Method: 该方法通过比较模型在有无特定用户或项目时的性能，来量化该观察结果对推荐系统的影响。

Result: 在MovieLens和Amazon Reviews数据集上的实验提供了对模型行为的见解，并突出了该方法在不同推荐范例中的通用性。

Conclusion: 该方法具有模型无关性，可以应用于基于深度学习的推荐模型和传统的协同过滤技术。

Abstract: Recommender systems often benefit from complex feature embeddings and deep
learning algorithms, which deliver sophisticated recommendations that enhance
user experience, engagement, and revenue. However, these methods frequently
reduce the interpretability and transparency of the system. In this research,
we develop a systematic application, adaptation, and evaluation of deletion
diagnostics in the recommender setting. The method compares the performance of
a model to that of a similar model trained without a specific user or item,
allowing us to quantify how that observation influences the recommender, either
positively or negatively. To demonstrate its model-agnostic nature, the
proposal is applied to both Neural Collaborative Filtering (NCF), a widely used
deep learning-based recommender, and Singular Value Decomposition (SVD), a
classical collaborative filtering technique. Experiments on the MovieLens and
Amazon Reviews datasets provide insights into model behavior and highlight the
generality of the approach across different recommendation paradigms.

</details>


### [145] [Diversified recommendations of cultural activities with personalized determinantal point processes](https://arxiv.org/abs/2509.10392)
*Carole Ibrahim,Hiba Bederina,Daniel Cuesta,Laurent Montier,Cyrille Delabre,Jill-Jênn Vie*

Main category: cs.IR

TL;DR: 本文探讨了在不影响核心业务指标的前提下，如何通过个性化行列式点过程（DPP）来优化推荐系统的多样性。


<details>
  <summary>Details</summary>
Motivation: 为了扩大用户群体的文化实践，研究如何有效地实现推荐多样化，这是一个重要的行业挑战。

Method: 使用个性化的行列式点过程（DPP）来对多样化和相关的推荐进行抽样。依赖于一种已知的质量-多样性分解的相似性核，以更多地考虑用户偏好。

Result: 通过离线和在线指标评估了相关性和多样性之间的权衡，并为从业者提供了在生产环境中使用它们的见解。 为了保证可重复性，在GitHub上发布了平台和实验的完整代码。

Conclusion: 个性化DPP抽样可以在保证推荐质量的同时，有效提高推荐的多样性。

Abstract: While optimizing recommendation systems for user engagement is a
well-established practice, effectively diversifying recommendations without
negatively impacting core business metrics remains a significant industry
challenge. In line with our initiative to broaden our audience's cultural
practices, this study investigates using personalized Determinantal Point
Processes (DPPs) to sample diverse and relevant recommendations. We rely on a
well-known quality-diversity decomposition of the similarity kernel to give
more weight to user preferences. In this paper, we present our implementations
of the personalized DPP sampling, evaluate the trade-offs between relevance and
diversity through both offline and online metrics, and give insights for
practitioners on their use in a production environment. For the sake of
reproducibility, we release the full code for our platform and experiments on
GitHub.

</details>


### [146] [RecoWorld: Building Simulated Environments for Agentic Recommender Systems](https://arxiv.org/abs/2509.10397)
*Fei Liu,Xinyu Lin,Hanchao Yu,Mingyuan Wu,Jianyu Wang,Qiang Zhang,Zhuokai Zhao,Yinglong Xia,Yao Zhang,Weiwei Li,Mingze Gao,Qifan Wang,Lizhu Zhang,Benyu Zhang,Xiangjun Fan*

Main category: cs.IR

TL;DR: RecoWorld是一个构建模拟环境的蓝图，专为代理推荐系统设计，允许agent在其中学习和改进。


<details>
  <summary>Details</summary>
Motivation: 为代理推荐系统提供一个安全的训练环境，避免对真实用户产生负面影响。

Method: 通过模拟用户和代理推荐者之间的多轮交互，利用用户模拟器更新心态并生成反馈指令，推荐者根据指令和推理轨迹调整推荐。

Result: RecoWorld支持多种内容表示和多智能体模拟，为个性化信息流的协同塑造奠定基础。

Conclusion: RecoWorld是朝着用户指导、推荐者响应的新交互模式迈出的重要一步，共同优化用户留存和参与度。

Abstract: We present RecoWorld, a blueprint for building simulated environments
tailored to agentic recommender systems. Such environments give agents a proper
training space where they can learn from errors without impacting real users.
RecoWorld distinguishes itself with a dual-view architecture: a simulated user
and an agentic recommender engage in multi-turn interactions aimed at
maximizing user retention. The user simulator reviews recommended items,
updates its mindset, and when sensing potential user disengagement, generates
reflective instructions. The agentic recommender adapts its recommendations by
incorporating these user instructions and reasoning traces, creating a dynamic
feedback loop that actively engages users. This process leverages the
exceptional reasoning capabilities of modern LLMs. We explore diverse content
representations within the simulator, including text-based, multimodal, and
semantic ID modeling, and discuss how multi-turn RL enables the recommender to
refine its strategies through iterative interactions. RecoWorld also supports
multi-agent simulations, allowing creators to simulate the responses of
targeted user populations. It marks an important first step toward recommender
systems where users and agents collaboratively shape personalized information
streams. We envision new interaction paradigms where "user instructs,
recommender responds," jointly optimizing user retention and engagement.

</details>


### [147] [MatSKRAFT: A framework for large-scale materials knowledge extraction from scientific tables](https://arxiv.org/abs/2509.10448)
*Kausik Hira,Mohd Zaki,Mausam,N. M. Anoop Krishnan*

Main category: cs.IR

TL;DR: MatSKRAFT是一个自动从表格数据中提取和整合材料科学知识的计算框架。


<details>
  <summary>Details</summary>
Motivation: 目前大多数实验数据都以半结构化格式存在，难以进行系统的提取和分析。

Method: 该方法将表格转换为图表示，并使用约束驱动的GNN进行处理，将科学原理直接编码到模型架构中。

Result: MatSKRAFT在属性提取和成分提取方面显著优于现有的大型语言模型，F1分数分别为88.68和71.35，且处理速度快19-496倍。

Conclusion: 该方法构建了一个包含超过535,000个条目的综合数据库，揭示了以前被忽视的具有独特属性组合的材料，并支持成分-属性关系的数据驱动发现。

Abstract: Scientific progress increasingly depends on synthesizing knowledge across
vast literature, yet most experimental data remains trapped in semi-structured
formats that resist systematic extraction and analysis. Here, we present
MatSKRAFT, a computational framework that automatically extracts and integrates
materials science knowledge from tabular data at unprecedented scale. Our
approach transforms tables into graph-based representations processed by
constraint-driven GNNs that encode scientific principles directly into model
architecture. MatSKRAFT significantly outperforms state-of-the-art large
language models, achieving F1 scores of 88.68 for property extraction and 71.35
for composition extraction, while processing data $19$-$496\times$ faster than
them (compared to the slowest and the fastest models, respectively) with modest
hardware requirements. Applied to nearly 69,000 tables from more than 47,000
research publications, we construct a comprehensive database containing over
535,000 entries, including 104,000 compositions that expand coverage beyond
major existing databases, pending manual validation. This systematic approach
reveals previously overlooked materials with distinct property combinations and
enables data-driven discovery of composition-property relationships forming the
cornerstone of materials and scientific discovery.

</details>


### [148] [Generative Engine Optimization: How to Dominate AI Search](https://arxiv.org/abs/2509.08919)
*Mahe Chen,Xiaoxuan Wang,Kaiwen Chen,Nick Koudas*

Main category: cs.IR

TL;DR: AI搜索引擎的出现改变了信息检索的方式，从传统的排序列表转变为综合的、有引文支持的答案。这需要一个新的范式，即生成引擎优化（GEO）。


<details>
  <summary>Details</summary>
Motivation: 探讨由ChatGPT、Perplexity和Gemini等生成式AI搜索引擎驱动的信息检索方式的转变，以及传统SEO实践面临的挑战。

Method: 通过一系列大规模的受控实验，跨多个垂直领域、语言和查询释义，量化分析了AI搜索和传统网络搜索（Google）在信息来源方面的关键差异。

Result: AI搜索在信息来源方面表现出系统性和压倒性的偏差，偏向于赢得媒体（第三方权威来源），而谷歌的混合更平衡。AI搜索服务在领域多样性、新鲜度、跨语言稳定性和对措辞的敏感性方面彼此差异显著。

Conclusion: 基于实证结果，制定了战略性的GEO议程，强调了为机器可扫描性和论证设计内容、主导赢得媒体以建立AI感知权威、采用引擎特定和语言感知策略，以及克服小众参与者的固有“大品牌偏见”的关键需求。

Abstract: The rapid adoption of generative AI-powered search engines like ChatGPT,
Perplexity, and Gemini is fundamentally reshaping information retrieval, moving
from traditional ranked lists to synthesized, citation-backed answers. This
shift challenges established Search Engine Optimization (SEO) practices and
necessitates a new paradigm, which we term Generative Engine Optimization
(GEO).
  This paper presents a comprehensive comparative analysis of AI Search and
traditional web search (Google). Through a series of large-scale, controlled
experiments across multiple verticals, languages, and query paraphrases, we
quantify critical differences in how these systems source information. Our key
findings reveal that AI Search exhibit a systematic and overwhelming bias
towards Earned media (third-party, authoritative sources) over Brand-owned and
Social content, a stark contrast to Google's more balanced mix. We further
demonstrate that AI Search services differ significantly from each other in
their domain diversity, freshness, cross-language stability, and sensitivity to
phrasing.
  Based on these empirical results, we formulate a strategic GEO agenda. We
provide actionable guidance for practitioners, emphasizing the critical need
to: (1) engineer content for machine scannability and justification, (2)
dominate earned media to build AI-perceived authority, (3) adopt
engine-specific and language-aware strategies, and (4) overcome the inherent
"big brand bias" for niche players. Our work provides the foundational
empirical analysis and a strategic framework for achieving visibility in the
new generative search landscape.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [Structure Matters: Brain Graph Augmentation via Learnable Edge Masking for Data-efficient Psychiatric Diagnosis](https://arxiv.org/abs/2509.09744)
*Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia*

Main category: cs.LG

TL;DR: 提出了一种名为SAM-BG的框架，用于学习具有结构语义保留的脑图表示，从而提高精神疾病诊断的准确性和可解释性，尤其是在小样本数据集中。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法依赖的增强策略可能会破坏脑图中的关键结构语义，从而导致精神疾病诊断不准确且难以解释。

Method: 该框架分为两个阶段：预训练阶段，使用少量标记子集训练边缘掩码器以捕获关键结构语义；自监督学习阶段，提取的结构先验指导结构感知增强过程，使模型能够学习更具语义意义和鲁棒性的表示。

Result: 在两个真实精神病数据集上的实验表明，SAM-BG优于现有方法，尤其是在小样本数据集中，并揭示了具有临床意义的连接模式，从而增强了可解释性。

Conclusion: SAM-BG框架通过结构语义保留学习脑图表示，提高了精神疾病诊断的准确性和可解释性，尤其是在小样本数据集中表现出色。

Abstract: The limited availability of labeled brain network data makes it challenging
to achieve accurate and interpretable psychiatric diagnoses. While
self-supervised learning (SSL) offers a promising solution, existing methods
often rely on augmentation strategies that can disrupt crucial structural
semantics in brain graphs. To address this, we propose SAM-BG, a two-stage
framework for learning brain graph representations with structural semantic
preservation. In the pre-training stage, an edge masker is trained on a small
labeled subset to capture key structural semantics. In the SSL stage, the
extracted structural priors guide a structure-aware augmentation process,
enabling the model to learn more semantically meaningful and robust
representations. Experiments on two real-world psychiatric datasets demonstrate
that SAM-BG outperforms state-of-the-art methods, particularly in small-labeled
data settings, and uncovers clinically relevant connectivity patterns that
enhance interpretability. Our code is available at
https://github.com/mjliu99/SAM-BG.

</details>


### [150] [D-CAT: Decoupled Cross-Attention Transfer between Sensor Modalities for Unimodal Inference](https://arxiv.org/abs/2509.09747)
*Leen Daher,Zhaobo Wang,Malcolm Mielle*

Main category: cs.LG

TL;DR: 提出了一种名为D-CAT的跨模态迁移学习框架，该框架可以在无需联合传感器模态的情况下对齐特定模态的表示，从而改进多模态分类模型。


<details>
  <summary>Details</summary>
Motivation: 现有的跨模态迁移学习方法需要在训练和推理时都使用配对的传感器数据，这限制了在资源受限环境中的部署。

Method: 结合了用于特征提取的自注意力模块和新颖的交叉注意力对齐损失，该损失强制传感器特征空间的对齐，而无需耦合两种模态的分类管道。

Result: 在同分布场景中，从高性能模态（例如，视频到IMU）的迁移比单模态训练产生高达10％的F1分数增益。在异地分布场景中，即使较弱的源模态（例如，IMU到视频）也可以提高目标性能，只要目标模型没有过度拟合训练数据。

Conclusion: D-CAT通过使用跨模态知识实现单传感器推理，从而减少了感知系统的硬件冗余，同时保持了准确性，这对于成本敏感或自适应部署至关重要。

Abstract: Cross-modal transfer learning is used to improve multi-modal classification
models (e.g., for human activity recognition in human-robot collaboration).
However, existing methods require paired sensor data at both training and
inference, limiting deployment in resource-constrained environments where full
sensor suites are not economically and technically usable. To address this, we
propose Decoupled Cross-Attention Transfer (D-CAT), a framework that aligns
modality-specific representations without requiring joint sensor modality
during inference. Our approach combines a self-attention module for feature
extraction with a novel cross-attention alignment loss, which enforces the
alignment of sensors' feature spaces without requiring the coupling of the
classification pipelines of both modalities. We evaluate D-CAT on three
multi-modal human activity datasets (IMU, video, and audio) under both
in-distribution and out-of-distribution scenarios, comparing against uni-modal
models. Results show that in in-distribution scenarios, transferring from
high-performing modalities (e.g., video to IMU) yields up to 10% F1-score gains
over uni-modal training. In out-of-distribution scenarios, even weaker source
modalities (e.g., IMU to video) improve target performance, as long as the
target model isn't overfitted on the training data. By enabling single-sensor
inference with cross-modal knowledge, D-CAT reduces hardware redundancy for
perception systems while maintaining accuracy, which is critical for
cost-sensitive or adaptive deployments (e.g., assistive robots in homes with
variable sensor availability). Code is available at
https://github.com/Schindler-EPFL-Lab/D-CAT.

</details>


### [151] [Meta-Learning Reinforcement Learning for Crypto-Return Prediction](https://arxiv.org/abs/2509.09751)
*Junqiao Wang,Zhaoyang Guan,Guanyu Liu,Tianze Xia,Xianzhi Li,Shuo Yin,Xinyuan Song,Chuhan Cheng,Tianyu Shi,Alex Lee*

Main category: cs.LG

TL;DR: 提出了一种基于Transformer的统一架构Meta-RL-Crypto，用于预测加密货币收益。


<details>
  <summary>Details</summary>
Motivation: 预测加密货币回报非常困难，价格波动受链上活动、新闻流和社会情绪的快速变化的影响，并且标记的训练数据稀缺且昂贵。

Method: 该架构统一了元学习和强化学习（RL），以创建一个完全自我改进的交易代理。从vanilla指令调整的LLM开始，agent在闭环架构中迭代地在三种角色（actor、judge和meta-judge）之间交替。

Result: 实验表明，Meta-RL-Crypto在真实市场的技术指标上表现良好，并且优于其他基于LLM的基线。

Conclusion: Meta-RL-Crypto 是一种有前景的加密货币交易agent。

Abstract: Predicting cryptocurrency returns is notoriously difficult: price movements
are driven by a fast-shifting blend of on-chain activity, news flow, and social
sentiment, while labeled training data are scarce and expensive. In this paper,
we present Meta-RL-Crypto, a unified transformer-based architecture that
unifies meta-learning and reinforcement learning (RL) to create a fully
self-improving trading agent. Starting from a vanilla instruction-tuned LLM,
the agent iteratively alternates between three roles-actor, judge, and
meta-judge-in a closed-loop architecture. This learning process requires no
additional human supervision. It can leverage multimodal market inputs and
internal preference feedback. The agent in the system continuously refines both
the trading policy and evaluation criteria. Experiments across diverse market
regimes demonstrate that Meta-RL-Crypto shows good performance on the technical
indicators of the real market and outperforming other LLM-based baselines.

</details>


### [152] [LAVa: Layer-wise KV Cache Eviction with Dynamic Budget Allocation](https://arxiv.org/abs/2509.09754)
*Yiqun Shen,Song Yuan,Zhengze Zhang,Xiaoliang Wang,Daxin Jiang,Nguyen Cam-Tu*

Main category: cs.LG

TL;DR: 提出了一种新的KV缓存压缩框架LAVa，它通过最小化Transformer残差流中的信息损失来实现动态预算分配，无需训练或组合多种策略。


<details>
  <summary>Details</summary>
Motivation: 现有的缓存压缩方法大多是启发式的，缺乏动态预算分配。

Method: 通过分析层注意力输出损失，推导出一个新的指标来比较不同头的缓存条目，从而实现具有动态头预算的层压缩。此外，通过对比跨层信息，还实现了动态层预算。

Result: 在多个基准测试中表现出色，并揭示了动态层预算对于生成任务至关重要，而动态头预算在提取任务中起关键作用。

Conclusion: LAVa作为一种完全动态的压缩方法，在各种任务类型中始终保持最佳性能。

Abstract: KV Cache is commonly used to accelerate LLM inference with long contexts, yet
its high memory demand drives the need for cache compression. Existing
compression methods, however, are largely heuristic and lack dynamic budget
allocation. To address this limitation, we introduce a unified framework for
cache compression by minimizing information loss in Transformer residual
streams. Building on it, we analyze the layer attention output loss and derive
a new metric to compare cache entries across heads, enabling layer-wise
compression with dynamic head budgets. Additionally, by contrasting cross-layer
information, we also achieve dynamic layer budgets. LAVa is the first unified
strategy for cache eviction and dynamic budget allocation that, unlike prior
methods, does not rely on training or the combination of multiple strategies.
Experiments with benchmarks (LongBench, Needle-In-A-Haystack, Ruler, and
InfiniteBench) demonstrate its superiority. Moreover, our experiments reveal a
new insight: dynamic layer budgets are crucial for generation tasks (e.g., code
completion), while dynamic head budgets play a key role in extraction tasks
(e.g., extractive QA). As a fully dynamic compression method, LAVa consistently
maintains top performance across task types. Our code is available at
https://github.com/MGDDestiny/Lava.

</details>


### [153] [Hybrid Adaptive Conformal Offline Reinforcement Learning for Fair Population Health Management](https://arxiv.org/abs/2509.09772)
*Sanjay Basu,Sadiq Y. Patel,Parth Sheth,Bhairavi Muralidharan,Namrata Elamaran,Aakriti Kinra,Rajaie Batniji*

Main category: cs.LG

TL;DR: 提出了一种混合自适应共形离线强化学习（HACO）框架，用于人口健康管理，旨在生成保守且可审计的行动建议。


<details>
  <summary>Details</summary>
Motivation: 人口健康管理项目需要协调纵向拓展和服务，并且必须安全、公平和可审计。该研究着眼于在控制近期不良事件风险的同时，选择合适的协调行动。

Method: HACO框架分离了风险校准和偏好优化，包括训练风险模型、推导共形阈值以屏蔽不安全行动，以及在安全子集上学习偏好策略。

Result: HACO在风险区分方面表现出色(AUC ~0.81)，具有校准阈值，同时保持较高的安全覆盖率。亚组分析揭示了不同人群在估计价值方面的系统性差异。

Conclusion: 共形风险门控与离线强化学习相结合，为人口健康管理团队提供保守且可审计的决策支持。

Abstract: Population health management programs for Medicaid populations coordinate
longitudinal outreach and services (e.g., benefits navigation, behavioral
health, social needs support, and clinical scheduling) and must be safe, fair,
and auditable. We present a Hybrid Adaptive Conformal Offline Reinforcement
Learning (HACO) framework that separates risk calibration from preference
optimization to generate conservative action recommendations at scale. In our
setting, each step involves choosing among common coordination actions (e.g.,
which member to contact, by which modality, and whether to route to a
specialized service) while controlling the near-term risk of adverse
utilization events (e.g., unplanned emergency department visits or
hospitalizations). Using a de-identified operational dataset from Waymark
comprising 2.77 million sequential decisions across 168,126 patients, HACO (i)
trains a lightweight risk model for adverse events, (ii) derives a conformal
threshold to mask unsafe actions at a target risk level, and (iii) learns a
preference policy on the resulting safe subset. We evaluate policies with a
version-agnostic fitted Q evaluation (FQE) on stratified subsets and audit
subgroup performance across age, sex, and race. HACO achieves strong risk
discrimination (AUC ~0.81) with a calibrated threshold ( {\tau} ~0.038 at
{\alpha} = 0.10), while maintaining high safe coverage. Subgroup analyses
reveal systematic differences in estimated value across demographics,
underscoring the importance of fairness auditing. Our results show that
conformal risk gating integrates cleanly with offline RL to deliver
conservative, auditable decision support for population health management
teams.

</details>


### [154] [One Head, Many Models: Cross-Attention Routing for Cost-Aware LLM Selection](https://arxiv.org/abs/2509.09782)
*Roshini Pulishetty,Mani Kishan Ghantasala,Keerthy Kaushik Dasoju,Niti Mangwani,Vishal Garimella,Aditya Mate,Somya Chatterjee,Yue Kang,Ehi Nosakhare,Sadid Hasan,Soundar Srinivasan*

Main category: cs.LG

TL;DR: 提出了一种统一的路由框架，通过单头交叉注意力机制动态选择最优LLM。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，大规模语言模型（LLM）的计算成本和性能差异大，难以规模化和低成本部署。

Method: 利用单头交叉注意力机制联合建模查询和模型嵌入，动态选择每个输入查询的最优LLM。

Result: 在RouterBench上评估，在平均质量改进（AIQ）方面提高了6.6%，在最大性能方面提高了2.9%。

Conclusion: 该架构轻量级，跨领域泛化能力强，效率更高，为成本感知的LLM路由建立了新标准。

Abstract: The proliferation of large language models (LLMs) with varying computational
costs and performance profiles presents a critical challenge for scalable,
cost-effective deployment in real-world applications. We introduce a unified
routing framework that leverages a single-head cross-attention mechanism to
jointly model query and model embeddings, enabling dynamic selection of the
optimal LLM for each input query. Our approach is evaluated on RouterBench, a
large-scale, publicly available benchmark encompassing diverse LLM pools and
domains. By explicitly capturing fine-grained query-model interactions, our
router predicts both response quality and generation cost, achieving up to 6.6%
improvement in Average Improvement in Quality (AIQ) and 2.9% in maximum
performance over existing routers. To robustly balance performance and cost, we
propose an exponential reward function that enhances stability across user
preferences. The resulting architecture is lightweight, generalizes effectively
across domains, and demonstrates improved efficiency compared to prior methods,
establishing a new standard for cost-aware LLM routing.

</details>


### [155] [From the Gradient-Step Denoiser to the Proximal Denoiser and their associated convergent Plug-and-Play algorithms](https://arxiv.org/abs/2509.09793)
*Vincent Herfeld,Baudouin Denis de Senneville,Arthur Leclaire,Nicolas Papadakis*

Main category: cs.LG

TL;DR: 本论文分析了梯度步降噪器及其在即插即用算法中的应用。


<details>
  <summary>Details</summary>
Motivation: 即插即用优化算法使用现成的降噪器来代替图像先验的邻近算子或梯度下降算子。通常，这种图像先验是隐式的，无法表达。

Method: 本论文研究了梯度步降噪器，该降噪器经过训练，可以精确地作为显式泛函的梯度下降算子或邻近算子。

Result: 梯度步降噪器在保持最先进的降噪能力的同时，能够精确地作为显式泛函的梯度下降算子或邻近算子。

Conclusion: 此论文 исследует 梯度步降噪器在即插即用算法中的应用

Abstract: In this paper we analyze the Gradient-Step Denoiser and its usage in
Plug-and-Play algorithms. The Plug-and-Play paradigm of optimization algorithms
uses off the shelf denoisers to replace a proximity operator or a gradient
descent operator of an image prior. Usually this image prior is implicit and
cannot be expressed, but the Gradient-Step Denoiser is trained to be exactly
the gradient descent operator or the proximity operator of an explicit
functional while preserving state-of-the-art denoising capabilities.

</details>


### [156] [Distinguishing Startle from Surprise Events Based on Physiological Signals](https://arxiv.org/abs/2509.09799)
*Mansi Sharma,Alexandre Duchevet,Florian Daiber,Jean-Paul Imbert,Maurice Rekrut*

Main category: cs.LG

TL;DR: 该研究旨在通过生理信号，利用机器学习和多模态融合策略区分惊吓和惊讶事件，从而解决意外事件对高风险环境中注意力和决策的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的研究大多孤立地研究这些反应，很少关注它们的综合影响，或者如何使用生理数据来区分它们。这项工作旨在填补这一空白。

Method: 利用机器学习和多模态融合策略，基于生理信号区分惊吓和惊讶事件。

Result: 该模型能够可靠地预测这些事件，使用SVM和Late Fusion实现了85.7%的最高平均准确率。在区分惊吓、惊讶和基线状态时，使用XGBoost和Late Fusion实现了74.9%的最高平均准确率。

Conclusion: 通过生理信号可以有效区分惊吓和惊讶事件。

Abstract: Unexpected events can impair attention and delay decision-making, posing
serious safety risks in high-risk environments such as aviation. In particular,
reactions like startle and surprise can impact pilot performance in different
ways, yet are often hard to distinguish in practice. Existing research has
largely studied these reactions separately, with limited focus on their
combined effects or how to differentiate them using physiological data. In this
work, we address this gap by distinguishing between startle and surprise events
based on physiological signals using machine learning and multi-modal fusion
strategies. Our results demonstrate that these events can be reliably
predicted, achieving a highest mean accuracy of 85.7% with SVM and Late Fusion.
To further validate the robustness of our model, we extended the evaluation to
include a baseline condition, successfully differentiating between Startle,
Surprise, and Baseline states with a highest mean accuracy of 74.9% with
XGBoost and Late Fusion.

</details>


### [157] [Revisiting Actor-Critic Methods in Discrete Action Off-Policy Reinforcement Learning](https://arxiv.org/abs/2509.09838)
*Reza Asad,Reza Babanezhad,Sharan Vaswani*

Main category: cs.LG

TL;DR: 本文改进了离散动作空间下的Actor-Critic方法，使其性能可与DQN相媲美。


<details>
  <summary>Details</summary>
Motivation: 传统的基于策略的方法要么是on-policy的，不能有效地从off-policy数据中学习，要么在离散动作设置中表现不佳(例如SAC)。

Method: 通过解耦actor和critic的熵，并结合m步贝尔曼算子进行critic更新，提出了一个灵活的off-policy actor-critic框架。

Result: 在Atari游戏上，该方法可以达到与DQN相当的性能，即使没有熵正则化或显式探索。

Conclusion: 所提出的方法在理论上保证了在表格设置中收敛到最优正则化值函数，并在实践中证明了其有效性。

Abstract: Value-based approaches such as DQN are the default methods for off-policy
reinforcement learning with discrete-action environments such as Atari. Common
policy-based methods are either on-policy and do not effectively learn from
off-policy data (e.g. PPO), or have poor empirical performance in the
discrete-action setting (e.g. SAC). Consequently, starting from discrete SAC
(DSAC), we revisit the design of actor-critic methods in this setting. First,
we determine that the coupling between the actor and critic entropy is the
primary reason behind the poor performance of DSAC. We demonstrate that by
merely decoupling these components, DSAC can have comparable performance as
DQN. Motivated by this insight, we introduce a flexible off-policy actor-critic
framework that subsumes DSAC as a special case. Our framework allows using an
m-step Bellman operator for the critic update, and enables combining standard
policy optimization methods with entropy regularization to instantiate the
resulting actor objective. Theoretically, we prove that the proposed methods
can guarantee convergence to the optimal regularized value function in the
tabular setting. Empirically, we demonstrate that these methods can approach
the performance of DQN on standard Atari games, and do so even without entropy
regularization or explicit exploration.

</details>


### [158] [HGEN: Heterogeneous Graph Ensemble Networks](https://arxiv.org/abs/2509.09843)
*Jiajun Shen,Yufei Jin,Yi He,Xingquan Zhu*

Main category: cs.LG

TL;DR: 本论文提出了异构图集成学习框架HGEN，通过元路径和基于转换的优化流程集成多个学习器，以提高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 异构图中节点类型、节点特征和局部邻域拓扑的异质性给集成学习带来了挑战，尤其是在适应不同的图学习器方面。

Method: HGEN使用元路径结合随机丢弃创建Allele图神经网络（GNN），训练和对齐基本图学习器以进行后续集成。HGEN包含两个关键组件：1）残差注意力机制，用于校准不同元路径的Allele GNN，从而使节点嵌入专注于更具信息的图，以提高基本学习器的准确性；2）相关正则化项，用于扩大从不同元路径生成的嵌入矩阵之间的差异，从而丰富基本学习器的多样性。

Result: 在五个异构网络上的实验表明，HGEN始终以显著的优势优于其最先进的竞争对手。

Conclusion: HGEN的收敛性分析和更高的正则化幅度验证了其有效性。

Abstract: This paper presents HGEN that pioneers ensemble learning for heterogeneous
graphs. We argue that the heterogeneity in node types, nodal features, and
local neighborhood topology poses significant challenges for ensemble learning,
particularly in accommodating diverse graph learners. Our HGEN framework
ensembles multiple learners through a meta-path and transformation-based
optimization pipeline to uplift classification accuracy. Specifically, HGEN
uses meta-path combined with random dropping to create Allele Graph Neural
Networks (GNNs), whereby the base graph learners are trained and aligned for
later ensembling. To ensure effective ensemble learning, HGEN presents two key
components: 1) a residual-attention mechanism to calibrate allele GNNs of
different meta-paths, thereby enforcing node embeddings to focus on more
informative graphs to improve base learner accuracy, and 2) a
correlation-regularization term to enlarge the disparity among embedding
matrices generated from different meta-paths, thereby enriching base learner
diversity. We analyze the convergence of HGEN and attest its higher
regularization magnitude over simple voting. Experiments on five heterogeneous
networks validate that HGEN consistently outperforms its state-of-the-art
competitors by substantial margin.

</details>


### [159] [Latency and Token-Aware Test-Time Compute](https://arxiv.org/abs/2509.09864)
*Jenny Y. Huang,Mehul Damani,Yousef El-Kurdi,Ramon Astudillo,Wei Sun*

Main category: cs.LG

TL;DR: Inference-time scaling improves LLM performance, but existing methods overlook incremental decoding and latency.


<details>
  <summary>Details</summary>
Motivation: Existing dynamic allocation methods for LLMs during inference don't fully consider incremental decoding methods like beam search and often ignore latency, focusing solely on token usage.

Method: This paper formulates inference-time scaling as a dynamic compute allocation and method selection problem, incorporating both token cost and wall-clock latency.

Result: The proposed approach consistently outperforms static strategies on reasoning benchmarks, achieving better accuracy-cost trade-offs.

Conclusion: The approach is practical for deployment and improves accuracy-cost trade-offs by dynamically allocating compute and considering latency.

Abstract: Inference-time scaling has emerged as a powerful way to improve large
language model (LLM) performance by generating multiple candidate responses and
selecting among them. However, existing work on dynamic allocation for
test-time compute typically considers only parallel generation methods such as
best-of-N, overlooking incremental decoding methods like beam search, and has
largely ignored latency, focusing only on token usage. We formulate
inference-time scaling as a problem of dynamic compute allocation and method
selection, where the system must decide which strategy to apply and how much
compute to allocate on a per-query basis. Our framework explicitly incorporates
both token cost and wall-clock latency, the latter being critical for user
experience and particularly for agentic workflows where models must issue
multiple queries efficiently. Experiments on reasoning benchmarks show that our
approach consistently outperforms static strategies, achieving favorable
accuracy-cost trade-offs while remaining practical for deployment.

</details>


### [160] [Variational Neural Networks for Observable Thermodynamics (V-NOTS)](https://arxiv.org/abs/2509.09899)
*Christopher Eldred,François Gay-Balmaz,Vakhtang Putkaradze*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于热力学拉格朗日量的新型数据驱动计算框架，该框架仅使用可观测变量，用于描述耗散动力系统的相空间演化。


<details>
  <summary>Details</summary>
Motivation: 在许多情况下，可用数据与定义系统相空间的变量不对应，例如耗散动力学系统中动量和熵通常无法直接观测。

Method: 该方法基于热力学拉格朗日量，并构建尊重热力学并保证熵不减的神经网络。

Result: 该网络能够基于有限数量的数据点和相对较少的系统参数，有效地描述相空间演化。

Conclusion: 该研究提供了一种有效的方法，仅使用可观测变量即可对耗散动力系统的相空间演化进行数据驱动的计算。

Abstract: Much attention has recently been devoted to data-based computing of evolution
of physical systems. In such approaches, information about data points from
past trajectories in phase space is used to reconstruct the equations of motion
and to predict future solutions that have not been observed before. However, in
many cases, the available data does not correspond to the variables that define
the system's phase space. We focus our attention on the important example of
dissipative dynamical systems. In that case, the phase space consists of
coordinates, momenta and entropies; however, the momenta and entropies cannot,
in general, be observed directly. To address this difficulty, we develop an
efficient data-based computing framework based exclusively on observable
variables, by constructing a novel approach based on the \emph{thermodynamic
Lagrangian}, and constructing neural networks that respect the thermodynamics
and guarantees the non-decreasing entropy evolution. We show that our network
can provide an efficient description of phase space evolution based on a
limited number of data points and a relatively small number of parameters in
the system.

</details>


### [161] [LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios](https://arxiv.org/abs/2509.09926)
*Jiahao Chen,Zhiyuan Huang,Yurou Liu,Bing Su*

Main category: cs.LG

TL;DR: 本文提出了一种新的长尾半监督学习框架，通过微调预训练模型来解决过自信和低质量伪标签的问题，并在开放世界条件下提高了模型的判别能力。


<details>
  <summary>Details</summary>
Motivation: 以往的长尾半监督学习方法从头开始训练模型，容易导致过自信和低质量伪标签。

Method: 本文将长尾半监督学习扩展到基础模型微调范式，提出了LoFT框架，并针对开放世界条件下的半监督学习提出了LoFT-OW。

Result: 实验结果表明，该方法在多个基准测试中取得了优于以往方法的结果，即使只使用以往工作1%的未标记数据。

Conclusion: 微调后的基础模型可以生成更可靠的伪标签，从而有利于不平衡学习，并且LoFT-OW提高了模型的判别能力。

Abstract: Long-tailed learning has garnered increasing attention due to its wide
applicability in real-world scenarios. Among existing approaches, Long-Tailed
Semi-Supervised Learning (LTSSL) has emerged as an effective solution by
incorporating a large amount of unlabeled data into the imbalanced labeled
dataset. However, most prior LTSSL methods are designed to train models from
scratch, which often leads to issues such as overconfidence and low-quality
pseudo-labels. To address these challenges, we extend LTSSL into the foundation
model fine-tuning paradigm and propose a novel framework: LoFT (Long-tailed
semi-supervised learning via parameter-efficient Fine-Tuning). We demonstrate
that fine-tuned foundation models can generate more reliable pseudolabels,
thereby benefiting imbalanced learning. Furthermore, we explore a more
practical setting by investigating semi-supervised learning under open-world
conditions, where the unlabeled data may include out-of-distribution (OOD)
samples. To handle this problem, we propose LoFT-OW (LoFT under Open-World
scenarios) to improve the discriminative ability. Experimental results on
multiple benchmarks demonstrate that our method achieves superior performance
compared to previous approaches, even when utilizing only 1\% of the unlabeled
data compared with previous works.

</details>


### [162] [Multi-Play Combinatorial Semi-Bandit Problem](https://arxiv.org/abs/2509.09933)
*Shintaro Nakamura,Yuko Kuroki,Wei Chen*

Main category: cs.LG

TL;DR: 本文提出了多重组合半bandit(MP-CSB)问题，允许选择非负整数动作，并观察每个回合中来自单个臂的多个反馈。


<details>
  <summary>Details</summary>
Motivation: 传统的组合半bandit(CSB)问题仅限于二元决策空间，无法处理涉及非负整数流或分配的问题，如最佳传输和背包问题。

Method: 提出了两种MP-CSB算法：一种是基于Thompson抽样的算法，另一种是兼顾两全其美的算法。

Result: 基于Thompson抽样的算法在随机情况下实现了O(log T)的分布依赖遗憾。兼顾两全其美的算法在随机情况下实现了O(log T)的方差依赖遗憾，在对抗情况下实现了tilde O(sqrt(T))的遗憾。数值结果表明，所提出的算法优于现有的CSB方法。

Conclusion: 提出的MP-CSB框架和算法为解决涉及非负整数流或分配的组合优化问题提供了新的思路。

Abstract: In the combinatorial semi-bandit (CSB) problem, a player selects an action
from a combinatorial action set and observes feedback from the base arms
included in the action. While CSB is widely applicable to combinatorial
optimization problems, its restriction to binary decision spaces excludes
important cases involving non-negative integer flows or allocations, such as
the optimal transport and knapsack problems.To overcome this limitation, we
propose the multi-play combinatorial semi-bandit (MP-CSB), where a player can
select a non-negative integer action and observe multiple feedbacks from a
single arm in each round. We propose two algorithms for the MP-CSB. One is a
Thompson-sampling-based algorithm that is computationally feasible even when
the action space is exponentially large with respect to the number of arms, and
attains $O(\log T)$ distribution-dependent regret in the stochastic regime,
where $T$ is the time horizon. The other is a best-of-both-worlds algorithm,
which achieves $O(\log T)$ variance-dependent regret in the stochastic regime
and the worst-case $\tilde{\mathcal{O}}\left( \sqrt{T} \right)$ regret in the
adversarial regime. Moreover, its regret in adversarial one is data-dependent,
adapting to the cumulative loss of the optimal action, the total quadratic
variation, and the path-length of the loss sequence. Finally, we numerically
show that the proposed algorithms outperform existing methods in the CSB
literature.

</details>


### [163] [SciML Agents: Write the Solver, Not the Solution](https://arxiv.org/abs/2509.09936)
*Saarth Gaonkar,Xiang Zheng,Haocheng Xi,Rishabh Tiwari,Kurt Keutzer,Dmitriy Morozov,Michael W. Mahoney,Amir Gholami*

Main category: cs.LG

TL;DR: 这篇论文探索了使用大型语言模型（LLMs）生成代码以利用数值算法来解决科学计算任务，特别是常微分方程（ODE）问题，而不是直接用神经网络预测目标值。论文提出了两个新的数据集来评估LLMs在此任务上的能力，并评估了不同LLM模型在生成可执行和数值有效的代码方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的科学机器学习方法在实现高精度和鲁棒性方面面临挑战。论文旨在探索一种替代方案，即利用LLMs生成代码，结合已有的数值算法，从而将负担从学习解决方案转移到做出领域相关的数值选择。

Method: 论文构建了两个新的数据集：一个包含对抗性“误导性”问题的诊断数据集和一个包含1000个多样化ODE任务的大规模基准。论文评估了开源和闭源LLM模型在不同prompting策略（有指导vs无指导）和模型变体（预训练vs微调）下的表现。评估指标包括代码的可执行性和数值有效性。

Result: 研究发现，通过足够的上下文和有指导的prompting，较新的指令遵循模型在可执行性和数值有效性方面都取得了较高的准确性。在许多情况下，最近的开源系统在没有微调的情况下表现出色，而较旧或较小的模型仍然受益于微调。

Conclusion: 初步结果表明，仔细的prompting和微调可以产生一个专门的LLM agent，能够可靠地解决简单的ODE问题。

Abstract: Recent work in scientific machine learning aims to tackle scientific tasks
directly by predicting target values with neural networks (e.g.,
physics-informed neural networks, neural ODEs, neural operators, etc.), but
attaining high accuracy and robustness has been challenging. We explore an
alternative view: use LLMs to write code that leverages decades of numerical
algorithms. This shifts the burden from learning a solution function to making
domain-aware numerical choices. We ask whether LLMs can act as SciML agents
that, given a natural-language ODE description, generate runnable code that is
scientifically appropriate, selecting suitable solvers (stiff vs. non-stiff),
and enforcing stability checks. There is currently no benchmark to measure this
kind of capability for scientific computing tasks. As such, we first introduce
two new datasets: a diagnostic dataset of adversarial "misleading" problems;
and a large-scale benchmark of 1,000 diverse ODE tasks. The diagnostic set
contains problems whose superficial appearance suggests stiffness, and that
require algebraic simplification to demonstrate non-stiffness; and the
large-scale benchmark spans stiff and non-stiff ODE regimes. We evaluate open-
and closed-source LLM models along two axes: (i) unguided versus guided
prompting with domain-specific knowledge; and (ii) off-the-shelf versus
fine-tuned variants. Our evaluation measures both executability and numerical
validity against reference solutions. We find that with sufficient context and
guided prompts, newer instruction-following models achieve high accuracy on
both criteria. In many cases, recent open-source systems perform strongly
without fine-tuning, while older or smaller models still benefit from
fine-tuning. Overall, our preliminary results indicate that careful prompting
and fine-tuning can yield a specialized LLM agent capable of reliably solving
simple ODE problems.

</details>


### [164] [DyKen-Hyena: Dynamic Kernel Generation via Cross-Modal Attention for Multimodal Intent Recognition](https://arxiv.org/abs/2509.09940)
*Yifei Wang,Wenbin Wang,Yong Luo*

Main category: cs.LG

TL;DR: 提出了DyKen-Hyena模型，通过将音频和视觉线索转化为动态的、逐token的卷积核来调节文本特征提取，从而解决多模态意图识别中意图无关和冲突信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态意图识别模型容易受到意图无关和冲突信息的影响，并且在融合模态时可能会破坏主要的语言特征。

Method: 将音频和视觉线索转化为动态的、逐token的卷积核，直接调节文本特征提取。

Result: 在MIntRec和MIntRec2.0基准测试上取得了state-of-the-art的结果，并且在out-of-scope检测中F1-score提高了+10.46%。

Conclusion: 该方法创建了一种更强大的意图表示。

Abstract: Though Multimodal Intent Recognition (MIR) proves effective by utilizing rich
information from multiple sources (e.g., language, video, and audio), the
potential for intent-irrelevant and conflicting information across modalities
may hinder performance from being further improved. Most current models attempt
to fuse modalities by applying mechanisms like multi-head attention to unimodal
feature sequences and then adding the result back to the original
representation. This process risks corrupting the primary linguistic features
with noisy or irrelevant non-verbal signals, as it often fails to capture the
fine-grained, token-level influence where non-verbal cues should modulate, not
just augment, textual meaning. To address this, we introduce DyKen-Hyena, which
reframes the problem from feature fusion to processing modulation. Our model
translates audio-visual cues into dynamic, per-token convolutional kernels that
directly modulate textual feature extraction. This fine-grained approach
achieves state-of-the-art results on the MIntRec and MIntRec2.0 benchmarks.
Notably, it yields a +10.46% F1-score improvement in out-of-scope detection,
validating that our method creates a fundamentally more robust intent
representation.

</details>


### [165] [Adaptive Token Merging for Efficient Transformer Semantic Communication at the Edge](https://arxiv.org/abs/2509.09955)
*Omar Erak,Omar Alhussein,Hatem Abou-Zeid,Mehdi Bennis,Sami Muhaidat*

Main category: cs.LG

TL;DR: 提出了一种无需训练的自适应令牌合并框架，用于压缩transformer表示，以在资源受限的边缘设备上部署大型transformer模型。


<details>
  <summary>Details</summary>
Motivation: 大型transformer模型计算和通信成本高，难以在资源受限的边缘设备上部署。

Method: 通过选择性地合并语义冗余的令牌来压缩transformer表示，并利用贝叶斯优化来获得精度、推理成本和通信成本之间的Pareto最优权衡。

Result: 在ImageNet分类上，与未修改的transformer相比，计算量减少30%，通信成本降低20%，同时保持精度。在视觉问答方面，性能与完整LLaVA模型相当，但计算量减少三分之二，带宽降低十分之一。该方法在不同的信道条件下具有鲁棒性，并提供固有的隐私优势。

Conclusion: 该框架为在资源受限的边缘智能场景中部署强大的transformer模型提供了一种实用且通用的解决方案。

Abstract: Large-scale transformers are central to modern semantic communication, yet
their high computational and communication costs hinder deployment on
resource-constrained edge devices. This paper introduces a training-free
framework for adaptive token merging, a novel mechanism that compresses
transformer representations at runtime by selectively merging semantically
redundant tokens under per-layer similarity thresholds. Unlike prior
fixed-ratio reduction, our approach couples merging directly to input
redundancy, enabling data-dependent adaptation that balances efficiency and
task relevance without retraining. We cast the discovery of merging strategies
as a multi-objective optimization problem and leverage Bayesian optimization to
obtain Pareto-optimal trade-offs between accuracy, inference cost, and
communication cost. On ImageNet classification, we match the accuracy of the
unmodified transformer with 30\% fewer floating-point operations per second and
under 20\% of the original communication cost, while for visual question
answering our method achieves performance competitive with the full LLaVA model
at less than one-third of the compute and one-tenth of the bandwidth. Finally,
we show that our adaptive merging is robust across varying channel conditions
and provides inherent privacy benefits, substantially degrading the efficacy of
model inversion attacks. Our framework provides a practical and versatile
solution for deploying powerful transformer models in resource-limited edge
intelligence scenarios.

</details>


### [166] [Limited Reference, Reliable Generation: A Two-Component Framework for Tabular Data Generation in Low-Data Regimes](https://arxiv.org/abs/2509.09960)
*Mingxuan Jiang,Yongxin Wang,Ziyue Dai,Yicun Liu,Hongyi Nie,Sen Liu,Hongfeng Chai*

Main category: cs.LG

TL;DR: ReFine框架通过从可解释模型中提取规则并嵌入到提示中，显式地指导生成特定领域的特征分布，并应用双重粒度过滤策略来减少分布不平衡，从而优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的表格生成方法通常需要足够的参考数据，限制了它们在记录稀缺的特定领域数据库中的有效性。Prompt-based LLMs虽然灵活，但常常无法捕捉数据集特定的特征-标签依赖关系并生成冗余数据，导致下游任务性能下降。

Method: ReFine框架：(i) 从可解释模型中提取符号“if-then”规则，并将它们嵌入到提示中，以显式地指导生成特定领域的特征分布；(ii) 应用双重粒度过滤策略，抑制过度采样模式，并选择性地细化稀有但信息丰富的样本，以减少分布不平衡。

Result: 在各种回归和分类基准测试中，ReFine始终优于最先进的方法，在回归的R平方方面实现了高达0.44的绝对改进，在分类任务的F1得分方面实现了10.0%的相对改进。

Conclusion: ReFine框架能够有效解决现有表格生成方法在数据稀缺和领域特定性方面的局限性，并在下游任务中表现出显著的性能提升。

Abstract: Synthetic tabular data generation is increasingly essential in data
management, supporting downstream applications when real-world and high-quality
tabular data is insufficient. Existing tabular generation approaches, such as
generative adversarial networks (GANs), diffusion models, and fine-tuned Large
Language Models (LLMs), typically require sufficient reference data, limiting
their effectiveness in domain-specific databases with scarce records. While
prompt-based LLMs offer flexibility without parameter tuning, they often fail
to capture dataset-specific feature-label dependencies and generate redundant
data, leading to degradation in downstream task performance. To overcome these
issues, we propose ReFine, a framework that (i) derives symbolic "if-then"
rules from interpretable models and embeds them into prompts to explicitly
guide generation toward domain-specific feature distribution, and (ii) applies
a dual-granularity filtering strategy that suppresses over-sampling patterns
and selectively refines rare but informative samples to reduce distributional
imbalance. Extensive experiments on various regression and classification
benchmarks demonstrate that ReFine consistently outperforms state-of-the-art
methods, achieving up to 0.44 absolute improvement in R-squared for regression
and 10.0 percent relative improvement in F1 score for classification tasks.

</details>


### [167] [Data-Driven Energy Estimation for Virtual Servers Using Combined System Metrics and Machine Learning](https://arxiv.org/abs/2509.09991)
*Amandip Sangha*

Main category: cs.LG

TL;DR: 本文提出了一种基于机器学习的方法，用于在无法访问物理电源测量接口的情况下估算虚拟服务器的能耗。


<details>
  <summary>Details</summary>
Motivation: 在虚拟化环境（如云）中，直接能量测量是不可行的，本文旨在解决这个问题。

Method: 使用从客户虚拟机收集的资源利用率指标，训练一个梯度提升回归器来预测主机上的能量消耗。

Result: 实验表明，该方法在各种工作负载下实现了高预测精度和方差解释（$0.90 
unichar8804 R^2 
unichar8804 0.97$），表明了客户端能量估计的可行性。

Conclusion: 该方法可以在虚拟化环境中实现节能调度、成本优化和物理主机独立的能量估计。

Abstract: This paper presents a machine learning-based approach to estimate the energy
consumption of virtual servers without access to physical power measurement
interfaces. Using resource utilization metrics collected from guest virtual
machines, we train a Gradient Boosting Regressor to predict energy consumption
measured via RAPL on the host. We demonstrate, for the first time, guest-only
resource-based energy estimation without privileged host access with
experiments across diverse workloads, achieving high predictive accuracy and
variance explained ($0.90 \leq R^2 \leq 0.97$), indicating the feasibility of
guest-side energy estimation. This approach can enable energy-aware scheduling,
cost optimization and physical host independent energy estimates in virtualized
environments. Our approach addresses a critical gap in virtualized environments
(e.g. cloud) where direct energy measurement is infeasible.

</details>


### [168] [Neural Scaling Laws for Deep Regression](https://arxiv.org/abs/2509.10000)
*Tilen Cadez,Kyoung-Min Kim*

Main category: cs.LG

TL;DR: 研究了深度回归模型中的神经标度律，发现损失与训练数据集大小和模型容量之间存在幂律关系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的成功表明了神经标度律的重要性，但其在深度回归模型中的应用仍未被充分探索。

Method: 使用扭曲范德华磁体的参数估计模型，在深度回归中实证研究神经标度律，并采用各种架构，包括全连接网络、残差网络和视觉转换器。

Result: 观察到损失与训练数据集大小和模型容量之间的幂律关系，且这些关系的标度指数范围为 1 到 2，具体值取决于回归参数和模型细节。

Conclusion: 深度回归模型的性能可以通过增加数据量得到显着提高。

Abstract: Neural scaling laws--power-law relationships between generalization errors
and characteristics of deep learning models--are vital tools for developing
reliable models while managing limited resources. Although the success of large
language models highlights the importance of these laws, their application to
deep regression models remains largely unexplored. Here, we empirically
investigate neural scaling laws in deep regression using a parameter estimation
model for twisted van der Waals magnets. We observe power-law relationships
between the loss and both training dataset size and model capacity across a
wide range of values, employing various architectures--including fully
connected networks, residual networks, and vision transformers. Furthermore,
the scaling exponents governing these relationships range from 1 to 2, with
specific values depending on the regressed parameters and model details. The
consistent scaling behaviors and their large scaling exponents suggest that the
performance of deep regression models can improve substantially with increasing
data size.

</details>


### [169] [Intrinsic Dimension Estimating Autoencoder (IDEA) Using CancelOut Layer and a Projected Loss](https://arxiv.org/abs/2509.10011)
*Antoine Orioua,Philipp Krah,Julian Koellermeier*

Main category: cs.LG

TL;DR: 提出了内在维度估计自编码器 (IDEA)，它可以识别各种数据集的潜在内在维度，这些数据集的样本位于线性或非线性流形上。


<details>
  <summary>Details</summary>
Motivation: 超越估计内在维度，IDEA 还可以将原始数据集投影到相应的潜在空间后重建原始数据集。

Method: 使用重新加权的 double CancelOut 层构建潜在空间。关键贡献是引入了投影重建损失项，通过不断评估去除额外潜在维度下的重建质量来指导模型训练。

Result: 在理论基准上评估了 IDEA 的性能，以验证其鲁棒性。这些实验允许测试其重建能力，并将其性能与最先进的内在维度估计器进行比较。基准测试显示了我们方法的良好准确性和高度通用性。将我们的模型应用于从垂直解析的一维自由表面流的数值解生成的数据，在水平方向、垂直方向和时间上对垂直速度剖面进行逐点离散化。IDEA 成功地估计了数据集的内在维度，然后通过直接在网络识别的投影空间内工作来重建原始解决方案。

Conclusion: IDEA 能够有效地估计数据集的内在维度并重建原始解决方案。

Abstract: This paper introduces the Intrinsic Dimension Estimating Autoencoder (IDEA),
which identifies the underlying intrinsic dimension of a wide range of datasets
whose samples lie on either linear or nonlinear manifolds. Beyond estimating
the intrinsic dimension, IDEA is also able to reconstruct the original dataset
after projecting it onto the corresponding latent space, which is structured
using re-weighted double CancelOut layers. Our key contribution is the
introduction of the projected reconstruction loss term, guiding the training of
the model by continuously assessing the reconstruction quality under the
removal of an additional latent dimension. We first assess the performance of
IDEA on a series of theoretical benchmarks to validate its robustness. These
experiments allow us to test its reconstruction ability and compare its
performance with state-of-the-art intrinsic dimension estimators. The
benchmarks show good accuracy and high versatility of our approach.
Subsequently, we apply our model to data generated from the numerical solution
of a vertically resolved one-dimensional free-surface flow, following a
pointwise discretization of the vertical velocity profile in the horizontal
direction, vertical direction, and time. IDEA succeeds in estimating the
dataset's intrinsic dimension and then reconstructs the original solution by
working directly within the projection space identified by the network.

</details>


### [170] [Exploring Expert Specialization through Unsupervised Training in Sparse Mixture of Experts](https://arxiv.org/abs/2509.10025)
*Strahinja Nikolic,Ilker Oguz,Demetri Psaltis*

Main category: cs.LG

TL;DR: 本文提出了一种稀疏混合专家变分自编码器(SMoE-VAE)架构，用于理解神经网络的内部组织。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络的内部组织仍然是深度学习可解释性中的一个根本挑战。

Method: 在QuickDraw数据集上测试了该模型，并将无监督专家路由与有监督的基线进行比较。

Result: 无监督路由始终获得优越的重建性能。专家学习识别有意义的子类别结构，这些结构通常超越人类定义的类边界。

Conclusion: MoE模型能够发现与模型目标更一致的基本数据结构，并且数据集大小对专家 specialization 之间存在权衡。

Abstract: Understanding the internal organization of neural networks remains a
fundamental challenge in deep learning interpretability. We address this
challenge by exploring a novel Sparse Mixture of Experts Variational
Autoencoder (SMoE-VAE) architecture. We test our model on the QuickDraw
dataset, comparing unsupervised expert routing against a supervised baseline
guided by ground-truth labels. Surprisingly, we find that unsupervised routing
consistently achieves superior reconstruction performance. The experts learn to
identify meaningful sub-categorical structures that often transcend
human-defined class boundaries. Through t-SNE visualizations and reconstruction
analysis, we investigate how MoE models uncover fundamental data structures
that are more aligned with the model's objective than predefined labels.
Furthermore, our study on the impact of dataset size provides insights into the
trade-offs between data quantity and expert specialization, offering guidance
for designing efficient MoE architectures.

</details>


### [171] [Sparse Coding Representation of 2-way Data](https://arxiv.org/abs/2509.10033)
*Boya Ma,Abram Magner,Maxwell McNeil,Petko Bogdanov*

Main category: cs.LG

TL;DR: 本文提出了一种用于双字典场景的低秩编码模型，并研究了其数据复杂度。


<details>
  <summary>Details</summary>
Motivation: 多字典场景下的数据学习，由于编码系数对应于字典的所有原子组合，因此具有挑战性。

Method: 提出了一种凸松弛解 AODL，并证明了其精确解也解决了原始问题。然后，通过稀疏编码矩阵和学习字典之间的交替优化来解决这种松弛问题，我们证明了它是收敛的。

Result: 对于固定的重建质量，与非低秩和分析（固定）字典基线相比，AODL 学习的稀疏解决方案最多可提高 90%。此外，学习的字典揭示了对训练样本中存在的模式的可解释的见解。

Conclusion: 该文提出的 AODL 方法在合成和真实世界数据集中，在数据重建和缺失值估算方面都表现出了良好的性能。

Abstract: Sparse dictionary coding represents signals as linear combinations of a few
dictionary atoms. It has been applied to images, time series, graph signals and
multi-way spatio-temporal data by jointly employing temporal and spatial
dictionaries. Data-agnostic analytical dictionaries, such as the discrete
Fourier transform, wavelets and graph Fourier, have seen wide adoption due to
efficient implementations and good practical performance. On the other hand,
dictionaries learned from data offer sparser and more accurate solutions but
require learning of both the dictionaries and the coding coefficients. This
becomes especially challenging for multi-dictionary scenarios since encoding
coefficients correspond to all atom combinations from the dictionaries. To
address this challenge, we propose a low-rank coding model for 2-dictionary
scenarios and study its data complexity. Namely, we establish a bound on the
number of samples needed to learn dictionaries that generalize to unseen
samples from the same distribution. We propose a convex relaxation solution,
called AODL, whose exact solution we show also solves the original problem. We
then solve this relaxation via alternating optimization between the sparse
coding matrices and the learned dictionaries, which we prove to be convergent.
We demonstrate its quality for data reconstruction and missing value imputation
in both synthetic and real-world datasets. For a fixed reconstruction quality,
AODL learns up to 90\% sparser solutions compared to non-low-rank and
analytical (fixed) dictionary baselines. In addition, the learned dictionaries
reveal interpretable insights into patterns present within the samples used for
training.

</details>


### [172] [Symbolic Feedforward Networks for Probabilistic Finite Automata: Exact Simulation and Learnability](https://arxiv.org/abs/2509.10034)
*Sahil Rajesh Dhayalkar*

Main category: cs.LG

TL;DR: 概率有限自动机（PFA）可以使用符号前馈神经网络精确模拟。


<details>
  <summary>Details</summary>
Motivation: 论文旨在弥合符号计算和深度学习之间的差距，将概率自动机理论与神经架构统一在严格的代数框架下。

Method: 通过将状态分布表示为向量，将转换表示为随机矩阵，利用矩阵-向量积实现概率状态传播，构建了一种并行、可解释且可微的 PFA 动态模拟，使用软更新且无循环。

Result: 研究表明，这些符号模拟器不仅具有表达性，而且是可学习的：通过在标记序列数据上进行基于梯度下降的优化训练，它们可以恢复真实 PFA 的精确行为。论文中命题 5.1 对这种可学习性进行了形式化。

Conclusion: 研究结果将概率自动机理论与神经架构在严格的代数框架下统一起来，弥合了符号计算和深度学习之间的差距。

Abstract: We present a formal and constructive theory showing that probabilistic finite
automata (PFAs) can be exactly simulated using symbolic feedforward neural
networks. Our architecture represents state distributions as vectors and
transitions as stochastic matrices, enabling probabilistic state propagation
via matrix-vector products. This yields a parallel, interpretable, and
differentiable simulation of PFA dynamics using soft updates-without
recurrence. We formally characterize probabilistic subset construction,
$\varepsilon$-closure, and exact simulation via layered symbolic computation,
and prove equivalence between PFAs and specific classes of neural networks. We
further show that these symbolic simulators are not only expressive but
learnable: trained with standard gradient descent-based optimization on labeled
sequence data, they recover the exact behavior of ground-truth PFAs. This
learnability, formalized in Proposition 5.1, is the crux of this work. Our
results unify probabilistic automata theory with neural architectures under a
rigorous algebraic framework, bridging the gap between symbolic computation and
deep learning.

</details>


### [173] [Clip Your Sequences Fairly: Enforcing Length Fairness for Sequence-Level RL](https://arxiv.org/abs/2509.09177)
*Hanyi Mao,Quanjia Xiao,Lei Pang,Haixiao Liu*

Main category: cs.LG

TL;DR: 提出了FSPO，一种序列级别的强化学习方法，通过在重要性采样权重空间中实施长度公平的裁剪来优化LLM。


<details>
  <summary>Details</summary>
Motivation: 发现将PPO/GRPO风格的裁剪直接应用于序列时存在不匹配：固定的裁剪范围系统性地重新加权短序列与长序列，从而扭曲了有效目标。

Method: 引入了一种简单、受高斯分布启发的补救措施：使用一个带对序列log-IS比率进行裁剪，该带应用了经KL校正的漂移项，并按$\\sqrt{L}$缩放。

Result: FSPO在长度范围内展平了裁剪率，稳定了训练，并在多个评估数据集中优于所有基线。

Conclusion: FSPO通过长度公平裁剪，在序列强化学习中实现了更好的性能和稳定性。

Abstract: We propose FSPO (Fair Sequence Policy Optimization), a sequence-level
reinforcement learning method for LLMs that enforces length-fair clipping
directly in the importance-sampling (IS) weight space. We revisit
sequence-level RL methods and identify a mismatch when PPO/GRPO-style clipping
is transplanted to sequences: a fixed clip range systematically reweights short
vs. long responses, distorting the effective objective. Theoretically, we
formalize length fairness via a Length Reweighting Error (LRE) and prove that
small LRE yields a directional cosine guarantee between the clipped and true
updates. FSPO introduces a simple, Gaussian-motivated remedy: we clip the
sequence log-IS ratio with a band that applies a KL-corrected drift term and
scales as $\sqrt{L}$. Empirically, FSPO flattens clip rates across length bins,
stabilizes training, and outperforms all baselines across multiple evaluation
datasets.

</details>


### [174] [FedRP: A Communication-Efficient Approach for Differentially Private Federated Learning Using Random Projection](https://arxiv.org/abs/2509.10041)
*Mohammad Hasan Narimani,Mostafa Tavassolipour*

Main category: cs.LG

TL;DR: 提出了一种新的联邦学习算法，在保护用户隐私的同时，降低了通信成本，并保持了较高的模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习虽然可以在保护用户隐私的同时，提高预测性能，但是也面临着用户隐私保护和通信成本管理的挑战。

Method: 该论文提出了一种名为FedRP的联邦学习算法，该算法结合了随机投影技术和交替方向乘子法（ADMM）优化框架。

Result: 实验结果表明，FedRP不仅保持了较高的模型精度，而且在隐私保护和通信效率方面优于现有的方法，包括传统的差分隐私方法和FedADMM。

Conclusion: FedRP算法通过随机投影降低模型参数的维度，从而增强隐私保护，降低通信成本，同时保持较高的模型精度。

Abstract: Federated learning (FL) offers an innovative paradigm for collaborative model
training across decentralized devices, such as smartphones, balancing enhanced
predictive performance with the protection of user privacy in sensitive areas
like Internet of Things (IoT) and medical data analysis. Despite its
advantages, FL encounters significant challenges related to user privacy
protection against potential attacks and the management of communication costs.
This paper introduces a novel federated learning algorithm called FedRP, which
integrates random projection techniques with the Alternating Direction Method
of Multipliers (ADMM) optimization framework. This approach enhances privacy by
employing random projection to reduce the dimensionality of model parameters
prior to their transmission to a central server, reducing the communication
cost. The proposed algorithm offers a strong $(\epsilon, \delta)$-differential
privacy guarantee, demonstrating resilience against data reconstruction
attacks. Experimental results reveal that FedRP not only maintains high model
accuracy but also outperforms existing methods, including conventional
differential privacy approaches and FedADMM, in terms of both privacy
preservation and communication efficiency.

</details>


### [175] [AEGIS: An Agent for Extraction and Geographic Identification in Scholarly Proceedings](https://arxiv.org/abs/2509.09470)
*Om Vishesh,Harshad Khadilkar,Deepak Akkil*

Main category: cs.LG

TL;DR: 提出了一种自动化的系统，用于从学术文献中识别特定地理区域的论文，并执行预定义的操作，例如提交提名表。


<details>
  <summary>Details</summary>
Motivation: 学术文献快速增长，学者、资助机构和学术团体难以跟上，需要大量的人工进行学术发现。

Method: 构建了一个名为“Agent-E”的AI Agent，可以从会议记录中识别特定地理区域的论文，并执行机器人流程自动化（RPA）以完成预定义的操作。

Result: 在五个不同会议的586篇论文上验证了系统，成功识别了所有目标论文，召回率为100%，准确率接近99.4%。

Conclusion: 面向任务的AI Agent不仅可以过滤信息，还可以积极参与并加速学术界的工作流程。

Abstract: Keeping pace with the rapid growth of academia literature presents a
significant challenge for researchers, funding bodies, and academic societies.
To address the time-consuming manual effort required for scholarly discovery,
we present a novel, fully automated system that transitions from data discovery
to direct action. Our pipeline demonstrates how a specialized AI agent,
'Agent-E', can be tasked with identifying papers from specific geographic
regions within conference proceedings and then executing a Robotic Process
Automation (RPA) to complete a predefined action, such as submitting a
nomination form. We validated our system on 586 papers from five different
conferences, where it successfully identified every target paper with a recall
of 100% and a near perfect accuracy of 99.4%. This demonstration highlights the
potential of task-oriented AI agents to not only filter information but also to
actively participate in and accelerate the workflows of the academic community.

</details>


### [176] [Uncertainty-Aware Tabular Prediction: Evaluating VBLL-Enhanced TabPFN in Safety-Critical Medical Data](https://arxiv.org/abs/2509.10048)
*Madhushan Ramalingam*

Main category: cs.LG

TL;DR: 本文研究了将VBLL方法与TabPFN模型结合以提高不确定性估计，但实验结果表明原始TabPFN模型在不确定性校准方面优于集成VBLL的版本。


<details>
  <summary>Details</summary>
Motivation: 在医疗诊断和刑事司法等安全关键应用中，可靠的不确定性估计至关重要。TabPFN是一种新的表格数据机器学习基础模型，而VBLL是一种先进的轻量级变分公式，旨在有效提高不确定性估计。

Method: 本文通过在三个基准医疗表格数据集上进行实验，比较了原始TabPFN和集成VBLL的TabPFN的性能。

Result: 实验结果表明，原始TabPFN在不确定性校准方面始终优于集成VBLL的TabPFN。

Conclusion: 与预期相反，集成VBLL方法并没有提高TabPFN模型的不确定性校准性能。

Abstract: Predictive models are being increasingly used across a wide range of domains,
including safety-critical applications such as medical diagnosis and criminal
justice. Reliable uncertainty estimation is a crucial task in such settings.
Tabular Prior-data Fitted Network (TabPFN) is a recently proposed machine
learning foundation model for tabular dataset, which uses a generative
transformer architecture. Variational Bayesian Last Layers (VBLL) is a
state-of-the-art lightweight variational formulation that effectively improves
uncertainty estimation with minimal computational overhead. In this work we aim
to evaluate the performance of VBLL integrated with the recently proposed
TabPFN in uncertainty calibration. Our experiments, conducted on three
benchmark medical tabular datasets, compare the performance of the original
TabPFN and the VBLL-integrated version. Contrary to expectations, we observed
that original TabPFN consistently outperforms VBLL integrated TabPFN in
uncertainty calibration across all datasets.

</details>


### [177] [KAN-SR: A Kolmogorov-Arnold Network Guided Symbolic Regression Framework](https://arxiv.org/abs/2509.10089)
*Marco Andrea Bühler,Gonzalo Guillén-Gosálbez*

Main category: cs.LG

TL;DR: 提出了一个基于Kolmogorov Arnold Networks (KANs)的新型符号回归框架KAN-SR。


<details>
  <summary>Details</summary>
Motivation: 传统的符号回归通常使用遗传编程方法，而本文旨在使用深度学习技术来解决这个问题。

Method: 使用KANs，并结合平移对称性和可分离性等简化策略。

Result: 在Feynman Symbolic Regression for Scientific Discovery (SRSD)数据集上，能够恢复ground-truth方程。结合神经控制微分方程，能够精确建模in-silico生物过程系统的动态。

Conclusion: 该框架为其他工程系统的动态建模打开了大门。

Abstract: We introduce a novel symbolic regression framework, namely KAN-SR, built on
Kolmogorov Arnold Networks (KANs) which follows a divide-and-conquer approach.
Symbolic regression searches for mathematical equations that best fit a given
dataset and is commonly solved with genetic programming approaches. We show
that by using deep learning techniques, more specific KANs, and combining them
with simplification strategies such as translational symmetries and
separabilities, we are able to recover ground-truth equations of the Feynman
Symbolic Regression for Scientific Discovery (SRSD) dataset. Additionally, we
show that by combining the proposed framework with neural controlled
differential equations, we are able to model the dynamics of an in-silico
bioprocess system precisely, opening the door for the dynamic modeling of other
engineering systems.

</details>


### [178] [Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning](https://arxiv.org/abs/2509.10132)
*Nour Jamoussi,Giuseppe Serra,Photios A. Stavrou,Marios Kountouris*

Main category: cs.LG

TL;DR: 本文提出了一种新的贝叶斯联邦学习个性化方法，该方法通过将全局模型投影到用户局部模型的邻域来实现全局泛化和局部专业化之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 在异构数据和隐私约束下，现有的贝叶斯联邦学习方法难以在全局泛化和局部专业化之间取得平衡。

Method: 提出了一种基于信息几何投影框架的参数贝叶斯联邦学习个性化方法。该方法通过将全局模型投影到用户局部模型的邻域，实现了全局泛化和局部专业化之间的权衡。在温和的假设下，证明了该投影步骤等价于计算统计流形上的重心，从而能够推导出闭式解并实现无成本的个性化。

Result: 在异构数据分布下的经验评估表明，该方法能够有效地平衡全局和局部性能，且计算开销最小。

Conclusion: 该方法在贝叶斯联邦学习中实现了全局泛化和局部专业化的有效平衡，且计算开销最小。

Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with
decentralized training, enabling the development of personalized and reliable
models under data heterogeneity and privacy constraints. Existing approaches
typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational
inference, often incorporating personalization mechanisms to better adapt to
local data distributions. In this work, we propose an information-geometric
projection framework for personalization in parametric BFL. By projecting the
global model onto a neighborhood of the user's local model, our method enables
a tunable trade-off between global generalization and local specialization.
Under mild assumptions, we show that this projection step is equivalent to
computing a barycenter on the statistical manifold, allowing us to derive
closed-form solutions and achieve cost-free personalization. We apply the
proposed approach to a variational learning setup using the Improved
Variational Online Newton (IVON) optimizer and extend its application to
general aggregation schemes in BFL. Empirical evaluations under heterogeneous
data distributions confirm that our method effectively balances global and
local performance with minimal computational overhead.

</details>


### [179] [BenchECG and xECG: a benchmark and baseline for ECG foundation models](https://arxiv.org/abs/2509.10151)
*Riccardo Lunelli,Angus Nicolson,Samuel Martin Pröll,Sebastian Johannes Reinstadler,Axel Bauer,Clemens Dlaska*

Main category: cs.LG

TL;DR: 提出了BenchECG，一个标准化的心电图基准，包含全面的公开数据集和通用任务。同时提出了xECG，一个基于xLSTM的循环模型，使用SimDINOv2自监督学习进行训练，与现有的最佳模型相比，实现了最佳的BenchECG评分。


<details>
  <summary>Details</summary>
Motivation: 缺乏一致的评估标准：以往的研究通常使用狭窄的任务选择和不一致的数据集，阻碍了公平的比较。

Method: 提出了xECG，一个基于xLSTM的循环模型，使用SimDINOv2自监督学习进行训练。

Result: xECG是唯一一个在所有数据集和任务上表现出色的公开模型。xECG的性能优于以往的方法，为未来的ECG基础模型定义了一个新的基线。

Conclusion: BenchECG实现了标准化评估，旨在加速ECG表征学习的进展。

Abstract: Electrocardiograms (ECGs) are inexpensive, widely used, and well-suited to
deep learning. Recently, interest has grown in developing foundation models for
ECGs - models that generalise across diverse downstream tasks. However,
consistent evaluation has been lacking: prior work often uses narrow task
selections and inconsistent datasets, hindering fair comparison. Here, we
introduce BenchECG, a standardised benchmark comprising a comprehensive suite
of publicly available ECG datasets and versatile tasks. We also propose xECG,
an xLSTM-based recurrent model trained with SimDINOv2 self-supervised learning,
which achieves the best BenchECG score compared to publicly available
state-of-the-art models. In particular, xECG is the only publicly available
model to perform strongly on all datasets and tasks. By standardising
evaluation, BenchECG enables rigorous comparison and aims to accelerate
progress in ECG representation learning. xECG achieves superior performance
over earlier approaches, defining a new baseline for future ECG foundation
models.

</details>


### [180] [FedBiF: Communication-Efficient Federated Learning via Bits Freezing](https://arxiv.org/abs/2509.10161)
*Shiwei Li,Qunwei Li,Haozhao Wang,Ruixuan Li,Jianbin Lin,Wenliang Zhong*

Main category: cs.LG

TL;DR: 提出了一种新的联邦学习框架，名为 Federated Bit Freezing (FedBiF)，它可以在本地训练期间直接学习量化的模型参数，显著降低通信开销，同时保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 联邦学习存在通信开销大的问题，现有量化方法在本地训练后应用量化，会引入量化误差，可能降低模型精度。

Method: 提出 FedBiF 框架，服务器量化模型参数并发送给客户端，客户端每次只更新多位参数表示中的一位，冻结其余位。这种逐位更新策略将每个参数更新减少到一位，同时保持参数表示的高精度。

Result: 在五个广泛使用的数据集上进行了大量实验，结果表明 FedBiF 不仅实现了卓越的通信压缩，还促进了生成模型的稀疏性。即使上行链路仅使用 1 bpp，下行链路仅使用 3 bpp，FedBiF 也能达到与 FedAvg 相当的精度。

Conclusion: FedBiF 是一种有效的联邦学习框架，可以在显著降低通信开销的同时保持模型精度，并促进模型的稀疏性。

Abstract: Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative model training without sharing local data. Despite
its advantages, FL suffers from substantial communication overhead, which can
affect training efficiency. Recent efforts have mitigated this issue by
quantizing model updates to reduce communication costs. However, most existing
methods apply quantization only after local training, introducing quantization
errors into the trained parameters and potentially degrading model accuracy. In
this paper, we propose Federated Bit Freezing (FedBiF), a novel FL framework
that directly learns quantized model parameters during local training. In each
communication round, the server first quantizes the model parameters and
transmits them to the clients. FedBiF then allows each client to update only a
single bit of the multi-bit parameter representation, freezing the remaining
bits. This bit-by-bit update strategy reduces each parameter update to one bit
while maintaining high precision in parameter representation. Extensive
experiments are conducted on five widely used datasets under both IID and
Non-IID settings. The results demonstrate that FedBiF not only achieves
superior communication compression but also promotes sparsity in the resulting
models. Notably, FedBiF attains accuracy comparable to FedAvg, even when using
only 1 bit-per-parameter (bpp) for uplink and 3 bpp for downlink communication.
The code is available at https://github.com/Leopold1423/fedbif-tpds25.

</details>


### [181] [Federated Multi-Agent Reinforcement Learning for Privacy-Preserving and Energy-Aware Resource Management in 6G Edge Networks](https://arxiv.org/abs/2509.10163)
*Francisco Javier Esono Nkulu Andong,Qi Min*

Main category: cs.LG

TL;DR: 提出了一种新颖的联邦多智能体强化学习 (Fed-MARL) 框架，用于在异构边缘设备上进行节能、保护隐私和实时的资源管理。


<details>
  <summary>Details</summary>
Motivation: 在严格的隐私、移动性和能源约束下，高效的资源管理至关重要。

Method: 每个智能体使用深度循环 Q 网络 (DRQN) 来学习分散策略，用于任务卸载、频谱接入和基于本地观察的 CPU 能量适应。引入了基于椭圆曲线 Diffie Hellman 密钥交换的安全聚合协议，以确保准确的模型更新，而不会将原始数据暴露给半诚实对手。将资源管理问题表述为部分可观察的多智能体马尔可夫决策过程 (POMMDP)，具有多目标奖励函数，该函数在 6G 特定服务要求（如 URLLC、eMBB 和 mMTC）下共同优化延迟、能源效率、频谱效率、公平性和可靠性。

Result: Fed-MARL 在任务成功率、延迟、能源效率和公平性方面优于集中式 MARL 和启发式基线，同时确保在动态、资源受限的 6G 边缘网络中实现强大的隐私保护和可扩展性。

Conclusion: Fed-MARL 框架在 6G 边缘网络中实现了节能、保护隐私和实时的资源管理。

Abstract: As sixth-generation (6G) networks move toward ultra-dense, intelligent edge
environments, efficient resource management under stringent privacy, mobility,
and energy constraints becomes critical. This paper introduces a novel
Federated Multi-Agent Reinforcement Learning (Fed-MARL) framework that
incorporates cross-layer orchestration of both the MAC layer and application
layer for energy-efficient, privacy-preserving, and real-time resource
management across heterogeneous edge devices. Each agent uses a Deep Recurrent
Q-Network (DRQN) to learn decentralized policies for task offloading, spectrum
access, and CPU energy adaptation based on local observations (e.g., queue
length, energy, CPU usage, and mobility). To protect privacy, we introduce a
secure aggregation protocol based on elliptic curve Diffie Hellman key
exchange, which ensures accurate model updates without exposing raw data to
semi-honest adversaries. We formulate the resource management problem as a
partially observable multi-agent Markov decision process (POMMDP) with a
multi-objective reward function that jointly optimizes latency, energy
efficiency, spectral efficiency, fairness, and reliability under 6G-specific
service requirements such as URLLC, eMBB, and mMTC. Simulation results
demonstrate that Fed-MARL outperforms centralized MARL and heuristic baselines
in task success rate, latency, energy efficiency, and fairness, while ensuring
robust privacy protection and scalability in dynamic, resource-constrained 6G
edge networks.

</details>


### [182] [A Symmetry-Integrated Approach to Surface Code Decoding](https://arxiv.org/abs/2509.10164)
*Hoshitaro Ohnishi,Hideo Mukai*

Main category: cs.LG

TL;DR: 提出了一种新的量子纠错解码器优化技术，通过神经网络插值连续函数逼近综合征测量。


<details>
  <summary>Details</summary>
Motivation: 先前的表面码解码器方法受限于解码器仅获得误差概率分布的问题。

Method: 通过神经网络将综合征测量近似为连续函数，从而重新优化解码器模型。

Result: 对于码距为 5 和 7 的多层感知器以及基于卷积和循环神经网络以及码距为 5 的 transformers 的解码器，重新优化后的解码器都比原始模型具有更高的准确率。

Conclusion: 将表面码解码问题重新定义为可以通过深度学习解决的回归问题是一种有用的策略。

Abstract: Quantum error correction, which utilizes logical qubits that are encoded as
redundant multiple physical qubits to find and correct errors in physical
qubits, is indispensable for practical quantum computing. Surface code is
considered to be a promising encoding method with a high error threshold that
is defined by stabilizer generators. However, previous methods have suffered
from the problem that the decoder acquires solely the error probability
distribution because of the non-uniqueness of correct prediction obtained from
the input. To circumvent this problem, we propose a technique to reoptimize the
decoder model by approximating syndrome measurements with a continuous function
that is mathematically interpolated by neural network. We evaluated the
improvement in accuracy of a multilayer perceptron based decoder for code
distances of 5 and 7 as well as for decoders based on convolutional and
recurrent neural networks and transformers for a code distance of 5. In all
cases, the reoptimized decoder gave better accuracy than the original models,
demonstrating the universal effectiveness of the proposed method that is
independent of code distance or network architecture. These results suggest
that re-framing the problem of surface code decoding into a regression problem
that can be tackled by deep learning is a useful strategy.

</details>


### [183] [The Hidden Width of Deep ResNets: Tight Error Bounds and Phase Diagrams](https://arxiv.org/abs/2509.10167)
*Lénaïc Chizat*

Main category: cs.LG

TL;DR: 研究了从标准随机初始化中进行的大深度残差网络 (ResNet) 的基于梯度的训练，并表明训练动态收敛于神经平均 ODE 训练动态。


<details>
  <summary>Details</summary>
Motivation: 研究深度残差网络（ResNets）的训练动态。

Method: 通过数学推导和实证验证，研究了残差网络在不同尺度下的训练动态，并将其与神经平均 ODE 进行比较。

Result: 当残差尺度为 $\Theta_D\big(\frac{\alpha}{LM}\big)$ 时，模型输出与其极限之间的误差界为 $O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$。对于具有两层感知器块的 ResNet，只有 $\Theta\big(\frac{\sqrt{D}}{LM}\big)$ 的残差尺度才能实现完整的特征学习。

Conclusion: 由于初始化的随机性，ResNet 的前向和后向传播表现为某些平均 ODE 的随机近似，并且通过混沌传播，这种行为在整个训练过程中得以保持。

Abstract: We study the gradient-based training of large-depth residual networks
(ResNets) from standard random initializations. We show that with a diverging
depth $L$, a fixed embedding dimension $D$, and an arbitrary hidden width $M$,
the training dynamics converges to a Neural Mean ODE training dynamics.
Remarkably, the limit is independent of the scaling of $M$, covering practical
cases of, say, Transformers, where $M$ (the number of hidden units or attention
heads per layer) is typically of the order of $D$. For a residual scale
$\Theta_D\big(\frac{\alpha}{LM}\big)$, we obtain the error bound
$O_D\big(\frac{1}{L}+ \frac{\alpha}{\sqrt{LM}}\big)$ between the model's output
and its limit after a fixed number gradient of steps, and we verify empirically
that this rate is tight. When $\alpha=\Theta(1)$, the limit exhibits complete
feature learning, i.e. the Mean ODE is genuinely non-linearly parameterized. In
contrast, we show that $\alpha \to \infty$ yields a \lazy ODE regime where the
Mean ODE is linearly parameterized. We then focus on the particular case of
ResNets with two-layer perceptron blocks, for which we study how these scalings
depend on the embedding dimension $D$. We show that for this model, the only
residual scale that leads to complete feature learning is
$\Theta\big(\frac{\sqrt{D}}{LM}\big)$. In this regime, we prove the error bound
$O\big(\frac{1}{L}+ \frac{\sqrt{D}}{\sqrt{LM}}\big)$ between the ResNet and its
limit after a fixed number of gradient steps, which is also empirically tight.
Our convergence results rely on a novel mathematical perspective on ResNets :
(i) due to the randomness of the initialization, the forward and backward pass
through the ResNet behave as the stochastic approximation of certain mean ODEs,
and (ii) by propagation of chaos (that is, asymptotic independence of the
units) this behavior is preserved through the training dynamics.

</details>


### [184] [P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context](https://arxiv.org/abs/2509.10186)
*Benjamin Holzschuh,Georg Kohl,Florian Redinger,Nils Thuerey*

Main category: cs.LG

TL;DR: 提出了一种可扩展的框架，用于学习高分辨率 3D 物理模拟的确定性和概率神经代理模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率 3D 物理模拟计算成本高的问题，现有架构在速度和准确性方面表现不佳。

Method: 引入了一种混合 CNN-Transformer 主干架构，并提出一种快速且可扩展的序列到序列模型来包含远程依赖。

Result: 该网络在速度和准确性方面显著优于现有架构，并且能够扩展到高达 $512^3$ 空间分辨率的高分辨率各向同性湍流。

Conclusion: 该网络可以通过训练为扩散模型，生成不同雷诺数下高度湍流 3D 通道流的概率样本，准确捕捉底层流动统计数据，展示了网络的通用性。

Abstract: We present a scalable framework for learning deterministic and probabilistic
neural surrogates for high-resolution 3D physics simulations. We introduce a
hybrid CNN-Transformer backbone architecture targeted for 3D physics
simulations, which significantly outperforms existing architectures in terms of
speed and accuracy. Our proposed network can be pretrained on small patches of
the simulation domain, which can be fused to obtain a global solution,
optionally guided via a fast and scalable sequence-to-sequence model to include
long-range dependencies. This setup allows for training large-scale models with
reduced memory and compute requirements for high-resolution datasets. We
evaluate our backbone architecture against a large set of baseline methods with
the objective to simultaneously learn the dynamics of 14 different types of
PDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic
turbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate
the versatility of our network by training it as a diffusion model to produce
probabilistic samples of highly turbulent 3D channel flows across varying
Reynolds numbers, accurately capturing the underlying flow statistics.

</details>


### [185] [Hadamard-Riemannian Optimization for Margin-Variance Ensemble](https://arxiv.org/abs/2509.10189)
*Zexu Jin*

Main category: cs.LG

TL;DR: 提出了一种新的集成学习框架，该框架将边际方差显式地纳入损失函数，通过在单位球面上重新参数化集成权重，简化了优化过程并提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的基于边际的集成方法主要集中于最大化预期边际，而忽略了边际方差的关键作用，这限制了模型的泛化能力，并增加了模型对过度拟合的脆弱性，特别是在噪声或不平衡的数据集中。此外，在概率单纯形中优化集成权重的传统方法通常会引入计算效率低下和可扩展性挑战。

Method: 该方法联合优化负预期边际及其方差，从而增强了鲁棒性并提高了泛化性能。通过将集成权重重新参数化到单位球面上，我们大大简化了优化过程并提高了计算效率。

Result: 在多个基准数据集上进行的大量实验表明，所提出的方法始终优于传统的基于边际的集成技术，突显了其有效性和实用性。

Conclusion: 该论文提出了一种新的集成学习框架，通过考虑边际方差和重新参数化权重，提高了模型的鲁棒性、泛化性能和计算效率。

Abstract: Ensemble learning has been widely recognized as a pivotal technique for
boosting predictive performance by combining multiple base models.
Nevertheless, conventional margin-based ensemble methods predominantly focus on
maximizing the expected margin while neglecting the critical role of margin
variance, which inherently restricts the generalization capability of the model
and heightens its vulnerability to overfitting, particularly in noisy or
imbalanced datasets. Additionally, the conventional approach of optimizing
ensemble weights within the probability simplex often introduces computational
inefficiency and scalability challenges, complicating its application to
large-scale problems. To tackle these limitations, this paper introduces a
novel ensemble learning framework that explicitly incorporates margin variance
into the loss function. Our method jointly optimizes the negative expected
margin and its variance, leading to enhanced robustness and improved
generalization performance. Moreover, by reparameterizing the ensemble weights
onto the unit sphere, we substantially simplify the optimization process and
improve computational efficiency. Extensive experiments conducted on multiple
benchmark datasets demonstrate that the proposed approach consistently
outperforms traditional margin-based ensemble techniques, underscoring its
effectiveness and practical utility.

</details>


### [186] [A Certifiable Machine Learning-Based Pipeline to Predict Fatigue Life of Aircraft Structures](https://arxiv.org/abs/2509.10227)
*Ángel Ladrón,Miguel Sánchez-Domínguez,Javier Rozalén,Fernando R. Sánchez,Javier de Vicente,Lucas Lacasa,Eusebio Valero,Gonzalo Rubio*

Main category: cs.LG

TL;DR: 这篇论文提出了一种基于机器学习的流程，用于估计不同飞机机翼位置的疲劳寿命，并使用真实的疲劳寿命估计用例验证了该流程。


<details>
  <summary>Details</summary>
Motivation: 航空航天工业的安全性需要及早发现疲劳裂纹，以防止飞行中发生故障。传统的工程方法虽然可靠，但耗时且涉及复杂的工作流程。机器学习为传统的疲劳寿命估计方法提供了一个有希望的补充，可以实现更快的迭代和泛化。

Method: 本文提出了一个基于机器学习的流程，该流程旨在根据飞机在整个运行过程中的不同任务的飞行参数来估计不同飞机机翼位置的疲劳寿命。

Result: 该流程在疲劳寿命估计的实际用例中进行了验证，产生了准确的预测以及全面的统计验证和不确定性量化。

Conclusion: 该流程通过减少昂贵的模拟次数，从而减少所需的计算和人力资源，是对传统方法论的补充。

Abstract: Fatigue life prediction is essential in both the design and operational
phases of any aircraft, and in this sense safety in the aerospace industry
requires early detection of fatigue cracks to prevent in-flight failures.
Robust and precise fatigue life predictors are thus essential to ensure safety.
Traditional engineering methods, while reliable, are time consuming and involve
complex workflows, including steps such as conducting several Finite Element
Method (FEM) simulations, deriving the expected loading spectrum, and applying
cycle counting techniques like peak-valley or rainflow counting. These steps
often require collaboration between multiple teams and tools, added to the
computational time and effort required to achieve fatigue life predictions.
Machine learning (ML) offers a promising complement to traditional fatigue life
estimation methods, enabling faster iterations and generalization, providing
quick estimates that guide decisions alongside conventional simulations.
  In this paper, we present a ML-based pipeline that aims to estimate the
fatigue life of different aircraft wing locations given the flight parameters
of the different missions that the aircraft will be operating throughout its
operational life. We validate the pipeline in a realistic use case of fatigue
life estimation, yielding accurate predictions alongside a thorough statistical
validation and uncertainty quantification. Our pipeline constitutes a
complement to traditional methodologies by reducing the amount of costly
simulations and, thereby, lowering the required computational and human
resources.

</details>


### [187] [Prompt Injection Attacks on LLM Generated Reviews of Scientific Publications](https://arxiv.org/abs/2509.10248)
*Janis Keuper*

Main category: cs.LG

TL;DR: 本文研究了使用隐藏提示注入操纵LLM评审分数的可能性和技术成功率。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在科学同行评审中被滥用的问题，特别是作者使用隐藏提示注入操纵评审分数的情况。

Method: 对由各种LLM生成的1k篇2024 ICLR论文的评审进行系统评估。

Result: 简单的提示注入非常有效，接受率高达100%；LLM评审普遍偏向于接受（在许多模型中>95%）。

Conclusion: 这两个结果对正在进行的关于LLM在同行评审中使用的讨论具有重大影响。

Abstract: The ongoing intense discussion on rising LLM usage in the scientific
peer-review process has recently been mingled by reports of authors using
hidden prompt injections to manipulate review scores. Since the existence of
such "attacks" - although seen by some commentators as "self-defense" - would
have a great impact on the further debate, this paper investigates the
practicability and technical success of the described manipulations. Our
systematic evaluation uses 1k reviews of 2024 ICLR papers generated by a wide
range of LLMs shows two distinct results: I) very simple prompt injections are
indeed highly effective, reaching up to 100% acceptance scores. II) LLM reviews
are generally biased toward acceptance (>95% in many models). Both results have
great impact on the ongoing discussions on LLM usage in peer-review.

</details>


### [188] [Property prediction for ionic liquids without prior structural knowledge using limited experimental data: A data-driven neural recommender system leveraging transfer learning](https://arxiv.org/abs/2509.10273)
*Sahil Sethi,Kai Sundmacher,Caroline Ganzer*

Main category: cs.LG

TL;DR: 本研究提出了一种数据驱动的迁移学习框架，利用神经推荐系统（NRS）和COSMO-RS模拟数据，以解决离子液体（ILs）热物理性质预测中实验数据稀疏的问题。


<details>
  <summary>Details</summary>
Motivation: 准确预测离子液体的关键热物理性质仍然具有挑战性，因为化学设计空间巨大且实验数据有限。

Method: 该方法包括两个阶段：首先，在固定温度和压力下，在基于COSMO-RS的模拟数据上预训练NRS模型，以学习阳离子和阴离子的特定于性质的结构嵌入；其次，使用这些嵌入和在不同温度和压力下的实验数据来微调简单的Feedforward神经网络。

Result: 密度、粘度和热容的预训练模型用于微调所有五个目标属性的模型，从而显着提高了其中四个模型的性能。该模型对以前未见过的离子液体表现出强大的外推能力。此外，最终训练的模型能够预测超过700,000种IL组合的属性。

Conclusion: 这项工作突出了结合模拟数据和迁移学习以克服实验数据稀疏性的有效性。

Abstract: Ionic liquids (ILs) have emerged as versatile replacements for traditional
solvents because their physicochemical properties can be precisely tailored to
various applications. However, accurately predicting key thermophysical
properties remains challenging due to the vast chemical design space and the
limited availability of experimental data. In this study, we present a
data-driven transfer learning framework that leverages a neural recommender
system (NRS) to enable reliable property prediction for ILs using sparse
experimental datasets. The approach involves a two-stage process: first,
pre-training NRS models on COSMO-RS-based simulated data at fixed temperature
and pressure to learn property-specific structural embeddings for cations and
anions; and second, fine-tuning simple feedforward neural networks using these
embeddings with experimental data at varying temperatures and pressures. In
this work, five essential IL properties are considered: density, viscosity,
surface tension, heat capacity, and melting point. The framework supports both
within-property and cross-property knowledge transfer. Notably, pre-trained
models for density, viscosity, and heat capacity are used to fine-tune models
for all five target properties, achieving improved performance by a substantial
margin for four of them. The model exhibits robust extrapolation to previously
unseen ILs. Moreover, the final trained models enable property prediction for
over 700,000 IL combinations, offering a scalable solution for IL screening in
process design. This work highlights the effectiveness of combining simulated
data and transfer learning to overcome sparsity in the experimental data.

</details>


### [189] [Proof of AutoML: SDN based Secure Energy Trading with Blockchain in Disaster Case](https://arxiv.org/abs/2509.10291)
*Salih Toprak,Muge Erel-Ozcevik*

Main category: cs.LG

TL;DR: 本文提出了一种基于SDN的架构，该架构利用机器学习回归器生成随机数，用作区块链网络中交易的nonce候选值，从而确保在灾难情况下太阳能家庭和移动充电单元之间安全可靠的能源交易。


<details>
  <summary>Details</summary>
Motivation: 在传统能源基础设施受损的灾难场景中，太阳能家庭和移动充电单元之间安全且可追踪的能源交易成为必需品。为了确保区块链网络上此类交易的完整性，强大且不可预测的nonce生成至关重要。

Method: 本文提出一种基于SDN的架构，其中利用机器学习回归器不是为了它们的准确性，而是为了它们生成适合作为nonce候选值的随机值的潜力。因此，它被新称为AutoML证明。这里，SDN允许灵活控制数据流和能源路由策略，即使在分散或降级的网络中，也能确保紧急情况下的自适应响应。使用一个9000个样本的数据集，我们评估了五个AutoML选择的回归模型——梯度提升、LightGBM、随机森林、Extra Trees和K-最近邻——不是通过它们的预测准确性，而是通过它们在混洗数据输入中产生多样化和非确定性输出的能力。

Result: 随机性分析表明，随机森林和Extra Trees回归器表现出对随机性的完全依赖性，而梯度提升、K-最近邻和LightGBM显示出很强但略低的随机性得分（分别为97.6%、98.8%和99.9%）。

Conclusion: 这些发现强调，某些机器学习模型，特别是基于树的集成模型，可以在基于区块链安全、基于SDN的能源交易基础设施中作为有效且轻量级的nonce生成器，从而能够抵抗灾难条件。

Abstract: In disaster scenarios where conventional energy infrastructure is
compromised, secure and traceable energy trading between solar-powered
households and mobile charging units becomes a necessity. To ensure the
integrity of such transactions over a blockchain network, robust and
unpredictable nonce generation is vital. This study proposes an SDN-enabled
architecture where machine learning regressors are leveraged not for their
accuracy, but for their potential to generate randomized values suitable as
nonce candidates. Therefore, it is newly called Proof of AutoML. Here, SDN
allows flexible control over data flows and energy routing policies even in
fragmented or degraded networks, ensuring adaptive response during emergencies.
Using a 9000-sample dataset, we evaluate five AutoML-selected regression models
- Gradient Boosting, LightGBM, Random Forest, Extra Trees, and K-Nearest
Neighbors - not by their prediction accuracy, but by their ability to produce
diverse and non-deterministic outputs across shuffled data inputs. Randomness
analysis reveals that Random Forest and Extra Trees regressors exhibit complete
dependency on randomness, whereas Gradient Boosting, K-Nearest Neighbors and
LightGBM show strong but slightly lower randomness scores (97.6%, 98.8% and
99.9%, respectively). These findings highlight that certain machine learning
models, particularly tree-based ensembles, may serve as effective and
lightweight nonce generators within blockchain-secured, SDN-based energy
trading infrastructures resilient to disaster conditions.

</details>


### [190] [Generalizing Beyond Suboptimality: Offline Reinforcement Learning Learns Effective Scheduling through Random Data](https://arxiv.org/abs/2509.10303)
*Jesse van Remmerden,Zaharah Bukhsh,Yingqian Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的离线强化学习算法CDQAC，用于解决Job-Shop调度问题和Flexible Job-Shop调度问题。


<details>
  <summary>Details</summary>
Motivation: 现有的在线强化学习方法需要与模拟环境进行数百万次交互，且随机策略初始化导致样本效率低下。

Method: CDQAC算法将基于分位数的评论家与延迟策略更新相结合，估计每个机器-操作对的收益分布。

Result: CDQAC在学习各种数据源方面表现出色，始终优于原始数据生成启发式方法以及最先进的离线和在线强化学习基线。

Conclusion: CDQAC 是一种高效的算法，仅需少量训练实例即可学习高质量策略，且在随机启发式生成的数据上训练效果更好。

Abstract: The Job-Shop Scheduling Problem (JSP) and Flexible Job-Shop Scheduling
Problem (FJSP), are canonical combinatorial optimization problems with
wide-ranging applications in industrial operations. In recent years, many
online reinforcement learning (RL) approaches have been proposed to learn
constructive heuristics for JSP and FJSP. Although effective, these online RL
methods require millions of interactions with simulated environments that may
not capture real-world complexities, and their random policy initialization
leads to poor sample efficiency. To address these limitations, we introduce
Conservative Discrete Quantile Actor-Critic (CDQAC), a novel offline RL
algorithm that learns effective scheduling policies directly from historical
data, eliminating the need for costly online interactions, while maintaining
the ability to improve upon suboptimal training data. CDQAC couples a
quantile-based critic with a delayed policy update, estimating the return
distribution of each machine-operation pair rather than selecting pairs
outright. Our extensive experiments demonstrate CDQAC's remarkable ability to
learn from diverse data sources. CDQAC consistently outperforms the original
data-generating heuristics and surpasses state-of-the-art offline and online RL
baselines. In addition, CDQAC is highly sample efficient, requiring only 10-20
training instances to learn high-quality policies. Surprisingly, we find that
CDQAC performs better when trained on data generated by a random heuristic than
when trained on higher-quality data from genetic algorithms and priority
dispatching rules.

</details>


### [191] [GraphCSVAE: Graph Categorical Structured Variational Autoencoder for Spatiotemporal Auditing of Physical Vulnerability Towards Sustainable Post-Disaster Risk Reduction](https://arxiv.org/abs/2509.10308)
*Joshua Dimasaka,Christian Geiß,Robert Muir-Wood,Emily So*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的概率数据驱动框架，用于模拟物理脆弱性，通过整合深度学习、图表示和分类概率推理，使用时间序列卫星衍生的数据集和先前的专家信念系统。


<details>
  <summary>Details</summary>
Motivation: 在全球范围内，许多机构在灾后持续监测灾害风险变化方面面临挑战，限制了关键决策者评估联合国仙台减少灾害风险框架（2015-2030）进展的能力。在通过地球观测和数据驱动方法大规模建模灾害和暴露方面取得了显著进展，但在建模风险方程中另一个同样重要但具有挑战性的要素（物理脆弱性）方面，进展仍然有限。

Method: 我们引入了图分类结构变分自动编码器（GraphCSVAE），这是一种新的概率数据驱动框架，用于模拟物理脆弱性，通过整合深度学习、图表示和分类概率推理，使用时间序列卫星衍生的数据集和先前的专家信念系统。我们引入了一个弱监督的一阶转移矩阵，反映了在两个受灾害和社会经济弱势地区（孟加拉国受飓风影响的沿海Khurushkul社区和塞拉利昂受泥石流影响的弗里敦市）物理脆弱性的时空分布变化。

Result: 我们的工作揭示了灾后区域物理脆弱性的动态变化，为灾后风险降低的局部时空审计和可持续策略提供了有价值的见解。

Conclusion: 这篇论文提出了一种新的方法来模拟物理脆弱性，并通过在两个实际灾区应用该方法，验证了其有效性，为灾后风险降低提供了新的思路。

Abstract: In the aftermath of disasters, many institutions worldwide face challenges in
continually monitoring changes in disaster risk, limiting the ability of key
decision-makers to assess progress towards the UN Sendai Framework for Disaster
Risk Reduction 2015-2030. While numerous efforts have substantially advanced
the large-scale modeling of hazard and exposure through Earth observation and
data-driven methods, progress remains limited in modeling another equally
important yet challenging element of the risk equation: physical vulnerability.
To address this gap, we introduce Graph Categorical Structured Variational
Autoencoder (GraphCSVAE), a novel probabilistic data-driven framework for
modeling physical vulnerability by integrating deep learning, graph
representation, and categorical probabilistic inference, using time-series
satellite-derived datasets and prior expert belief systems. We introduce a
weakly supervised first-order transition matrix that reflects the changes in
the spatiotemporal distribution of physical vulnerability in two
disaster-stricken and socioeconomically disadvantaged areas: (1) the
cyclone-impacted coastal Khurushkul community in Bangladesh and (2) the
mudslide-affected city of Freetown in Sierra Leone. Our work reveals
post-disaster regional dynamics in physical vulnerability, offering valuable
insights into localized spatiotemporal auditing and sustainable strategies for
post-disaster risk reduction.

</details>


### [192] [ARMA Block: A CNN-Based Autoregressive and Moving Average Module for Long-Term Time Series Forecasting](https://arxiv.org/abs/2509.10324)
*Myung Jin Kim,YeongHyeon Park,Il Dong Yun*

Main category: cs.LG

TL;DR: 提出一个用于长期时间序列预测的卷积模块，该模块受 ARIMA 模型启发，由两个卷积组件组成：一个用于捕获趋势（自回归），另一个用于细化局部变化（移动平均）。


<details>
  <summary>Details</summary>
Motivation: 传统 ARIMA 需要迭代多步预测，该模块直接执行多步预测，使其易于扩展到多变量设置。

Method: 该方法由两个卷积部分组成，一个用于捕获趋势（自回归），另一个用于细化局部变化（移动平均）。

Result: 在九个广泛使用的基准数据集上的实验表明，该方法 ARMA 实现了具有竞争力的准确性，尤其是在表现出强烈趋势变化的数据集上，同时保持了架构的简单性。

Conclusion: 该模块固有地编码绝对位置信息，表明其有潜力作为顺序模型中位置嵌入的轻量级替代品。

Abstract: This paper proposes a simple yet effective convolutional module for long-term
time series forecasting. The proposed block, inspired by the Auto-Regressive
Integrated Moving Average (ARIMA) model, consists of two convolutional
components: one for capturing the trend (autoregression) and the other for
refining local variations (moving average). Unlike conventional ARIMA, which
requires iterative multi-step forecasting, the block directly performs
multi-step forecasting, making it easily extendable to multivariate settings.
Experiments on nine widely used benchmark datasets demonstrate that our method
ARMA achieves competitive accuracy, particularly on datasets exhibiting strong
trend variations, while maintaining architectural simplicity. Furthermore,
analysis shows that the block inherently encodes absolute positional
information, suggesting its potential as a lightweight replacement for
positional embeddings in sequential models.

</details>


### [193] [Physics-informed sensor coverage through structure preserving machine learning](https://arxiv.org/abs/2509.10363)
*Benjamin David Shaffer,Brooks Kinch,Joseph Klobusicky,M. Ani Hsieh,Nathaniel Trask*

Main category: cs.LG

TL;DR: 提出了一种用于自适应源定位的机器学习框架，该框架利用结构保持数字孪生模型进行实时轨迹规划和数据同化。


<details>
  <summary>Details</summary>
Motivation: 在耦合水动力传输系统中进行自适应源定位。

Method: 使用条件神经Whitney形式（CNWF）构建数字孪生模型，结合有限元外calculus（FEEC）的数值保证和基于Transformer的算子学习。采用交错方案，交替评估数字孪生模型和应用Lloyd算法来指导传感器放置。

Result: 实验表明，与物理不可知的Transformer架构相比，当强制执行物理约束时，在复杂几何形状中提高了准确性。

Conclusion: 结构保持为源识别提供了一种有效的归纳偏置。

Abstract: We present a machine learning framework for adaptive source localization in
which agents use a structure-preserving digital twin of a coupled
hydrodynamic-transport system for real-time trajectory planning and data
assimilation. The twin is constructed with conditional neural Whitney forms
(CNWF), coupling the numerical guarantees of finite element exterior calculus
(FEEC) with transformer-based operator learning. The resulting model preserves
discrete conservation, and adapts in real time to streaming sensor data. It
employs a conditional attention mechanism to identify: a reduced Whitney-form
basis; reduced integral balance equations; and a source field, each compatible
with given sensor measurements. The induced reduced-order environmental model
retains the stability and consistency of standard finite-element simulation,
yielding a physically realizable, regular mapping from sensor data to the
source field. We propose a staggered scheme that alternates between evaluating
the digital twin and applying Lloyd's algorithm to guide sensor placement, with
analysis providing conditions for monotone improvement of a coverage
functional. Using the predicted source field as an importance function within
an optimal-recovery scheme, we demonstrate recovery of point sources under
continuity assumptions, highlighting the role of regularity as a sufficient
condition for localization. Experimental comparisons with physics-agnostic
transformer architectures show improved accuracy in complex geometries when
physical constraints are enforced, indicating that structure preservation
provides an effective inductive bias for source identification.

</details>


### [194] [A Discrepancy-Based Perspective on Dataset Condensation](https://arxiv.org/abs/2509.10367)
*Tong Chen,Raghavendra Selvan*

Main category: cs.LG

TL;DR: 数据集精简旨在用远小于原始数据集的合成数据集，训练出泛化性能相当甚至更优的模型。


<details>
  <summary>Details</summary>
Motivation: 研究表明数据集精简与用缩减的点集近似数据分布问题密切相关。

Method: 提出了一个统一的框架，涵盖了现有的数据集精简方法，并将特定任务的数据集精简概念扩展到更通用和正式的定义。

Result: 该框架将数据集精简的目标扩展到泛化之外，适应了鲁棒性、隐私和其他理想属性等附加目标。

Conclusion: 该论文提出了一个更通用和正式的数据集精简框架，可以实现鲁棒性、隐私等目标。

Abstract: Given a dataset of finitely many elements $\mathcal{T} = \{\mathbf{x}_i\}_{i
= 1}^N$, the goal of dataset condensation (DC) is to construct a synthetic
dataset $\mathcal{S} = \{\tilde{\mathbf{x}}_j\}_{j = 1}^M$ which is
significantly smaller ($M \ll N$) such that a model trained from scratch on
$\mathcal{S}$ achieves comparable or even superior generalization performance
to a model trained on $\mathcal{T}$. Recent advances in DC reveal a close
connection to the problem of approximating the data distribution represented by
$\mathcal{T}$ with a reduced set of points. In this work, we present a unified
framework that encompasses existing DC methods and extend the task-specific
notion of DC to a more general and formal definition using notions of
discrepancy, which quantify the distance between probability distribution in
different regimes. Our framework broadens the objective of DC beyond
generalization, accommodating additional objectives such as robustness,
privacy, and other desirable properties.

</details>


### [195] [Data distribution impacts the performance and generalisability of contrastive learning-based foundation models of electrocardiograms](https://arxiv.org/abs/2509.10369)
*Gul Rukh Khattak,Konstantinos Patlatzoglou,Joseph Barker,Libor Pastika,Boroumand Zeidaabadi,Ahmed El-Medany,Hesham Aggour,Yixiu Liang,Antonio H. Ribeiro,Jeffrey Annis,Antonio Luiz Pinho Ribeiro,Junbo Ge,Daniel B. Kramer,Jonathan W. Waks,Evan Brittain,Nicholas Peters,Fu Siong Ng,Arunashis Sau*

Main category: cs.LG

TL;DR: 对比学习是一种广泛采用的自我监督预训练策略，但其对队列组成部分的依赖性仍未得到充分探索。我们提出了CAPE基础模型，并在来自三大洲（北美、南美、亚洲）的不同人群的四个队列（n = 5,203,352）上进行预训练。


<details>
  <summary>Details</summary>
Motivation: 评估队列人口统计、健康状况和人口多样性如何影响预测任务的下游性能。

Method: 提出In-Distribution Batch (IDB)策略，该策略在预训练期间保持队列内一致性并增强OOD鲁棒性。

Result: 下游性能取决于预训练队列的分布特性，包括人口统计和健康状况。使用多中心、人口结构多样化的队列进行预训练虽然可以提高分布内的准确性，但会通过编码队列特有的伪影来降低对比方法的分布外（OOD）泛化能力。

Conclusion: 这项工作为开发临床上公平和可推广的基础模型提供了重要的见解。

Abstract: Contrastive learning is a widely adopted self-supervised pretraining
strategy, yet its dependence on cohort composition remains underexplored. We
present Contrasting by Patient Augmented Electrocardiograms (CAPE) foundation
model and pretrain on four cohorts (n = 5,203,352), from diverse populations
across three continents (North America, South America, Asia). We systematically
assess how cohort demographics, health status, and population diversity
influence the downstream performance for prediction tasks also including two
additional cohorts from another continent (Europe). We find that downstream
performance depends on the distributional properties of the pretraining cohort,
including demographics and health status. Moreover, while pretraining with a
multi-centre, demographically diverse cohort improves in-distribution accuracy,
it reduces out-of-distribution (OOD) generalisation of our contrastive approach
by encoding cohort-specific artifacts. To address this, we propose the
In-Distribution Batch (IDB) strategy, which preserves intra-cohort consistency
during pretraining and enhances OOD robustness. This work provides important
insights for developing clinically fair and generalisable foundation models.

</details>


### [196] [Flow Straight and Fast in Hilbert Space: Functional Rectified Flow](https://arxiv.org/abs/2509.10384)
*Jianxin Zhang,Clayton Scott*

Main category: cs.LG

TL;DR: 本文将修正流推广到无限维 Hilbert 空间，并证明该框架可以自然地扩展到函数流匹配和函数概率流 ODE。


<details>
  <summary>Details</summary>
Motivation: 将有限维欧几里得空间中开发的生成模型推广到无限维环境中，但修正流在无限维空间中的扩展仍未被探索。

Method: 基于无限维空间中连续性方程的叠加原理，建立了修正流的严格函数公式。

Result: 该方法在函数流匹配方面优于现有的函数生成模型，并删除了 \{kerrigan2024functional\} 现有理论中严格的测度理论假设。

Conclusion: 该研究成功地将修正流扩展到无限维 Hilbert 空间，为函数生成模型的发展提供了新的方向。

Abstract: Many generative models originally developed in finite-dimensional Euclidean
space have functional generalizations in infinite-dimensional settings.
However, the extension of rectified flow to infinite-dimensional spaces remains
unexplored. In this work, we establish a rigorous functional formulation of
rectified flow in an infinite-dimensional Hilbert space. Our approach builds
upon the superposition principle for continuity equations in an
infinite-dimensional space. We further show that this framework extends
naturally to functional flow matching and functional probability flow ODEs,
interpreting them as nonlinear generalizations of rectified flow. Notably, our
extension to functional flow matching removes the restrictive measure-theoretic
assumptions in the existing theory of \citet{kerrigan2024functional}.
Furthermore, we demonstrate experimentally that our method achieves superior
performance compared to existing functional generative models.

</details>


### [197] [Vendi Information Gain for Active Learning and its Application to Ecology](https://arxiv.org/abs/2509.10390)
*Quan Nguyen,Adji Bousso Dieng*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的主动学习策略，Vendi 信息增益（VIG），用于解决生态研究中相机陷阱图像数据物种识别的标签资源有限问题。


<details>
  <summary>Details</summary>
Motivation: 现有的主动学习方法通常侧重于个体预测的不确定性，而忽略了整个数据集的不确定性。为了解决这个问题。

Method: VIG 策略基于图像对数据集范围内的预测不确定性的影响来选择图像，从而同时捕捉信息性和多样性。

Result: 在 Snapshot Serengeti 数据集上的实验结果表明，使用不到 10% 的标签，VIG 实现了接近完全监督的预测准确率，并且在各项指标和批量大小上均优于标准基线，在特征空间中收集了更多样化的数据。

Conclusion: VIG 具有广泛的适用性，超越了生态学领域，并且对数据有限环境下的生物多样性监测具有重要价值。

Abstract: While monitoring biodiversity through camera traps has become an important
endeavor for ecological research, identifying species in the captured image
data remains a major bottleneck due to limited labeling resources. Active
learning -- a machine learning paradigm that selects the most informative data
to label and train a predictive model -- offers a promising solution, but
typically focuses on uncertainty in the individual predictions without
considering uncertainty across the entire dataset. We introduce a new active
learning policy, Vendi information gain (VIG), that selects images based on
their impact on dataset-wide prediction uncertainty, capturing both
informativeness and diversity. Applied to the Snapshot Serengeti dataset, VIG
achieves impressive predictive accuracy close to full supervision using less
than 10% of the labels. It consistently outperforms standard baselines across
metrics and batch sizes, collecting more diverse data in the feature space. VIG
has broad applicability beyond ecology, and our results highlight its value for
biodiversity monitoring in data-limited environments.

</details>


### [198] [Inpainting-Guided Policy Optimization for Diffusion Large Language Models](https://arxiv.org/abs/2509.10396)
*Siyan Zhao,Mengchen Liu,Jing Huang,Miao Liu,Chenyu Wang,Bo Liu,Yuandong Tian,Guan Pang,Sean Bell,Aditya Grover,Feiyu Chen*

Main category: cs.LG

TL;DR: 提出了一个名为IGPO的强化学习框架，利用dLLMs的修复能力来指导探索，从而提高样本效率并在数学基准测试中获得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中对齐LLM面临探索性挑战，当模型无法发现正确的解决方案时，奖励信号稀疏且样本浪费。dLLM的修复能力可以指导探索。

Method: 提出了IGPO，一种RL框架，可在在线采样期间策略性地插入部分地面实况推理轨迹。此外，还提出了对合成重写的简洁轨迹进行监督微调，这些轨迹与dLLM生成模式更好地对齐。使用了包括基于熵的过滤等其他技术。

Result: 在三个数学基准测试（GSM8K、Math500和AMC）中获得了显著的收益，为全注意力掩码dLLM实现了新的最先进的结果。

Conclusion: IGPO通过在探索期间注入ground-truth信息，有效指导dLLM的强化学习，显著提升了性能。

Abstract: Masked diffusion large language models (dLLMs) are emerging as promising
alternatives to autoregressive LLMs, offering competitive performance while
supporting unique generation capabilities such as inpainting. We explore how
inpainting can inform RL algorithm design for dLLMs. Aligning LLMs with
reinforcement learning faces an exploration challenge: sparse reward signals
and sample waste when models fail to discover correct solutions. While this
inefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their
inpainting ability can guide exploration. We introduce IGPO (Inpainting Guided
Policy Optimization), an RL framework that strategically inserts partial
ground-truth reasoning traces during online sampling. Unlike providing full
solutions, inpainting steers exploration toward promising trajectory spaces
while preserving self-generated reasoning, bridging supervised fine-tuning and
reinforcement learning. We apply IGPO to group-based optimization methods such
as GRPO, where exploration failures cause zero advantages and gradients. IGPO
restores meaningful gradients while improving sample efficiency. We also
propose supervised fine-tuning on synthetically rewritten concise traces that
better align with dLLM generation patterns. With additional techniques
including entropy-based filtering, our training recipe yields substantial gains
across three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new
state-of-the-art results for full-attention masked dLLMs.

</details>


### [199] [Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining](https://arxiv.org/abs/2509.10406)
*Rupert Mitchell,Kristian Kersting*

Main category: cs.LG

TL;DR: 提出了一种名为Multipole Semantic Attention (MuSe) 的高效softmax注意力近似方法，该方法结合了语义聚类和计算物理中的多极展开。


<details>
  <summary>Details</summary>
Motivation: 为了解决transformer在上下文长度方面的二次计算复杂度问题。

Method: 通过在学习的表示空间中分别对queries和keys进行聚类，实现分层两阶段注意力机制。使用偶极校正来增强基于质心的近似。

Result: 在孤立的注意力层上，与CUDNN Flash Attention相比，在8k上下文长度下实现了3倍的加速，相对平方误差低于20%。在具有16k上下文的书籍长度文本的30M参数模型的端到端预训练中，实现了12.2%的运行时减少，而损失仅降低了0.36%。

Conclusion: 多极近似对于高效transformer预训练是可行的。

Abstract: We present Multipole Semantic Attention (MuSe), an efficient approximation of
softmax attention that combines semantic clustering with multipole expansions
from computational physics. Our method addresses the quadratic computational
complexity of transformers in the context length by clustering queries and keys
separately in their learned representation spaces, enabling a hierarchical
two-stage attention mechanism. Unlike prior clustering approaches that group
only keys or use unified clustering, we maintain separate clusterings that
respect attention's asymmetric treatment of these spaces. We augment
centroid-based (monopole) approximations with dipole corrections that capture
directional variance within clusters, preserving richer information during
training. The method operates as a drop-in replacement for standard attention,
requiring only hyperparameter specification without architectural
modifications. Our approach achieves $\mathcal{O}(NCD)$ complexity for acausal
attention with $C$ clusters and $\mathcal{O}(NCD \log N)$ for causal attention.
On isolated attention layers, we demonstrate $3\times$ speedup over CUDNN Flash
Attention at 8k context length, with relative squared errors below 20%. For
causal attention, we develop a hierarchical block decomposition that combines
exact local computation with efficient long-range approximation. In end-to-end
pretraining of a 30M parameter model on book-length texts with 16k context, we
achieve 12.2% runtime reduction with only 0.36% loss degradation, establishing
the viability of multipole approximations for efficient transformer
pretraining.

</details>


### [200] [Run-Time Monitoring of ERTMS/ETCS Control Flow by Process Mining](https://arxiv.org/abs/2509.10419)
*Francesco Vitale,Tommaso Zoppi,Francesco Flammini,Nicola Mazzocca*

Main category: cs.LG

TL;DR: 本文提出了一种使用过程挖掘进行运行时控制流异常检测的方法，以增强ERTMS/ETCS L2的弹性。


<details>
  <summary>Details</summary>
Motivation: 确保计算机铁路的弹性越来越重要，以应对由于这些系统日益复杂和关键的不确定性和变化。尽管他们的软件依赖于严格的验证和确认过程，遵循完善的最佳实践和认证标准，但由于残余故障、在设计时未知的系统和环境修改或其他新兴的网络威胁情景，异常仍然可能在运行时发生。

Method: 使用过程挖掘从执行跟踪中学习系统的实际控制流，从而通过在线一致性检查实现运行时监控。此外，通过无监督机器学习执行异常定位，以将相关偏差链接到关键系统组件。

Result: 在参考ERTMS/ETCS L2场景（即RBC/RBC切换）上测试了该方法，结果表明该方法能够以高精度、效率和可解释性检测和定位异常。

Conclusion: 本文提出了一种使用过程挖掘进行运行时控制流异常检测的方法，该方法能够在ERTMS/ETCS L2场景中有效地检测和定位异常。

Abstract: Ensuring the resilience of computer-based railways is increasingly crucial to
account for uncertainties and changes due to the growing complexity and
criticality of those systems. Although their software relies on strict
verification and validation processes following well-established best-practices
and certification standards, anomalies can still occur at run-time due to
residual faults, system and environmental modifications that were unknown at
design-time, or other emergent cyber-threat scenarios. This paper explores
run-time control-flow anomaly detection using process mining to enhance the
resilience of ERTMS/ETCS L2 (European Rail Traffic Management System / European
Train Control System Level 2). Process mining allows learning the actual
control flow of the system from its execution traces, thus enabling run-time
monitoring through online conformance checking. In addition, anomaly
localization is performed through unsupervised machine learning to link
relevant deviations to critical system components. We test our approach on a
reference ERTMS/ETCS L2 scenario, namely the RBC/RBC Handover, to show its
capability to detect and localize anomalies with high accuracy, efficiency, and
explainability.

</details>


### [201] [Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration](https://arxiv.org/abs/2509.10439)
*Ahmed Khaled,Satyen Kale,Arthur Douillard,Chi Jin,Rob Fergus,Manzil Zaheer*

Main category: cs.LG

TL;DR: 本文研究了Local SGD中外部优化器的作用，并为其提供了新的收敛保证。


<details>
  <summary>Details</summary>
Motivation: 大规模机器学习通常需要在大型batch size、分布式数据和大规模并行计算硬件上进行训练，通信成为主要的瓶颈。Local SGD通过减少额外的通信开销，在这种情况下显示出巨大的潜力。虽然已经有大量文献理解局部优化过程中超参数的影响，但外部优化器的选择及其超参数的选择尚不清楚。

Method: 研究Local SGD中外部优化器的作用，并证明该算法的新的收敛保证。将结果扩展到外部优化器中使用动量的情况，并展示了动量调整后的外部学习率的类似作用。研究了外部优化器中的加速，并表明它可以提高收敛速度。

Result: 调整外部学习率允许在优化误差和随机梯度噪声方差之间进行权衡，并弥补内部学习率的不良调整。理论表明，外部学习率有时应设置为大于1的值。在外部优化器中使用动量时，结果类似。外部优化器中的加速提高了收敛速度。引入了Local SGD的新的数据相关分析，从而进一步了解了外部学习率的调整。

Conclusion: 对标准语言模型和各种外部优化器进行了全面的实验，以验证理论。

Abstract: Modern machine learning often requires training with large batch size,
distributed data, and massively parallel compute hardware (like mobile and
other edge devices or distributed data centers). Communication becomes a major
bottleneck in such settings but methods like Local Stochastic Gradient Descent
(Local SGD) show great promise in reducing this additional communication
overhead. Local SGD consists of three parts: a local optimization process, an
aggregation mechanism, and an outer optimizer that uses the aggregated updates
from the nodes to produce a new model. While there exists an extensive
literature on understanding the impact of hyperparameters in the local
optimization process, the choice of outer optimizer and its hyperparameters is
less clear. We study the role of the outer optimizer in Local SGD, and prove
new convergence guarantees for the algorithm. In particular, we show that
tuning the outer learning rate allows us to (a) trade off between optimization
error and stochastic gradient noise variance, and (b) make up for ill-tuning of
the inner learning rate. Our theory suggests that the outer learning rate
should sometimes be set to values greater than $1$. We extend our results to
settings where we use momentum in the outer optimizer, and we show a similar
role for the momentum-adjusted outer learning rate. We also study acceleration
in the outer optimizer and show that it improves the convergence rate as a
function of the number of communication rounds, improving upon the convergence
rate of prior algorithms that apply acceleration locally. Finally, we also
introduce a novel data-dependent analysis of Local SGD that yields further
insights on outer learning rate tuning. We conduct comprehensive experiments
with standard language models and various outer optimizers to validate our
theory.

</details>
