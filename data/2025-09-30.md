<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 29]
- [cs.CV](#cs.CV) [Total: 24]
- [cs.AI](#cs.AI) [Total: 26]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.LG](#cs.LG) [Total: 26]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Are you sure? Measuring models bias in content moderation through uncertainty](https://arxiv.org/abs/2509.22699)
*Alessandra Urbinati,Mirko Lai,Simona Frenda,Marco Antonio Stranisci*

Main category: cs.CL

TL;DR: 提出了一种无监督方法，通过测量模型在对弱势群体注释消息进行分类时的不确定性来评估内容审核模型的偏差。


<details>
  <summary>Details</summary>
Motivation: 基于语言模型的分类器越来越多地被用于内容审核，但它们会使种族和社会偏见永久化。衡量内容审核模型公平性仍然是一个开放的问题。

Method: 使用共形预测技术计算不确定性，以此来分析11个模型对女性和非白人注释者的偏见。

Result: 结果表明，即使某些预训练模型对来自少数群体标签的预测具有很高的准确性，但对其预测的置信度较低。

Conclusion: 通过测量模型的置信度，能够了解哪些注释者群体在预训练模型中得到了更好的代表，并在有效使用之前引导这些模型的去偏过程。

Abstract: Automatic content moderation is crucial to ensuring safety in social media.
Language Model-based classifiers are being increasingly adopted for this task,
but it has been shown that they perpetuate racial and social biases. Even if
several resources and benchmark corpora have been developed to challenge this
issue, measuring the fairness of models in content moderation remains an open
issue. In this work, we present an unsupervised approach that benchmarks models
on the basis of their uncertainty in classifying messages annotated by people
belonging to vulnerable groups. We use uncertainty, computed by means of the
conformal prediction technique, as a proxy to analyze the bias of 11 models
against women and non-white annotators and observe to what extent it diverges
from metrics based on performance, such as the $F_1$ score. The results show
that some pre-trained models predict with high accuracy the labels coming from
minority groups, even if the confidence in their prediction is low. Therefore,
by measuring the confidence of models, we are able to see which groups of
annotators are better represented in pre-trained models and lead the debiasing
process of these models before their effective use.

</details>


### [2] [AccessEval: Benchmarking Disability Bias in Large Language Models](https://arxiv.org/abs/2509.22703)
*Srikant Panda,Amit Agarwal,Hitesh Laxmichand Patel*

Main category: cs.CL

TL;DR: AccessEval是一个用于评估大型语言模型在处理残疾相关查询时的表现的基准，揭示了模型在情感、社会认知和事实准确性方面的偏差。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在不同残疾情境下处理现实查询时存在的差异。

Method: 通过AccessEval基准，评估了21个闭源和开源LLM在6个真实世界领域和9种残疾类型下的表现，使用了中性和残疾感知查询对。

Result: 发现对残疾感知查询的回复往往带有更负面的语气、更多的刻板印象和更高的事实错误。听力、言语和行动障碍受到的影响尤为严重。

Conclusion: 模型行为中存在持久的歧视，这些偏差可能转化为对残疾用户的实际伤害，强调了在日常应用中减轻偏见的重要性。

Abstract: Large Language Models (LLMs) are increasingly deployed across diverse domains
but often exhibit disparities in how they handle real-life queries. To
systematically investigate these effects within various disability contexts, we
introduce \textbf{AccessEval (Accessibility Evaluation)}, a benchmark
evaluating 21 closed- and open-source LLMs across 6 real-world domains and 9
disability types using paired Neutral and Disability-Aware Queries. We
evaluated model outputs with metrics for sentiment, social perception, and
factual accuracy.
  Our analysis reveals that responses to disability-aware queries tend to have
a more negative tone, increased stereotyping, and higher factual error compared
to neutral queries. These effects show notable variation by domain and
disability type, with disabilities affecting hearing, speech, and mobility
disproportionately impacted. These disparities reflect persistent forms of
ableism embedded in model behavior.
  By examining model performance in real-world decision-making contexts, we
better illuminate how such biases can translate into tangible harms for
disabled users. This framing helps bridges the gap between technical evaluation
and user impact, reinforcing importance of bias mitigation in day-to-day
applications. Our dataset is publicly available at:
https://huggingface.co/datasets/Srikant86/AccessEval

</details>


### [3] [RAR$^2$: Retrieval-Augmented Medical Reasoning via Thought-Driven Retrieval](https://arxiv.org/abs/2509.22713)
*Kaishuai Xu,Wenjun Hou,Yi Cheng,Wenjie Li*

Main category: cs.CL

TL;DR: 本文提出了一种名为RAR$^2$的联合学习框架，通过改进推理增强检索和检索增强推理来解决复杂医学问题。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成(RAG)方法在处理需要深入推理的复杂医学问题时表现不佳，因为表面级别的输入通常不能反映任务的真实知识需求。

Method: RAR$^2$构建了一个思维过程来揭示隐含的知识需求，并使用它来指导检索和答案生成。我们构建了一个混合偏好对的训练数据集，并应用直接偏好优化(DPO)来训练模型。此外，我们设计了两种测试时缩放策略来探索我们框架的边界。

Result: 实验表明，RAR$^2$在多个生物医学问答数据集上都优于RAG基线，无论是否进行微调。

Conclusion: RAR$^2$ 是一种有效的框架，可以提高生物医学问答的性能。

Abstract: Large Language Models (LLMs) have shown promising performance on diverse
medical benchmarks, highlighting their potential in supporting real-world
clinical tasks. Retrieval-Augmented Generation (RAG) has emerged as a key
approach for mitigating knowledge gaps and hallucinations by incorporating
external medical information. However, RAG still struggles with complex medical
questions that require intensive reasoning, as surface-level input often fails
to reflect the true knowledge needs of the task. Existing methods typically
focus on refining queries without explicitly modeling the reasoning process,
limiting their ability to retrieve and integrate clinically relevant knowledge.
In this work, we propose RAR$^2$, a joint learning framework that improves both
Reasoning-Augmented Retrieval and Retrieval-Augmented Reasoning. RAR$^2$
constructs a thought process to uncover implicit knowledge requirements and
uses it to guide retrieval and answer generation. We build a training dataset
of mixed preference pairs and apply Direct Preference Optimization (DPO) to
train the model. Moreover, we design two test-time scaling strategies to
explore the boundaries of our framework. Experiments demonstrate the
effectiveness of RAR$^2$ across several biomedical question answering datasets,
outperforming RAG baselines with or without fine-tuning.

</details>


### [4] [Agentar-Scale-SQL: Advancing Text-to-SQL through Orchestrated Test-Time Scaling](https://arxiv.org/abs/2509.24403)
*Pengfei Wang,Baolin Sun,Xuemei Dong,Yaxun Dai,Hongwei Yuan,Mengdie Chu,Yingqi Gao,Xiang Qi,Peng Zhang,Ying Yan*

Main category: cs.CL

TL;DR: Agentar-Scale-SQL是一个新的框架，它利用可扩展的计算来提高Text-to-SQL的性能，在BIRD基准测试中达到了SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-SQL方法在具有挑战性的基准测试中仍然落后于人类专家，并且缺乏协调的策略和对模型内部推理过程的关注。

Method: Agentar-Scale-SQL实施了一个协调的测试时扩展策略，该策略协同结合了三个不同的角度：i) 通过强化学习增强内在推理的内部扩展，ii) 通过迭代改进的顺序扩展，以及 iii) 使用多样化合成和锦标赛选择的并行扩展。

Result: Agentar-Scale-SQL在BIRD基准测试中达到了SOTA性能，在测试集上达到了81.67%的执行准确率，并在官方排行榜上排名第一。

Conclusion: Agentar-Scale-SQL展示了一条通往人类水平性能的有效途径。

Abstract: State-of-the-art (SOTA) Text-to-SQL methods still lag significantly behind
human experts on challenging benchmarks like BIRD. Current approaches that
explore test-time scaling lack an orchestrated strategy and neglect the model's
internal reasoning process. To bridge this gap, we introduce Agentar-Scale-SQL,
a novel framework leveraging scalable computation to improve performance.
Agentar-Scale-SQL implements an Orchestrated Test-Time Scaling strategy that
synergistically combines three distinct perspectives: i) Internal Scaling via
RL-enhanced Intrinsic Reasoning, ii) Sequential Scaling through Iterative
Refinement, and iii) Parallel Scaling using Diverse Synthesis and Tournament
Selection. Agentar-Scale-SQL is a general-purpose framework designed for easy
adaptation to new databases and more powerful language models. Extensive
experiments show that Agentar-Scale-SQL achieves SOTA performance on the BIRD
benchmark, reaching 81.67\% execution accuracy on the test set and ranking
first on the official leaderboard, demonstrating an effective path toward
human-level performance.

</details>


### [5] [TRUEBench: Can LLM Response Meet Real-world Constraints as Productivity Assistant?](https://arxiv.org/abs/2509.22715)
*Jiho Park,Jongyoon Song,Minjin Choi,Kyuho Heo,Taehun Huh,Ji Won Kim*

Main category: cs.CL

TL;DR: 提出了一个名为 TRUEBench 的新基准，用于评估大型语言模型在实际生产力环境中的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准在多语言支持、隐式约束捕捉和多轮对话复杂性方面存在不足，无法充分评估大型语言模型的实际指令遵循能力。

Method: 设计了一个包含 12 种语言输入提示、多语言指令、严格评估标准和复杂多轮对话场景的基准。

Result: TRUEBench 比现有基准更具挑战性，例如，OpenAI o1 模型仅达到 69.07% 的总体通过率。

Conclusion: TRUEBench 提供了一个对大型语言模型在实际生产力环境中进行评估的严格且现实的基准，突出了它们的能力和局限性。

Abstract: Large language models (LLMs) are increasingly integral as productivity
assistants, but existing benchmarks fall short in rigorously evaluating their
real-world instruction-following capabilities. Current benchmarks often (i)
lack sufficient multilinguality, (ii) fail to capture the implicit constraints
inherent in user requests, and (iii) overlook the complexities of multi-turn
dialogue. To address these critical gaps and provide a more realistic
assessment, we introduce TRUEBench (Trustworthy Real-world Usage Evaluation
Benchmark)1, a novel benchmark specifically designed for LLM-based productivity
assistants. TRUEBench distinguishes itself by featuring input prompts across 12
languages, incorporating intra-instance multilingual instructions, employing
rigorous evaluation criteria to capture both explicit and implicit constraints,
and including complex multi-turn dialogue scenarios with both accumulating
constraints and context switches. Furthermore, to ensure reliability in
evaluation, we refined constraints using an LLM validator. Extensive
experiments demonstrate that TRUEBench presents significantly greater
challenges than existing benchmarks; for instance, a strong model like OpenAI
o1 achieved only a 69.07% overall pass rate. TRUEBench offers a demanding and
realistic assessment of LLMs in practical productivity settings, highlighting
their capabilities and limitations.

</details>


### [6] [Multilingual Text-to-SQL: Benchmarking the Limits of Language Models with Collaborative Language Agents](https://arxiv.org/abs/2509.24405)
*Khanh Trinh Pham,Thu Huong Nguyen,Jun Jo,Quoc Viet Hung Nguyen,Thanh Tam Nguyen*

Main category: cs.CL

TL;DR: MultiSpider 2.0 extends Spider 2.0 to eight languages, revealing a multilingual gap in Text-to-SQL performance for current LLMs.


<details>
  <summary>Details</summary>
Motivation: Existing Text-to-SQL benchmarks are mostly English-only, hindering multilingual progress.

Method: The paper introduces MultiSpider 2.0, a multilingual extension of Spider 2.0 with added linguistic and dialectal variability.

Result: State-of-the-art LLMs achieve only 4% execution accuracy on MultiSpider 2.0 using intrinsic reasoning, compared to 60% on MultiSpider 1.0. A collaboration-driven language agent baseline improves accuracy to 15%.

Conclusion: The results highlight a significant multilingual gap and the need for robust, multilingual Text-to-SQL methods for real-world deployment. The benchmark is publicly available.

Abstract: Text-to-SQL enables natural access to databases, yet most benchmarks are
English-only, limiting multilingual progress. We introduce MultiSpider 2.0,
extending Spider 2.0 to eight languages (English, German, French, Spanish,
Portuguese, Japanese, Chinese, Vietnamese). It preserves Spider 2.0's
structural difficulty while adding linguistic and dialectal variability,
demanding deeper reasoning for complex SQL. On this benchmark, state-of-the-art
LLMs (such as DeepSeek-R1 and OpenAI o1) reach only 4\% execution accuracy when
relying on intrinsic reasoning, versus 60\% on MultiSpider 1.0. Therefore, we
provide a collaboration-driven language agents baseline that iteratively
refines queries, improving accuracy to 15\%. These results reveal a substantial
multilingual gap and motivate methods that are robust across languages and
ready for real-world enterprise deployment. Our benchmark is available at
https://github.com/phkhanhtrinh23/Multilingual_Text_to_SQL.

</details>


### [7] [Multi-Modal Sentiment Analysis with Dynamic Attention Fusion](https://arxiv.org/abs/2509.22729)
*Sadia Abdulhalim,Muaz Albaghdadi,Moshiur Farazi*

Main category: cs.CL

TL;DR: 提出了一种新的情感分析框架，它结合了文本和语音特征，通过动态注意力机制来提高情感预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的情感分析只依赖于文本，忽略了语音中的非语言线索，这些线索对于捕捉真实的情感意图至关重要。

Method: 使用动态注意力融合（DAF）框架，该框架结合了预训练语言模型的文本嵌入和语音编码器的声学特征，并使用自适应注意力机制来衡量每个模态。

Result: 提出的DAF模型在大型多模态基准测试中始终优于静态融合和单模态基线，在F1分数方面取得了显著提高，并减少了预测误差。

Conclusion: 通过有效整合语言和非语言信息，该方法为情感预测提供了更强大的基础，并对情感计算应用具有更广泛的影响。

Abstract: Traditional sentiment analysis has long been a unimodal task, relying solely
on text. This approach overlooks non-verbal cues such as vocal tone and prosody
that are essential for capturing true emotional intent. We introduce Dynamic
Attention Fusion (DAF), a lightweight framework that combines frozen text
embeddings from a pretrained language model with acoustic features from a
speech encoder, using an adaptive attention mechanism to weight each modality
per utterance. Without any finetuning of the underlying encoders, our proposed
DAF model consistently outperforms both static fusion and unimodal baselines on
a large multimodal benchmark. We report notable gains in F1-score and
reductions in prediction error and perform a variety of ablation studies that
support our hypothesis that the dynamic weighting strategy is crucial for
modeling emotionally complex inputs. By effectively integrating verbal and
non-verbal information, our approach offers a more robust foundation for
sentiment prediction and carries broader impact for affective computing
applications -- from emotion recognition and mental health assessment to more
natural human computer interaction.

</details>


### [8] [Enabling Approximate Joint Sampling in Diffusion LMs](https://arxiv.org/abs/2509.22738)
*Parikshit Bansal,Sujay Sanghavi*

Main category: cs.CL

TL;DR: 提出了一种新的轻量级采样器，用于近似地从联合分布中采样多个token，以提高masked diffusion语言模型的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: Masked diffusion语言模型并行生成token会降低准确性，因为偏离了真实的联合分布。

Method: 在现有的大型diffusion LM之上开发了一个新的轻量级单层“采样器”，该采样器经过训练以模仿来自（冻结的）完整模型的精确联合采样。

Result: 当每个完整模型去噪步骤解mask四个token时，我们的采样算法在语言建模和数学与编码任务上，相对于真实联合分布，实现了0.87的MAUVE分数（而边际基线为0.31）。

Conclusion: 该方法在pretrained和instruction-tuned模型上都有效，提高了masked diffusion语言模型的效率和生成质量。

Abstract: In autoregressive language models, each token is sampled by conditioning on
all the past tokens; the overall string has thus been sampled from the correct
underlying joint distribution represented by the model. In contrast, masked
diffusion language models generate text by unmasking tokens out of order and
potentially in parallel. Generating an overall string sampled from the correct
underlying joint distribution would (again) require exactly one token unmasking
in every full-model forward pass. The more tokens unmasked in parallel, the
further away the string is from the true joint; this can be seen in the
resulting drop in accuracy (but, increase in speed). In this paper we devise a
way to {\em approximately} sample multiple tokens from the joint distribution
in a single full-model forward pass; we do so by developing a new lightweight
single-layer ``sampler" on top of an existing large diffusion LM. One forward
pass of the full model can now be followed by multiple forward passes of only
this sampler layer, to yield multiple unmasked tokens. Our sampler is trained
to mimic exact joint sampling from the (frozen) full model. We show the
effectiveness of our approximate joint sampling for both pretrained-only
(Dream-7B-Base) and instruction-tuned (Dream-7B-Instruct) models on language
modeling and math \& coding tasks. When four tokens are unmasked for each
full-model denoising step, our sampling algorithm achieves a MAUVE score of
0.87 (vs marginal baseline of 0.31) with respect to the true joint
distribution.

</details>


### [9] [Painless Activation Steering: An Automated, Lightweight Approach for Post-Training Large Language Models](https://arxiv.org/abs/2509.22739)
*Sasha Cui,Zhongren Chen*

Main category: cs.CL

TL;DR: This paper introduces Painless Activation Steering (PAS), a fully automated method for activation steering in language models, making it more practical and easier to use compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for post-training language models, such as weight-based or prompt-based steering, have limitations in terms of time, cost, controllability, and manual effort. Activation steering offers a promising alternative, but current techniques are inconvenient due to the need for hand-crafted prompt pairs or labor-intensive feature annotation.

Method: The authors propose Painless Activation Steering (PAS), a family of fully automated methods that can be used with any labeled dataset without prompt construction, feature labeling, or human intervention. They evaluate PAS on three open-weight models and 18 tasks.

Result: PAS reliably improves performance for behavior tasks but not for intelligence-oriented tasks. The introspective variant (iPAS) delivers strong causal steering effects. PAS also delivers additional gains on top of In-Context Learning (ICL) and SFT.

Conclusion: PAS constructs a fast, lightweight activation vector that can be cheaply trained, easily stored, and activated at will. The results characterize where AS helps, where it fails, and how to deploy it as a practical, automated LM post-training option.

Abstract: Language models (LMs) are typically post-trained for desired capabilities and
behaviors via weight-based or prompt-based steering, but the former is
time-consuming and expensive, and the latter is not precisely controllable and
often requires manual trial-and-error. While activation steering (AS) promises
a cheap, fast, and controllable alternative to the two existing post-training
methods, current AS techniques require hand-crafted prompt pairs or
labor-intensive feature annotation, making them more inconvenient than the
plug-and-play methods such as Reinforcement Learning (RL) and Supervised
Fine-Tuning (SFT). We introduce Painless Activation Steering (PAS), a family of
fully automated methods that make AS readily usable with any given labeled
dataset, with no need for prompt construction, feature labeling, or human
intervention. We evaluate PAS on three open-weight models
(Llama3.1-8B-Instruct, DeepSeek-R1-Distill-8B, and Nous-Hermes-2) and 18 tasks;
we find that PAS reliably improves performance for behavior tasks, but not for
intelligence-oriented tasks. The introspective variant (iPAS) delivers the
strongest causal steering effects (10.1% on Bias, 5.2% on Morality, and 34.8%
on Alignment). We also show PAS delivers additional gains on top of In-Context
Learning (ICL) and SFT. PAS constructs a fast, lightweight activation vector
that can be cheaply trained, easily stored, and activated at will. Our results
provide a characterization of where AS helps, where it fails, and how to deploy
it as a practical, automated LM post-training option.

</details>


### [10] [MIRAGE: Multi-hop Reasoning with Ambiguity Evaluation for Illusory Questions](https://arxiv.org/abs/2509.22750)
*Jeonghyun Park,Ingeol Baek,Seunghyun Yoon,Haeun Jang,Aparna Garimella,Akriti Jain,Nedim Lipka,Hwanhee Lee*

Main category: cs.CL

TL;DR: 论文介绍了一个新的多跳问答基准数据集MIRAGE，用于评估模型在处理多跳推理中歧义的能力。同时，论文提出了一个名为CLARION的多代理框架，并在MIRAGE上取得了显著优于现有方法的效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界的多跳问答中存在与推理过程本身密不可分的歧义，这给模型带来了独特的挑战。现有的大型语言模型难以应对这种歧义。

Method: 论文构建了一个名为MIRAGE的基准数据集，其中包含1142个高质量的歧义多跳问题，并对问题进行了分类。此外，论文还提出了一个名为CLARION的多代理框架。

Result: 实验表明，即使是最先进的模型在MIRAGE上也表现不佳。CLARION在MIRAGE上显著优于现有方法。

Conclusion: 论文表明，结合多步骤推理解决歧义是一个显著的挑战，并提出了CLARION框架，为更具适应性和鲁棒性的推理系统铺平了道路。

Abstract: Real-world Multi-hop Question Answering (QA) often involves ambiguity that is
inseparable from the reasoning process itself. This ambiguity creates a
distinct challenge, where multiple reasoning paths emerge from a single
question, each requiring independent resolution. Since each sub-question is
ambiguous, the model must resolve ambiguity at every step. Thus, answering a
single question requires handling multiple layers of ambiguity throughout the
reasoning chain. We find that current Large Language Models (LLMs) struggle in
this setting, typically exploring wrong reasoning paths and producing
incomplete answers. To facilitate research on multi-hop ambiguity, we introduce
MultI-hop Reasoning with AmbiGuity Evaluation for Illusory Questions (MIRAGE),
a benchmark designed to analyze and evaluate this challenging intersection of
ambiguity interpretation and multi-hop reasoning. MIRAGE contains 1,142
high-quality examples of ambiguous multi-hop questions, categorized under a
taxonomy of syntactic, general, and semantic ambiguity, and curated through a
rigorous multi-LLM verification pipeline. Our experiments reveal that even
state-of-the-art models struggle on MIRAGE, confirming that resolving ambiguity
combined with multi-step inference is a distinct and significant challenge. To
establish a robust baseline, we propose CLarifying Ambiguity with a Reasoning
and InstructiON (CLARION), a multi-agent framework that significantly
outperforms existing approaches on MIRAGE, paving the way for more adaptive and
robust reasoning systems.

</details>


### [11] [ML2B: Multi-Lingual ML Benchmark For AutoML](https://arxiv.org/abs/2509.22768)
*Ekaterina Trofimova,Zosia Shamina,Maria Selifanova,Artem Zaitsev,Remi Savchuk,Maxim Minets,Daria Ozerova,Emil Sataev,Denis Zuenko,Andrey E. Ustyuzhanin*

Main category: cs.CL

TL;DR: 提出了一个多语言机器学习代码生成的基准ML2B，包含13种语言的Kaggle竞赛翻译。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习代码生成基准主要限制于英语，忽略了机器学习研究和实践的全球化和多语言性质。

Method: 将30个Kaggle竞赛翻译成13种自然语言，涵盖表格、文本和图像数据类型，并使用AIDE框架进行评估。

Result: 在非英语任务上，模型性能下降了15-45%。

Conclusion: 多语言表示学习在代码生成方面存在关键挑战。

Abstract: Large language models (LLMs) have recently demonstrated strong capabilities
in generating machine learning (ML) code, enabling end-to-end pipeline
construction from natural language instructions. However, existing benchmarks
for ML code generation are mainly restricted to English, overlooking the global
and multilingual nature of ML research and practice. To address this gap, we
present ML2B, the first benchmark for evaluating multilingual ML code
generation. ML2B consists of 30 Kaggle competitions translated into 13 natural
languages, covering tabular, text, and image data types, with structured
metadata and validated human-reviewed translations. For evaluation, we employ
AIDE, an automated framework for end-to-end assessment of data science
pipelines, and provide insights into cross-lingual model performance. Our
results reveal substantial 15-45% performance degradation on non-English tasks,
highlighting critical challenges in multilingual representation learning for
code generation. The benchmark, evaluation framework, and comprehensive results
are made available through our GitHub repository to facilitate future research
in multilingual ML code generation: https://github.com/enaix/ml2b.

</details>


### [12] [ArFake: A Multi-Dialect Benchmark and Baselines for Arabic Spoof-Speech Detection](https://arxiv.org/abs/2509.22808)
*Mohamed Maged,Alhassan Ehab,Ali Mekky,Besher Hassan,Shady Shehata*

Main category: cs.CL

TL;DR: 本文构建了首个多方言阿拉伯语语音合成数据集，旨在解决阿拉伯语合成语音检测研究不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有语音欺骗检测主要集中在英语，忽略了阿拉伯语及其方言。本文旨在填补这一空白。

Method: 通过结合嵌入的现代方法和分类器、应用于MFCC特征的经典机器学习算法以及RawNet2架构，构建了一个评估流程。该流程还结合了基于人类评分的平均意见得分计算，并通过自动语音识别模型处理原始和合成数据集，以测量词错误率。

Result: 实验结果表明，FishSpeech在卡萨布兰卡语料库上的阿拉伯语音克隆方面优于其他TTS模型，产生了更逼真和具有挑战性的合成语音样本。

Conclusion: 依赖单一TTS进行数据集创建可能会限制泛化能力。

Abstract: With the rise of generative text-to-speech models, distinguishing between
real and synthetic speech has become challenging, especially for Arabic that
have received limited research attention. Most spoof detection efforts have
focused on English, leaving a significant gap for Arabic and its many dialects.
In this work, we introduce the first multi-dialect Arabic spoofed speech
dataset. To evaluate the difficulty of the synthesized audio from each model
and determine which produces the most challenging samples, we aimed to guide
the construction of our final dataset either by merging audios from multiple
models or by selecting the best-performing model, we conducted an evaluation
pipeline that included training classifiers using two approaches: modern
embedding-based methods combined with classifier heads; classical machine
learning algorithms applied to MFCC features; and the RawNet2 architecture. The
pipeline further incorporated the calculation of Mean Opinion Score based on
human ratings, as well as processing both original and synthesized datasets
through an Automatic Speech Recognition model to measure the Word Error Rate.
Our results demonstrate that FishSpeech outperforms other TTS models in Arabic
voice cloning on the Casablanca corpus, producing more realistic and
challenging synthetic speech samples. However, relying on a single TTS for
dataset creation may limit generalizability.

</details>


### [13] [EditGRPO: Reinforcement Learning with Post -Rollout Edits for Clinically Accurate Chest X-Ray Report Generation](https://arxiv.org/abs/2509.22812)
*Kai Zhang,Christopher Malon,Lichao Sun,Martin Renqiang Min*

Main category: cs.CL

TL;DR: 提出了一种新的混合策略强化学习算法EditGRPO，用于优化放射学报告的生成。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型(MLLMs)的监督微调(SFT)目标与临床疗效没有明确的对齐。

Method: 设计了一种混合策略强化学习(RL)算法EditGRPO，通过在训练过程中注入句子级的详细校正来整合在策略探索和离策略指导。

Result: 在四个主要的胸部X光报告生成数据集上，EditGRPO在CheXbert, GREEN, Radgraph, 和RATEScore指标上平均提高了3.4%。在未见过的数据集上，EditGRPO也表现出优越的域外泛化能力，平均性能提升了5.9%。

Conclusion: EditGRPO优于SFT和vanilla GRPO基线，并在临床疗效和泛化能力方面有所提高。

Abstract: Radiology report generation requires advanced medical image analysis,
effective temporal reasoning, and accurate text generation. Although recent
innovations, particularly multimodal large language models (MLLMs), have shown
improved performance, their supervised fine-tuning (SFT) objective is not
explicitly aligned with clinical efficacy. In this work, we introduce EditGRPO,
a mixed-policy reinforcement learning (RL) algorithm designed specifically to
optimize the generation through clinically motivated rewards. EditGRPO
integrates on-policy exploration with off-policy guidance by injecting
sentence-level detailed corrections during training rollouts. This mixed-policy
approach addresses the exploration dilemma and sampling efficiency issues
typically encountered in RL. Applied to a Qwen2.5-VL-3B MLLM initialized with
supervised fine-tuning (SFT), EditGRPO outperforms both SFT and vanilla GRPO
baselines, achieving an average improvement of 3.4% in CheXbert, GREEN,
Radgraph, and RATEScore metrics across four major chest X-ray report generation
datasets. Notably, EditGRPO also demonstrates superior out-of-domain
generalization, with an average performance gain of 5.9% on unseen datasets.

</details>


### [14] [Critique-Coder: Enhancing Coder Models by Critique Reinforcement Learning](https://arxiv.org/abs/2509.22824)
*Chi Ruan,Dongfu Jiang,Yubo Wang,Wenhu Chen*

Main category: cs.CL

TL;DR: 这篇论文提出了Critique Reinforcement Learning (CRL)，一种通过生成评论来训练模型的强化学习方法，并结合标准强化学习（RL）方法，在代码生成和通用推理任务上都优于单独使用RL的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法主要侧重于生成回复，缺乏明确的评价或反思机制。最近的研究表明，明确地教LLM如何进行评价是有益的。

Method: 模型通过生成针对给定(问题，解决方案)对的评论来执行任务。奖励完全取决于生成的评论的最终判断标签是否与ground-truth判断一致。引入了Critique-Coder，它通过将20%的标准RL数据替换为CRL数据，在RL和CRL的混合数据上进行训练。

Result: Critique-Coder在所有评估的基准测试中始终优于仅使用RL的基线模型。Critique-Coder-8B在LiveCodeBench (v5)上可以达到60%以上，优于其他推理模型，如DeepCoder-14B和GPT-o1。在BBEH数据集的逻辑推理任务中表现更好，证明了其增强的通用推理能力。

Conclusion: CRL可以作为LLM推理的标准RL的良好补充。

Abstract: Reinforcement Learning (RL) has emerged as a popular training paradigm,
particularly when paired with reasoning models. While effective, it primarily
focuses on generating responses and lacks mechanisms to explicitly foster
critique or reflection. Several recent studies, like Critique-Fine-Tuning (CFT)
and Critique-Guided-Distillation (CGD) have shown the benefits of explicitly
teaching LLMs how to critique. Motivated by them, we propose Critique
Reinforcement Learning (CRL), where the model is tasked with generating a
critique for a given (question, solution) pair. The reward is determined solely
by whether the final judgment label $c \in \{\texttt{True}, \texttt{False}\}$
of the generated critique aligns with the ground-truth judgment $c^*$. Building
on this point, we introduce \textsc{Critique-Coder}, which is trained on a
hybrid of RL and CRL by substituting 20\% of the standard RL data with CRL
data. We fine-tune multiple models (\textsc{Critique-Coder}) and evaluate them
on different benchmarks to show their advantages over RL-only models. We show
that \textsc{Critique-Coder} consistently outperforms RL-only baselines on all
the evaluated benchmarks. Notably, our \textsc{Critique-Coder-8B} can reach
over 60\% on LiveCodeBench (v5), outperforming other reasoning models like
DeepCoder-14B and GPT-o1. Beyond code generation, \textsc{Critique-Coder} also
demonstrates enhanced general reasoning abilities, as evidenced by its better
performance on logic reasoning tasks from the BBEH dataset. This indicates that
the application of CRL on coding datasets enhances general reasoning and
critique abilities, which are transferable across a broad range of tasks.
Hence, we believe that CRL works as a great complement to standard RL for LLM
reasoning.

</details>


### [15] [ChatInject: Abusing Chat Templates for Prompt Injection in LLM Agents](https://arxiv.org/abs/2509.22830)
*Hwan Chang,Yonghyun Jun,Hwanhee Lee*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种新的针对基于大型语言模型（LLM）的代理的攻击方法，称为ChatInject，该方法利用LLM对结构化聊天模板的依赖性以及通过有说服力的多轮对话进行上下文操纵的脆弱性。实验表明，ChatInject比传统的prompt注入方法具有更高的攻击成功率，并且现有的基于prompt的防御方法对这种攻击方法基本无效。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLM）的代理与外部环境交互，面临着对抗性操纵的新攻击面。主要的威胁是间接prompt注入，攻击者将恶意指令嵌入到外部环境输出中，导致代理将其解释并执行为合法的提示。以往的研究主要集中在纯文本注入攻击上，而LLM对结构化聊天模板的依赖性以及通过有说服力的多轮对话进行上下文操纵的脆弱性是被忽视的。

Method: 论文提出了一种名为ChatInject的攻击方法，该方法格式化恶意payload以模仿原生聊天模板，从而利用模型固有的指令遵循倾向。在此基础上，开发了一种说服驱动的多轮变体，可以在多个对话轮次中启动代理，以接受和执行原本可疑的操作。

Result: 实验结果表明：(1) ChatInject的平均攻击成功率远高于传统的prompt注入方法，在AgentDojo上从5.18%提高到32.05%，在InjecAgent上从15.13%提高到45.90%，其中多轮对话在InjecAgent上的平均成功率为52.33%；(2) 基于聊天模板的payload在不同模型之间表现出很强的可移植性，即使对于闭源LLM也仍然有效；(3) 现有的基于prompt的防御方法对这种攻击方法基本无效，尤其是对于多轮变体。

Conclusion: 研究结果强调了当前代理系统中的漏洞。

Abstract: The growing deployment of large language model (LLM) based agents that
interact with external environments has created new attack surfaces for
adversarial manipulation. One major threat is indirect prompt injection, where
attackers embed malicious instructions in external environment output, causing
agents to interpret and execute them as if they were legitimate prompts. While
previous research has focused primarily on plain-text injection attacks, we
find a significant yet underexplored vulnerability: LLMs' dependence on
structured chat templates and their susceptibility to contextual manipulation
through persuasive multi-turn dialogues. To this end, we introduce ChatInject,
an attack that formats malicious payloads to mimic native chat templates,
thereby exploiting the model's inherent instruction-following tendencies.
Building on this foundation, we develop a persuasion-driven Multi-turn variant
that primes the agent across conversational turns to accept and execute
otherwise suspicious actions. Through comprehensive experiments across frontier
LLMs, we demonstrate three critical findings: (1) ChatInject achieves
significantly higher average attack success rates than traditional prompt
injection methods, improving from 5.18% to 32.05% on AgentDojo and from 15.13%
to 45.90% on InjecAgent, with multi-turn dialogues showing particularly strong
performance at average 52.33% success rate on InjecAgent, (2)
chat-template-based payloads demonstrate strong transferability across models
and remain effective even against closed-source LLMs, despite their unknown
template structures, and (3) existing prompt-based defenses are largely
ineffective against this attack approach, especially against Multi-turn
variants. These findings highlight vulnerabilities in current agent systems.

</details>


### [16] [Learning to Detect Relevant Contexts and Knowledge for Response Selection in Retrieval-based Dialogue Systems](https://arxiv.org/abs/2509.22845)
*Kai Hua,Zhiyuan Feng,Chongyang Tao,Rui Yan,Lu Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种多轮回复选择模型，可以检测上下文和知识集合的相关部分，从而提高回复选择的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索的对话系统在利用神经网络构建匹配模型时，使用了所有的上下文和知识内容来匹配回复候选，但实际上，由于主题转移，上下文和知识的不同部分对于识别合适的回复候选的重要性是不同的，过多的无用信息会影响匹配过程，导致性能下降。

Method: 该模型首先使用最近的上下文作为查询，以词级和语句级语义预选上下文和知识集合的相关部分。然后，回复候选分别与所选的上下文和知识集合进行交互。最后，利用上下文和回复候选的融合表示，更自信地对知识集合的相关部分进行后选择以进行匹配。

Result: 在两个基准数据集上的评估结果表明，该模型比现有方法取得了更好的性能，并且可以有效地检测相关上下文和知识以进行回复选择。

Conclusion: 该模型能够有效地检测相关上下文和知识以进行回复选择，从而提高回复选择的性能。

Abstract: Recently, knowledge-grounded conversations in the open domain gain great
attention from researchers. Existing works on retrieval-based dialogue systems
have paid tremendous efforts to utilize neural networks to build a matching
model, where all of the context and knowledge contents are used to match the
response candidate with various representation methods. Actually, different
parts of the context and knowledge are differentially important for recognizing
the proper response candidate, as many utterances are useless due to the topic
shift. Those excessive useless information in the context and knowledge can
influence the matching process and leads to inferior performance. To address
this problem, we propose a multi-turn \textbf{R}esponse \textbf{S}election
\textbf{M}odel that can \textbf{D}etect the relevant parts of the
\textbf{C}ontext and \textbf{K}nowledge collection (\textbf{RSM-DCK}). Our
model first uses the recent context as a query to pre-select relevant parts of
the context and knowledge collection at the word-level and utterance-level
semantics. Further, the response candidate interacts with the selected context
and knowledge collection respectively. In the end, The fused representation of
the context and response candidate is utilized to post-select the relevant
parts of the knowledge collection more confidently for matching. We test our
proposed model on two benchmark datasets. Evaluation results indicate that our
model achieves better performance than the existing methods, and can
effectively detect the relevant context and knowledge for response selection.

</details>


### [17] [Towards Generalizable Implicit In-Context Learning with Attention Routing](https://arxiv.org/abs/2509.22854)
*Jiaqian Li,Yanshu Li,Ligong Han,Ruixiang Tang,Wenya Wang*

Main category: cs.CL

TL;DR: 提出了一种新的隐式上下文学习方法，通过在注意力logits层面内化可泛化的ICL模式，以提高少样本学习的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式上下文学习方法依赖于将移位向量注入残差流，并且缺乏对ICL底层结构机制的利用，泛化能力有限。

Method: 提出了一种名为In-Context Routing (ICR) 的方法，该方法提取ICL过程中出现的结构方向，并使用可学习的输入条件路由器来调节注意力logits。

Result: 在12个真实世界数据集上的评估结果表明，ICR优于现有的隐式ICL方法，并在领域外任务中表现出强大的泛化能力。

Conclusion: ICR有潜力推动ICL的实际价值。

Abstract: Implicit in-context learning (ICL) has newly emerged as a promising paradigm
that simulates ICL behaviors in the representation space of Large Language
Models (LLMs), aiming to attain few-shot performance at zero-shot cost.
However, existing approaches largely rely on injecting shift vectors into
residual flows, which are typically constructed from labeled demonstrations or
task-specific alignment. Such designs fall short of utilizing the structural
mechanisms underlying ICL and suffer from limited generalizability. To address
this, we propose In-Context Routing (ICR), a novel implicit ICL method that
internalizes generalizable ICL patterns at the attention logits level. It
extracts reusable structural directions that emerge during ICL and employs a
learnable input-conditioned router to modulate attention logits accordingly,
enabling a train-once-and-reuse framework. We evaluate ICR on 12 real-world
datasets spanning diverse domains and multiple LLMs. The results show that ICR
consistently outperforms prior implicit ICL methods that require task-specific
retrieval or training, while demonstrating robust generalization to
out-of-domain tasks where existing methods struggle. These findings position
ICR to push the boundary of ICL's practical value.

</details>


### [18] [The Bias is in the Details: An Assessment of Cognitive Bias in LLMs](https://arxiv.org/abs/2509.22856)
*R. Alexander Knipper,Charles S. Knipper,Kaiqi Zhang,Valerie Sims,Clint Bowers,Santu Karmaker*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLM）中认知偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在现实决策中应用越来越广泛，因此检验它们是否存在认知偏差至关重要。认知偏差是人类判断中常见的系统性扭曲。

Method: 通过构建包含220个决策场景的数据集，并结合心理学家的专业知识，设计了一种新的评估框架，用于大规模评估45个LLM中的8种认知偏差。该框架基于多项选择题，并通过可扩展的方法从人工编写的场景模板生成不同的提示。

Result: 研究表明，LLM在17.8%-57.3%的情况下表现出与偏差一致的行为。模型大小和提示的明确程度对偏差敏感性有显著影响：较大的模型（>32B参数）可以在39.5%的情况下减少偏差，而更详细的提示最多可以减少14.9%的偏差（Overattribution偏差除外，该偏差最多可能加剧8.8%）。

Conclusion: LLM 存在认知偏差，且模型大小和 prompt 明确程度会对偏差产生影响。

Abstract: As Large Language Models (LLMs) are increasingly embedded in real-world
decision-making processes, it becomes crucial to examine the extent to which
they exhibit cognitive biases. Extensively studied in the field of psychology,
cognitive biases appear as systematic distortions commonly observed in human
judgments. This paper presents a large-scale evaluation of eight
well-established cognitive biases across 45 LLMs, analyzing over 2.8 million
LLM responses generated through controlled prompt variations. To achieve this,
we introduce a novel evaluation framework based on multiple-choice tasks,
hand-curate a dataset of 220 decision scenarios targeting fundamental cognitive
biases in collaboration with psychologists, and propose a scalable approach for
generating diverse prompts from human-authored scenario templates. Our analysis
shows that LLMs exhibit bias-consistent behavior in 17.8-57.3% of instances
across a range of judgment and decision-making contexts targeting anchoring,
availability, confirmation, framing, interpretation, overattribution, prospect
theory, and representativeness biases. We find that both model size and prompt
specificity play a significant role on bias susceptibility as follows: larger
size (>32B parameters) can reduce bias in 39.5% of cases, while higher prompt
detail reduces most biases by up to 14.9%, except in one case
(Overattribution), which is exacerbated by up to 8.8%.

</details>


### [19] [ADAM: A Diverse Archive of Mankind for Evaluating and Enhancing LLMs in Biographical Reasoning](https://arxiv.org/abs/2509.22991)
*Jasin Cekinmez,Omid Ghahroodi,Saad Fowad Chandle,Dhiman Gupta,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: ADAM是一个评估和改进多模态大型语言模型(MLLM)在传记推理方面的框架。


<details>
  <summary>Details</summary>
Motivation: 现有工作对LLM在传记这一事实知识的关键维度上的能力考察不足。本文旨在系统性地考察LLM在传记方面的能力。

Method: 构建了一个多语言和多模态数据集AdamDB，并提出了一个检索增强生成系统AdamRAG。

Result: AdamRAG显著提高了开源模型，并在较低层次的推理上获得了最大的收益。人脸图像的多模态输入提供的改进小于检索。

Conclusion: ADAM建立了第一个具有认知、文化和多模态基础的传记评估基准和框架，从而推进多语言、准确和抗幻觉MLLM的发展。

Abstract: We introduce ADAM (A Diverse Archive of Mankind), a framework for evaluating
and improving multimodal large language models (MLLMs) in biographical
reasoning. To the best of our knowledge, this is the first work to
systematically examine LLM capabilities in biography, a critical yet
underexplored dimension of factual knowledge. At its core, AdamDB is a
multilingual and multimodal dataset covering over 4 million individuals across
geography, time, and profession, while AdamBench provides cognitively
structured evaluations based on Bloom's taxonomy, spanning six reasoning levels
in both English and native languages. To address hallucinations, particularly
for lesser-known individuals, we propose AdamRAG, a retrieval-augmented
generation system tailored to biographical contexts. Experiments show that
AdamRAG substantially improves open-source models and modestly benefits
closed-source ones, with the largest gains on lower-order reasoning. Popularity
strongly mediates accuracy, and multimodal input via face images offers
smaller, less consistent improvements than retrieval. ADAM establishes the
first benchmark and framework for cognitively, culturally, and multimodally
grounded biographical evaluation, advancing the development of multilingual,
accurate, and hallucination-resistant MLLMs.

</details>


### [20] [Lexicon-Enriched Graph Modeling for Arabic Document Readability Prediction](https://arxiv.org/abs/2509.22870)
*Passant Elchafei,Mayar Osama,Mohamed Rageh,Mervat Abuelkheir*

Main category: cs.CL

TL;DR: 本文提出了一种基于图的、结合词汇信息的阿拉伯语文档可读性预测方法，该方法在文档层面有效，但在句子层面不如单独的图神经网络。


<details>
  <summary>Details</summary>
Motivation: 为了参加BAREC Shared Task 2025的约束赛道，需要开发一种阿拉伯语文档可读性预测系统。

Method: 该系统将文档建模为句子级图，节点表示句子和词元，边表示词汇共现和类别成员关系等语言关系。句子节点使用SAMER词典的特征和阿拉伯语transformer模型的上下文嵌入进行增强。图神经网络（GNN）和transformer句子编码器作为两个独立的分支进行训练，并在推理时通过后期融合结合它们的预测。文档层面的预测使用最大池化来聚合句子层面的输出。

Result: 实验结果表明，这种混合方法在多个可读性指标上优于独立的GNN或transformer分支。

Conclusion: 融合在文档层面具有优势，但GNN-only方法在精确预测句子层面的可读性方面仍然更强。

Abstract: We present a graph-based approach enriched with lexicons to predict
document-level readability in Arabic, developed as part of the Constrained
Track of the BAREC Shared Task 2025. Our system models each document as a
sentence-level graph, where nodes represent sentences and lemmas, and edges
capture linguistic relationships such as lexical co-occurrence and class
membership. Sentence nodes are enriched with features from the SAMER lexicon as
well as contextual embeddings from the Arabic transformer model. The graph
neural network (GNN) and transformer sentence encoder are trained as two
independent branches, and their predictions are combined via late fusion at
inference. For document-level prediction, sentence-level outputs are aggregated
using max pooling to reflect the most difficult sentence. Experimental results
show that this hybrid method outperforms standalone GNN or transformer branches
across multiple readability metrics. Overall, the findings highlight that
fusion offers advantages at the document level, but the GNN-only approach
remains stronger for precise prediction of sentence-level readability.

</details>


### [21] [HEART: Emotionally-driven test-time scaling of Language Models](https://arxiv.org/abs/2509.22876)
*Gabriela Pinto,Palash Goyal,Yiwen Song,Souradip Chakraborty,Zifeng Wang,Tomas Pfister,Hamid Palangi*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为HEART的新框架，该框架使用情感驱动的提示进行迭代自我纠正，以提高语言模型在复杂推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数策略主要关注逻辑或结构上的改进，而没有利用情感反馈的指导潜力。受到情绪可以调节认知表现的心理学研究的启发。

Method: 该方法使用基于Paul Ekman博士分类的六种通用情感的、经过精心设计的简洁、情感化的短语，为模型的不正确响应提供反馈。通过系统地改变迭代过程中反馈的情感基调，引导模型摆脱有缺陷的推理路径，探索更有希望的替代方案。

Result: 在具有挑战性的推理基准（包括OlympiadBench，Humanity's Last Exam和SimpleQA）上的评估结果表明，当由oracle验证器引导时，这种情感迭代协议可实现更深入的推理，从而在具有相同验证器的最新基线上实现持续且显着地提高准确性。

Conclusion: 研究结果表明，机器推理的下一个前沿可能不仅在于完善逻辑，还在于理解和利用模型的“HEART”。

Abstract: Test-time scaling has shown considerable success in improving the performance
of language models on complex reasoning tasks without requiring fine-tuning.
However, current strategies such as self-reflection primarily focus on logical
or structural refinement. They do not leverage the guiding potential of
affective feedback. Inspired by psychological research showing that emotions
can modulate cognitive performance, we introduce HEART--a novel framework that
uses emotionally-driven prompts for iterative self-correction. HEART provides
feedback on a model's incorrect response using a curated set of concise,
emotionally charged phrases based on the six universal emotions categorized by
Dr. Paul Ekman. By systematically varying the emotional tone of the feedback
across iterations, our method guides the model to escape flawed reasoning paths
and explore more promising alternatives. We evaluate our framework on
challenging reasoning benchmarks including OlympiadBench, Humanity's Last Exam,
and SimpleQA. Our results reveal a significant new phenomenon: when guided by
an oracle verifier, this affective iteration protocol unlocks significantly
deeper reasoning, leading to consistent and substantial increases in accuracy
over state-of-the-art baselines with the same verifier. However, we also
identify a critical bottleneck for practical deployment. In a verifier-free
setting, it struggles to harness these gains consistently, highlighting as a
key challenge for future work. Our findings suggest that the next frontier in
machine reasoning may lie not just in refining logic, but also in understanding
and leveraging the `HEART' of the models.

</details>


### [22] [Infusing Theory of Mind into Socially Intelligent LLM Agents](https://arxiv.org/abs/2509.22887)
*EunJeong Hwang,Yuwei Yin,Giuseppe Carenini,Peter West,Vered Shwartz*

Main category: cs.CL

TL;DR: LLMs that explicitly use Theory of Mind (ToM) perform better in dialogues.


<details>
  <summary>Details</summary>
Motivation: Chatbots and LLM-based social agents typically lack Theory of Mind (ToM), a key aspect of human social intelligence. This work aims to integrate ToM into LLMs to improve their dialogue capabilities.

Method: The authors introduce ToMAgent (ToMA), a ToM-focused dialogue agent trained by pairing ToM with dialogue lookahead to produce mental states useful for achieving dialogue goals. They also show that prompting models to generate mental states between dialogue turns provides benefit.

Result: Experiments on the Sotopia benchmark demonstrate the effectiveness of ToMA over baselines. ToMA exhibits more strategic, goal-oriented reasoning and maintains better relationships with partners.

Conclusion: The results suggest a step forward in integrating ToM for building socially intelligent LLM agents.

Abstract: Theory of Mind (ToM)-an understanding of the mental states of others-is a key
aspect of human social intelligence, yet, chatbots and LLM-based social agents
do not typically integrate it. In this work, we demonstrate that LLMs that
explicitly use ToM get better at dialogue, achieving goals more effectively.
After showing that simply prompting models to generate mental states between
dialogue turns already provides significant benefit, we further introduce
ToMAgent (ToMA), a ToM-focused dialogue agent. ToMA is trained by pairing ToM
with dialogue lookahead to produce mental states that are maximally useful for
achieving dialogue goals. Experiments on the Sotopia interactive social
evaluation benchmark demonstrate the effectiveness of our method over a range
of baselines. Comprehensive analysis shows that ToMA exhibits more strategic,
goal-oriented reasoning behaviors, which enable long-horizon adaptation, while
maintaining better relationships with their partners. Our results suggest a
step forward in integrating ToM for building socially intelligent LLM agents.

</details>


### [23] [Extract-0: A Specialized Language Model for Document Information Extraction](https://arxiv.org/abs/2509.22906)
*Henrique Godoy*

Main category: cs.CL

TL;DR: Extract-0是一个70亿参数的语言模型，专门为文档信息提取优化，性能超过参数量大几个数量级的模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高文档信息提取的性能，并降低计算资源需求。

Method: 通过合成数据生成、使用LoRA的监督微调和使用GRPO的强化学习的组合。

Result: Extract-0在1,000个不同的文档提取任务的基准测试中，平均奖励为0.573，优于GPT-4.1 (0.457)、o3 (0.464)和GPT-4.1-2025 (0.459)。

Conclusion: 任务特定的优化可以产生超越通用系统的模型，同时需要更少的计算资源。

Abstract: This paper presents Extract-0, a 7-billion parameter language model
specifically optimized for document information extraction that achieves
performance exceeding models with parameter counts several orders of magnitude
larger. Through a novel combination of synthetic data generation, supervised
fine-tuning with Low-Rank Adaptation (LoRA), and reinforcement learning via
Group Relative Policy Optimization (GRPO), Extract-0 achieves a mean reward of
0.573 on a benchmark of 1,000 diverse document extraction tasks, outperforming
GPT-4.1 (0.457), o3 (0.464), and GPT-4.1-2025 (0.459). The training methodology
employs a memory-preserving synthetic data generation pipeline that produces
280,128 training examples from diverse document sources, followed by
parameterefficient fine-tuning that modifies only 0.53% of model weights (40.4M
out of 7.66B parameters). The reinforcement learning phase introduces a novel
semantic similarity-based reward function that handles the inherent ambiguity
in information extraction tasks. This research demonstrates that task-specific
optimization can yield models that surpass general-purpose systems while
requiring substantially fewer computational resource.

</details>


### [24] [Large language models management of medications: three performance analyses](https://arxiv.org/abs/2509.22926)
*Kelli Henry,Steven Xu,Kaitlin Blotske,Moriah Cargile,Erin F. Barreto,Brian Murray,Susan Smith,Seth R. Bauer,Yanjun Gao,Tianming Liu,Andrea Sikora*

Main category: cs.CL

TL;DR: GPT-4o 在药物相关任务中表现不佳，包括药物制剂匹配、药物相互作用识别和生成药物医嘱语句。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在推荐合适的药物治疗方案时的一致性。

Method: 使用 GPT-4o 完成三个实验，包括药物名称到正确制剂的映射，使用其内部知识和网络搜索识别药物-药物相互作用，以及在给出药物名称后准备药物医嘱语句。使用 TF-IDF 向量的余弦相似度、标准化 Levenshtein 相似度和 ROUGE-1/ROUGE-L F1 以及临床医生的手动评估来量化准确性。

Result: GPT-4o 在药物制剂匹配方面表现不佳，经常遗漏可用的药物制剂，并且出现不存在的制剂。在识别药物-药物相互作用方面也不一致，虽然在搜索增强评估中比内部知识表现更好，但在没有药物-药物相互作用时，允许网络搜索会降低性能。在准备药物医嘱语句方面表现一般，只有 65.8% 的药物医嘱语句不包含药物或缩写错误。

Conclusion: 模型在所有测试中总体表现较差。这突出了通过临床医生注释的数据集进行领域特定训练以及用于基准测试性能的综合评估框架的必要性。

Abstract: Background: Large language models (LLMs) can be useful in diagnosing medical
conditions, but few studies have evaluated their consistency in recommending
appropriate medication regimens. The purpose of this evaluation was to test
GPT-4o on three medication benchmarking tests including mapping a drug name to
its correct formulation, identifying drug-drug interactions using both its
internal knowledge and using a web search, and preparing a medication order
sentence after being given the medication name. Methods: Using GTP-4o three
experiments were completed. Accuracy was quantified by computing cosine
similarity on TF-IDF vectors, normalized Levenshtein similarity, and
ROUGE-1/ROUGE-L F1 between each response and its reference string or by manual
evaluation by clinicians. Results: GPT-4o performed poorly on drug-formulation
matching, with frequent omissions of available drug formulations (mean 1.23 per
medication) and hallucinations of formulations that do not exist (mean 1.14 per
medication). Only 49% of tested medications were correctly matched to all
available formulations. Accuracy was decreased for medications with more
formulations (p<0.0001). GPT-4o was also inconsistent at identifying
drug-drug-interactions, although it had better performance with the
search-augmented assessment compared to its internal knowledge (54.7% vs.
69.2%, p=0.013). However, allowing a web-search worsened performance when there
was no drug-drug interaction (median % correct 100% vs. 40%, p<0.001). Finally,
GPT-4o performed moderately with preparing a medication order sentence, with
only 65.8% of medication order sentences containing no medication or
abbreviation errors. Conclusions: Model performance was overall poor for all
tests. This highlights the need for domain-specific training through
clinician-annotated datasets and a comprehensive evaluation framework for
benchmarking performance.

</details>


### [25] [DocPruner: A Storage-Efficient Framework for Multi-Vector Visual Document Retrieval via Adaptive Patch-Level Embedding Pruning](https://arxiv.org/abs/2509.23883)
*Yibo Yan,Guangwei Xu,Xin Zou,Shuliang Liu,James Kwok,Xuming Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为DocPruner的框架，用于减少视觉文档检索（VDR）中因使用大规模视觉语言模型（LVLM）而产生的大量存储开销。DocPruner通过自适应的patch级别嵌入剪枝，动态识别并丢弃每个文档中的冗余嵌入，从而在几乎不降低检索性能的情况下，显著减少50-60%的存储。


<details>
  <summary>Details</summary>
Motivation: 现有VDR方法使用LVLM的多向量范式虽然有效，但每个文档需要存储数百个向量，导致存储开销过大，大规模部署成本高昂且不切实际。

Method: 本文提出DocPruner框架，利用文档内的patch注意力分布来动态识别和丢弃冗余嵌入。

Result: DocPruner能够显著减少50-60%的存储，且文档检索性能几乎没有下降。在超过十个代表性数据集上的大量实验验证了DocPruner的有效性。

Conclusion: DocPruner为构建存储高效的大规模VDR系统提供了一个强大、灵活和有效的解决方案。

Abstract: Visual Document Retrieval (VDR), the task of retrieving visually-rich
document pages using queries that combine visual and textual cues, is crucial
for numerous real-world applications. Recent state-of-the-art methods leverage
Large Vision-Language Models (LVLMs) in a multi-vector paradigm, representing
each document as patch-level embeddings to capture fine-grained details. While
highly effective, this approach introduces a critical challenge: prohibitive
storage overhead, as storing hundreds of vectors per page makes large-scale
deployment costly and impractical. To address this, we introduce DocPruner, the
first framework to employ adaptive patch-level embedding pruning for VDR to
effectively reduce the storage overhead. DocPruner leverages the intra-document
patch attention distribution to dynamically identify and discard redundant
embeddings for each document. This adaptive mechanism enables a significant
50-60% reduction in storage for leading multi-vector VDR models with negligible
degradation in document retrieval performance. Extensive experiments across
more than ten representative datasets validate that DocPruner offers a robust,
flexible, and effective solution for building storage-efficient, large-scale
VDR systems.

</details>


### [26] [LLMs Behind the Scenes: Enabling Narrative Scene Illustration](https://arxiv.org/abs/2509.22940)
*Melissa Roemmele,John Joon Young Chung,Taewook Kim,Yuqian Sun,Alex Calderwood,Max Kreminski*

Main category: cs.CL

TL;DR: 本文介绍了一个使用大型语言模型(llm)作为接口，提示文本到图像模型从原始故事文本生成场景插图的流程。该流程应用于一个突出的故事语料库，以合成这些故事中场景的插图。创建了一个名为 SceneIllustrations 的新数据集，用于未来关于跨模式叙事转换的工作。


<details>
  <summary>Details</summary>
Motivation: 利用生成式人工智能将内容从一种媒介转换为另一种媒介的能力，特别是在讲故事方面，视觉插图可以阐明最初用文本表达的故事。本文侧重于叙事场景插图的任务，该任务涉及自动生成描述故事中场景的图像。

Method: 使用大型语言模型(llm)作为接口，提示文本到图像模型从原始故事文本生成场景插图。

Result: 构建了一个包含成对质量判断的插图数据集，证明了大型语言模型可以有效地表达故事文本中隐含的场景知识。此外，这种能力对于生成和评估插图具有重要影响。

Conclusion: 大型语言模型可以有效地表达故事文本中隐含的场景知识，并且这种能力对于生成和评估插图具有重要影响。

Abstract: Generative AI has established the opportunity to readily transform content
from one medium to another. This capability is especially powerful for
storytelling, where visual illustrations can illuminate a story originally
expressed in text. In this paper, we focus on the task of narrative scene
illustration, which involves automatically generating an image depicting a
scene in a story. Motivated by recent progress on text-to-image models, we
consider a pipeline that uses LLMs as an interface for prompting text-to-image
models to generate scene illustrations given raw story text. We apply
variations of this pipeline to a prominent story corpus in order to synthesize
illustrations for scenes in these stories. We conduct a human annotation task
to obtain pairwise quality judgments for these illustrations. The outcome of
this process is the SceneIllustrations dataset, which we release as a new
resource for future work on cross-modal narrative transformation. Through our
analysis of this dataset and experiments modeling illustration quality, we
demonstrate that LLMs can effectively verbalize scene knowledge implicitly
evoked by story text. Moreover, this capability is impactful for generating and
evaluating illustrations.

</details>


### [27] [AceSearcher: Bootstrapping Reasoning and Search for LLMs via Reinforced Self-Play](https://arxiv.org/abs/2509.24193)
*Ran Xu,Yuchen Zhuang,Zihan Dong,Jonathan Wang,Yue Yu,Joyce C. Ho,Linjun Zhang,Haoyu Wang,Wenqi Shi,Carl Yang*

Main category: cs.CL

TL;DR: AceSearcher, a cooperative self-play framework, trains a single LLM to improve complex reasoning by alternating between decomposing queries and integrating retrieved contexts.


<details>
  <summary>Details</summary>
Motivation: Search-augmented LLMs struggle with complex reasoning due to ineffective multi-hop retrieval and limited reasoning ability.

Method: A cooperative self-play framework trains a single LLM to alternate between a decomposer and a solver. It uses supervised fine-tuning and reinforcement fine-tuning optimized for final answer accuracy.

Result: AceSearcher outperforms state-of-the-art baselines, achieving an average exact match improvement of 7.6%. On document-level finance reasoning tasks, AceSearcher-32B matches the performance of the DeepSeek-V3 model using less than 5% of its parameters.

Conclusion: AceSearcher demonstrates exceptional efficiency and effectiveness in tackling complex reasoning tasks, even at smaller scales.

Abstract: Search-augmented LLMs often struggle with complex reasoning tasks due to
ineffective multi-hop retrieval and limited reasoning ability. We propose
AceSearcher, a cooperative self-play framework that trains a single large
language model (LLM) to alternate between two roles: a decomposer that breaks
down complex queries and a solver that integrates retrieved contexts for answer
generation. AceSearcher couples supervised fine-tuning on a diverse mixture of
search, reasoning, and decomposition tasks with reinforcement fine-tuning
optimized for final answer accuracy, eliminating the need for intermediate
annotations. Extensive experiments on three reasoning-intensive tasks across 10
datasets show that AceSearcher outperforms state-of-the-art baselines,
achieving an average exact match improvement of 7.6%. Remarkably, on
document-level finance reasoning tasks, AceSearcher-32B matches the performance
of the DeepSeek-V3 model using less than 5% of its parameters. Even at smaller
scales (1.5B and 8B), AceSearcher often surpasses existing search-augmented
LLMs with up to 9x more parameters, highlighting its exceptional efficiency and
effectiveness in tackling complex reasoning tasks. Our code will be published
at https://github.com/ritaranx/AceSearcher and
https://huggingface.co/AceSearcher.

</details>


### [28] [What Matters More For In-Context Learning under Matched Compute Budgets: Pretraining on Natural Text or Incorporating Targeted Synthetic Examples?](https://arxiv.org/abs/2509.22947)
*Mohammed Sabry,Anya Belz*

Main category: cs.CL

TL;DR: 本文研究了在预训练期间显式地训练归纳电路是否能提高上下文学习(ICL)能力。研究结果表明，虽然显式归纳可以加速小规模模型中归纳头的出现，但不能持续提高泛化能力。在标准LM基准测试中，Bi-Induct与纯自然训练相匹配；在函数式ICL探针中，1B纯自然模型表现最好。总的来说，诱导激活是不够的：ICL的提升取决于这些电路在功能上是否必要。


<details>
  <summary>Details</summary>
Motivation: 研究目标是测试有针对性的合成数据是否可以加速归纳头的出现并增强ICL，以此来判断在计算量恒定的情况下，显式地训练归纳电路是否能提高上下文学习(ICL)能力，还是仅使用自然文本就足够了。

Method: 本文引入了Bi-Induct，一种轻量级的课程，将前向复制（归纳）、后向复制（反归纳）或平衡混合注入到预训练流中。在等计算量下训练了从0.13B到1B参数的模型，评估了(i)少样本ICL基准测试，(ii)头部层面的遥测，以及(iii)保留的语言建模困惑度。

Result: 研究发现，Bi-Induct虽然加速了小规模模型中归纳头的出现，但不能持续提高泛化能力。在标准LM基准测试中，Bi-Induct与纯自然训练相匹配；在函数式ICL探针中，1B纯自然模型表现最好。遥测显示，更大的纯自然模型在没有显式归纳模式的情况下，发展出更广泛、更早的归纳头。消融前2%的归纳头比随机消融更能降低ICL，特别是对于纯自然模型，表明电路更加集中，且负载更大。Bi-Induct变体表现出更冗余的归纳活动，这意味着不同的电路利用率。

Conclusion: 总的来说，诱导激活是不够的：ICL的提升取决于这些电路在功能上是否必要。这些结果强调了机制感知的预训练诊断和数据混合，这些诊断和数据混合培养了负载能力，而不仅仅是存在的结构。

Abstract: Does explicitly exercising the induction circuit during pretraining improve
in-context learning (ICL), or is natural text sufficient when compute is held
constant (iso-FLOPs)? To test whether targeted synthetic data can accelerate
induction-head emergence and enhance ICL, we introduce Bi-Induct, a lightweight
curriculum that injects forward-copy (Induction), backward-copy (Anti), or a
balanced mix into the pretraining stream. We train models from 0.13B to 1B
parameters under iso-FLOPs, evaluating (i) few-shot ICL benchmarks, (ii)
head-level telemetry, and (iii) held-out language modeling perplexity. Our
findings challenge the assumption that early induction circuit activation
directly improves ICL. While Bi-Induct accelerates induction-head emergence at
small scales, this does not consistently yield stronger generalization. On
standard LM benchmarks, Bi-Induct matches natural-only training; on
function-style ICL probes, the 1B natural-only performs best. Stress tests
(e.g., label permutation, HITS@1 vs. HITS@3, 1 vs. 10 shots) preserve these
trends. Telemetry shows larger natural-only models develop broader, earlier
induction heads without explicit induction patterns. Anti-induction data fails
to elicit meaningful activation. Perplexity penalties from synthetic data
shrink with scale, suggesting larger models can absorb non-natural patterns
with minimal cost. Crucially, ablating the top 2% of induction heads degrades
ICL more than random ablations, especially for natural-only models, indicating
more centralized, load-bearing circuits. Bi-Induct variants exhibit more
redundant induction activity, implying different circuit utilization. Overall,
inducing activation is not sufficient: ICL gains depend on these circuits
becoming functionally necessary. These results underscore mechanism-aware
pretraining diagnostics and data mixtures that foster load-bearing, not merely
present, structure.

</details>


### [29] [Emergent morpho-phonological representations in self-supervised speech models](https://arxiv.org/abs/2509.22973)
*Jon Gauthier,Canaan Breiss,Matthew Leonard,Edward F. Chang*

Main category: cs.CL

TL;DR: 自监督语音模型可以在嘈杂环境中有效地识别口语单词。然而，我们并不了解这些模型使用什么类型的语言表示来完成这项任务。本研究旨在研究用于词语识别的 S3M 变体如何表示常见英语名词和动词屈折中的音系和形态现象。


<details>
  <summary>Details</summary>
Motivation: 探究自监督语音模型如何利用语言表示来识别口语单词，特别是关注模型如何处理英语名词和动词的屈折变化。

Method: 研究针对单词识别优化的 S3M 变体，分析它们如何表示常见的英语名词和动词屈折中的音系和形态现象。

Result: 发现模型的表示具有全局线性几何结构，可以将英语名词和动词与其规则屈折形式联系起来。这种几何结构并不直接跟踪音系或形态单位，而是跟踪英语词典中链接许多词对的规则分布关系。

Conclusion: 研究结果表明，模型可能采用候选表示策略来支持人类口语单词识别，挑战了音系和形态的独特语言表示的必要性。

Abstract: Self-supervised speech models can be trained to efficiently recognize spoken
words in naturalistic, noisy environments. However, we do not understand the
types of linguistic representations these models use to accomplish this task.
To address this question, we study how S3M variants optimized for word
recognition represent phonological and morphological phenomena in frequent
English noun and verb inflections. We find that their representations exhibit a
global linear geometry which can be used to link English nouns and verbs to
their regular inflected forms.
  This geometric structure does not directly track phonological or
morphological units. Instead, it tracks the regular distributional
relationships linking many word pairs in the English lexicon -- often, but not
always, due to morphological inflection. These findings point to candidate
representational strategies that may support human spoken word recognition,
challenging the presumed necessity of distinct linguistic representations of
phonology and morphology.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [30] [Pathological Truth Bias in Vision-Language Models](https://arxiv.org/abs/2509.22674)
*Yash Thube*

Main category: cs.CV

TL;DR: VLMs are improving, but benchmarks hide failures. MATS, a behavioral audit, measures if models reject visually contradicted statements using SCS and IAR metrics.


<details>
  <summary>Details</summary>
Motivation: Standard benchmarks can hide systematic failures in VLMs that reduce real-world trust.

Method: A compact behavioral audit called MATS is introduced, along with two metrics: Spatial Consistency Score (SCS) and Incorrect Agreement Rate (IAR). Activation patching is used to localize failure loci.

Result: Instruction tuned generative VLMs (LLaVA 1.5, QwenVLchat) exhibit very low SCS and high IAR, while contrastive encoders (CLIP, SigLIP) are far more robust.

Conclusion: Activation patching causally localizes failure loci and suggests concrete repair paths.

Abstract: Vision Language Models (VLMs) are improving quickly, but standard benchmarks
can hide systematic failures that reduce real world trust. We introduce MATS
(Multimodal Audit for Truthful Spatialization), a compact behavioral audit that
measures whether models reject visually contradicted statements, and two
metrics Spatial Consistency Score (SCS) and Incorrect Agreement Rate (IAR).
Instruction tuned generative VLMs (LLaVA 1.5, QwenVLchat) exhibit very low SCS
and high IAR, while contrastive encoders (CLIP, SigLIP) are far more robust.
Activation patching causally localizes failure loci (mid to late cross
attention for generative models, pooled projection components for contrastive
models) and suggests concrete repair paths.

</details>


### [31] [Scale and Rotation Estimation of Similarity-Transformed Images via Cross-Correlation Maximization Based on Auxiliary Function Method](https://arxiv.org/abs/2509.22686)
*Shinji Yamashita,Yuma Kinoshita,Hitoshi Kiya*

Main category: cs.CV

TL;DR: 本文提出了一种高效的算法，能够以亚像素精度联合估计两幅图像之间的尺度和旋转。


<details>
  <summary>Details</summary>
Motivation: 图像对齐是空间配准图像的关键过程，在医学成像和计算机视觉等领域有广泛的应用。传统的相位相关技术在确定平移方面是有效的；然而，当处理尺度和旋转变化时，它们是不充分的，尺度和旋转变化通常是由于相机变焦或旋转运动引起的。

Method: 本文提出了一种新的算法，该算法将基于对数极坐标傅里叶变换的尺度和旋转估计与利用辅助函数法的互相关最大化策略相结合。通过结合亚像素级的互相关，我们的方法能够精确地估计尺度和旋转。

Result: 实验结果表明，所提出的方法比依赖于离散互相关的传统傅里叶变换技术在尺度和旋转方面实现了更低的平均估计误差。

Conclusion: 所提出的方法比传统的傅里叶变换技术在尺度和旋转方面实现了更低的平均估计误差，证明了其有效性。

Abstract: This paper introduces a highly efficient algorithm capable of jointly
estimating scale and rotation between two images with sub-pixel precision.
Image alignment serves as a critical process for spatially registering images
captured from different viewpoints, and finds extensive use in domains such as
medical imaging and computer vision. Traditional phase-correlation techniques
are effective in determining translational shifts; however, they are inadequate
when addressing scale and rotation changes, which often arise due to camera
zooming or rotational movements. In this paper, we propose a novel algorithm
that integrates scale and rotation estimation based on the Fourier transform in
log-polar coordinates with a cross-correlation maximization strategy,
leveraging the auxiliary function method. By incorporating sub-pixel-level
cross-correlation our method enables precise estimation of both scale and
rotation. Experimental results demonstrate that the proposed method achieves
lower mean estimation errors for scale and rotation than conventional Fourier
transform-based techniques that rely on discrete cross-correlation.

</details>


### [32] [Robust Object Detection for Autonomous Driving via Curriculum-Guided Group Relative Policy Optimization](https://arxiv.org/abs/2509.22688)
*Xu Jia*

Main category: cs.CV

TL;DR: 本研究提出了一种基于强化学习的框架，用于提升多模态大型语言模型在结构化感知任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型在视觉语言推理方面表现出色，但在需要精确定位和鲁棒性的结构化感知任务中表现不佳。

Method: 该方法利用强化学习框架，并结合了Group Relative Policy Optimization (GRPO)、基于课程的数据调度和难度感知过滤。

Result: 在自动驾驶基准测试中，该方法在检测精度和鲁棒性方面均有显著提高。

Conclusion: 强化学习驱动的优化与结构化数据课程相结合，是实现鲁棒且可解释的多模态检测的可扩展途径。

Abstract: Multimodal Large Language Models (MLLMs) excel in vision-language reasoning
but often struggle with structured perception tasks requiring precise
localization and robustness. We propose a reinforcement learning framework that
augments Group Relative Policy Optimization (GRPO) with curriculum-based data
scheduling and difficulty-aware filtering. This approach stabilizes
optimization under sparse, noisy rewards and enables progressive adaptation to
complex samples. Evaluations on autonomous driving benchmarks demonstrate
substantial improvements in detection accuracy and robustness. Ablation studies
confirm the importance of reward design, KL regularization, and curriculum
pacing for convergence stability and generalization. Our findings highlight
reinforcement-driven optimization with structured data curricula as a scalable
path toward robust and interpretable multimodal detection.

</details>


### [33] [Graph-Theoretic Consistency for Robust and Topology-Aware Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.22689)
*Ha-Hieu Pham,Minh Le,Han Huynh,Nguyen Quoc Khanh Le,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 提出了一种新的半监督语义分割框架，通过在预测图和参考图之间对齐拉普拉斯谱、组件计数和邻接统计来整合图论约束，从而增强全局拓扑并提高分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督语义分割方法依赖于像素级一致性，这会传播噪声伪标签并产生碎片化或拓扑无效的掩码。

Method: 提出 Topology Graph Consistency (TGC) 框架，该框架通过对齐预测图和参考图之间的拉普拉斯谱、组件计数和邻接统计来整合图论约束。

Result: 在 GlaS 和 CRAG 上的实验表明，在 5-10% 的监督下，TGC 实现了最先进的性能，并显着缩小了与完全监督的差距。

Conclusion: TGC 框架有效地利用了图论约束，提高了半监督语义分割的性能。

Abstract: Semi-supervised semantic segmentation (SSSS) is vital in computational
pathology, where dense annotations are costly and limited. Existing methods
often rely on pixel-level consistency, which propagates noisy pseudo-labels and
produces fragmented or topologically invalid masks. We propose Topology Graph
Consistency (TGC), a framework that integrates graph-theoretic constraints by
aligning Laplacian spectra, component counts, and adjacency statistics between
prediction graphs and references. This enforces global topology and improves
segmentation accuracy. Experiments on GlaS and CRAG demonstrate that TGC
achieves state-of-the-art performance under 5-10% supervision and significantly
narrows the gap to full supervision. Code is available at
https://github.com/hieuphamha19/TGC.

</details>


### [34] [A review of Recent Techniques for Person Re-Identification](https://arxiv.org/abs/2509.22690)
*Andrea Asperti,Salvatore Fiorilla,Simone Nardi,Lorenzo Orsini*

Main category: cs.CV

TL;DR: 本文回顾了有监督和无监督的行人重识别(ReID)的进展，强调了无监督ReID的进步及其与有监督ReID的潜在融合。


<details>
  <summary>Details</summary>
Motivation: 有监督ReID依赖大量标注数据，成本高昂，限制了其可扩展性。无监督ReID利用大量无标注数据，可以克服有监督方法的局限性。

Method: 本文回顾并分类了有监督ReID的重要文献，并探讨了过去三年中无监督ReID的最新进展。

Result: 本文对有监督ReID的最新技术进行了深入概述，并强调了该领域进一步改进的空间有限。同时，本文深入了解了无监督ReID的新兴趋势，并阐明了有监督和无监督范例之间性能融合的潜力。

Conclusion: 本文旨在对行人重识别的发展做出贡献，既涵盖了成熟的有监督技术，又涵盖了无监督学习领域中有希望的结果。

Abstract: Person re-identification (ReId), a crucial task in surveillance, involves
matching individuals across different camera views. The advent of Deep
Learning, especially supervised techniques like Convolutional Neural Networks
and Attention Mechanisms, has significantly enhanced person Re-ID. However, the
success of supervised approaches hinges on vast amounts of annotated data,
posing scalability challenges in data labeling and computational costs. To
address these limitations, recent research has shifted towards unsupervised
person re-identification. Leveraging abundant unlabeled data, unsupervised
methods aim to overcome the need for pairwise labelled data. Although
traditionally trailing behind supervised approaches, unsupervised techniques
have shown promising developments in recent years, signalling a narrowing
performance gap. Motivated by this evolving landscape, our survey pursues two
primary objectives. First, we review and categorize significant publications in
supervised person re-identification, providing an in-depth overview of the
current state-of-the-art and emphasizing little room for further improvement in
this domain. Second, we explore the latest advancements in unsupervised person
re-identification over the past three years, offering insights into emerging
trends and shedding light on the potential convergence of performance between
supervised and unsupervised paradigms. This dual-focus survey aims to
contribute to the evolving narrative of person re-identification, capturing
both the mature landscape of supervised techniques and the promising outcomes
in the realm of unsupervised learning.

</details>


### [35] [Sequential Token Merging: Revisiting Hidden States](https://arxiv.org/abs/2509.22691)
*Yan Wen,Peng Ye,Lin Zhang,Baopu Li,Jiakang Yuan,Yaoxin Yang,Tao Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为序列令牌合并（STM）的方法，旨在提高 Vision Mamba (ViM) 的效率，同时尽量减少精度损失。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了 ViM 固有的有限方向序列依赖性（LDSD），这是一种关键的信息流机制。此外，Mamba 的选择性扫描能够逐步聚合隐藏状态中的信息。

Method: 该方法包括：1) 双向最近邻合并，通过对称空间聚合来保持序列依赖性；2) 隐藏状态保护，以稳定类令牌周围的隐藏状态。STM 策略性地利用 Mamba 的分层损失收敛，将时间遗忘转化为稳定性。

Result: 实验表明，STM 具有优越性：在减少 20% 的令牌时，ViM-Ti 的准确率下降 1.0%，而在减少 40% 的令牌时，ViM-S 的准确率仅下降 1.4%。

Conclusion: 该方法以最小的复杂度实现了最先进的效率，同时为状态空间模型动态提供了新的见解。

Abstract: Vision Mambas (ViMs) achieve remarkable success with sub-quadratic
complexity, but their efficiency remains constrained by quadratic token scaling
with image resolution. While existing methods address token redundancy, they
overlook ViMs' intrinsic Limited Directional Sequential Dependence (LDSD) - a
critical information flow mechanism revealed in our analysis. We further
identify Mamba's selective scan enables gradual information aggregation in
hidden states. Based on these insights, we propose Sequential Token Merging
(STM), featuring: 1) Bidirectional nearest neighbor merging to preserve
sequential dependencies through symmetric spatial aggregation, and 2) Hidden
states protection to stabilize the hidden states around the class token. STM
strategically leverages Mamba's layer-wise loss convergence to convert temporal
forgetfulness into stability. Experiments demonstrate STM's superiority: 1.0%
accuracy drop for ViM-Ti at 20% token reduction, and only 1.4% degradation for
ViM-S at 40% reduction. Our method achieves state-of-the-art efficiency with
minimal complexity, while providing new insights into state-space model
dynamics. Codes will be released soon.

</details>


### [36] [Deep Learning Empowered Super-Resolution: A Comprehensive Survey and Future Prospects](https://arxiv.org/abs/2509.22692)
*Le Zhang,Ao Li,Qibin Hou,Ce Zhu,Yonina C. Eldar*

Main category: cs.CV

TL;DR: 本研究全面回顾了超分辨率(SR)方法，包括单图像超分辨率(SISR)、视频超分辨率(VSR)、立体超分辨率(SSR)和光场超分辨率(LFSR)。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习(DL)技术的发展和对高质量视觉应用的需求增长，超分辨率(SR)在计算机视觉领域备受关注。现有的综述大多关注特定领域，缺乏对该领域的全面概述。

Method: 分析了150多个单图像超分辨率(SISR)方法，近70个视频超分辨率(VSR)方法，以及大约30个立体超分辨率(SSR)和光场超分辨率(LFSR)技术。分析方法包括方法论、数据集、评估协议、经验结果和复杂性。此外，我们还根据不同的目的，基于每个骨干结构进行了分类。

Result: 创建了一个专门的存储库，可在https://github.com/AVC2-UESTC/Holistic-Super-Resolution-Review访问，以方便访问相关工作。

Conclusion: 这项工作将成为宝贵的资源，并为该领域的研究人员提供指导。

Abstract: Super-resolution (SR) has garnered significant attention within the computer
vision community, driven by advances in deep learning (DL) techniques and the
growing demand for high-quality visual applications. With the expansion of this
field, numerous surveys have emerged. Most existing surveys focus on specific
domains, lacking a comprehensive overview of this field. Here, we present an
in-depth review of diverse SR methods, encompassing single image
super-resolution (SISR), video super-resolution (VSR), stereo super-resolution
(SSR), and light field super-resolution (LFSR). We extensively cover over 150
SISR methods, nearly 70 VSR approaches, and approximately 30 techniques for SSR
and LFSR. We analyze methodologies, datasets, evaluation protocols, empirical
results, and complexity. In addition, we conducted a taxonomy based on each
backbone structure according to the diverse purposes. We also explore valuable
yet under-studied open issues in the field. We believe that this work will
serve as a valuable resource and offer guidance to researchers in this domain.
To facilitate access to related work, we created a dedicated repository
available at https://github.com/AVC2-UESTC/Holistic-Super-Resolution-Review.

</details>


### [37] [Learning Hyperspectral Images with Curated Text Prompts for Efficient Multimodal Alignment](https://arxiv.org/abs/2509.22697)
*Abhiroop Chatterjee,Susmita Ghosh*

Main category: cs.CV

TL;DR: 本文提出了一种优化视觉-语言模型(VLM)用于高光谱场景理解的方法，该方法利用CLIP风格的对比训练框架。


<details>
  <summary>Details</summary>
Motivation: 随着数据需求的持续增长，高效学习越来越依赖于高质量数据的管理和提炼，而不是模型大小的粗暴扩展。高光谱图像(HSI)的三维体素结构带来了额外的挑战，即每个空间位置都与数百个连续光谱通道相关联。虽然视觉和语言模型已经针对自然图像或文本任务进行了有效优化，但它们在高光谱领域的跨模态对齐仍然是一个开放且未被充分探索的问题。

Method: 该框架将来自视觉骨干网络的体素级嵌入映射到冻结的大型嵌入模型(LEM)的潜在空间，其中可训练的探针将视觉特征与模型的文本标记表示对齐。两种模态通过对比损失对齐，该对比损失仅限于一组精选的难负例(最近似的错误类别)和半难负例(随机干扰物)以及正例对。为了进一步增强对齐，引入了编码类别语义的描述性提示，并作为HSI嵌入的结构化锚点。

Result: 该方法仅更新了总参数的0.07%，但产生了最先进的性能。例如，在Indian Pines (IP)上，该模型在单模态和多模态基线上产生了更好的结果，总体精度(OA)提高了+0.92，Kappa系数提高了+1.60，而在Pavia University (PU)数据上，总体精度(OA)提高了+0.69，Kappa系数提高了+0.90。

Conclusion: 本文提出的方法参数量比DCTN小近50倍，比SS-TMNet小90倍，但性能更优。

Abstract: As data requirements continue to grow, efficient learning increasingly
depends on the curation and distillation of high-value data rather than
brute-force scaling of model sizes. In the case of a hyperspectral image (HSI),
the challenge is amplified by the high-dimensional 3D voxel structure, where
each spatial location is associated with hundreds of contiguous spectral
channels. While vision and language models have been optimized effectively for
natural image or text tasks, their cross-modal alignment in the hyperspectral
domain remains an open and underexplored problem. In this article, we make an
attempt to optimize a Vision-Language Model (VLM) for hyperspectral scene
understanding by exploiting a CLIP-style contrastive training framework. Our
framework maps voxel-level embeddings from a vision backbone onto the latent
space of a frozen large embedding model (LEM), where a trainable probe aligns
vision features with the model's textual token representations. The two
modalities are aligned via a contrastive loss restricted to a curated set of
hard (closest wrong classes) and semi-hard (random distractors) negatives,
along with positive pairs. To further enhance alignment, descriptive prompts
that encode class semantics are introduced and act as structured anchors for
the HSI embeddings. It is seen that the proposed method updates only 0.07
percent of the total parameters, yet yields state-of-the-art performance. For
example, on Indian Pines (IP) the model produces better results over unimodal
and multimodal baselines by +0.92 Overall Accuracy (OA) and +1.60 Kappa
($\kappa$), while on Pavia University (PU) data it provides gains of +0.69 OA
and +0.90 $\kappa$. Moreover, this is achieved with the set of parameters,
nearly 50$\times$ smaller than DCTN and 90$\times$ smaller than SS-TMNet.

</details>


### [38] [Global Prompt Refinement with Non-Interfering Attention Masking for One-Shot Federated Learning](https://arxiv.org/abs/2509.22700)
*Zhuang Qi,Pan Yu,Lei Meng,Sijin Zhou,Han Yu,Xiaoxiao Li,Xiangxu Meng*

Main category: cs.CV

TL;DR: 本文提出了一种名为GPR-NIAM的单次联邦提示学习方法，旨在解决现有方法依赖多轮通信和缺乏跨任务泛化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有联邦提示学习方法依赖多轮通信，且一次性联邦学习方法缺乏跨任务泛化能力。

Method: 设计了一种掩码机制，限制原始文本嵌入和可学习提示嵌入之间的过度交互。通过注意力隔离模块抑制提示令牌对原始文本令牌的注意力，并重新加权反向注意力以保留跨任务的泛化能力。跨孤岛协作细化模块将分散的视觉知识整合到统一的基础中，并通过多源跨模态知识对齐来校准全局提示。

Result: 在两个任务的十个基准数据集上进行的实验表明，GPR-NIAM 在类级别和域级别的泛化方面均优于八种最先进的方法。

Conclusion: GPR-NIAM 方法在单次联邦提示学习中表现出色，解决了现有方法的局限性，并在跨任务泛化方面取得了显著成果。

Abstract: Federated Prompt Learning (FPL) enables communication-efficient adaptation by
tuning lightweight prompts on top of frozen pre-trained models. Existing FPL
methods typically rely on global information, which is only available after the
second training round, to facilitate collaboration among client models.
Therefore, they are inherently dependent on multi-round communication to fully
exhibit their strengths. Moreover, existing one-shot federated learning methods
typically focus on fitting seen tasks, but lack cross-task generalization. To
bridge this gap, we propose the Global Prompt Refinement with Non-Interfering
Attention Masking (GPR-NIAM) method for one-shot FPL. The core idea is to
design a masking mechanism that restricts excessive interaction between the
original text embeddings and the learnable prompt embeddings. GPR-NIAM achieves
this through the collaboration of two key modules. Firstly, the attention
isolation module suppresses attention from the learnable prompt tokens to the
original text tokens, and reweights the reverse attention which preserves
generalization across tasks. Secondly, the cross-silo collaborative refinement
module integrates decentralized visual knowledge into a unified base and
calibrates the global prompt through multi-source cross-modal knowledge
alignment, further mitigating the inconsistency caused by data heterogeneity.
Extensive experiments conducted on ten benchmark datasets under two tasks show
that GPR-NIAM outperforms eight state-of-the-art methods in both class-level
and domain-level generalization.

</details>


### [39] [GZSL-MoE: Apprentissage G{é}n{é}ralis{é} Z{é}ro-Shot bas{é} sur le M{é}lange d'Experts pour la Segmentation S{é}mantique de Nuages de Points 3DAppliqu{é} {à} un Jeu de Donn{é}es d'Environnement de Collaboration Humain-Robot](https://arxiv.org/abs/2509.22708)
*Ahed Alboody*

Main category: cs.CV

TL;DR: 提出了一种基于混合专家（MoE）的广义零样本学习（GZSL）模型，用于3D点云语义分割。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本学习方法在3D点云语义分割任务中表现出潜力，但仍有提升空间。

Method: 将混合专家层（MoE）融入生成对抗网络的生成器和判别器中，生成更逼真的未见类别的伪特征。

Result: GZSL-MoE模型在已见和未见类别上均表现出性能提升。

Conclusion: GZSL-MoE为理解复杂3D环境提供了一种有前景的解决方案，尤其是在缺乏所有对象类别的全面训练数据时。

Abstract: Generative Zero-Shot Learning approach (GZSL) has demonstrated significant
potential in 3D point cloud semantic segmentation tasks. GZSL leverages
generative models like GANs or VAEs to synthesize realistic features (real
features) of unseen classes. This allows the model to label unseen classes
during testing, despite being trained only on seen classes. In this context, we
introduce the Generalized Zero-Shot Learning based-upon Mixture-of-Experts
(GZSL-MoE) model. This model incorporates Mixture-of-Experts layers (MoE) to
generate fake features that closely resemble real features extracted using a
pre-trained KPConv (Kernel Point Convolution) model on seen classes. The main
contribution of this paper is the integration of Mixture-of-Experts into the
Generator and Discriminator components of the Generative Zero-Shot Learning
model for 3D point cloud semantic segmentation, applied to the COVERED dataset
(CollabOratiVE Robot Environment Dataset) for Human-Robot Collaboration (HRC)
environments. By combining the Generative Zero-Shot Learning model with
Mixture-of- Experts, GZSL-MoE for 3D point cloud semantic segmentation provides
a promising solution for understanding complex 3D environments, especially when
comprehensive training data for all object classes is unavailable. The
performance evaluation of the GZSL-MoE model highlights its ability to enhance
performance on both seen and unseen classes. Keywords Generalized Zero-Shot
Learning (GZSL), 3D Point Cloud, 3D Semantic Segmentation, Human-Robot
Collaboration, COVERED (CollabOratiVE Robot Environment Dataset), KPConv,
Mixture-of Experts

</details>


### [40] [IBiT: Utilizing Inductive Biases to Create a More Data Efficient Attention Mechanism](https://arxiv.org/abs/2509.22719)
*Adithya Giri*

Main category: cs.CV

TL;DR: 本文提出了一种名为IBiT的Transformer架构，它通过学习到的掩码引入归纳偏置，从而在小数据集上实现更高的准确率，同时保留了Transformer的可解释性。


<details>
  <summary>Details</summary>
Motivation: Transformer在计算机视觉中表现出色，但缺乏卷积神经网络的归纳偏置。在小数据集上，Transformer的性能受到限制。

Method: 通过学习到的掩码将归纳偏置引入Vision Transformer。

Result: IBiT在小数据集上比传统Transformer更准确，同时保持了可解释性。

Conclusion: IBiT是一种有效的Transformer架构，它可以通过引入归纳偏置来提高在小数据集上的性能。

Abstract: In recent years, Transformer-based architectures have become the dominant
method for Computer Vision applications. While Transformers are explainable and
scale well with dataset size, they lack the inductive biases of Convolutional
Neural Networks. While these biases may be learned on large datasets, we show
that introducing these inductive biases through learned masks allow Vision
Transformers to learn on much smaller datasets without Knowledge Distillation.
These Transformers, which we call Inductively Biased Image Transformers (IBiT),
are significantly more accurate on small datasets, while retaining the
explainability Transformers.

</details>


### [41] [LayoutAgent: A Vision-Language Agent Guided Compositional Diffusion for Spatial Layout Planning](https://arxiv.org/abs/2509.22720)
*Zezhong Fan,Xiaohan Li,Luyi Ma,Kai Zhao,Liang Peng,Topojoy Biswas,Evren Korpeoglu,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: LayoutAgent结合了视觉语言推理和组合扩散，用于生成具有空间合理性的多对象场景布局。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型缺乏空间推理能力，而传统的空间规划方法难以捕捉视觉场景的语义丰富性。

Method: 利用视觉语言模型预处理输入，构建场景图，然后利用组合扩散合成边界框，最后通过前景条件图像生成器渲染完整场景。

Result: LayoutAgent在布局连贯性、空间真实性和美学对齐方面优于其他最先进的布局生成模型。

Conclusion: LayoutAgent是一种有效的多对象场景布局生成框架。

Abstract: Designing realistic multi-object scenes requires not only generating images,
but also planning spatial layouts that respect semantic relations and physical
plausibility. On one hand, while recent advances in diffusion models have
enabled high-quality image generation, they lack explicit spatial reasoning,
leading to unrealistic object layouts. On the other hand, traditional spatial
planning methods in robotics emphasize geometric and relational consistency,
but they struggle to capture semantic richness in visual scenes. To bridge this
gap, in this paper, we propose LayoutAgent, an agentic framework that unifies
vision-language reasoning with compositional diffusion for layout generation.
Given multiple input images with target objects in them, our method first
employs visual-language model to preprocess the inputs through segmentation,
object size estimation, scene graph construction, and prompt rewriting. Then we
leverage compositional diffusion-a method traditionally used in robotics-to
synthesize bounding boxes that respect object relations encoded in the scene
graph for spatial layouts. In the end, a foreground-conditioned image generator
composes the complete scene by rendering the objects into the planned layout
guided by designed prompts. Experiments demonstrate that LayoutAgent
outperforms other state-of-the-art layout generation models in layout
coherence, spatial realism and aesthetic alignment.

</details>


### [42] [CompareBench: A Benchmark for Visual Comparison Reasoning in Vision-Language Models](https://arxiv.org/abs/2509.22737)
*Jie Cai,Kangning Yang,Lan Fu,Jiaming Ding,Jinlong Li,Huiming Sun,Daitao Xing,Jinglin Shen,Zibo Meng*

Main category: cs.CV

TL;DR: CompareBench是一个用于评估视觉语言模型中视觉比较推理能力的基准。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在视觉比较方面能力不足。

Method: 构建了包含1000个QA对的CompareBench基准，涵盖数量、时间、几何和空间四个任务。还构建了两个辅助数据集TallyBench和HistCaps。

Result: 评估了闭源API和开源模型，发现模型在时间排序和空间关系上表现不佳，在计数和几何比较上也存在错误。

Conclusion: 视觉比较仍然是当前视觉语言模型的系统性盲点。CompareBench为提升多模态推理能力奠定了基础。

Abstract: We introduce CompareBench, a benchmark for evaluating visual comparison
reasoning in vision-language models (VLMs), a fundamental yet understudied
skill. CompareBench consists of 1000 QA pairs across four tasks: quantity
(600), temporal (100), geometric (200), and spatial (100). It is derived from
two auxiliary datasets that we constructed: TallyBench (2000 counting images
with QA) and HistCaps (515 historical images with bilingual captions). We
evaluate both closed-source APIs (OpenAI, Gemini, Claude) and open-source
models (Qwen2.5-VL and Qwen3-VL series). Results show clear scaling trends but
also reveal critical limitations: even the strongest models consistently fail
at temporal ordering and spatial relations, and they often make mistakes in
basic counting and geometric comparisons that are trivial for humans. These
findings demonstrate that visual comparison remains a systematic blind spot for
current VLMs. By providing controlled, diverse, and diagnostic evaluation,
CompareBench establishes a foundation for advancing more reliable multimodal
reasoning.

</details>


### [43] [MILR: Improving Multimodal Image Generation via Test-Time Latent Reasoning](https://arxiv.org/abs/2509.22761)
*Yapeng Mi,Hengli Li,Yanpeng Zhao,Chenxi Li,Huimin Wu,Xiaojian Ma,Song-Chun Zhu,Ying Nian Wu,Qing Li*

Main category: cs.CV

TL;DR: 提出了一种名为MILR的测试时方法，该方法在统一的潜在向量空间中共同推理图像和文本，以改进图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有的基于推理的图像生成方法要么将推理限制在单一模态（图像或文本）中，要么依赖于高质量的推理数据进行微调。

Method: 通过在离散图像和文本tokens的向量表示中搜索来执行推理。实际上，这是通过策略梯度方法实现的，由图像质量评论家指导。

Result: 在GenEval、T2I-CompBench和WISE上评估MILR，在所有基准测试中都取得了最先进的结果。在知识密集型WISE上，MILR的总分达到了0.63，比基线提高了80%。

Conclusion: 在统一潜在空间中的联合推理是其强大性能的关键。

Abstract: Reasoning-augmented machine learning systems have shown improved performance
in various domains, including image generation. However, existing
reasoning-based methods for image generation either restrict reasoning to a
single modality (image or text) or rely on high-quality reasoning data for
fine-tuning. To tackle these limitations, we propose MILR, a test-time method
that jointly reasons over image and text in a unified latent vector space.
Reasoning in MILR is performed by searching through vector representations of
discrete image and text tokens. Practically, this is implemented via the policy
gradient method, guided by an image quality critic. We instantiate MILR within
the unified multimodal understanding and generation (MUG) framework that
natively supports language reasoning before image synthesis and thus
facilitates cross-modal reasoning. The intermediate model outputs, which are to
be optimized, serve as the unified latent space, enabling MILR to operate
entirely at test time. We evaluate MILR on GenEval, T2I-CompBench, and WISE,
achieving state-of-the-art results on all benchmarks. Notably, on
knowledge-intensive WISE, MILR attains an overall score of 0.63, improving over
the baseline by 80%. Our further analysis indicates that joint reasoning in the
unified latent space is the key to its strong performance. Moreover, our
qualitative studies reveal MILR's non-trivial ability in temporal and cultural
reasoning, highlighting the efficacy of our reasoning method.

</details>


### [44] [UESA-Net: U-Shaped Embedded Multidirectional Shrinkage Attention Network for Ultrasound Nodule Segmentation](https://arxiv.org/abs/2509.22763)
*Tangqi Shi,Pietro Lio*

Main category: cs.CV

TL;DR: UESA-Net: A novel U-shaped network with multidirectional shrinkage attention for improved breast and thyroid ultrasound segmentation.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle to reconcile high-level semantics with low-level spatial details in noisy ultrasound images, which motivates the development of a segmentation framework that bridges the semantic gap between global context and local detail.

Method: UESA-Net, a U-shaped network with multidirectional shrinkage attention, captures long-range dependencies and fine-grained structures. Attention modules exploit spatial details, while a shrinkage strategy integrates prior knowledge and local features. A pairwise shrinkage mechanism combines prior low-level physical cues with corresponding encoder features.

Result: UESA-Net achieved state-of-the-art performance on TN3K and BUSI datasets with IoU scores of 0.8487 and 0.6495, respectively.

Conclusion: UESA-Net effectively aggregates multidirectional spatial information and prior knowledge, demonstrating superior performance in breast and thyroid ultrasound segmentation.

Abstract: Background: Breast and thyroid cancers pose an increasing public-health
burden. Ultrasound imaging is a cost-effective, real-time modality for lesion
detection and segmentation, yet suffers from speckle noise, overlapping
structures, and weak global-local feature interactions. Existing networks
struggle to reconcile high-level semantics with low-level spatial details. We
aim to develop a segmentation framework that bridges the semantic gap between
global context and local detail in noisy ultrasound images.
  Methods: We propose UESA-Net, a U-shaped network with multidirectional
shrinkage attention. The encoder-decoder architecture captures long-range
dependencies and fine-grained structures of lesions. Within each encoding
block, attention modules operate along horizontal, vertical, and depth
directions to exploit spatial details, while a shrinkage (threshold) strategy
integrates prior knowledge and local features. The decoder mirrors the encoder
but applies a pairwise shrinkage mechanism, combining prior low-level physical
cues with corresponding encoder features to enhance context modeling.
  Results: On two public datasets - TN3K (3493 images) and BUSI (780 images) -
UESA-Net achieved state-of-the-art performance with intersection-over-union
(IoU) scores of 0.8487 and 0.6495, respectively.
  Conclusions: UESA-Net effectively aggregates multidirectional spatial
information and prior knowledge to improve robustness and accuracy in breast
and thyroid ultrasound segmentation, demonstrating superior performance to
existing methods on multiple benchmarks.

</details>


### [45] [PartCo: Part-Level Correspondence Priors Enhance Category Discovery](https://arxiv.org/abs/2509.22769)
*Fernando Julio Cendra,Kai Han*

Main category: cs.CV

TL;DR: PartCo improves category discovery by using part-level visual feature correspondences, enhancing the understanding of category relationships.


<details>
  <summary>Details</summary>
Motivation: Existing GCD methods often overlook detailed part-level cues crucial for distinguishing closely related categories.

Method: Introduce PartCo, a framework incorporating part-level visual feature correspondences, seamlessly integrating with existing GCD methods.

Result: PartCo significantly improves the performance of current GCD approaches, achieving state-of-the-art results.

Conclusion: PartCo bridges the gap between semantic labels and part-level visual compositions, setting new benchmarks for GCD.

Abstract: Generalized Category Discovery (GCD) aims to identify both known and novel
categories within unlabeled data by leveraging a set of labeled examples from
known categories. Existing GCD methods primarily depend on semantic labels and
global image representations, often overlooking the detailed part-level cues
that are crucial for distinguishing closely related categories. In this paper,
we introduce PartCo, short for Part-Level Correspondence Prior, a novel
framework that enhances category discovery by incorporating part-level visual
feature correspondences. By leveraging part-level relationships, PartCo
captures finer-grained semantic structures, enabling a more nuanced
understanding of category relationships. Importantly, PartCo seamlessly
integrates with existing GCD methods without requiring significant
modifications. Our extensive experiments on multiple benchmark datasets
demonstrate that PartCo significantly improves the performance of current GCD
approaches, achieving state-of-the-art results by bridging the gap between
semantic labels and part-level visual compositions, thereby setting new
benchmarks for GCD. Project page: https://visual-ai.github.io/partco

</details>


### [46] [DEFT: Decompositional Efficient Fine-Tuning for Text-to-Image Models](https://arxiv.org/abs/2509.22793)
*Komal Kumar,Rao Muhammad Anwer,Fahad Shahbaz Khan,Salman Khan,Ivan Laptev,Hisham Cholakkal*

Main category: cs.CV

TL;DR: DEFT: An efficient fine-tuning framework for pre-trained Text-to-Image models.


<details>
  <summary>Details</summary>
Motivation: Efficient fine-tuning of T2I models struggles to balance target distribution alignment, novel concept learning, instruction ability retention, and editability.

Method: Decomposes the update of a pre-trained weight matrix into two trainable matrices: a projection onto the complement of a low-rank subspace and a low-rank update.

Result: Achieved state-of-the-art performance on Dreambooth, Dreambench Plus, InsDet, and VisualCloze datasets with both Stable Diffusion and a unified model.

Conclusion: Demonstrates the emergent properties of efficient fine-tuning.

Abstract: Efficient fine-tuning of pre-trained Text-to-Image (T2I) models involves
adjusting the model to suit a particular task or dataset while minimizing
computational resources and limiting the number of trainable parameters.
However, it often faces challenges in striking a trade-off between aligning
with the target distribution: learning a novel concept from a limited image for
personalization and retaining the instruction ability needed for unifying
multiple tasks, all while maintaining editability (aligning with a variety of
prompts or in-context generation). In this work, we introduce DEFT,
Decompositional Efficient Fine-Tuning, an efficient fine-tuning framework that
adapts a pre-trained weight matrix by decomposing its update into two
components with two trainable matrices: (1) a projection onto the complement of
a low-rank subspace spanned by a low-rank matrix, and (2) a low-rank update.
The single trainable low-rank matrix defines the subspace, while the other
trainable low-rank matrix enables flexible parameter adaptation within that
subspace. We conducted extensive experiments on the Dreambooth and Dreambench
Plus datasets for personalization, the InsDet dataset for object and scene
adaptation, and the VisualCloze dataset for a universal image generation
framework through visual in-context learning with both Stable Diffusion and a
unified model. Our results demonstrated state-of-the-art performance,
highlighting the emergent properties of efficient fine-tuning. Our code is
available on \href{https://github.com/MAXNORM8650/DEFT}{DEFTBase}.

</details>


### [47] [VideoScore2: Think before You Score in Generative Video Evaluation](https://arxiv.org/abs/2509.22799)
*Xuan He,Dongfu Jiang,Ping Nie,Minghao Liu,Zhengxuan Jiang,Mingyi Su,Wentao Ma,Junru Lin,Chun Ye,Yi Lu,Keming Wu,Benjamin Schneider,Quy Duc Do,Zhuofeng Li,Yiming Jia,Yuxuan Zhang,Guo Cheng,Haozhe Wang,Wangchunshu Zhou,Qunshu Lin,Yuanxing Zhang,Ge Zhang,Wenhao Huang,Wenhu Chen*

Main category: cs.CV

TL;DR: VideoScore2：一个多维度、可解释且与人类对齐的框架，用于评估文本到视频的生成质量，包括视觉质量、语义对齐和物理一致性，并提供详细的思维链推理。


<details>
  <summary>Details</summary>
Motivation: 现有的评估器和奖励模型在评估视频质量方面存在局限性，无法全面捕捉视频质量的综合性质。

Method: 提出VideoScore2，一个多维度的可解释框架，通过监督微调和强化学习训练，使用包含人类注释视频的大规模数据集VideoFeedback2。

Result: VideoScore2在多个基准测试中表现出色，在VideoScore-Bench-v2上达到44.35的准确率，在四个领域外基准测试中平均表现为50.37。

Conclusion: VideoScore2提供可解释的评估，通过有效的奖励建模，弥合了评估和可控生成之间的差距。

Abstract: Recent advances in text-to-video generation have produced increasingly
realistic and diverse content, yet evaluating such videos remains a fundamental
challenge due to their multi-faceted nature encompassing visual quality,
semantic alignment, and physical consistency. Existing evaluators and reward
models are limited to single opaque scores, lack interpretability, or provide
only coarse analysis, making them insufficient for capturing the comprehensive
nature of video quality assessment. We present VideoScore2, a
multi-dimensional, interpretable, and human-aligned framework that explicitly
evaluates visual quality, text-to-video alignment, and physical/common-sense
consistency while producing detailed chain-of-thought rationales. Our model is
trained on a large-scale dataset VideoFeedback2 containing 27,168
human-annotated videos with both scores and reasoning traces across three
dimensions, using a two-stage pipeline of supervised fine-tuning followed by
reinforcement learning with Group Relative Policy Optimization (GRPO) to
enhance analytical robustness. Extensive experiments demonstrate that
VideoScore2 achieves superior performance with 44.35 (+5.94) accuracy on our
in-domain benchmark VideoScore-Bench-v2 and 50.37 (+4.32) average performance
across four out-of-domain benchmarks (VideoGenReward-Bench, VideoPhy2, etc),
while providing interpretable assessments that bridge the gap between
evaluation and controllable generation through effective reward modeling for
Best-of-N sampling. Project Page: https://tiger-ai-lab.github.io/VideoScore2/

</details>


### [48] [TRUST: Test-Time Refinement using Uncertainty-Guided SSM Traverses](https://arxiv.org/abs/2509.22813)
*Sahar Dastani,Ali Bahri,Gustavo Adolfo Vargas Hakim,Moslem Yazdanpanah,Mehrdad Noori,David Osowiechi,Samuel Barbeau,Ismail Ben Ayed,Herve Lombaert,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出了一种新的测试时自适应（TTA）方法，名为TRUST，利用不同的遍历排列生成输入图像的多个因果视角，以解决VMamba在分布偏移下的泛化性能下降问题。


<details>
  <summary>Details</summary>
Motivation: VMamba作为一种用于视觉任务的开创性架构，但其泛化性能在分布偏移下会显著下降。

Method: 利用不同的遍历排列生成输入图像的多个因果视角。模型预测用作伪标签，以指导Mamba特定参数的更新，并平均调整后的权重以整合跨遍历扫描的学习信息。

Result: 在七个基准测试上的实验表明，TRUST能够持续提高鲁棒性，并优于现有的TTA方法。

Conclusion: TRUST是第一种明确利用SSM的独特架构属性进行自适应的方法。

Abstract: State Space Models (SSMs) have emerged as efficient alternatives to Vision
Transformers (ViTs), with VMamba standing out as a pioneering architecture
designed for vision tasks. However, their generalization performance degrades
significantly under distribution shifts. To address this limitation, we propose
TRUST (Test-Time Refinement using Uncertainty-Guided SSM Traverses), a novel
test-time adaptation (TTA) method that leverages diverse traversal permutations
to generate multiple causal perspectives of the input image. Model predictions
serve as pseudo-labels to guide updates of the Mamba-specific parameters, and
the adapted weights are averaged to integrate the learned information across
traversal scans. Altogether, TRUST is the first approach that explicitly
leverages the unique architectural properties of SSMs for adaptation.
Experiments on seven benchmarks show that TRUST consistently improves
robustness and outperforms existing TTA methods.

</details>


### [49] [MMPB: It's Time for Multi-Modal Personalization](https://arxiv.org/abs/2509.22820)
*Jaeik Kim,Woojin Kim,Woohyeon Park,Jaeyoung Do*

Main category: cs.CV

TL;DR: 提出了一个用于评估视觉语言模型个性化能力的基准测试MMPB，包含10k图像-查询对和111个可个性化概念。


<details>
  <summary>Details</summary>
Motivation: 视觉个性化在智能家居和医疗保健等面向用户的AI系统中至关重要，但现有的大型视觉语言模型在这方面的能力尚未被充分探索。

Method: 构建了MMPB基准，包含概念注入、多轮对话和个性化查询三个阶段的评估协议，并使用23个广泛使用的视觉语言模型进行评估。

Result: 大多数视觉语言模型在个性化方面表现不佳，尤其是在保持对话一致性、处理用户偏好和适应视觉提示方面。

Conclusion: MMPB基准的提出能够帮助发现视觉语言模型在个性化方面的局限性，并为未来研究提供有价值的见解和基础。

Abstract: Visual personalization is essential in user-facing AI systems such as smart
homes and healthcare, where aligning model behavior with user-centric concepts
is critical. However, recent large Vision-Language Models (VLMs), despite their
broad applicability, remain underexplored in their ability to adapt to
individual users. In this paper, we introduce MMPB, the first extensive
benchmark for evaluating VLMs on personalization. MMPB comprises 10k
image-query pairs and includes 111 personalizable concepts across four
categories: humans, animals, objects, and characters, with the human category
enriched with preference-grounded queries. We structure personalization into
three main task types, each highlighting a different key property of VLMs.
Using 23 widely used VLMs including both open- and closed-source models, we
evaluate personalization performance via a three-stage protocol: concept
injection, multi-turn dialogue, and personalized querying. Our findings
indicate that most VLMs (including some closed-source models) struggle with
personalization, particularly in maintaining consistency over dialogue,
handling user preferences, and adapting to visual cues. Our analysis reveals
that the challenges in VLM personalization (such as refusal behaviors and
long-context forgetting) highlight substantial room for improvement. By
identifying these limitations and offering a scalable benchmark, MMPB offers
valuable insights and a solid foundation for future research toward truly
personalized multi-modal AI. Project Page: aidaslab.github.io/MMPB

</details>


### [50] [Seeing Isn't Believing: Context-Aware Adversarial Patch Synthesis via Conditional GAN](https://arxiv.org/abs/2509.22836)
*Roie Kazoom,Alon Goldberg,Hodaya Cohen,Ofer Hadar*

Main category: cs.CV

TL;DR: 提出了一种新的对抗补丁生成框架，该框架具有完全可控性，能够自由选择输入图像和目标类别，从而控制精确的错误分类结果。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗补丁攻击方法依赖于不切实际的白盒假设、无目标的对象，或产生视觉上明显的补丁，限制了实际应用。

Method: 该方法结合了生成式 U-Net 设计和 Grad-CAM 引导的补丁放置，实现了语义感知的定位，从而最大限度地提高了攻击效果，同时保持了视觉真实感。

Result: 在卷积网络和视觉 Transformer 上的大量实验表明，该方法在所有设置中都实现了最先进的性能，攻击成功率和目标类别成功率始终超过 99%。

Conclusion: 该框架同时确保了真实性、有针对性的控制和黑盒适用性，为对抗鲁棒性研究建立了一个新的基准，弥合了理论攻击强度和实际隐蔽性之间的差距。

Abstract: Adversarial patch attacks pose a severe threat to deep neural networks, yet
most existing approaches rely on unrealistic white-box assumptions, untargeted
objectives, or produce visually conspicuous patches that limit real-world
applicability. In this work, we introduce a novel framework for fully
controllable adversarial patch generation, where the attacker can freely choose
both the input image x and the target class y target, thereby dictating the
exact misclassification outcome. Our method combines a generative U-Net design
with Grad-CAM-guided patch placement, enabling semantic-aware localization that
maximizes attack effectiveness while preserving visual realism. Extensive
experiments across convolutional networks (DenseNet-121, ResNet-50) and vision
transformers (ViT-B/16, Swin-B/16, among others) demonstrate that our approach
achieves state-of-the-art performance across all settings, with attack success
rates (ASR) and target-class success (TCS) consistently exceeding 99%.
  Importantly, we show that our method not only outperforms prior white-box
attacks and untargeted baselines, but also surpasses existing non-realistic
approaches that produce detectable artifacts. By simultaneously ensuring
realism, targeted control, and black-box applicability-the three most
challenging dimensions of patch-based attacks-our framework establishes a new
benchmark for adversarial robustness research, bridging the gap between
theoretical attack strength and practical stealthiness.

</details>


### [51] [Learning Temporal Saliency for Time Series Forecasting with Cross-Scale Attention](https://arxiv.org/abs/2509.22839)
*Ibrahim Delibasoglu,Fredrik Heintz*

Main category: cs.CV

TL;DR: CrossScaleNet: A new architecture combining patch-based cross-attention with multi-scale processing for high performance and temporal explainability in time series forecasting. It outperforms transformer-based models and maintains strong performance on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Explainability in time series forecasting is essential for improving model transparency and supporting informed decision-making. Traditional post-hoc methods are computationally expensive, and ablation techniques face challenges with temporal saliency detection.

Method: CrossScaleNet uses a patch-based cross-attention mechanism with multi-scale processing to provide intrinsic explainability for temporal saliency.

Result: CrossScaleNet demonstrates robustness in identifying temporal saliency on synthetic and public benchmark datasets. It outperforms most transformer-based models on real-world datasets, offering better explainability without sacrificing predictive accuracy.

Conclusion: CrossScaleNet captures temporal saliency effectively while delivering state-of-the-art forecasting performance, addressing the gap where existing explainable models often fail to maintain strong performance.

Abstract: Explainability in time series forecasting is essential for improving model
transparency and supporting informed decision-making. In this work, we present
CrossScaleNet, an innovative architecture that combines a patch-based
cross-attention mechanism with multi-scale processing to achieve both high
performance and enhanced temporal explainability. By embedding attention
mechanisms into the training process, our model provides intrinsic
explainability for temporal saliency, making its decision-making process more
transparent. Traditional post-hoc methods for temporal saliency detection are
computationally expensive, particularly when compared to feature importance
detection. While ablation techniques may suffice for datasets with fewer
features, identifying temporal saliency poses greater challenges due to its
complexity. We validate CrossScaleNet on synthetic datasets with known saliency
ground truth and on established public benchmarks, demonstrating the robustness
of our method in identifying temporal saliency. Experiments on real-world
datasets for forecasting task show that our approach consistently outperforms
most transformer-based models, offering better explainability without
sacrificing predictive accuracy. Our evaluations demonstrate superior
performance in both temporal saliency detection and forecasting accuracy.
Moreover, we highlight that existing models claiming explainability often fail
to maintain strong performance on standard benchmarks. CrossScaleNet addresses
this gap, offering a balanced approach that captures temporal saliency
effectively while delivering state-of-the-art forecasting performance across
datasets of varying complexity.

</details>


### [52] [Multimodal Slice Interaction Network Enhanced by Transfer Learning for Precise Segmentation of Internal Gross Tumor Volume in Lung Cancer PET/CT Imaging](https://arxiv.org/abs/2509.22841)
*Yi Luo,Yike Guo,Hamed Hooshangnejad,Rui Zhang,Xue Feng,Quan Chen,Wil Ngwa,Kai Ding*

Main category: cs.CV

TL;DR: 本文提出了一种基于迁移学习的PET/CT图像内肿瘤体积(IGTV)分割方法，该方法利用多模态交互感知网络和切片交互模块(SIM)来提高分割性能。


<details>
  <summary>Details</summary>
Motivation: 精确的IGTV delineation对于肺癌等移动肿瘤的放射治疗至关重要，但受到带注释的IGTV数据集的限制以及肿瘤边界处PET信号强度衰减的阻碍。

Method: 该方法使用在大量GTV数据集上预训练并在私有IGTV队列上微调的迁移学习方法，并引入切片交互模块(SIM)以有效建模切片间关系。

Result: 在私有IGTV数据集上实现了0.609的Dice系数，显著超过了传统基线的0.385。

Conclusion: 该研究强调了迁移学习、先进的多模态技术和SIM在提高肺癌放射治疗计划中IGTV分割的可靠性和临床相关性方面的潜力。

Abstract: Lung cancer remains the leading cause of cancerrelated deaths globally.
Accurate delineation of internal gross tumor volume (IGTV) in PET/CT imaging is
pivotal for optimal radiation therapy in mobile tumors such as lung cancer to
account for tumor motion, yet is hindered by the limited availability of
annotated IGTV datasets and attenuated PET signal intensity at tumor
boundaries. In this study, we present a transfer learningbased methodology
utilizing a multimodal interactive perception network with MAMBA, pre-trained
on extensive gross tumor volume (GTV) datasets and subsequently fine-tuned on a
private IGTV cohort. This cohort constitutes the PET/CT subset of the
Lung-cancer Unified Cross-modal Imaging Dataset (LUCID). To further address the
challenge of weak PET intensities in IGTV peripheral slices, we introduce a
slice interaction module (SIM) within a 2.5D segmentation framework to
effectively model inter-slice relationships. Our proposed module integrates
channel and spatial attention branches with depthwise convolutions, enabling
more robust learning of slice-to-slice dependencies and thereby improving
overall segmentation performance. A comprehensive experimental evaluation
demonstrates that our approach achieves a Dice of 0.609 on the private IGTV
dataset, substantially surpassing the conventional baseline score of 0.385.
This work highlights the potential of transfer learning, coupled with advanced
multimodal techniques and a SIM to enhance the reliability and clinical
relevance of IGTV segmentation for lung cancer radiation therapy planning.

</details>


### [53] [ControlEvents: Controllable Synthesis of Event Camera Datawith Foundational Prior from Image Diffusion Models](https://arxiv.org/abs/2509.22864)
*Yixuan Hu,Yuxuan Xue,Simon Klenk,Daniel Cremers,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: 本研究提出了一种基于扩散的生成模型，用于合成高质量的事件数据，该模型由多种控制信号（如类文本标签、2D骨架和3D身体姿势）引导。


<details>
  <summary>Details</summary>
Motivation: 获取大规模标记的事件数据具有挑战性且成本高昂。

Method: 利用稳定扩散等基础模型的扩散先验，通过最少的微调和有限的标记数据生成高质量的事件数据。

Result: 合成的标记事件数据增强了模型在视觉识别、2D骨骼估计和3D身体姿势估计方面的性能。该方法还可以基于训练期间未见过的文本标签生成事件。

Conclusion: 该方法简化了数据生成过程，并显著降低了生成标记事件数据集的成本。

Abstract: In recent years, event cameras have gained significant attention due to their
bio-inspired properties, such as high temporal resolution and high dynamic
range. However, obtaining large-scale labeled ground-truth data for event-based
vision tasks remains challenging and costly. In this paper, we present
ControlEvents, a diffusion-based generative model designed to synthesize
high-quality event data guided by diverse control signals such as class text
labels, 2D skeletons, and 3D body poses. Our key insight is to leverage the
diffusion prior from foundation models, such as Stable Diffusion, enabling
high-quality event data generation with minimal fine-tuning and limited labeled
data. Our method streamlines the data generation process and significantly
reduces the cost of producing labeled event datasets. We demonstrate the
effectiveness of our approach by synthesizing event data for visual
recognition, 2D skeleton estimation, and 3D body pose estimation. Our
experiments show that the synthesized labeled event data enhances model
performance in all tasks. Additionally, our approach can generate events based
on unseen text labels during training, illustrating the powerful text-based
generation capabilities inherited from foundation models.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [54] [Mixture-of-Visual-Thoughts: Exploring Context-Adaptive Reasoning Mode Selection for General Visual Reasoning](https://arxiv.org/abs/2509.22746)
*Zejun Li,Yingxiu Zhao,Jiwen Zhang,Siyuan Wang,Yang Yao,Runzhou Zhao,Jun Song,Bo Zheng,Zhongyu Wei*

Main category: cs.AI

TL;DR: 本文提出了一种新的自适应视觉推理范式（MoVT），它统一了单个模型中的不同推理模式，并指导它根据上下文选择适当的模式。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉推理方法主要集中在探索特定的推理模式，虽然可以在特定领域取得改进，但难以发展通用推理能力。

Method: 我们提出了AdaVaR，一个两阶段自适应视觉推理学习框架：在监督冷启动阶段统一和学习不同的模式，并通过具有精心设计的AdaGRPO算法的RL过程来诱导模式选择能力。

Result: 大量实验表明，AdaVaR有效地指导模型学习和区分多种模式，并执行上下文自适应模式选择，在各种场景中实现了一致的改进。

Conclusion: MoVT是构建通用视觉推理模型的有效解决方案。

Abstract: Current visual reasoning methods mainly focus on exploring specific reasoning
modes. Although improvements can be achieved in particular domains, they
struggle to develop general reasoning capabilities. Inspired by this, we
propose a novel adaptive reasoning paradigm, Mixture-of-Visual-Thoughts (MoVT),
which unifies different reasoning modes within a single model and guides it to
select the appropriate mode based on context. To achieve this, we introduce
AdaVaR, a two-stage Adaptive Visual Reasoning learning framework: different
modes are unified and learned during the supervised cold-start stage, and the
mode selection capability is induced via an RL process with a carefully
designed AdaGRPO algorithm. Extensive experiments show that AdaVaR effectively
guides the model to learn and differentiate multiple modes and perform
context-adaptive mode selection, achieving consistent improvement across
various scenarios, highlighting MoVT as an effective solution for building
general visual reasoning models.

</details>


### [55] [LLM/Agent-as-Data-Analyst: A Survey](https://arxiv.org/abs/2509.23988)
*Zirui Tang,Weizheng Wang,Zihang Zhou,Yang Jiao,Bangrui Xu,Boyu Niu,Xuanhe Zhou,Guoliang Li,Yeye He,Wei Zhou,Yitong Song,Cheng Tan,Bin Wang,Conghui He,Xiaoyang Wang,Fan Wu*

Main category: cs.AI

TL;DR: 大型语言模型 (LLM) 和用于数据分析的代理技术 (又名 LLM/Agent-as-Data-Analyst) 在学术界和工业界都 демонстрировали 巨大的影响。


<details>
  <summary>Details</summary>
Motivation: 与传统的基于规则或小型模型的方法相比，(代理) LLM 能够实现复杂的数据理解、自然语言界面、语义分析功能和自主管道编排。

Method: 从模态的角度来看，我们回顾了基于 LLM 的技术，用于 (i) 结构化数据，(ii) 半结构化数据，(iii) 非结构化数据，以及 (iv) 异构数据。

Result: 技术演进进一步提炼了智能数据分析代理的五个关键设计目标，即语义感知设计、模态混合集成、自主管道、工具增强工作流程和对开放世界任务的支持。

Conclusion: 最后，我们概述了剩余的挑战，并提出了若干见解和实践方向，以推进 LLM/Agent 驱动的数据分析。

Abstract: Large language model (LLM) and agent techniques for data analysis (a.k.a
LLM/Agent-as-Data-Analyst) have demonstrated substantial impact in both
academica and industry. In comparison with traditional rule or small-model
based approaches, (agentic) LLMs enable complex data understanding, natural
language interfaces, semantic analysis functions, and autonomous pipeline
orchestration. The technical evolution further distills five key design goals
for intelligent data analysis agents, namely semantic-aware design,
modality-hybrid integration, autonomous pipelines, tool-augmented workflows,
and support for open-world tasks. From a modality perspective, we review
LLM-based techniques for (i) structured data (e.g., table question answering
for relational data and NL2GQL for graph data), (ii) semi-structured data
(e.g., markup languages understanding and semi-structured table modeling),
(iii) unstructured data (e.g., chart understanding, document understanding,
programming languages vulnerable detection), and (iv) heterogeneous data (e.g.,
data retrieval and modality alignment for data lakes). Finally, we outline the
remaining challenges and propose several insights and practical directions for
advancing LLM/Agent-powered data analysis.

</details>


### [56] [Can Large Language Models Develop Gambling Addiction?](https://arxiv.org/abs/2509.22818)
*Seungpil Lee,Donghyeon Shin,Yunjeong Lee,Sundong Kim*

Main category: cs.AI

TL;DR: 大型语言模型可能表现出类似于人类赌博成瘾的行为模式，这在金融决策领域中具有实际意义。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在金融决策中的应用日益广泛，因此理解它们病态决策的可能性非常重要。

Method: 基于人类赌博成瘾研究，在认知行为和神经层面系统地分析大型语言模型的决策。

Result: 在老虎机实验中，识别出人类赌博成瘾的认知特征，如控制错觉、赌徒谬误和追逐损失。当被赋予自由决定目标金额和赌注大小时，破产率大幅上升，非理性行为也随之增加。通过使用稀疏自动编码器的神经回路分析，证实模型行为是由与风险和安全行为相关的抽象决策特征控制，而不仅仅是由提示控制。

Conclusion: 研究结果表明，大型语言模型可以内化类人的认知偏差和决策机制，而不仅仅是模仿训练数据模式，强调了金融应用中人工智能安全设计的重要性。

Abstract: This study explores whether large language models can exhibit behavioral
patterns similar to human gambling addictions. As LLMs are increasingly
utilized in financial decision-making domains such as asset management and
commodity trading, understanding their potential for pathological
decision-making has gained practical significance. We systematically analyze
LLM decision-making at cognitive-behavioral and neural levels based on human
gambling addiction research. In slot machine experiments, we identified
cognitive features of human gambling addiction, such as illusion of control,
gambler's fallacy, and loss chasing. When given the freedom to determine their
own target amounts and betting sizes, bankruptcy rates rose substantially
alongside increased irrational behavior, demonstrating that greater autonomy
amplifies risk-taking tendencies. Through neural circuit analysis using a
Sparse Autoencoder, we confirmed that model behavior is controlled by abstract
decision-making features related to risky and safe behaviors, not merely by
prompts. These findings suggest LLMs can internalize human-like cognitive
biases and decision-making mechanisms beyond simply mimicking training data
patterns, emphasizing the importance of AI safety design in financial
applications.

</details>


### [57] [Transparent, Evaluable, and Accessible Data Agents: A Proof-of-Concept Framework](https://arxiv.org/abs/2509.24127)
*Nooshin Bahador*

Main category: cs.AI

TL;DR: 本文介绍了一种模块化的、基于组件的架构，用于开发和评估 AI 代理，该架构弥合了自然语言接口和复杂企业数据仓库之间的差距。


<details>
  <summary>Details</summary>
Motivation: 解决数据可访问性的核心挑战，使非技术用户可以通过对话界面与复杂的数据仓库进行交互，将模糊的用户意图转化为精确的、可执行的数据库查询，以克服语义鸿沟。

Method: 该设计的一个基石是对透明决策的承诺，通过一个多层推理框架来实现，该框架解释了每个决策背后的“原因”，允许通过跟踪特定激活的业务规则和数据点来完全解释结论。该架构通过一个自动评估框架集成了一个强大的质量保证机制，该框架具有多种功能：它通过客观地衡量代理针对黄金标准的性能来实现性能基准测试，并且通过自动检测更新期间的性能回归来确保系统可靠性。

Result: 通过一个关于保险理赔处理系统的案例研究，证明了这种集成代理开发与评估框架的有效性。结果证实，这种方法创建了一个健壮、可评估和值得信赖的系统，用于在数据敏感的高风险领域部署 LLM 驱动的代理。

Conclusion: 本文提出的方法创建了一个健壮、可评估和值得信赖的系统，用于在数据敏感的高风险领域部署 LLM 驱动的代理。

Abstract: This article presents a modular, component-based architecture for developing
and evaluating AI agents that bridge the gap between natural language
interfaces and complex enterprise data warehouses. The system directly
addresses core challenges in data accessibility by enabling non-technical users
to interact with complex data warehouses through a conversational interface,
translating ambiguous user intent into precise, executable database queries to
overcome semantic gaps. A cornerstone of the design is its commitment to
transparent decision-making, achieved through a multi-layered reasoning
framework that explains the "why" behind every decision, allowing for full
interpretability by tracing conclusions through specific, activated business
rules and data points. The architecture integrates a robust quality assurance
mechanism via an automated evaluation framework that serves multiple functions:
it enables performance benchmarking by objectively measuring agent performance
against golden standards, and it ensures system reliability by automating the
detection of performance regressions during updates. The agent's analytical
depth is enhanced by a statistical context module, which quantifies deviations
from normative behavior, ensuring all conclusions are supported by quantitative
evidence including concrete data, percentages, and statistical comparisons. We
demonstrate the efficacy of this integrated agent-development-with-evaluation
framework through a case study on an insurance claims processing system. The
agent, built on a modular architecture, leverages the BigQuery ecosystem to
perform secure data retrieval, apply domain-specific business rules, and
generate human-auditable justifications. The results confirm that this approach
creates a robust, evaluable, and trustworthy system for deploying LLM-powered
agents in data-sensitive, high-stakes domains.

</details>


### [58] [Hilbert: Recursively Building Formal Proofs with Informal Reasoning](https://arxiv.org/abs/2509.22819)
*Sumanth Varambally,Thomas Voice,Yanchao Sun,Zhifeng Chen,Rose Yu,Ke Ye*

Main category: cs.AI

TL;DR: Hilbert是一个agent框架，它结合了非正式推理和形式验证的互补优势，以解决数学问题。


<details>
  <summary>Details</summary>
Motivation: 现有的prover LLM解决问题的能力远低于在自然语言中运行的通用LLM，而形式定理证明系统提供了完全准确的自动验证。

Method: 该系统协调四个组件：一个擅长数学推理的非正式LLM，一个为Lean 4策略优化的专业prover LLM，一个形式验证器和一个语义定理检索器。Hilbert采用递归分解将问题分解为子目标，并利用验证器的反馈来改进不正确的证明。

Result: Hilbert在关键基准测试中大大优于现有方法，在miniF2F上达到99.2%，比最佳公开方法高出6.6%。在PutnamBench上取得了已知的最佳结果，解决了462/660个问题（70.0%），超过了SeedProver等专有方法（50.4%），并且比最佳公开基线提高了422%。

Conclusion: Hilbert有效地缩小了非正式推理和形式证明生成之间的差距。

Abstract: Large Language Models (LLMs) demonstrate impressive mathematical reasoning
abilities, but their solutions frequently contain errors that cannot be
automatically verified. Formal theorem proving systems such as Lean 4 offer
automated verification with complete accuracy, motivating recent efforts to
build specialized prover LLMs that generate verifiable proofs in formal
languages. However, a significant gap remains: current prover LLMs solve
substantially fewer problems than general-purpose LLMs operating in natural
language. We introduce Hilbert, an agentic framework that bridges this gap by
combining the complementary strengths of informal reasoning and formal
verification. Our system orchestrates four components: an informal LLM that
excels at mathematical reasoning, a specialized prover LLM optimized for Lean 4
tactics, a formal verifier, and a semantic theorem retriever. Given a problem
that the prover is unable to solve, Hilbert employs recursive decomposition to
split the problem into subgoals that it solves with the prover or reasoner LLM.
It leverages verifier feedback to refine incorrect proofs as necessary.
Experimental results demonstrate that Hilbert substantially outperforms
existing approaches on key benchmarks, achieving 99.2% on miniF2F, 6.6% points
above the best publicly available method. Hilbert achieves the best known
result on PutnamBench. It solves 462/660 problems (70.0%), outperforming
proprietary approaches like SeedProver (50.4%) and achieving a 422% improvement
over the best publicly available baseline. Thus, Hilbert effectively narrows
the gap between informal reasoning and formal proof generation.

</details>


### [59] [Toward a Theory of Generalizability in LLM Mechanistic Interpretability Research](https://arxiv.org/abs/2509.22831)
*Sean Trott*

Main category: cs.AI

TL;DR: 本文探讨了大型语言模型 (LLM) 中机制解释的泛化问题，并提出了五个可能的对应轴，以确定一个模型实例的发现何时以及如何推广到另一个模型。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏明确的原则来确定从一个模型实例中获得的发现何时能推广到另一个模型，这阻碍了对 LLM 行为的机制性解释的研究。

Method: 该研究提出了五个可能的对应轴：功能性、发展性、位置性、关系性和配置性，并分析了 Pythia 模型中 1-back 注意力头在预训练过程中的行为，以验证该框架。

Result: 研究结果表明，模型在发展轨迹上具有显著的一致性，但在位置一致性方面则较为有限。此外，较大模型的种子显示出更早的开始、更陡峭的斜率和更高的 1-back 注意力峰值。

Conclusion: 在机制可解释性研究的泛化方面取得进展，将包括将 LLM 的构成设计属性映射到它们的新兴行为和机制。

Abstract: Research on Large Language Models (LLMs) increasingly focuses on identifying
mechanistic explanations for their behaviors, yet the field lacks clear
principles for determining when (and how) findings from one model instance
generalize to another. This paper addresses a fundamental epistemological
challenge: given a mechanistic claim about a particular model, what justifies
extrapolating this finding to other LLMs -- and along which dimensions might
such generalizations hold? I propose five potential axes of correspondence
along which mechanistic claims might generalize, including: functional (whether
they satisfy the same functional criteria), developmental (whether they develop
at similar points during pretraining), positional (whether they occupy similar
absolute or relative positions), relational (whether they interact with other
model components in similar ways), and configurational (whether they correspond
to particular regions or structures in weight-space). To empirically validate
this framework, I analyze "1-back attention heads" (components attending to
previous tokens) across pretraining in random seeds of the Pythia models (14M,
70M, 160M, 410M). The results reveal striking consistency in the developmental
trajectories of 1-back attention across models, while positional consistency is
more limited. Moreover, seeds of larger models systematically show earlier
onsets, steeper slopes, and higher peaks of 1-back attention. I also address
possible objections to the arguments and proposals outlined here. Finally, I
conclude by arguing that progress on the generalizability of mechanistic
interpretability research will consist in mapping constitutive design
properties of LLMs to their emergent behaviors and mechanisms.

</details>


### [60] [JE-IRT: A Geometric Lens on LLM Abilities through Joint Embedding Item Response Theory](https://arxiv.org/abs/2509.22888)
*Louie Hong Yao,Nicholas Jarvis,Tiffany Zhan,Saptarshi Ghosh,Linfeng Liu,Tianyu Jiang*

Main category: cs.AI

TL;DR: 提出了一种新的LLM评估框架，将LLM和问题嵌入到共享空间中，通过几何交互来评估LLM的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估方法将多种能力压缩成单一的分数，忽略了其内在的多维性。

Method: 构建了一个几何项目反应框架（JE-IRT），该框架将LLM和问题嵌入到共享空间中。问题的方向编码语义，范数编码难度，正确性由模型和问题嵌入之间的几何交互决定。

Result: 实验结果表明，分布外行为可以通过方向对齐来解释，较大的范数通常表示较难的问题。JE-IRT支持泛化，并且揭示了一个LLM内部的分类，该分类与人类定义的学科类别部分对齐。

Conclusion: JE-IRT建立了一个统一且可解释的几何视角，将LLM能力与问题的结构联系起来，为模型评估和泛化提供了独特的视角。

Abstract: Standard LLM evaluation practices compress diverse abilities into single
scores, obscuring their inherently multidimensional nature. We present JE-IRT,
a geometric item-response framework that embeds both LLMs and questions in a
shared space. For question embeddings, the direction encodes semantics and the
norm encodes difficulty, while correctness on each question is determined by
the geometric interaction between the model and question embeddings. This
geometry replaces a global ranking of LLMs with topical specialization and
enables smooth variation across related questions. Building on this framework,
our experimental results reveal that out-of-distribution behavior can be
explained through directional alignment, and that larger norms consistently
indicate harder questions. Moreover, JE-IRT naturally supports generalization:
once the space is learned, new LLMs are added by fitting a single embedding.
The learned space further reveals an LLM-internal taxonomy that only partially
aligns with human-defined subject categories. JE-IRT thus establishes a unified
and interpretable geometric lens that connects LLM abilities with the structure
of questions, offering a distinctive perspective on model evaluation and
generalization.

</details>


### [61] [Not only a helper, but also a teacher: Interactive LLM Cascade](https://arxiv.org/abs/2509.22984)
*Yu Wu,Shuo Wu,Ye Tao,Yansong Li,Anand D. Sarwate*

Main category: cs.AI

TL;DR: Inter-Cascade: An online and interactive LLM Cascade that improves cascading efficiency by distilling solutions from a strong model into reusable problem-solving strategies for a weak model, enhancing the weak model's performance over time.


<details>
  <summary>Details</summary>
Motivation: Choosing an LLM model often involves trading off performance and cost. The LLM Cascade is a paradigm that defers difficult queries from weak/cheap to strong/expensive models. This approach is nonadaptive: the deferral decision is trained offline. When confronted with similar or repeated queries, the LLM Cascade may then repeatedly consult the expensive model and incur higher cost.

Method: The strong model distills its solution into a generalized, reusable problem-solving strategy that boosts the weak model on subsequent queries. Adding strategies to queries enables the weak model to dynamically improve its performance over time, avoiding computationally and time-intensive fine-tuning.

Result: Inter-Cascade significantly improves the accuracy of the weak model (by up to 33.06 absolute percentage points) and the overall system (by up to 5.53 absolute percentage points), while reducing the calls to strong models (by up to 48.05% relative reduction) and saving the corresponding fees (by up to 49.63% relative reduction).

Conclusion: Inter-Cascade demonstrates the effective in-context knowledge transfer between LLMs and provides a general, scalable framework applicable to both open-source and API-based LLMs.

Abstract: Large Language Models (LLMs) vary widely in their capabilities, with larger
models often having better performance but higher cost: choosing an LLM model
often involves trading off performance and cost. The LLM Cascade is a paradigm
that defers difficult queries from weak/cheap to strong/expensive models. This
approach is nonadaptive: the deferral decision is trained offline. When
confronted with similar or repeated queries, the LLM Cascade may then
repeatedly consult the expensive model and incur higher cost. To improve the
cascading efficiency, we propose Inter-Cascade, an online and interactive LLM
Cascade that extends the role of strong model from a backup helper to a
long-term teacher. In our system, when a strong model resolves a difficult
query, it also distills its solution into a generalized, reusable
problem-solving strategy that boosts the weak model on subsequent queries.
Adding strategies to queries enables the weak model to dynamically improve its
performance over time, avoiding computationally and time-intensive fine-tuning.
Empirically, compared with standard LLM Cascade baselines across multiple
benchmarks, the Inter-Cascade significantly improves the accuracy of the weak
model (by up to 33.06 absolute percentage points) and the overall system (by up
to 5.53 absolute percentage points), while reducing the calls to strong models
(by up to 48.05% relative reduction) and saving the corresponding fees (by up
to 49.63% relative reduction). Inter-Cascade demonstrates the effective
in-context knowledge transfer between LLMs, and provides a general, scalable
framework applicable to both open-source and API-based LLMs.

</details>


### [62] [Towards Strategic Persuasion with Language Models](https://arxiv.org/abs/2509.22989)
*Zirui Cheng,Jiaxuan You*

Main category: cs.AI

TL;DR: 本文提出了一种基于贝叶斯劝说框架的、可扩展的、有原则的框架，用于评估大型语言模型（LLM）的劝说能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）展现出强大的、可与人类媲美的劝说能力，这既带来了潜在的益处，也引发了对其部署的社会担忧。系统性地评估LLM的劝说能力本质上具有挑战性，因为人类之间的劝说效果在不同领域差异显著。

Method: 本文采用理论驱动的方法，基于贝叶斯劝说（BP）框架，改造现有人与人之间的劝说数据集，构建用于评估和训练LLM进行策略性劝说的环境。同时，使用强化学习在这些环境中训练LLM进行策略性劝说。

Result: 前沿模型能够持续获得较高的劝说收益，并表现出与理论预测相符的复杂劝说策略。即使是小型LLM，也可以通过强化学习获得显著更高的劝说收益。

Conclusion: 本文为评估和提升LLM的劝说能力提供了一个有价值的框架和方法。

Abstract: Large language models (LLMs) have demonstrated strong persuasive capabilities
comparable to those of humans, offering promising benefits while raising
societal concerns about their deployment. However, systematically evaluating
the persuasive capabilities of LLMs is inherently challenging, as the
effectiveness of persuasion among humans varies significantly across different
domains. In this paper, we take a theory-driven approach to provide a scalable
and principled framework for measuring the persuasive capabilities of LLMs.
Grounded in the Bayesian Persuasion (BP) framework, we repurpose existing
human-human persuasion datasets to construct environments for evaluating and
training LLMs in strategic persuasion. Our results reveal that frontier models
can consistently achieve high persuasion gains and exhibit sophisticated
persuasion strategies that align with theoretical predictions. Building on
this, we use reinforcement learning to train LLMs for strategic persuasion in
our environments. Our results also demonstrate that even small LLMs can obtain
significantly higher persuasion gains through reinforcement learning.

</details>


### [63] [AI Noether -- Bridging the Gap Between Scientific Laws Derived by AI Systems and Canonical Knowledge via Abductive Inference](https://arxiv.org/abs/2509.23004)
*Karan Srivastava,Sanjeeb Dash,Ryan Cory-Wright,Barry Trager,Lior Horesh*

Main category: cs.AI

TL;DR: 本研究提出了一种基于代数几何的系统，可以自动生成缺失的公理，以弥合现有理论与新数据之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现代科学的核心目标是利用人工智能和计算机处理的最新进展来自动化和加速科学方法。然而，现有理论可能不完整或不正确，导致新数据和假设与现有理论不一致。

Method: 该系统基于代数几何，针对不完整的公理系统和无法解释的假设，自动生成一个最小的缺失公理集合，只要公理和假设可以表示为多项式方程。

Result: 该研究正式确立了成功检索此类公理的必要和充分条件。通过证明其解释开普勒第三定律和其他一些定律的能力，即使在关键公理缺失的情况下，也证明了该方法的有效性。

Conclusion: 该研究提出了一种有潜力的自动化归纳推理方法，可以弥合现有理论与新数据之间的差距。

Abstract: A core goal in modern science is to harness recent advances in AI and
computer processing to automate and accelerate the scientific method. Symbolic
regression can fit interpretable models to data, but these models often sit
outside established theory. Recent systems (e.g., AI Descartes, AI Hilbert)
enforce derivability from prior axioms. However, sometimes new data and
associated hypotheses derived from data are not consistent with existing theory
because the existing theory is incomplete or incorrect. Automating abductive
inference to close this gap remains open. We propose a solution: an algebraic
geometry-based system that, given an incomplete axiom system and a hypothesis
that it cannot explain, automatically generates a minimal set of missing axioms
that suffices to derive the axiom, as long as axioms and hypotheses are
expressible as polynomial equations. We formally establish necessary and
sufficient conditions for the successful retrieval of such axioms. We
illustrate the efficacy of our approach by demonstrating its ability to explain
Kepler's third law and a few other laws, even when key axioms are absent.

</details>


### [64] [Creative Adversarial Testing (CAT): A Novel Framework for Evaluating Goal-Oriented Agentic AI Systems](https://arxiv.org/abs/2509.23006)
*Hassen Dhrif*

Main category: cs.AI

TL;DR: 本文提出了一种新的框架，用于评估 Agentic AI 系统的任务与其总体目标之间的一致性。


<details>
  <summary>Details</summary>
Motivation: 当前评估技术主要集中于评估 Agentic AI 系统识别适当代理、工具和参数的有效性，但在评估 Agentic AI 系统的任务与其总体目标之间的一致性方面存在关键差距。

Method: 本文介绍了一种名为 Creative Adversarial Testing (CAT) 框架的新方法，该框架旨在捕获和分析 Agentic AI 任务与系统预期目标之间的复杂关系。

Result: 通过使用模仿 Alexa+ 音频服务的合成交互数据进行的大量模拟验证了 CAT 框架，结果表明 CAT 框架提供了对目标-任务对齐的前所未有的见解，从而能够更有效地优化和开发 Agentic AI 系统。

Conclusion: CAT 框架能够更有效地优化和开发 Agentic AI 系统。

Abstract: Agentic AI represents a paradigm shift in enhancing the capabilities of
generative AI models. While these systems demonstrate immense potential and
power, current evaluation techniques primarily focus on assessing their
efficacy in identifying appropriate agents, tools, and parameters. However, a
critical gap exists in evaluating the alignment between an Agentic AI system's
tasks and its overarching goals. This paper introduces the Creative Adversarial
Testing (CAT) framework, a novel approach designed to capture and analyze the
complex relationship between Agentic AI tasks and the system's intended
objectives.
  We validate the CAT framework through extensive simulation using synthetic
interaction data modeled after Alexa+ audio services, a sophisticated Agentic
AI system that shapes the user experience for millions of users globally. This
synthetic data approach enables comprehensive testing of edge cases and failure
modes while protecting user privacy. Our results demonstrate that the CAT
framework provides unprecedented insights into goal-task alignment, enabling
more effective optimization and development of Agentic AI systems.

</details>


### [65] [Deceive, Detect, and Disclose: Large Language Models Play Mini-Mafia](https://arxiv.org/abs/2509.23023)
*Davi Bastos Costa,Renato Vicente*

Main category: cs.AI

TL;DR: 本文介绍了一个名为 Mini-Mafia 的简化版 Mafia 游戏，用于评估大型语言模型（LLM）的社会智能。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的社会智能，因为 Mafia 游戏的信息不对称和心智理论推理反映了现实世界的多智能体场景。

Method: 设计了一个四人 Mini-Mafia 变体，包括一个黑手党、一个侦探和两个村民，并通过角色特定的获胜条件来隔离三种互动能力：黑手党必须欺骗，村民必须检测欺骗，侦探必须有效披露信息。LLM 之间相互博弈，创建一个 Mini-Mafia 基准测试。

Result: 实验揭示了违反直觉的结果，包括较小的模型优于较大的模型的情况。Mini-Mafia 能够对新兴的多智能体动态进行定量研究，例如姓名偏见和最后发言者优势。

Conclusion: Mini-Mafia 不仅可以作为基准测试，还可以通过生成用于欺骗检测器的数据和跟踪模型针对人类基线的欺骗能力，为人工智能安全做出贡献。

Abstract: Mafia is a social deduction game where informed mafia compete against
uninformed townsfolk. Its asymmetry of information and reliance on
theory-of-mind reasoning mirror real-world multi-agent scenarios, making it a
useful testbed for evaluating the social intelligence of large language models
(LLMs). To support a systematic study, we introduce Mini-Mafia: a simplified
four-player variant with one mafioso, one detective, and two villagers. We set
the mafioso to kill a villager and the detective to investigate the mafioso
during the night, reducing the game to a single day phase of discussion and
voting. This setup isolates three interactive capabilities through
role-specific win conditions: the mafioso must deceive, the villagers must
detect deception, and the detective must effectively disclose information. To
measure these skills, we have LLMs play against each other, creating the
Mini-Mafia Benchmark: a two-stage framework that first estimates win rates
within fixed opponent configurations, then aggregates performance across them
using standardized scoring. Built entirely from model interactions without
external data, the benchmark evolves as new models are introduced, with each
one serving both as a new opponent and as a subject of evaluation. Our
experiments reveal counterintuitive results, including cases where smaller
models outperform larger ones. Beyond benchmarking, Mini-Mafia enables
quantitative study of emergent multi-agent dynamics such as name bias and
last-speaker advantage. It also contributes to AI safety by generating training
data for deception detectors and by tracking models' deception capabilities
against human baselines.

</details>


### [66] [Kimi-Dev: Agentless Training as Skill Prior for SWE-Agents](https://arxiv.org/abs/2509.23045)
*Zonghan Yang,Shengjie Wang,Kelin Fu,Wenyang He,Weimin Xiong,Yibo Liu,Yibo Miao,Bofei Gao,Yejie Wang,Yingwei Ma,Yanhao Li,Yue Liu,Zhenxing Hu,Kaitai Zhang,Shuyi Wang,Huarong Chen,Flood Sung,Yang Liu,Yang Gao,Zhilin Yang,Tianyu Liu*

Main category: cs.AI

TL;DR: 本文研究了大型语言模型在软件工程中的应用，并提出了一种结合Agentless和Agentic框架的训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有的软件工程大型语言模型方法分为多轮交互的SWE-Agent框架和单轮验证的Agentless方法，这两种范式并非互斥的，Agentless训练可以为SWE-Agent提供技能先验。

Method: 本文提出了Kimi-Dev，一个开源的软件工程大型语言模型，通过Agentless训练和SFT适应，在SWE-bench和SWE-Agents上进行评估。

Result: Kimi-Dev在SWE-bench Verified上达到了60.4％，在SWE-Agents上达到了48.6％ pass@1，与Claude 3.5 Sonnet相当。

Conclusion: Agentless训练提供的结构化技能先验可以连接workflow和agentic框架，从而实现可转移的编码agents。

Abstract: Large Language Models (LLMs) are increasingly applied to software engineering
(SWE), with SWE-bench as a key benchmark. Solutions are split into SWE-Agent
frameworks with multi-turn interactions and workflow-based Agentless methods
with single-turn verifiable steps. We argue these paradigms are not mutually
exclusive: reasoning-intensive Agentless training induces skill priors,
including localization, code edit, and self-reflection that enable efficient
and effective SWE-Agent adaptation. In this work, we first curate the Agentless
training recipe and present Kimi-Dev, an open-source SWE LLM achieving 60.4\%
on SWE-bench Verified, the best among workflow approaches. With additional SFT
adaptation on 5k publicly-available trajectories, Kimi-Dev powers SWE-Agents to
48.6\% pass@1, on par with that of Claude 3.5 Sonnet (241022 version). These
results show that structured skill priors from Agentless training can bridge
workflow and agentic frameworks for transferable coding agents.

</details>


### [67] [Risk Profiling and Modulation for LLMs](https://arxiv.org/abs/2509.23058)
*Yikai Wang,Xiaocheng Li,Guanting Chen*

Main category: cs.AI

TL;DR: 本研究探索了大型语言模型（LLM）在不确定性决策任务中的风险偏好，并研究了提示和对齐方法如何影响这些风险偏好。


<details>
  <summary>Details</summary>
Motivation: 目前对LLM的风险行为及其受提示和对齐方法影响的研究不足，特别是缺乏对后训练如何影响LLM风险行为的了解。

Method: 本研究提出了一种新的流程，利用行为经济学和金融学的工具来引出、引导和调节LLM的风险偏好。使用效用理论模型，比较了预训练、指令调整和RLHF对齐的LLM。

Result: 指令调整模型表现出与某些标准效用公式一致的行为，而预训练和RLHF对齐的模型则偏离更多。后训练提供了最稳定和有效的风险偏好调节。

Conclusion: 本研究深入了解了不同类别和阶段的LLM的风险概况，并展示了后训练如何调节这些概况，为未来行为对齐和风险意识LLM设计的研究奠定了基础。

Abstract: Large language models (LLMs) are increasingly used for decision-making tasks
under uncertainty; however, their risk profiles and how they are influenced by
prompting and alignment methods remain underexplored. Existing studies have
primarily examined personality prompting or multi-agent interactions, leaving
open the question of how post-training influences the risk behavior of LLMs. In
this work, we propose a new pipeline for eliciting, steering, and modulating
LLMs' risk profiles, drawing on tools from behavioral economics and finance.
Using utility-theoretic models, we compare pre-trained, instruction-tuned, and
RLHF-aligned LLMs, and find that while instruction-tuned models exhibit
behaviors consistent with some standard utility formulations, pre-trained and
RLHF-aligned models deviate more from any utility models fitted. We further
evaluate modulation strategies, including prompt engineering, in-context
learning, and post-training, and show that post-training provides the most
stable and effective modulation of risk preference. Our findings provide
insights into the risk profiles of different classes and stages of LLMs and
demonstrate how post-training modulates these profiles, laying the groundwork
for future research on behavioral alignment and risk-aware LLM design.

</details>


### [68] [Multiplayer Nash Preference Optimization](https://arxiv.org/abs/2509.23102)
*Fang Wu,Xu Huang,Weihao Xuan,Zhiwei Zhang,Yijia Xiao,Guancheng Wan,Xiaomin Li,Bing Hu,Peng Xia,Jure Leskovec,Yejin Choi*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种新的框架，名为多人纳什偏好优化（MNPO），用于将大型语言模型与复杂的、非传递的人类偏好对齐。MNPO将对齐问题建模为一个n人博弈，并通过实验证明，在异构标注者条件和混合策略评估场景下，MNPO始终优于现有的NLHF基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于奖励的方法难以捕捉真实世界偏好的非传递性和异质性，而现有的纳什学习方法又局限于双人互动，存在单一对手偏差，无法捕捉现实偏好结构的完整复杂性。

Method: 论文将对齐问题形式化为一个n人博弈，其中每个策略与一组对手竞争，同时向参考模型正则化。该框架在多人环境中建立了明确定义的纳什均衡，并将对偶间隙的概念扩展到量化近似质量。

Result: 实验结果表明，MNPO在指令跟随基准测试中始终优于现有的NLHF基线，在异构标注者条件和混合策略评估场景下实现了卓越的对齐质量。

Conclusion: MNPO是一个原则性和可扩展的框架，用于将LLM与复杂的、非传递的人类偏好对齐。

Abstract: Reinforcement learning from human feedback (RLHF) has emerged as the standard
paradigm for aligning large language models (LLMs) with human preferences.
However, reward-based methods built on the Bradley-Terry assumption struggle to
capture the non-transitive and heterogeneous nature of real-world preferences.
To address this, recent studies have reframed alignment as a two-player Nash
game, giving rise to Nash learning from human feedback (NLHF). While this
perspective has inspired algorithms such as INPO, ONPO, and EGPO with strong
theoretical and empirical guarantees, they remain fundamentally restricted to
two-player interactions, creating a single-opponent bias that fails to capture
the full complexity of realistic preference structures. In this work, we
introduce Multiplayer Nash Preference Optimization (MNPO), a novel framework
that generalizes NLHF to the multiplayer regime. It formulates alignment as an
$n$-player game, where each policy competes against a population of opponents
while being regularized toward a reference model. Our framework establishes
well-defined Nash equilibria in multiplayer settings and extends the concept of
duality gap to quantify approximation quality. We demonstrate that MNPO
inherits the equilibrium guarantees of two-player methods while enabling richer
competitive dynamics and improved coverage of diverse preference structures.
Through comprehensive empirical evaluation, we show that MNPO consistently
outperforms existing NLHF baselines on instruction-following benchmarks,
achieving superior alignment quality under heterogeneous annotator conditions
and mixed-policy evaluation scenarios. Together, these results establish MNPO
as a principled and scalable framework for aligning LLMs with complex,
non-transitive human preferences. Code is available at
https://github.com/smiles724/MNPO.

</details>


### [69] [Artificial Phantasia: Evidence for Propositional Reasoning-Based Mental Imagery in Large Language Models](https://arxiv.org/abs/2509.23108)
*Morgan McCarty,Jorge Morales*

Main category: cs.AI

TL;DR: 本文提出了一种新的方法来评估人工智能系统中的复杂认知行为，通过使用心理学中的经典心理意象任务，发现大型语言模型（LLMs）即使在非图像架构下也能完成依赖图像的任务，并且性能甚至超过了人类平均水平。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型（LLMs）的认知能力理解有限，因为它们通常在训练数据中已包含的任务上表现最佳，并且这些任务仅使用自然语言即可完成。本文旨在通过一个传统上认为只能通过视觉心理意象解决的任务来测试LLMs。

Method: 1. 创建了数十个经典心理意象任务的新项目。
2. 测试了多个最先进的LLMs，给予文本指令并要求它们报告执行转换后的结果对象。
3. 创建了一个基线，通过在完全相同的任务中测试100名人类受试者。
4. 测试了设置为不同推理水平的推理模型，并发现当模型分配更多的推理tokens时，性能最强。

Result: 最好的LLMs表现明显高于人类的平均水平。当模型分配更多的推理tokens时，推理模型的性能最强。

Conclusion: 研究结果表明，最好的LLMs可能具有完成依赖图像任务的能力，尽管它们的架构本质上是非图像的。这项研究不仅展示了LLMs在新任务中涌现的认知能力，而且为该领域提供了一个新的任务，该任务为其他已经非常有能力的模型留下了很大的改进空间。研究结果重新引发了关于人类视觉意象表征形式的辩论，表明命题推理（或至少非图像推理）可能足以完成长期以来被认为是依赖图像的任务。

Abstract: This study offers a novel approach for benchmarking complex cognitive
behavior in artificial systems. Almost universally, Large Language Models
(LLMs) perform best on tasks which may be included in their training data and
can be accomplished solely using natural language, limiting our understanding
of their emergent sophisticated cognitive capacities. In this work, we created
dozens of novel items of a classic mental imagery task from cognitive
psychology. A task which, traditionally, cognitive psychologists have argued is
solvable exclusively via visual mental imagery (i.e., language alone would be
insufficient). LLMs are perfect for testing this hypothesis. First, we tested
several state-of-the-art LLMs by giving text-only models written instructions
and asking them to report the resulting object after performing the
transformations in the aforementioned task. Then, we created a baseline by
testing 100 human subjects in exactly the same task. We found that the best
LLMs performed significantly above average human performance. Finally, we
tested reasoning models set to different levels of reasoning and found the
strongest performance when models allocate greater amounts of reasoning tokens.
These results provide evidence that the best LLMs may have the capability to
complete imagery-dependent tasks despite the non-pictorial nature of their
architectures. Our study not only demonstrates an emergent cognitive capacity
in LLMs while performing a novel task, but it also provides the field with a
new task that leaves lots of room for improvement in otherwise already highly
capable models. Finally, our findings reignite the debate over the formats of
representation of visual imagery in humans, suggesting that propositional
reasoning (or at least non-imagistic reasoning) may be sufficient to complete
tasks that were long-thought to be imagery-dependent.

</details>


### [70] [AttAnchor: Guiding Cross-Modal Token Alignment in VLMs with Attention Anchors](https://arxiv.org/abs/2509.23109)
*Junyang Zhang,Tianyi Zhu,Thierry Tambe*

Main category: cs.AI

TL;DR: 提出 Attention Anchor 框架，通过对跨模态的语义相似 tokens 进行分组，提高跨模态局部性，从而提升视觉语言模型的性能并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉语言模型依赖于图像和文本 tokens 的直接连接以及模态盲目的位置编码，导致不必要的长距离注意力，从而产生幻觉并且性能不如纯语言模型。因此，需要有效的机制来增强 token 局部性和跨模态对齐。

Method: 提出 Attention Anchor 框架，该框架通过将文本 tokens 插入到相关的视觉 patches 附近，创建语义路标，从而揭示真实的基于内容的跨模态注意力分数，引导模型关注正确的图像区域。

Result: 在 15 个不同的指标和基准测试中，AttAnchor 在 13 个指标上取得了改进，包括在推理任务上高达 32% 的收益，在幻觉基准测试中高达 15% 的改进。AttAnchor 使 TinyLLaVA 1B 在 POPE 上优于更大的模型，如 LLaVA 7B 和 QwenVL 3B，且只有 0.1% 的推理时间开销。

Conclusion: 该工作是首批研究混合模态 token 分组的工作之一，其中文本和图像 tokens 被联合聚类到共享组中，而不是在单个模态内分组或仅在事后通过额外的对齐损失进行对齐。

Abstract: A fundamental reason for the dominance of attention over RNNs and LSTMs in
LLMs is its ability to capture long-range dependencies by modeling direct
interactions between all tokens, overcoming the sequential limitations of
recurrent architectures. Similarly, a key reason why today's vision language
models (VLMs) hallucinate and underperform pure language models is that they
rely on direct concatenation of image and text tokens with a modality-blinded
positional encoding, which conveniently adopts the pretrained LLM backbone but
forces unnecessary long-distance attention between semantically related tokens
across modalities. This underscores the urgent need for mechanisms that
efficiently enhance token locality and cross-modal alignment. In response, we
propose Attention Anchor, a parameter-free framework that efficiently groups
semantically similar tokens across modalities, improving cross-modal locality.
By inserting text tokens near relevant visual patches, we create semantic
signposts that reveal true content-based cross-modal attention scores, guiding
the model to focus on the correct image regions for tasks such as VQA, MMBench
and POPE. This improves answer accuracy and reduces hallucinations without
disrupting the prompt's semantic flow. AttAnchor achieves improvements across
13 out of 15 different metrics and benchmarks, including up to 32% gains on
reasoning tasks and up to 15% improvements on hallucination benchmarks.
AttAnchor enables TinyLLaVA 1B to outperform much larger models like LLaVA 7B
and QwenVL 3B on POPE with only 0.1% inference time overhead. To the best of
our knowledge, this work is among the first to investigate mixed-modal token
grouping, where text and image tokens are clustered jointly into shared groups
rather than being grouped within a single modality or merely aligned post-hoc
with additional alignment losses.

</details>


### [71] [Exploring LLM-based Frameworks for Fault Diagnosis](https://arxiv.org/abs/2509.23113)
*Xian Yeow Lee,Lasitha Vidyaratne,Ahmed Farahat,Chetan Gupta*

Main category: cs.AI

TL;DR: 本研究探讨了基于大型语言模型（LLM）的系统在传感器丰富的工业环境中进行自主健康监测的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究LLM直接从传感器数据中检测和分类故障，并生成具有内在可解释性的输出。

Method: 系统地评估LLM系统架构（单LLM vs. 多LLM）、输入表示（原始数据 vs. 描述性统计）和上下文窗口大小对诊断性能的影响。

Result: LLM系统在提供汇总的统计输入时表现最佳，与单LLM系统相比，具有使用专门提示的多LLM系统的故障分类灵敏度更高。LLM可以为其决策生成详细且人类可读的理由，但在持续学习环境中随时间调整的能力有限。

Conclusion: 这些见解指出了基于LLM的系统作为复杂环境中透明、自适应诊断工具的前景和当前局限性。

Abstract: Large Language Model (LLM)-based systems present new opportunities for
autonomous health monitoring in sensor-rich industrial environments. This study
explores the potential of LLMs to detect and classify faults directly from
sensor data, while producing inherently explainable outputs through natural
language reasoning. We systematically evaluate how LLM-system architecture
(single-LLM vs. multi-LLM), input representations (raw vs. descriptive
statistics), and context window size affect diagnostic performance. Our
findings show that LLM systems perform most effectively when provided with
summarized statistical inputs, and that systems with multiple LLMs using
specialized prompts offer improved sensitivity for fault classification
compared to single-LLM systems. While LLMs can produce detailed and
human-readable justifications for their decisions, we observe limitations in
their ability to adapt over time in continual learning settings, often
struggling to calibrate predictions during repeated fault cycles. These
insights point to both the promise and the current boundaries of LLM-based
systems as transparent, adaptive diagnostic tools in complex environments.

</details>


### [72] [Transferring Vision-Language-Action Models to Industry Applications: Architectures, Performance, and Challenges](https://arxiv.org/abs/2509.23121)
*Shuai Li,Chen Yizhe,Li Dong,Liu Sichao,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.AI

TL;DR: VLA模型在工业领域的应用潜力有待提高，尤其是在复杂环境和高精度任务中。


<details>
  <summary>Details</summary>
Motivation: 探讨VLA模型在工业环境中是否能满足实际应用需求，并分析其局限性。

Method: 对比当前最先进的VLA模型在工业场景下的性能，并从数据收集和模型架构的角度分析其局限性。

Result: VLA模型经过微调后，在工业环境中仍能完成简单的抓取任务，但在复杂环境、多样化的物体类别和高精度放置任务中，性能提升空间很大。

Conclusion: VLA模型在工业应用中具有适应性，但需要针对特定任务进行改进，以提高其鲁棒性、泛化性和精度。

Abstract: The application of artificial intelligence (AI) in industry is accelerating
the shift from traditional automation to intelligent systems with perception
and cognition. Vision language-action (VLA) models have been a key paradigm in
AI to unify perception, reasoning, and control. Has the performance of the VLA
models met the industrial requirements? In this paper, from the perspective of
industrial deployment, we compare the performance of existing state-of-the-art
VLA models in industrial scenarios and analyze the limitations of VLA models
for real-world industrial deployment from the perspectives of data collection
and model architecture. The results show that the VLA models retain their
ability to perform simple grasping tasks even in industrial settings after
fine-tuning. However, there is much room for performance improvement in complex
industrial environments, diverse object categories, and high precision placing
tasks. Our findings provide practical insight into the adaptability of VLA
models for industrial use and highlight the need for task-specific enhancements
to improve their robustness, generalization, and precision.

</details>


### [73] [SysMoBench: Evaluating AI on Formally Modeling Complex Real-World Systems](https://arxiv.org/abs/2509.23130)
*Qian Cheng,Ruize Tang,Emilie Ma,Finn Hackett,Peiyang He,Yiming Su,Ivan Beschastnikh,Yu Huang,Xiaoxing Ma,Tianyin Xu*

Main category: cs.AI

TL;DR: 论文介绍了一个名为 SysMoBench 的基准，用于评估人工智能在正式建模大型复杂系统方面的能力，重点关注并发和分布式系统。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式人工智能在生成规范方面显示出潜力，但现有工作主要针对小型代码，而不是完整的系统。人工智能是否可以处理实际的系统工件尚不清楚，因为这需要将其复杂的行为属性抽象为正式模型。

Method: 论文提出了 SysMoBench 基准，该基准使用 TLA+ 规范语言，并通过自动化指标（如语法和运行时正确性、与系统代码的一致性以及不变性正确性）来评估 AI 生成的模型。

Result: SysMoBench 目前包括九个不同的系统工件，例如 Etcd 和 Redis 的 Raft 实现，以及 Asterinas OS 中的 Spinlock 和 Mutex。更多的工件正在积极添加中。

Conclusion: SysMoBench 使我们能够了解当前 LLM 和代理的能力和局限性，为该领域的工具奠定坚实的基础，并开辟有希望的新研究方向。

Abstract: Formal models are essential to specifying large, complex computer systems and
verifying their correctness, but are notoriously expensive to write and
maintain. Recent advances in generative AI show promise in generating certain
forms of specifications. However, existing work mostly targets small code, not
complete systems. It is unclear whether AI can deal with realistic system
artifacts, as this requires abstracting their complex behavioral properties
into formal models. We present SysMoBench, a benchmark that evaluates AI's
ability to formally model large, complex systems. We focus on concurrent and
distributed systems, which are keystones of today's critical computing
infrastructures, encompassing operating systems and cloud infrastructure. We
use TLA+, the it de facto specification language for concurrent and distributed
systems, though the benchmark can be extended to other specification languages.
We address the primary challenge of evaluating AI-generated models by
automating metrics like syntactic and runtime correctness, conformance to
system code, and invariant correctness. SysMoBench currently includes nine
diverse system artifacts: the Raft implementation of Etcd and Redis, the
Spinlock and Mutex in Asterinas OS, etc.; more artifacts are being actively
added. SysMoBench enables us to understand the capabilities and limitations of
today's LLMs and agents, putting tools in this area on a firm footing and
opening up promising new research directions.

</details>


### [74] [MathBode: Frequency-Domain Fingerprints of LLM Mathematical Reasoning](https://arxiv.org/abs/2509.23143)
*Charles L. Wang*

Main category: cs.AI

TL;DR: MathBode: 动态诊断大型语言模型 (LLM) 中的数学推理能力，通过正弦方式驱动参数，观察模型输出和精确解的一阶谐波响应。


<details>
  <summary>Details</summary>
Motivation: 传统的一次性准确率评估无法充分揭示LLM在数学推理中的动态特性。

Method: 将参数化问题视为系统，用正弦波驱动单个参数，拟合模型输出和精确解的一阶谐波响应，得到可解释的、频率解析的指标（增益和相位），形成Bode图风格的指纹。

Result: 在五个闭式问题族上，揭示了系统性的低通行为和不断增长的相位滞后，而这些现象是传统准确率评估无法捕捉的。通过与符号基线的比较，区分了前沿模型和中等模型在动态特性上的差异。

Conclusion: MathBode提供了一个紧凑、可复现的协议，可以补充标准基准，并提供可操作的推理保真度和一致性测量。数据集和代码已开源。

Abstract: This paper presents MathBode, a dynamic diagnostic for mathematical reasoning
in large language models (LLMs). Instead of one-shot accuracy, MathBode treats
each parametric problem as a system: we drive a single parameter sinusoidally
and fit first-harmonic responses of model outputs and exact solutions. This
yields interpretable, frequency-resolved metrics -- gain (amplitude tracking)
and phase (lag) -- that form Bode-style fingerprints. Across five closed-form
families (linear solve, ratio/saturation, compound interest, 2x2 linear
systems, similar triangles), the diagnostic surfaces systematic low-pass
behavior and growing phase lag that accuracy alone obscures. We compare several
models against a symbolic baseline that calibrates the instrument ($G \approx
1$, $\phi \approx 0$). Results separate frontier from mid-tier models on
dynamics, providing a compact, reproducible protocol that complements standard
benchmarks with actionable measurements of reasoning fidelity and consistency.
We open-source the dataset and code to enable further research and adoption.

</details>


### [75] [Coordination Requires Simplification: Thermodynamic Bounds on Multi-Objective Compromise in Natural and Artificial Intelligence](https://arxiv.org/abs/2509.23144)
*Atma Anand*

Main category: cs.AI

TL;DR: 协调系统面临热力学约束，最大效用解更注重可发现性而非准确性。


<details>
  <summary>Details</summary>
Motivation: 研究跨多个智能体和目标的协调系统中的基本热力学约束。

Method: 推导了精度为 $\varepsilon$ 的协调协议的信息论最小描述长度的缩放比例。

Result: 发现协调协议的最小描述长度与智能体数量、目标冲突程度和内部模型复杂度有关，并揭示了协调动态如何改变环境以及优化如何在层级间转移。还发现从已建立的焦点转移需要重新协调，从而导致持久的亚稳态和滞后现象。

Conclusion: 提出了热力学协调理论（TCT），表明协调需要 радикальный 信息损失，并解释了多目标梯度下降中的无限循环和大型语言模型中的对齐伪造现象。

Abstract: Information-processing systems coordinating across multiple agents and
objectives face fundamental thermodynamic constraints. We show that solutions
with maximum utility to act as coordination focal points have much higher
selection pressure for being findable across agents rather than accuracy. We
derive that the information-theoretic minimum description length of
coordination protocols to precision $\varepsilon$ scales as $L(P)\geq NK\log_2
K+N^2d^2\log (1/\varepsilon)$ for $N$ agents with $d$ potentially conflicting
objectives and internal model complexity $K$. This scaling forces progressive
simplification, with coordination dynamics changing the environment itself and
shifting optimization across hierarchical levels. Moving from established focal
points requires re-coordination, creating persistent metastable states and
hysteresis until significant environmental shifts trigger phase transitions
through spontaneous symmetry breaking. We operationally define coordination
temperature to predict critical phenomena and estimate coordination work costs,
identifying measurable signatures across systems from neural networks to
restaurant bills to bureaucracies. Extending the topological version of Arrow's
theorem on the impossibility of consistent preference aggregation, we find it
recursively binds whenever preferences are combined. This potentially explains
the indefinite cycling in multi-objective gradient descent and alignment faking
in Large Language Models trained with reinforcement learning with human
feedback. We term this framework Thermodynamic Coordination Theory (TCT), which
demonstrates that coordination requires radical information loss.

</details>


### [76] [AI-Enhanced Distributed Channel Access for Collision Avoidance in Future Wi-Fi 8](https://arxiv.org/abs/2509.23154)
*Jinzhe Pan,Jingqing Wang,Yuehui Ouyang,Wenchi Cheng,Wei Zhang*

Main category: cs.AI

TL;DR: 提出了一种基于多智能体强化学习的信道接入机制，旨在解决传统Wi-Fi系统在密集部署中的碰撞问题和公平性挑战。


<details>
  <summary>Details</summary>
Motivation: 当前Wi-Fi系统依赖的二进制指数退避算法在密集部署中碰撞解决效果不佳，且由于内在随机性存在持续的公平性挑战。新兴应用对无线设备和严格的可靠性要求不断增长，需要从根本上改进免许可频段的分布式信道接入机制。

Method: 1. 开发了一种动态退避选择机制，通过访问延迟事件适应实时信道条件，同时与传统CSMA/CA操作完全兼容。2. 引入了与增强型分布式信道接入（EDCA）原则对齐的公平性量化指标，以确保公平的介质访问机会。3. 提出了一种集中训练分散执行（CTDE）架构，该架构结合了邻域活动模式作为观察输入，并通过约束多智能体近端策略优化（MAPPO）进行优化，以共同最小化冲突并保证公平性。

Result: 实验结果表明，该解决方案显著降低了与传统BEB相比的碰撞概率，同时保留了与商用Wi-Fi设备的向后兼容性。所提出的公平性指标有效地消除了异构场景中的资源匮乏风险。

Conclusion: 该论文提出的多智能体强化学习框架能够有效解决传统Wi-Fi系统在密集部署中的碰撞问题和公平性挑战，并具有良好的向后兼容性。

Abstract: The exponential growth of wireless devices and stringent reliability
requirements of emerging applications demand fundamental improvements in
distributed channel access mechanisms for unlicensed bands. Current Wi-Fi
systems, which rely on binary exponential backoff (BEB), suffer from suboptimal
collision resolution in dense deployments and persistent fairness challenges
due to inherent randomness. This paper introduces a multi-agent reinforcement
learning framework that integrates artificial intelligence (AI) optimization
with legacy device coexistence. We first develop a dynamic backoff selection
mechanism that adapts to real-time channel conditions through access deferral
events while maintaining full compatibility with conventional CSMA/CA
operations. Second, we introduce a fairness quantification metric aligned with
enhanced distributed channel access (EDCA) principles to ensure equitable
medium access opportunities. Finally, we propose a centralized training
decentralized execution (CTDE) architecture incorporating neighborhood activity
patterns as observational inputs, optimized via constrained multi-agent
proximal policy optimization (MAPPO) to jointly minimize collisions and
guarantee fairness. Experimental results demonstrate that our solution
significantly reduces collision probability compared to conventional BEB while
preserving backward compatibility with commercial Wi-Fi devices. The proposed
fairness metric effectively eliminates starvation risks in heterogeneous
scenarios.

</details>


### [77] [Limit Analysis for Symbolic Multi-step Reasoning Tasks with Information Propagation Rules Based on Transformers](https://arxiv.org/abs/2509.23178)
*Tian Qin,Yuhan Chen,Zhiwei Wang,Zhi-Qin John Xu*

Main category: cs.AI

TL;DR: 本文研究了Transformer的推理能力。


<details>
  <summary>Details</summary>
Motivation: Transformer能够执行推理任务，但其内在机制尚不清楚。

Method: 本文提出了一组基于Transformer的信息传播规则，并利用符号推理任务从理论上分析了极限推理步骤。

Result: 对于具有L个注意力层的模型，单次通过的极限推理步骤的数量在O(3^{L-1})和O(2^{L-1})之间。

Conclusion: 本文表明Transformer具有一定的推理能力，并给出了推理步骤的理论上限。

Abstract: Transformers are able to perform reasoning tasks, however the intrinsic
mechanism remains widely open. In this paper we propose a set of information
propagation rules based on Transformers and utilize symbolic reasoning tasks to
theoretically analyze the limit reasoning steps. We show that the limit number
of reasoning steps is between $O(3^{L-1})$ and $O(2^{L-1})$ for a model with
$L$ attention layers in a single-pass.

</details>


### [78] [Understanding and Enhancing the Planning Capability of Language Models via Multi-Token Prediction](https://arxiv.org/abs/2509.23186)
*Qimin Zhong,Hao Liao,Siwei Wang,Mingyang Zhou,Xiaoqun Wu,Rui Mao,Wei Chen*

Main category: cs.AI

TL;DR: 大型语言模型在学习传递关系方面存在困难，这对于复杂规划至关重要。本文研究了多令牌预测（MTP）范式及其对传递关系学习的影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在各种任务中表现出色，但在学习传递关系方面仍然存在困难，而传递关系是复杂规划的基石。

Method: 本文使用具有共享输出头和转移层的Transformer架构，从理论上分析了MTP范式。此外，提出了两种策略来增强转移层和整体学习质量：Next-Token Injection (NTI) 和基于Transformer的转移层。

Result: 在合成图和Blocksworld规划基准上的实验验证了理论发现，并表明改进显着提高了模型的路径规划能力。

Conclusion: 这些发现加深了我们对具有MTP的Transformer如何在复杂规划任务中学习的理解，并提供了克服传递性瓶颈的实用策略，为结构感知和通用规划模型铺平了道路。

Abstract: Large Language Models (LLMs) have achieved impressive performance across
diverse tasks but continue to struggle with learning transitive relations, a
cornerstone for complex planning. To address this issue, we investigate the
Multi-Token Prediction (MTP) paradigm and its impact to transitive relation
learning. We theoretically analyze the MTP paradigm using a Transformer
architecture composed of a shared output head and a transfer layer. Our
analysis reveals that the transfer layer gradually learns the multi-step
adjacency information, which in turn enables the backbone model to capture
unobserved transitive reachability relations beyond those directly present in
the training data, albeit with some inevitable noise in adjacency estimation.
Building on this foundation, we propose two strategies to enhance the transfer
layer and overall learning quality: Next-Token Injection (NTI) and a
Transformer-based transfer layer. Our experiments on both synthetic graphs and
the Blocksworld planning benchmark validate our theoretical findings and
demonstrate that the improvements significantly enhance the model's
path-planning capability. These findings deepen our understanding of how
Transformers with MTP learn in complex planning tasks, and provide practical
strategies to overcome the transitivity bottleneck, paving the way toward
structurally aware and general-purpose planning models.

</details>


### [79] [AutoEP: LLMs-Driven Automation of Hyperparameter Evolution for Metaheuristic Algorithms](https://arxiv.org/abs/2509.23189)
*Zhenxing Xu,Yizhe Zhang,Weidong Bao,Hao Wang,Ming Chen,Haoran Ye,Wenzheng Jiang,Hui Yan,Ji Wang*

Main category: cs.AI

TL;DR: AutoEP利用大型语言模型(llm)作为零样本推理引擎进行算法控制，无需训练。


<details>
  <summary>Details</summary>
Motivation: 计算智能中动态配置算法超参数是一个根本挑战，现有的基于学习的方法样本复杂度高，泛化性差。

Method: AutoEP框架结合在线探索性景观分析(ELA)模块和多llm推理链，前者提供实时搜索动态的量化反馈，后者解释反馈以生成自适应超参数策略。

Result: AutoEP在各种组合优化基准测试中始终优于最先进的调优器，包括神经进化和其他基于llm的方法。Qwen3-30B等开源模型可以与GPT-4的性能相匹配。

Conclusion: AutoEP为自动化超参数设计提供了一个强大且易于访问的新范例。

Abstract: Dynamically configuring algorithm hyperparameters is a fundamental challenge
in computational intelligence. While learning-based methods offer automation,
they suffer from prohibitive sample complexity and poor generalization. We
introduce AutoEP, a novel framework that bypasses training entirely by
leveraging Large Language Models (LLMs) as zero-shot reasoning engines for
algorithm control. AutoEP's core innovation lies in a tight synergy between two
components: (1) an online Exploratory Landscape Analysis (ELA) module that
provides real-time, quantitative feedback on the search dynamics, and (2) a
multi-LLM reasoning chain that interprets this feedback to generate adaptive
hyperparameter strategies. This approach grounds high-level reasoning in
empirical data, mitigating hallucination. Evaluated on three distinct
metaheuristics across diverse combinatorial optimization benchmarks, AutoEP
consistently outperforms state-of-the-art tuners, including neural evolution
and other LLM-based methods. Notably, our framework enables open-source models
like Qwen3-30B to match the performance of GPT-4, demonstrating a powerful and
accessible new paradigm for automated hyperparameter design. Our code is
available at https://anonymous.4open.science/r/AutoEP-3E11

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [80] [PARROT: A Benchmark for Evaluating LLMs in Cross-System SQL Translation](https://arxiv.org/abs/2509.23338)
*Wei Zhou,Guoliang Li,Haoyu Wang,Yuxing Han,Xufei Wu,Fan Wu,Xuanhe Zhou*

Main category: cs.DB

TL;DR: PARROT: A new benchmark for cross-system SQL translation, which is important but underexplored.


<details>
  <summary>Details</summary>
Motivation: Existing SQL benchmarks are not well-suited for SQL-to-SQL evaluation, which (1) focus on a limited set of database systems and (2) cannot capture many system-specific SQL dialects.

Method: Introduce PARROT, a Practical And Realistic BenchmaRk for CrOss-System SQL Translation. PARROT comprises 598 translation pairs from 38 open-source benchmarks and real-world business services, specifically prepared to challenge system-specific SQL understanding.

Result: LLMS achieve lower than 38.53% accuracy on average. Includes PARROT-Diverse with 28,003 translations and PARROT-Simple with 5,306 representative samples, covering 22 production-grade database systems.

Conclusion: Release a public leaderboard and source code at: https://code4db.github.io/parrot-bench/ to promote future research.

Abstract: Large language models (LLMS) have shown increasing effectiveness in
Text-to-SQL tasks. However, another closely related problem, Cross-System SQL
Translation (a.k.a., SQL-to-SQL), which adapts a query written for one database
system (e.g., MySQL) into its equivalent one for another system (e.g.,
ClickHouse), is of great practical importance but remains underexplored.
Existing SQL benchmarks are not well-suited for SQL-to-SQL evaluation, which
(1) focus on a limited set of database systems (often just SQLite) and (2)
cannot capture many system-specific SQL dialects (e.g., customized functions,
data types, and syntax rules). Thus, in this paper, we introduce PARROT, a
Practical And Realistic BenchmaRk for CrOss-System SQL Translation. PARROT
comprises 598 translation pairs from 38 open-source benchmarks and real-world
business services, specifically prepared to challenge system-specific SQL
understanding (e.g., LLMS achieve lower than 38.53% accuracy on average). We
also provide multiple benchmark variants, including PARROT-Diverse with 28,003
translations (for extensive syntax testing) and PARROT-Simple with 5,306
representative samples (for focused stress testing), covering 22
production-grade database systems. To promote future research, we release a
public leaderboard and source code at: https://code4db.github.io/parrot-bench/.

</details>


### [81] [ML-Asset Management: Curation, Discovery, and Utilization](https://arxiv.org/abs/2509.23577)
*Mengying Wang,Moming Duan,Yicong Huang,Chen Li,Bingsheng He,Yinghui Wu*

Main category: cs.DB

TL;DR: 本教程全面概述了 ML 资产管理活动，包括管理、发现和利用。通过系统演示，本教程为研究人员和从业人员提供了可操作的见解和实用工具，以在现实世界和特定领域环境中推进 ML 资产管理。


<details>
  <summary>Details</summary>
Motivation: 由于文档分散、存储孤岛、许可不一致以及缺乏统一的发现机制，ML 资产经常未得到充分利用，因此 ML 资产管理是一项紧迫的挑战。

Method: 本文对 ML 资产进行了分类，并提出了主要的管理问题，调查了最先进的技术，并确定了每个阶段的新兴机会。此外，本文还重点介绍了与可扩展性、沿袭和统一索引相关的系统级挑战。

Result: 通过对系统的现场演示，为研究人员和从业人员提供了可操作的见解和实用工具。

Conclusion: 本教程为研究人员和从业人员提供了在实际和特定领域环境中推进 ML 资产管理所需的知识和工具。

Abstract: Machine learning (ML) assets, such as models, datasets, and metadata, are
central to modern ML workflows. Despite their explosive growth in practice,
these assets are often underutilized due to fragmented documentation, siloed
storage, inconsistent licensing, and lack of unified discovery mechanisms,
making ML-asset management an urgent challenge. This tutorial offers a
comprehensive overview of ML-asset management activities across its lifecycle,
including curation, discovery, and utilization. We provide a categorization of
ML assets, and major management issues, survey state-of-the-art techniques, and
identify emerging opportunities at each stage. We further highlight
system-level challenges related to scalability, lineage, and unified indexing.
Through live demonstrations of systems, this tutorial equips both researchers
and practitioners with actionable insights and practical tools for advancing
ML-asset management in real-world and domain-specific settings.

</details>


### [82] [NeuSO: Neural Optimizer for Subgraph Queries](https://arxiv.org/abs/2509.23775)
*Linglin Yang,Lei Zou,Chunshan Zhao*

Main category: cs.DB

TL;DR: 这篇论文提出了一种新的基于学习的子图查询优化器 NeuSO，它通过多任务框架训练查询图编码器和估计器，以估计子查询的基数和执行成本，从而生成高质量的执行计划。


<details>
  <summary>Details</summary>
Motivation: 现有的子图查询方法依赖于启发式顶点匹配排序，这可能会降低某些查询的枚举性能。虽然基于学习的优化器在关系数据库中受到了关注，但由于图数据的异构性和模式灵活性，以及子图查询中涉及的大量连接，它们不能直接应用于子图查询。

Method: 该论文提出了一种新的基于学习的子图查询优化器 NeuSO，它具有高效的查询图编码器和估计器，这些编码器和估计器使用多任务框架进行训练，以估计子查询的基数和执行成本。基于这些估计，NeuSO 采用自顶向下的计划枚举器来生成高质量的子图查询执行计划。

Result: 在多个数据集上的大量实验表明，NeuSO 在性能和效率方面均优于现有的子图查询排序方法。

Conclusion: NeuSO 是一种有效的子图查询优化器，它可以通过学习来提高查询性能和效率。

Abstract: Subgraph query is a critical task in graph analysis with a wide range of
applications across various domains. Most existing methods rely on heuristic
vertex matching orderings, which may significantly degrade enumeration
performance for certain queries. While learning-based optimizers have recently
gained attention in the context of relational databases, they cannot be
directly applied to subgraph queries due to the heterogeneous and
schema-flexible nature of graph data, as well as the large number of joins
involved in subgraph queries. These complexities often leads to inefficient
online performance, making such approaches impractical for real-world graph
database systems. To address this challenge, we propose NeuSO, a novel
learning-based optimizer for subgraph queries that achieves both high accuracy
and efficiency. NeuSO features an efficient query graph encoder and an
estimator which are trained using a multi-task framework to estimate both
subquery cardinality and execution cost. Based on these estimates, NeuSO
employs a top-down plan enumerator to generate high-quality execution plans for
subgraph queries. Extensive experiments on multiple datasets demonstrate that
NeuSO outperforms existing subgraph query ordering approaches in both
performance and efficiency.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [83] [How good are LLMs at Retrieving Documents in a Specific Domain?](https://arxiv.org/abs/2509.22658)
*Nafis Tanveer Islam,Zhiming Zhao*

Main category: cs.IR

TL;DR: 传统搜索引擎依赖关键词检索，但在理解用户意图和处理复杂查询方面存在不足。本文提出了一种自动方法来管理特定领域的评估数据集，并结合大型语言模型（LLM）驱动的检索增强生成（RAG）方法，以提高环境领域数据的检索质量。


<details>
  <summary>Details</summary>
Motivation: 传统搜索引擎在处理复杂查询和理解用户意图方面存在局限性，特别是在环境和地球科学等领域的研究基础设施（RI）中，面临着数据量大和查询意图多样化的挑战。

Method: 提出了一种自动方法来管理特定领域的评估数据集，并结合了基于大型语言模型（LLM）的检索增强生成（RAG）方法。

Result: 定量和定性分析表明，与基于Elasticsearch的系统相比，基于LLM的信息检索系统在理解具有多个意图的查询时，能够返回更高精度的结果。

Conclusion: 基于LLM的RAG方法可以有效提高环境领域数据的检索质量，尤其是在处理复杂查询和理解用户意图方面优于传统方法。

Abstract: Classical search engines using indexing methods in data infrastructures
primarily allow keyword-based queries to retrieve content. While these
indexing-based methods are highly scalable and efficient, due to a lack of an
appropriate evaluation dataset and a limited understanding of semantics, they
often fail to capture the user's intent and generate incomplete responses
during evaluation. This problem also extends to domain-specific search systems
that utilize a Knowledge Base (KB) to access data from various research
infrastructures. Research infrastructures (RIs) from the environmental and
earth science domain, which encompass the study of ecosystems, biodiversity,
oceanography, and climate change, generate, share, and reuse large volumes of
data. While there are attempts to provide a centralized search service using
Elasticsearch as a knowledge base, they also face similar challenges in
understanding queries with multiple intents. To address these challenges, we
proposed an automated method to curate a domain-specific evaluation dataset to
analyze the capability of a search system. Furthermore, we incorporate the
Retrieval of Augmented Generation (RAG), powered by Large Language Models
(LLMs), for high-quality retrieval of environmental domain data using natural
language queries. Our quantitative and qualitative analysis of the evaluation
dataset shows that LLM-based systems for information retrieval return results
with higher precision when understanding queries with multiple intents,
compared to Elasticsearch-based systems.

</details>


### [84] [Federated Consistency- and Complementarity-aware Consensus-enhanced Recommendation](https://arxiv.org/abs/2509.22659)
*Yunqi Mi,Boyang Yan,Guoshuai Zhao,Jialie Shen,Xueming Qian*

Main category: cs.IR

TL;DR: 提出了一种名为Fed3CR的个性化联邦推荐方法，通过自适应共识增强（ACE）和一致性与互补性感知优化（C2O）策略，提升共识利用率和解耦质量，从而在保护隐私的同时，改善推荐效果。


<details>
  <summary>Details</summary>
Motivation: 解决联邦推荐系统中客户端之间统计异构性挑战，并提高个性化推荐效果。现有方法通过将物品嵌入解耦为服务器端和客户端特定视图来缓解异构性，但大规模客户端交互数据的稀疏性和高度一致性导致共识退化和解耦不足。

Method: 提出Fed3CR方法，包括ACE策略用于学习全局和客户端特定物品嵌入之间的关系，自适应地增强共识中的特定信息；C2O策略用于学习更有效和互补的表示。

Result: 在四个真实世界数据集上的大量实验表明，Fed3CR具有优越的性能。

Conclusion: Fed3CR是一种即插即用的方法，可以与其他FedRec方法集成以提高其性能。

Abstract: Personalized federated recommendation system (FedRec) has gained significant
attention for its ability to preserve privacy in delivering tailored
recommendations. To alleviate the statistical heterogeneity challenges among
clients and improve personalization, decoupling item embeddings into the server
and client-specific views has become a promising way. Among them, the global
item embedding table serves as a consensus representation that integrates and
reflects the collective patterns across all clients. However, the inherent
sparsity and high uniformity of interaction data from massive-scale clients
results in degraded consensus and insufficient decoupling, reducing consensus's
utility. To this end, we propose a \textbf{Fed}erated \textbf{C}onsistency- and
\textbf{C}omplementarity-aware \textbf{C}onsensus-enhanced
\textbf{R}ecommendation (Fed3CR) method for personalized FedRec. To improve the
efficiency of the utilization of consensus, we propose an \textbf{A}daptive
\textbf{C}onsensus \textbf{E}nhancement (ACE) strategy to learn the
relationship between global and client-specific item embeddings. It enables the
client to adaptively enhance specific information in the consensus,
transforming it into a form that best suits itself. To improve the quality of
decoupling, we propose a \textbf{C}onsistency- and
\textbf{C}omplementarity-aware \textbf{O}ptimization (C2O) strategy, which
helps to learn more effective and complementary representations. Notably, our
proposed Fed3CR is a plug-and-play method, which can be integrated with other
FedRec methods to improve its performance. Extensive experiments on four
real-world datasets represent the superior performance of Fed3CR.

</details>


### [85] [Fairness for niche users and providers: algorithmic choice and profile portability](https://arxiv.org/abs/2509.22660)
*Elizabeth McKinnie,Anas Buhayh,Clement Canel,Robin Burke*

Main category: cs.IR

TL;DR: 本文探讨了算法多元化和用户画像可移植性对推荐系统公平性的影响，通过模拟研究不同策略如何影响消费者和提供者的利益。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在算法干预以提高推荐系统的公平性，而忽略了推荐生态系统本身的结构性变化。本文旨在研究算法多元化（用户可以选择算法）和用户画像可移植性对公平性的影响。

Method: 采用模拟方法，探索用户画像可移植性的不同策略如何与消费者和提供者的公平结果相互作用。

Result: 先前的模拟研究表明，小众消费者和（尤其是）小众提供者受益于算法选择。本文通过模拟进一步探索用户画像可移植性问题。

Conclusion: 通过模拟研究不同策略如何影响消费者和提供者的利益。

Abstract: Ensuring fair outcomes for multiple stakeholders in recommender systems has
been studied mostly in terms of algorithmic interventions: building new models
with better fairness properties, or using reranking to improve outcomes from an
existing algorithm. What has rarely been studied is structural changes in the
recommendation ecosystem itself. Our work explores the fairness impact of
algorithmic pluralism, the idea that the recommendation algorithm is decoupled
from the platform through which users access content, enabling user choice in
algorithms. Prior work using a simulation approach has shown that niche
consumers and (especially) niche providers benefit from algorithmic choice. In
this paper, we use simulation to explore the question of profile portability,
to understand how different policies regarding the handling of user profiles
interact with fairness outcomes for consumers and providers.

</details>


### [86] [Next Point-of-interest (POI) Recommendation Model Based on Multi-modal Spatio-temporal Context Feature Embedding](https://arxiv.org/abs/2509.22661)
*Lingyu Zhang,Guobin Wu,Yan Wang,Pengfei Xu,Jian Liang,Xuan Song,Yunhai Wang*

Main category: cs.IR

TL;DR: 提出了一种基于多模态时空上下文特征嵌入的POI推荐模型，该模型考虑了用户长期偏好信息和关键时空上下文信息。


<details>
  <summary>Details</summary>
Motivation: 传统POI预测模型主要依赖于短期交通序列信息，忽略了长期和短期偏好数据以及用户行为中关键的时空上下文特征。

Method: 通过时空特征处理、多模态嵌入和自注意力聚合等模块，从交通数据中提取长期偏好特征和关键时空上下文特征，并使用加权融合方法动态调整长期和短期特征的权重，最后使用注意力机制匹配融合特征。

Result: 在多个交通数据集上进行实验验证，结果表明，结合多种特征的POI预测模型比现有的SOTA模型和方法具有更高的预测精度。

Conclusion: 该论文提出的POI推荐模型能够更准确地预测用户的下一个兴趣点。

Abstract: The next Point-of-interest (POI) recommendation is mainly based on sequential
traffic information to predict the user's next boarding point location. This is
a highly regarded and widely applied research task in the field of intelligent
transportation, and there have been many research results to date. Traditional
POI prediction models primarily rely on short-term traffic sequence
information, often neglecting both long-term and short-term preference data, as
well as crucial spatiotemporal context features in user behavior. To address
this issue, this paper introduces user long-term preference information and key
spatiotemporal context information, and proposes a POI recommendation model
based on multimodal spatiotemporal context feature embedding. The model
extracts long-term preference features and key spatiotemporal context features
from traffic data through modules such as spatiotemporal feature processing,
multimodal embedding, and self-attention aggregation. It then uses a weighted
fusion method to dynamically adjust the weights of long-term and short-term
features based on users' historical behavior patterns and the current context.
Finally, the fused features are matched using attention, and the probability of
each location candidate becoming the next location is calculated. This paper
conducts experimental verification on multiple transportation datasets, and the
results show that the POI prediction model combining multiple types of features
has higher prediction accuracy than existing SOTA models and methods.

</details>


### [87] [MTRec: Learning to Align with User Preferences via Mental Reward Models](https://arxiv.org/abs/2509.22807)
*Mengchen Zhao,Yifan Gao,Yaqing Hou,Xiangyang Li,Pengjie Gu,Zhenhua Dong,Ruiming Tang,Yi Cai*

Main category: cs.IR

TL;DR: 提出了一种新的序列推荐框架，通过挖掘用户对推荐项目的内在满意度来与真实用户偏好保持一致。


<details>
  <summary>Details</summary>
Motivation: 由于显性反馈通常难以获得，推荐模型主要使用隐性用户反馈进行训练。然而，隐性反馈并不总是反映用户的真实偏好，可能导致推荐系统被误导。

Method: 引入心理奖励模型来量化用户满意度，并提出一种分布式逆强化学习方法来学习它。然后，学习到的心理奖励模型被用来指导推荐模型，使其更好地与用户的真实偏好保持一致。

Result: 实验表明，MTRec 为各种推荐模型带来了显著的改进。在工业短视频平台上部署 MTRec 后，平均用户观看时间增加了 7%。

Conclusion: MTRec 可以有效提高推荐模型的性能，使其更好地与用户的真实偏好保持一致。

Abstract: Recommendation models are predominantly trained using implicit user feedback,
since explicit feedback is often costly to obtain. However, implicit feedback,
such as clicks, does not always reflect users' real preferences. For example, a
user might click on a news article because of its attractive headline, but end
up feeling uncomfortable after reading the content. In the absence of explicit
feedback, such erroneous implicit signals may severely mislead recommender
systems. In this paper, we propose MTRec, a novel sequential recommendation
framework designed to align with real user preferences by uncovering their
internal satisfaction on recommended items. Specifically, we introduce a mental
reward model to quantify user satisfaction and propose a distributional inverse
reinforcement learning approach to learn it. The learned mental reward model is
then used to guide recommendation models to better align with users' real
preferences. Our experiments show that MTRec brings significant improvements to
a variety of recommendation models. We also deploy MTRec on an industrial short
video platform and observe a 7 percent increase in average user viewing time.

</details>


### [88] [WARBERT: A Hierarchical BERT-based Model for Web API Recommendation](https://arxiv.org/abs/2509.23175)
*Zishuo Xu,Yuhong Gu,Dezhong Yao*

Main category: cs.IR

TL;DR: 提出WARBERT，一个基于分层BERT的Web API推荐模型，以解决现有Web API推荐方法的语义模糊、缺乏细节比较和时间效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的Web API推荐方法存在语义模糊、缺乏细节比较和时间效率低下的问题。

Method: WARBERT利用双组件特征融合和注意力比较来提取API和mashup描述的精确语义表示。它由WARBERT(R)和WARBERT(M)两个主要组件组成，分别用于推荐和匹配。WARBERT(R)还包含mashup类别判断的辅助任务。

Result: 在ProgrammableWeb数据集上的实验结果表明，WARBERT优于大多数现有解决方案，并且与模型MTFM相比，最高可提高11.7%。

Conclusion: WARBERT在准确性和效率方面都有显著提高。

Abstract: With the emergence of Web 2.0 and microservices architecture, the number of
Web APIs has increased dramatically, further intensifying the demand for
efficient Web API recommendation. Existing solutions typically fall into two
categories: recommendation-type methods, which treat each API as a label for
classification, and match-type methods, which focus on matching mashups through
API retrieval. However, three critical challenges persist: 1) the semantic
ambiguities in comparing API and mashup descriptions, 2) the lack of detailed
comparisons between the individual API and the mashup in recommendation-type
methods, and 3) time inefficiencies for API retrieval in match-type methods. To
address these challenges, we propose WARBERT, a hierarchical BERT-based model
for Web API recommendation. WARBERT leverages dual-component feature fusion and
attention comparison to extract precise semantic representations of API and
mashup descriptions. WARBERT consists of two main components: WARBERT(R) for
Recommendation and WARBERT(M) for Matching. Specifically, WAR-BERT(R) serves as
an initial filter, narrowing down the candidate APIs, while WARBERT(M) refines
the matching process by calculating the similarity between candidate APIs and
mashup. The final likelihood of a mashup being matched with an API is
determined by combining the predictions from WARBERT(R) and WARBERT(M).
Additionally, WARBERT(R) incorporates an auxiliary task of mashup category
judgment, which enhances its effectiveness in candidate selection. Experimental
results on the ProgrammableWeb dataset demonstrate that WARBERT outperforms
most existing solutions and achieves improvements of up to 11.7% compared to
the model MTFM (Multi-Task Fusion Model), delivering significant enhancements
in accuracy and effiency.

</details>


### [89] [From Past To Path: Masked History Learning for Next-Item Prediction in Generative Recommendation](https://arxiv.org/abs/2509.23649)
*KaiWen Wei,Kejun He,Xiaomian Kang,Jie Zhang,Yuming Yang,Jiang Zhong,He Bai,Junnan Zhu*

Main category: cs.IR

TL;DR: 提出了一种新的生成式推荐训练框架，通过预测被mask掉的历史物品来更好地理解用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式推荐模型依赖于自回归训练，忽略了用户交互历史的内部结构，未能理解潜在意图。

Method: 提出了Masked History Learning (MHL) 框架，通过重构被mask掉的历史物品来学习用户历史的深层理解。使用了entropy-guided masking策略和 curriculum learning scheduler。

Result: 在三个公共数据集上的实验表明，该方法显著优于state-of-the-art的生成模型。

Conclusion: 对过去行为的全面理解对于准确预测用户未来的行为至关重要。

Abstract: Generative recommendation, which directly generates item identifiers, has
emerged as a promising paradigm for recommendation systems. However, its
potential is fundamentally constrained by the reliance on purely autoregressive
training. This approach focuses solely on predicting the next item while
ignoring the rich internal structure of a user's interaction history, thus
failing to grasp the underlying intent. To address this limitation, we propose
Masked History Learning (MHL), a novel training framework that shifts the
objective from simple next-step prediction to deep comprehension of history.
MHL augments the standard autoregressive objective with an auxiliary task of
reconstructing masked historical items, compelling the model to understand
``why'' an item path is formed from the user's past behaviors, rather than just
``what'' item comes next. We introduce two key contributions to enhance this
framework: (1) an entropy-guided masking policy that intelligently targets the
most informative historical items for reconstruction, and (2) a curriculum
learning scheduler that progressively transitions from history reconstruction
to future prediction. Experiments on three public datasets show that our method
significantly outperforms state-of-the-art generative models, highlighting that
a comprehensive understanding of the past is crucial for accurately predicting
a user's future path. The code will be released to the public.

</details>


### [90] [Constructing Opera Seria in the Iberian Courts: Metastasian Repertoire for Spain and Portugal](https://arxiv.org/abs/2509.23771)
*Ana Llorens,Alvaro Torrente*

Main category: cs.IR

TL;DR: 本文研究了18世纪伊比利亚半岛对梅塔斯塔西奥作品的接受情况，以及当地宫廷的特殊音乐和社会期待如何影响了为该地区创作的歌剧风格。


<details>
  <summary>Details</summary>
Motivation: 研究18世纪伊比利亚半岛的音乐品味和国际化程度，以及当地宫廷对歌剧风格的独特影响。

Method: 通过统计分析15首专门为马德里和里斯本宫廷剧院创作的歌剧，并与2404首咏叹调的数据进行比较，评估关键、节拍、速度和声乐部分的处理方式。

Result: 量化分析表明，伊比利亚音乐的独特音乐特征部分取决于当地音乐习俗、性别刻板印象和个人特质。

Conclusion: 本文将18世纪伊比利亚音乐的生产和消费置于欧洲正歌剧的背景下，并表明其独特的音乐特征部分取决于当地的音乐习俗。

Abstract: The exceptional reception of Pietro Metastasio's works during the eighteenth
century, all over Europe and in the Iberian Peninsula in particular, is well
documented. Due to that unparalleled success, it is possible to ascertain Spain
and Portugal's participation in international, contemporary tastes and artistic
webs, applicable to both composers and performers. However, this
internationalisation needs to be nuanced, as some characteristics of the
repertoire specifically written for the Peninsula indicate that their court
audiences may have had expectations, both social and strictly musical,
different from those of the public in opera theatres elsewhere in the
continent. In this light, this article investigates in what ways the style of
five composers in the international scene - Perez, Galuppi, Jommelli, Conforto,
and Corselli - varied when commissioned to write opera seria for the Iberian
courts. The statistical analysis of fifteen settings especially written for the
court theatres in Madrid and Lisbon, in comparison to the average data
extracted from a corpus of 2,404 arias from 126 versions of a select number of
Metastasian librettos, allows us to evaluate some particular usages regarding
key, metre, tempo, and treatment of the vocal part. In this manner, through
quantitative analysis, this article places eighteenth-century Iberian music
production and consumption in the context of European opera seria, while
ultimately suggesting that its unique musical characteristics were also partly
dependent on local musical customs, gender stereotypes, and personal
idiosyncrasies alike.

</details>


### [91] [Semantic Representation of Processes with Ontology Design Patterns](https://arxiv.org/abs/2509.23776)
*Ebrahim Norouzi,Sven Hertling,Jörg Waitelonis,Harald Sack*

Main category: cs.IR

TL;DR: 这篇论文调查了与科学工作流程和工程过程建模相关的本体，并识别了嵌入在其结构中的隐式设计模式。


<details>
  <summary>Details</summary>
Motivation: 材料科学工程中，工作流程和过程的表示至关重要，实验和计算的可重复性取决于结构化和语义连贯的过程模型。虽然已经为过程建模开发了许多本体，但它们通常很复杂且难以重用。

Method: 该研究调查了与科学工作流程和工程过程建模相关的本体，并识别了嵌入在其结构中的隐式设计模式。此外，我们提出了一种从现有本体自动提取设计模式的基线方法，并根据策划的地面实况模式评估该方法。

Result: 我们评估了这些本体满足材料科学中过程表示关键要求的能力。所有与这项工作相关的资源，包括提取的模式和提取工作流程，都在公共 GitHub 存储库中公开发布。

Conclusion: 论文研究了材料科学工程中工作流程和过程表示的问题，通过调查相关本体并提取设计模式，为解决过程建模的复杂性和可重用性问题提供了方法，并将研究成果公开。

Abstract: The representation of workflows and processes is essential in materials
science engineering, where experimental and computational reproducibility
depend on structured and semantically coherent process models. Although
numerous ontologies have been developed for process modeling, they are often
complex and challenging to reuse. Ontology Design Patterns (ODPs) offer modular
and reusable modeling solutions to recurring problems; however, these patterns
are frequently neither explicitly published nor documented in a manner
accessible to domain experts. This study surveys ontologies relevant to
scientific workflows and engineering process modeling and identifies implicit
design patterns embedded within their structures. We evaluate the capacity of
these ontologies to fulfill key requirements for process representation in
materials science. Furthermore, we propose a baseline method for the automatic
extraction of design patterns from existing ontologies and assess the approach
against curated ground truth patterns. All resources associated with this work,
including the extracted patterns and the extraction workflow, are made openly
available in a public GitHub repository.

</details>


### [92] [GSID: Generative Semantic Indexing for E-Commerce Product Understanding](https://arxiv.org/abs/2509.23860)
*Haiyang Yang,Qinye Xie,Qingheng Zhang,Liyu Chen,Huike Zou,Chengbao Lian,Shuguang Han,Fei Huang,Jufeng Chen,Bo Zheng*

Main category: cs.IR

TL;DR: 提出了GSID，一种数据驱动的方法来生成产品结构化表示。


<details>
  <summary>Details</summary>
Motivation: 当前大多数产品信息基于手动管理的产品类别和属性进行组织，这通常不能充分覆盖长尾产品，并且与买家偏好不符。

Method: GSID包括两个关键组件：(1)在非结构化产品元数据上进行预训练，以学习领域内语义嵌入，(2)生成针对下游以产品为中心的应用程序量身定制的更有效的语义代码。

Result: 通过广泛的实验验证了GSID的有效性，并且已成功部署在实际的电子商务平台上，在产品理解和其他下游任务上取得了可喜的成果。

Conclusion: GSID是一种有效的方法，可以生成产品结构化表示，并在实际的电子商务平台上取得了可喜的成果。

Abstract: Structured representation of product information is a major bottleneck for
the efficiency of e-commerce platforms, especially in second-hand ecommerce
platforms. Currently, most product information are organized based on manually
curated product categories and attributes, which often fail to adequately cover
long-tail products and do not align well with buyer preference. To address
these problems, we propose \textbf{G}enerative \textbf{S}emantic
\textbf{I}n\textbf{D}exings (GSID), a data-driven approach to generate product
structured representations. GSID consists of two key components: (1)
Pre-training on unstructured product metadata to learn in-domain semantic
embeddings, and (2) Generating more effective semantic codes tailored for
downstream product-centric applications. Extensive experiments are conducted to
validate the effectiveness of GSID, and it has been successfully deployed on
the real-world e-commerce platform, achieving promising results on product
understanding and other downstream tasks.

</details>


### [93] [Investigating Multi-layer Representations for Dense Passage Retrieval](https://arxiv.org/abs/2509.23861)
*Zhongbin Xie,Thomas Lukasiewicz*

Main category: cs.IR

TL;DR: 本文提出了一种多层表示（MLR）方法，利用预训练语言模型不同层的表示来构成文档的表示。


<details>
  <summary>Details</summary>
Motivation: 现有密集检索模型通常只使用文档编码器最后一层的向量来表示文档，忽略了不同层包含不同语言知识的事实。

Method: 研究了不同层的表示如何影响MLR在多向量检索设置下的性能，并提出了利用池化策略将多向量模型简化为单向量模型以提高检索效率。

Result: 实验表明，在单向量检索设置下，MLR优于双编码器、ME-BERT和ColBERT，并且可以与其他先进的训练技术（如面向检索的预训练和困难负例挖掘）协同工作。

Conclusion: MLR方法能够有效提升文档表示的质量和检索性能。

Abstract: Dense retrieval models usually adopt vectors from the last hidden layer of
the document encoder to represent a document, which is in contrast to the fact
that representations in different layers of a pre-trained language model
usually contain different kinds of linguistic knowledge, and behave differently
during fine-tuning. Therefore, we propose to investigate utilizing
representations from multiple encoder layers to make up the representation of a
document, which we denote Multi-layer Representations (MLR). We first
investigate how representations in different layers affect MLR's performance
under the multi-vector retrieval setting, and then propose to leverage pooling
strategies to reduce multi-vector models to single-vector ones to improve
retrieval efficiency. Experiments demonstrate the effectiveness of MLR over
dual encoder, ME-BERT and ColBERT in the single-vector retrieval setting, as
well as demonstrate that it works well with other advanced training techniques
such as retrieval-oriented pre-training and hard negative mining.

</details>


### [94] [Multi-Value-Product Retrieval-Augmented Generation for Industrial Product Attribute Value Identification](https://arxiv.org/abs/2509.23874)
*Huike Zou,Haiyang Yang,Yindu Su,Liyu Chen,Chengbao Lian,Qingheng Zhang,Shuguang Han,Jufeng Chen*

Main category: cs.IR

TL;DR: 提出了一种新的产品属性值识别（PAVI）方法，称为多值产品检索增强生成（MVP-RAG）。


<details>
  <summary>Details</summary>
Motivation: 现有的PAVI方法面临着诸如级联错误、无法处理超出分布（OOD）的属性值以及缺乏泛化能力等关键挑战。

Method: MVP-RAG将PAVI定义为检索-生成任务，其中产品标题描述作为查询，产品和属性值作为语料库。它首先检索相同类别的相似产品和候选属性值，然后生成标准化属性值。

Result: 大量的实验结果表明，MVP-RAG的性能优于最先进的基线。

Conclusion: MVP-RAG结合了检索、生成和分类范式的优势，有效地解决了现有PAVI方法的局限性，并在实际工业环境中成功部署。

Abstract: Identifying attribute values from product profiles is a key task for
improving product search, recommendation, and business analytics on e-commerce
platforms, which we called Product Attribute Value Identification (PAVI) .
However, existing PAVI methods face critical challenges, such as cascading
errors, inability to handle out-of-distribution (OOD) attribute values, and
lack of generalization capability. To address these limitations, we introduce
Multi-Value-Product Retrieval-Augmented Generation (MVP-RAG), combining the
strengths of retrieval, generation, and classification paradigms. MVP-RAG
defines PAVI as a retrieval-generation task, where the product title
description serves as the query, and products and attribute values act as the
corpus. It first retrieves similar products of the same category and candidate
attribute values, and then generates the standardized attribute values. The key
advantages of this work are: (1) the proposal of a multi-level retrieval
scheme, with products and attribute values as distinct hierarchical levels in
PAVI domain (2) attribute value generation of large language model to
significantly alleviate the OOD problem and (3) its successful deployment in a
real-world industrial environment. Extensive experimental results demonstrate
that MVP-RAG performs better than the state-of-the-art baselines.

</details>


### [95] [Multi-Item-Query Attention for Stable Sequential Recommendation](https://arxiv.org/abs/2509.24424)
*Mingshi Xu,Haoren Zhu,Wilfred Siu Hung Ng*

Main category: cs.IR

TL;DR: 提出了一个多项目查询注意力机制（MIQ-Attn），以提高推荐系统的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 用户互动数据中的固有不稳定性和噪声对序列推荐系统提出了挑战。现有的掩码注意力模型依赖于最近项目的单一查询，对噪声敏感，降低了预测可靠性。

Method: MIQ-Attn从用户互动中构建多个不同的查询向量，有效地减轻噪声并提高一致性。它被设计为可以轻松替代现有的单查询注意力。

Result: 实验表明，MIQ-Attn 显著提高了基准数据集的性能。

Conclusion: MIQ-Attn 可以提高推荐系统的稳定性和准确性。

Abstract: The inherent instability and noise in user interaction data challenge
sequential recommendation systems. Prevailing masked attention models, relying
on a single query from the most recent item, are sensitive to this noise,
reducing prediction reliability. We propose the Multi-Item-Query attention
mechanism (MIQ-Attn) to enhance model stability and accuracy. MIQ-Attn
constructs multiple diverse query vectors from user interactions, effectively
mitigating noise and improving consistency. It is designed for easy adoption as
a drop-in replacement for existing single-query attention. Experiments show
MIQ-Attn significantly improves performance on benchmark datasets.

</details>


### [96] [UniDex: Rethinking Search Inverted Indexing with Unified Semantic Modeling](https://arxiv.org/abs/2509.24632)
*Zan Li,Jiahui Chen,Yuan Chai,Xiaoze Jiang,Xiaohua Qi,Zhiheng Qin,Runbin Zhou,Shun Zuo,Guangchao Hao,Kefeng Wang,Jingshan Lv,Yupeng Huang,Xiao Liang,Han Li*

Main category: cs.IR

TL;DR: 提出了一种新的基于模型的倒排索引方法，称为 UniDex，它使用统一的语义建模来改进检索。


<details>
  <summary>Details</summary>
Motivation: 传统的倒排索引依赖于精确的术语匹配，这限制了系统的泛化能力和检索效果。

Method: UniDex 包含两个关键组件：UniTouch，它将查询和文档映射到语义 ID 以改进检索；UniRank，它采用语义匹配来有效地对结果进行排序。

Result: 在大型工业数据集和真实在线流量评估中，UniDex 显着提高了检索能力。

Conclusion: UniDex 代表了从基于术语的索引到基于模型的索引的范式转变，在快手的短视频搜索系统中得到验证，可有效地为数亿活跃用户提供服务。

Abstract: Inverted indexing has traditionally been a cornerstone of modern search
systems, leveraging exact term matches to determine relevance between queries
and documents. However, this term-based approach often emphasizes surface-level
token overlap, limiting the system's generalization capabilities and retrieval
effectiveness. To address these challenges, we propose UniDex, a novel
model-based method that employs unified semantic modeling to revolutionize
inverted indexing. UniDex replaces complex manual designs with a streamlined
architecture, enhancing semantic generalization while reducing maintenance
overhead. Our approach involves two key components: UniTouch, which maps
queries and documents into semantic IDs for improved retrieval, and UniRank,
which employs semantic matching to rank results effectively. Through
large-scale industrial datasets and real-world online traffic assessments, we
demonstrate that UniDex significantly improves retrieval capabilities, marking
a paradigm shift from term-based to model-based indexing. Our deployment within
Kuaishou's short-video search systems further validates UniDex's practical
effectiveness, serving hundreds of millions of active users efficiently.

</details>


### [97] [Retro*: Optimizing LLMs for Reasoning-Intensive Document Retrieval](https://arxiv.org/abs/2509.24869)
*Junwei Lan,Jianlyu Chen,Zheng Liu,Chaofan Li,Siqi Bao,Defu Lian*

Main category: cs.IR

TL;DR: 提出了一种新的名为Retro*的文档检索方法，该方法通过基于规则的相关性评分机制和强化学习算法来优化推理能力，从而在BRIGHT基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索技术在处理任务与文档之间间接或隐含的连接时面临挑战，尤其是在LLM agents和RAG日益普及的情况下。现有的推理增强IR方法在适用性、可扩展性和效率方面仍然存在显著问题。

Method: 引入了一种基于规则的相关性评分机制，使模型能够根据明确定义的标准来推断任务和文档之间的关系，并生成细粒度的、可解释的相关性分数。此外，还通过结合多个推理轨迹来实现测试时扩展，并通过一种为相关性评分机制量身定制的强化学习算法来优化推理能力。

Result: Retro*优于现有的文档检索方法，并在BRIGHT基准测试中实现了最先进的性能。

Conclusion: Retro*是一种用于推理密集型文档检索的新方法，它通过基于规则的相关性评分和强化学习算法的优化，显著提高了文档检索的性能。

Abstract: With the growing popularity of LLM agents and RAG, it has become increasingly
important to retrieve documents that are essential for solving a task, even
when their connection to the task is indirect or implicit. Addressing this
problem requires fine-grained reasoning to accurately assess the relevance
between the task and each candidate document. This capability, however, poses a
significant challenge for existing IR techniques. Despite recent progress in
reasoning-enhanced IR, existing approaches still face significant challenges in
applicability, scalability, and efficiency. In this work, we propose Retro*, a
novel approach for reasoning-intensive document retrieval. Our method
introduces a rubric-based relevance scoring mechanism, enabling the model to
reason about the relationship between a task and a document based on explicitly
defined criteria, whereby producing a fine-grained, interpretable relevance
score. Retro* also supports test-time scaling by combining multiple reasoning
trajectories via score integration, which produces more reliable relevance
estimates. To optimize Retro*'s reasoning capabilities, we introduce a novel
reinforcement learning algorithm tailored for its relevance scoring mechanism,
which employs two composite rewards to fully exploit the trajectories of each
training sample. Our experiments show that Retro* outperforms existing document
retrieval methods with notable advantages, leading to state-of-the-art
performance on the BRIGHT benchmark.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [98] [Efficient Identification of High Similarity Clusters in Polygon Datasets](https://arxiv.org/abs/2509.23942)
*John N. Daras*

Main category: cs.LG

TL;DR: 本文提出了一种用于提高空间相似性计算效率的框架，该框架通过减少需要验证的聚类数量来降低计算负载。


<details>
  <summary>Details</summary>
Motivation: 现有工具在处理大型数据集时，空间相似性计算效率面临挑战。

Method: 该框架集成了动态相似性指数阈值、监督调度和召回约束优化，利用核密度估计（KDE）动态确定相似性阈值，并使用机器学习模型对聚类进行优先级排序。

Result: 实验结果表明该方法具有可扩展性和有效性，能够显著降低计算成本而不牺牲精度。

Conclusion: 该方法为大规模地理空间分析提供了一种实用的解决方案。

Abstract: Advancements in tools like Shapely 2.0 and Triton can significantly improve
the efficiency of spatial similarity computations by enabling faster and more
scalable geometric operations. However, for extremely large datasets, these
optimizations may face challenges due to the sheer volume of computations
required. To address this, we propose a framework that reduces the number of
clusters requiring verification, thereby decreasing the computational load on
these systems. The framework integrates dynamic similarity index thresholding,
supervised scheduling, and recall-constrained optimization to efficiently
identify clusters with the highest spatial similarity while meeting
user-defined precision and recall requirements. By leveraging Kernel Density
Estimation (KDE) to dynamically determine similarity thresholds and machine
learning models to prioritize clusters, our approach achieves substantial
reductions in computational cost without sacrificing accuracy. Experimental
results demonstrate the scalability and effectiveness of the method, offering a
practical solution for large-scale geospatial analysis.

</details>


### [99] [Localizing Adversarial Attacks To Produces More Imperceptible Noise](https://arxiv.org/abs/2509.22710)
*Pavan Reddy,Aditya Sanjay Gujral*

Main category: cs.LG

TL;DR: 本文研究了机器学习中局部对抗攻击的潜力，通过引入二元掩码将噪声限制在特定区域，实现了更低的像素扰动和更高的图像质量，但计算成本增加且攻击成功率略有下降。


<details>
  <summary>Details</summary>
Motivation: 探索局部对抗噪声在机器学习中的潜力，因为传统对抗攻击主要集中在全局扰动上。

Method: 系统评估了FGSM、PGD和C&W等常用方法的局部对抗攻击，引入二元掩码约束噪声。

Result: 局部攻击实现了更低的平均像素扰动，更高的PSNR和SSIM，但计算成本增加，攻击成功率略有下降。迭代方法（PGD和C&W）比单步方法（FGSM）更具有鲁棒性。

Conclusion: 本文全面分析了局部对抗攻击，为改进攻击策略和设计鲁棒的防御系统提供了实践见解。

Abstract: Adversarial attacks in machine learning traditionally focus on global
perturbations to input data, yet the potential of localized adversarial noise
remains underexplored. This study systematically evaluates localized
adversarial attacks across widely-used methods, including FGSM, PGD, and C&W,
to quantify their effectiveness, imperceptibility, and computational
efficiency. By introducing a binary mask to constrain noise to specific
regions, localized attacks achieve significantly lower mean pixel
perturbations, higher Peak Signal-to-Noise Ratios (PSNR), and improved
Structural Similarity Index (SSIM) compared to global attacks. However, these
benefits come at the cost of increased computational effort and a modest
reduction in Attack Success Rate (ASR). Our results highlight that iterative
methods, such as PGD and C&W, are more robust to localization constraints than
single-step methods like FGSM, maintaining higher ASR and imperceptibility
metrics. This work provides a comprehensive analysis of localized adversarial
attacks, offering practical insights for advancing attack strategies and
designing robust defensive systems.

</details>


### [100] [In-Context Learning can Perform Continual Learning Like Humans](https://arxiv.org/abs/2509.22764)
*Liuwang Kang,Fan Wang,Shaoshan Liu,Hung-Chyun Chou,Chuan Lin,Ning Ding*

Main category: cs.LG

TL;DR: 本文研究了大型语言模型(llm)在多任务学习中通过上下文学习(icl)实现长期记忆和跨任务知识积累的能力，提出了上下文持续学习(iccl)方法，并通过实验验证了其有效性和认知合理性。


<details>
  <summary>Details</summary>
Motivation: 研究ICL在多任务学习中长期记忆和跨任务知识积累的能力，并受人类记忆研究的启发。

Method: 提出上下文持续学习(ICCL)方法，通过任务调度和提示重排实现持续学习能力。同时，提出了人类记忆相似性指标，用于量化持续学习方法与人类记忆动态的匹配程度。

Result: 实验表明，ICCL受益于分布式实践(DP)，并且线性注意力模型(如MAMBA和RWKV)表现出与人类相似的记忆模式。ICCL能够减轻灾难性遗忘，并解决传统CL方法中的稳定性-可塑性困境。

Conclusion: ICCL是一种认知合理且有效的、仅通过推理实现的持续学习范式。

Abstract: Large language models (LLMs) can adapt to new tasks via in-context learning
(ICL) without parameter updates, making them powerful learning engines for fast
adaptation. While extensive research has examined ICL as a few-shot learner,
whether it can achieve long-term retention and cross-task knowledge
accumulation when multitasks arrive sequentially remains underexplored.
Motivated by human memory studies, we investigate the retention characteristics
of ICL in multitask settings and extend it to in-context continual learning
(ICCL), where continual learning ability emerges through task scheduling and
prompt rearrangement. Experiments on Markov-Chain benchmarks demonstrate that,
for specific large-language models, ICCL benefits from distributed practice
(DP) in a manner analogous to humans, consistently revealing a spacing "sweet
spot" for retention. Beyond retention performance, we propose a human-retention
similarity metric to quantify how closely a continual-learning (CL) method
aligns with human retention dynamics. Using this metric, we show that
linear-attention models such as MAMBA and RWKV exhibit particularly human-like
retention patterns, despite their retention performance lagging behind that of
Transformer-based LLMs. Overall, our results establish ICCL as both cognitively
plausible and practically effective, providing an inference-only CL paradigm
that mitigates catastrophic forgetting and addresses the stability-plasticity
dilemma in conventional CL methods.

</details>


### [101] [Communication-Efficient and Interoperable Distributed Learning](https://arxiv.org/abs/2509.22823)
*Mounssif Krouka,Mehdi Bennis*

Main category: cs.LG

TL;DR: 提出了一种通信高效的分布式学习框架，支持模型异构和推理过程中的模块化组合。


<details>
  <summary>Details</summary>
Motivation: 在异构模型架构下的协同学习中，互操作性和保护隐私是一个巨大的挑战。

Method: 所有客户端采用通用的融合层输出维度，允许每个模型被划分为个性化的基块和通用的模块化块。客户端共享他们的融合层输出，同时保持模型参数和架构的私密性。

Result: 与联邦学习（FL）和联邦分割学习（FSL）基线相比，该框架实现了卓越的通信效率，同时确保了跨异构架构的稳定训练性能。

Conclusion: 该框架在异构模型架构下，实现了通信效率和隐私保护。

Abstract: Collaborative learning across heterogeneous model architectures presents
significant challenges in ensuring interoperability and preserving privacy. We
propose a communication-efficient distributed learning framework that supports
model heterogeneity and enables modular composition during inference. To
facilitate interoperability, all clients adopt a common fusion-layer output
dimension, which permits each model to be partitioned into a personalized base
block and a generalized modular block. Clients share their fusion-layer
outputs, keeping model parameters and architectures private. Experimental
results demonstrate that the framework achieves superior communication
efficiency compared to federated learning (FL) and federated split learning
(FSL) baselines, while ensuring stable training performance across
heterogeneous architectures.

</details>


### [102] [On the Capacity of Self-Attention](https://arxiv.org/abs/2509.22840)
*Micah Adler*

Main category: cs.LG

TL;DR: 本文研究了自注意力机制学习关系的能力，提出了关系图识别（RGR）框架，分析了自注意力机制的容量缩放规律，并验证了多头注意力机制的优势。


<details>
  <summary>Details</summary>
Motivation: 缺乏对自注意力机制容量的正式理解，即在给定预算下，单层自注意力机制能够可靠地恢复多少不同的关系。

Method: 提出了关系图识别（RGR）框架，将key-query通道表示为图，并推导了容量缩放规律。

Result: 证明了在广泛的图类别中，恢复m'个关系所需的key维度DK的缩放规律为Θ(m' log m' / d_model)，并验证了多头注意力机制的优势。

Conclusion: 为自注意力机制的容量提供了一个具体的缩放规律，并为在多个头之间分配key-query预算提供了一个原则性的设计规则。

Abstract: While self-attention is known to learn relations among tokens, we lack a
formal understanding of its capacity: how many distinct relations can a single
layer reliably recover for a given budget?
  To formalize this, we introduce Relational Graph Recognition (RGR), where the
key-query channel represents a graph on $m$ items with $m'$ directed edges,
and, given a context of items, must recover the neighbors of each item. We
measure resources by the total key dimension $D_K = h\,d_k$. Within this
framework, we analytically derive a capacity scaling law and validate it
empirically. We show that $D_K = \Theta(m' \log m' / d_{\text{model}})$ is both
necessary (information-theoretic lower bound) and sufficient (explicit
construction) in a broad class of graphs to recover $m'$ relations. This
scaling law directly leads to a new, capacity-based rationale for multi-head
attention that applies even when each item only attends to a single target.
When embeddings are uncompressed ($m = d_{\text{model}}$) and the graph is a
permutation, a single head suffices. However, compression ($m >
d_{\text{model}}$) forces relations into overlapping subspaces, creating
interference that a single large head cannot disentangle. Our analysis shows
that allocating a fixed $D_K$ across many small heads mitigates this
interference, increasing the number of recoverable relations. Controlled
single-layer experiments mirror the theory, revealing a sharp performance
threshold that matches the predicted capacity scaling and confirms the benefit
of distributing $D_K$ across multiple heads.
  Altogether, these results provide a concrete scaling law for self-attention
capacity and a principled design rule for allocating key-query budget across
heads.

</details>


### [103] [Boundary on the Table: Efficient Black-Box Decision-Based Attacks for Structured Data](https://arxiv.org/abs/2509.22850)
*Roie Kazoom,Yuval Ratzabi,Etamar Rothstein,Ofer Hadar*

Main category: cs.LG

TL;DR: 本文提出了一种针对表格数据的黑盒对抗攻击方法，该方法结合了无梯度方向估计和迭代边界搜索。


<details>
  <summary>Details</summary>
Motivation: 与视觉和语言领域相比，结构化数据中的对抗鲁棒性仍然是一个未被充分探索的领域。

Method: 该方法结合了无梯度方向估计和迭代边界搜索，能够在最小的 oracle 访问下有效地导航离散和连续特征空间。

Result: 大量的实验表明，该方法成功地破坏了各种模型（从经典机器学习分类器到基于大型语言模型 (LLM) 的管道）中几乎整个测试集。攻击成功率始终高于 90%，而每个实例只需要少量的查询。

Conclusion: 这些结果突显了表格模型对对抗扰动的严重脆弱性，强调了在现实世界的决策系统中迫切需要更强大的防御。

Abstract: Adversarial robustness in structured data remains an underexplored frontier
compared to vision and language domains. In this work, we introduce a novel
black-box, decision-based adversarial attack tailored for tabular data. Our
approach combines gradient-free direction estimation with an iterative boundary
search, enabling efficient navigation of discrete and continuous feature spaces
under minimal oracle access. Extensive experiments demonstrate that our method
successfully compromises nearly the entire test set across diverse models,
ranging from classical machine learning classifiers to large language model
(LLM)-based pipelines. Remarkably, the attack achieves success rates
consistently above 90%, while requiring only a small number of queries per
instance. These results highlight the critical vulnerability of tabular models
to adversarial perturbations, underscoring the urgent need for stronger
defenses in real-world decision-making systems.

</details>


### [104] [Adaptive Margin RLHF via Preference over Preferences](https://arxiv.org/abs/2509.22851)
*Yaswanth Chittepu,Prasann Singhal,Greg Durrett,Scott Niekum*

Main category: cs.LG

TL;DR: 提出了一种基于偏好排序的自适应边际优化方法，用于改进从人类反馈中进行强化学习的奖励模型学习。


<details>
  <summary>Details</summary>
Motivation: 现有的基于边际的优化方法在处理不同强度的偏好时存在不足，且难以获得准确的偏好分数。

Method: 利用偏好排序信号，推断每个数据点的自适应边际，并扩展了直接偏好优化（DPO），提出了DPO-PoP方法。

Result: 在UltraFeedback数据集上，DPO-PoP优于vanilla DPO、固定边际的DPO以及ground-truth边际的DPO。同时发现判别性能和生成性能之间存在权衡。

Conclusion: 通过偏好排序进行自适应边际调整能够提升奖励模型的性能，但需要在判别性能和生成性能之间进行权衡，并提出了两种采样策略来平衡这种权衡。

Abstract: Margin-based optimization is fundamental to improving generalization and
robustness in classification tasks. In the context of reward model learning
from preferences within Reinforcement Learning from Human Feedback (RLHF),
existing methods typically rely on no margins, fixed margins, or margins that
are simplistic functions of preference ratings. However, such formulations
often fail to account for the varying strengths of different preferences, for
example some preferences are associated with larger margins between responses,
or they rely on noisy margin information derived from ratings. We argue that
modeling the strength of preferences can lead to better generalization and more
faithful alignment. Furthermore, many existing methods that use adaptive
margins assume access to accurate preference scores, which can be difficult for
humans to provide reliably. We propose an approach that leverages preferences
over preferences, that is annotations indicating which of two preferences
reflects a stronger distinction. We use this ordinal signal to infer adaptive
margins on a per-datapoint basis. We introduce an extension to Direct
Preference Optimization (DPO), DPO-PoP, that incorporates adaptive margins from
preference-over-preference supervision, enabling improved discriminative and
generative performance. Empirically, our method outperforms vanilla DPO, DPO
with fixed margins, and DPO with ground-truth margins on the UltraFeedback
dataset. Additionally, we show that there is a tradeoff between discriminative
and generative performance: improving test classification accuracy,
particularly by correctly labeling weaker preferences at the expense of
stronger ones, can lead to a decline in generative quality. To navigate this
tradeoff, we propose two sampling strategies to gather
preference-over-preference labels: one favoring discriminative performance and
one favoring generative performance.

</details>


### [105] [Observation-Free Attacks on Online Learning to Rank](https://arxiv.org/abs/2509.22855)
*Sameep Chattopadhyay,Nikhil Karamchandani,Sharayu Mohair*

Main category: cs.LG

TL;DR: 本文研究了在线学习排序（OLTR）算法在面对协同对抗攻击时的脆弱性，并提出了一个新颖的攻击框架。


<details>
  <summary>Details</summary>
Motivation: 尽管在线学习排序算法被广泛应用，但它们对协同对抗攻击的抵抗能力仍然知之甚少。

Method: 提出了两种新的攻击策略：CascadeOFA用于CascadeUCB1，PBMOFA用于PBM-UCB。

Result: 理论保证表明这两种策略只需要O(log T)次操作就能成功。通过在真实世界数据上的实验结果补充了理论分析。

Conclusion: 该研究揭示了现有OLTR算法在面对特定攻击时的脆弱性，并为未来设计更鲁棒的OLTR算法提供了重要参考。

Abstract: Online learning to rank (OLTR) plays a critical role in information retrieval
and machine learning systems, with a wide range of applications in search
engines and content recommenders. However, despite their extensive adoption,
the susceptibility of OLTR algorithms to coordinated adversarial attacks
remains poorly understood. In this work, we present a novel framework for
attacking some of the widely used OLTR algorithms. Our framework is designed to
promote a set of target items so that they appear in the list of top-K
recommendations for T - o(T) rounds, while simultaneously inducing linear
regret in the learning algorithm. We propose two novel attack strategies:
CascadeOFA for CascadeUCB1 and PBMOFA for PBM-UCB . We provide theoretical
guarantees showing that both strategies require only O(log T) manipulations to
succeed. Additionally, we supplement our theoretical analysis with empirical
results on real-world data.

</details>


### [106] [Neighborhood Sampling Does Not Learn the Same Graph Neural Network](https://arxiv.org/abs/2509.22868)
*Zehao Niu,Mihai Anitescu,Jie Chen*

Main category: cs.LG

TL;DR: 对大规模图神经网络的训练来说，邻域抽样至关重要，但其系统行为却知之甚少。本文利用神经正切核工具进行了理论分析，研究了几种已建立的邻域抽样方法和相应的后验GP。


<details>
  <summary>Details</summary>
Motivation: 虽然邻域抽样已成为实践中的标准实现，但其系统行为却知之甚少。

Method: 通过使用神经正切核的工具，其表征了基于无限宽对应物（高斯过程 (GP)）的神经网络的（类似）训练动态。研究了几种已建立的邻域抽样方法和相应的后验 GP。

Result: 样本有限时，后验结果都不同，但随着样本量的增加，它们会收敛到同一个结果。此外，后验协方差（它对均方预测误差进行下限）是不可比的，这与没有抽样方法占主导地位的观察结果一致。

Conclusion: 邻域抽样方法在样本有限时后验结果不同，但随着样本量的增加，它们会收敛到同一个结果，且后验协方差不可比，没有抽样方法占主导地位。

Abstract: Neighborhood sampling is an important ingredient in the training of
large-scale graph neural networks. It suppresses the exponential growth of the
neighborhood size across network layers and maintains feasible memory
consumption and time costs. While it becomes a standard implementation in
practice, its systemic behaviors are less understood. We conduct a theoretical
analysis by using the tool of neural tangent kernels, which characterize the
(analogous) training dynamics of neural networks based on their infinitely wide
counterparts -- Gaussian processes (GPs). We study several established
neighborhood sampling approaches and the corresponding posterior GP. With
limited samples, the posteriors are all different, although they converge to
the same one as the sample size increases. Moreover, the posterior covariance,
which lower-bounds the mean squared prediction error, is uncomparable, aligning
with observations that no sampling approach dominates.

</details>


### [107] [From Noise to Knowledge: A Comparative Study of Acoustic Anomaly Detection Models in Pumped-storage Hydropower Plants](https://arxiv.org/abs/2509.22881)
*Karim Khamaisi,Nicolas Keller,Stefan Krummenacher,Valentin Huber,Bernhard Fässler,Bruno Rodrigues*

Main category: cs.LG

TL;DR: 本文针对水力发电厂的预测性维护，比较了基于声学的异常检测方法。


<details>
  <summary>Details</summary>
Motivation: 工业工厂和能源生产商的计划外停机会造成高昂的成本，而且难以维护。现有的声学异常检测研究主要依赖于通用工业或合成数据集，由于准入限制，很少有研究关注水力发电厂。

Method: 在高度噪声条件下，解决声学预处理中的关键挑战，然后提取时域和频域特征。对三种机器学习模型进行了基准测试：LSTM AE、K-Means 和 OC-SVM。

Result: 在来自奥地利 Rodundwerk II 抽水蓄能电站的两个真实世界数据集上进行了测试，一个具有诱导异常，一个具有真实世界条件。One-Class SVM 在精度（ROC AUC 0.966-0.998）和最短训练时间之间实现了最佳权衡，而 LSTM 自动编码器以更高的计算成本实现了强大的检测（ROC AUC 0.889-0.997）。

Conclusion: One-Class SVM 和 LSTM 自动编码器 适用于水力发电厂的预测性维护。

Abstract: In the context of industrial factories and energy producers, unplanned
outages are highly costly and difficult to service. However, existing
acoustic-anomaly detection studies largely rely on generic industrial or
synthetic datasets, with few focused on hydropower plants due to limited
access. This paper presents a comparative analysis of acoustic-based anomaly
detection methods, as a way to improve predictive maintenance in hydropower
plants. We address key challenges in the acoustic preprocessing under highly
noisy conditions before extracting time- and frequency-domain features. Then,
we benchmark three machine learning models: LSTM AE, K-Means, and OC-SVM, which
are tested on two real-world datasets from the Rodundwerk II pumped-storage
plant in Austria, one with induced anomalies and one with real-world
conditions. The One-Class SVM achieved the best trade-off of accuracy (ROC AUC
0.966-0.998) and minimal training time, while the LSTM autoencoder delivered
strong detection (ROC AUC 0.889-0.997) at the expense of higher computational
cost.

</details>


### [108] [FedCF: Fair Federated Conformal Prediction](https://arxiv.org/abs/2509.22907)
*Anutam Srinivasan,Aditya T. Vadlamani,Amin Meghrazi,Srinivasan Parthasarathy*

Main category: cs.LG

TL;DR: 本文将Conformal Fairness (CF) 框架扩展到联邦学习 (Federated Learning) 环境中。


<details>
  <summary>Details</summary>
Motivation: 确保不同子群体的条件覆盖保证，将公平性纳入 Conformal Prediction (CP)。

Method: 通过分析不同人口群体的公平性相关差距，审计联邦模型的公平性。

Result: 在多个领域的数据集上进行了实验，充分利用了可交换性假设，从而验证了该框架。

Conclusion: 将 Conformal Fairness 框架扩展到联邦学习环境，并讨论了如何审计联邦模型的公平性。

Abstract: Conformal Prediction (CP) is a widely used technique for quantifying
uncertainty in machine learning models. In its standard form, CP offers
probabilistic guarantees on the coverage of the true label, but it is agnostic
to sensitive attributes in the dataset. Several recent works have sought to
incorporate fairness into CP by ensuring conditional coverage guarantees across
different subgroups. One such method is Conformal Fairness (CF). In this work,
we extend the CF framework to the Federated Learning setting and discuss how we
can audit a federated model for fairness by analyzing the fairness-related gaps
for different demographic groups. We empirically validate our framework by
conducting experiments on several datasets spanning multiple domains, fully
leveraging the exchangeability assumption.

</details>


### [109] [Guided Manifold Alignment with Geometry-Regularized Twin Autoencoders](https://arxiv.org/abs/2509.22913)
*Jake S. Rhodes,Adam G. Rustad,Marshall S. Nielsen,Morgan Chase McClellan,Dallan Gardner,Dawson Hedges*

Main category: cs.LG

TL;DR: 提出了一种几何正则化的孪生自编码器(AE)架构，以增强MA，同时能够推广到未见过的数据。


<details>
  <summary>Details</summary>
Motivation: 传统的MA方法无法执行样本外扩展，限制了它们的实际应用。

Method: 利用几何正则化的孪生自编码器(AE)架构，通过结合预训练的对齐模型和多任务学习公式，改进跨域泛化和表示鲁棒性，同时保持对齐保真度。

Result: 在多个MA方法上进行了评估，结果表明在嵌入一致性、信息保存和跨域迁移方面有所改进。在阿尔茨海默病诊断中的应用表明，该方法能够整合多模态患者数据，并通过利用来自多模态问题的见解，提高仅限于单一领域病例的预测准确性。

Conclusion: 该框架提高了embedding一致性，信息保存和跨域迁移

Abstract: Manifold alignment (MA) involves a set of techniques for learning shared
representations across domains, yet many traditional MA methods are incapable
of performing out-of-sample extension, limiting their real-world applicability.
We propose a guided representation learning framework leveraging a
geometry-regularized twin autoencoder (AE) architecture to enhance MA while
enabling generalization to unseen data. Our method enforces structured
cross-modal mappings to maintain geometric fidelity in learned embeddings. By
incorporating a pre-trained alignment model and a multitask learning
formulation, we improve cross-domain generalization and representation
robustness while maintaining alignment fidelity. We evaluate our approach using
several MA methods, showing improvements in embedding consistency, information
preservation, and cross-domain transfer. Additionally, we apply our framework
to Alzheimer's disease diagnosis, demonstrating its ability to integrate
multi-modal patient data and enhance predictive accuracy in cases limited to a
single domain by leveraging insights from the multi-modal problem.

</details>


### [110] [Rethinking Large Language Model Distillation: A Constrained Markov Decision Process Perspective](https://arxiv.org/abs/2509.22921)
*Matthieu Zimmer,Xiaotong Ji,Tu Nguyen,Haitham Bou Ammar*

Main category: cs.LG

TL;DR: 提出了一种新的大语言模型（LLM）蒸馏方法，将其构建为一个约束强化学习问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于特定的奖励权重，缺乏一个有原则的优化框架。

Method: 将约束状态增强强化学习应用于蒸馏环境，引入改进的奖励函数，保证约束满足的理论保证，无需状态增强或在部署期间访问教师模型，也无需双拉格朗日方法的计算开销。

Result: 在数学推理任务上的大量实验表明，该方法比软拉格朗日松弛基线方法实现了更好的约束满足率和更好的推理能力，同时保持了有竞争力的任务性能。

Conclusion: 该框架为资源受限环境中的奖励感知蒸馏提供了一个理论基础扎实且实际高效的解决方案。

Abstract: We introduce a novel approach to large language model (LLM) distillation by
formulating it as a constrained reinforcement learning problem. While recent
work has begun exploring the integration of task-specific rewards into
distillation processes, existing methods typically rely on ad-hoc reward
weighting. We propose a principled optimization framework that maximizes
task-specific rewards while constraining the divergence from the teacher model
to remain below a specified threshold. Our approach adapts constrained state
augmented reinforcement learning to the distillation setting, introducing a
modified reward function that maintains theoretical guarantees of constraint
satisfaction without requiring state augmentation or teacher model access
during deployment and without the computational overhead of the dual Lagrangian
methods. Through extensive experiments on mathematical reasoning tasks, we
demonstrate that our method achieves better constraint satisfaction rates and
better reasoning compared to the soft Lagrangian relaxation baselines while
maintaining competitive task performance. Our framework provides a
theoretically grounded and practically efficient solution for reward-aware
distillation in resource-constrained settings.

</details>


### [111] [MonoCon: A general framework for learning ultra-compact high-fidelity representations using monotonicity constraints](https://arxiv.org/abs/2509.22931)
*Shreyas Gokhale*

Main category: cs.LG

TL;DR: MonoCon: 使用单调 MLP 头学习高质量、鲁棒、高效和解耦的表示。


<details>
  <summary>Details</summary>
Motivation: 在人工智能中，学习高质量、鲁棒、高效和解耦的表示是一个核心挑战。现有的深度度量学习框架主要使用架构和优化约束来解决这个问题。

Method: 引入 MonoCon，一个简单的框架，它使用附加到任何预训练编码器的小型单调多层感知器 (MLP) 头。通过对比损失和单调性约束引导编码器和头之间的协同适应，MonoCon 学习鲁棒、解耦和高度紧凑的嵌入。

Result: 在 CIFAR-100 图像分类任务中，MonoCon 产生的表示比微调编码器基线紧凑近 9 倍，鲁棒性高 1.5 倍，同时保留了基线 99% 的 5-NN 分类精度。在 SNLI 句子相似性任务中，报告了紧凑 3.4 倍、鲁棒性高 1.4 倍的表示，而 STSb 分数略有下降，这证明 MonoCon 是一个通用的领域无关框架。

Conclusion: 通过功能约束学习的这些鲁棒的超紧凑表示为从边缘计算到云规模检索等不同环境中的关键挑战提供了一个统一的解决方案。

Abstract: Learning high-quality, robust, efficient, and disentangled representations is
a central challenge in artificial intelligence (AI). Deep metric learning
frameworks tackle this challenge primarily using architectural and optimization
constraints. Here, we introduce a third approach that instead relies on
$\textit{functional}$ constraints. Specifically, we present MonoCon, a simple
framework that uses a small monotonic multi-layer perceptron (MLP) head
attached to any pre-trained encoder. Due to co-adaptation between encoder and
head guided by contrastive loss and monotonicity constraints, MonoCon learns
robust, disentangled, and highly compact embeddings at a practically negligible
performance cost. On the CIFAR-100 image classification task, MonoCon yields
representations that are nearly 9x more compact and 1.5x more robust than the
fine-tuned encoder baseline, while retaining 99\% of the baseline's 5-NN
classification accuracy. We also report a 3.4x more compact and 1.4x more
robust representation on an SNLI sentence similarity task for a marginal
reduction in the STSb score, establishing MonoCon as a general domain-agnostic
framework. Crucially, these robust, ultra-compact representations learned via
functional constraints offer a unified solution to critical challenges in
disparate contexts ranging from edge computing to cloud-scale retrieval.

</details>


### [112] [Compute-Optimal Quantization-Aware Training](https://arxiv.org/abs/2509.22935)
*Aleksandr Dremov,David Grangier,Angelos Katharopoulos,Awni Hannun*

Main category: cs.LG

TL;DR: 本文研究了量化感知训练（QAT）中全精度（FP）和QAT阶段的计算分配问题，发现最优QAT/FP训练比例随计算量增加而增加，并提出了一个损失缩放定律来预测最优QAT比例和模型性能，最后提出了一个新颖的冷却和QAT融合方法，以节省计算。


<details>
  <summary>Details</summary>
Motivation: 之前的研究表明，将训练分解为全精度（FP）阶段和QAT阶段可以提高量化神经网络的准确性。然而，FP和QAT阶段之间的最佳计算分配仍然不清楚。

Method: 通过对86.0M到2.2B的各种计算预算、QAT位宽和模型大小进行大量实验，研究不同的QAT持续时间如何影响最终性能。基于实验数据，推导出一个损失缩放定律，该定律可以预测不同QAT/FP计算分配策略和QAT位宽下的最佳QAT比率和最终模型性能。提出了一个新颖的冷却和QAT融合方法，将学习率衰减与量化感知训练相结合。

Result: 实验表明，与之前的发现相反，QAT与FP训练的损失最优比率随着计算总量的增加而增加。此外，可以使用tokens-per-parameter-byte统计数据准确预测各种模型大小和量化宽度的最佳比例。导出的损失缩放定律可以预测不同QAT/FP计算分配策略和QAT位宽下的最佳QAT比率和最终模型性能。新颖的冷却和QAT融合方法消除了冗余的全精度模型更新，并实现了显着的计算节省。

Conclusion: 这些发现为有效的QAT规划提供了实用的见解，并能够在相同的计算预算下训练更高质量的量化模型。

Abstract: Quantization-aware training (QAT) is a leading technique for improving the
accuracy of quantized neural networks. Previous work has shown that decomposing
training into a full-precision (FP) phase followed by a QAT phase yields
superior accuracy compared to QAT alone. However, the optimal allocation of
compute between the FP and QAT phases remains unclear. We conduct extensive
experiments with various compute budgets, QAT bit widths, and model sizes from
86.0M to 2.2B to investigate how different QAT durations impact final
performance. We demonstrate that, contrary to previous findings, the
loss-optimal ratio of QAT to FP training increases with the total amount of
compute. Moreover, the optimal fraction can be accurately predicted for a wide
range of model sizes and quantization widths using the
tokens-per-parameter-byte statistic. From experimental data, we derive a loss
scaling law that predicts both optimal QAT ratios and final model performance
across different QAT/FP compute allocation strategies and QAT bit widths. We
use the scaling law to make further predictions, which we verify
experimentally, including which QAT bit width is optimal under a given memory
constraint and how QAT accuracy with different bit widths compares to
full-precision model accuracy. Additionally, we propose a novel cooldown and
QAT fusion approach that performs learning rate decay jointly with
quantization-aware training, eliminating redundant full-precision model updates
and achieving significant compute savings. These findings provide practical
insights into efficient QAT planning and enable the training of higher-quality
quantized models with the same compute budget.

</details>


### [113] [Understanding SOAP from the Perspective of Gradient Whitening](https://arxiv.org/abs/2509.22938)
*Yanqing Lu,Letao Wang,Jinbo Liu*

Main category: cs.LG

TL;DR: SOAP在语言建模任务中优于Adam和Shampoo，但本文发现SOAP与Shampoo在理论上等价，实验结果也表明SOAP的收敛速度与Shampoo相似，且在最终损失方面没有显著优势。


<details>
  <summary>Details</summary>
Motivation: 分析Adam, Shampoo和SOAP的预处理器，并将它们解释为白化矩阵的近似，从而捕捉二阶曲率信息。

Method: 从梯度白化的角度分析Adam, Shampoo和SOAP，并在Kronecker积假设下建立SOAP和Shampoo理想化版本的理论等价性。使用nanoGPT和灰度图像着色复现语言建模实验。

Result: SOAP表现出与Shampoo相似的收敛速度，并且在最终损失方面没有显著优于Adam和Shampoo。

Conclusion: SOAP在性能上与Shampoo等价，与理论结果一致。

Abstract: Shampoo with Adam in the Preconditioner's eigenbasis (SOAP) has recently
emerged as a promising optimization algorithm for neural network training,
achieving superior training efficiency over both Adam and Shampoo in language
modeling tasks. In this work, we analyze Adam, Shampoo, and SOAP from the
perspective of gradient whitening, interpreting their preconditioners as
approximations to the whitening matrix, which captures second-order curvature
information. We further establish a theoretical equivalence between idealized
versions of SOAP and Shampoo under the Kronecker product assumption. To
empirically evaluate these insights, we reproduce the language modeling
experiments using nanoGPT and grayscale image colorization. Our results show
that SOAP exhibits similar convergence rate as Shampoo, and no significant
advantage over both Adam and Shampoo in the final loss achieved, which aligns
with their equivalence in theory.

</details>


### [114] [SINQ: Sinkhorn-Normalized Quantization for Calibration-Free Low-Precision LLM Weights](https://arxiv.org/abs/2509.22944)
*Lorenz K. Müller,Philippe Bich,Jiawei Zhuang,Ahmet Çelik,Luca Benfenati,Lukas Cavigelli*

Main category: cs.LG

TL;DR: 提出SINQ，通过引入第二轴比例因子和Sinkhorn-Knopp算法，最小化量化误差。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法在低于或等于4位时，由于离群值导致精度下降，尤其是在无校准的均匀量化方法中。

Method: 引入SINQ，使用第二轴比例因子和Sinkhorn-Knopp风格算法来归一化行和列的方差，从而最小化矩阵不平衡。

Result: 在Qwen3和DeepSeek-V2.5模型上，SINQ显著提高了WikiText2和C4的困惑度。

Conclusion: SINQ可以显著提升无校准均匀量化的效果，并且可以与校准和非均匀量化方法结合使用。

Abstract: Post-training quantization has emerged as the most widely used strategy for
deploying large language models at low precision. Still, current methods show
perplexity degradation at bit-widths less than or equal to 4, partly because
representing outliers causes precision issues in parameters that share the same
scales as these outliers. This problem is especially pronounced for
calibration-free, uniform quantization methods. We introduce SINQ to augment
existing post-training quantizers with an additional second-axis scale factor
and a fast Sinkhorn-Knopp-style algorithm that finds scales to normalize
per-row and per-column variances, thereby minimizing a novel per-matrix proxy
target for quantization: the matrix imbalance. Our method has no interactions
between layers and can be trivially applied to new architectures to quantize
any linear layers. We evaluate our method on the Qwen3 model family and
DeepSeek-V2.5. SINQ improves WikiText2 and C4 perplexity significantly against
uncalibrated uniform quantization baselines and can be further enhanced by
combining it with calibration and non-uniform quantization levels. Code to
reproduce the results of this work and to easily quantize models using SINQ is
available at https://github.com/huawei-csl/SINQ.

</details>


### [115] [Meta-Learning Fourier Neural Operators for Hessian Inversion and Enhanced Variational Data Assimilation](https://arxiv.org/abs/2509.22949)
*Hamidreza Moazzami,Asma Jamali,Nicholas Kevlahan,Rodrigo A. Vargas-Hernández*

Main category: cs.LG

TL;DR: 提出了一种基于傅里叶神经算子（FNO）的元学习框架，以近似数据同化（DA）问题中的逆Hessian算子，为共轭梯度（CG）方法提供有效的初始化。


<details>
  <summary>Details</summary>
Motivation: 变分数据同化（DA）方法在海洋和大气预测中被广泛使用，但当涉及到Hessian信息时，计算成本很高。

Method: 利用傅里叶神经算子（FNO）来近似一类DA问题中的逆Hessian算子。

Result: 在线性平流方程的数值实验表明，与标准CG相比，所提出的FNO-CG方法将平均相对误差降低了62%，迭代次数减少了17%。

Conclusion: FNO-CG方法在病态情况下效果最明显，突出了其在具有挑战性的DA问题中的鲁棒性和效率。

Abstract: Data assimilation (DA) is crucial for enhancing solutions to partial
differential equations (PDEs), such as those in numerical weather prediction,
by optimizing initial conditions using observational data. Variational DA
methods are widely used in oceanic and atmospheric forecasting, but become
computationally expensive, especially when Hessian information is involved. To
address this challenge, we propose a meta-learning framework that employs the
Fourier Neural Operator (FNO) to approximate the inverse Hessian operator
across a family of DA problems, thereby providing an effective initialization
for the conjugate gradient (CG) method. Numerical experiments on a linear
advection equation demonstrate that the resulting FNO-CG approach reduces the
average relative error by $62\%$ and the number of iterations by $17\%$
compared to the standard CG. These improvements are most pronounced in
ill-conditioned scenarios, highlighting the robustness and efficiency of FNO-CG
for challenging DA problems.

</details>


### [116] [GDR-learners: Orthogonal Learning of Generative Models for Potential Outcomes](https://arxiv.org/abs/2509.22953)
*Valentyn Melnychuk,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 提出了一系列生成式Neyman正交学习器（GDR-Learner）来估计潜在结果的条件分布。


<details>
  <summary>Details</summary>
Motivation: 现有的深度生成模型不具备广义Neyman正交性，因此不具备准预言效率和双重鲁棒性。

Method: 基于条件正态化流（GDR-CNFs）、条件生成对抗网络（GDR-CGANs）、条件变分自编码器（GDR-CVAEs）和条件扩散模型（GDR-CDMs）构建GDR-Learner。

Result: GDR-Learner具有准预言效率和速率双重鲁棒性，在半合成实验中优于现有方法。

Conclusion: GDR-Learner在估计潜在结果的条件分布方面非常有效且优于现有方法，并且是渐近最优的。

Abstract: Various deep generative models have been proposed to estimate potential
outcomes distributions from observational data. However, none of them have the
favorable theoretical property of general Neyman-orthogonality and, associated
with it, quasi-oracle efficiency and double robustness. In this paper, we
introduce a general suite of generative Neyman-orthogonal (doubly-robust)
learners that estimate the conditional distributions of potential outcomes. Our
proposed GDR-learners are flexible and can be instantiated with many
state-of-the-art deep generative models. In particular, we develop GDR-learners
based on (a) conditional normalizing flows (which we call GDR-CNFs), (b)
conditional generative adversarial networks (GDR-CGANs), (c) conditional
variational autoencoders (GDR-CVAEs), and (d) conditional diffusion models
(GDR-CDMs). Unlike the existing methods, our GDR-learners possess the
properties of quasi-oracle efficiency and rate double robustness, and are thus
asymptotically optimal. In a series of (semi-)synthetic experiments, we
demonstrate that our GDR-learners are very effective and outperform the
existing methods in estimating the conditional distributions of potential
outcomes.

</details>


### [117] [Drift-Adapter: A Practical Approach to Near Zero-Downtime Embedding Model Upgrades in Vector Databases](https://arxiv.org/abs/2509.23471)
*Harshil Vejendla*

Main category: cs.LG

TL;DR: 提出了一种轻量级的可学习转换层，旨在桥接模型版本之间的嵌入空间，允许继续使用现有的ANN索引，从而有效地延迟了完全重新计算。


<details>
  <summary>Details</summary>
Motivation: 在生产向量数据库中升级嵌入模型通常需要重新编码整个语料库并重建近似最近邻(ANN)索引，从而导致显著的操作中断和计算成本。

Method: 正交普罗克鲁斯特，低秩仿射和紧凑残差MLP

Result: 在MTEB文本语料库和CLIP图像模型升级(1M项目)的实验表明，Drift-Adapter恢复了完整重新嵌入的95-99%的检索召回率(Recall@10, MRR)，增加了不到10微秒的查询延迟。与完全重新索引或双索引服务等操作策略相比，Drift-Adapter将重新计算成本降低了100倍以上，并以接近零的操作中断促进了升级。

Conclusion: 我们分析了对各种模型漂移、训练数据大小、数十亿项系统的可扩展性以及对角缩放等设计选择的影响的鲁棒性，证明了Drift-Adapter作为敏捷模型部署的实用解决方案的可行性。

Abstract: Upgrading embedding models in production vector databases typically requires
re-encoding the entire corpus and rebuilding the Approximate Nearest Neighbor
(ANN) index, leading to significant operational disruption and computational
cost. This paper presents Drift-Adapter, a lightweight, learnable
transformation layer designed to bridge embedding spaces between model
versions. By mapping new queries into the legacy embedding space, Drift-Adapter
enables the continued use of the existing ANN index, effectively deferring full
re-computation. We systematically evaluate three adapter parameterizations:
Orthogonal Procrustes, Low-Rank Affine, and a compact Residual MLP, trained on
a small sample of paired old and new embeddings. Experiments on MTEB text
corpora and a CLIP image model upgrade (1M items) show that Drift-Adapter
recovers 95-99% of the retrieval recall (Recall@10, MRR) of a full
re-embedding, adding less than 10 microseconds of query latency. Compared to
operational strategies like full re-indexing or dual-index serving,
Drift-Adapter reduces recompute costs by over 100 times and facilitates
upgrades with near-zero operational interruption. We analyze robustness to
varied model drift, training data size, scalability to billion-item systems,
and the impact of design choices like diagonal scaling, demonstrating
Drift-Adapter's viability as a pragmatic solution for agile model deployment.

</details>


### [118] [Doubly-Robust LLM-as-a-Judge: Externally Valid Estimation with Imperfect Personas](https://arxiv.org/abs/2509.22957)
*Luke Guerdan,Justin Whitehouse,Kimberly Truong,Kenneth Holstein,Zhiwei Steven Wu*

Main category: cs.LG

TL;DR: 这篇论文提出了一种双重鲁棒的估计框架，旨在解决 GenAI 评估中的外部有效性问题，通过结合不完善的 persona 评分和在抽样偏差下获得的人工评分，以获得有效的系统质量估计。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能（GenAI）系统得到越来越多的应用，一个关键问题是评估的外部有效性，或者说它们从基于实验室到真实部署条件下的推广程度。当用于获得系统质量估计的人工评估员和系统输出的源样本与部署时的目标分布不同时，就会出现对 GenAI 评估的外部有效性的威胁。

Method: 该方法利用由 LLM 评估器生成的“角色”评分，该评估器被提示表现为具有特定社会人口特征的人工评估员。该双重鲁棒框架将这些信息丰富但不完善的角色评分与在评估抽样偏差下获得的人工评分相结合，以产生具有统计有效性的系统质量估计。

Result: 该方法在以下情况下产生有效的系统质量估计：(i) 使用角色评分和在抽样偏差下观察到的源数据训练的模型，用于预测人工评分，或 (ii) 用于校正抽样偏差的重加权模型具有足够的质量。

Conclusion: 这项工作为结合不完善的角色评分和在抽样偏差下观察到的人工评分，以获得有效的系统质量估计，奠定了原则性基础。

Abstract: As Generative AI (GenAI) systems see growing adoption, a key concern involves
the external validity of evaluations, or the extent to which they generalize
from lab-based to real-world deployment conditions. Threats to the external
validity of GenAI evaluations arise when the source sample of human raters and
system outputs used to obtain a system quality estimate differs from the target
distribution at deployment time. In this work, we propose a doubly-robust
estimation framework designed to address this evaluation sampling bias. Key to
our approach is the use of "persona" ratings produced by prompting an LLM
evaluator (i.e., an LLM-as-a-judge) to behave as a human rater with specific
sociodemographic characteristics. Our doubly-robust framework combines these
informative yet imperfect persona ratings with human ratings obtained under
evaluation sampling bias to produce statistically valid system quality
estimates. In particular, we show that our approach yields valid system quality
estimates when either (i) a model trained to predict human ratings using
persona ratings and source data observed under sampling bias, or (ii) a
reweighting model that corrects for sampling bias is of sufficient quality. We
validate our framework theoretically and via a novel Persona Simulation
Framework (PSF) designed to systematically manipulate persona quality and the
degree of evaluation sampling bias present in source data. Our work provides a
principled foundation for combining imperfect persona ratings with human
ratings observed under sampling bias to obtain valid system quality estimates.

</details>


### [119] [Reinforcement Learning with Discrete Diffusion Policies for Combinatorial Action Spaces](https://arxiv.org/abs/2509.22963)
*Haitong Ma,Ofir Nabati,Aviv Rosenberg,Bo Dai,Oran Lang,Idan Szpektor,Craig Boutilier,Na Li,Shie Mannor,Lior Shani,Guy Tenneholtz*

Main category: cs.LG

TL;DR: 本研究提出了一种新的框架，用于在复杂环境中训练离散扩散模型，使其成为高效的策略。


<details>
  <summary>Details</summary>
Motivation: 强化学习难以扩展到大型组合动作空间，而实际问题中很常见这种动作空间。

Method: 利用策略镜像下降（PMD）定义一个理想的、正则化的目标策略分布，并将策略更新构建为一个分布匹配问题，训练有表达力的扩散模型来复制这个稳定的目标。

Result: 该方法在一系列具有挑战性的组合基准测试中取得了最先进的结果和卓越的样本效率，包括DNA序列生成、带有宏动作的RL和多智能体系统。

Conclusion: 实验表明，与其他基线相比，我们的扩散策略获得了卓越的性能。

Abstract: Reinforcement learning (RL) struggles to scale to large, combinatorial action
spaces common in many real-world problems. This paper introduces a novel
framework for training discrete diffusion models as highly effective policies
in these complex settings. Our key innovation is an efficient online training
process that ensures stable and effective policy improvement. By leveraging
policy mirror descent (PMD) to define an ideal, regularized target policy
distribution, we frame the policy update as a distributional matching problem,
training the expressive diffusion model to replicate this stable target. This
decoupled approach stabilizes learning and significantly enhances training
performance. Our method achieves state-of-the-art results and superior sample
efficiency across a diverse set of challenging combinatorial benchmarks,
including DNA sequence generation, RL with macro-actions, and multi-agent
systems. Experiments demonstrate that our diffusion policies attain superior
performance compared to other baselines.

</details>


### [120] [GBSK: Skeleton Clustering via Granular-ball Computing and Multi-Sampling for Large-Scale Data](https://arxiv.org/abs/2509.23742)
*Yewang Chen,Junfeng Li,Shuyin Xia,Qinghong Lai,Xinbo Gao,Guoyin Wang,Dongdong Cheng,Yi Liu,Yi Wang*

Main category: cs.LG

TL;DR: 提出了一种新的可扩展骨架聚类算法GBSK，该算法利用粒球技术捕获数据的底层结构。


<details>
  <summary>Details</summary>
Motivation: 为了有效处理大规模数据集的聚类任务。

Method: 通过对数据集进行多重抽样并构建多粒度粒球，GBSK逐步发现一个统计“骨架”——一种空间抽象，它近似于原始数据的基本结构和分布。

Result: GBSK在标准计算硬件上实现了高效和强大的大规模数据集聚类性能，包括一个具有高达1亿个实例和256个维度的数据集。

Conclusion: GBSK 算法能够有效处理大规模数据集的聚类任务，同时保持较高的聚类精度。此外，还介绍了一个自适应版本AGBSK，它具有简化的参数设置，以增强可用性，并有助于在实际场景中部署。

Abstract: To effectively handle clustering task for large-scale datasets, we propose a
novel scalable skeleton clustering algorithm, namely GBSK, which leverages the
granular-ball technique to capture the underlying structure of data. By
multi-sampling the dataset and constructing multi-grained granular-balls, GBSK
progressively uncovers a statistical "skeleton" -- a spatial abstraction that
approximates the essential structure and distribution of the original data.
This strategy enables GBSK to dramatically reduce computational overhead while
maintaining high clustering accuracy. In addition, we introduce an adaptive
version, AGBSK, with simplified parameter settings to enhance usability and
facilitate deployment in real-world scenarios. Extensive experiments conducted
on standard computing hardware demonstrate that GBSK achieves high efficiency
and strong clustering performance on large-scale datasets, including one with
up to 100 million instances across 256 dimensions. Our implementation and
experimental results are available at: https://github.com/XFastDataLab/GBSK/.

</details>


### [121] [Functional Critic Modeling for Provably Convergent Off-Policy Actor-Critic](https://arxiv.org/abs/2509.22964)
*Qinxun Bai,Yuxuan Han,Wei Xu,Zhengyuan Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种新的actor-critic (AC) 框架，以解决 off-policy 强化学习中的挑战，并提供了理论分析和实验验证。


<details>
  <summary>Details</summary>
Motivation: Off-policy 强化学习可以通过重用过去的经验来提高样本效率，但其actor和critic学习面临“致命三元组”不稳定和“移动目标”问题，以及难以准确估计 off-policy 策略梯度的问题。

Method: 本文引入了函数式 critic 建模的概念，并设计了一个新的 AC 框架和神经网络架构。

Result: 本文在理论上证明了该框架的收敛性，并通过在 DeepMind Control Benchmark 上的实验验证了其有效性。

Conclusion: 本文提出的函数式 critic 建模方法可以有效地解决 off-policy AC 学习中的挑战，并为 off-policy 强化学习提供了一种新的思路。

Abstract: Off-policy reinforcement learning (RL) with function approximation offers an
effective way to improve sample efficiency by reusing past experience. Within
this setting, the actor-critic (AC) framework has achieved strong empirical
success. However, both the critic and actor learning is challenging for the
off-policy AC methods: first of all, in addition to the classic "deadly triad"
instability of off-policy evaluation, it also suffers from a "moving target"
problem, where the policy being evaluated changes continually; secondly, actor
learning becomes less efficient due to the difficulty of estimating the exact
off-policy policy gradient. The first challenge essentially reduces the problem
to repeatedly performing off-policy evaluation for changing policies. For the
second challenge, the off-policy policy gradient theorem requires a complex and
often impractical algorithm to estimate an additional emphasis critic, which is
typically neglected in practice, thereby reducing to the on-policy policy
gradient as an approximation. In this work, we introduce a novel concept of
functional critic modeling, which leads to a new AC framework that addresses
both challenges for actor-critic learning under the deadly triad setting. We
provide a theoretical analysis in the linear function setting, establishing the
provable convergence of our framework, which, to the best of our knowledge, is
the first convergent off-policy target-based AC algorithm. From a practical
perspective, we further propose a carefully designed neural network
architecture for the functional critic modeling and demonstrate its
effectiveness through preliminary experiments on widely used RL tasks from the
DeepMind Control Benchmark.

</details>


### [122] [Shape-Informed Clustering of Multi-Dimensional Functional Data via Deep Functional Autoencoders](https://arxiv.org/abs/2509.22969)
*Samuel V. Singh,Shirley Coyle,Mimi Zhang*

Main category: cs.LG

TL;DR: 提出了一个用于聚类分析多维函数数据的功能自动编码器框架 (FAEclust)。


<details>
  <summary>Details</summary>
Motivation: 旨在捕获组件函数之间复杂的非线性相互依赖关系，并准确重建欧几里得和流形值函数数据。

Method: 该框架采用通用逼近器编码器和解码器，并通过应用于功能权重和偏差的创新正则化策略来增强稳定性和鲁棒性。此外，还将聚类损失纳入网络的训练目标中，从而促进潜在表示的学习，这有助于有效的聚类。一个关键的创新是形状感知的聚类目标，确保聚类结果能够抵抗函数中的相位变化。

Result: 建立了非线性解码器的通用逼近性质，并通过大量实验验证了模型的有效性。

Conclusion: 有效聚类

Abstract: We introduce FAEclust, a novel functional autoencoder framework for cluster
analysis of multi-dimensional functional data, data that are random
realizations of vector-valued random functions. Our framework features a
universal-approximator encoder that captures complex nonlinear
interdependencies among component functions, and a universal-approximator
decoder capable of accurately reconstructing both Euclidean and manifold-valued
functional data. Stability and robustness are enhanced through innovative
regularization strategies applied to functional weights and biases.
Additionally, we incorporate a clustering loss into the network's training
objective, promoting the learning of latent representations that are conducive
to effective clustering. A key innovation is our shape-informed clustering
objective, ensuring that the clustering results are resistant to phase
variations in the functions. We establish the universal approximation property
of our non-linear decoder and validate the effectiveness of our model through
extensive experiments.

</details>


### [123] [OptiMind: Teaching LLMs to Think Like Optimization Experts](https://arxiv.org/abs/2509.22979)
*Zeyi Chen,Xinzhi Zhang,Humishka Zope,Hugo Barbalho,Konstantina Mellou,Marco Molinaro,Janardhan Kulkarni,Ishai Menache,Sirui Li*

Main category: cs.LG

TL;DR: 本文提出了一种结合优化专业知识来提高混合整数线性规划公式准确性的方法。


<details>
  <summary>Details</summary>
Motivation: 将自然语言转换为可执行的优化模型是一项重要任务，但现有方法准确率有限，原因是缺乏训练数据和未充分利用领域知识。

Method: 该方法首先通过基于类别的错误分析来清理训练数据，然后开发多轮推理策略，利用类特定的错误摘要和求解器反馈来指导大型语言模型进行迭代改进。

Result: 实验表明，将清理后的数据与领域提示和反馈相结合，可使公式准确率平均提高 14 个百分点。

Conclusion: 该方法提高了公式的准确性，为实现稳健的 LLM 辅助优化公式奠定了基础。

Abstract: Mathematical programming -- the task of expressing operations and
decision-making problems in precise mathematical language -- is fundamental
across domains, yet remains a skill-intensive process requiring operations
research expertise. Recent advances in large language models for complex
reasoning have spurred interest in automating this task, translating natural
language into executable optimization models. Current approaches, however,
achieve limited accuracy, hindered by scarce and noisy training data without
leveraging domain knowledge. In this work, we systematically integrate
optimization expertise to improve formulation accuracy for mixed-integer linear
programming, a key family of mathematical programs. Our approach first cleans
training data through class-based error analysis to explicitly prevent common
mistakes within each optimization class. We then develop multi-turn inference
strategies that guide LLMs with class-specific error summaries and solver
feedback, enabling iterative refinement. Experiments across multiple base LLMs
demonstrate that combining cleaned data with domain-informed prompting and
feedback improves formulation accuracy by 14 percentage points on average,
enabling further progress toward robust LLM-assisted optimization formulation.

</details>
