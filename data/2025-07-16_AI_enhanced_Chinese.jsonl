{"id": "2507.10726", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10726", "abs": "https://arxiv.org/abs/2507.10726", "authors": ["Yuki Iwamoto", "Kaoru Tsunoda", "Ken Kaneiwa"], "title": "Extracting Document Relations from Search Corpus by Marginalizing over User Queries", "comment": "9 pages, 6 figures", "summary": "Understanding relationships between documents in large-scale corpora is\nessential for knowledge discovery and information organization. However,\nexisting approaches rely heavily on manual annotation or predefined\nrelationship taxonomies. We propose EDR-MQ (Extracting Document Relations by\nMarginalizing over User Queries), a novel framework that discovers document\nrelationships through query marginalization. EDR-MQ is based on the insight\nthat strongly related documents often co-occur in results across diverse user\nqueries, enabling us to estimate joint probabilities between document pairs by\nmarginalizing over a collection of queries. To enable this query\nmarginalization approach, we develop Multiply Conditioned Retrieval-Augmented\nGeneration (MC-RAG), which employs conditional retrieval where subsequent\ndocument retrievals depend on previously retrieved content. By observing\nco-occurrence patterns across diverse queries, EDR-MQ estimates joint\nprobabilities between document pairs without requiring labeled training data or\npredefined taxonomies. Experimental results show that our query marginalization\napproach successfully identifies meaningful document relationships, revealing\ntopical clusters, evidence chains, and cross-domain connections that are not\napparent through traditional similarity-based methods. Our query-driven\nframework offers a practical approach to document organization that adapts to\ndifferent user perspectives and information needs.", "AI": {"tldr": "EDR-MQ \u901a\u8fc7\u8fb9\u7f18\u5316\u7528\u6237\u67e5\u8be2\u53d1\u73b0\u6587\u6863\u5173\u7cfb\uff0c\u65e0\u9700\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u6216\u9884\u5b9a\u4e49\u7684\u5206\u7c7b\uff0c\u4ece\u800c\u80fd\u591f\u8bc6\u522b\u6709\u610f\u4e49\u7684\u6587\u6863\u5173\u7cfb\u3002", "motivation": "\u7406\u89e3\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e2d\u6587\u6863\u4e4b\u95f4\u7684\u5173\u7cfb\u5bf9\u4e8e\u77e5\u8bc6\u53d1\u73b0\u548c\u4fe1\u606f\u7ec4\u7ec7\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u4e25\u91cd\u4f9d\u8d56\u4e8e\u624b\u52a8\u6ce8\u91ca\u6216\u9884\u5b9a\u4e49\u7684\u5173\u7cfb\u5206\u7c7b\u3002", "method": "EDR-MQ (\u901a\u8fc7\u8fb9\u7f18\u5316\u7528\u6237\u67e5\u8be2\u63d0\u53d6\u6587\u6863\u5173\u7cfb) \u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u67e5\u8be2\u8fb9\u7f18\u5316\u53d1\u73b0\u6587\u6863\u5173\u7cfb\u3002\u4e3a\u4e86\u5b9e\u73b0\u8fd9\u79cd\u67e5\u8be2\u8fb9\u7f18\u5316\u65b9\u6cd5\uff0c\u6211\u4eec\u5f00\u53d1\u4e86\u591a\u91cd\u6761\u4ef6\u68c0\u7d22\u589e\u5f3a\u751f\u6210 (MC-RAG)\uff0c\u5b83\u91c7\u7528\u6761\u4ef6\u68c0\u7d22\uff0c\u5176\u4e2d\u540e\u7eed\u6587\u6863\u68c0\u7d22\u53d6\u51b3\u4e8e\u5148\u524d\u68c0\u7d22\u7684\u5185\u5bb9\u3002", "result": "\u6211\u4eec\u7684\u67e5\u8be2\u8fb9\u7f18\u5316\u65b9\u6cd5\u6210\u529f\u5730\u8bc6\u522b\u4e86\u6709\u610f\u4e49\u7684\u6587\u6863\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u4e3b\u9898\u96c6\u7fa4\u3001\u8bc1\u636e\u94fe\u548c\u8de8\u57df\u8fde\u63a5\uff0c\u8fd9\u4e9b\u90fd\u662f\u4f20\u7edf\u7684\u57fa\u4e8e\u76f8\u4f3c\u6027\u7684\u65b9\u6cd5\u65e0\u6cd5\u5b9e\u73b0\u7684\u3002", "conclusion": "query-driven \u6846\u67b6\u4e3a\u6587\u6863\u7ec4\u7ec7\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u9002\u5e94\u4e0d\u540c\u7684\u7528\u6237\u89c6\u89d2\u548c\u4fe1\u606f\u9700\u6c42\u3002"}}
{"id": "2507.10865", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10865", "abs": "https://arxiv.org/abs/2507.10865", "authors": ["Nick Craswell", "Bhaskar Mitra", "Emine Yilmaz", "Daniel Campos", "Jimmy Lin", "Ellen M. Voorhees", "Ian Soboroff"], "title": "Overview of the TREC 2022 deep learning track", "comment": "arXiv admin note: substantial text overlap with arXiv:2507.08191,\n  arXiv:2507.08890", "summary": "This is the fourth year of the TREC Deep Learning track. As in previous\nyears, we leverage the MS MARCO datasets that made hundreds of thousands of\nhuman annotated training labels available for both passage and document ranking\ntasks. In addition, this year we also leverage both the refreshed passage and\ndocument collections that were released last year leading to a nearly $16$\ntimes increase in the size of the passage collection and nearly four times\nincrease in the document collection size. Unlike previous years, in 2022 we\nmainly focused on constructing a more complete test collection for the passage\nretrieval task, which has been the primary focus of the track. The document\nranking task was kept as a secondary task, where document-level labels were\ninferred from the passage-level labels. Our analysis shows that similar to\nprevious years, deep neural ranking models that employ large scale pretraining\ncontinued to outperform traditional retrieval methods. Due to the focusing our\njudging resources on passage judging, we are more confident in the quality of\nthis year's queries and judgments, with respect to our ability to distinguish\nbetween runs and reuse the dataset in future. We also see some surprises in\noverall outcomes. Some top-performing runs did not do dense retrieval. Runs\nthat did single-stage dense retrieval were not as competitive this year as they\nwere last year.", "AI": {"tldr": "TREC Deep Learning track \u7b2c\u56db\u5e74\uff0c\u4e3b\u8981\u5173\u6ce8\u6784\u5efa\u66f4\u5b8c\u6574\u7684 passage \u68c0\u7d22\u6d4b\u8bd5\u96c6\u3002\u6df1\u5ea6\u795e\u7ecf\u6392\u5e8f\u6a21\u578b\u7ee7\u7eed\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u5bc6\u96c6\u68c0\u7d22\u7684\u8868\u73b0\u4ee4\u4eba\u610f\u5916\u3002", "motivation": "\u6784\u5efa\u4e00\u4e2a\u66f4\u5b8c\u6574\u7684 passage \u68c0\u7d22\u4efb\u52a1\u7684\u6d4b\u8bd5\u96c6\u5408\uff0c\u8fd9\u4e00\u76f4\u662f\u8be5 track \u7684\u4e3b\u8981\u91cd\u70b9\u3002\u6587\u6863\u6392\u5e8f\u4efb\u52a1\u88ab\u4fdd\u7559\u4e3a\u8f85\u52a9\u4efb\u52a1\uff0c\u5176\u4e2d\u6587\u6863\u7ea7\u522b\u7684\u6807\u7b7e\u662f\u4ece passage \u7ea7\u522b\u7684\u6807\u7b7e\u63a8\u65ad\u51fa\u6765\u7684\u3002", "method": "\u5229\u7528 MS MARCO \u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u4e3a passage \u548c\u6587\u6863\u6392\u5e8f\u4efb\u52a1\u63d0\u4f9b\u4e86\u6570\u5341\u4e07\u4e2a\u4eba\u5de5\u6807\u6ce8\u7684\u8bad\u7ec3\u6807\u7b7e\u3002\u6b64\u5916\uff0c\u4eca\u5e74\u6211\u4eec\u8fd8\u5229\u7528\u4e86\u53bb\u5e74\u53d1\u5e03\u7684\u5237\u65b0\u7684 passage \u548c\u6587\u6863\u96c6\u5408\uff0c\u5bfc\u81f4 passage \u96c6\u5408\u7684\u5927\u5c0f\u589e\u52a0\u4e86\u8fd1 16 \u500d\uff0c\u6587\u6863\u96c6\u5408\u7684\u5927\u5c0f\u589e\u52a0\u4e86\u8fd1 4 \u500d\u3002", "result": "\u4e0e\u5f80\u5e74\u7c7b\u4f3c\uff0c\u91c7\u7528\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u795e\u7ecf\u6392\u5e8f\u6a21\u578b\u7ee7\u7eed\u4f18\u4e8e\u4f20\u7edf\u68c0\u7d22\u65b9\u6cd5\u3002\u7531\u4e8e\u6211\u4eec\u5c06 judging \u8d44\u6e90\u96c6\u4e2d\u5728 passage judging \u4e0a\uff0c\u56e0\u6b64\u6211\u4eec\u66f4\u6709\u4fe1\u5fc3\u533a\u5206 runs \u5e76\u5728\u672a\u6765\u91cd\u7528\u6570\u636e\u96c6\u3002\u6211\u4eec\u8fd8\u770b\u5230\u4e86\u4e00\u4e9b\u4ee4\u4eba\u60ca\u8bb6\u7684\u603b\u4f53\u7ed3\u679c\u3002\u4e00\u4e9b\u8868\u73b0\u6700\u4f73\u7684 runs \u6ca1\u6709\u505a\u5bc6\u96c6\u68c0\u7d22\u3002\u5355\u9636\u6bb5\u5bc6\u96c6\u68c0\u7d22\u7684 runs \u4e0d\u5982\u53bb\u5e74\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "\u6df1\u5ea6\u795e\u7ecf\u6392\u5e8f\u6a21\u578b\u7ee7\u7eed\u4f18\u4e8e\u4f20\u7edf\u68c0\u7d22\u65b9\u6cd5\u3002\u4e13\u6ce8\u4e8e passage judging \u4f7f\u5f97\u6211\u4eec\u66f4\u6709\u4fe1\u5fc3\u533a\u5206 runs \u5e76\u5728\u672a\u6765\u91cd\u7528\u6570\u636e\u96c6\u3002\u4e00\u4e9b\u8868\u73b0\u6700\u4f73\u7684 runs \u6ca1\u6709\u505a\u5bc6\u96c6\u68c0\u7d22\u3002\u5355\u9636\u6bb5\u5bc6\u96c6\u68c0\u7d22\u7684 runs \u4e0d\u5982\u53bb\u5e74\u6709\u7ade\u4e89\u529b\u3002"}}
{"id": "2507.10917", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10917", "abs": "https://arxiv.org/abs/2507.10917", "authors": ["Ziyan Wang", "Yingpeng Du", "Zhu Sun", "Jieyi Bi", "Haoyan Chua", "Tianjun Wei", "Jie Zhang"], "title": "LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation", "comment": "10 pages, 5 figures", "summary": "Recently, much effort has been devoted to modeling users' multi-interests\nbased on their behaviors or auxiliary signals. However, existing methods often\nrely on heuristic assumptions, e.g., co-occurring items indicate the same\ninterest of users, failing to capture user multi-interests aligning with\nreal-world scenarios. While large language models (LLMs) show significant\npotential for multi-interest analysis due to their extensive knowledge and\npowerful reasoning capabilities, two key challenges remain. First, the\ngranularity of LLM-driven multi-interests is agnostic, possibly leading to\noverly fine or coarse interest grouping. Second, individual user analysis\nprovides limited insights due to the data sparsity issue. In this paper, we\npropose an LLM-driven dual-level multi-interest modeling framework for more\neffective recommendation. At the user-individual level, we exploit LLMs to\nflexibly allocate items engaged by users into different semantic clusters,\nindicating their diverse and distinct interests. To alleviate the agnostic\ngeneration of LLMs, we adaptively assign these semantic clusters to users'\ncollaborative multi-interests learned from global user-item interactions,\nallowing the granularity to be automatically adjusted according to the user's\nbehaviors using an alignment module. To alleviate the limited insights derived\nfrom individual users' behaviors, at the user-crowd level, we propose\naggregating user cliques into synthesized users with rich behaviors for more\ncomprehensive LLM-driven multi-interest analysis. We formulate a max covering\nproblem to ensure the compactness and representativeness of synthesized users'\nbehaviors, and then conduct contrastive learning based on their LLM-driven\nmulti-interests to disentangle item representations among different interests.\nExperiments on real-world datasets show the superiority of our approach against\nstate-of-the-art methods.", "AI": {"tldr": "This paper introduces an LLM-driven dual-level multi-interest modeling framework to enhance recommendation systems by addressing the limitations of existing methods in capturing user multi-interests. It leverages LLMs at both individual and crowd levels, using semantic clusters and synthesized users to improve interest analysis and item representation.", "motivation": "Existing methods often rely on heuristic assumptions, e.g., co-occurring items indicate the same interest of users, failing to capture user multi-interests aligning with real-world scenarios. While large language models (LLMs) show significant potential for multi-interest analysis due to their extensive knowledge and powerful reasoning capabilities, two key challenges remain. First, the granularity of LLM-driven multi-interests is agnostic, possibly leading to overly fine or coarse interest grouping. Second, individual user analysis provides limited insights due to the data sparsity issue.", "method": "We propose an LLM-driven dual-level multi-interest modeling framework for more effective recommendation. At the user-individual level, we exploit LLMs to flexibly allocate items engaged by users into different semantic clusters, indicating their diverse and distinct interests. To alleviate the agnostic generation of LLMs, we adaptively assign these semantic clusters to users' collaborative multi-interests learned from global user-item interactions, allowing the granularity to be automatically adjusted according to the user's behaviors using an alignment module. To alleviate the limited insights derived from individual users' behaviors, at the user-crowd level, we propose aggregating user cliques into synthesized users with rich behaviors for more comprehensive LLM-driven multi-interest analysis. We formulate a max covering problem to ensure the compactness and representativeness of synthesized users' behaviors, and then conduct contrastive learning based on their LLM-driven multi-interests to disentangle item representations among different interests.", "result": "superiority of our approach against state-of-the-art methods", "conclusion": "Experiments on real-world datasets show the superiority of our approach against state-of-the-art methods."}}
{"id": "2507.10953", "categories": ["cs.IR", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2507.10953", "abs": "https://arxiv.org/abs/2507.10953", "authors": ["Balu Bhasuran", "Sabenabanu Abdulkadhar", "Jeyakumar Natarajan"], "title": "Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining", "comment": null, "summary": "High-altitude diseases (HAD), encompassing acute mountain sickness (AMS),\nhigh-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE),\nare triggered by hypobaric hypoxia at elevations above 2,500 meters. These\nconditions pose significant health risks, yet the molecular mechanisms remain\ninsufficiently understood. In this study, we developed a biomolecular event\nextraction pipeline integrating supervised machine learning with feature-based\nand multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related\nabstracts from PubMed. We extracted over 150 unique biomolecular events\nincluding gene expression, regulation, binding, and localization and\nconstructed a weighted, undirected biomolecular event network comprising 97\nnodes and 153 edges. Using the PageRank algorithm, we prioritized key\nbiomolecules based on their centrality within the event network. The top-ranked\nproteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth\nfactor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136),\nEndothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme\n(ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70\nkilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles\nin oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure\nregulation. Subnetwork analysis revealed three major functional clusters\ncentered on hypoxia response, inflammation, and stress adaptation pathways. Our\nintegrative approach demonstrates the utility of large-scale text mining and\ngraph-based analysis to uncover mechanistic insights and prioritize potential\nbiomarkers for high-altitude disease.", "AI": {"tldr": "This study uses text mining and graph analysis to identify key biomolecules and pathways involved in high-altitude diseases.", "motivation": "High-altitude diseases (HAD) pose significant health risks, yet the molecular mechanisms remain insufficiently understood.", "method": "The authors developed a biomolecular event extraction pipeline integrating supervised machine learning with feature-based and multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related abstracts from PubMed. They constructed a weighted, undirected biomolecular event network and used the PageRank algorithm to prioritize key biomolecules.", "result": "The study extracted over 150 unique biomolecular events and identified key proteins including Erythropoietin (EPO), Vascular endothelial growth factor (VEGF), and Hypoxia-inducible factor 1 (HIF-1) alpha. Subnetwork analysis revealed three major functional clusters centered on hypoxia response, inflammation, and stress adaptation pathways.", "conclusion": "This study demonstrates the utility of large-scale text mining and graph-based analysis to uncover mechanistic insights and prioritize potential biomarkers for high-altitude disease."}}
{"id": "2507.10629", "categories": ["cs.DB", "cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.10629", "abs": "https://arxiv.org/abs/2507.10629", "authors": ["Song Cheng", "Qiannan Cheng", "Linbo Jin", "Lei Yi", "Guannan Zhang"], "title": "SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition", "comment": "WWW '25: Companion Proceedings of the ACM on Web Conference 2025\n  Pages 919 - 923 https://doi.org/10.1145/3701716.3715541", "summary": "Transforming natural language into SQL queries (NL2SQL) is crucial for\ndata-driven business applications. Existing frameworks, trained on open-source\ndatasets, struggle with complex business logic and lack domain-specific data\nfor fine-tuning. Additionally, evaluation methods often require annotated data\nand executable database environments, which are scarce in real-world scenarios.\nTo address these challenges, we propose SQLord, an enterprise-level NL2SQL\nframework. First, SQLord introduces a data reverse generation approach to\nconvert raw SQL statements into annotated data for supervised fine-tuning\n(SFT). Second, it proposes a decomposition method for complex queries using an\nautomated workflow generator. Additionally, SQLord features a comprehensive\nGPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL\nEvaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios.\nOffline tests significantly outperform state of the art baselines, and online\naccuracy consistently exceeds 90, highlighting SQLord's advantages and\neffectiveness in complex real world scenarios. SQLord has been successfully\napplied across multiple scenarios on the world's largest B2B e-commerce\nplatform.", "AI": {"tldr": "SQLord\u662f\u4e00\u4e2a\u4f01\u4e1a\u7ea7NL2SQL\u6846\u67b6\uff0c\u5b83\u5f15\u5165\u4e86\u4e00\u79cd\u6570\u636e\u53cd\u5411\u751f\u6210\u65b9\u6cd5\uff0c\u5c06\u539f\u59cbSQL\u8bed\u53e5\u8f6c\u6362\u4e3a\u5e26\u6ce8\u91ca\u7684\u6570\u636e\uff0c\u7528\u4e8e\u76d1\u7763\u5fae\u8c03 (SFT)\u3002", "motivation": "\u73b0\u6709\u7684\u6846\u67b6\u5728\u590d\u6742\u4e1a\u52a1\u903b\u8f91\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u4e14\u7f3a\u4e4f\u7528\u4e8e\u5fae\u8c03\u7684\u9886\u57df\u7279\u5b9a\u6570\u636e\u3002\u6b64\u5916\uff0c\u8bc4\u4f30\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u5e26\u6ce8\u91ca\u7684\u6570\u636e\u548c\u53ef\u6267\u884c\u7684\u6570\u636e\u5e93\u73af\u5883\uff0c\u8fd9\u5728\u73b0\u5b9e\u573a\u666f\u4e2d\u5f88\u5c11\u89c1\u3002", "method": "SQLord \u5f15\u5165\u4e86\u4e00\u79cd\u6570\u636e\u53cd\u5411\u751f\u6210\u65b9\u6cd5\uff0c\u5c06\u539f\u59cb SQL \u8bed\u53e5\u8f6c\u6362\u4e3a\u5e26\u6ce8\u91ca\u7684\u6570\u636e\uff0c\u7528\u4e8e\u76d1\u7763\u5fae\u8c03 (SFT)\u3002\u5176\u6b21\uff0c\u5b83\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u751f\u6210\u5668\u5206\u89e3\u590d\u6742\u67e5\u8be2\u7684\u65b9\u6cd5\u3002\u6b64\u5916\uff0cSQLord \u8fd8\u5177\u6709\u4e00\u4e2a\u5168\u9762\u7684 GPT-Judge \u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ec\u6267\u884c\u8bc4\u4f30 (EXE)\u3001\u67e5\u8be2-SQL \u8bc4\u4f30 (QSE) \u548c SQL-SQL \u8bc4\u4f30 (SSE)\uff0c\u4e13\u4e3a\u5404\u79cd\u573a\u666f\u91cf\u8eab\u5b9a\u5236\u3002", "result": "\u79bb\u7ebf\u6d4b\u8bd5\u660e\u663e\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\uff0c\u5728\u7ebf\u51c6\u786e\u7387\u59cb\u7ec8\u8d85\u8fc7 90\u3002", "conclusion": "SQLord\u5728\u590d\u6742\u73b0\u5b9e\u573a\u666f\u4e2d\u5177\u6709\u4f18\u52bf\u548c\u6709\u6548\u6027\uff0c\u5df2\u6210\u529f\u5e94\u7528\u4e8e\u5168\u7403\u6700\u5927\u7684B2B\u7535\u5b50\u5546\u52a1\u5e73\u53f0\u7684\u591a\u4e2a\u573a\u666f\u3002"}}
{"id": "2507.10577", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2507.10577", "abs": "https://arxiv.org/abs/2507.10577", "authors": ["Log\u00e9 C\u00e9cile", "Ghori Rehan"], "title": "Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions", "comment": null, "summary": "Misinformation poses a significant threat in today's digital world, often\nspreading rapidly through platforms like YouTube. This paper introduces a novel\napproach to combating misinformation by developing an AI-powered system that\nnot only fact-checks claims made in YouTube videos but also actively engages\nusers in the comment section and challenge misleading narratives. Our system\ncomprises two main agents: Truth Sleuth and Trend Bender.\n  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented\nGeneration (RAG) approach - drawing on sources like Wikipedia, Google Search,\nGoogle FactCheck - to accurately assess their veracity and generates a nuanced\nand comprehensive report. Through rigorous prompt engineering, Trend Bender\nleverages this report along with a curated corpus of relevant articles to\ngenerate insightful and persuasive comments designed to stimulate a productive\ndebate. With a carefully set up self-evaluation loop, this agent is able to\niteratively improve its style and refine its output.\n  We demonstrate the system's capabilities through experiments on established\nbenchmark datasets and a real-world deployment on YouTube, showcasing its\npotential to engage users and potentially influence perspectives. Our findings\nhighlight the high accuracy of our fact-checking agent, and confirm the\npotential of AI-driven interventions in combating misinformation and fostering\na more informed online space.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e8b\u5b9e\u6838\u67e5\u548c\u7528\u6237\u4e92\u52a8\u6765\u6253\u51fbYouTube\u4e0a\u7684\u865a\u5047\u4fe1\u606f\u3002", "motivation": "\u865a\u5047\u4fe1\u606f\u5728\u5f53\u4eca\u7684\u6570\u5b57\u4e16\u754c\u4e2d\u6784\u6210\u91cd\u5927\u5a01\u80c1\uff0c\u7ecf\u5e38\u901a\u8fc7YouTube\u7b49\u5e73\u53f0\u8fc5\u901f\u4f20\u64ad\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2aAI\u9a71\u52a8\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u4e0d\u4ec5\u53ef\u4ee5\u6838\u5b9eYouTube\u89c6\u9891\u4e2d\u7684\u58f0\u660e\uff0c\u8fd8\u53ef\u4ee5\u4e3b\u52a8\u8ba9\u7528\u6237\u53c2\u4e0e\u8bc4\u8bba\u90e8\u5206\u5e76\u6311\u6218\u8bef\u5bfc\u6027\u53d9\u8ff0\u3002\u8be5\u7cfb\u7edf\u5305\u542b\u4e24\u4e2a\u4e3b\u8981\u4ee3\u7406\uff1aTruth Sleuth\u548cTrend Bender\u3002", "result": "\u901a\u8fc7\u5728\u5df2\u5efa\u7acb\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548cYouTube\u4e0a\u7684\u5b9e\u9645\u90e8\u7f72\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86\u8be5\u7cfb\u7edf\u7684\u529f\u80fd\uff0c\u5c55\u793a\u4e86\u5176\u5438\u5f15\u7528\u6237\u5e76\u53ef\u80fd\u5f71\u54cd\u89c2\u70b9\u7684\u6f5c\u529b\u3002\u8c03\u67e5\u7ed3\u679c\u5f3a\u8c03\u4e86\u4e8b\u5b9e\u6838\u67e5\u4ee3\u7406\u7684\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u8bc1\u5b9e\u4e86AI\u9a71\u52a8\u7684\u5e72\u9884\u63aa\u65bd\u5728\u6253\u51fb\u865a\u5047\u4fe1\u606f\u548c\u8425\u9020\u66f4\u660e\u667a\u7684\u5728\u7ebf\u7a7a\u95f4\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u5e72\u9884\u63aa\u65bd\u6709\u6f5c\u529b\u6253\u51fb\u865a\u5047\u4fe1\u606f\uff0c\u8425\u9020\u66f4\u660e\u667a\u7684\u5728\u7ebf\u7a7a\u95f4\u3002"}}
{"id": "2507.10689", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10689", "abs": "https://arxiv.org/abs/2507.10689", "authors": ["Tongshun Zhang", "Pingping Liu", "Yubing Lu", "Mengen Cai", "Zijian Zhang", "Zhe Zhang", "Qiuzhan Zhou"], "title": "CWNet: Causal Wavelet Network for Low-Light Image Enhancement", "comment": "Accepted by ICCV 2025", "summary": "Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on\nuniform brightness adjustment, often neglecting instance-level semantic\ninformation and the inherent characteristics of different features. To address\nthese limitations, we propose CWNet (Causal Wavelet Network), a novel\narchitecture that leverages wavelet transforms for causal reasoning.\nSpecifically, our approach comprises two key components: 1) Inspired by the\nconcept of intervention in causality, we adopt a causal reasoning perspective\nto reveal the underlying causal relationships in low-light enhancement. From a\nglobal perspective, we employ a metric learning strategy to ensure causal\nembeddings adhere to causal principles, separating them from non-causal\nconfounding factors while focusing on the invariance of causal factors. At the\nlocal level, we introduce an instance-level CLIP semantic loss to precisely\nmaintain causal factor consistency. 2) Based on our causal analysis, we present\na wavelet transform-based backbone network that effectively optimizes the\nrecovery of frequency information, ensuring precise enhancement tailored to the\nspecific attributes of wavelet transforms. Extensive experiments demonstrate\nthat CWNet significantly outperforms current state-of-the-art methods across\nmultiple datasets, showcasing its robust performance across diverse scenes.\nCode is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.", "AI": {"tldr": "CWNet, a Causal Wavelet Network, leverages wavelet transforms and causal reasoning to enhance low-light images, outperforming existing methods by considering instance-level semantic information and feature characteristics.", "motivation": "Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on uniform brightness adjustment, often neglecting instance-level semantic information and the inherent characteristics of different features. To address these limitations", "method": "a novel architecture that leverages wavelet transforms for causal reasoning. Specifically, our approach comprises two key components: 1) Inspired by the concept of intervention in causality, we adopt a causal reasoning perspective to reveal the underlying causal relationships in low-light enhancement. From a global perspective, we employ a metric learning strategy to ensure causal embeddings adhere to causal principles, separating them from non-causal confounding factors while focusing on the invariance of causal factors. At the local level, we introduce an instance-level CLIP semantic loss to precisely maintain causal factor consistency. 2) Based on our causal analysis, we present a wavelet transform-based backbone network that effectively optimizes the recovery of frequency information, ensuring precise enhancement tailored to the specific attributes of wavelet transforms.", "result": "CWNet significantly outperforms current state-of-the-art methods across multiple datasets, showcasing its robust performance across diverse scenes.", "conclusion": "CWNet significantly outperforms current state-of-the-art methods across multiple datasets, showcasing its robust performance across diverse scenes."}}
{"id": "2507.10564", "categories": ["cs.LG", "cs.AI", "eess.SP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10564", "abs": "https://arxiv.org/abs/2507.10564", "authors": ["Sameera Bharadwaja H.", "Siddhrath Jandial", "Shashank S. Agashe", "Rajesh Kumar Reddy Moore", "Youngkwan Kim"], "title": "Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing", "comment": null, "summary": "We consider the problem of tool-to-tool matching (TTTM), also called, chamber\nmatching in the context of a semiconductor manufacturing equipment. Traditional\nTTTM approaches utilize static configuration data or depend on a golden\nreference which are difficult to obtain in a commercial manufacturing line.\nFurther, existing methods do not extend very well to a heterogeneous setting,\nwhere equipment are of different make-and-model, sourced from different\nequipment vendors. We propose novel TTTM analysis pipelines to overcome these\nissues. We hypothesize that a mismatched equipment would have higher variance\nand/or higher number of modes in the data. Our best univariate method achieves\na correlation coefficient >0.95 and >0.5 with the variance and number of modes,\nrespectively showing that the proposed methods are effective. Also, the best\nmultivariate method achieves a correlation coefficient >0.75 with the\ntop-performing univariate methods, showing its effectiveness. Finally, we\nanalyze the sensitivity of the multivariate algorithms to the algorithm\nhyper-parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5de5\u5177\u5339\u914d (TTTM) \u5206\u6790\u7ba1\u9053\uff0c\u7528\u4e8e\u89e3\u51b3\u4f20\u7edf TTTM \u65b9\u6cd5\u5728\u5f02\u6784\u73af\u5883\u4e2d\u96be\u4ee5\u5e94\u7528\u7684\u95ee\u9898\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u662f\u6709\u6548\u7684\u3002", "motivation": "\u4f20\u7edf\u7684 TTTM \u65b9\u6cd5\u5229\u7528\u9759\u6001\u914d\u7f6e\u6570\u636e\u6216\u4f9d\u8d56\u4e8e\u96be\u4ee5\u5728\u5546\u4e1a\u751f\u4ea7\u7ebf\u4e2d\u83b7\u5f97\u7684\u9ec4\u91d1\u53c2\u8003\u3002\u6b64\u5916\uff0c\u73b0\u6709\u65b9\u6cd5\u4e0d\u80fd\u5f88\u597d\u5730\u6269\u5c55\u5230\u5f02\u6784\u73af\u5883\uff0c\u5373\u8bbe\u5907\u6765\u81ea\u4e0d\u540c\u7684\u5236\u9020\u5546\u548c\u578b\u53f7\uff0c\u6765\u81ea\u4e0d\u540c\u7684\u8bbe\u5907\u4f9b\u5e94\u5546\u3002", "method": "\u63d0\u51fa\u4e86\u65b0\u7684 TTTM \u5206\u6790\u7ba1\u9053\u3002", "result": "\u6700\u4f73\u5355\u53d8\u91cf\u65b9\u6cd5\u4e0e\u65b9\u5dee\u548c\u6a21\u6001\u6570\u7684\u76f8\u5173\u7cfb\u6570\u5206\u522b\u5927\u4e8e 0.95 \u548c 0.5\uff0c\u6700\u4f73\u591a\u53d8\u91cf\u65b9\u6cd5\u4e0e\u8868\u73b0\u6700\u4f73\u7684\u5355\u53d8\u91cf\u65b9\u6cd5\u7684\u76f8\u5173\u7cfb\u6570\u5927\u4e8e 0.75\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u6709\u6548\u7684\uff0c\u6700\u4f73\u5355\u53d8\u91cf\u65b9\u6cd5\u4e0e\u65b9\u5dee\u548c\u6a21\u6001\u6570\u7684\u76f8\u5173\u7cfb\u6570\u5206\u522b\u5927\u4e8e 0.95 \u548c 0.5\uff0c\u6700\u4f73\u591a\u53d8\u91cf\u65b9\u6cd5\u4e0e\u8868\u73b0\u6700\u4f73\u7684\u5355\u53d8\u91cf\u65b9\u6cd5\u7684\u76f8\u5173\u7cfb\u6570\u5927\u4e8e 0.75\u3002\u5206\u6790\u4e86\u591a\u5143\u7b97\u6cd5\u5bf9\u7b97\u6cd5\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\u3002"}}
{"id": "2507.10562", "categories": ["cs.AI", "cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10562", "abs": "https://arxiv.org/abs/2507.10562", "authors": ["Hari Masoor"], "title": "SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents", "comment": "7 pages, 4 figures, 3 implementation examples. Original work\n  submitted as a preprint", "summary": "Current AI agent architectures suffer from ephemeral memory limitations,\npreventing effective collaboration and knowledge sharing across sessions and\nagent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a\nnovel framework that enables persistent, secure, and semantically searchable\nmemory sharing among AI agents. Our protocol addresses three critical\nchallenges: (1) persistent context preservation across agent sessions, (2)\nsecure multi-agent collaboration with fine-grained access control, and (3)\nefficient semantic discovery of relevant historical context. SAMEP implements a\ndistributed memory repository with vector-based semantic search, cryptographic\naccess controls (AES-256-GCM), and standardized APIs compatible with existing\nagent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness\nacross diverse domains including multi-agent software development, healthcare\nAI with HIPAA compliance, and multi-modal processing pipelines. Experimental\nresults show 73% reduction in redundant computations, 89% improvement in\ncontext relevance scores, and complete compliance with regulatory requirements\nincluding audit trail generation. SAMEP enables a new paradigm of persistent,\ncollaborative AI agent ecosystems while maintaining security and privacy\nguarantees.", "AI": {"tldr": "SAMEP\u662f\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u5b83\u652f\u6301AI\u4ee3\u7406\u4e4b\u95f4\u6301\u4e45\u3001\u5b89\u5168\u548c\u8bed\u4e49\u53ef\u641c\u7d22\u7684\u5185\u5b58\u5171\u4eab\u3002", "motivation": "\u76ee\u524d\u7684AI\u4ee3\u7406\u67b6\u6784\u5b58\u5728\u77ed\u6682\u7684\u5185\u5b58\u9650\u5236\uff0c\u963b\u788d\u4e86\u8de8\u4f1a\u8bdd\u548c\u4ee3\u7406\u8fb9\u754c\u7684\u6709\u6548\u534f\u4f5c\u548c\u77e5\u8bc6\u5171\u4eab\u3002", "method": "SAMEP\u5b9e\u73b0\u4e86\u5177\u6709\u57fa\u4e8e\u5411\u91cf\u7684\u8bed\u4e49\u641c\u7d22\u3001\u52a0\u5bc6\u8bbf\u95ee\u63a7\u5236\uff08AES-256-GCM\uff09\u548c\u4e0e\u73b0\u6709\u4ee3\u7406\u901a\u4fe1\u534f\u8bae\uff08MCP\u3001A2A\uff09\u517c\u5bb9\u7684\u6807\u51c6\u5316API\u7684\u5206\u5e03\u5f0f\u5b58\u50a8\u5e93\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5197\u4f59\u8ba1\u7b97\u51cf\u5c11\u4e8673%\uff0c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u8bc4\u5206\u63d0\u9ad8\u4e8689%\uff0c\u5e76\u4e14\u5b8c\u5168\u7b26\u5408\u5305\u62ec\u5ba1\u8ba1\u8ddf\u8e2a\u751f\u6210\u5728\u5185\u7684\u76d1\u7ba1\u8981\u6c42\u3002", "conclusion": "SAMEP\u5b9e\u73b0\u4e86\u6301\u4e45\u3001\u534f\u4f5c\u7684AI\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\uff0c\u540c\u65f6\u4fdd\u6301\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u8bc1\u3002"}}
{"id": "2507.11042", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2507.11042", "abs": "https://arxiv.org/abs/2507.11042", "authors": ["Adam Yang", "Gustavo Penha", "Enrico Palumbo", "Hugues Bouchard"], "title": "Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment", "comment": null, "summary": "With the breakthroughs in large language models (LLMs), query generation\ntechniques that expand documents and queries with related terms are becoming\nincreasingly popular in the information retrieval field. Such techniques have\nbeen shown to improve the effectiveness of traditional lexical retrieval\nmethods by dealing with the vocabulary mismatch problem. Recent work has found\nthat generating queries with a greedy decoding strategy can produce sub-optimal\nqueries, including hallucinations, and proposed to filter out queries before\nexpansion. This `generate-then-filter' approach is costly, as it requires\ngenerating multiple queries and applying a relevance model to all of them and\ndoes not teach the LLM which of the generated queries is more effective for\nexpansion. To overcome such limitations, we propose Aligned Query Expansion\n(AQE), a novel approach to enhance query expansion for passage retrieval in\nopen-domain question answering. AQE leverages recent techniques in LLM\nalignment to fine-tune models for generating query expansions that directly\noptimize the effectiveness of the retrieval task, eliminating the need for\nadditional filtering steps. This alignment ensures that queries are more\nrelevant, reducing computational costs while improving retrieval effectiveness.\nEmpirical evaluations show that AQE outperforms baseline models for query\nexpansion in both in-domain and out-of-domain settings, demonstrating\nsignificant improvements in retrieval effectiveness.", "AI": {"tldr": "AQE\u662f\u4e00\u79cd\u65b0\u7684\u67e5\u8be2\u6269\u5c55\u65b9\u6cd5\uff0c\u5b83\u901a\u8fc7\u5bf9\u9f50LLM\u6765\u4f18\u5316\u68c0\u7d22\u4efb\u52a1\u7684\u6709\u6548\u6027\uff0c\u65e0\u9700\u989d\u5916\u7684\u8fc7\u6ee4\u6b65\u9aa4\u3002", "motivation": "\u514b\u670d\u751f\u6210\u5f0f\u67e5\u8be2\u6269\u5c55\u7684\u5c40\u9650\u6027\uff0c\u4f8b\u5982\u5e7b\u89c9\u548c\u8ba1\u7b97\u6210\u672c\u3002", "method": "Aligned Query Expansion (AQE)", "result": "AQE\u63d0\u9ad8\u4e86\u68c0\u7d22\u6709\u6548\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "AQE\u5728\u540c\u57df\u548c\u5f02\u57df\u8bbe\u7f6e\u4e2d\u4f18\u4e8e\u67e5\u8be2\u6269\u5c55\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u68c0\u7d22\u6709\u6548\u6027\u7684\u663e\u7740\u63d0\u9ad8\u3002"}}
{"id": "2507.10897", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2507.10897", "abs": "https://arxiv.org/abs/2507.10897", "authors": ["Sha Wang", "Yuchen Li", "Hanhua Xiao", "Bing Tian Dai", "Roy Ka-Wei Lee", "Yanfei Dong", "Lambert Deng"], "title": "LLMATCH: A Unified Schema Matching Framework with Large Language Models", "comment": "Accepted at APWeb 2025, Schema Matching, LLM, Data Management", "summary": "Schema matching is a foundational task in enterprise data integration, aiming\nto align disparate data sources. While traditional methods handle simple\none-to-one table mappings, they often struggle with complex multi-table schema\nmatching in real-world applications. We present LLMatch, a unified and modular\nschema matching framework. LLMatch decomposes schema matching into three\ndistinct stages: schema preparation, table-candidate selection, and\ncolumn-level alignment, enabling component-level evaluation and future-proof\ncompatibility. It includes a novel two-stage optimization strategy: a Rollup\nmodule that consolidates semantically related columns into higher-order\nconcepts, followed by a Drilldown module that re-expands these concepts for\nfine-grained column mapping. To address the scarcity of complex semantic\nmatching benchmarks, we introduce SchemaNet, a benchmark derived from\nreal-world schema pairs across three enterprise domains, designed to capture\nthe challenges of multi-table schema alignment in practical settings.\nExperiments demonstrate that LLMatch significantly improves matching accuracy\nin complex schema matching settings and substantially boosts engineer\nproductivity in real-world data integration.", "AI": {"tldr": "LLMatch \u662f\u4e00\u4e2a\u7edf\u4e00\u4e14\u6a21\u5757\u5316\u7684\u6a21\u5f0f\u5339\u914d\u6846\u67b6\uff0c\u5b83\u5c06\u6a21\u5f0f\u5339\u914d\u5206\u89e3\u4e3a\u4e09\u4e2a\u4e0d\u540c\u7684\u9636\u6bb5\uff0c\u5e76\u5305\u542b\u4e00\u4e2a\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\u3002\u4e3a\u4e86\u89e3\u51b3\u590d\u6742\u8bed\u4e49\u5339\u914d\u57fa\u51c6\u7684\u7a00\u7f3a\u95ee\u9898\uff0c\u6211\u4eec\u5f15\u5165\u4e86 SchemaNet\uff0c\u8fd9\u662f\u4e00\u4e2a\u6765\u81ea\u4e09\u4e2a\u4f01\u4e1a\u57df\u7684\u771f\u5b9e\u6a21\u5f0f\u5bf9\u7684\u57fa\u51c6\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u53ef\u4ee5\u5904\u7406\u7b80\u5355\u7684\u4e00\u5bf9\u4e00\u8868\u683c\u6620\u5c04\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u96be\u4ee5\u5e94\u5bf9\u5b9e\u9645\u5e94\u7528\u4e2d\u590d\u6742\u7684\u591a\u8868\u683c\u6a21\u5f0f\u5339\u914d\u3002", "method": "LLMatch \u5c06\u6a21\u5f0f\u5339\u914d\u5206\u89e3\u4e3a\u4e09\u4e2a\u4e0d\u540c\u7684\u9636\u6bb5\uff1a\u6a21\u5f0f\u51c6\u5907\u3001\u8868\u5019\u9009\u9009\u62e9\u548c\u5217\u7ea7\u5bf9\u9f50\uff0c\u4ece\u800c\u5b9e\u73b0\u7ec4\u4ef6\u7ea7\u8bc4\u4f30\u548c\u9762\u5411\u672a\u6765\u7684\u517c\u5bb9\u6027\u3002\u5b83\u5305\u62ec\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u7b56\u7565\uff1a\u4e00\u4e2a Rollup \u6a21\u5757\uff0c\u5c06\u8bed\u4e49\u76f8\u5173\u7684\u5217\u6574\u5408\u5230\u66f4\u9ad8\u9636\u7684\u6982\u5ff5\u4e2d\uff0c\u7136\u540e\u662f\u4e00\u4e2a Drilldown \u6a21\u5757\uff0c\u91cd\u65b0\u6269\u5c55\u8fd9\u4e9b\u6982\u5ff5\u4ee5\u8fdb\u884c\u7ec6\u7c92\u5ea6\u7684\u5217\u6620\u5c04\u3002", "result": "LLMatch \u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u6a21\u5f0f\u5339\u914d\u8bbe\u7f6e\u4e2d\u7684\u5339\u914d\u7cbe\u5ea6\uff0c\u5e76\u5927\u5927\u63d0\u9ad8\u4e86\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u6210\u4e2d\u7684\u5de5\u7a0b\u5e08\u751f\u4ea7\u529b\u3002\u6211\u4eec\u5f15\u5165\u4e86 SchemaNet\uff0c\u8fd9\u662f\u4e00\u4e2a\u6765\u81ea\u4e09\u4e2a\u4f01\u4e1a\u57df\u7684\u771f\u5b9e\u6a21\u5f0f\u5bf9\u7684\u57fa\u51c6\uff0c\u65e8\u5728\u6355\u6349\u5b9e\u9645\u8bbe\u7f6e\u4e2d\u591a\u8868\u6a21\u5f0f\u5bf9\u9f50\u7684\u6311\u6218\u3002", "conclusion": "LLMatch \u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u6a21\u5f0f\u5339\u914d\u8bbe\u7f6e\u4e2d\u7684\u5339\u914d\u7cbe\u5ea6\uff0c\u5e76\u5927\u5927\u63d0\u9ad8\u4e86\u73b0\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u6210\u4e2d\u7684\u5de5\u7a0b\u5e08\u751f\u4ea7\u529b\u3002"}}
{"id": "2507.10580", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2507.10580", "abs": "https://arxiv.org/abs/2507.10580", "authors": ["Vimaleswar A", "Prabhu Nandan Sahu", "Nilesh Kumar Sahu", "Haroon R Lone"], "title": "An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation", "comment": null, "summary": "Mental health plays a crucial role in the overall well-being of an\nindividual. In recent years, digital platforms have been increasingly used to\nexpand mental health and emotional support. However, there are persistent\nchallenges related to limited user accessibility, internet connectivity, and\ndata privacy, which highlight the need for an offline, smartphone-based\nsolution. To address these challenges, we propose EmoSApp (Emotional Support\nApp): an entirely offline, smartphone-based conversational app designed for\nmental health and emotional support. The system leverages Large Language Models\n(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and\nExecutorch for resource-constrained devices, allowing all inferences to occur\non the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned\nthe LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of\n14,582 mental-health QA pairs, along with the multi-turn conversational data.\n  Through qualitative human evaluation with the student population, we\ndemonstrate that EmoSApp has the ability to respond coherently, empathetically,\nmaintain interactive dialogue, and provide relevant suggestions to user's\nmental health problems. Additionally, quantitative evaluations on nine standard\ncommonsense and reasoning benchmarks demonstrate the efficacy of our\nfine-tuned, quantized model in low-resource settings. By prioritizing on-device\ndeployment and specialized domain adaptation, EmoSApp serves as a blueprint for\nfuture innovations in portable, secure, and highly tailored AI-driven mental\nhealth solutions.", "AI": {"tldr": "EmoSApp: an offline, smartphone-based conversational app for mental health, leveraging fine-tuned LLMs.", "motivation": "Persistent challenges related to limited user accessibility, internet connectivity, and data privacy highlight the need for an offline, smartphone-based solution.", "method": "fine-tuned, quantized and deployed LLMs (LLaMA-3.2-1B-Instruct model) using Torchtune and Executorch", "result": "EmoSApp can respond coherently and empathetically, maintain interactive dialogue, and provide relevant suggestions. Quantitative evaluations demonstrate the efficacy of the model in low-resource settings.", "conclusion": "EmoSApp serves as a blueprint for future innovations in portable, secure, and highly tailored AI-driven mental health solutions."}}
{"id": "2507.10737", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10737", "abs": "https://arxiv.org/abs/2507.10737", "authors": ["Jiayuan Chen", "Thai-Hoang Pham", "Yuanlong Wang", "Ping Zhang"], "title": "Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines", "comment": "ICCV 2025", "summary": "High-throughput screening techniques, such as microscopy imaging of cellular\nresponses to genetic and chemical perturbations, play a crucial role in drug\ndiscovery and biomedical research. However, robust perturbation screening for\n\\textit{de novo} cell lines remains challenging due to the significant\nmorphological and biological heterogeneity across cell lines. To address this,\nwe propose a novel framework that integrates external biological knowledge into\nexisting pretraining strategies to enhance microscopy image profiling models.\nOur approach explicitly disentangles perturbation-specific and cell\nline-specific representations using external biological information.\nSpecifically, we construct a knowledge graph leveraging protein interaction\ndata from STRING and Hetionet databases to guide models toward\nperturbation-specific features during pretraining. Additionally, we incorporate\ntranscriptomic features from single-cell foundation models to capture cell\nline-specific representations. By learning these disentangled features, our\nmethod improves the generalization of imaging models to \\textit{de novo} cell\nlines. We evaluate our framework on the RxRx database through one-shot\nfine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from\nthe RxRx19a dataset. Experimental results demonstrate that our method enhances\nmicroscopy image profiling for \\textit{de novo} cell lines, highlighting its\neffectiveness in real-world phenotype-based drug discovery applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u5916\u90e8\u751f\u7269\u5b66\u77e5\u8bc6\u6765\u63d0\u9ad8\u663e\u5fae\u955c\u56fe\u50cf\u5206\u6790\u6a21\u578b\u5bf9\u65b0\u7ec6\u80de\u7cfb\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4ece\u800c\u6539\u5584\u57fa\u4e8e\u8868\u578b\u7684\u836f\u7269\u53d1\u73b0\u5e94\u7528\u3002", "motivation": "\u7531\u4e8e\u7ec6\u80de\u7cfb\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u7684\u5f62\u6001\u548c\u751f\u7269\u5b66\u5f02\u8d28\u6027\uff0c\u56e0\u6b64\u5bf9\u65b0\u7ec6\u80de\u7cfb\u8fdb\u884c\u7a33\u5065\u7684\u6270\u52a8\u7b5b\u9009\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u6574\u5408\u4e86\u5916\u90e8\u751f\u7269\u5b66\u77e5\u8bc6\u5230\u73b0\u6709\u7684\u9884\u8bad\u7ec3\u7b56\u7565\u4e2d\uff0c\u4ee5\u589e\u5f3a\u663e\u5fae\u955c\u56fe\u50cf\u5206\u6790\u6a21\u578b\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5b83\u5229\u7528\u86cb\u767d\u8d28\u4e92\u4f5c\u6570\u636e\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\uff0c\u5e76\u7ed3\u5408\u6765\u81ea\u5355\u7ec6\u80de\u57fa\u7840\u6a21\u578b\u7684\u8f6c\u5f55\u7ec4\u7279\u5f81\uff0c\u6765\u5206\u522b\u5f15\u5bfc\u6a21\u578b\u5b66\u4e60\u6270\u52a8\u7279\u5f02\u6027\u548c\u7ec6\u80de\u7cfb\u7279\u5f02\u6027\u7684\u8868\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u589e\u5f3a\u4e86\u65b0\u7ec6\u80de\u7cfb\u7684\u663e\u5fae\u955c\u56fe\u50cf\u5206\u6790\u80fd\u529b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u89e3\u8026\u7684\u7279\u5f81\uff0c\u63d0\u9ad8\u4e86\u56fe\u50cf\u6a21\u578b\u5bf9\u65b0\u7ec6\u80de\u7cfb\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u5728 RxRx \u6570\u636e\u5e93\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2507.10574", "categories": ["cs.LG", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.10574", "abs": "https://arxiv.org/abs/2507.10574", "authors": ["Jae Wan Shim"], "title": "Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance", "comment": "13 pages, 2 figures", "summary": "We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel\nmeasure derived from the information theory. In comparison to the standard\ncross entropy loss function, the proposed one has an additional term that\ndepends on the predicted probability of the true class. This feature serves to\nenhance the optimization process in classification tasks involving one-hot\nencoded class labels. The proposed one has been evaluated on a ResNet-based\nmodel using the CIFAR-100 dataset. Preliminary results show that the proposed\none consistently outperforms the standard cross entropy loss function in terms\nof classification accuracy. Moreover, the proposed one maintains simplicity,\nachieving practically the same efficiency to the traditional cross entropy\nloss. These findings suggest that our approach could broaden the scope for\nfuture research into loss function design.", "AI": {"tldr": "A new loss function, Linearly Adaptive Cross Entropy, improves classification accuracy compared to standard cross entropy without sacrificing efficiency.", "motivation": "Enhance the optimization process in classification tasks with one-hot encoded class labels.", "method": "A linearly adaptive cross entropy loss function is proposed, which includes an additional term based on the predicted probability of the true class.", "result": "The proposed loss function consistently outperforms the standard cross entropy loss in classification accuracy on CIFAR-100 using a ResNet-based model and maintains similar efficiency.", "conclusion": "The proposed linearly adaptive cross entropy loss function outperforms the standard cross entropy loss in classification accuracy on CIFAR-100 with ResNet, while maintaining similar efficiency. This suggests potential for future research in loss function design."}}
{"id": "2507.10566", "categories": ["cs.AI", "cs.GT", "cs.LG", "cs.MA", "cs.NE", "68T07, 68T40, 91A20", "I.2.6; I.2.11; I.2.4"], "pdf": "https://arxiv.org/pdf/2507.10566", "abs": "https://arxiv.org/abs/2507.10566", "authors": ["Hung Ming Liu"], "title": "AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems", "comment": "30 pages, 4 figures", "summary": "In Decentralized Multi-Agent Reinforcement Learning (MARL), the development\nof Emergent Communication has long been constrained by the ``Joint Exploration\nDilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .\nTraditional methods address this by introducing inductive biases to facilitate\ncommunication emergence . This study fundamentally questions whether such\nartificial inductive biases are, in fact, over-engineering. Through experiments\nwith the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized\nVariational Autoencoder (VQ-VAE), we demonstrate that when agents possess an\nendogenous symbol system, their neural representations naturally exhibit\nspontaneous semantic compression and Nash equilibrium-driven semantic\nconvergence, achieving effective symbolic communication without external\ninductive biases. This aligns with recent neuroscience findings suggesting that\nthe human brain does not directly use human language for internal thought , and\nresonates with research on ``soft thinking'' capabilities in Large Language\nModels (LLMs) . Compared to traditional explicit communication methods, AIM\ndemonstrates stronger generality and efficiency. The interpretable analysis\ntoolkit developed in this study confirms that symbol usage exhibits a\nsignificant power-law distribution, leading to three major theoretical\ninsights: the ``Neural Communication Hypothesis'', the ``Tool-First\nPrinciple'', and the ``Semantic Interpretability Paradigm''. Future research\nwill explore the integration of Hierarchical Quantized Variational Autoencoders\n(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the\npotential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This\ndiscovery offers new avenues for bridging symbolism and connectionism.", "AI": {"tldr": "The paper explores emergent communication in MARL using the AIM framework, showing that agents with an endogenous symbol system can achieve effective communication without external inductive biases, suggesting new directions for bridging symbolism and connectionism.", "motivation": "The development of Emergent Communication in Decentralized Multi-Agent Reinforcement Learning (MARL) has been constrained by the Joint Exploration Dilemma, leading to a Communication Vacuum Equilibrium. The study questions whether artificial inductive biases are over-engineering.", "method": "The study uses the AIM framework, based on a Vector Quantized Variational Autoencoder (VQ-VAE), to enable agents to possess an endogenous symbol system.", "result": "Agents' neural representations naturally exhibit spontaneous semantic compression and Nash equilibrium-driven semantic convergence, achieving effective symbolic communication without external inductive biases. Symbol usage exhibits a significant power-law distribution, leading to three major theoretical insights: the Neural Communication Hypothesis, the Tool-First Principle, and the Semantic Interpretability Paradigm.", "conclusion": "AIM demonstrates stronger generality and efficiency compared to traditional explicit communication methods, offering new avenues for bridging symbolism and connectionism."}}
{"id": "2507.11364", "categories": ["cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.11364", "abs": "https://arxiv.org/abs/2507.11364", "authors": ["Kelly Kurowski", "Xixi Lu", "Hajo A. Reijers"], "title": "From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation", "comment": "Accepted at AUTOMATE 2025", "summary": "The growing volume of unstructured data within organizations poses\nsignificant challenges for data analysis and process automation. Unstructured\ndata, which lacks a predefined format, encompasses various forms such as\nemails, reports, and scans. It is estimated to constitute approximately 80% of\nenterprise data. Despite the valuable insights it can offer, extracting\nmeaningful information from unstructured data is more complex compared to\nstructured data. Robotic Process Automation (RPA) has gained popularity for\nautomating repetitive tasks, improving efficiency, and reducing errors.\nHowever, RPA is traditionally reliant on structured data, limiting its\napplication to processes involving unstructured documents. This study addresses\nthis limitation by developing the UNstructured Document REtrieval SyStem\n(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural\nlanguage processing, and large language models to enable RPA platforms to\neffectively retrieve information from unstructured documents. The research\ninvolved the design and development of a prototype system, and its subsequent\nevaluation based on text extraction and information retrieval performance. The\nresults demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities\nfor unstructured data, providing a significant advancement in the field. The\nfindings suggest that this system could facilitate broader RPA adoption across\nprocesses traditionally hindered by unstructured data, thereby improving\noverall business process efficiency.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aUNDRESS\u7684\u7cfb\u7edf\uff0c\u5229\u7528\u6a21\u7cca\u6b63\u5219\u8868\u8fbe\u5f0f\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4f7fRPA\u5e73\u53f0\u80fd\u591f\u6709\u6548\u5730\u4ece\u975e\u7ed3\u6784\u5316\u6587\u6863\u4e2d\u68c0\u7d22\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u5347\u4e1a\u52a1\u6d41\u7a0b\u6548\u7387\u3002", "motivation": "\u7ec4\u7ec7\u5185\u4e0d\u65ad\u589e\u957f\u7684\u975e\u7ed3\u6784\u5316\u6570\u636e\u7ed9\u6570\u636e\u5206\u6790\u548c\u6d41\u7a0b\u81ea\u52a8\u5316\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edfRPA\u4f9d\u8d56\u4e8e\u7ed3\u6784\u5316\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u6d89\u53ca\u975e\u7ed3\u6784\u5316\u6587\u6863\u7684\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aUNDRESS\u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86\u6a21\u7cca\u6b63\u5219\u8868\u8fbe\u5f0f\u3001\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "UNDRESS\u7cfb\u7edf\u5728\u589e\u5f3aRPA\u5904\u7406\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u80fd\u529b\u65b9\u9762\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002", "conclusion": "UNDRESS\u7cfb\u7edf\u901a\u8fc7\u589e\u5f3aRPA\u5e73\u53f0\u5904\u7406\u975e\u7ed3\u6784\u5316\u6570\u636e\u7684\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e1a\u52a1\u6d41\u7a0b\u6548\u7387\uff0c\u5e76\u4fc3\u8fdb\u4e86RPA\u5728\u4f20\u7edf\u4e0a\u53d7\u975e\u7ed3\u6784\u5316\u6570\u636e\u9650\u5236\u7684\u6d41\u7a0b\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2507.10934", "categories": ["cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10934", "abs": "https://arxiv.org/abs/2507.10934", "authors": ["Xinyuan Liu", "Jiahui Chen", "Bocheng Hu", "Yu Sun", "Xinyang Chen", "Shaoxu Song"], "title": "Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models", "comment": null, "summary": "Data quality remains an important challenge in data-driven systems, as errors\nin tabular data can severely compromise downstream analytics and machine\nlearning performance. Although numerous error detection algorithms have been\nproposed, the lack of diverse, real-world error datasets limits comprehensive\nevaluation. Manual error annotation is both time-consuming and inconsistent,\nmotivating the exploration of synthetic error generation as an alternative. In\nthis work, we introduce TableEG, a framework that leverages large language\nmodels (LLMs) to generate authentic errors. By employing a table fine-tuning\nstrategy and a triplet representation $(I, T, O)$ to model error generation,\ndetection, and correction tasks, TableEG captures the complex dependencies\ninherent in two-dimensional tables. Trained on 12 real-world datasets spanning\n10 diverse domains, TableEG ensures that the synthesized errors faithfully\nreflect authentic error distributions. Experimental results indicate that\nerrors generated by TableEG exhibit superior pattern and distribution\nsimilarity compared to both rule-based methods and LLM-generated errors without\nfine-tuning. Furthermore, performance metrics on TableEG-generated errors\nclosely align with those on real-world errors across nearly all datasets and\ndetection algorithms, particularly for machine learning based detection\ntechniques. Overall, TableEG not only bridges the gap between synthetic and\nreal-world errors but also establishes a robust benchmark for subsequent error\ndetection and correction tasks.", "AI": {"tldr": "TableEG\u662f\u4e00\u4e2a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u771f\u5b9e\u9519\u8bef\u7684\u6846\u67b6\uff0c\u53ef\u4ee5\u5f25\u5408\u5408\u6210\u9519\u8bef\u548c\u771f\u5b9e\u9519\u8bef\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u4e3a\u540e\u7eed\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u4efb\u52a1\u5efa\u7acb\u4e86\u53ef\u9760\u7684\u57fa\u51c6\u3002", "motivation": "\u8868\u683c\u6570\u636e\u4e2d\u7684\u9519\u8bef\u4f1a\u4e25\u91cd\u5f71\u54cd\u4e0b\u6e38\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u6027\u80fd\u3002\u7f3a\u4e4f\u591a\u6837\u5316\u7684\u771f\u5b9e\u4e16\u754c\u9519\u8bef\u6570\u636e\u96c6\u9650\u5236\u4e86\u7efc\u5408\u8bc4\u4f30\u3002\u624b\u52a8\u9519\u8bef\u6ce8\u91ca\u65e2\u8017\u65f6\u53c8\u4e0d\u4e00\u81f4\uff0c\u4fc3\u4f7f\u4eba\u4eec\u63a2\u7d22\u5408\u6210\u9519\u8bef\u751f\u6210\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u751f\u6210\u771f\u5b9e\u9519\u8bef\u7684\u6846\u67b6", "result": "TableEG\u751f\u6210\u7684\u9519\u8bef\u4e0e\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u548c\u672a\u7ecf\u5fae\u8c03\u7684LLM\u751f\u6210\u7684\u9519\u8bef\u76f8\u6bd4\uff0c\u8868\u73b0\u51fa\u5353\u8d8a\u7684\u6a21\u5f0f\u548c\u5206\u5e03\u76f8\u4f3c\u6027\u3002\u6b64\u5916\uff0c\u5728TableEG\u751f\u6210\u7684\u9519\u8bef\u4e0a\u7684\u6027\u80fd\u6307\u6807\u4e0e\u51e0\u4e4e\u6240\u6709\u6570\u636e\u96c6\u548c\u68c0\u6d4b\u7b97\u6cd5\uff08\u7279\u522b\u662f\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u68c0\u6d4b\u6280\u672f\uff09\u4e0a\u7684\u771f\u5b9e\u4e16\u754c\u9519\u8bef\u4e0a\u7684\u6027\u80fd\u6307\u6807\u975e\u5e38\u543b\u5408\u3002", "conclusion": "TableEG\u5f25\u5408\u4e86\u5408\u6210\u9519\u8bef\u548c\u771f\u5b9e\u9519\u8bef\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e76\u4e3a\u540e\u7eed\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u4efb\u52a1\u5efa\u7acb\u4e86\u53ef\u9760\u7684\u57fa\u51c6\u3002"}}
{"id": "2507.10582", "categories": ["cs.CL", "stat.ME"], "pdf": "https://arxiv.org/pdf/2507.10582", "abs": "https://arxiv.org/abs/2507.10582", "authors": ["Anders Ledberg", "Anna Thal\u00e9n"], "title": "Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis", "comment": null, "summary": "Unstructured text from legal, medical, and administrative sources offers a\nrich but underutilized resource for research in public health and the social\nsciences. However, large-scale analysis is hampered by two key challenges: the\npresence of sensitive, personally identifiable information, and significant\nheterogeneity in structure and language. We present a modular toolchain that\nprepares such text data for embedding-based analysis, relying entirely on\nopen-weight models that run on local hardware, requiring only a\nworkstation-level GPU and supporting privacy-sensitive research.\n  The toolchain employs large language model (LLM) prompting to standardize,\nsummarize, and, when needed, translate texts to English for greater\ncomparability. Anonymization is achieved via LLM-based redaction, supplemented\nwith named entity recognition and rule-based methods to minimize the risk of\ndisclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court\ndecisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.\nEach document is processed into an anonymized, standardized summary and\ntransformed into a document-level embedding. Validation, including manual\nreview, automated scanning, and predictive evaluation shows the toolchain\neffectively removes identifying information while retaining semantic content.\nAs an illustrative application, we train a predictive model using embedding\nvectors derived from a small set of manually labeled summaries, demonstrating\nthe toolchain's capacity for semi-automated content analysis at scale.\n  By enabling structured, privacy-conscious analysis of sensitive documents,\nour toolchain opens new possibilities for large-scale research in domains where\ntextual data was previously inaccessible due to privacy and heterogeneity\nconstraints.", "AI": {"tldr": "\u8be5\u5de5\u5177\u94fe\u4f7f\u7528LLM\u6765\u533f\u540d\u5316\u548c\u6807\u51c6\u5316\u6cd5\u5f8b\u3001\u533b\u7597\u548c\u7ba1\u7406\u6587\u672c\uff0c\u4ee5\u4fbf\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\u3002", "motivation": "\u6765\u81ea\u6cd5\u5f8b\u3001\u533b\u7597\u548c\u884c\u653f\u6765\u6e90\u7684\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e3a\u516c\u5171\u536b\u751f\u548c\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u4e30\u5bcc\u4f46\u672a\u88ab\u5145\u5206\u5229\u7528\u7684\u8d44\u6e90\u3002\u7136\u800c\uff0c\u5927\u89c4\u6a21\u5206\u6790\u53d7\u5230\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\u7684\u963b\u788d\uff1a\u654f\u611f\u7684\u4e2a\u4eba\u8eab\u4efd\u4fe1\u606f\u7684\u5b58\u5728\uff0c\u4ee5\u53ca\u7ed3\u6784\u548c\u8bed\u8a00\u7684\u663e\u7740\u5f02\u8d28\u6027\u3002", "method": "\u8be5\u5de5\u5177\u94fe\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63d0\u793a\u6765\u6807\u51c6\u5316\u3001\u603b\u7ed3\u6587\u672c\uff0c\u5e76\u5728\u9700\u8981\u65f6\u5c06\u6587\u672c\u7ffb\u8bd1\u6210\u82f1\u8bed\u4ee5\u63d0\u9ad8\u53ef\u6bd4\u6027\u3002\u901a\u8fc7\u57fa\u4e8eLLM\u7684\u7f16\u8f91\u5b9e\u73b0\u533f\u540d\u5316\uff0c\u5e76\u8f85\u4ee5\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\uff0c\u4ee5\u6700\u5927\u9650\u5ea6\u5730\u964d\u4f4e\u6cc4\u9732\u98ce\u9669\u3002", "result": "\u6211\u4eec\u5728\u4e00\u4e2a\u5305\u542b10,842\u4efd\u745e\u5178\u6cd5\u9662\u5224\u51b3\u7684\u8bed\u6599\u5e93\u4e0a\u6f14\u793a\u4e86\u8be5\u5de5\u5177\u94fe\uff0c\u8fd9\u4e9b\u5224\u51b3\u5c5e\u4e8e\u300a\u8650\u5f85\u8005\u7167\u987e\u6cd5\u6848\u300b\uff08LVM\uff09\uff0c\u5305\u542b\u8d85\u8fc756,000\u9875\u3002\u6bcf\u4e2a\u6587\u6863\u90fd\u88ab\u5904\u7406\u6210\u533f\u540d\u3001\u6807\u51c6\u5316\u7684\u6458\u8981\uff0c\u5e76\u8f6c\u6362\u4e3a\u6587\u6863\u7ea7\u5d4c\u5165\u3002\u9a8c\u8bc1\uff0c\u5305\u62ec\u624b\u52a8\u5ba1\u67e5\u3001\u81ea\u52a8\u626b\u63cf\u548c\u9884\u6d4b\u8bc4\u4f30\uff0c\u8868\u660e\u8be5\u5de5\u5177\u94fe\u6709\u6548\u5730\u5220\u9664\u4e86\u8bc6\u522b\u4fe1\u606f\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u8bed\u4e49\u5185\u5bb9\u3002", "conclusion": "\u8be5\u5de5\u5177\u94fe\u901a\u8fc7\u5bf9\u654f\u611f\u6587\u6863\u8fdb\u884c\u7ed3\u6784\u5316\u548c\u4fdd\u62a4\u9690\u79c1\u7684\u5206\u6790\uff0c\u4e3a\u5927\u89c4\u6a21\u7814\u7a76\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\uff0c\u8fd9\u4e9b\u7814\u7a76\u9886\u57df\u4ee5\u524d\u7531\u4e8e\u9690\u79c1\u548c\u5f02\u6784\u6027\u9650\u5236\u800c\u65e0\u6cd5\u8bbf\u95ee\u6587\u672c\u6570\u636e\u3002"}}
{"id": "2507.10755", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10755", "abs": "https://arxiv.org/abs/2507.10755", "authors": ["Rina Khan", "Catherine Stinson"], "title": "Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias", "comment": null, "summary": "Facial expression recognition (FER) algorithms classify facial expressions\ninto emotions such as happy, sad, or angry. An evaluative challenge facing FER\nalgorithms is the fall in performance when detecting spontaneous expressions\ncompared to posed expressions. An ethical (and evaluative) challenge facing FER\nalgorithms is that they tend to perform poorly for people of some races and\nskin colors. These challenges are linked to the data collection practices\nemployed in the creation of FER datasets. In this study, we audit two\nstate-of-the-art FER datasets. We take random samples from each dataset and\nexamine whether images are spontaneous or posed. In doing so, we propose a\nmethodology for identifying spontaneous or posed images. We discover a\nsignificant number of images that were posed in the datasets purporting to\nconsist of in-the-wild images. Since performance of FER models vary between\nspontaneous and posed images, the performance of models trained on these\ndatasets will not represent the true performance if such models were to be\ndeployed in in-the-wild applications. We also observe the skin color of\nindividuals in the samples, and test three models trained on each of the\ndatasets to predict facial expressions of people from various races and skin\ntones. We find that the FER models audited were more likely to predict people\nlabeled as not white or determined to have dark skin as showing a negative\nemotion such as anger or sadness even when they were smiling. This bias makes\nsuch models prone to perpetuate harm in real life applications.", "AI": {"tldr": "FER \u7b97\u6cd5\u5728\u81ea\u53d1\u8868\u60c5\u548c\u4e0d\u540c\u79cd\u65cf\u7684\u4eba\u8138\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u6570\u636e\u96c6\u5b58\u5728\u504f\u5dee\u3002", "motivation": "\u4e0e\u6446\u62cd\u8868\u60c5\u76f8\u6bd4\uff0cFER \u7b97\u6cd5\u5728\u68c0\u6d4b\u81ea\u53d1\u8868\u60c5\u65f6\u6027\u80fd\u4e0b\u964d\u3002FER \u7b97\u6cd5\u9762\u4e34\u7684\u4f26\u7406\uff08\u548c\u8bc4\u4f30\uff09\u6311\u6218\u662f\uff0c\u5b83\u4eec\u5bf9\u4e8e\u67d0\u4e9b\u79cd\u65cf\u548c\u80a4\u8272\u7684\u4eba\u6765\u8bf4\uff0c\u5f80\u5f80\u8868\u73b0\u4e0d\u4f73\u3002\u8fd9\u4e9b\u6311\u6218\u4e0e FER \u6570\u636e\u96c6\u521b\u5efa\u8fc7\u7a0b\u4e2d\u91c7\u7528\u7684\u6570\u636e\u6536\u96c6\u5b9e\u8df5\u6709\u5173\u3002", "method": "\u6211\u4eec\u4ece\u6bcf\u4e2a\u6570\u636e\u96c6\u4e2d\u62bd\u53d6\u968f\u673a\u6837\u672c\uff0c\u5e76\u68c0\u67e5\u56fe\u50cf\u662f\u81ea\u53d1\u7684\u8fd8\u662f\u6446\u62cd\u7684\u3002\u5728\u8fd9\u6837\u505a\u65f6\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc6\u522b\u81ea\u53d1\u6216\u6446\u62cd\u56fe\u50cf\u7684\u65b9\u6cd5\u3002", "result": "\u6211\u4eec\u53d1\u73b0\u5927\u91cf\u56fe\u50cf\u662f\u5728\u58f0\u79f0\u7531\u91ce\u5916\u56fe\u50cf\u7ec4\u6210\u7684\u6570\u636e\u96c6\u4e2d\u6446\u62cd\u7684\u3002\u7531\u4e8e FER \u6a21\u578b\u5728\u81ea\u53d1\u56fe\u50cf\u548c\u6446\u62cd\u56fe\u50cf\u4e4b\u95f4\u7684\u6027\u80fd\u5404\u4e0d\u76f8\u540c\uff0c\u56e0\u6b64\u5982\u679c\u5c06\u6b64\u7c7b\u6a21\u578b\u90e8\u7f72\u5728\u91ce\u5916\u5e94\u7528\u4e2d\uff0c\u5219\u5728\u8fd9\u4e9b\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6a21\u578b\u7684\u6027\u80fd\u5c06\u65e0\u6cd5\u4ee3\u8868\u771f\u5b9e\u6027\u80fd\u3002", "conclusion": "FER \u6a21\u578b\u5728\u9884\u6d4b\u975e\u767d\u4eba\u6216\u6df1\u8272\u76ae\u80a4\u7684\u4eba\u7684\u9762\u90e8\u8868\u60c5\u65f6\uff0c\u66f4\u6709\u53ef\u80fd\u5c06\u5176\u9884\u6d4b\u4e3a\u8d1f\u9762\u60c5\u7eea\uff0c\u5373\u4f7f\u4ed6\u4eec\u5728\u5fae\u7b11\u3002\u8fd9\u79cd\u504f\u89c1\u4f7f\u5f97\u8fd9\u4e9b\u6a21\u578b\u5bb9\u6613\u5728\u73b0\u5b9e\u751f\u6d3b\u4e2d\u9020\u6210\u4f24\u5bb3\u3002"}}
{"id": "2507.10575", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10575", "abs": "https://arxiv.org/abs/2507.10575", "authors": ["Kieran Chai Kai Ren"], "title": "An Adaptive Volatility-based Learning Rate Scheduler", "comment": null, "summary": "Effective learning rate (LR) scheduling is crucial for training deep neural\nnetworks. However, popular pre-defined and adaptive schedulers can still lead\nto suboptimal generalization. This paper introduces VolSched, a novel adaptive\nLR scheduler inspired by the concept of volatility in stochastic processes like\nGeometric Brownian Motion to dynamically adjust the learning rate. By\ncalculating the ratio between long-term and short-term accuracy volatility,\nVolSched increases the LR to escape plateaus and decreases it to stabilize\ntraining, allowing the model to explore the loss landscape more effectively. We\nevaluate VolSched on the CIFAR-100 dataset against a strong baseline using a\nstandard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our\nscheduler delivers consistent performance gains, improving top-1 accuracy by\n1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals\nthat VolSched promotes a longer exploration phase. A quantitative analysis of\nthe Hessian shows that VolSched finds a final solution that is 38% flatter than\nthe next-best baseline, allowing the model to obtain wider minima and hence\nbetter generalization performance.", "AI": {"tldr": "VolSched, a volatility-inspired LR scheduler, enhances generalization by dynamically adjusting the learning rate, leading to performance gains on CIFAR-100.", "motivation": "Popular LR schedulers can lead to suboptimal generalization.", "method": "A novel adaptive LR scheduler inspired by volatility in stochastic processes.", "result": "VolSched improves top-1 accuracy by 1.4 and 1.3 percentage points on CIFAR-100 with ResNet-18 and ResNet-34, respectively.", "conclusion": "VolSched finds flatter solutions leading to better generalization."}}
{"id": "2507.10571", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2507.10571", "abs": "https://arxiv.org/abs/2507.10571", "authors": ["Konstantinos I. Roumeliotis", "Ranjan Sapkota", "Manoj Karkee", "Nikolaos D. Tselikas"], "title": "Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning", "comment": null, "summary": "Modern Artificial Intelligence (AI) increasingly relies on multi-agent\narchitectures that blend visual and language understanding. Yet, a pressing\nchallenge remains: How can we trust these agents especially in zero-shot\nsettings with no fine-tuning? We introduce a novel modular Agentic AI visual\nclassification framework that integrates generalist multimodal agents with a\nnon-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)\nmodule. Applied to apple leaf disease diagnosis, we benchmark three\nconfigurations: (I) zero-shot with confidence-based orchestration, (II)\nfine-tuned agents with improved performance, and (III) trust-calibrated\norchestration enhanced by CLIP-based image retrieval and re-evaluation loops.\nUsing confidence calibration metrics (ECE, OCR, CCC), the orchestrator\nmodulates trust across agents. Our results demonstrate a 77.94\\% accuracy\nimprovement in the zero-shot setting using trust-aware orchestration and RAG,\nachieving 85.63\\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL\ndisplayed overconfidence. Furthermore, image-RAG grounded predictions with\nvisually similar cases, enabling correction of agent overconfidence via\niterative re-evaluation. The proposed system separates perception (vision\nagents) from meta-reasoning (orchestrator), enabling scalable and interpretable\nmulti-agent AI. This blueprint is extensible to diagnostics, biology, and other\ntrust-critical domains. All models, prompts, results, and system components\nincluding the complete software source code are openly released to support\nreproducibility, transparency, and community benchmarking at Github:\nhttps://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust", "AI": {"tldr": "This paper presents a new AI framework for visual classification that uses multiple agents, a reasoning orchestrator, and RAG to improve accuracy and trust, especially in zero-shot scenarios, with significant improvements demonstrated in apple leaf disease diagnosis.", "motivation": "Trusting multi-agent AI systems in zero-shot settings is challenging. This paper addresses this by introducing a novel framework to improve trust and accuracy in such systems.", "method": "The study introduces a modular Agentic AI visual classification framework that combines multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. It benchmarks zero-shot, fine-tuned, and trust-calibrated configurations, using confidence calibration metrics (ECE, OCR, CCC) to modulate trust across agents and CLIP-based image retrieval for re-evaluation.", "result": "The framework achieves a 77.94% accuracy improvement in the zero-shot setting with trust-aware orchestration and RAG, reaching 85.63% overall. Image-RAG helps correct agent overconfidence through iterative re-evaluation. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence.", "conclusion": "The proposed modular Agentic AI framework, featuring trust-aware orchestration and RAG, significantly improves zero-shot accuracy in apple leaf disease diagnosis. The system's design, separating perception from meta-reasoning, offers scalability and interpretability for trust-critical domains."}}
{"id": "2507.10772", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10772", "abs": "https://arxiv.org/abs/2507.10772", "authors": ["Michal Podstawski"], "title": "Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs", "comment": null, "summary": "Labeled property graphs often contain rich textual attributes that can\nenhance analytical tasks when properly leveraged. This work explores the use of\npretrained text embedding models to enable efficient semantic analysis in such\ngraphs. By embedding textual node and edge properties, we support downstream\ntasks including node classification and relation prediction with improved\ncontextual understanding. Our approach integrates language model embeddings\ninto the graph pipeline without altering its structure, demonstrating that\ntextual semantics can significantly enhance the accuracy and interpretability\nof property graph analysis.", "AI": {"tldr": "\u5229\u7528\u9884\u8bad\u7ec3\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u5728\u4e0d\u6539\u53d8\u56fe\u7ed3\u6784\u7684\u60c5\u51b5\u4e0b\uff0c\u589e\u5f3a\u5c5e\u6027\u56fe\u7684\u8bed\u4e49\u5206\u6790\uff0c\u63d0\u9ad8\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u6807\u8bb0\u5c5e\u6027\u56fe\u901a\u5e38\u5305\u542b\u4e30\u5bcc\u7684\u6587\u672c\u5c5e\u6027\uff0c\u5982\u679c \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u5229\u7528\uff0c\u53ef\u4ee5\u589e\u5f3a\u5206\u6790\u4efb\u52a1\u3002", "method": "\u5c06\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u96c6\u6210\u5230\u56fe\u7ba1\u9053\u4e2d\uff0c\u800c\u4e0d\u6539\u53d8\u5176\u7ed3\u6784\u3002", "result": "\u901a\u8fc7\u5d4c\u5165\u6587\u672c\u8282\u70b9\u548c\u8fb9\u5c5e\u6027\uff0c\u6211\u4eec\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff0c\u5305\u62ec\u8282\u70b9\u5206\u7c7b\u548c\u5173\u7cfb\u9884\u6d4b\uff0c\u5e76\u5177\u6709\u6539\u8fdb\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u3002", "conclusion": "\u6587\u672c\u8bed\u4e49\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5c5e\u6027\u56fe\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2507.11505", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2507.11505", "abs": "https://arxiv.org/abs/2507.11505", "authors": ["Harsha Kokel", "Aamod Khatiwada", "Tejaswini Pedapati", "Haritha Ananthakrishnan", "Oktie Hassanzadeh", "Horst Samulowitz", "Kavitha Srinivas"], "title": "TOPJoin: A Context-Aware Multi-Criteria Approach for Joinable Column Search", "comment": "VLDB 2025 Workshop: Tabular Data Analysis (TaDA); The source code,\n  data, and/or other artifacts have been made available at\n  https://github.com/IBM/ContextAwareJoin", "summary": "One of the major challenges in enterprise data analysis is the task of\nfinding joinable tables that are conceptually related and provide meaningful\ninsights. Traditionally, joinable tables have been discovered through a search\nfor similar columns, where two columns are considered similar syntactically if\nthere is a set overlap or they are considered similar semantically if either\nthe column embeddings or value embeddings are closer in the embedding space.\nHowever, for enterprise data lakes, column similarity is not sufficient to\nidentify joinable columns and tables. The context of the query column is\nimportant. Hence, in this work, we first define context-aware column\njoinability. Then we propose a multi-criteria approach, called TOPJoin, for\njoinable column search. We evaluate TOPJoin against existing join search\nbaselines over one academic and one real-world join search benchmark. Through\nexperiments, we find that TOPJoin performs better on both benchmarks than the\nbaselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u5217\u8fde\u63a5\u6027\u7684\u591a\u6807\u51c6\u65b9\u6cd5TOPJoin\uff0c\u5e76\u5728\u5b66\u672f\u754c\u548c\u73b0\u5b9e\u4e16\u754c\u4e2d\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5728\u4f01\u4e1a\u6570\u636e\u5206\u6790\u4e2d\uff0c\u53d1\u73b0\u6982\u5ff5\u76f8\u5173\u4e14\u63d0\u4f9b\u6709\u610f\u4e49\u89c1\u89e3\u7684\u53ef\u8fde\u63a5\u8868\u662f\u4e00\u9879\u91cd\u5927\u6311\u6218\u3002\u5bf9\u4e8e\u4f01\u4e1a\u6570\u636e\u6e56\uff0c\u5217\u76f8\u4f3c\u6027\u4e0d\u8db3\u4ee5\u8bc6\u522b\u53ef\u8fde\u63a5\u7684\u5217\u548c\u8868\u3002\u67e5\u8be2\u5217\u7684\u4e0a\u4e0b\u6587\u975e\u5e38\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTOPJoin\u7684\u591a\u6807\u51c6\u65b9\u6cd5\uff0c\u7528\u4e8e\u53ef\u8fde\u63a5\u7684\u5217\u641c\u7d22\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\uff0c\u6211\u4eec\u53d1\u73b0TOPJoin\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "TOPJoin\u5728\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u3002"}}
{"id": "2507.10585", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10585", "abs": "https://arxiv.org/abs/2507.10585", "authors": ["Isar Nejadgholi", "Mona Omidyeganeh", "Marc-Antoine Drouin", "Jonathan Boisvert"], "title": "A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations", "comment": "Presented at the Workshop of Technical AI Governance, 5 pages 2\n  figures", "summary": "Effective AI governance requires structured approaches for stakeholders to\naccess and verify AI system behavior. With the rise of large language models,\nNatural Language Explanations (NLEs) are now key to articulating model\nbehavior, which necessitates a focused examination of their characteristics and\ngovernance implications. We draw on Explainable AI (XAI) literature to create\nan updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:\n(1) Context, including task, data, audience, and goals; (2) Generation and\nPresentation, covering generation methods, inputs, interactivity, outputs, and\nforms; and (3) Evaluation, focusing on content, presentation, and user-centered\nproperties, as well as the setting of the evaluation. This taxonomy provides a\nframework for researchers, auditors, and policymakers to characterize, design,\nand enhance NLEs for transparent AI systems.", "AI": {"tldr": "This paper presents an updated XAI taxonomy for prompt-based NLEs to improve AI governance and transparency.", "motivation": "Effective AI governance requires structured approaches for stakeholders to access and verify AI system behavior. With the rise of large language models, Natural Language Explanations (NLEs) are now key to articulating model behavior, which necessitates a focused examination of their characteristics and governance implications.", "method": "We draw on Explainable AI (XAI) literature to create an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, including task, data, audience, and goals; (2) Generation and Presentation, covering generation methods, inputs, interactivity, outputs, and forms; and (3) Evaluation, focusing on content, presentation, and user-centered properties, as well as the setting of the evaluation.", "result": "An updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, (2) Generation and Presentation, and (3) Evaluation.", "conclusion": "This taxonomy provides a framework for researchers, auditors, and policymakers to characterize, design, and enhance NLEs for transparent AI systems."}}
{"id": "2507.10770", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.10770", "abs": "https://arxiv.org/abs/2507.10770", "authors": ["Ionu\u0163 Grigore", "C\u0103lin-Adrian Popa", "Claudiu Leoveanu-Condrei"], "title": "FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching", "comment": null, "summary": "The extraction and matching of interest points are fundamental to many\ngeometric computer vision tasks. Traditionally, matching is performed by\nassigning descriptors to interest points and identifying correspondences based\non descriptor similarity. This work introduces a technique where interest\npoints are inherently associated during detection, eliminating the need for\ncomputing, storing, transmitting, or matching descriptors. Although the\nmatching accuracy is marginally lower than that of conventional approaches, our\nmethod completely eliminates the need for descriptors, leading to a drastic\nreduction in memory usage for localization systems. We assess its effectiveness\nby comparing it against both classical handcrafted methods and modern learned\napproaches.", "AI": {"tldr": "This paper introduces a descriptor-free interest point matching technique that reduces memory usage but sacrifices some accuracy.", "motivation": "The extraction and matching of interest points are fundamental to many geometric computer vision tasks. Traditionally, matching is performed by assigning descriptors to interest points and identifying correspondences based on descriptor similarity.", "method": "A technique where interest points are inherently associated during detection, eliminating the need for computing, storing, transmitting, or matching descriptors.", "result": "The matching accuracy is marginally lower than that of conventional approaches, and it drastically reduces memory usage.", "conclusion": "This method reduces memory usage for localization systems by eliminating the need for descriptors, but with marginally lower matching accuracy compared to conventional approaches."}}
{"id": "2507.10581", "categories": ["cs.LG", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2507.10581", "abs": "https://arxiv.org/abs/2507.10581", "authors": ["Esmail Gumaan"], "title": "Universal Approximation Theorem for a Single-Layer Transformer", "comment": "7 pages, 2 figures, 1 theorem, 10 formulas", "summary": "Deep learning employs multi-layer neural networks trained via the\nbackpropagation algorithm. This approach has achieved success across many\ndomains and relies on adaptive gradient methods such as the Adam optimizer.\nSequence modeling evolved from recurrent neural networks to attention-based\nmodels, culminating in the Transformer architecture. Transformers have achieved\nstate-of-the-art performance in natural language processing (for example, BERT\nand GPT-3) and have been applied in computer vision and computational biology.\nHowever, theoretical understanding of these models remains limited. In this\npaper, we examine the mathematical foundations of deep learning and\nTransformers and present a novel theoretical result. We review key concepts\nfrom linear algebra, probability, and optimization that underpin deep learning,\nand we analyze the multi-head self-attention mechanism and the backpropagation\nalgorithm in detail. Our main contribution is a universal approximation theorem\nfor Transformers: we prove that a single-layer Transformer, comprising one\nself-attention layer followed by a position-wise feed-forward network with ReLU\nactivation, can approximate any continuous sequence-to-sequence mapping on a\ncompact domain to arbitrary precision. We provide a formal statement and a\ncomplete proof. Finally, we present case studies that demonstrate the practical\nimplications of this result. Our findings advance the theoretical understanding\nof Transformer models and help bridge the gap between theory and practice.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u4e86\u5355\u5c42Transformer\u53ef\u4ee5\u903c\u8fd1\u4efb\u4f55\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u6620\u5c04\u3002", "motivation": "\u76ee\u524d\u5bf9\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u7406\u8bba\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002", "method": "\u672c\u6587\u6df1\u5165\u5206\u6790\u4e86\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\u548c\u53cd\u5411\u4f20\u64ad\u7b97\u6cd5\uff0c\u5e76\u7ed3\u5408\u7ebf\u6027\u4ee3\u6570\u3001\u6982\u7387\u548c\u4f18\u5316\u7b49\u5173\u952e\u6982\u5ff5\uff0c\u4e3a\u6df1\u5ea6\u5b66\u4e60\u548cTransformer\u7684\u6570\u5b66\u57fa\u7840\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6491\u3002", "result": "\u672c\u6587\u7684\u4e3b\u8981\u8d21\u732e\u662fTransformer\u7684\u901a\u7528\u903c\u8fd1\u5b9a\u7406\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86Transformer\u7684\u901a\u7528\u903c\u8fd1\u5b9a\u7406\uff0c\u8bc1\u660e\u4e86\u5355\u5c42Transformer\u53ef\u4ee5\u4ee5\u4efb\u610f\u7cbe\u5ea6\u903c\u8fd1\u7d27\u57df\u4e0a\u7684\u4efb\u4f55\u8fde\u7eed\u5e8f\u5217\u5230\u5e8f\u5217\u7684\u6620\u5c04\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u7ed3\u679c\u7684\u5b9e\u9645\u610f\u4e49\u3002"}}
{"id": "2507.10624", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.10624", "abs": "https://arxiv.org/abs/2507.10624", "authors": ["Zheng Zhang"], "title": "Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning", "comment": "Substantial change to previous version (experiments, theorem,\n  analysis and related work); currently under review at TMLR", "summary": "Large Language Models (LLMs) display striking surface fluency yet\nsystematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,\nand logical consistency. This paper offers a structural diagnosis of such\nfailures, revealing a persistent gap between \\textit{comprehension} and\n\\textit{competence}. Through controlled experiments and architectural analysis,\nwe demonstrate that LLMs often articulate correct principles without reliably\napplying them--a failure rooted not in knowledge access, but in computational\nexecution. We term this phenomenon the computational \\textit{split-brain\nsyndrome}, where instruction and action pathways are geometrically and\nfunctionally dissociated. This core limitation recurs across domains, from\nmathematical operations to relational inferences, and explains why model\nbehavior remains brittle even under idealized prompting. We argue that LLMs\nfunction as powerful pattern completion engines, but lack the architectural\nscaffolding for principled, compositional reasoning. Our findings delineate the\nboundary of current LLM capabilities and motivate future models with\nmetacognitive control, principle lifting, and structurally grounded execution.\nThis diagnosis also clarifies why mechanistic interpretability findings may\nreflect training-specific pattern coordination rather than universal\ncomputational principles, and why the geometric separation between instruction\nand execution pathways suggests limitations in neural introspection and\nmechanistic analysis.", "AI": {"tldr": "LLM\u5728\u9700\u8981\u63a8\u7406\u7684\u4efb\u52a1\u4e2d\u5931\u8d25\uff0c\u56e0\u4e3a\u5b83\u4eec\u7406\u89e3\u6982\u5ff5\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u5e94\u7528\u5b83\u4eec\uff0c\u8fd9\u662f\u7531\u4e8e\u6307\u4ee4\u548c\u6267\u884c\u8def\u5f84\u5206\u79bb\u9020\u6210\u7684\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8868\u9762\u4e0a\u8868\u73b0\u51fa\u60ca\u4eba\u7684\u6d41\u7545\u6027\uff0c\u4f46\u5728\u9700\u8981\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u7cbe\u5ea6\u548c\u903b\u8f91\u4e00\u81f4\u6027\u7684\u4efb\u52a1\u4e2d\u5374\u7cfb\u7edf\u6027\u5730\u5931\u8d25\u3002", "method": "\u901a\u8fc7\u5bf9\u7167\u5b9e\u9a8c\u548c\u67b6\u6784\u5206\u6790", "result": "LLM\u901a\u5e38\u53ef\u4ee5\u8868\u8fbe\u6b63\u786e\u7684\u539f\u5219\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u5e94\u7528\u5b83\u4eec\u3002\u6307\u4ee4\u548c\u6267\u884c\u8def\u5f84\u5728\u51e0\u4f55\u548c\u529f\u80fd\u4e0a\u5206\u79bb\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u9700\u8981\u7b26\u53f7\u63a8\u7406\u3001\u7b97\u672f\u7cbe\u5ea6\u548c\u903b\u8f91\u4e00\u81f4\u6027\u7684\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u7684\u4e0d\u8db3\uff0c\u8fd9\u6e90\u4e8e\u7406\u89e3\u548c\u80fd\u529b\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002LLM\u53ef\u4ee5\u8868\u8fbe\u6b63\u786e\u7684\u539f\u5219\uff0c\u4f46\u4e0d\u80fd\u53ef\u9760\u5730\u5e94\u7528\u5b83\u4eec\u3002\u8fd9\u79cd\u73b0\u8c61\u88ab\u79f0\u4e3a\u8ba1\u7b97\u201c\u88c2\u8111\u7efc\u5408\u75c7\u201d\uff0c\u662f\u7531\u4e8e\u6307\u4ee4\u548c\u6267\u884c\u8def\u5f84\u5728\u51e0\u4f55\u548c\u529f\u80fd\u4e0a\u5206\u79bb\u3002\u8fd9\u79cd\u6838\u5fc3\u9650\u5236\u5728\u6570\u5b66\u8fd0\u7b97\u548c\u5173\u7cfb\u63a8\u7406\u7b49\u9886\u57df\u53cd\u590d\u51fa\u73b0\u3002LLM\u4f5c\u4e3a\u5f3a\u5927\u7684\u6a21\u5f0f\u5b8c\u6210\u5f15\u64ce\u8fd0\u884c\uff0c\u4f46\u7f3a\u4e4f\u539f\u5219\u6027\u548c\u7ec4\u5408\u63a8\u7406\u7684\u67b6\u6784\u652f\u6491\u3002\u8fd9\u4e9b\u53d1\u73b0\u754c\u5b9a\u4e86\u5f53\u524dLLM\u80fd\u529b\u7684\u8fb9\u754c\uff0c\u5e76\u4fc3\u4f7f\u672a\u6765\u7684\u6a21\u578b\u5177\u6709\u5143\u8ba4\u77e5\u63a7\u5236\u3001\u539f\u5219\u63d0\u5347\u548c\u7ed3\u6784\u5316\u6267\u884c\u3002"}}
{"id": "2507.10803", "categories": ["cs.AI", "cs.CL", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.10803", "abs": "https://arxiv.org/abs/2507.10803", "authors": ["JaMor Hairston", "Ritvik Ranjan", "Sahithi Lakamana", "Anthony Spadaro", "Selen Bozkurt", "Jeanmarie Perrone", "Abeed Sarker"], "title": "Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case", "comment": "Pages: 19, Abstract word count: 151 words, Manuscript word count:\n  2185 words, References: 14, Figures: 3, Tables: 2", "summary": "Background Large language models (LLMs) face challenges in inductive thematic\nanalysis, a task requiring deep interpretive and domain-specific expertise. We\nevaluated the feasibility of using LLMs to replicate expert-driven thematic\nanalysis of social media data. Methods Using two temporally non-intersecting\nReddit datasets on xylazine (n=286 and n=686, for model optimization and\nvalidation, respectively) with twelve expert-derived themes, we evaluated five\nLLMs against expert coding. We modeled the task as a series of binary\nclassifications, rather than a single, multi-label classification, employing\nzero-, single-, and few-shot prompting strategies and measuring performance via\naccuracy, precision, recall, and F1-score. Results On the validation set,\nGPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:\n0.71). For high-prevalence themes, model-derived thematic distributions closely\nmirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:\n16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based\napproaches can automate thematic analyses, offering a scalable supplement for\nqualitative research. Keywords: thematic analysis, large language models,\nnatural language processing, qualitative analysis, social media, prompt\nengineering, public health", "AI": {"tldr": "LLMs, especially GPT-4o with few-shot prompting, can automate thematic analysis of social media data with high accuracy, providing a scalable tool for qualitative research.", "motivation": "LLMs face challenges in inductive thematic analysis, a task requiring deep interpretive and domain-specific expertise. The study evaluates the feasibility of using LLMs to replicate expert-driven thematic analysis of social media data.", "method": "Evaluated five LLMs against expert coding using two Reddit datasets on xylazine, modeling the task as binary classifications with zero-, single-, and few-shot prompting.", "result": "GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score: 0.71). Model-derived thematic distributions closely mirrored expert classifications for high-prevalence themes.", "conclusion": "Few-shot LLM-based approaches can automate thematic analyses, offering a scalable supplement for qualitative research."}}
{"id": "2507.10586", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.10586", "abs": "https://arxiv.org/abs/2507.10586", "authors": ["Kaushik Dwivedi", "Padmanabh Patanjali Mishra"], "title": "AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable fluency across a\nrange of natural language tasks, yet remain vulnerable to hallucinations -\nfactual inaccuracies that undermine trust in real world deployment. We present\nAutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that\ntackles hallucination in large language models through lightweight LoRA-based\nadapters and KL-regularized training. Our pipeline integrates automated prompt\nrewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in\nretrieved evidence. A hallucination detection module, using both\nclassifier-based and self-evaluation techniques, assigns confidence scores to\ngenerated outputs, triggering an optional feedback correction loop. This loop\nenforces factual alignment via contrastive KL loss and adapter fine tuning. We\ndemonstrate that AutoRAG-LoRA significantly reduces the factual drift while\npreserving the efficiency and modularity of the model.", "AI": {"tldr": "AutoRAG-LoRA\u662f\u4e00\u4e2aRAG\u6846\u67b6\uff0c\u5b83\u4f7f\u7528LoRA\u9002\u914d\u5668\u548cKL\u6b63\u5219\u5316\u8bad\u7ec3\u6765\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e00\u7cfb\u5217\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4e86\u5353\u8d8a\u7684\u6d41\u7545\u6027\uff0c\u4f46\u4ecd\u7136\u5bb9\u6613\u51fa\u73b0\u5e7b\u89c9\u2014\u2014\u4e8b\u5b9e\u6027\u4e0d\u51c6\u786e\uff0c\u8fd9\u7834\u574f\u4e86\u5bf9\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u7684\u4fe1\u4efb\u3002", "method": "AutoRAG-LoRA\uff0c\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u57fa\u4e8eLoRA\u7684\u9002\u914d\u5668\u548cKL\u6b63\u5219\u5316\u8bad\u7ec3\u6765\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u3002", "result": "\u5e7b\u89c9\u68c0\u6d4b\u6a21\u5757\uff0c\u4f7f\u7528\u57fa\u4e8e\u5206\u7c7b\u5668\u548c\u81ea\u6211\u8bc4\u4f30\u6280\u672f\uff0c\u4e3a\u751f\u6210\u7684\u8f93\u51fa\u5206\u914d\u7f6e\u4fe1\u5ea6\u5206\u6570\uff0c\u89e6\u53d1\u53ef\u9009\u7684\u53cd\u9988\u6821\u6b63\u5faa\u73af\u3002\u8be5\u5faa\u73af\u901a\u8fc7\u5bf9\u6bd4KL\u635f\u5931\u548c\u9002\u914d\u5668\u5fae\u8c03\u6765\u52a0\u5f3a\u4e8b\u5b9e\u5bf9\u9f50\u3002", "conclusion": "AutoRAG-LoRA\u663e\u8457\u51cf\u5c11\u4e86\u4e8b\u5b9e\u6027\u6f02\u79fb\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u6548\u7387\u548c\u6a21\u5757\u5316\u3002"}}
{"id": "2507.10775", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.10775", "abs": "https://arxiv.org/abs/2507.10775", "authors": ["Jeffrey Joan Sam", "Janhavi Sathe", "Nikhil Chigali", "Naman Gupta", "Radhey Ruparel", "Yicheng Jiang", "Janmajay Singh", "James W. Berck", "Arko Barman"], "title": "A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers", "comment": null, "summary": "Spacecraft deployed in outer space are routinely subjected to various forms\nof damage due to exposure to hazardous environments. In addition, there are\nsignificant risks to the subsequent process of in-space repairs through human\nextravehicular activity or robotic manipulation, incurring substantial\noperational costs. Recent developments in image segmentation could enable the\ndevelopment of reliable and cost-effective autonomous inspection systems. While\nthese models often require large amounts of training data to achieve\nsatisfactory results, publicly available annotated spacecraft segmentation data\nare very scarce. Here, we present a new dataset of nearly 64k annotated\nspacecraft images that was created using real spacecraft models, superimposed\non a mixture of real and synthetic backgrounds generated using NASA's TTALOS\npipeline. To mimic camera distortions and noise in real-world image\nacquisition, we also added different types of noise and distortion to the\nimages. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to\ngenerate performance benchmarks for the dataset under well-defined hardware and\ninference time constraints to mimic real-world image segmentation challenges\nfor real-time onboard applications in space on NASA's inspector spacecraft. The\nresulting models, when tested under these constraints, achieved a Dice score of\n0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.\nThe dataset and models for performance benchmark are available at\nhttps://github.com/RiceD2KLab/SWiM.", "AI": {"tldr": "A new dataset of 64k annotated spacecraft images was created and used to finetune YOLO models for autonomous inspection systems, achieving a Dice score of 0.92 and Hausdorff distance of 0.69 with an inference time of about 0.5 second.", "motivation": "Spacecraft in outer space are subjected to damage, and in-space repairs are costly. Image segmentation can enable cost-effective autonomous inspection systems, but annotated spacecraft segmentation data are scarce.", "method": "Finetuned YOLOv8 and YOLOv11 segmentation models", "result": "A new dataset of nearly 64k annotated spacecraft images was created using real spacecraft models, superimposed on a mixture of real and synthetic backgrounds. The dataset and models for performance benchmark are available at https://github.com/RiceD2KLab/SWiM.", "conclusion": "The finetuned YOLOv8 and YOLOv11 segmentation models achieved a Dice score of 0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second under defined hardware and inference time constraints."}}
{"id": "2507.10591", "categories": ["cs.LG", "cs.AI", "cs.CR", "cs.PF", "68T01", "I.2"], "pdf": "https://arxiv.org/pdf/2507.10591", "abs": "https://arxiv.org/abs/2507.10591", "authors": ["Vanderson Rocha", "Diego Kreutz", "Gabriel Canto", "Hendrio Bragan\u00e7a", "Eduardo Feitosa"], "title": "MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation", "comment": "11 pages; 4 figures; 5 tables; submitted to JBCS", "summary": "Feature selection is vital for building effective predictive models, as it\nreduces dimensionality and emphasizes key features. However, current research\noften suffers from limited benchmarking and reliance on proprietary datasets.\nThis severely hinders reproducibility and can negatively impact overall\nperformance. To address these limitations, we introduce the MH-FSF framework, a\ncomprehensive, modular, and extensible platform designed to facilitate the\nreproduction and implementation of feature selection methods. Developed through\ncollaborative research, MH-FSF provides implementations of 17 methods (11\nclassical, 6 domain-specific) and enables systematic evaluation on 10 publicly\navailable Android malware datasets. Our results reveal performance variations\nacross both balanced and imbalanced datasets, highlighting the critical need\nfor data preprocessing and selection criteria that account for these\nasymmetries. We demonstrate the importance of a unified platform for comparing\ndiverse feature selection techniques, fostering methodological consistency and\nrigor. By providing this framework, we aim to significantly broaden the\nexisting literature and pave the way for new research directions in feature\nselection, particularly within the context of Android malware detection.", "AI": {"tldr": "MH-FSF\u662f\u4e00\u4e2a\u7279\u5f81\u9009\u62e9\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u53ef\u91cd\u590d\u6027\u95ee\u9898\uff0c\u5e76\u5728Android\u6076\u610f\u8f6f\u4ef6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8617\u79cd\u65b9\u6cd5\uff0c\u7ed3\u679c\u5f3a\u8c03\u4e86\u6570\u636e\u9884\u5904\u7406\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u7814\u7a76\u901a\u5e38\u53d7\u5230\u6709\u9650\u7684\u57fa\u51c6\u6d4b\u8bd5\u548c\u5bf9\u4e13\u6709\u6570\u636e\u96c6\u7684\u4f9d\u8d56\u7684\u56f0\u6270\uff0c\u8fd9\u4e25\u91cd\u963b\u788d\u4e86\u53ef\u91cd\u590d\u6027\uff0c\u5e76\u53ef\u80fd\u5bf9\u6574\u4f53\u6027\u80fd\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\u3002", "method": "MH-FSF\u6846\u67b6\uff0c\u4e00\u4e2a\u7efc\u5408\u7684\u3001\u6a21\u5757\u5316\u7684\u548c\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u65e8\u5728\u4fc3\u8fdb\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u7684\u91cd\u73b0\u548c\u5b9e\u65bd\u3002", "result": "\u7ed3\u679c\u63ed\u793a\u4e86\u5e73\u8861\u548c\u4e0d\u5e73\u8861\u6570\u636e\u96c6\u7684\u6027\u80fd\u53d8\u5316\uff0c\u7a81\u51fa\u4e86\u6570\u636e\u9884\u5904\u7406\u548c\u9009\u62e9\u6807\u51c6\u7684\u5173\u952e\u9700\u6c42\uff0c\u8fd9\u4e9b\u6807\u51c6\u8003\u8651\u4e86\u8fd9\u4e9b\u4e0d\u5bf9\u79f0\u6027\u3002", "conclusion": "MH-FSF\u5e73\u53f0\u80fd\u591f\u6bd4\u8f83\u4e0d\u540c\u7684\u7279\u5f81\u9009\u62e9\u6280\u672f\uff0c\u4fc3\u8fdb\u65b9\u6cd5\u5b66\u7684\u4e00\u81f4\u6027\u548c\u4e25\u8c28\u6027\u3002\u8be5\u6846\u67b6\u65e8\u5728\u62d3\u5c55\u73b0\u6709\u6587\u732e\uff0c\u5e76\u4e3a\u7279\u5f81\u9009\u62e9\u7684\u65b0\u7814\u7a76\u65b9\u5411\u94fa\u5e73\u9053\u8def\uff0c\u7279\u522b\u662f\u5728Android\u6076\u610f\u8f6f\u4ef6\u68c0\u6d4b\u7684\u80cc\u666f\u4e0b\u3002"}}
{"id": "2507.10630", "categories": ["cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2507.10630", "abs": "https://arxiv.org/abs/2507.10630", "authors": ["Ye Yang", "Xue Xiao", "Ping Yin", "Taotao Xie"], "title": "Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs", "comment": null, "summary": "API calls by large language models (LLMs) offer a cutting-edge approach for\ndata analysis. However, their ability to effectively utilize tools via API\ncalls remains underexplored in knowledge-intensive domains like meteorology.\nThis paper introduces KG2data, a system that integrates knowledge graphs, LLMs,\nReAct agents, and tool-use technologies to enable intelligent data acquisition\nand query handling in the meteorological field. Using a virtual API, we\nevaluate API call accuracy across three metrics: name recognition failure,\nhallucination failure, and call correctness. KG2data achieves superior\nperformance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and\nchat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based\nsystems by addressing their limited access to domain-specific knowledge, which\nhampers performance on complex or terminology-rich queries. By using a\nknowledge graph as persistent memory, our system enhances content retrieval,\ncomplex query handling, domain-specific reasoning, semantic relationship\nresolution, and heterogeneous data integration. It also mitigates the high cost\nof fine-tuning LLMs, making the system more adaptable to evolving domain\nknowledge and API structures. In summary, KG2data provides a novel solution for\nintelligent, knowledge-based question answering and data analysis in domains\nwith high knowledge demands.", "AI": {"tldr": "KG2data \u662f\u4e00\u79cd\u5229\u7528\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6c14\u8c61\u9886\u57df\u6570\u636e\u5206\u6790\u80fd\u529b\u7684\u7cfb\u7edf\uff0c\u5b83\u901a\u8fc7\u63d0\u9ad8\u5185\u5bb9\u68c0\u7d22\u3001\u590d\u6742\u67e5\u8be2\u5904\u7406\u548c\u9886\u57df\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728 API \u8c03\u7528\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u7cfb\u7edf\uff0c\u4ece\u800c\u4e3a\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u7684 API \u8c03\u7528\u4e3a\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u524d\u6cbf\u65b9\u6cd5\u3002\u7136\u800c\uff0c\u5b83\u4eec\u901a\u8fc7 API \u8c03\u7528\u6709\u6548\u5229\u7528\u5de5\u5177\u7684\u80fd\u529b\u5728\u6c14\u8c61\u7b49\u77e5\u8bc6\u5bc6\u96c6\u578b\u9886\u57df\u4ecd\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3a KG2data \u7684\u7cfb\u7edf\uff0c\u8be5\u7cfb\u7edf\u96c6\u6210\u4e86\u77e5\u8bc6\u56fe\u8c31\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM)\u3001ReAct \u4ee3\u7406\u548c\u5de5\u5177\u4f7f\u7528\u6280\u672f\uff0c\u4ee5\u5b9e\u73b0\u5728\u6c14\u8c61\u9886\u57df\u4e2d\u7684\u667a\u80fd\u6570\u636e\u91c7\u96c6\u548c\u67e5\u8be2\u5904\u7406\u3002", "result": "KG2data \u5728\u540d\u79f0\u8bc6\u522b\u5931\u8d25\u7387\uff081.43%\uff09\u3001\u5e7b\u89c9\u5931\u8d25\u7387 (0%) \u548c\u8c03\u7528\u6b63\u786e\u7387 (88.57%) \u4e09\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e RAG2data (16%, 10%, 72.14%) \u548c chat2data (7.14%, 8.57%, 71.43%)\u3002", "conclusion": "KG2data \u4e3a\u9ad8\u77e5\u8bc6\u9700\u6c42\u7684\u9886\u57df\u4e2d\u7684\u667a\u80fd\u3001\u57fa\u4e8e\u77e5\u8bc6\u7684\u95ee\u7b54\u548c\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
