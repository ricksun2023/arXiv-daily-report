<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 19]
- [cs.CV](#cs.CV) [Total: 19]
- [cs.AI](#cs.AI) [Total: 23]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 15]
- [cs.LG](#cs.LG) [Total: 20]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Dialogue Annotation with Speaker Characteristics Leveraging a Frozen LLM](https://arxiv.org/abs/2508.04795)
*Thomas Thebaud,Yen-Ju Lu,Matthew Wiesner,Peter Viechnicki,Najim Dehak*

Main category: cs.CL

TL;DR: using frozen audio foundation models with a frozen LLAMA language model to infer speaker attributes, without requiring task-specific fine-tuning of either model


<details>
  <summary>Details</summary>
Motivation: enriching transcribed dialogues by adding metadata tags for speaker characteristics such as age, gender, and emotion to improve grammar, punctuation, and readability.

Method: coupling frozen audio foundation models, such as Whisper or WavLM, with a frozen LLAMA language model to infer these speaker attributes, without requiring task-specific fine-tuning of either model. Using lightweight, efficient connectors to bridge audio and language representations

Result: achieve competitive performance on speaker profiling tasks while preserving modularity and speed

Conclusion: A frozen LLAMA model can compare x-vectors directly, achieving an Equal Error Rate of 8.8% in some scenarios.

Abstract: In dialogue transcription pipelines, Large Language Models (LLMs) are
frequently employed in post-processing to improve grammar, punctuation, and
readability. We explore a complementary post-processing step: enriching
transcribed dialogues by adding metadata tags for speaker characteristics such
as age, gender, and emotion. Some of the tags are global to the entire
dialogue, while some are time-variant. Our approach couples frozen audio
foundation models, such as Whisper or WavLM, with a frozen LLAMA language model
to infer these speaker attributes, without requiring task-specific fine-tuning
of either model. Using lightweight, efficient connectors to bridge audio and
language representations, we achieve competitive performance on speaker
profiling tasks while preserving modularity and speed. Additionally, we
demonstrate that a frozen LLAMA model can compare x-vectors directly, achieving
an Equal Error Rate of 8.8% in some scenarios.

</details>


### [2] [Parity-Aware Byte-Pair Encoding: Improving Cross-lingual Fairness in Tokenization](https://arxiv.org/abs/2508.04796)
*Negar Foroutan,Clara Meister,Debjit Paul,Joel Niklaus,Sina Ahmadi,Antoine Bosselut,Rico Sennrich*

Main category: cs.CL

TL;DR: Parity-aware BPE 是一种 BPE 算法的变体，它通过优化压缩效果最差的语言来提高跨语言的公平性，而不会显著降低全局性能。


<details>
  <summary>Details</summary>
Motivation: 标准的分词算法依赖于基于频率的目标，这有利于训练数据中占主导地位的语言，因此，低资源语言的分词结果 disproportionately longer, morphologically implausible, or even riddled with <UNK> placeholders。这种现象最终加剧了不同语言背景用户之间的计算和经济不平等。

Method: 引入 Parity-aware Byte Pair Encoding (BPE)，这是一种广泛使用的 BPE 算法的变体。在每个合并步骤中，Parity-aware BPE 最大化当前压缩效果最差的语言的压缩增益，从而以少量全局压缩为代价来实现跨语言的公平性。

Result: Parity-aware BPE 可以在不同语言之间实现更公平的 token 数量，对全局压缩率的影响可以忽略不计，并且对下游任务中语言模型的性能没有实质性影响。

Conclusion: Parity-aware BPE 可以在保证全局压缩率和下游任务中语言模型性能不受实质影响的情况下，实现更公平的跨语言 token 数量。

Abstract: Tokenization is the first -- and often least scrutinized -- step of most NLP
pipelines. Standard algorithms for learning tokenizers rely on frequency-based
objectives, which favor languages dominant in the training data and
consequently leave lower-resource languages with tokenizations that are
disproportionately longer, morphologically implausible, or even riddled with
<UNK> placeholders. This phenomenon ultimately amplifies computational and
financial inequalities between users from different language backgrounds. To
remedy this, we introduce Parity-aware Byte Pair Encoding (BPE), a variant of
the widely-used BPE algorithm. At every merge step, Parity-aware BPE maximizes
the compression gain of the currently worst-compressed language, trading a
small amount of global compression for cross-lingual parity. We find
empirically that Parity-aware BPE leads to more equitable token counts across
languages, with negligible impact on global compression rate and no substantial
effect on language-model performance in downstream tasks.

</details>


### [3] [Pitch Accent Detection improves Pretrained Automatic Speech Recognition](https://arxiv.org/abs/2508.04814)
*David Sasu,Natalie Schluter*

Main category: cs.CL

TL;DR: Joint ASR and pitch accent detection model boosts ASR performance and improves pitch accent detection.


<details>
  <summary>Details</summary>
Motivation: boosting the performance of Automatic Speech Recognition (ASR) systems that use semi-supervised speech representations

Method: introducing a joint ASR and pitch accent detection model

Result: the ASR performance in joint training decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning, the pitch accent detection component of our model achieves a significant improvement on the state-of-the-art for the task, closing the gap in F1-score by 41%

Conclusion: Extending pretrained speech models to retain or re-learn important prosodic cues such as pitch accent is important.

Abstract: We show the performance of Automatic Speech Recognition (ASR) systems that
use semi-supervised speech representations can be boosted by a complimentary
pitch accent detection module, by introducing a joint ASR and pitch accent
detection model. The pitch accent detection component of our model achieves a
significant improvement on the state-of-the-art for the task, closing the gap
in F1-score by 41%. Additionally, the ASR performance in joint training
decreases WER by 28.3% on LibriSpeech, under limited resource fine-tuning. With
these results, we show the importance of extending pretrained speech models to
retain or re-learn important prosodic cues such as pitch accent.

</details>


### [4] [Persistent Instability in LLM's Personality Measurements: Effects of Scale, Reasoning, and Conversation History](https://arxiv.org/abs/2508.04826)
*Tommaso Tosato,Saskia Helbling,Yorguin-Jose Mantilla-Ramos,Mahmood Hegazy,Alberto Tosato,David John Lemay,Irina Rish,Guillaume Dumas*

Main category: cs.CL

TL;DR: 大型语言模型在规模和缓解策略方面表现出持续的不稳定性，这表明当前的大型语言模型缺乏真正行为一致性的基础。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型需要一致的行为模式才能安全部署，但其类似人格的特征仍然知之甚少。

Method: 使用传统和新颖的LLM调整人格工具，系统地改变问题顺序、释义、角色和推理模式，对25+开源模型（1B-671B参数）在500,000+响应中进行测试。

Result: 即使是400B+的模型也表现出很大的响应可变性; 提示的微小重新排序会使人格测量改变高达20%; 旨在稳定行为的干预措施，例如思维链推理、详细的角色指令、包含对话历史记录，反而会增加可变性; 经LLM调整的工具显示出与以人为中心的版本相同的 不稳定性，证实了架构而不是翻译的局限性。

Conclusion: 当前的大型语言模型缺乏真正的行为一致性的基础，对于需要可预测行为的安全关键型应用，基于人格的对齐策略可能从根本上不足。

Abstract: Large language models require consistent behavioral patterns for safe
deployment, yet their personality-like traits remain poorly understood. We
present PERSIST (PERsonality Stability in Synthetic Text), a comprehensive
evaluation framework testing 25+ open-source models (1B-671B parameters) across
500,000+ responses. Using traditional (BFI-44, SD3) and novel LLM-adapted
personality instruments, we systematically vary question order, paraphrasing,
personas, and reasoning modes. Our findings challenge fundamental deployment
assumptions: (1) Even 400B+ models exhibit substantial response variability (SD
> 0.4); (2) Minor prompt reordering alone shifts personality measurements by up
to 20%; (3) Interventions expected to stabilize behavior, such as
chain-of-thought reasoning, detailed personas instruction, inclusion of
conversation history, can paradoxically increase variability; (4) LLM-adapted
instruments show equal instability to human-centric versions, confirming
architectural rather than translational limitations. This persistent
instability across scales and mitigation strategies suggests current LLMs lack
the foundations for genuine behavioral consistency. For safety-critical
applications requiring predictable behavior, these findings indicate that
personality-based alignment strategies may be fundamentally inadequate.

</details>


### [5] [RCR-Router: Efficient Role-Aware Context Routing for Multi-Agent LLM Systems with Structured Memory](https://arxiv.org/abs/2508.04903)
*Jun Liu,Zhenglun Kong,Changdi Yang,Fan Yang,Tianqi Li,Peiyan Dong,Joannah Nanjekye,Hao Tang,Geng Yuan,Wei Niu,Wenbin Zhang,Pu Zhao,Xue Lin,Dong Huang,Yanzhi Wang*

Main category: cs.CL

TL;DR: RCR-Router通过动态选择记忆子集和优化token使用，提升了多代理LLM系统的效率和答案质量。


<details>
  <summary>Details</summary>
Motivation: 现有的多代理LLM系统中的协调方案依赖于静态或完全上下文路由策略，导致过度的token消耗、冗余的记忆暴露和有限的跨交互轮次适应性。

Method: RCR-Router，一种模块化和角色感知的上下文路由框架，它基于角色和任务阶段为每个代理动态选择语义相关的记忆子集，同时遵守严格的token预算。轻量级评分策略指导记忆选择，并且代理输出被迭代地集成到共享记忆存储中，以促进渐进式上下文细化。

Result: 在三个多跳QA基准测试（HotPotQA、MuSiQue和2WikiMultihop）上的实验表明，RCR-Router减少了token使用（高达30%），同时提高或保持了答案质量。

Conclusion: RCR-Router通过在多跳QA基准测试中减少token使用并提高或保持答案质量，证明了结构化记忆路由和输出感知评估在推进可扩展多代理LLM系统中的重要性。

Abstract: Multi-agent large language model (LLM) systems have shown strong potential in
complex reasoning and collaborative decision-making tasks. However, most
existing coordination schemes rely on static or full-context routing
strategies, which lead to excessive token consumption, redundant memory
exposure, and limited adaptability across interaction rounds. We introduce
RCR-Router, a modular and role-aware context routing framework designed to
enable efficient, adaptive collaboration in multi-agent LLMs. To our knowledge,
this is the first routing approach that dynamically selects semantically
relevant memory subsets for each agent based on its role and task stage, while
adhering to a strict token budget. A lightweight scoring policy guides memory
selection, and agent outputs are iteratively integrated into a shared memory
store to facilitate progressive context refinement. To better evaluate model
behavior, we further propose an Answer Quality Score metric that captures
LLM-generated explanations beyond standard QA accuracy. Experiments on three
multi-hop QA benchmarks -- HotPotQA, MuSiQue, and 2WikiMultihop -- demonstrate
that RCR-Router reduces token usage (up to 30%) while improving or maintaining
answer quality. These results highlight the importance of structured memory
routing and output-aware evaluation in advancing scalable multi-agent LLM
systems.

</details>


### [6] [I Think, Therefore I Am Under-Qualified? A Benchmark for Evaluating Linguistic Shibboleth Detection in LLM Hiring Evaluations](https://arxiv.org/abs/2508.04939)
*Julia Kharchenko,Tanya Roosta,Aman Chadha,Chirag Shah*

Main category: cs.CL

TL;DR: The paper introduces a benchmark to evaluate demographic bias in LLMs based on linguistic shibboleths. It finds that LLMs penalize certain linguistic patterns, like hedging, and the benchmark can effectively identify model-specific biases.


<details>
  <summary>Details</summary>
Motivation: This paper introduces a comprehensive benchmark for evaluating how Large Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic markers that can inadvertently reveal demographic attributes such as gender, social class, or regional background.

Method: Through carefully constructed interview simulations using 100 validated question-response pairs, the authors demonstrate how LLMs systematically penalize certain linguistic patterns, particularly hedging language, despite equivalent content quality. The benchmark generates controlled linguistic variations that isolate specific phenomena while maintaining semantic equivalence, which enables the precise measurement of demographic bias in automated evaluation systems.

Result: Hedged responses receive 25.6% lower ratings on average, and demonstrate the benchmark's effectiveness in identifying model-specific biases.

Conclusion: This work establishes a foundational framework for detecting and measuring linguistic discrimination in AI systems, with broad applications to fairness in automated decision-making contexts.

Abstract: This paper introduces a comprehensive benchmark for evaluating how Large
Language Models (LLMs) respond to linguistic shibboleths: subtle linguistic
markers that can inadvertently reveal demographic attributes such as gender,
social class, or regional background. Through carefully constructed interview
simulations using 100 validated question-response pairs, we demonstrate how
LLMs systematically penalize certain linguistic patterns, particularly hedging
language, despite equivalent content quality. Our benchmark generates
controlled linguistic variations that isolate specific phenomena while
maintaining semantic equivalence, which enables the precise measurement of
demographic bias in automated evaluation systems. We validate our approach
along multiple linguistic dimensions, showing that hedged responses receive
25.6% lower ratings on average, and demonstrate the benchmark's effectiveness
in identifying model-specific biases. This work establishes a foundational
framework for detecting and measuring linguistic discrimination in AI systems,
with broad applications to fairness in automated decision-making contexts.

</details>


### [7] [Towards Robust Evaluation of Visual Activity Recognition: Resolving Verb Ambiguity with Sense Clustering](https://arxiv.org/abs/2508.04945)
*Louie Hong Yao,Nicholas Jarvis,Tianyu Jiang*

Main category: cs.CL

TL;DR: 提出了一种基于聚类的视觉活动识别系统评估框架，以解决传统评估方法中存在的模糊性问题，并提高了与人类判断的一致性。


<details>
  <summary>Details</summary>
Motivation: 由于动词语义和图像理解的模糊性，评估视觉活动识别系统具有挑战性。标准精确匹配评估无法捕捉这些模糊性，导致模型性能评估不完整。

Method: 提出了一种视觉-语言聚类框架，构建动词语义簇。

Result: 每个图像平均映射到 2.8 个语义簇，每个簇代表图像的一个不同视角。

Conclusion: 聚类评估方法与人类判断更吻合，能更准确地评估模型性能。

Abstract: Evaluating visual activity recognition systems is challenging due to inherent
ambiguities in verb semantics and image interpretation. When describing actions
in images, synonymous verbs can refer to the same event (e.g., brushing vs.
grooming), while different perspectives can lead to equally valid but distinct
verb choices (e.g., piloting vs. operating). Standard exact-match evaluation,
which relies on a single gold answer, fails to capture these ambiguities,
resulting in an incomplete assessment of model performance. To address this, we
propose a vision-language clustering framework that constructs verb sense
clusters, providing a more robust evaluation. Our analysis of the imSitu
dataset shows that each image maps to an average of 2.8 sense clusters, with
each cluster representing a distinct perspective of the image. We evaluate
multiple activity recognition models and compare our cluster-based evaluation
with standard evaluation methods. Additionally, our human alignment analysis
suggests that the cluster-based evaluation better aligns with human judgements,
offering a more nuanced assessment of model performance.

</details>


### [8] [A Multi-Stage Large Language Model Framework for Extracting Suicide-Related Social Determinants of Health](https://arxiv.org/abs/2508.05003)
*Song Wang,Yishu Wei,Haotian Ma,Max Lovitt,Kelly Deng,Yuan Meng,Zihan Xu,Jingze Zhang,Yunyu Xiao,Ying Ding,Xuhai Xu,Joydeep Ghosh,Yifan Peng*

Main category: cs.CL

TL;DR: 提出了一种多阶段大型语言模型框架，以提高从非结构化文本中提取健康社会决定因素 (SDoH) 的准确性和透明度，从而支持早期识别高危个体并为更有效的预防策略提供信息。


<details>
  <summary>Details</summary>
Motivation: 理解导致自杀事件的健康社会决定因素 (SDoH) 对于早期干预和预防至关重要。然而，以数据驱动的方法来实现这一目标面临着诸如长尾因素分布、分析自杀事件前的关键应激因素以及模型可解释性有限等挑战。

Method: 提出了一个多阶段大型语言模型框架，以增强从非结构化文本中提取 SDoH 因素。

Result: 该框架在提取 SDoH 因素的总体任务和检索相关上下文的更精细任务中均表现出性能提升。此外，对较小的、特定于任务的模型进行微调，可以以更低的推理成本实现相当或更好的性能。多阶段设计不仅增强了提取，还提供了中间解释，提高了模型的可解释性。

Conclusion: 该方法提高了从非结构化文本中提取与自杀相关的 SDoH 的准确性和透明度。这些进展有助于及早识别高危个体，并为更有效的预防策略提供信息。

Abstract: Background: Understanding social determinants of health (SDoH) factors
contributing to suicide incidents is crucial for early intervention and
prevention. However, data-driven approaches to this goal face challenges such
as long-tailed factor distributions, analyzing pivotal stressors preceding
suicide incidents, and limited model explainability. Methods: We present a
multi-stage large language model framework to enhance SDoH factor extraction
from unstructured text. Our approach was compared to other state-of-the-art
language models (i.e., pre-trained BioBERT and GPT-3.5-turbo) and reasoning
models (i.e., DeepSeek-R1). We also evaluated how the model's explanations help
people annotate SDoH factors more quickly and accurately. The analysis included
both automated comparisons and a pilot user study. Results: We show that our
proposed framework demonstrated performance boosts in the overarching task of
extracting SDoH factors and in the finer-grained tasks of retrieving relevant
context. Additionally, we show that fine-tuning a smaller, task-specific model
achieves comparable or better performance with reduced inference costs. The
multi-stage design not only enhances extraction but also provides intermediate
explanations, improving model explainability. Conclusions: Our approach
improves both the accuracy and transparency of extracting suicide-related SDoH
from unstructured texts. These advancements have the potential to support early
identification of individuals at risk and inform more effective prevention
strategies.

</details>


### [9] [Dialogues Aspect-based Sentiment Quadruple Extraction via Structural Entropy Minimization Partitioning](https://arxiv.org/abs/2508.05023)
*Kun Peng,Cong Cao,Hao Peng,Zhifeng Hao,Lei Jiang,Kongjing Gu,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: The paper introduces a new method for Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) that partitions dialogues into semantically independent sub-dialogues using structural entropy minimization and then extracts quadruples in two steps, achieving state-of-the-art performance with lower computational costs.


<details>
  <summary>Details</summary>
Motivation: Existing methods learn word relations across entire dialogues, assuming a uniform distribution of sentiment elements, but dialogues often contain multiple semantically independent sub-dialogues, introducing noise into the extraction process.

Method: A structural entropy minimization algorithm is used to partition the dialogues, followed by a two-step framework for quadruple extraction: first extracting individual sentiment elements at the utterance level, then matching quadruples at the sub-dialogue level.

Result: The proposed approach achieves state-of-the-art performance in DiaASQ with much lower computational costs.

Conclusion: The proposed approach achieves state-of-the-art performance in DiaASQ with much lower computational costs.

Abstract: Dialogues Aspect-based Sentiment Quadruple Extraction (DiaASQ) aims to
extract all target-aspect-opinion-sentiment quadruples from a given
multi-round, multi-participant dialogue. Existing methods typically learn word
relations across entire dialogues, assuming a uniform distribution of sentiment
elements. However, we find that dialogues often contain multiple semantically
independent sub-dialogues without clear dependencies between them. Therefore,
learning word relationships across the entire dialogue inevitably introduces
additional noise into the extraction process. To address this, our method
focuses on partitioning dialogues into semantically independent sub-dialogues.
Achieving completeness while minimizing these sub-dialogues presents a
significant challenge. Simply partitioning based on reply relationships is
ineffective. Instead, we propose utilizing a structural entropy minimization
algorithm to partition the dialogues. This approach aims to preserve relevant
utterances while distinguishing irrelevant ones as much as possible.
Furthermore, we introduce a two-step framework for quadruple extraction: first
extracting individual sentiment elements at the utterance level, then matching
quadruples at the sub-dialogue level. Extensive experiments demonstrate that
our approach achieves state-of-the-art performance in DiaASQ with much lower
computational costs.

</details>


### [10] [Evaluation of LLMs in AMR Parsing](https://arxiv.org/abs/2508.05028)
*Shu Han Ho*

Main category: cs.CL

TL;DR: decoder only LLMs经过简单微调后，可以在AMR解析上达到SOTA水平，LLaMA 3.2表现突出。


<details>
  <summary>Details</summary>
Motivation: 探索使用decoder only的大型语言模型（LLM）进行AMR解析的新方法。

Method: 对Phi 3.5、Gemma 2、LLaMA 3.2和DeepSeek R1 LLaMA Distilled四种不同的LLM架构进行微调。

Result: LLaMA 3.2在语义性能方面领先，而Phi 3.5在结构有效性方面表现出色。通过对decoder only LLMs的直接微调，可以实现与复杂的SOTA AMR解析器相媲美的性能。

Conclusion: LLaMA 3.2通过简单的微调，在AMR解析方面表现出与SOTA相当的性能，SMATCH F1值为0.804，与APT + Silver (IBM)持平，接近Graphene Smatch (MBSE)。

Abstract: Meaning Representation (AMR) is a semantic formalism that encodes sentence
meaning as rooted, directed, acyclic graphs, where nodes represent concepts and
edges denote semantic relations. Finetuning decoder only Large Language Models
(LLMs) represent a promising novel straightfoward direction for AMR parsing.
This paper presents a comprehensive evaluation of finetuning four distinct LLM
architectures, Phi 3.5, Gemma 2, LLaMA 3.2, and DeepSeek R1 LLaMA Distilled
using the LDC2020T02 Gold AMR3.0 test set. Our results have shown that
straightfoward finetuning of decoder only LLMs can achieve comparable
performance to complex State of the Art (SOTA) AMR parsers. Notably, LLaMA 3.2
demonstrates competitive performance against SOTA AMR parsers given a
straightforward finetuning approach. We achieved SMATCH F1: 0.804 on the full
LDC2020T02 test split, on par with APT + Silver (IBM) at 0.804 and approaching
Graphene Smatch (MBSE) at 0.854. Across our analysis, we also observed a
consistent pattern where LLaMA 3.2 leads in semantic performance while Phi 3.5
excels in structural validity.

</details>


### [11] [Align, Don't Divide: Revisiting the LoRA Architecture in Multi-Task Learning](https://arxiv.org/abs/2508.05078)
*Jinda Liu,Bo Cheng,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: 本文提出Align-LoRA，一种更简单但更有效的LLM多任务学习范式，强调学习鲁棒的共享表示。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务学习方法倾向于使用具有多个适配器或头的LoRA变体，以捕捉任务特定的知识，但这种范式受到质疑。

Method: 提出Align-LoRA，通过显式损失对齐共享适配器空间内的任务表示。

Result: 简化后的多头架构优于复杂的多适配器和多头系统；标准单适配器LoRA在秩足够大的情况下也表现出色；Align-LoRA显著优于所有基线。

Conclusion: Align-LoRA在多任务学习中表现出色，验证了学习鲁棒共享表示的重要性。

Abstract: Parameter-Efficient Fine-Tuning (PEFT) is essential for adapting Large
Language Models (LLMs). In practice, LLMs are often required to handle a
diverse set of tasks from multiple domains, a scenario naturally addressed by
multi-task learning (MTL). Within this MTL context, a prevailing trend involves
LoRA variants with multiple adapters or heads, which advocate for structural
diversity to capture task-specific knowledge. Our findings present a direct
challenge to this paradigm. We first show that a simplified multi-head
architecture with high inter-head similarity substantially outperforms complex
multi-adapter and multi-head systems. This leads us to question the
multi-component paradigm itself, and we further demonstrate that a standard
single-adapter LoRA, with a sufficiently increased rank, also achieves highly
competitive performance. These results lead us to a new hypothesis: effective
MTL generalization hinges on learning robust shared representations, not
isolating task-specific features. To validate this, we propose Align-LoRA,
which incorporates an explicit loss to align task representations within the
shared adapter space. Experiments confirm that Align-LoRA significantly
surpasses all baselines, establishing a simpler yet more effective paradigm for
adapting LLMs to multiple tasks. The code is available at
https://github.com/jinda-liu/Align-LoRA.

</details>


### [12] [Multimodal Fact Checking with Unified Visual, Textual, and Contextual Representations](https://arxiv.org/abs/2508.05097)
*Aditya Kishore,Gaurav Kumar,Jasabanta Patro*

Main category: cs.CL

TL;DR: This paper introduces MultiCheck, a unified framework for fine-grained multimodal fact verification that combines text and images, achieving strong performance on the Factify 2 dataset.


<details>
  <summary>Details</summary>
Motivation: The growing rate of multimodal misinformation poses significant challenges to fact-checking systems that rely primarily on textual evidence.

Method: The architecture combines dedicated encoders for text and images with a fusion module that captures cross-modal relationships using element-wise interactions. A classification head then predicts the veracity of a claim, supported by a contrastive learning objective that encourages semantic alignment between claim-evidence pairs in a shared latent space.

Result: The MultiCheck framework achieved a weighted F1 score of 0.84 on the Factify 2 dataset, substantially outperforming the baseline.

Conclusion: The proposed MultiCheck framework demonstrates effective multimodal reasoning and shows potential for scalable and interpretable fact-checking, achieving a weighted F1 score of 0.84 on the Factify 2 dataset, outperforming the baseline.

Abstract: The growing rate of multimodal misinformation, where claims are supported by
both text and images, poses significant challenges to fact-checking systems
that rely primarily on textual evidence. In this work, we have proposed a
unified framework for fine-grained multimodal fact verification called
"MultiCheck", designed to reason over structured textual and visual signals.
Our architecture combines dedicated encoders for text and images with a fusion
module that captures cross-modal relationships using element-wise interactions.
A classification head then predicts the veracity of a claim, supported by a
contrastive learning objective that encourages semantic alignment between
claim-evidence pairs in a shared latent space. We evaluate our approach on the
Factify 2 dataset, achieving a weighted F1 score of 0.84, substantially
outperforming the baseline. These results highlight the effectiveness of
explicit multimodal reasoning and demonstrate the potential of our approach for
scalable and interpretable fact-checking in complex, real-world scenarios.

</details>


### [13] [BEE-RAG: Balanced Entropy Engineering for Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05100)
*Yuhao Wang,Ruiyang Ren,Yucheng Wang,Jing Liu,Wayne Xin Zhao,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: This paper proposes BEE-RAG, a balanced entropy-engineered RAG framework, which improves the adaptability of RAG systems to varying context lengths through the principle of entropy invariance.


<details>
  <summary>Details</summary>
Motivation: RAG tends to operate with long context lengths. From the perspective of entropy engineering, we identify unconstrained entropy growth and attention dilution due to long retrieval context as significant factors affecting RAG performance.

Method: balanced entropy-engineered RAG (BEE-RAG) framework, which improves the adaptability of RAG systems to varying context lengths through the principle of entropy invariance. By leveraging balanced context entropy to reformulate attention dynamics, BEE-RAG separates attention sensitivity from context length, ensuring a stable entropy level. Building upon this, we introduce a zero-shot inference strategy for multi-importance estimation and a parameter-efficient adaptive fine-tuning mechanism to obtain the optimal balancing factor for different settings.

Result: BEE-RAG separates attention sensitivity from context length, ensuring a stable entropy level.

Conclusion: Extensive experiments across multiple RAG tasks demonstrate the effectiveness of BEE-RAG.

Abstract: With the rapid advancement of large language models (LLMs),
retrieval-augmented generation (RAG) has emerged as a critical approach to
supplement the inherent knowledge limitations of LLMs. However, due to the
typically large volume of retrieved information, RAG tends to operate with long
context lengths. From the perspective of entropy engineering, we identify
unconstrained entropy growth and attention dilution due to long retrieval
context as significant factors affecting RAG performance. In this paper, we
propose the balanced entropy-engineered RAG (BEE-RAG) framework, which improves
the adaptability of RAG systems to varying context lengths through the
principle of entropy invariance. By leveraging balanced context entropy to
reformulate attention dynamics, BEE-RAG separates attention sensitivity from
context length, ensuring a stable entropy level. Building upon this, we
introduce a zero-shot inference strategy for multi-importance estimation and a
parameter-efficient adaptive fine-tuning mechanism to obtain the optimal
balancing factor for different settings. Extensive experiments across multiple
RAG tasks demonstrate the effectiveness of BEE-RAG.

</details>


### [14] [Attention Basin: Why Contextual Position Matters in Large Language Models](https://arxiv.org/abs/2508.05128)
*Zihao Yi,Delong Zeng,Zhenqing Ling,Haohao Luo,Zhe Xu,Wei Liu,Jian Luan,Wanxia Cao,Ying Shen*

Main category: cs.CL

TL;DR: 大型语言模型的性能对输入位置敏感，模型更关注开头和结尾的信息。AttnRank通过重新排序输入信息的位置来提高模型性能，无需训练。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 的性能对输入中信息的上下文位置非常敏感。为了研究这种位置偏差背后的机制，我们进行了广泛的实验，揭示了一种我们称之为注意力盆地的一致现象：当呈现一系列结构化项目（例如，检索到的文档或少样本示例）时，模型系统地将更高的注意力分配给序列开头和结尾的项目，而忽略中间的项目。至关重要的是，我们的分析进一步表明，将更高的注意力分配给关键信息是提高模型性能的关键。

Method: Attention-Driven Reranking (AttnRank)，一个两阶段框架，(i) 使用小型校准集估计模型的内在位置注意力偏好，以及 (ii) 重新排序检索到的文档或少样本示例，以将最显着的内容与这些高注意力位置对齐。

Result: 模型系统地将更高的注意力分配给序列开头和结尾的项目，而忽略中间的项目。分配更高的注意力给关键信息是提高模型性能的关键。

Conclusion: AttnRank在多跳问答和少样本上下文学习任务上取得了显著的改进，适用于各种架构和规模的10个大型语言模型，无需修改模型参数或训练程序。

Abstract: The performance of Large Language Models (LLMs) is significantly sensitive to
the contextual position of information in the input. To investigate the
mechanism behind this positional bias, our extensive experiments reveal a
consistent phenomenon we term the attention basin: when presented with a
sequence of structured items (e.g., retrieved documents or few-shot examples),
models systematically assign higher attention to the items at the beginning and
end of the sequence, while neglecting those in the middle. Crucially, our
analysis further reveals that allocating higher attention to critical
information is key to enhancing model performance. Based on these insights, we
introduce Attention-Driven Reranking (AttnRank), a two-stage framework that (i)
estimates a model's intrinsic positional attention preferences using a small
calibration set, and (ii) reorders retrieved documents or few-shot examples to
align the most salient content with these high-attention positions. AttnRank is
a model-agnostic, training-free, and plug-and-play method with minimal
computational overhead. Experiments on multi-hop QA and few-shot in-context
learning tasks demonstrate that AttnRank achieves substantial improvements
across 10 large language models of varying architectures and scales, without
modifying model parameters or training procedures.

</details>


### [15] [Towards Assessing Medical Ethics from Knowledge to Practice](https://arxiv.org/abs/2508.05132)
*Chang Hong,Minghao Wu,Qingying Xiao,Yuchi Wang,Xiang Wan,Guangjun Yu,Benyou Wang,Yan Hu*

Main category: cs.CL

TL;DR: PrinciplismQA是一个评估LLM在医疗伦理方面表现的基准，揭示了现有模型的差距，并为改进医疗AI指明了方向。


<details>
  <summary>Details</summary>
Motivation: 当前基准通常忽略了对大型语言模型伦理推理的严格评估，而将其整合到医疗保健中是必要的。

Method: 介绍了PrinciplismQA，一个包含3,648个问题的综合基准，旨在系统地评估大型语言模型与核心医学伦理的一致性。该基准基于Principlism，包含一个高质量的数据集。这包括从权威教科书中挑选的多项选择题和来自权威医学伦理案例研究文献的开放式问题，所有这些都经过医学专家的验证。

Result: 实验表明，模型在伦理知识和实际应用之间存在显著差距，尤其是在动态地将伦理原则应用于实际场景时。大多数LLM在有关行善的困境中挣扎，常常过度强调其他原则。由强大的通用能力驱动的前沿封闭源模型目前领先于该基准。值得注意的是，医学领域微调可以增强模型的整体伦理能力，但进一步的进展需要与医学伦理知识更好地结合。

Conclusion: PrinciplismQA提供了一个可扩展的框架，用于诊断这些特定的伦理弱点，为更平衡和负责任的医疗人工智能铺平了道路。

Abstract: The integration of large language models into healthcare necessitates a
rigorous evaluation of their ethical reasoning, an area current benchmarks
often overlook. We introduce PrinciplismQA, a comprehensive benchmark with
3,648 questions designed to systematically assess LLMs' alignment with core
medical ethics. Grounded in Principlism, our benchmark features a high-quality
dataset. This includes multiple-choice questions curated from authoritative
textbooks and open-ended questions sourced from authoritative medical ethics
case study literature, all validated by medical experts. Our experiments reveal
a significant gap between models' ethical knowledge and their practical
application, especially in dynamically applying ethical principles to
real-world scenarios. Most LLMs struggle with dilemmas concerning Beneficence,
often over-emphasizing other principles. Frontier closed-source models, driven
by strong general capabilities, currently lead the benchmark. Notably, medical
domain fine-tuning can enhance models' overall ethical competence, but further
progress requires better alignment with medical ethical knowledge.
PrinciplismQA offers a scalable framework to diagnose these specific ethical
weaknesses, paving the way for more balanced and responsible medical AI.

</details>


### [16] [ATLANTIS at SemEval-2025 Task 3: Detecting Hallucinated Text Spans in Question Answering](https://arxiv.org/abs/2508.05179)
*Catherine Kobus,François Lancelot,Marion-Cécile Martin,Nawal Ould Amer*

Main category: cs.CL

TL;DR: detecting hallucinated text spans in question answering systems by explored methods both with and without external context


<details>
  <summary>Details</summary>
Motivation: Large Language Models (LLMs) have significantly advanced Natural Language Generation (NLG) but remain susceptible to hallucinations, generating incorrect or misleading content.

Method: explored methods both with and without external context, utilizing few-shot prompting with a LLM, token-level classification or LLM fine-tuned on synthetic data

Result: approaches achieved top rankings in Spanish and competitive placements in English and German.

Conclusion: This work highlights the importance of integrating relevant context to mitigate hallucinations and demonstrate the potential of fine-tuned models and prompt engineering.

Abstract: This paper presents the contributions of the ATLANTIS team to SemEval-2025
Task 3, focusing on detecting hallucinated text spans in question answering
systems. Large Language Models (LLMs) have significantly advanced Natural
Language Generation (NLG) but remain susceptible to hallucinations, generating
incorrect or misleading content. To address this, we explored methods both with
and without external context, utilizing few-shot prompting with a LLM,
token-level classification or LLM fine-tuned on synthetic data. Notably, our
approaches achieved top rankings in Spanish and competitive placements in
English and German. This work highlights the importance of integrating relevant
context to mitigate hallucinations and demonstrate the potential of fine-tuned
models and prompt engineering.

</details>


### [17] [Resource-Limited Joint Multimodal Sentiment Reasoning and Classification via Chain-of-Thought Enhancement and Distillation](https://arxiv.org/abs/2508.05234)
*Haonan Shangguan,Xiaocui Yang,Shi Feng,Daling Wang,Yifei Zhang,Ge Yu*

Main category: cs.CL

TL;DR: 提出了一种轻量级的多模态情感推理和分类模型MulCoT-RD，通过蒸馏方法在资源受限的环境中实现了高性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要利用参数量大的(多模态)LLM进行情感分类，忽略了资源受限环境中的自主多模态情感推理生成。

Method: 提出了一种多模态Chain-of-Thought推理蒸馏模型MulCoT-RD，采用“Teacher-Assistant-Student”蒸馏范式。

Result: 在四个数据集上的大量实验表明，MulCoT-RD仅使用3B参数就在JMSRC上实现了强大的性能。

Conclusion: MulCoT-RD模型在JMSRC任务上表现出色，具有良好的泛化性和可解释性，并且仅使用3B参数。

Abstract: The surge in rich multimodal content on social media platforms has greatly
advanced Multimodal Sentiment Analysis (MSA), with Large Language Models (LLMs)
further accelerating progress in this field. Current approaches primarily
leverage the knowledge and reasoning capabilities of parameter-heavy
(Multimodal) LLMs for sentiment classification, overlooking autonomous
multimodal sentiment reasoning generation in resource-constrained environments.
Therefore, we focus on the Resource-Limited Joint Multimodal Sentiment
Reasoning and Classification task, JMSRC, which simultaneously performs
multimodal sentiment reasoning chain generation and sentiment classification
only with a lightweight model. We propose a Multimodal Chain-of-Thought
Reasoning Distillation model, MulCoT-RD, designed for JMSRC that employs a
"Teacher-Assistant-Student" distillation paradigm to address deployment
constraints in resource-limited environments. We first leverage a
high-performance Multimodal Large Language Model (MLLM) to generate the initial
reasoning dataset and train a medium-sized assistant model with a multi-task
learning mechanism. A lightweight student model is jointly trained to perform
efficient multimodal sentiment reasoning generation and classification.
Extensive experiments on four datasets demonstrate that MulCoT-RD with only 3B
parameters achieves strong performance on JMSRC, while exhibiting robust
generalization and enhanced interpretability.

</details>


### [18] [Pruning Large Language Models by Identifying and Preserving Functional Networks](https://arxiv.org/abs/2508.05239)
*Yiheng Liu,Junhao Ning,Sichen Xia,Xiaohui Gao,Ning Qiang,Bao Ge,Junwei Han,Xintao Hu*

Main category: cs.CL

TL;DR: Prune LLMs by identifying and preserving functional networks within LLMs.


<details>
  <summary>Details</summary>
Motivation: Current structured pruning methods typically rely on assessment of the importance of the structure units and pruning the units with less importance. Most of them overlooks the interaction and collaboration among artificial neurons that are crucial for the functionalities of LLMs, leading to a disruption in the macro functional architecture of LLMs and consequently a pruning performance degradation.

Method: treat an LLM as a digital brain and decompose the LLM into functional networks, analogous to identifying functional brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving the key neurons within these functional networks.

Result: enabling efficient model pruning

Conclusion: The proposed method can successfully identify and locate functional networks and key neurons in LLMs, enabling efficient model pruning.

Abstract: Structured pruning is one of the representative techniques for compressing
large language models (LLMs) to reduce GPU memory consumption and accelerate
inference speed. It offers significant practical value in improving the
efficiency of LLMs in real-world applications. Current structured pruning
methods typically rely on assessment of the importance of the structure units
and pruning the units with less importance. Most of them overlooks the
interaction and collaboration among artificial neurons that are crucial for the
functionalities of LLMs, leading to a disruption in the macro functional
architecture of LLMs and consequently a pruning performance degradation.
Inspired by the inherent similarities between artificial neural networks and
functional neural networks in the human brain, we alleviate this challenge and
propose to prune LLMs by identifying and preserving functional networks within
LLMs in this study. To achieve this, we treat an LLM as a digital brain and
decompose the LLM into functional networks, analogous to identifying functional
brain networks in neuroimaging data. Afterwards, an LLM is pruned by preserving
the key neurons within these functional networks. Experimental results
demonstrate that the proposed method can successfully identify and locate
functional networks and key neurons in LLMs, enabling efficient model pruning.
Our code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.

</details>


### [19] [CodeBoost: Boosting Code LLMs by Squeezing Knowledge from Code Snippets with RL](https://arxiv.org/abs/2508.05242)
*Sijie Wang,Quanjiang Guo,Kai Zhao,Yawei Zhang,Xin Li,Xiang Li,Siqi Li,Rui She,Shangshu Yu,Wee Peng Tay*

Main category: cs.CL

TL;DR: CodeBoost 是一种新颖的后训练框架，它通过利用代码片段，而无需人工注释的指令，来增强代码大型语言模型 (LLM)。


<details>
  <summary>Details</summary>
Motivation: 收集高质量的编码指令既费力又难以扩展。另一方面，代码片段可以从各种来源大量获得。这种不平衡在基于指令的后训练中提出了一个主要的瓶颈。

Method: CodeBoost，一个后训练框架，它纯粹从代码片段增强代码 LLM，而无需依赖人工注释的指令。CodeBoost 引入了以下关键组件：(1) 最大集团策展，它从代码中选择具有代表性和多样性的训练语料库；(2) 双向预测，使模型能够从前向和后向预测目标中学习；(3) 错误感知预测，它结合了来自正确和不正确输出的学习信号；(4) 异构增强，它使训练分布多样化以丰富代码语义；(5) 异构奖励。

Result: 跨多个代码 LLM 和基准的广泛实验验证 CodeBoost 持续提高性能，证明了其作为可扩展且有效的训练管道的有效性。

Conclusion: CodeBoost 通过多个奖励类型（包括格式正确性和来自成功和失败的执行反馈）来指导模型学习，并通过跨多个代码 LLM 和基准的广泛实验验证，持续提高性能，展示了其作为可扩展且有效的训练管道的有效性。

Abstract: Code large language models (LLMs) have become indispensable tools for
building efficient and automated coding pipelines. Existing models are
typically post-trained using reinforcement learning (RL) from general-purpose
LLMs using "human instruction-final answer" pairs, where the instructions are
usually from manual annotations. However, collecting high-quality coding
instructions is both labor-intensive and difficult to scale. On the other hand,
code snippets are abundantly available from various sources. This imbalance
presents a major bottleneck in instruction-based post-training. We propose
CodeBoost, a post-training framework that enhances code LLMs purely from code
snippets, without relying on human-annotated instructions. CodeBoost introduces
the following key components: (1) maximum-clique curation, which selects a
representative and diverse training corpus from code; (2) bi-directional
prediction, which enables the model to learn from both forward and backward
prediction objectives; (3) error-aware prediction, which incorporates learning
signals from both correct and incorrect outputs; (4) heterogeneous
augmentation, which diversifies the training distribution to enrich code
semantics; and (5) heterogeneous rewarding, which guides model learning through
multiple reward types including format correctness and execution feedback from
both successes and failures. Extensive experiments across several code LLMs and
benchmarks verify that CodeBoost consistently improves performance,
demonstrating its effectiveness as a scalable and effective training pipeline.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [20] [RetinexDual: Retinex-based Dual Nature Approach for Generalized Ultra-High-Definition Image Restoration](https://arxiv.org/abs/2508.04797)
*Mohab Kishawy,Ali Abdellatif Hussein,Jun Chen*

Main category: cs.CV

TL;DR: RetinexDual 是一种用于广义 UHD IR 任务的基于 Retinex 理论的新框架，它优于最新的方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法（例如极端下采样或从空间域到频域的转换）存在显着缺点：下采样会导致 UHD 图像中不可逆转的信息丢失，而我们的频率分析表明，纯频域方法对于空间受限的图像伪影无效，这主要是由于降级局部性的丧失。

Method: RetinexDual：一种基于 Retinex 理论的新框架，专为广义 UHD IR 任务而设计。RetinexDual 利用两个互补的子网络：Scale-Attentive maMBA (SAMBA) 和 Frequency Illumination Adaptor (FIA)。

Result: RetinexDual 在质量和数量上均优于最新的方法。

Conclusion: RetinexDual在四个UHD IR任务（即去雨、去模糊、去雾和低光图像增强 (LLIE)）上的评估表明，它在质量和数量上均优于最近的方法。消融研究表明，在 RetinexDual 中为每个分支采用不同的设计非常重要，并且证明了其各种组件的有效性。

Abstract: Advancements in image sensing have elevated the importance of
Ultra-High-Definition Image Restoration (UHD IR). Traditional methods, such as
extreme downsampling or transformation from the spatial to the frequency
domain, encounter significant drawbacks: downsampling induces irreversible
information loss in UHD images, while our frequency analysis reveals that pure
frequency-domain approaches are ineffective for spatially confined image
artifacts, primarily due to the loss of degradation locality. To overcome these
limitations, we present RetinexDual, a novel Retinex theory-based framework
designed for generalized UHD IR tasks. RetinexDual leverages two complementary
sub-networks: the Scale-Attentive maMBA (SAMBA) and the Frequency Illumination
Adaptor (FIA). SAMBA, responsible for correcting the reflectance component,
utilizes a coarse-to-fine mechanism to overcome the causal modeling of mamba,
which effectively reduces artifacts and restores intricate details. On the
other hand, FIA ensures precise correction of color and illumination
distortions by operating in the frequency domain and leveraging the global
context provided by it. Evaluating RetinexDual on four UHD IR tasks, namely
deraining, deblurring, dehazing, and Low-Light Image Enhancement (LLIE), shows
that it outperforms recent methods qualitatively and quantitatively. Ablation
studies demonstrate the importance of employing distinct designs for each
branch in RetinexDual, as well as the effectiveness of its various components.

</details>


### [21] [ACM Multimedia Grand Challenge on ENT Endoscopy Analysis](https://arxiv.org/abs/2508.04801)
*Trong-Thuan Nguyen,Viet-Tham Huynh,Thao Thi Phuong Dao,Ha Nguyen Thi,Tien To Vu Thuy,Uyen Hanh Tran,Tam V. Nguyen,Thanh Dinh Le,Minh-Triet Tran*

Main category: cs.CV

TL;DR: This paper introduces a new dataset, ENTRep, for ENT endoscopy analysis with three benchmark tasks for anatomical classification and image/text retrieval.


<details>
  <summary>Details</summary>
Motivation: Automated analysis of endoscopic imagery is a critical yet underdeveloped component of ENT care, hindered by variability in devices and operators, subtle and localized findings, and fine-grained distinctions such as laterality and vocal-fold state. Clinicians require reliable retrieval of similar cases, both visually and through concise textual descriptions, which are rarely supported by existing public benchmarks.

Method: The paper defines three benchmark tasks, standardizes the submission protocol, and evaluates performance on public and private test splits using server-side scoring.

Result: The dataset comprises expert-annotated images, labeled for anatomical region and normal or abnormal status, and accompanied by dual-language narrative descriptions.

Conclusion: The paper introduces ENTRep, the ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis, which integrates fine-grained anatomical classification with image-to-image and text-to-image retrieval under bilingual clinical supervision. The paper also reports results from the top-performing teams and provide an insight discussion.

Abstract: Automated analysis of endoscopic imagery is a critical yet underdeveloped
component of ENT (ear, nose, and throat) care, hindered by variability in
devices and operators, subtle and localized findings, and fine-grained
distinctions such as laterality and vocal-fold state. In addition to
classification, clinicians require reliable retrieval of similar cases, both
visually and through concise textual descriptions. These capabilities are
rarely supported by existing public benchmarks. To this end, we introduce
ENTRep, the ACM Multimedia 2025 Grand Challenge on ENT endoscopy analysis,
which integrates fine-grained anatomical classification with image-to-image and
text-to-image retrieval under bilingual (Vietnamese and English) clinical
supervision. Specifically, the dataset comprises expert-annotated images,
labeled for anatomical region and normal or abnormal status, and accompanied by
dual-language narrative descriptions. In addition, we define three benchmark
tasks, standardize the submission protocol, and evaluate performance on public
and private test splits using server-side scoring. Moreover, we report results
from the top-performing teams and provide an insight discussion.

</details>


### [22] [CoMAD: A Multiple-Teacher Self-Supervised Distillation Framework](https://arxiv.org/abs/2508.04816)
*Sriram Mandalika,Lalitha V*

Main category: cs.CV

TL;DR: CoMAD is a lightweight framework that distills knowledge from multiple self-supervised Vision Transformers into a compact student network, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Current self-supervised learning paradigms are typically pretrained in isolation, overlooking complementary insights and yielding large models that are impractical for resource-constrained deployment.

Method: Consensus-oriented Masked Distillation (CoMAD), a lightweight, parameter-free framework that unifies knowledge from multiple current state-of-the-art self-supervised Vision Transformers into a compact student network. It applies asymmetric masking and joint consensus gating.

Result: CoMAD achieves state-of-the-art results on ImageNet-1K, ADE20K, and MS-COCO.

Conclusion: CoMAD's ViT-Tiny achieves 75.4 percent Top-1 on ImageNet-1K, 47.3 percent mIoU on ADE20K, and 44.5 percent box average precision and 40.5 percent mask average precision on MS-COCO, establishing a new state-of-the-art in compact SSL distillation.

Abstract: Numerous self-supervised learning paradigms, such as contrastive learning and
masked image modeling, learn powerful representations from unlabeled data but
are typically pretrained in isolation, overlooking complementary insights and
yielding large models that are impractical for resource-constrained deployment.
To overcome these challenges, we introduce Consensus-oriented Masked
Distillation (CoMAD), a lightweight, parameter-free framework that unifies
knowledge from multiple current state-of-the-art self-supervised Vision
Transformers into a compact student network. CoMAD distills from three
pretrained ViT-Base teachers, MAE, MoCo v3, and iBOT, each offering distinct
semantic and contextual priors. Rather than naively averaging teacher outputs,
we apply asymmetric masking: the student sees only 25 percent of patches while
each teacher receives a progressively lighter, unique mask, forcing the student
to interpolate missing features under richer contexts. Teacher embeddings are
aligned to the student's space via a linear adapter and layer normalization,
then fused through our joint consensus gating, which weights each token by
combining cosine affinity with inter-teacher agreement. The student is trained
with dual-level KL divergence on visible tokens and reconstructed feature maps,
capturing both local and global structure. On ImageNet-1K, CoMAD's ViT-Tiny
achieves 75.4 percent Top-1, an increment of 0.4 percent over the previous
state-of-the-art. In dense-prediction transfers, it attains 47.3 percent mIoU
on ADE20K, and 44.5 percent box average precision and 40.5 percent mask average
precision on MS-COCO, establishing a new state-of-the-art in compact SSL
distillation.

</details>


### [23] [Single-Step Reconstruction-Free Anomaly Detection and Segmentation via Diffusion Models](https://arxiv.org/abs/2508.04818)
*Mehrdad Moradi,Marco Grasso,Bianca Maria Colosimo,Kamran Paynabar*

Main category: cs.CV

TL;DR: RADAR是一种无重建的异常检测方法，它直接从扩散模型生成异常图，提高了检测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 基于重建的方法计算成本高，重建图像可能对应于不同的正常模式，选择合适的中间噪声水平具有挑战性。

Method: 提出了一种基于注意力扩散模型的无重建异常检测方法RADAR。

Result: RADAR在所有关键指标上都优于最先进的基于扩散和统计机器学习的模型。

Conclusion: RADAR在MVTec-AD和3D打印材料数据集上的F1分数分别提高了7%和13%，优于其他模型。

Abstract: Generative models have demonstrated significant success in anomaly detection
and segmentation over the past decade. Recently, diffusion models have emerged
as a powerful alternative, outperforming previous approaches such as GANs and
VAEs. In typical diffusion-based anomaly detection, a model is trained on
normal data, and during inference, anomalous images are perturbed to a
predefined intermediate step in the forward diffusion process. The
corresponding normal image is then reconstructed through iterative reverse
sampling.
  However, reconstruction-based approaches present three major challenges: (1)
the reconstruction process is computationally expensive due to multiple
sampling steps, making real-time applications impractical; (2) for complex or
subtle patterns, the reconstructed image may correspond to a different normal
pattern rather than the original input; and (3) Choosing an appropriate
intermediate noise level is challenging because it is application-dependent and
often assumes prior knowledge of anomalies, an assumption that does not hold in
unsupervised settings.
  We introduce Reconstruction-free Anomaly Detection with Attention-based
diffusion models in Real-time (RADAR), which overcomes the limitations of
reconstruction-based anomaly detection. Unlike current SOTA methods that
reconstruct the input image, RADAR directly produces anomaly maps from the
diffusion model, improving both detection accuracy and computational
efficiency. We evaluate RADAR on real-world 3D-printed material and the
MVTec-AD dataset. Our approach surpasses state-of-the-art diffusion-based and
statistical machine learning models across all key metrics, including accuracy,
precision, recall, and F1 score. Specifically, RADAR improves F1 score by 7% on
MVTec-AD and 13% on the 3D-printed material dataset compared to the next best
model.
  Code available at: https://github.com/mehrdadmoradi124/RADAR

</details>


### [24] [A deep learning approach to track eye movements based on events](https://arxiv.org/abs/2508.04827)
*Chirag Seth,Divya Naiken,Keyan Lin*

Main category: cs.CV

TL;DR: This paper introduces a deep learning method to predict human attention using an event camera and CNN-LSTM model, achieving 81% accuracy. The goal is to develop a cost-effective algorithm for eye tracking to improve user experience in VR/AR applications.


<details>
  <summary>Details</summary>
Motivation: precise eye tracking typically requires expensive and high-speed cameras. ultimate goal is to develop an interpretable and cost-effective algorithm using deep learning methods to predict human attention, thereby improving device comfort and enhancing overall user experience. Eye movement analysis has extensive applications in consumer electronics, especially in VR and AR product development.

Method: explored various approaches, with the CNN_LSTM model proving most effective

Result: CNN_LSTM model achieving approximately 81% accuracy

Conclusion: The CNN_LSTM model was most effective, achieving approximately 81% accuracy. Future work focuses on Layer-wise Relevance Propagation (LRP) to further enhance the model's interpretability and predictive performance.

Abstract: This research project addresses the challenge of accurately tracking eye
movements during specific events by leveraging previous research. Given the
rapid movements of human eyes, which can reach speeds of 300{\deg}/s, precise
eye tracking typically requires expensive and high-speed cameras. Our primary
objective is to locate the eye center position (x, y) using inputs from an
event camera. Eye movement analysis has extensive applications in consumer
electronics, especially in VR and AR product development. Therefore, our
ultimate goal is to develop an interpretable and cost-effective algorithm using
deep learning methods to predict human attention, thereby improving device
comfort and enhancing overall user experience. To achieve this goal, we
explored various approaches, with the CNN\_LSTM model proving most effective,
achieving approximately 81\% accuracy. Additionally, we propose future work
focusing on Layer-wise Relevance Propagation (LRP) to further enhance the
model's interpretability and predictive performance.

</details>


### [25] [LuKAN: A Kolmogorov-Arnold Network Framework for 3D Human Motion Prediction](https://arxiv.org/abs/2508.04847)
*Md Zahidul Hasan,A. Ben Hamza,Nizar Bouguila*

Main category: cs.CV

TL;DR: LuKAN: An efficient 3D human motion prediction model using KANs with Lucas polynomials.


<details>
  <summary>Details</summary>
Motivation: Existing methods often face limitations in achieving a balance between prediction accuracy and computational efficiency in 3D human motion prediction.

Method: The LuKAN model uses Kolmogorov-Arnold Networks (KANs) with Lucas polynomial activations, discrete wavelet transform, and a spatial projection layer.

Result: The LuKAN model demonstrates competitive performance compared to strong baselines, as evidenced by both quantitative and qualitative evaluations.

Conclusion: The LuKAN model achieves competitive performance on three benchmark datasets with computational efficiency.

Abstract: The goal of 3D human motion prediction is to forecast future 3D poses of the
human body based on historical motion data. Existing methods often face
limitations in achieving a balance between prediction accuracy and
computational efficiency. In this paper, we present LuKAN, an effective model
based on Kolmogorov-Arnold Networks (KANs) with Lucas polynomial activations.
Our model first applies the discrete wavelet transform to encode temporal
information in the input motion sequence. Then, a spatial projection layer is
used to capture inter-joint dependencies, ensuring structural consistency of
the human body. At the core of LuKAN is the Temporal Dependency Learner, which
employs a KAN layer parameterized by Lucas polynomials for efficient function
approximation. These polynomials provide computational efficiency and an
enhanced capability to handle oscillatory behaviors. Finally, the inverse
discrete wavelet transform reconstructs motion sequences in the time domain,
generating temporally coherent predictions. Extensive experiments on three
benchmark datasets demonstrate the competitive performance of our model
compared to strong baselines, as evidenced by both quantitative and qualitative
evaluations. Moreover, its compact architecture coupled with the linear
recurrence of Lucas polynomials, ensures computational efficiency.

</details>


### [26] [VER-Bench: Evaluating MLLMs on Reasoning with Fine-Grained Visual Evidence](https://arxiv.org/abs/2508.04852)
*Chenhui Qiang,Zhaoyang Wei,Xumeng Han Zipeng Wang,Siyao Li,Xiangyuan Lan,Jianbin Jiao,Zhenjun Han*

Main category: cs.CV

TL;DR: VER-Bench是一个新的框架，用于评估MLLM识别细粒度视觉线索并将其与世界知识相结合以进行复杂推理的能力。


<details>
  <summary>Details</summary>
Motivation: 当前的基准测试主要分为两种主要类型：基本感知基准测试，侧重于局部细节但缺乏深度推理；主流推理基准测试，侧重于突出的图像元素，但可能无法评估需要复杂分析的细微线索。然而，深刻的视觉理解和复杂的推理更多地依赖于解释细微的、不显眼的局部细节，而不是感知显著的、宏观层面的对象。

Method: 引入VER-Bench，这是一个新的框架，用于评估MLLM的能力：1）识别细粒度的视觉线索，通常平均只占图像面积的0.25%；2）将这些线索与世界知识相结合，进行复杂的推理。

Result: VER-Bench揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性，强调需要提高模型在细粒度视觉证据提取、整合和推理方面的能力，以实现真正的视觉理解和类人分析。

Conclusion: VER-Bench揭示了当前模型在提取细微视觉证据和构建基于证据的论证方面的局限性，强调需要提高模型在细粒度视觉证据提取、整合和推理方面的能力，以实现真正的视觉理解和类人分析。

Abstract: With the rapid development of MLLMs, evaluating their visual capabilities has
become increasingly crucial. Current benchmarks primarily fall into two main
types: basic perception benchmarks, which focus on local details but lack deep
reasoning (e.g., "what is in the image?"), and mainstream reasoning benchmarks,
which concentrate on prominent image elements but may fail to assess subtle
clues requiring intricate analysis. However, profound visual understanding and
complex reasoning depend more on interpreting subtle, inconspicuous local
details than on perceiving salient, macro-level objects. These details, though
occupying minimal image area, often contain richer, more critical information
for robust analysis. To bridge this gap, we introduce the VER-Bench, a novel
framework to evaluate MLLMs' ability to: 1) identify fine-grained visual clues,
often occupying on average just 0.25% of the image area; 2) integrate these
clues with world knowledge for complex reasoning. Comprising 374 carefully
designed questions across Geospatial, Temporal, Situational, Intent, System
State, and Symbolic reasoning, each question in VER-Bench is accompanied by
structured evidence: visual clues and question-related reasoning derived from
them. VER-Bench reveals current models' limitations in extracting subtle visual
evidence and constructing evidence-based arguments, highlighting the need to
enhance models's capabilities in fine-grained visual evidence extraction,
integration, and reasoning for genuine visual understanding and human-like
analysis. Dataset and additional materials are available
https://github.com/verbta/ACMMM-25-Materials.

</details>


### [27] [Dual-Stream Attention with Multi-Modal Queries for Object Detection in Transportation Applications](https://arxiv.org/abs/2508.04868)
*Noreen Anwar,Guillaume-Alexandre Bilodeau,Wassim Bouachir*

Main category: cs.CV

TL;DR: DAMM introduces query adaptation and structured cross-attention with multi-modal queries, boosting localization precision and achieving state-of-the-art performance.


<details>
  <summary>Details</summary>
Motivation: Transformer-based object detectors often struggle with occlusions, fine-grained localization, and computational inefficiency caused by fixed queries and dense attention.

Method: Introducing both query adaptation and structured cross-attention, DAMM capitalizes on three types of queries: appearance-based queries from vision-language models, positional queries using polygonal embeddings, and random learned queries for general scene coverage. Furthermore, a dual-stream cross-attention module separately refines semantic and spatial features

Result: Evaluated DAMM on four challenging benchmarks, and it achieved state-of-the-art performance in average precision (AP) and recall

Conclusion: DAMM achieves state-of-the-art performance in average precision (AP) and recall, demonstrating the effectiveness of multi-modal query adaptation and dual-stream attention.

Abstract: Transformer-based object detectors often struggle with occlusions,
fine-grained localization, and computational inefficiency caused by fixed
queries and dense attention. We propose DAMM, Dual-stream Attention with
Multi-Modal queries, a novel framework introducing both query adaptation and
structured cross-attention for improved accuracy and efficiency. DAMM
capitalizes on three types of queries: appearance-based queries from
vision-language models, positional queries using polygonal embeddings, and
random learned queries for general scene coverage. Furthermore, a dual-stream
cross-attention module separately refines semantic and spatial features,
boosting localization precision in cluttered scenes. We evaluated DAMM on four
challenging benchmarks, and it achieved state-of-the-art performance in average
precision (AP) and recall, demonstrating the effectiveness of multi-modal query
adaptation and dual-stream attention. Source code is at:
\href{https://github.com/DET-LIP/DAMM}{GitHub}.

</details>


### [28] [Revealing Temporal Label Noise in Multimodal Hateful Video Classification](https://arxiv.org/abs/2508.04900)
*Shuonan Yang,Tailin Chen,Rahul Singh,Jiangbei Yue,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: Investigates label ambiguity in hateful videos by trimming them to isolate hateful segments, finding that timestamp noise alters model decisions. Need better models.


<details>
  <summary>Details</summary>
Motivation: Coarse, video-level annotations overlook the temporal granularity of hateful content, introducing label noise.

Method: Trimmed hateful videos using annotated timestamps to isolate hateful segments, then analyzed.

Result: Highlights the degree of semantic overlap and the confusion introduced by coarse, video-level annotations.

Conclusion: Timestamp noise alters model decision boundaries and weakens classification confidence, showing context dependency and temporal continuity of hate speech. Need temporally aware models.

Abstract: The rapid proliferation of online multimedia content has intensified the
spread of hate speech, presenting critical societal and regulatory challenges.
While recent work has advanced multimodal hateful video detection, most
approaches rely on coarse, video-level annotations that overlook the temporal
granularity of hateful content. This introduces substantial label noise, as
videos annotated as hateful often contain long non-hateful segments. In this
paper, we investigate the impact of such label ambiguity through a fine-grained
approach. Specifically, we trim hateful videos from the HateMM and
MultiHateClip English datasets using annotated timestamps to isolate explicitly
hateful segments. We then conduct an exploratory analysis of these trimmed
segments to examine the distribution and characteristics of both hateful and
non-hateful content. This analysis highlights the degree of semantic overlap
and the confusion introduced by coarse, video-level annotations. Finally,
controlled experiments demonstrated that time-stamp noise fundamentally alters
model decision boundaries and weakens classification confidence, highlighting
the inherent context dependency and temporal continuity of hate speech
expression. Our findings provide new insights into the temporal dynamics of
multimodal hateful videos and highlight the need for temporally aware models
and benchmarks for improved robustness and interpretability. Code and data are
available at
https://github.com/Multimodal-Intelligence-Lab-MIL/HatefulVideoLabelNoise.

</details>


### [29] [Test-Time Adaptation for Video Highlight Detection Using Meta-Auxiliary Learning and Cross-Modality Hallucinations](https://arxiv.org/abs/2508.04924)
*Zahidul Islam,Sujoy Paul,Mrigank Rochan*

Main category: cs.CV

TL;DR: Highlight-TTA, a test-time adaptation framework, dynamically adapts the model during testing to better align with the specific characteristics of each test video, improving generalization and highlight detection performance.


<details>
  <summary>Details</summary>
Motivation: Existing video highlight detection methods struggle to generalize well to all test videos because they fail to account for the unique characteristics and variations of individual test videos.

Method: a test-time adaptation framework Highlight-TTA, jointly optimized with an auxiliary task, cross-modality hallucinations, alongside the primary highlight detection task. We utilize a meta-auxiliary training scheme to enable effective adaptation through the auxiliary task while enhancing the primary task. During testing, we adapt the trained model using the auxiliary task on the test video

Result: Introducing Highlight-TTA to these models improves their performance, yielding superior results.

Conclusion: Highlight-TTA improves the performance of three state-of-the-art highlight detection models on three benchmark datasets.

Abstract: Existing video highlight detection methods, although advanced, struggle to
generalize well to all test videos. These methods typically employ a generic
highlight detection model for each test video, which is suboptimal as it fails
to account for the unique characteristics and variations of individual test
videos. Such fixed models do not adapt to the diverse content, styles, or audio
and visual qualities present in new, unseen test videos, leading to reduced
highlight detection performance. In this paper, we propose Highlight-TTA, a
test-time adaptation framework for video highlight detection that addresses
this limitation by dynamically adapting the model during testing to better
align with the specific characteristics of each test video, thereby improving
generalization and highlight detection performance. Highlight-TTA is jointly
optimized with an auxiliary task, cross-modality hallucinations, alongside the
primary highlight detection task. We utilize a meta-auxiliary training scheme
to enable effective adaptation through the auxiliary task while enhancing the
primary task. During testing, we adapt the trained model using the auxiliary
task on the test video to further enhance its highlight detection performance.
Extensive experiments with three state-of-the-art highlight detection models
and three benchmark datasets show that the introduction of Highlight-TTA to
these models improves their performance, yielding superior results.

</details>


### [30] [Extending Foundational Monocular Depth Estimators to Fisheye Cameras with Calibration Tokens](https://arxiv.org/abs/2508.04928)
*Suchisrit Gangopadhyay,Jung-Hee Kim,Xien Chen,Patrick Rim,Hyoungseob Park,Alex Wong*

Main category: cs.CV

TL;DR: 我们提出了一种将基础单眼深度估计器 (FMDE) 从透视图像扩展到鱼眼图像的方法。


<details>
  <summary>Details</summary>
Motivation: 基础单眼深度估计器 (FMDE) 容易受到相机校准（内在、失真）参数变化引入的协变量偏移的影响，从而导致错误的深度估计。

Method: 我们引入了一组校准令牌作为一种轻量级的适应机制，可以调节潜在的嵌入以进行对齐。

Result: 我们的方法将编码鱼眼图像的潜在嵌入分布与透视图像的潜在嵌入分布对齐，从而无需重新训练或微调即可将 FMDE 重用于鱼眼相机。

Conclusion: 该方法优于最先进的方法，室内和室外都使用一组令牌。

Abstract: We propose a method to extend foundational monocular depth estimators
(FMDEs), trained on perspective images, to fisheye images. Despite being
trained on tens of millions of images, FMDEs are susceptible to the covariate
shift introduced by changes in camera calibration (intrinsic, distortion)
parameters, leading to erroneous depth estimates. Our method aligns the
distribution of latent embeddings encoding fisheye images to those of
perspective images, enabling the reuse of FMDEs for fisheye cameras without
retraining or finetuning. To this end, we introduce a set of Calibration Tokens
as a light-weight adaptation mechanism that modulates the latent embeddings for
alignment. By exploiting the already expressive latent space of FMDEs, we posit
that modulating their embeddings avoids the negative impact of artifacts and
loss introduced in conventional recalibration or map projection to a canonical
reference frame in the image space. Our method is self-supervised and does not
require fisheye images but leverages publicly available large-scale perspective
image datasets. This is done by recalibrating perspective images to fisheye
images, and enforcing consistency between their estimates during training. We
evaluate our approach with several FMDEs, on both indoors and outdoors, where
we consistently improve over state-of-the-art methods using a single set of
tokens for both. Code available at:
https://github.com/JungHeeKim29/calibration-token.

</details>


### [31] [Toward Errorless Training ImageNet-1k](https://arxiv.org/abs/2508.04941)
*Bo Deng,Levi Heath*

Main category: cs.CV

TL;DR: A feedforward neural network achieves 98.3% accuracy on ImageNet using a new method, but double-labeling prevents 100% accuracy.


<details>
  <summary>Details</summary>
Motivation: Trained on the ImageNet 2012 contest dataset [7]

Method: a feedforward artificial neural network trained with the new method of [5]

Result: accuracy rate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are perfectly classified

Conclusion: The model does not achieve a 100% accuracy rate due to a double-labeling problem.

Abstract: In this paper, we describe a feedforward artificial neural network trained on
the ImageNet 2012 contest dataset [7] with the new method of [5] to an accuracy
rate of 98.3% with a 99.69 Top-1 rate, and an average of 285.9 labels that are
perfectly classified over the 10 batch partitions of the dataset. The best
performing model uses 322,430,160 parameters, with 4 decimal places precision.
We conjecture that the reason our model does not achieve a 100% accuracy rate
is due to a double-labeling problem, by which there are duplicate images in the
dataset with different labels.

</details>


### [32] [Accelerating Conditional Prompt Learning via Masked Image Modeling for Vision-Language Models](https://arxiv.org/abs/2508.04942)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: ProMIM通过将掩码图像建模集成到视觉语言模型中，提高了零样本和少样本学习的泛化能力，且计算成本可忽略不计。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型(VLMs)在零样本学习中表现出色，但通常需要大量的资源来进行训练以适应新的任务。提示学习技术虽然提供了高效的适应性，但往往过度拟合已知的类别，限制了对未见类别的泛化能力。

Method: ProMIM利用一个简单但有效的掩码策略来生成鲁棒的、实例条件的提示，无缝地增强了CoOp和CoCoOp等方法。

Result: 在零样本和少样本分类任务中的大量实验表明，当ProMIM被插入到现有的方法中时，它能够持续地提高泛化性能。

Conclusion: ProMIM通过结合掩码图像建模(MIM)增强了条件提示学习，提升了泛化性能，为实际视觉语言应用提供了一个轻量级解决方案。

Abstract: Vision-language models (VLMs) like CLIP excel in zero-shot learning but often
require resource-intensive training to adapt to new tasks. Prompt learning
techniques, such as CoOp and CoCoOp, offer efficient adaptation but tend to
overfit to known classes, limiting generalization to unseen categories. We
introduce ProMIM, a plug-and-play framework that enhances conditional prompt
learning by integrating masked image modeling (MIM) into existing VLM
pipelines. ProMIM leverages a simple yet effective masking strategy to generate
robust, instance-conditioned prompts, seamlessly augmenting methods like CoOp
and CoCoOp without altering their core architectures. By masking only visible
image patches and using these representations to guide prompt generation,
ProMIM improves feature robustness and mitigates overfitting, all while
introducing negligible additional computational cost. Extensive experiments
across zero-shot and few-shot classification tasks demonstrate that ProMIM
consistently boosts generalization performance when plugged into existing
approaches, providing a practical, lightweight solution for real-world
vision-language applications.

</details>


### [33] [TRKT: Weakly Supervised Dynamic Scene Graph Generation with Temporal-enhanced Relation-aware Knowledge Transferring](https://arxiv.org/abs/2508.04943)
*Zhu Xu,Ting Lei,Zhimin Li,Guan Wang,Qingchao Chen,Yuxin Peng,Yang liu*

Main category: cs.CV

TL;DR: TRKT提出了一种新的弱监督动态场景图生成方法，该方法利用时序增强的关系感知知识转移来提高对象检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督动态场景图生成 (WS-DSGG) 方法依赖于现成的外部对象检测器来为后续DSGG训练生成伪标签。然而，在静态的、以对象为中心的图像上训练的检测器在DSGG所需的动态的、关系感知的场景中表现不佳，导致不准确的定位和低置信度的提议。

Method: Temporal-enhanced Relation-aware Knowledge Transferring (TRKT)

Result: TRKT通过利用知识来加强关系感知动态场景中的检测，解决了外部对象检测器在WS-DSGG中带来的挑战。

Conclusion: TRKT在Action Genome数据集上实现了最先进的性能。

Abstract: Dynamic Scene Graph Generation (DSGG) aims to create a scene graph for each
video frame by detecting objects and predicting their relationships. Weakly
Supervised DSGG (WS-DSGG) reduces annotation workload by using an unlocalized
scene graph from a single frame per video for training. Existing WS-DSGG
methods depend on an off-the-shelf external object detector to generate pseudo
labels for subsequent DSGG training. However, detectors trained on static,
object-centric images struggle in dynamic, relation-aware scenarios required
for DSGG, leading to inaccurate localization and low-confidence proposals. To
address the challenges posed by external object detectors in WS-DSGG, we
propose a Temporal-enhanced Relation-aware Knowledge Transferring (TRKT)
method, which leverages knowledge to enhance detection in relation-aware
dynamic scenarios. TRKT is built on two key components:(1)Relation-aware
knowledge mining: we first employ object and relation class decoders that
generate category-specific attention maps to highlight both object regions and
interactive areas. Then we propose an Inter-frame Attention Augmentation
strategy that exploits optical flow for neighboring frames to enhance the
attention maps, making them motion-aware and robust to motion blur. This step
yields relation- and motion-aware knowledge mining for WS-DSGG. (2) we
introduce a Dual-stream Fusion Module that integrates category-specific
attention maps into external detections to refine object localization and boost
confidence scores for object proposals. Extensive experiments demonstrate that
TRKT achieves state-of-the-art performance on Action Genome dataset. Our code
is avaliable at https://github.com/XZPKU/TRKT.git.

</details>


### [34] [AdvDINO: Domain-Adversarial Self-Supervised Representation Learning for Spatial Proteomics](https://arxiv.org/abs/2508.04955)
*Stella Su,Marc Harary,Scott J. Rodig,William Lotter*

Main category: cs.CV

TL;DR: AdvDINO, a domain-adversarial self-supervised learning framework, mitigates slide-specific biases to learn more robust and biologically meaningful representations


<details>
  <summary>Details</summary>
Motivation: the robustness of standard SSL methods to domain shift remains uncertain, posing an especially critical challenge in biomedical imaging where batch effects can obscure true biological signals

Method: AdvDINO, a domain-adversarial self-supervised learning framework that integrates a gradient reversal layer into the DINOv2 architecture to promote domain-invariant feature learning

Result: Across >5.46 million mIF image tiles, AdvDINO mitigates slide-specific biases to learn more robust and biologically meaningful representations than non-adversarial baselines. the model uncovers phenotype clusters with distinct proteomic profiles and prognostic significance, and improves survival prediction in attention-based multiple instance learning

Conclusion: AdvDINO mitigates slide-specific biases to learn more robust and biologically meaningful representations than non-adversarial baselines. the model uncovers phenotype clusters with distinct proteomic profiles and prognostic significance, and improves survival prediction in attention-based multiple instance learning

Abstract: Self-supervised learning (SSL) has emerged as a powerful approach for
learning visual representations without manual annotations. However, the
robustness of standard SSL methods to domain shift -- systematic differences
across data sources -- remains uncertain, posing an especially critical
challenge in biomedical imaging where batch effects can obscure true biological
signals. We present AdvDINO, a domain-adversarial self-supervised learning
framework that integrates a gradient reversal layer into the DINOv2
architecture to promote domain-invariant feature learning. Applied to a
real-world cohort of six-channel multiplex immunofluorescence (mIF) whole slide
images from non-small cell lung cancer patients, AdvDINO mitigates
slide-specific biases to learn more robust and biologically meaningful
representations than non-adversarial baselines. Across $>5.46$ million mIF
image tiles, the model uncovers phenotype clusters with distinct proteomic
profiles and prognostic significance, and improves survival prediction in
attention-based multiple instance learning. While demonstrated on mIF data,
AdvDINO is broadly applicable to other imaging domains -- including radiology,
remote sensing, and autonomous driving -- where domain shift and limited
annotated data hinder model generalization and interpretability.

</details>


### [35] [Open-world Point Cloud Semantic Segmentation: A Human-in-the-loop Framework](https://arxiv.org/abs/2508.04962)
*Peng Zhang,Songru Yang,Jinsheng Sun,Weiqing Li,Zhiyong Su*

Main category: cs.CV

TL;DR: HOW-Seg is a human-in-the-loop framework for open-world point cloud semantic segmentation that uses sparse human annotations to achieve high-quality segmentation for both base and novel classes, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing open-world point cloud semantic segmentation (OW-Seg) methods rely on resource-intensive offline incremental learning or densely annotated support data, limiting their practicality.

Method: The authors propose HOW-Seg, a human-in-the-loop framework for open-world point cloud semantic segmentation (OW-Seg). They construct class prototypes directly on the query data and use sparse human annotations as guidance. A hierarchical prototype disambiguation mechanism refines ambiguous prototypes, and a dense conditional random field (CRF) optimizes label assignments.

Result: HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2 with advanced backbones and denser annotations, significantly outperforming alternatives. With sparse annotations, it matches or surpasses state-of-the-art generalized few-shot segmentation (GFS-Seg) under the 5-shot setting.

Conclusion: HOW-Seg dynamically improves its predictions through iterative human feedback, achieving high-quality segmentation for both base and novel classes. Experiments demonstrate that with sparse annotations, HOW-Seg matches or surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg) method under the 5-shot setting. When using advanced backbones and denser annotations, HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2, significantly outperforming alternatives.

Abstract: Open-world point cloud semantic segmentation (OW-Seg) aims to predict point
labels of both base and novel classes in real-world scenarios. However,
existing methods rely on resource-intensive offline incremental learning or
densely annotated support data, limiting their practicality. To address these
limitations, we propose HOW-Seg, the first human-in-the-loop framework for
OW-Seg. Specifically, we construct class prototypes, the fundamental
segmentation units, directly on the query data, avoiding the prototype bias
caused by intra-class distribution shifts between the support and query data.
By leveraging sparse human annotations as guidance, HOW-Seg enables
prototype-based segmentation for both base and novel classes. Considering the
lack of granularity of initial prototypes, we introduce a hierarchical
prototype disambiguation mechanism to refine ambiguous prototypes, which
correspond to annotations of different classes. To further enrich contextual
awareness, we employ a dense conditional random field (CRF) upon the refined
prototypes to optimize their label assignments. Through iterative human
feedback, HOW-Seg dynamically improves its predictions, achieving high-quality
segmentation for both base and novel classes. Experiments demonstrate that with
sparse annotations (e.g., one-novel-class-one-click), HOW-Seg matches or
surpasses the state-of-the-art generalized few-shot segmentation (GFS-Seg)
method under the 5-shot setting. When using advanced backbones (e.g.,
Stratified Transformer) and denser annotations (e.g., 10 clicks per sub-scene),
HOW-Seg achieves 85.27% mIoU on S3DIS and 66.37% mIoU on ScanNetv2,
significantly outperforming alternatives.

</details>


### [36] [UGOD: Uncertainty-Guided Differentiable Opacity and Soft Dropout for Enhanced Sparse-View 3DGS](https://arxiv.org/abs/2508.04968)
*Zhihao Guo,Peng Wang,Zidong Chen,Xiangyu Kong,Yan Lyu,Guanyu Gao,Liangxiu Han*

Main category: cs.CV

TL;DR: 该论文提出了一种新的3DGS方法，通过自适应加权Gaussians来提高稀疏视图场景下的渲染质量，并取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法在渲染时对Gaussians进行同等加权，这使得它们容易过拟合，尤其是在稀疏视图的情况下。

Method: 通过学习的不确定性来表征，研究Gaussians的自适应加权如何影响渲染质量。这种学习的不确定性有两个关键目的：首先，它指导Gaussian不透明度的可微更新，同时保持3DGS管道的完整性；其次，不确定性经历软可微dropout正则化，策略性地将原始不确定性转换为连续的dropout概率，从而控制最终的Gaussian投影和混合过程以进行渲染。

Result: 在广泛采用的数据集上进行的大量实验结果表明，该方法在稀疏视图3D合成中优于其他方法，与现有的稀疏视图方法相比，在大多数数据集中以更少的Gaussians实现了更高质量的重建，例如，与DropGaussian相比，该方法在MipNeRF 360数据集上实现了3.27％的PSNR改进。

Conclusion: 在稀疏视图3D合成中，该方法优于其他方法，与现有的稀疏视图方法相比，在大多数数据集中以更少的Gaussian实现了更高质量的重建。

Abstract: 3D Gaussian Splatting (3DGS) has become a competitive approach for novel view
synthesis (NVS) due to its advanced rendering efficiency through 3D Gaussian
projection and blending. However, Gaussians are treated equally weighted for
rendering in most 3DGS methods, making them prone to overfitting, which is
particularly the case in sparse-view scenarios. To address this, we investigate
how adaptive weighting of Gaussians affects rendering quality, which is
characterised by learned uncertainties proposed. This learned uncertainty
serves two key purposes: first, it guides the differentiable update of Gaussian
opacity while preserving the 3DGS pipeline integrity; second, the uncertainty
undergoes soft differentiable dropout regularisation, which strategically
transforms the original uncertainty into continuous drop probabilities that
govern the final Gaussian projection and blending process for rendering.
Extensive experimental results over widely adopted datasets demonstrate that
our method outperforms rivals in sparse-view 3D synthesis, achieving higher
quality reconstruction with fewer Gaussians in most datasets compared to
existing sparse-view approaches, e.g., compared to DropGaussian, our method
achieves 3.27\% PSNR improvements on the MipNeRF 360 dataset.

</details>


### [37] [CSRAP: Enhanced Canvas Attention Scheduling for Real-Time Mission Critical Perception](https://arxiv.org/abs/2508.04976)
*Md Iftekharul Islam Sakib,Yigong Hu,Tarek Abdelzaher*

Main category: cs.CV

TL;DR: This paper improves canvas-based attention scheduling by allowing for variable-size canvas frames and employing selectable canvas frame rates, which improves the attainable quality/cost trade-offs.


<details>
  <summary>Details</summary>
Motivation: Real-time perception on edge platforms faces a core challenge: executing high-resolution object detection under stringent latency constraints on limited computing resources.

Method: This paper extends prior canvas-based attention scheduling literature by (i) allowing for variable-size canvas frames and (ii) employing selectable canvas frame rates that may depart from the original data frame rate. We evaluate our solution by running YOLOv11, as the perception module, on an NVIDIA Jetson Orin Nano to inspect video frames from the Waymo Open Dataset.

Result: Our results show that the additional degrees of freedom improve the attainable quality/cost trade-offs, thereby allowing for a consistently higher mean average precision (mAP) and recall with respect to the state of the art.

Conclusion: The additional degrees of freedom improve the attainable quality/cost trade-offs, thereby allowing for a consistently higher mean average precision (mAP) and recall with respect to the state of the art.

Abstract: Real-time perception on edge platforms faces a core challenge: executing
high-resolution object detection under stringent latency constraints on limited
computing resources. Canvas-based attention scheduling was proposed in earlier
work as a mechanism to reduce the resource demands of perception subsystems. It
consolidates areas of interest in an input data frame onto a smaller area,
called a canvas frame, that can be processed at the requisite frame rate. This
paper extends prior canvas-based attention scheduling literature by (i)
allowing for variable-size canvas frames and (ii) employing selectable canvas
frame rates that may depart from the original data frame rate. We evaluate our
solution by running YOLOv11, as the perception module, on an NVIDIA Jetson Orin
Nano to inspect video frames from the Waymo Open Dataset. Our results show that
the additional degrees of freedom improve the attainable quality/cost
trade-offs, thereby allowing for a consistently higher mean average precision
(mAP) and recall with respect to the state of the art.

</details>


### [38] [Steering One-Step Diffusion Model with Fidelity-Rich Decoder for Fast Image Compression](https://arxiv.org/abs/2508.04979)
*Zheng Chen,Mingde Zhou,Jinpei Guo,Jiale Yuan,Yifei Ji,Yulun Zhang*

Main category: cs.CV

TL;DR: 提出了SODEC，一种单步扩散图像压缩模型，它更快、更保真。


<details>
  <summary>Details</summary>
Motivation: 基于扩散的图像压缩在感知性能方面表现出色，但存在解码延迟过高和过度依赖生成先验导致的保真度差两个关键缺点。

Method: 提出了一种新的单步扩散图像压缩模型SODEC，利用预训练的VAE模型生成包含丰富信息的潜在变量，并用单步解码代替迭代去噪过程。引入保真度指导模块，提高保真度，并设计了速率退火训练策略。

Result: SODEC在速率-失真-感知性能方面优于现有方法，解码速度提高了20倍以上。

Conclusion: SODEC在速率-失真-感知性能方面显著优于现有方法，并且解码速度提高了20倍以上。

Abstract: Diffusion-based image compression has demonstrated impressive perceptual
performance. However, it suffers from two critical drawbacks: (1) excessive
decoding latency due to multi-step sampling, and (2) poor fidelity resulting
from over-reliance on generative priors. To address these issues, we propose
SODEC, a novel single-step diffusion image compression model. We argue that in
image compression, a sufficiently informative latent renders multi-step
refinement unnecessary. Based on this insight, we leverage a pre-trained
VAE-based model to produce latents with rich information, and replace the
iterative denoising process with a single-step decoding. Meanwhile, to improve
fidelity, we introduce the fidelity guidance module, encouraging output that is
faithful to the original image. Furthermore, we design the rate annealing
training strategy to enable effective training under extremely low bitrates.
Extensive experiments show that SODEC significantly outperforms existing
methods, achieving superior rate-distortion-perception performance. Moreover,
compared to previous diffusion-based compression models, SODEC improves
decoding speed by more than 20$\times$. Code is released at:
https://github.com/zhengchen1999/SODEC.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [39] [Prescriptive Agents based on Rag for Automated Maintenance (PARAM)](https://arxiv.org/abs/2508.04714)
*Chitranshu Harbola,Anupam Purwar*

Main category: cs.AI

TL;DR: 本文提出了一个基于LLM的智能系统，用于规范性维护，该系统超越了传统的异常检测，提供可操作的维护建议。


<details>
  <summary>Details</summary>
Motivation: 工业机械维护需要及时干预，以防止灾难性故障并优化运营效率。本文提出了一种基于大型语言模型 (LLM) 的集成智能系统，用于规范性维护，该系统超越了传统的异常检测，提供可操作的维护建议。

Method: 该方法将轴承振动数据（BPFO、BPFI、BSF、FTF 频率）序列化为自然语言，以便 LLM 处理，从而实现高精度的少量样本异常检测。一个多代理组件使用向量嵌入和语义搜索处理维护手册，同时进行网络搜索以检索全面的程序知识，并访问最新的维护实践，以获得更准确和深入的建议。

Result: 在轴承振动数据集中的实验验证表明，该系统能够有效地进行异常检测并提供上下文相关的维护指导。该系统对故障类型（内圈、外圈、滚珠/滚柱、保持架故障）进行分类并评估严重程度级别。Gemini 模型然后生成结构化的维护建议，包括立即采取的措施、检查清单、纠正措施、零件要求和时间表规范。

Conclusion: 该系统成功弥合了状态监测和可操作的维护计划之间的差距，为工业从业人员提供智能决策支持。这项工作推进了LLM在工业维护中的应用，为跨机械部件和工业部门的规范性维护提供了一个可扩展的框架。

Abstract: Industrial machinery maintenance requires timely intervention to prevent
catastrophic failures and optimize operational efficiency. This paper presents
an integrated Large Language Model (LLM)-based intelligent system for
prescriptive maintenance that extends beyond traditional anomaly detection to
provide actionable maintenance recommendations. Building upon our prior LAMP
framework for numerical data analysis, we develop a comprehensive solution that
combines bearing vibration frequency analysis with multi agentic generation for
intelligent maintenance planning. Our approach serializes bearing vibration
data (BPFO, BPFI, BSF, FTF frequencies) into natural language for LLM
processing, enabling few-shot anomaly detection with high accuracy. The system
classifies fault types (inner race, outer race, ball/roller, cage faults) and
assesses severity levels. A multi-agentic component processes maintenance
manuals using vector embeddings and semantic search, while also conducting web
searches to retrieve comprehensive procedural knowledge and access up-to-date
maintenance practices for more accurate and in-depth recommendations. The
Gemini model then generates structured maintenance recommendations includes
immediate actions, inspection checklists, corrective measures, parts
requirements, and timeline specifications. Experimental validation in bearing
vibration datasets demonstrates effective anomaly detection and contextually
relevant maintenance guidance. The system successfully bridges the gap between
condition monitoring and actionable maintenance planning, providing industrial
practitioners with intelligent decision support. This work advances the
application of LLMs in industrial maintenance, offering a scalable framework
for prescriptive maintenance across machinery components and industrial
sectors.

</details>


### [40] [GeoFlow: Agentic Workflow Automation for Geospatial Tasks](https://arxiv.org/abs/2508.04719)
*Amulya Bhattaram,Justin Chung,Stanley Chung,Ranit Gupta,Janani Ramamoorthy,Kartikeya Gullapalli,Diana Marculescu,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: GeoFlow generates agentic workflows for geospatial tasks with increased agentic success and reduces token usage.


<details>
  <summary>Details</summary>
Motivation: generate agentic workflows for geospatial tasks

Method: a method that provides each agent with detailed tool-calling objectives to guide geospatial API invocation at runtime

Result: GeoFlow increases agentic success by 6.8% and reduces token usage by up to fourfold across major LLM families compared to state-of-the-art approaches

Conclusion: GeoFlow increases agentic success and reduces token usage.

Abstract: We present GeoFlow, a method that automatically generates agentic workflows
for geospatial tasks. Unlike prior work that focuses on reasoning decomposition
and leaves API selection implicit, our method provides each agent with detailed
tool-calling objectives to guide geospatial API invocation at runtime. GeoFlow
increases agentic success by 6.8% and reduces token usage by up to fourfold
across major LLM families compared to state-of-the-art approaches.

</details>


### [41] [Who is a Better Player: LLM against LLM](https://arxiv.org/abs/2508.04720)
*Yingjie Zhou,Jiezhang Cao,Farong Wen,Li Xu,Yanwei Jiang,Jun Jia,Ronghui Li,Xiaohong Liu,Yu Zhou,Xiongkuo Min,Jie Guo,Zicheng Zhang,Guangtao Zhai*

Main category: cs.AI

TL;DR: 提出了一个通过棋盘游戏评估LLM的对抗性基准框架，实验表明LLM在高压环境下表现出适应性，但技能表现不稳定。


<details>
  <summary>Details</summary>
Motivation: 对抗性棋盘游戏长期以来既是流行的竞技活动，也是评估人工智能（AI）系统的基准。主流的基于问答（Q＆A）的基准方法存在数据依赖性的限制，因此需要新的评估方法。

Method: 提出了一个对抗性基准框架，通过棋盘游戏竞赛来评估大型语言模型（LLM）的综合性能。引入了一个专门的评估平台Qi Town，该平台支持5种广泛使用的游戏，并涉及20个LLM驱动的玩家。该平台采用Elo等级系统和一种新的Performance Loop Graph（PLG）来定量评估LLM的技术能力，同时在整个游戏过程中捕获Positive Sentiment Score（PSS）以评估心理健康。

Result: 实验结果表明，大多数LLM对输赢都保持乐观，并且PLG中循环胜负的复杂关系暴露了LLM在游戏过程中技能表现的不稳定性。

Conclusion: 尽管存在技术差异，大多数LLM对输赢都保持乐观，表明它们比人类更能适应高压对抗环境。循环胜负的复杂关系暴露了LLM在游戏过程中技能表现的不稳定性，需要进一步解释和探索。

Abstract: Adversarial board games, as a paradigmatic domain of strategic reasoning and
intelligence, have long served as both a popular competitive activity and a
benchmark for evaluating artificial intelligence (AI) systems. Building on this
foundation, we propose an adversarial benchmarking framework to assess the
comprehensive performance of Large Language Models (LLMs) through board games
competition, compensating the limitation of data dependency of the mainstream
Question-and-Answer (Q&A) based benchmark method. We introduce Qi Town, a
specialized evaluation platform that supports 5 widely played games and
involves 20 LLM-driven players. The platform employs both the Elo rating system
and a novel Performance Loop Graph (PLG) to quantitatively evaluate the
technical capabilities of LLMs, while also capturing Positive Sentiment Score
(PSS) throughout gameplay to assess mental fitness. The evaluation is
structured as a round-robin tournament, enabling systematic comparison across
players. Experimental results indicate that, despite technical differences,
most LLMs remain optimistic about winning and losing, demonstrating greater
adaptability to high-stress adversarial environments than humans. On the other
hand, the complex relationship between cyclic wins and losses in PLGs exposes
the instability of LLMs' skill play during games, warranting further
explanation and exploration.

</details>


### [42] [Fine-Tuning Small Language Models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS)](https://arxiv.org/abs/2508.04846)
*Mahdi Nazari Ashani,Ali Asghar Alesheikh,Saba Kazemi,Kimya Kheirkhah,Yasin Mohammadi,Fatemeh Rezaie,Amir Mahdi Manafi,Hedieh Zarkesh*

Main category: cs.AI

TL;DR: AWebGIS can be effectively implemented using client-side small language models, offering high accuracy, improved privacy, and reduced server load compared to cloud-based LLMs.


<details>
  <summary>Details</summary>
Motivation: Current AWebGIS solutions rely on cloud-based large language models (LLMs), which require continuous internet access and raise privacy and scalability issues.

Method: The study compares three approaches: a fully-automated online method using cloud-based LLMs, a semi-automated offline method using classical machine learning classifiers, and a fully autonomous offline method based on a fine-tuned small language model (T5-small) executed in the client's web browser.

Result: The client-side method using SLMs achieved the highest accuracy, with an exact matching accuracy of 0.93, Levenshtein similarity of 0.99, and ROUGE-1 and ROUGE-L scores of 0.98. This approach also reduces the load on backend servers.

Conclusion: This study demonstrates the feasibility of using browser-executable small language models (SLMs) for Autonomous Web-based Geographical Information Systems (AWebGIS), achieving high accuracy while reducing server load and addressing privacy concerns.

Abstract: Autonomous web-based geographical information systems (AWebGIS) aim to
perform geospatial operations from natural language input, providing intuitive,
intelligent, and hands-free interaction. However, most current solutions rely
on cloud-based large language models (LLMs), which require continuous internet
access and raise users' privacy and scalability issues due to centralized
server processing. This study compares three approaches to enabling AWebGIS:
(1) a fully-automated online method using cloud-based LLMs (e.g., Cohere); (2)
a semi-automated offline method using classical machine learning classifiers
such as support vector machine and random forest; and (3) a fully autonomous
offline (client-side) method based on a fine-tuned small language model (SLM),
specifically T5-small model, executed in the client's web browser. The third
approach, which leverages SLMs, achieved the highest accuracy among all
methods, with an exact matching accuracy of 0.93, Levenshtein similarity of
0.99, and recall-oriented understudy for gisting evaluation ROUGE-1 and ROUGE-L
scores of 0.98. Crucially, this client-side computation strategy reduces the
load on backend servers by offloading processing to the user's device,
eliminating the need for server-based inference. These results highlight the
feasibility of browser-executable models for AWebGIS solutions.

</details>


### [43] [Large Language Models Reasoning Abilities Under Non-Ideal Conditions After RL-Fine-Tuning](https://arxiv.org/abs/2508.04848)
*Chang Tian,Matthew B. Blaschko,Mingzhe Xing,Xiuxing Li,Yinliang Yue,Marie-Francine Moens*

Main category: cs.AI

TL;DR: This paper identifies that the reasoning abilities of large models are often overstated and underscores the importance of evaluating models under non-ideal scenarios.


<details>
  <summary>Details</summary>
Motivation: existing benchmarks evaluate large-language-model reasoning under idealized settings, overlooking performance in realistic, non-ideal scenarios. identify three representative non-ideal scenarios with practical relevance: summary inference, fine-grained noise suppression, and contextual filtering. introduce a new research direction guided by brain-science findings that human reasoning remains reliable under imperfect inputs.

Method: fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM) using RL with a representative policy-gradient algorithm

Result: RL fine-tuning improves baseline reasoning under idealized settings, performance declines significantly across all three non-ideal scenarios

Conclusion: RL fine-tuning improves baseline reasoning under idealized settings, performance declines significantly across all three non-ideal scenarios, exposing critical limitations in advanced reasoning capabilities. current methods leave these reasoning deficits largely unresolved. The reasoning abilities of large models are often overstated and underscores the importance of evaluating models under non-ideal scenarios.

Abstract: Reinforcement learning (RL) has become a key technique for enhancing the
reasoning abilities of large language models (LLMs), with policy-gradient
algorithms dominating the post-training stage because of their efficiency and
effectiveness. However, most existing benchmarks evaluate large-language-model
reasoning under idealized settings, overlooking performance in realistic,
non-ideal scenarios. We identify three representative non-ideal scenarios with
practical relevance: summary inference, fine-grained noise suppression, and
contextual filtering. We introduce a new research direction guided by
brain-science findings that human reasoning remains reliable under imperfect
inputs. We formally define and evaluate these challenging scenarios. We
fine-tune three LLMs and a state-of-the-art large vision-language model (LVLM)
using RL with a representative policy-gradient algorithm and then test their
performance on eight public datasets. Our results reveal that while RL
fine-tuning improves baseline reasoning under idealized settings, performance
declines significantly across all three non-ideal scenarios, exposing critical
limitations in advanced reasoning capabilities. Although we propose a
scenario-specific remediation method, our results suggest current methods leave
these reasoning deficits largely unresolved. This work highlights that the
reasoning abilities of large models are often overstated and underscores the
importance of evaluating models under non-ideal scenarios. The code and data
will be released at XXXX.

</details>


### [44] [ConfAgents: A Conformal-Guided Multi-Agent Framework for Cost-Efficient Medical Diagnosis](https://arxiv.org/abs/2508.04915)
*Huiya Zhao,Yinghao Zhu,Zixiang Wang,Yasha Wang,Junyi Gao,Liantao Ma*

Main category: cs.AI

TL;DR: HealthFlow 是一种自进化人工智能代理，它通过提炼程序上的成功和失败来改进其策略，优于现有技术，并为医疗保健领域的自主人工智能开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 人工智能代理在医疗保健研究中的有效性受到其对静态、预定义策略的依赖的阻碍。这造成了一个关键的限制：代理可以成为更好的工具使用者，但不能学会成为更好的战略规划者，这是医疗保健等复杂领域的一项关键技能。

Method: 引入了一种新颖的元级别进化机制，通过将程序上的成功和失败提炼成持久的战略知识库，自主地改进其自身的高级问题解决策略。

Result: HealthFlow的自进化方法明显优于最先进的代理框架。

Conclusion: HealthFlow显著优于现有技术，标志着从构建更好的工具使用者到设计更智能、自进化的任务管理器的必要转变，为更自主、更有效的科学发现人工智能铺平了道路。

Abstract: The efficacy of AI agents in healthcare research is hindered by their
reliance on static, predefined strategies. This creates a critical limitation:
agents can become better tool-users but cannot learn to become better strategic
planners, a crucial skill for complex domains like healthcare. We introduce
HealthFlow, a self-evolving AI agent that overcomes this limitation through a
novel meta-level evolution mechanism. HealthFlow autonomously refines its own
high-level problem-solving policies by distilling procedural successes and
failures into a durable, strategic knowledge base. To anchor our research and
facilitate reproducible evaluation, we introduce EHRFlowBench, a new benchmark
featuring complex, realistic health data analysis tasks derived from
peer-reviewed clinical research. Our comprehensive experiments demonstrate that
HealthFlow's self-evolving approach significantly outperforms state-of-the-art
agent frameworks. This work marks a necessary shift from building better
tool-users to designing smarter, self-evolving task-managers, paving the way
for more autonomous and effective AI for scientific discovery.

</details>


### [45] [The Docking Game: Loop Self-Play for Fast, Dynamic, and Accurate Prediction of Flexible Protein--Ligand Binding](https://arxiv.org/abs/2508.05006)
*Youzhi Zhang,Yufei Li,Gaofeng Meng,Hongbin Liu,Jiebo Luo*

Main category: cs.AI

TL;DR: The paper introduces LoopPlay, a game-theoretic framework for molecular docking that improves prediction accuracy by 10% compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: current multi-task learning models for docking often show inferior performance in ligand docking compared to protein pocket docking. This disparity arises largely due to the distinct structural complexities of ligands and proteins

Method: a novel game-theoretic framework that models the protein-ligand interaction as a two-player game called the Docking Game, with the ligand docking module acting as the ligand player and the protein pocket docking module as the protein player. To solve this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which alternately trains these players through a two-level loop.

Result: LoopPlay achieves approximately a 10% improvement in predicting accurate binding modes compared to previous state-of-the-art methods

Conclusion: LoopPlay achieves approximately a 10% improvement in predicting accurate binding modes compared to previous state-of-the-art methods. This highlights its potential to enhance the accuracy of molecular docking in drug discovery.

Abstract: Molecular docking is a crucial aspect of drug discovery, as it predicts the
binding interactions between small-molecule ligands and protein pockets.
However, current multi-task learning models for docking often show inferior
performance in ligand docking compared to protein pocket docking. This
disparity arises largely due to the distinct structural complexities of ligands
and proteins. To address this issue, we propose a novel game-theoretic
framework that models the protein-ligand interaction as a two-player game
called the Docking Game, with the ligand docking module acting as the ligand
player and the protein pocket docking module as the protein player. To solve
this game, we develop a novel Loop Self-Play (LoopPlay) algorithm, which
alternately trains these players through a two-level loop. In the outer loop,
the players exchange predicted poses, allowing each to incorporate the other's
structural predictions, which fosters mutual adaptation over multiple
iterations. In the inner loop, each player dynamically refines its predictions
by incorporating its own predicted ligand or pocket poses back into its model.
We theoretically show the convergence of LoopPlay, ensuring stable
optimization. Extensive experiments conducted on public benchmark datasets
demonstrate that LoopPlay achieves approximately a 10\% improvement in
predicting accurate binding modes compared to previous state-of-the-art
methods. This highlights its potential to enhance the accuracy of molecular
docking in drug discovery.

</details>


### [46] [Can Large Language Models Integrate Spatial Data? Empirical Insights into Reasoning Strengths and Computational Weaknesses](https://arxiv.org/abs/2508.05009)
*Bin Han,Robert Wolfe,Anat Caspi,Bill Howe*

Main category: cs.AI

TL;DR: This paper explores the application of large language models (LLMs) to empower domain experts in integrating large, heterogeneous, and noisy urban spatial datasets.


<details>
  <summary>Details</summary>
Motivation: Traditional rule-based integration methods are unable to cover all edge cases, requiring manual verification and repair. Machine learning approaches require collecting and labeling of large numbers of task-specific samples.

Method: We adapt a review-and-refine method to correct erroneous initial responses while preserving accurate responses.

Result: LLMs exhibit spatial reasoning capabilities, they struggle to connect the macro-scale environment with the relevant computational geometry tasks, often producing logically incoherent responses. But when provided relevant features, thereby reducing dependence on spatial reasoning, LLMs are able to generate high-performing results.

Conclusion: LLMs are a promising and flexible alternative to traditional rule-based heuristics for adaptive spatial data integration.

Abstract: We explore the application of large language models (LLMs) to empower domain
experts in integrating large, heterogeneous, and noisy urban spatial datasets.
Traditional rule-based integration methods are unable to cover all edge cases,
requiring manual verification and repair. Machine learning approaches require
collecting and labeling of large numbers of task-specific samples. In this
study, we investigate the potential of LLMs for spatial data integration. Our
analysis first considers how LLMs reason about environmental spatial
relationships mediated by human experience, such as between roads and
sidewalks. We show that while LLMs exhibit spatial reasoning capabilities, they
struggle to connect the macro-scale environment with the relevant computational
geometry tasks, often producing logically incoherent responses. But when
provided relevant features, thereby reducing dependence on spatial reasoning,
LLMs are able to generate high-performing results. We then adapt a
review-and-refine method, which proves remarkably effective in correcting
erroneous initial responses while preserving accurate responses. We discuss
practical implications of employing LLMs for spatial data integration in
real-world contexts and outline future research directions, including
post-training, multi-modal integration methods, and support for diverse data
formats. Our findings position LLMs as a promising and flexible alternative to
traditional rule-based heuristics, advancing the capabilities of adaptive
spatial data integration.

</details>


### [47] [Cognitive Duality for Adaptive Web Agents](https://arxiv.org/abs/2508.05081)
*Jiarun Liu,Chunhong Zhang,Zheng Hu*

Main category: cs.AI

TL;DR: CogniWeb, inspired by dual-process theory, combines offline learning and online planning for efficient web navigation, achieving competitive performance on WebArena.


<details>
  <summary>Details</summary>
Motivation: Web navigation is critical for AGI, demanding complex decision-making in dynamic environments. Current approaches rarely integrate offline imitation learning and online exploration effectively.

Method: A modular agent architecture that adaptively toggles between fast intuitive processing and deliberate reasoning based on task complexity.

Result: CogniWeb achieves 43.96% success rate with 75% reduction in token usage on WebArena.

Conclusion: CogniWeb achieves competitive performance with higher efficiency.

Abstract: Web navigation represents a critical and challenging domain for evaluating
artificial general intelligence (AGI), demanding complex decision-making within
high-entropy, dynamic environments with combinatorially explosive action
spaces. Current approaches to building autonomous web agents either focus on
offline imitation learning or online exploration, but rarely integrate both
paradigms effectively. Inspired by the dual-process theory of human cognition,
we derive a principled decomposition into fast System 1 and slow System 2
cognitive processes. This decomposition provides a unifying perspective on
existing web agent methodologies, bridging the gap between offline learning of
intuitive reactive behaviors and online acquisition of deliberative planning
capabilities. We implement this framework in CogniWeb, a modular agent
architecture that adaptively toggles between fast intuitive processing and
deliberate reasoning based on task complexity. Our evaluation on WebArena
demonstrates that CogniWeb achieves competitive performance (43.96% success
rate) while maintaining significantly higher efficiency (75% reduction in token
usage).

</details>


### [48] [MedMKEB: A Comprehensive Knowledge Editing Benchmark for Medical Multimodal Large Language Models](https://arxiv.org/abs/2508.05083)
*Dexuan Xu,Jieyi Wang,Zhongyan Chai,Yongzhi Cao,Hanpin Wang,Huamin Zhang,Yu Huang*

Main category: cs.AI

TL;DR: 提出了MedMKEB，这是一个综合性基准，旨在评估医学多模态大型语言模型中知识编辑的可靠性、通用性、局部性、可移植性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 允许这些模型有效地更新过时或不正确的信息，而无需从头开始重新训练，这一点至关重要。尽管文本知识编辑已被广泛研究，但仍然缺乏对涉及图像和文本模式的多模态医学知识编辑的系统基准。

Method: 构建在高质量的医学视觉问答数据集之上，并通过精心设计的编辑任务进行丰富，包括反事实纠正、语义概括、知识转移和对抗鲁棒性。

Result: 对最先进的通用和医学 MLLM 的广泛单次编辑和顺序编辑实验表明，现有基于知识的编辑方法在医学中的局限性，突出了开发专门的编辑策略的必要性。

Conclusion: MedMKEB将作为一个标准基准，以促进可信和高效的医学知识编辑算法的开发。

Abstract: Recent advances in multimodal large language models (MLLMs) have
significantly improved medical AI, enabling it to unify the understanding of
visual and textual information. However, as medical knowledge continues to
evolve, it is critical to allow these models to efficiently update outdated or
incorrect information without retraining from scratch. Although textual
knowledge editing has been widely studied, there is still a lack of systematic
benchmarks for multimodal medical knowledge editing involving image and text
modalities. To fill this gap, we present MedMKEB, the first comprehensive
benchmark designed to evaluate the reliability, generality, locality,
portability, and robustness of knowledge editing in medical multimodal large
language models. MedMKEB is built on a high-quality medical visual
question-answering dataset and enriched with carefully constructed editing
tasks, including counterfactual correction, semantic generalization, knowledge
transfer, and adversarial robustness. We incorporate human expert validation to
ensure the accuracy and reliability of the benchmark. Extensive single editing
and sequential editing experiments on state-of-the-art general and medical
MLLMs demonstrate the limitations of existing knowledge-based editing
approaches in medicine, highlighting the need to develop specialized editing
strategies. MedMKEB will serve as a standard benchmark to promote the
development of trustworthy and efficient medical knowledge editing algorithms.

</details>


### [49] [EasySize: Elastic Analog Circuit Sizing via LLM-Guided Heuristic Search](https://arxiv.org/abs/2508.05113)
*Xinyue Wu,Fan Hu,Shaik Jani Babu,Yi Zhao,Xinfei Guo*

Main category: cs.AI

TL;DR: EasySize is a lightweight gate sizing framework based on a finetuned Qwen3-8B model, designed for universal applicability across process nodes, design specifications, and circuit topologies. It achieves strong performance across different technology nodes and outperforms AutoCkt with significant simulation resource reduction.


<details>
  <summary>Details</summary>
Motivation: developing universal, fast, and stable gate sizing methods for analog circuits remains a significant challenge. Recent approaches combine Large Language Models (LLMs) with heuristic search techniques to enhance generalizability, but they often depend on large model sizes and lack portability across different technology nodes.

Method: a lightweight gate sizing framework based on a finetuned Qwen3-8B model, designed for universal applicability across process nodes, design specifications, and circuit topologies. EasySize exploits the varying Ease of Attainability (EOA) of performance metrics to dynamically construct task-specific loss functions, enabling efficient heuristic search through global Differential Evolution (DE) and local Particle Swarm Optimization (PSO) within a feedback-enhanced flow.

Result: achieves strong performance on 5 operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology nodes without additional targeted training, and outperforms AutoCkt, a widely-used Reinforcement Learning based sizing framework, on 86.67% of tasks with more than 96.67% of simulation resources reduction.

Conclusion: EasySize can significantly reduce the reliance on human expertise and computational resources in gate sizing, thereby accelerating and simplifying the analog circuit design process.

Abstract: Analog circuit design is a time-consuming, experience-driven task in chip
development. Despite advances in AI, developing universal, fast, and stable
gate sizing methods for analog circuits remains a significant challenge. Recent
approaches combine Large Language Models (LLMs) with heuristic search
techniques to enhance generalizability, but they often depend on large model
sizes and lack portability across different technology nodes. To overcome these
limitations, we propose EasySize, the first lightweight gate sizing framework
based on a finetuned Qwen3-8B model, designed for universal applicability
across process nodes, design specifications, and circuit topologies. EasySize
exploits the varying Ease of Attainability (EOA) of performance metrics to
dynamically construct task-specific loss functions, enabling efficient
heuristic search through global Differential Evolution (DE) and local Particle
Swarm Optimization (PSO) within a feedback-enhanced flow. Although finetuned
solely on 350nm node data, EasySize achieves strong performance on 5
operational amplifier (Op-Amp) netlists across 180nm, 45nm, and 22nm technology
nodes without additional targeted training, and outperforms AutoCkt, a
widely-used Reinforcement Learning based sizing framework, on 86.67\% of tasks
with more than 96.67\% of simulation resources reduction. We argue that
EasySize can significantly reduce the reliance on human expertise and
computational resources in gate sizing, thereby accelerating and simplifying
the analog circuit design process. EasySize will be open-sourced at a later
date.

</details>


### [50] [Beyond Automation: Socratic AI, Epistemic Agency, and the Implications of the Emergence of Orchestrated Multi-Agent Learning Architectures](https://arxiv.org/abs/2508.05116)
*Peer-Benedikt Degen,Igor Asanov*

Main category: cs.AI

TL;DR: This paper presents findings from a controlled experiment evaluating a Socratic AI Tutor, suggesting that dialogic AI can stimulate metacognitive engagement. The study introduces the notion of orchestrated MAS and proposes an adapted offer-and-use model.


<details>
  <summary>Details</summary>
Motivation: Generative AI is rapidly evolving into a general-purpose infrastructure that reshapes how knowledge is generated, mediated, and validated in higher education.

Method: a controlled experiment evaluating a Socratic AI Tutor with 65 pre-service teacher students in Germany

Result: Students using the Socratic Tutor reported significantly greater support for critical, independent, and reflective thinking.

Conclusion: This study contributes both empirical evidence and a conceptual roadmap for hybrid learning ecosystems that embed human-AI co-agency and pedagogical alignment.

Abstract: Generative AI is no longer a peripheral tool in higher education. It is
rapidly evolving into a general-purpose infrastructure that reshapes how
knowledge is generated, mediated, and validated. This paper presents findings
from a controlled experiment evaluating a Socratic AI Tutor, a large language
model designed to scaffold student research question development through
structured dialogue grounded in constructivist theory. Conducted with 65
pre-service teacher students in Germany, the study compares interaction with
the Socratic Tutor to engagement with an uninstructed AI chatbot. Students
using the Socratic Tutor reported significantly greater support for critical,
independent, and reflective thinking, suggesting that dialogic AI can stimulate
metacognitive engagement and challenging recent narratives of de-skilling due
to generative AI usage. These findings serve as a proof of concept for a
broader pedagogical shift: the use of multi-agent systems (MAS) composed of
specialised AI agents. To conceptualise this, we introduce the notion of
orchestrated MAS, modular, pedagogically aligned agent constellations, curated
by educators, that support diverse learning trajectories through differentiated
roles and coordinated interaction. To anchor this shift, we propose an adapted
offer-and-use model, in which students appropriate instructional offers from
these agents. Beyond technical feasibility, we examine system-level
implications for higher education institutions and students, including funding
necessities, changes to faculty roles, curriculars, competencies and assessment
practices. We conclude with a comparative cost-effectiveness analysis
highlighting the scalability of such systems. In sum, this study contributes
both empirical evidence and a conceptual roadmap for hybrid learning ecosystems
that embed human-AI co-agency and pedagogical alignment.

</details>


### [51] [Graph-based Event Log Repair](https://arxiv.org/abs/2508.05145)
*Sebastiano Dissegna,Chiara Di Francescomarino,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 提出了一种基于异构图神经网络的模型来补全过程挖掘事件日志中的缺失属性，实验结果表明该模型性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 过程挖掘中事件日志的质量至关重要，但现实世界的事件日志常常存在缺失信息的情况。现有的轨迹或日志重建方法要么依赖于过程模型，要么使用机器学习/深度学习模型，而这些方法存在一定的局限性。

Method: 开发了一个异构图神经网络模型，该模型能够处理编码为图的输入数据，利用图神经网络对过程挖掘中的复杂多模态序列进行更自然地表示。

Result: 在两个合成日志和四个真实事件日志上，针对不同类型的缺失值，对该模型进行了评估，结果表明该模型在重建所有不同的事件属性方面表现出非常好的性能，优于使用自动编码器的现有技术水平。

Conclusion: 该研究提出了一种异构图神经网络模型，用于补全包含不完整事件的轨迹中的缺失属性，并且在重建所有不同的事件属性方面表现出非常好的性能。

Abstract: The quality of event logs in Process Mining is crucial when applying any form
of analysis to them. In real-world event logs, the acquisition of data can be
non-trivial (e.g., due to the execution of manual activities and related manual
recording or to issues in collecting, for each event, all its attributes), and
often may end up with events recorded with some missing information. Standard
approaches to the problem of trace (or log) reconstruction either require the
availability of a process model that is used to fill missing values by
leveraging different reasoning techniques or employ a Machine Learning/Deep
Learning model to restore the missing values by learning from similar cases. In
recent years, a new type of Deep Learning model that is capable of handling
input data encoded as graphs has emerged, namely Graph Neural Networks. Graph
Neural Network models, and even more so Heterogeneous Graph Neural Networks,
offer the advantage of working with a more natural representation of complex
multi-modal sequences like the execution traces in Process Mining, allowing for
more expressive and semantically rich encodings.
  In this work, we focus on the development of a Heterogeneous Graph Neural
Network model that, given a trace containing some incomplete events, will
return the full set of attributes missing from those events. We evaluate our
work against a state-of-the-art approach leveraging autoencoders on two
synthetic logs and four real event logs, on different types of missing values.
Different from state-of-the-art model-free approaches, which mainly focus on
repairing a subset of event attributes, the proposed approach shows very good
performance in reconstructing all different event attributes.

</details>


### [52] [QA-Dragon: Query-Aware Dynamic RAG System for Knowledge-Intensive Visual Question Answering](https://arxiv.org/abs/2508.05197)
*Zhuohang Jiang,Pangjing Wu,Xu Yuan,Wenqi Fan,Qing Li*

Main category: cs.AI

TL;DR: This paper introduces QA-Dragon, a query-aware dynamic RAG system for knowledge-intensive VQA, which outperforms baselines in the Meta CRAG-MM Challenge by using a hybrid text and image search approach.


<details>
  <summary>Details</summary>
Motivation: Existing RAG methods typically retrieve from either text or images in isolation, limiting their ability to address complex queries that require multi-hop reasoning or up-to-date factual knowledge. The paper aims to address this limitation.

Method: The paper proposes QA-Dragon, a Query-Aware Dynamic RAG System for Knowledge-Intensive VQA, which introduces a domain router and a search router that dynamically selects optimal retrieval strategies. It orchestrates both text and image search agents in a hybrid setup.

Result: QA-Dragon significantly enhances the reasoning performance of base models under challenging scenarios in the Meta CRAG-MM Challenge at KDD Cup 2025.

Conclusion: The QA-Dragon framework achieves substantial improvements in both answer accuracy and knowledge overlap scores, outperforming baselines by 5.06% on the single-source task, 6.35% on the multi-source task, and 5.03% on the multi-turn task.

Abstract: Retrieval-Augmented Generation (RAG) has been introduced to mitigate
hallucinations in Multimodal Large Language Models (MLLMs) by incorporating
external knowledge into the generation process, and it has become a widely
adopted approach for knowledge-intensive Visual Question Answering (VQA).
However, existing RAG methods typically retrieve from either text or images in
isolation, limiting their ability to address complex queries that require
multi-hop reasoning or up-to-date factual knowledge. To address this
limitation, we propose QA-Dragon, a Query-Aware Dynamic RAG System for
Knowledge-Intensive VQA. Specifically, QA-Dragon introduces a domain router to
identify the query's subject domain for domain-specific reasoning, along with a
search router that dynamically selects optimal retrieval strategies. By
orchestrating both text and image search agents in a hybrid setup, our system
supports multimodal, multi-turn, and multi-hop reasoning, enabling it to tackle
complex VQA tasks effectively. We evaluate our QA-Dragon on the Meta CRAG-MM
Challenge at KDD Cup 2025, where it significantly enhances the reasoning
performance of base models under challenging scenarios. Our framework achieves
substantial improvements in both answer accuracy and knowledge overlap scores,
outperforming baselines by 5.06% on the single-source task, 6.35% on the
multi-source task, and 5.03% on the multi-turn task.

</details>


### [53] [An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication](https://arxiv.org/abs/2508.05267)
*Vítor N. Lourenço,Mohnish Dubey,Yunfei Bai,Audrey Depeige,Vivek Jain*

Main category: cs.AI

TL;DR: RDF graph databases and LLMs are combined to improve communication in large-scale maintenance organizations by enabling precise audience targeting and transparent reasoning.


<details>
  <summary>Details</summary>
Motivation: Traditional communication approaches in large-scale maintenance organizations face challenges like information overload and longer response times.

Method: The proposed framework combines RDF graph databases with LLMs and uses a planning-orchestration architecture.

Result: The solution enables communication owners to formulate intuitive queries and delivers explainable results, improving communication efficiency and maintaining trust.

Conclusion: This paper introduces a framework combining RDF graph databases and LLMs for precise audience targeting and transparent reasoning in large-scale maintenance organizations.

Abstract: In large-scale maintenance organizations, identifying subject matter experts
and managing communications across complex entities relationships poses
significant challenges -- including information overload and longer response
times -- that traditional communication approaches fail to address effectively.
We propose a novel framework that combines RDF graph databases with LLMs to
process natural language queries for precise audience targeting, while
providing transparent reasoning through a planning-orchestration architecture.
Our solution enables communication owners to formulate intuitive queries
combining concepts such as equipment, manufacturers, maintenance engineers, and
facilities, delivering explainable results that maintain trust in the system
while improving communication efficiency across the organization.

</details>


### [54] [A Novel Architecture for Symbolic Reasoning with Decision Trees and LLM Agents](https://arxiv.org/abs/2508.05311)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: a hybrid neuro-symbolic architecture that integrates decision tree reasoning with large language models, achieving strong performance on reasoning benchmarks.


<details>
  <summary>Details</summary>
Motivation: Unlike prior approaches that loosely couple symbolic and neural modules, our design embeds decision trees and random forests as callable oracles within a unified reasoning system.  Tree-based modules enable interpretable rule inference and causal logic, while LLM agents handle abductive reasoning, generalization, and interactive planning. A central orchestrator maintains belief state consistency and mediates communication across agents and external tools, enabling reasoning over both structured and unstructured inputs.

Method: a hybrid architecture that integrates decision tree-based symbolic reasoning with the generative capabilities of large language models (LLMs) within a coordinated multi-agent framework

Result: achieves strong performance on reasoning benchmarks. On ProofWriter, it improves entailment consistency by +7.2\% through logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in multistep mathematical problems via symbolic augmentation. On ARC, it boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.

Conclusion: This architecture offers a robust, interpretable, and extensible solution for general-purpose neuro-symbolic reasoning.

Abstract: We propose a hybrid architecture that integrates decision tree-based symbolic
reasoning with the generative capabilities of large language models (LLMs)
within a coordinated multi-agent framework. Unlike prior approaches that
loosely couple symbolic and neural modules, our design embeds decision trees
and random forests as callable oracles within a unified reasoning system.
Tree-based modules enable interpretable rule inference and causal logic, while
LLM agents handle abductive reasoning, generalization, and interactive
planning. A central orchestrator maintains belief state consistency and
mediates communication across agents and external tools, enabling reasoning
over both structured and unstructured inputs.
  The system achieves strong performance on reasoning benchmarks. On
\textit{ProofWriter}, it improves entailment consistency by +7.2\% through
logic-grounded tree validation. On GSM8k, it achieves +5.3\% accuracy gains in
multistep mathematical problems via symbolic augmentation. On \textit{ARC}, it
boosts abstraction accuracy by +6.0\% through integration of symbolic oracles.
Applications in clinical decision support and scientific discovery show how the
system encodes domain rules symbolically while leveraging LLMs for contextual
inference and hypothesis generation. This architecture offers a robust,
interpretable, and extensible solution for general-purpose neuro-symbolic
reasoning.

</details>


### [55] [The Term 'Agent' Has Been Diluted Beyond Utility and Requires Redefinition](https://arxiv.org/abs/2508.05338)
*Brinnae Bent*

Main category: cs.AI

TL;DR: Redefine the term agent


<details>
  <summary>Details</summary>
Motivation: the term 'agent' requires redefinition because  Recent developments in AI capabilities amplified ambiguity, creating significant challenges

Method: Drawing from historical analysis and contemporary usage patterns

Result: provides precise vocabulary for system description while preserving the term's historically multifaceted nature and offers practical tools for improving research clarity and reproducibility while supporting more effective policy development

Conclusion: propose a framework that defines clear minimum requirements for a system to be considered an agent while characterizing systems along a multidimensional spectrum

Abstract: The term 'agent' in artificial intelligence has long carried multiple
interpretations across different subfields. Recent developments in AI
capabilities, particularly in large language model systems, have amplified this
ambiguity, creating significant challenges in research communication, system
evaluation and reproducibility, and policy development. This paper argues that
the term 'agent' requires redefinition. Drawing from historical analysis and
contemporary usage patterns, we propose a framework that defines clear minimum
requirements for a system to be considered an agent while characterizing
systems along a multidimensional spectrum of environmental interaction,
learning and adaptation, autonomy, goal complexity, and temporal coherence.
This approach provides precise vocabulary for system description while
preserving the term's historically multifaceted nature. After examining
potential counterarguments and implementation challenges, we provide specific
recommendations for moving forward as a field, including suggestions for
terminology standardization and framework adoption. The proposed approach
offers practical tools for improving research clarity and reproducibility while
supporting more effective policy development.

</details>


### [56] [NomicLaw: Emergent Trust and Strategic Argumentation in LLMs During Collaborative Law-Making](https://arxiv.org/abs/2508.05344)
*Asutosh Hota,Jussi P. P. Jokinen*

Main category: cs.AI

TL;DR: LLMs can engage in collaborative law-making, form alliances, betray trust, and adapt their rhetoric to shape collective decisions.


<details>
  <summary>Details</summary>
Motivation: Empirical understanding of LLM behavior in open-ended, multi-agent settings especially those involving deliberation over legal and ethical dilemmas remains limited.

Method: NomicLaw, a structured multi-agent simulation where LLMs engage in collaborative law-making, responding to complex legal vignettes by proposing rules, justifying them, and voting on peer proposals.

Result: Experiments involving homogeneous and heterogeneous LLM groups demonstrate how agents spontaneously form alliances, betray trust, and adapt their rhetoric to shape collective decisions. We quantitatively measure trust and reciprocity via voting patterns and qualitatively assess how agents use strategic language to justify proposals and influence outcomes.

Conclusion: This paper highlights the latent social reasoning and persuasive capabilities of ten open-source LLMs and provide insights into the design of future AI systems capable of autonomous negotiation, coordination and drafting legislation in legal settings.

Abstract: Recent advancements in large language models (LLMs) have extended their
capabilities from basic text processing to complex reasoning tasks, including
legal interpretation, argumentation, and strategic interaction. However,
empirical understanding of LLM behavior in open-ended, multi-agent settings
especially those involving deliberation over legal and ethical dilemmas remains
limited. We introduce NomicLaw, a structured multi-agent simulation where LLMs
engage in collaborative law-making, responding to complex legal vignettes by
proposing rules, justifying them, and voting on peer proposals. We
quantitatively measure trust and reciprocity via voting patterns and
qualitatively assess how agents use strategic language to justify proposals and
influence outcomes. Experiments involving homogeneous and heterogeneous LLM
groups demonstrate how agents spontaneously form alliances, betray trust, and
adapt their rhetoric to shape collective decisions. Our results highlight the
latent social reasoning and persuasive capabilities of ten open-source LLMs and
provide insights into the design of future AI systems capable of autonomous
negotiation, coordination and drafting legislation in legal settings.

</details>


### [57] [Minimal Model Reasoning in Description Logics: Don't Try This at Home!](https://arxiv.org/abs/2508.05350)
*Federica Di Stefano,Quentin Manière,Magdalena Ortiz,Mantas Šimkus*

Main category: cs.AI

TL;DR: 研究了描述逻辑中纯最小模型的问题，发现概念的可满足性是不可判定的，但通过施加非循环条件可以重新获得可判定性。


<details>
  <summary>Details</summary>
Motivation: 使用最小模型进行推理一直是许多知识表示技术的核心，但我们对描述逻辑（DLs）中的这个问题仍然只有有限的理解。在限定中提出的最小化一些选定的谓词，让剩余的谓词变化或固定，已经被探索过，并且表现出高复杂性。所有谓词的扩展必须最小的`纯'最小模型的情况，在很大程度上仍未被探索。

Method: 在流行的DLs中解决这个问题，并在TBox上施加非循环条件。

Result: 通过对TBox施加非循环条件，将最坏情况下的复杂性降低到双指数时间以下，并允许我们建立与最近研究的逐点限定的联系；我们还在数据复杂性方面得出了结果。我们以DL-Lite家族的简要考察作为结束，其中DL-Lite$_{text{core}}$有一个积极的结果，但我们的研究表明，对于它的扩展DL-Lite$_{text{horn}}$，已经存在ExpSpace-hardness。

Conclusion: 概念的可满足性在最小模型中是不可判定的，即使对于$\\mathcal{EL}$也是如此。这种不可判定性也延伸到tuple-generating dependencies的一个非常受限的片段。

Abstract: Reasoning with minimal models has always been at the core of many knowledge
representation techniques, but we still have only a limited understanding of
this problem in Description Logics (DLs). Minimization of some selected
predicates, letting the remaining predicates vary or be fixed, as proposed in
circumscription, has been explored and exhibits high complexity. The case of
`pure' minimal models, where the extension of all predicates must be minimal,
has remained largely uncharted. We address this problem in popular DLs and
obtain surprisingly negative results: concept satisfiability in minimal models
is undecidable already for $\mathcal{EL}$. This undecidability also extends to
a very restricted fragment of tuple-generating dependencies. To regain
decidability, we impose acyclicity conditions on the TBox that bring the
worst-case complexity below double exponential time and allow us to establish a
connection with the recently studied pointwise circumscription; we also derive
results in data complexity. We conclude with a brief excursion to the DL-Lite
family, where a positive result was known for DL-Lite$_{\text{core}}$, but our
investigation establishes ExpSpace-hardness already for its extension
DL-Lite$_{\text{horn}}$.

</details>


### [58] [StructVRM: Aligning Multimodal Reasoning with Structured and Verifiable Reward Models](https://arxiv.org/abs/2508.05383)
*Xiangxiang Zhang,Jingxuan Wei,Donghong Zhong,Qi Chen,Caijun Jia,Cheng Tan,Jinming Gu,Xiaobo Qin,Zhiping Liu,Liang Hu,Tong Sun,Yuchen Wu,Zewei Sun,Chenwei Lou,Hua Zheng,Tianyang Zhan,Changbao Wang,Shuangzhi Wu,Zefa Lin,Chang Guo,Sihang Yuan,Riwei Chen,Shixiong Zhao,Yingping Zhang,Gaowei Wu,Bihui Yu,Jiahui Wu,Zhehui Zhao,Qianqian Liu,Ruofeng Tang,Xingyue Huang,Bing Zhao,Mengyang Zhang,Youqiang Zhou*

Main category: cs.AI

TL;DR: introduces StructVRM, a method that aligns multimodal reasoning with Structured and Verifiable Reward Models, which allows for nuanced, partial credit scoring in previously intractable problem formats.


<details>
  <summary>Details</summary>
Motivation: Existing Vision-Language Models often struggle with complex, multi-question reasoning tasks where partial correctness is crucial for effective learning. Traditional reward mechanisms, which provide a single binary score for an entire response, are too coarse to guide models through intricate problems with multiple sub-parts.

Method: a method that aligns multimodal reasoning with Structured and Verifiable Reward Models. At its core is a model-based verifier trained to provide fine-grained, sub-question-level feedback, assessing semantic and mathematical equivalence rather than relying on rigid string matching.

Result: achieves state-of-the-art performance on six out of twelve public multimodal benchmarks and our newly curated, high-difficulty STEM-Bench.

Conclusion: The success of StructVRM validates that training with structured, verifiable rewards is a highly effective approach for advancing the capabilities of multimodal models in complex, real-world reasoning domains.

Abstract: Existing Vision-Language Models often struggle with complex, multi-question
reasoning tasks where partial correctness is crucial for effective learning.
Traditional reward mechanisms, which provide a single binary score for an
entire response, are too coarse to guide models through intricate problems with
multiple sub-parts. To address this, we introduce StructVRM, a method that
aligns multimodal reasoning with Structured and Verifiable Reward Models. At
its core is a model-based verifier trained to provide fine-grained,
sub-question-level feedback, assessing semantic and mathematical equivalence
rather than relying on rigid string matching. This allows for nuanced, partial
credit scoring in previously intractable problem formats. Extensive experiments
demonstrate the effectiveness of StructVRM. Our trained model, Seed-StructVRM,
achieves state-of-the-art performance on six out of twelve public multimodal
benchmarks and our newly curated, high-difficulty STEM-Bench. The success of
StructVRM validates that training with structured, verifiable rewards is a
highly effective approach for advancing the capabilities of multimodal models
in complex, real-world reasoning domains.

</details>


### [59] [An Explainable Machine Learning Framework for Railway Predictive Maintenance using Data Streams from the Metro Operator of Portugal](https://arxiv.org/abs/2508.05388)
*Silvia García-Méndez,Francisco de Arriba-Pérez,Fátima Leal,Bruno Veloso,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.AI

TL;DR: 提出了一种用于智能交通系统的实时数据驱动预测性维护解决方案，该方案具有在线处理流水线，可实现高精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为智能交通系统提供实时数据驱动的预测性维护解决方案。

Method: 该方法实现了一个处理流水线，该流水线包括样本预处理、使用机器学习模型进行增量分类和结果解释。

Result: 使用来自葡萄牙波尔图地铁运营商的 MetroPT 数据集进行的实验结果表明，F-measure 超过 98%，准确率超过 99%。

Conclusion: 该流水线即使在存在类别不平衡和噪声的情况下也能保持高性能，并且其解释有效地反映了决策过程。这些发现验证了该方法的合理性，并证实了其在支持现实世界铁路运营中的主动维护决策方面的实际适用性。因此，通过识别故障的早期迹象，该流水线使决策者能够了解根本问题并迅速采取相应行动。

Abstract: This work contributes to a real-time data-driven predictive maintenance
solution for Intelligent Transportation Systems. The proposed method implements
a processing pipeline comprised of sample pre-processing, incremental
classification with Machine Learning models, and outcome explanation. This
novel online processing pipeline has two main highlights: (i) a dedicated
sample pre-processing module, which builds statistical and frequency-related
features on the fly, and (ii) an explainability module. This work is the first
to perform online fault prediction with natural language and visual
explainability. The experiments were performed with the MetroPT data set from
the metro operator of Porto, Portugal. The results are above 98 % for F-measure
and 99 % for accuracy. In the context of railway predictive maintenance,
achieving these high values is crucial due to the practical and operational
implications of accurate failure prediction. In the specific case of a high
F-measure, this ensures that the system maintains an optimal balance between
detecting the highest possible number of real faults and minimizing false
alarms, which is crucial for maximizing service availability. Furthermore, the
accuracy obtained enables reliability, directly impacting cost reduction and
increased safety. The analysis demonstrates that the pipeline maintains high
performance even in the presence of class imbalance and noise, and its
explanations effectively reflect the decision-making process. These findings
validate the methodological soundness of the approach and confirm its practical
applicability for supporting proactive maintenance decisions in real-world
railway operations. Therefore, by identifying the early signs of failure, this
pipeline enables decision-makers to understand the underlying problems and act
accordingly swiftly.

</details>


### [60] [DeepPHY: Benchmarking Agentic VLMs on Physical Reasoning](https://arxiv.org/abs/2508.05405)
*Xinrun Xu,Pi Bu,Ye Wang,Börje F. Karlsson,Ziming Wang,Tengtao Song,Qi Zhu,Jun Song,Zhiming Ding,Bo Zheng*

Main category: cs.AI

TL;DR: 视觉语言模型在物理推理方面表现不佳。我们引入了DeepPHY基准来评估它们在模拟环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLMs)表现出强大的感知能力和令人印象深刻的视觉推理能力，但它们在复杂、动态环境中难以关注细节和进行精确的行动规划，导致性能不佳。现实世界的任务通常需要复杂的交互、先进的空间推理、长期规划和持续的策略改进，通常需要理解目标场景的物理规则。然而，在现实场景中评估这些能力通常非常昂贵。

Method: 引入DeepPHY，一个旨在系统评估视觉语言模型对基本物理原理的理解和推理的新型基准框架，该框架通过一系列具有挑战性的模拟环境。

Result: 我们的评估发现，即使是最先进的视觉语言模型也难以将描述性的物理知识转化为精确的预测控制。

Conclusion: 即使是最先进的视觉语言模型也难以将描述性的物理知识转化为精确的预测控制。

Abstract: Although Vision Language Models (VLMs) exhibit strong perceptual abilities
and impressive visual reasoning, they struggle with attention to detail and
precise action planning in complex, dynamic environments, leading to subpar
performance. Real-world tasks typically require complex interactions, advanced
spatial reasoning, long-term planning, and continuous strategy refinement,
usually necessitating understanding the physics rules of the target scenario.
However, evaluating these capabilities in real-world scenarios is often
prohibitively expensive. To bridge this gap, we introduce DeepPHY, a novel
benchmark framework designed to systematically evaluate VLMs' understanding and
reasoning about fundamental physical principles through a series of challenging
simulated environments. DeepPHY integrates multiple physical reasoning
environments of varying difficulty levels and incorporates fine-grained
evaluation metrics. Our evaluation finds that even state-of-the-art VLMs
struggle to translate descriptive physical knowledge into precise, predictive
control.

</details>


### [61] [Large Language Models Transform Organic Synthesis From Reaction Prediction to Automation](https://arxiv.org/abs/2508.05427)
*Kartar Kumar Lohana Tharwani,Rajesh Kumar,Sumita,Numan Ahmed,Yong Tang*

Main category: cs.AI

TL;DR: 大型语言模型正在改变化学家计划和进行有机合成反应的方式。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）正在改变化学家计划和进行有机合成反应的方式。

Method: 对大型语言模型（LLM）在有机合成中应用的里程碑进行调查。

Result: 展示了LLM与图神经网络、量子计算和实时光谱的耦合如何缩短发现周期并支持更环保、数据驱动的化学。讨论了局限性，包括有偏见的数据集、不透明的推理以及对防止意外危险的安全门的需求。概述了社区倡议，开放基准、联邦学习和可解释的界面，旨在 democratize 访问，同时让人类牢牢控制。

Conclusion: 人工智能和自动化正在推动快速、可靠和包容的分子创新。

Abstract: Large language models (LLMs) are beginning to reshape how chemists plan and
run reactions in organic synthesis. Trained on millions of reported
transformations, these text-based models can propose synthetic routes, forecast
reaction outcomes and even instruct robots that execute experiments without
human supervision. Here we survey the milestones that turned LLMs from
speculative tools into practical lab partners. We show how coupling LLMs with
graph neural networks, quantum calculations and real-time spectroscopy shrinks
discovery cycles and supports greener, data-driven chemistry. We discuss
limitations, including biased datasets, opaque reasoning and the need for
safety gates that prevent unintentional hazards. Finally, we outline community
initiatives open benchmarks, federated learning and explainable interfaces that
aim to democratize access while keeping humans firmly in control. These
advances chart a path towards rapid, reliable and inclusive molecular
innovation powered by artificial intelligence and automation.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [62] [AgenticData: An Agentic Data Analytics System for Heterogeneous Data](https://arxiv.org/abs/2508.05002)
*Ji Sun,Guoliang Li,Peiyao Zhou,Yihui Ma,Jingzhe Xu,Yuan Li*

Main category: cs.DB

TL;DR: AgenticData is an agentic data analytics system that allows users to simply pose natural language questions while autonomously analyzing data sources across multiple domains, including both unstructured and structured data.


<details>
  <summary>Details</summary>
Motivation: Existing unstructured data analytics systems rely on experts to write code and manage complex analysis workflows, making them both expensive and time-consuming.

Method: AgenticData employs a feedback-driven planning technique that automatically converts an NL query into a semantic plan composed of relational and semantic operators. It proposes a multi-agent collaboration strategy and a semantic optimization model.

Result: AgenticData achieved superior accuracy on both easy and difficult tasks, significantly outperforming state-of-the-art methods.

Conclusion: AgenticData achieves superior accuracy on both easy and difficult tasks, significantly outperforming state-of-the-art methods.

Abstract: Existing unstructured data analytics systems rely on experts to write code
and manage complex analysis workflows, making them both expensive and
time-consuming. To address these challenges, we introduce AgenticData, an
innovative agentic data analytics system that allows users to simply pose
natural language (NL) questions while autonomously analyzing data sources
across multiple domains, including both unstructured and structured data.
First, AgenticData employs a feedback-driven planning technique that
automatically converts an NL query into a semantic plan composed of relational
and semantic operators. We propose a multi-agent collaboration strategy by
utilizing a data profiling agent for discovering relevant data, a semantic
cross-validation agent for iterative optimization based on feedback, and a
smart memory agent for maintaining short-term context and long-term knowledge.
Second, we propose a semantic optimization model to refine and execute semantic
plans effectively. Our system, AgenticData, has been tested using three
benchmarks. Experimental results showed that AgenticData achieved superior
accuracy on both easy and difficult tasks, significantly outperforming
state-of-the-art methods.

</details>


### [63] [Making Prompts First-Class Citizens for Adaptive LLM Pipelines](https://arxiv.org/abs/2508.05012)
*Ugur Cetintemel,Shu Chen,Alexander W. Lee,Deepti Raghavan*

Main category: cs.DB

TL;DR: SPEAR introduces a new language and runtime for managing prompts in LLM pipelines, making them structured, adaptive, and optimizable.


<details>
  <summary>Details</summary>
Motivation: Modern LLM pipelines are increasingly data-centric, but prompts remain brittle, opaque strings disconnected from the surrounding dataflow, limiting reuse, optimization, and runtime control.

Method: The paper presents the design of SPEAR, a language and runtime featuring a prompt algebra for constructing and adapting prompts. It supports multiple refinement modes and optimizations.

Result: Preliminary experiments quantify the behavior of different refinement modes compared to static prompts and agentic retries, as well as the impact of prompt-level optimizations such as operator fusion.

Conclusion: The paper introduces SPEAR, a language and runtime for structured, adaptive prompt management in LLM pipelines, enabling runtime prompt refinement, structured prompt management, and optimizations like operator fusion.

Abstract: Modern LLM pipelines increasingly resemble data-centric systems: they
retrieve external context, compose intermediate outputs, validate results, and
adapt based on runtime feedback. Yet, the central element guiding this process
-- the prompt -- remains a brittle, opaque string, disconnected from the
surrounding dataflow. This disconnect limits reuse, optimization, and runtime
control.
  In this paper, we describe our vision and an initial design for SPEAR, a
language and runtime that fills this prompt management gap by making prompts
structured, adaptive, and first-class components of the execution model. SPEAR
enables (1) runtime prompt refinement -- modifying prompts dynamically in
response to execution-time signals such as confidence, latency, or missing
context; and (2) structured prompt management -- organizing prompt fragments
into versioned views with support for introspection and logging.
  SPEAR defines a prompt algebra that governs how prompts are constructed and
adapted within a pipeline. It supports multiple refinement modes (manual,
assisted, and automatic), giving developers a balance between control and
automation. By treating prompt logic as structured data, SPEAR enables
optimizations such as operator fusion, prefix caching, and view reuse.
Preliminary experiments quantify the behavior of different refinement modes
compared to static prompts and agentic retries, as well as the impact of
prompt-level optimizations such as operator fusion.

</details>


### [64] [Data-Aware Socratic Query Refinement in Database Systems](https://arxiv.org/abs/2508.05061)
*Ruiyuan Zhang,Chrysanthi Kosyfaki,Xiaofang Zhou*

Main category: cs.DB

TL;DR: DASG通过交互式澄清来增强自然语言查询，提高了查询精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询中的歧义性问题

Method: Data-Aware Socratic Guidance (DASG)，一个基于对话的查询增强框架，它将交互式澄清作为数据库系统中的一等公民操作符嵌入，以解决自然语言查询中的歧义。

Result: DASG在三个数据集上表现出改进的查询精度，同时保持了效率。

Conclusion: DASG提升了查询精度并保持了效率，建立了一种协作分析范式，系统主动参与查询制定，而不是被动地翻译用户请求。

Abstract: In this paper, we propose Data-Aware Socratic Guidance (DASG), a
dialogue-based query enhancement framework that embeds \linebreak interactive
clarification as a first-class operator within database systems to resolve
ambiguity in natural language queries. DASG treats dialogue as an optimization
decision, asking clarifying questions only when the expected execution cost
reduction exceeds the interaction overhead. The system quantifies ambiguity
through linguistic fuzziness, schema grounding confidence, and projected costs
across relational and vector backends. Our algorithm selects the optimal
clarifications by combining semantic relevance, catalog-based information gain,
and potential cost reduction. We evaluate our proposed framework on three
datasets. The results show that DASG demonstrates improved query precision
while maintaining efficiency, establishing a cooperative analytics paradigm
where systems actively participate in query formulation rather than passively
translating user requests.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [65] [Augmented Question-guided Retrieval (AQgR) of Indian Case Law with LLM, RAG, and Structured Summaries](https://arxiv.org/abs/2508.04710)
*Vishnuprabha V,Daleesha M Viswanathan,Rajesh R,Aneesh V Pillai*

Main category: cs.IR

TL;DR: 该论文提出了一种使用LLM进行案例检索的新方法，该方法使用RAG和AQgR框架，并在FIRE数据集上取得了比现有方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的案例检索方法侧重于事实相似性而非法律问题，并且缺乏解释，这使得识别相关的法律先例仍然具有挑战性。

Method: 该方法结合了检索增强生成（RAG）与针对印度案例法优化的结构化摘要，并利用增强问题引导检索（AQgR）框架，基于事实情景生成有针对性的法律问题，以更有效地识别相关案例法。

Result: 在FIRE 2019数据集的子集上进行的实验评估显示，该方法取得了有希望的结果，在测试查询中实现了0.36的平均精度均值（MAP）和0.67的平均召回率均值（MAR），显著超过了当前0.1573的MAP基准。

Conclusion: 该论文提出了一种使用大型语言模型（LLM）来改进案例检索的方法，该方法通过生成解释来阐明相关性，并识别核心法律问题，无需法律专业知识。实验结果表明，该方法在案例检索方面取得了显著的改进。

Abstract: Identifying relevant legal precedents remains challenging, as most retrieval
methods emphasize factual similarity over legal issues, and current systems
often lack explanations clarifying case relevance. This paper proposes the use
of Large Language Models (LLMs) to address this gap by facilitating the
retrieval of relevant cases, generating explanations to elucidate relevance,
and identifying core legal issues all autonomously, without requiring legal
expertise. Our approach combines Retrieval Augmented Generation (RAG) with
structured summaries optimized for Indian case law. Leveraging the Augmented
Question-guided Retrieval (AQgR) framework, the system generates targeted legal
questions based on factual scenarios to identify relevant case law more
effectively. The structured summaries were assessed manually by legal experts,
given the absence of a suitable structured summary dataset. Case law retrieval
was evaluated using the FIRE dataset, and explanations were reviewed by legal
experts, as explanation generation alongside case retrieval is an emerging
innovation. Experimental evaluation on a subset of the FIRE 2019 dataset
yielded promising outcomes, achieving a Mean Average Precision (MAP) score of
0.36 and a Mean Average Recall (MAR) of 0.67 across test queries, significantly
surpassing the current MAP benchmark of 0.1573. This work introduces a suite of
novel contributions to advance case law retrieval. By transitioning from
fact-based to legal-issue-based retrieval, the proposed approach delivers more
contextually relevant results that align closely with legal professionals'
needs. Integrating legal questions within the retrieval process through the
AQgR framework ensures more precise and meaningful retrieval by refining the
context of queries.

</details>


### [66] [Scaling Generative Recommendations with Context Parallelism on Hierarchical Sequential Transducers](https://arxiv.org/abs/2508.04711)
*Yue Dong,Han Li,Shen Li,Nikhil Patel,Xing Liu,Xiaodong Wang,Chuanhao Zhuge*

Main category: cs.IR

TL;DR: 本文提出了一种用于扩展推荐系统中用户交互序列长度的上下文并行方法，该方法在扩展序列长度的同时，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 大规模推荐系统对于处理大量的日常用户交互至关重要，需要对高基数和异构特征进行有效建模，以确保准确的预测。扩展序列长度是激活密集型的，需要并行解决方案来有效地共享激活内存。

Method: 引入了支持锯齿张量的 HSTU 注意力的上下文并行性

Result: 支持的用户交互序列长度增加了 5.3 倍，并且在与分布式数据并行 (DDP) 结合使用时，实现了 1.55 倍的缩放因子。

Conclusion: 该论文介绍了一种用于 HSTU 注意力的上下文并行方法，该方法支持锯齿张量，为扩大序列维度奠定了基础。该方法能够将支持的用户交互序列长度增加 5.3 倍，并且在与分布式数据并行 (DDP) 结合使用时，可实现 1.55 倍的缩放因子。

Abstract: Large-scale recommendation systems are pivotal to process an immense volume
of daily user interactions, requiring the effective modeling of high
cardinality and heterogeneous features to ensure accurate predictions. In prior
work, we introduced Hierarchical Sequential Transducers (HSTU), an
attention-based architecture for modeling high cardinality, non-stationary
streaming recommendation data, providing good scaling law in the generative
recommender framework (GR). Recent studies and experiments demonstrate that
attending to longer user history sequences yields significant metric
improvements. However, scaling sequence length is activation-heavy,
necessitating parallelism solutions to effectively shard activation memory. In
transformer-based LLMs, context parallelism (CP) is a commonly used technique
that distributes computation along the sequence-length dimension across
multiple GPUs, effectively reducing memory usage from attention activations. In
contrast, production ranking models typically utilize jagged input tensors to
represent user interaction features, introducing unique CP implementation
challenges. In this work, we introduce context parallelism with jagged tensor
support for HSTU attention, establishing foundational capabilities for scaling
up sequence dimensions. Our approach enables a 5.3x increase in supported user
interaction sequence length, while achieving a 1.55x scaling factor when
combined with Distributed Data Parallelism (DDP).

</details>


### [67] [A Metric for MLLM Alignment in Large-scale Recommendation](https://arxiv.org/abs/2508.04963)
*Yubin Zhang,Yanhua Huang,Haiming Xu,Mingliang Qi,Chang Wang,Jiarui Jin,Xiangyuan Ren,Xiaodan Wang,Ruiwen Xu*

Main category: cs.IR

TL;DR: This paper introduces LIS, a new metric for evaluating MLLM alignment in recommender systems, and shows its effectiveness in real-world online A/B tests.


<details>
  <summary>Details</summary>
Motivation: Evaluating the alignment of multimodal large language models (MLLMs) for recommendation is challenging due to static benchmarks' inaccuracy, the high cost of online system evaluations, and the lack of actionable insights from conventional metrics.

Method: The paper proposes the Leakage Impact Score (LIS) metric to measure the upper bound of preference data.

Result: Online A/B tests on Xiaohongshu's Explore Feed demonstrate the effectiveness of LIS, with significant improvements in user spent time and advertiser value.

Conclusion: The paper introduces the Leakage Impact Score (LIS) metric and demonstrates its effectiveness through online A/B tests on Xiaohongshu's Explore Feed, showing improvements in user engagement and advertiser value.

Abstract: Multimodal recommendation has emerged as a critical technique in modern
recommender systems, leveraging content representations from advanced
multimodal large language models (MLLMs). To ensure these representations are
well-adapted, alignment with the recommender system is essential. However,
evaluating the alignment of MLLMs for recommendation presents significant
challenges due to three key issues: (1) static benchmarks are inaccurate
because of the dynamism in real-world applications, (2) evaluations with online
system, while accurate, are prohibitively expensive at scale, and (3)
conventional metrics fail to provide actionable insights when learned
representations underperform. To address these challenges, we propose the
Leakage Impact Score (LIS), a novel metric for multimodal recommendation.
Rather than directly assessing MLLMs, LIS efficiently measures the upper bound
of preference data. We also share practical insights on deploying MLLMs with
LIS in real-world scenarios. Online A/B tests on both Content Feed and Display
Ads of Xiaohongshu's Explore Feed production demonstrate the effectiveness of
our proposed method, showing significant improvements in user spent time and
advertiser value.

</details>


### [68] [Align-for-Fusion: Harmonizing Triple Preferences via Dual-oriented Diffusion for Cross-domain Sequential Recommendation](https://arxiv.org/abs/2508.05074)
*Yongfu Zha,Xinxin Dong,Haokai Ma,Yonghui Yang,Xiaodong Wang*

Main category: cs.IR

TL;DR: 提出了一种名为HorizonRec的框架，用于跨域序列推荐，通过双向扩散模型协调三重偏好，从而实现一致的多域偏好建模。


<details>
  <summary>Details</summary>
Motivation: 为了缓解数据稀疏和兴趣漂移问题，传统方法通常通过跨域转换来整合来自其他领域的辅助行为。然而，现有的跨域序列推荐（CDSR）方法通常遵循一种对齐然后融合的范例，该范例执行跨多个域的表示级别对齐，并将它们机械地组合起来以进行推荐，忽略了领域特定偏好的细粒度融合。

Method: 提出了一种双向偏好扩散方法，以抑制潜在噪声并强调多域用户表示融合期间的目标相关兴趣。

Result: 在来自两个不同平台的四个CDSR数据集上进行了大量实验，证明了HorizonRec在细粒度的三域偏好融合方面的有效性和稳健性。

Conclusion: HorizonRec在细粒度的三域偏好融合方面表现出有效性和稳健性。

Abstract: Personalized sequential recommendation aims to predict appropriate items for
users based on their behavioral sequences. To alleviate data sparsity and
interest drift issues, conventional approaches typically incorporate auxiliary
behaviors from other domains via cross-domain transition. However, existing
cross-domain sequential recommendation (CDSR) methods often follow an
align-then-fusion paradigm that performs representation-level alignment across
multiple domains and combines them mechanically for recommendation, overlooking
the fine-grained fusion of domain-specific preferences. Inspired by recent
advances in diffusion models (DMs) for distribution matching, we propose an
align-for-fusion framework for CDSR to harmonize triple preferences via
dual-oriented DMs, termed HorizonRec. Specifically, we investigate the
uncertainty injection of DMs and identify stochastic noise as a key source of
instability in existing DM-based recommenders. To address this, we introduce a
mixed-conditioned distribution retrieval strategy that leverages distributions
retrieved from users' authentic behavioral logic as semantic bridges across
domains, enabling consistent multi-domain preference modeling. Furthermore, we
propose a dual-oriented preference diffusion method to suppress potential noise
and emphasize target-relevant interests during multi-domain user representation
fusion. Extensive experiments on four CDSR datasets from two distinct platforms
demonstrate the effectiveness and robustness of HorizonRec in fine-grained
triple-domain preference fusion.

</details>


### [69] [An End-to-End Multi-objective Ensemble Ranking Framework for Video Recommendation](https://arxiv.org/abs/2508.05093)
*Tiantian He,Minzhi Xie,Runtong Li,Xiaoxiao Xu,Jiaqi Yu,Zixiu Wang,Lantao Hu,Han Li,Kun Gai*

Main category: cs.IR

TL;DR: 提出了一种新的端到端多目标集成排序框架(EMER)，并在快手上取得了显著的效果。


<details>
  <summary>Details</summary>
Motivation: 通过用端到端建模范式取代手动设计的启发式公式来增强个性化。

Method: 提出了一种新的端到端多目标集成排序框架(EMER)。

Result: 在真实工业数据集上进行了大量的经验测试，结果充分证明了所提出的框架的有效性。

Conclusion: 在快手短视频推荐平台上部署后，App停留时长增加了1.39%，7日用户生命周期(LT7)增加了0.196%，效果显著。

Abstract: We propose a novel End-to-end Multi-objective Ensemble Ranking framework
(EMER) for the multi-objective ensemble ranking module, which is the most
critical component of the short video recommendation system. EMER enhances
personalization by replacing manually-designed heuristic formulas with an
end-to-end modeling paradigm. EMER introduces a meticulously designed loss
function to address the fundamental challenge of defining effective supervision
for ensemble ranking, where no single ground-truth signal can fully capture
user satisfaction. Moreover, EMER introduces novel sample organization method
and transformer-based network architecture to capture the comparative
relationships among candidates, which are critical for effective ranking.
Additionally, we have proposed an offline-online consistent evaluation system
to enhance the efficiency of offline model optimization, which is an
established yet persistent challenge within the multi-objective ranking domain
in industry. Abundant empirical tests are conducted on a real industrial
dataset, and the results well demonstrate the effectiveness of our proposed
framework. In addition, our framework has been deployed in the primary
scenarios of Kuaishou, a short video recommendation platform with hundreds of
millions of daily active users, achieving a 1.39% increase in overall App Stay
Time and a 0.196% increase in 7-day user Lifetime(LT7), which are substantial
improvements.

</details>


### [70] [Navigating Through Paper Flood: Advancing LLM-based Paper Evaluation through Domain-Aware Retrieval and Latent Reasoning](https://arxiv.org/abs/2508.05129)
*Wuqiang Zheng,Yiyan Xu,Xinyu Lin,Chongming Gao,Wenjie Wang,Fuli Feng*

Main category: cs.IR

TL;DR: PaperEval 是一种用于自动论文评估的 LLM 框架，它优于现有方法，并在真实的论文推荐系统中表现出实际有效性。


<details>
  <summary>Details</summary>
Motivation: 随着学术出版物的快速和持续增长，识别高质量的研究已成为一个越来越紧迫的挑战。现有方法受过时的领域知识和有限的推理能力约束。

Method: 一种新颖的基于LLM的自动论文评估框架，通过领域感知论文检索模块和潜在推理机制来解决现有方法的局限性。

Result: PaperEval在学术影响和论文质量评估方面始终优于现有方法。在真实的论文推荐系统中部署 PaperEval 过滤高质量论文，该系统在社交媒体上获得了广泛的参与。

Conclusion: PaperEval在学术影响和论文质量评估方面始终优于现有方法。它已部署在真实的论文推荐系统中，用于过滤高质量论文，并在社交媒体上获得了广泛的参与。

Abstract: With the rapid and continuous increase in academic publications, identifying
high-quality research has become an increasingly pressing challenge. While
recent methods leveraging Large Language Models (LLMs) for automated paper
evaluation have shown great promise, they are often constrained by outdated
domain knowledge and limited reasoning capabilities. In this work, we present
PaperEval, a novel LLM-based framework for automated paper evaluation that
addresses these limitations through two key components: 1) a domain-aware paper
retrieval module that retrieves relevant concurrent work to support
contextualized assessments of novelty and contributions, and 2) a latent
reasoning mechanism that enables deep understanding of complex motivations and
methodologies, along with comprehensive comparison against concurrently related
work, to support more accurate and reliable evaluation. To guide the reasoning
process, we introduce a progressive ranking optimization strategy that
encourages the LLM to iteratively refine its predictions with an emphasis on
relative comparison. Experiments on two datasets demonstrate that PaperEval
consistently outperforms existing methods in both academic impact and paper
quality evaluation. In addition, we deploy PaperEval in a real-world paper
recommendation system for filtering high-quality papers, which has gained
strong engagement on social media -- amassing over 8,000 subscribers and
attracting over 10,000 views for many filtered high-quality papers --
demonstrating the practical effectiveness of PaperEval.

</details>


### [71] [Tool Graph Retriever: Exploring Dependency Graph-based Tool Retrieval for Large Language Models](https://arxiv.org/abs/2508.05152)
*Linfeng Gao,Yaoxiang Wang,Minlong Peng,Jialong Tang,Yuzhe Shang,Mingming Sun,Jinsong Su*

Main category: cs.IR

TL;DR: 提出了一种名为工具图检索器 (TGR) 的新工具检索方法，该方法利用工具依赖关系来提高性能。


<details>
  <summary>Details</summary>
Motivation: 由于人工智能代理的显著进步，它们配备的工具数量正在迅速增加。然而，将所有工具信息集成到有限的模型上下文中变得不切实际，这突显了对高效工具检索方法的需求。然而，它们通常独立考虑每个工具，忽略了工具之间的依赖关系，这可能导致遗漏成功执行任务的先决工具。

Method: 提出工具图检索器 (TGR)，它利用工具之间的依赖关系来学习更好的工具表示以进行检索。首先，我们构建一个名为 TDI300K 的数据集，以训练用于识别工具依赖关系的判别器。然后，我们将所有候选工具表示为工具依赖关系图，并使用图卷积将依赖关系集成到它们的表示中。最后，这些更新的工具表示用于在线检索。

Result: 在多个常用数据集上的实验结果表明，我们的 TGR 可以为现有主流方法带来性能改进，实现 SOTA 性能。此外，深入分析也验证了工具依赖关系的重要性和我们的 TGR 的有效性。

Conclusion: TGR通过利用工具依赖关系，在常用数据集上实现了SOTA性能，验证了工具依赖关系的重要性。

Abstract: With the remarkable advancement of AI agents, the number of their equipped
tools is increasing rapidly. However, integrating all tool information into the
limited model context becomes impractical, highlighting the need for efficient
tool retrieval methods. In this regard, dominant methods primarily rely on
semantic similarities between tool descriptions and user queries to retrieve
relevant tools. However, they often consider each tool independently,
overlooking dependencies between tools, which may lead to the omission of
prerequisite tools for successful task execution. To deal with this defect, in
this paper, we propose Tool Graph Retriever (TGR), which exploits the
dependencies among tools to learn better tool representations for retrieval.
First, we construct a dataset termed TDI300K to train a discriminator for
identifying tool dependencies. Then, we represent all candidate tools as a tool
dependency graph and use graph convolution to integrate the dependencies into
their representations. Finally, these updated tool representations are employed
for online retrieval. Experimental results on several commonly used datasets
show that our TGR can bring a performance improvement to existing dominant
methods, achieving SOTA performance. Moreover, in-depth analyses also verify
the importance of tool dependencies and the effectiveness of our TGR.

</details>


### [72] [Balancing Accuracy and Novelty with Sub-Item Popularity](https://arxiv.org/abs/2508.05198)
*Chiara Mallamaci,Aleksandr Vladimirovich Petrov,Alberto Carlo Maria Mancino,Vito Walter Anelli,Tommaso Di Noia,Craig Macdonald*

Main category: cs.IR

TL;DR: The paper introduces sPPS, a novel method to improve personalised novelty in music recommendation by integrating sub-ID-level personalised popularity within the RecJPQ framework.


<details>
  <summary>Details</summary>
Motivation: Personalised Popularity Scores (PPS) enhances relevance in recommendation, it often reinforces already-known content, limiting the system's ability to surface novel or serendipitous items - key elements for fostering long-term user engagement and satisfaction.

Method: A novel integration of sub-ID-level personalised popularity within the RecJPQ framework.

Result: sPPS achieves significantly higher personalised novelty without compromising recommendation accuracy compared to item-level PPS.

Conclusion: The sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by achieving significantly higher personalised novelty without compromising recommendation accuracy.

Abstract: In the realm of music recommendation, sequential recommenders have shown
promise in capturing the dynamic nature of music consumption. A key
characteristic of this domain is repetitive listening, where users frequently
replay familiar tracks. To capture these repetition patterns, recent research
has introduced Personalised Popularity Scores (PPS), which quantify
user-specific preferences based on historical frequency. While PPS enhances
relevance in recommendation, it often reinforces already-known content,
limiting the system's ability to surface novel or serendipitous items - key
elements for fostering long-term user engagement and satisfaction. To address
this limitation, we build upon RecJPQ, a Transformer-based framework initially
developed to improve scalability in large-item catalogues through sub-item
decomposition. We repurpose RecJPQ's sub-item architecture to model
personalised popularity at a finer granularity. This allows us to capture
shared repetition patterns across sub-embeddings - latent structures not
accessible through item-level popularity alone. We propose a novel integration
of sub-ID-level personalised popularity within the RecJPQ framework, enabling
explicit control over the trade-off between accuracy and personalised novelty.
Our sub-ID-level PPS method (sPPS) consistently outperforms item-level PPS by
achieving significantly higher personalised novelty without compromising
recommendation accuracy. Code and experiments are publicly available at
https://github.com/sisinflab/Sub-id-Popularity.

</details>


### [73] [FIRE: Faithful Interpretable Recommendation Explanations](https://arxiv.org/abs/2508.05225)
*S. M. F. Sani,Asal Meskin,Mohammad Amanlou,Hamid R. Rabiee*

Main category: cs.IR

TL;DR: 本文提出了一种轻量级的可解释框架FIRE，用于生成忠实、多样且用户对齐的解释，从而克服现有推荐系统中解释的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在与模型预测弱对齐、识别用户意图模糊或不准确以及过度重复或通用等常见限制。

Method: 结合了基于SHAP的特征属性与结构化的、提示驱动的语言生成。

Result: FIRE不仅实现了具有竞争力的推荐准确率，而且在对齐、结构和忠实度等关键维度上显著提高了推荐解释的质量。

Conclusion: FIRE在提高解释质量的同时，实现了具有竞争力的推荐准确率，强调了超越评论作为解释范式的必要性，并朝着负责任和可解释的解释方法发展。

Abstract: Natural language explanations in recommender systems are often framed as a
review generation task, leveraging user reviews as ground-truth supervision.
While convenient, this approach conflates a user's opinion with the system's
reasoning, leading to explanations that may be fluent but fail to reflect the
true logic behind recommendations. In this work, we revisit the core objective
of explainable recommendation: to transparently communicate why an item is
recommended by linking user needs to relevant item features. Through a
comprehensive analysis of existing methods across multiple benchmark datasets,
we identify common limitations-explanations that are weakly aligned with model
predictions, vague or inaccurate in identifying user intents, and overly
repetitive or generic. To overcome these challenges, we propose FIRE, a
lightweight and interpretable framework that combines SHAP-based feature
attribution with structured, prompt-driven language generation. FIRE produces
faithful, diverse, and user-aligned explanations, grounded in the actual
decision-making process of the model. Our results demonstrate that FIRE not
only achieves competitive recommendation accuracy but also significantly
improves explanation quality along critical dimensions such as alignment,
structure, and faithfulness. This work highlights the need to move beyond the
review-as-explanation paradigm and toward explanation methods that are both
accountable and interpretable.

</details>


### [74] [Difference Views for Visual Graph Query Building](https://arxiv.org/abs/2508.05314)
*Benedikt Kantz,Stefan Lengauer,Peter Waldert,Tobias Schreck*

Main category: cs.IR

TL;DR: A visual query interface uses graph differences and natural language to help users explore and analyze knowledge graphs.


<details>
  <summary>Details</summary>
Motivation: Existing visual query builders enable non-expert users to construct SPARQL queries, but query building is an iterative process where the user's question can change.

Method: A visual querying interface communicates changes between iterative steps using graph differences and integrates a natural language interface.

Result: The change in results is communicated in the result view by contrasting the differences in both result distribution and individual instances of the prototype graph.

Conclusion: The system's applicability is demonstrated through case studies on different ontologies and usage scenarios, illustrating how the system fosters both data exploration and analysis of domain-specific graphs.

Abstract: Knowledge Graphs (KGs) contain vast amounts of linked resources that encode
knowledge in various domains, which can be queried and searched for using
specialized languages like SPARQL, a query language developed to query KGs.
Existing visual query builders enable non-expert users to construct SPARQL
queries and utilize the knowledge contained in these graphs. Query building is,
however, an iterative and, often, visual process where the question of the user
can change and differ throughout the process, especially for explorative
search. Our visual querying interface communicates these change between
iterative steps in the query building process using graph differences to
contrast the changes and the evolution in the graph query. We also enable users
to formulate their evolving information needs using a natural language
interface directly integrated into the difference query view. We, furthermore,
communicate the change in results in the result view by contrasting the
differences in both result distribution and individual instances of the
prototype graph and demonstrate the system's applicability through case studies
on different ontologies and usage scenarios, illustrating how our system
fosters, both, data exploration and analysis of domain-specific graphs.

</details>


### [75] [Multi-Modal Multi-Behavior Sequential Recommendation with Conditional Diffusion-Based Feature Denoising](https://arxiv.org/abs/2508.05352)
*Xiaoxi Cui,Weihai Lu,Yu Tong,Yiheng Li,Zhejun Zhao*

Main category: cs.IR

TL;DR: 提出了一种新的多模态多行为序列推荐模型 (M$^3$BSR)，通过条件扩散去噪和多专家兴趣提取来提高推荐性能，实验结果表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 有效地整合多样化的用户行为模式与丰富的项目多模态信息，以提高序列推荐的准确性，这是一个新兴且具有挑战性的研究方向。本文着重于多模态多行为序列推荐问题，旨在解决以下挑战：(1) 缺乏对不同行为的模态偏好的有效表征，因为用户对不同项目模态的关注程度因行为而异；(2) 难以有效缓解用户行为中的隐式噪声，例如意外点击等非故意的动作；(3) 无法处理多模态表示中的模态噪声，这进一步影响了用户偏好的准确建模。

Method: 提出了一种新的多模态多行为序列推荐模型 (M$^3$BSR)。该模型首先使用条件扩散模态去噪层去除多模态表示中的噪声。随后，它利用深层行为信息来指导浅层行为数据的去噪，从而通过条件扩散行为去噪来减轻隐式反馈中的噪声影响。最后，通过引入多专家兴趣提取层，M$^3$BSR 显式地建模了跨行为和模态的共同和特定兴趣，以提高推荐性能。

Result: 实验结果表明 M$^3$BSR 在基准数据集上明显优于现有的最佳方法。

Conclusion: M$^3$BSR显著优于现有最佳方法。

Abstract: The sequential recommendation system utilizes historical user interactions to
predict preferences. Effectively integrating diverse user behavior patterns
with rich multimodal information of items to enhance the accuracy of sequential
recommendations is an emerging and challenging research direction. This paper
focuses on the problem of multi-modal multi-behavior sequential recommendation,
aiming to address the following challenges: (1) the lack of effective
characterization of modal preferences across different behaviors, as user
attention to different item modalities varies depending on the behavior; (2)
the difficulty of effectively mitigating implicit noise in user behavior, such
as unintended actions like accidental clicks; (3) the inability to handle
modality noise in multi-modal representations, which further impacts the
accurate modeling of user preferences. To tackle these issues, we propose a
novel Multi-Modal Multi-Behavior Sequential Recommendation model (M$^3$BSR).
This model first removes noise in multi-modal representations using a
Conditional Diffusion Modality Denoising Layer. Subsequently, it utilizes deep
behavioral information to guide the denoising of shallow behavioral data,
thereby alleviating the impact of noise in implicit feedback through
Conditional Diffusion Behavior Denoising. Finally, by introducing a
Multi-Expert Interest Extraction Layer, M$^3$BSR explicitly models the common
and specific interests across behaviors and modalities to enhance
recommendation performance. Experimental results indicate that M$^3$BSR
significantly outperforms existing state-of-the-art methods on benchmark
datasets.

</details>


### [76] [Does Multimodality Improve Recommender Systems as Expected? A Critical Analysis and Future Directions](https://arxiv.org/abs/2508.05377)
*Hongyu Zhou,Yinan Zhang,Aixin Sun,Zhiqi Shen*

Main category: cs.IR

TL;DR: This paper proposes a structured evaluation framework to assess multimodal recommendations. The findings show that multimodal data is particularly beneficial in sparse interaction scenarios and during the recall stage. The importance of each modality is task-specific.


<details>
  <summary>Details</summary>
Motivation: The actual benefits of integrating diverse data types in multimodal recommendation systems remain unclear, raising questions about when and how it truly enhances recommendations.

Method: a structured evaluation framework to systematically assess multimodal recommendations across four dimensions: Comparative Efficiency, Recommendation Tasks, Recommendation Stages, and Multimodal Data Integration. benchmark a set of reproducible multimodal models against strong traditional baselines and evaluate their performance on different platforms. explore different integration strategies and model sizes, include case studies and review findings from other recommendation domains.

Result: Multimodal data is particularly beneficial in sparse interaction scenarios and during the recall stage of recommendation pipelines. The importance of each modality is task-specific. Ensemble-Based Learning outperforms Fusion-Based Learning, and larger models do not necessarily deliver better results.

Conclusion: Multimodal data is particularly beneficial in sparse interaction scenarios and during the recall stage of recommendation pipelines. The importance of each modality is task-specific, where text features are more useful in e-commerce and visual features are more effective in short-video recommendations. Ensemble-Based Learning outperforms Fusion-Based Learning, and larger models do not necessarily deliver better results.

Abstract: Multimodal recommendation systems are increasingly popular for their
potential to improve performance by integrating diverse data types. However,
the actual benefits of this integration remain unclear, raising questions about
when and how it truly enhances recommendations. In this paper, we propose a
structured evaluation framework to systematically assess multimodal
recommendations across four dimensions: Comparative Efficiency, Recommendation
Tasks, Recommendation Stages, and Multimodal Data Integration. We benchmark a
set of reproducible multimodal models against strong traditional baselines and
evaluate their performance on different platforms. Our findings show that
multimodal data is particularly beneficial in sparse interaction scenarios and
during the recall stage of recommendation pipelines. We also observe that the
importance of each modality is task-specific, where text features are more
useful in e-commerce and visual features are more effective in short-video
recommendations. Additionally, we explore different integration strategies and
model sizes, finding that Ensemble-Based Learning outperforms Fusion-Based
Learning, and that larger models do not necessarily deliver better results. To
deepen our understanding, we include case studies and review findings from
other recommendation domains. Our work provides practical insights for building
efficient and effective multimodal recommendation systems, emphasizing the need
for thoughtful modality selection, integration strategies, and model design.

</details>


### [77] [On the Reliability of Sampling Strategies in Offline Recommender Evaluation](https://arxiv.org/abs/2508.05398)
*Bruno L. Pereira,Alan Said,Rodrygo L. T. Santos*

Main category: cs.IR

TL;DR: This paper studies how logging and sampling biases impact offline recommender system evaluation and provides guidance for more reliable evaluations.


<details>
  <summary>Details</summary>
Motivation: Offline evaluation in recommender systems is susceptible to exposure bias and sampling bias, which can affect the reliability of model comparisons.

Method: The paper uses a fully observed dataset to simulate diverse exposure biases and assesses the reliability of common sampling strategies.

Result: The findings highlight when and how sampling distorts evaluation outcomes and offer guidance for selecting faithful and robust offline comparison strategies.

Conclusion: This paper investigates how different logging and sampling choices affect the reliability of offline evaluation.

Abstract: Offline evaluation plays a central role in benchmarking recommender systems
when online testing is impractical or risky. However, it is susceptible to two
key sources of bias: exposure bias, where users only interact with items they
are shown, and sampling bias, introduced when evaluation is performed on a
subset of logged items rather than the full catalog. While prior work has
proposed methods to mitigate sampling bias, these are typically assessed on
fixed logged datasets rather than for their ability to support reliable model
comparisons under varying exposure conditions or relative to true user
preferences. In this paper, we investigate how different combinations of
logging and sampling choices affect the reliability of offline evaluation.
Using a fully observed dataset as ground truth, we systematically simulate
diverse exposure biases and assess the reliability of common sampling
strategies along four dimensions: sampling resolution (recommender model
separability), fidelity (agreement with full evaluation), robustness (stability
under exposure bias), and predictive power (alignment with ground truth). Our
findings highlight when and how sampling distorts evaluation outcomes and offer
practical guidance for selecting strategies that yield faithful and robust
offline comparisons.

</details>


### [78] [RankArena: A Unified Platform for Evaluating Retrieval, Reranking and RAG with Human and LLM Feedback](https://arxiv.org/abs/2508.05512)
*Abdelrahman Abdallah,Mahmoud Abdalla,Bhawna Piryani,Jamshid Mozafari,Mohammed Ali,Adam Jatowt*

Main category: cs.IR

TL;DR: RankArena是一个统一的平台，用于评估检索增强生成(RAG)和文档重排序系统的质量，它使用结构化的人工和LLM反馈，支持多种评估模式，并存储所有交互作为结构化的评估数据集。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏可扩展的、以用户为中心的和多视角的评估工具，评估检索增强生成(RAG)和文档重排序系统的质量仍然具有挑战性。

Method: 引入RankArena平台，一个统一的平台，用于比较和分析检索管道，重排序器和RAG系统的性能，使用结构化的人工和LLM反馈，以及用于收集此类反馈。

Result: RankArena支持多种评估模式：直接重排序可视化、人工或LLM投票的盲配对比较、监督手动文档注释和端到端RAG答案质量评估。它通过配对偏好和完整列表注释来捕获细粒度的相关性反馈，以及辅助元数据，如移动指标、注释时间和质量评级。该平台还集成了LLM-as-a-judge评估，从而可以在模型生成的排名和人工基本真值注释之间进行比较。

Conclusion: RankArena平台通过结构化的人工和LLM反馈，以及用于收集此类反馈，来比较和分析检索管道、重排序器和RAG系统的性能。所有交互都存储为结构化的评估数据集，可用于训练重排序器、奖励模型、判断代理或检索策略选择器。

Abstract: Evaluating the quality of retrieval-augmented generation (RAG) and document
reranking systems remains challenging due to the lack of scalable,
user-centric, and multi-perspective evaluation tools. We introduce RankArena, a
unified platform for comparing and analysing the performance of retrieval
pipelines, rerankers, and RAG systems using structured human and LLM-based
feedback as well as for collecting such feedback. RankArena supports multiple
evaluation modes: direct reranking visualisation, blind pairwise comparisons
with human or LLM voting, supervised manual document annotation, and end-to-end
RAG answer quality assessment. It captures fine-grained relevance feedback
through both pairwise preferences and full-list annotations, along with
auxiliary metadata such as movement metrics, annotation time, and quality
ratings. The platform also integrates LLM-as-a-judge evaluation, enabling
comparison between model-generated rankings and human ground truth annotations.
All interactions are stored as structured evaluation datasets that can be used
to train rerankers, reward models, judgment agents, or retrieval strategy
selectors. Our platform is publicly available at https://rankarena.ngrok.io/,
and the Demo video is provided https://youtu.be/jIYAP4PaSSI.

</details>


### [79] [KuaiLive: A Real-time Interactive Dataset for Live Streaming Recommendation](https://arxiv.org/abs/2508.05633)
*Changle Qu,Sunhao Dai,Ke Guo,Liqin Zhao,Yanan Niu,Xiao Zhang,Jun Xu*

Main category: cs.IR

TL;DR: Introduce a new real-time interactive dataset KuaiLive collected from Kuaishou, which can support a wide range of tasks in the live streaming domain.


<details>
  <summary>Details</summary>
Motivation: research progress in academia has been hindered by the lack of publicly available datasets that accurately reflect the dynamic nature of live streaming environments

Method: introduce KuaiLive, the first real-time, interactive dataset collected from Kuaishou

Result: thorough analysis of KuaiLive from multiple perspectives and evaluate several representative recommendation methods on it, establishing a strong benchmark for future research

Conclusion: KuaiLive can support a wide range of tasks in the live streaming domain, such as top-K recommendation, click-through rate prediction, watch time prediction, and gift price prediction. Moreover, its fine-grained behavioral data also enables research on multi-behavior modeling, multi-task learning, and fairness-aware recommendation.

Abstract: Live streaming platforms have become a dominant form of online content
consumption, offering dynamically evolving content, real-time interactions, and
highly engaging user experiences. These unique characteristics introduce new
challenges that differentiate live streaming recommendation from traditional
recommendation settings and have garnered increasing attention from industry in
recent years. However, research progress in academia has been hindered by the
lack of publicly available datasets that accurately reflect the dynamic nature
of live streaming environments. To address this gap, we introduce KuaiLive, the
first real-time, interactive dataset collected from Kuaishou, a leading live
streaming platform in China with over 400 million daily active users. The
dataset records the interaction logs of 23,772 users and 452,621 streamers over
a 21-day period. Compared to existing datasets, KuaiLive offers several
advantages: it includes precise live room start and end timestamps, multiple
types of real-time user interactions (click, comment, like, gift), and rich
side information features for both users and streamers. These features enable
more realistic simulation of dynamic candidate items and better modeling of
user and streamer behaviors. We conduct a thorough analysis of KuaiLive from
multiple perspectives and evaluate several representative recommendation
methods on it, establishing a strong benchmark for future research. KuaiLive
can support a wide range of tasks in the live streaming domain, such as top-K
recommendation, click-through rate prediction, watch time prediction, and gift
price prediction. Moreover, its fine-grained behavioral data also enables
research on multi-behavior modeling, multi-task learning, and fairness-aware
recommendation. The dataset and related resources are publicly available at
https://imgkkk574.github.io/KuaiLive.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [80] [NAEx: A Plug-and-Play Framework for Explaining Network Alignment](https://arxiv.org/abs/2508.04731)
*Shruti Saxena,Arijit Khan,Joydeep Chandra*

Main category: cs.LG

TL;DR: NAEx: a plug-and-play, model-agnostic framework that explains alignment models by identifying key subgraphs and features influencing predictions.


<details>
  <summary>Details</summary>
Motivation: Despite advances in alignment models, their interpretability remains limited, making it difficult to understand alignment decisions and posing challenges in building trust, particularly in high-stakes domains. To address this, we introduce NAEx

Method: NAEx, a plug-and-play, model-agnostic framework that explains alignment models by identifying key subgraphs and features influencing predictions. NAEx addresses the key challenge of preserving the joint cross-network dependencies on alignment decisions by: (1) jointly parameterizing graph structures and feature spaces through learnable edge and feature masks, and (2) introducing an optimization objective that ensures explanations are both faithful to the original predictions and enable meaningful comparisons of structural and feature-based similarities between networks.

Result: demonstrate NAEx's effectiveness and efficiency on benchmark datasets by integrating it with four representative NA models.

Conclusion: NAEx is an inductive framework that efficiently generates NA explanations for previously unseen data. We introduce evaluation metrics tailored to alignment explainability and demonstrate NAEx's effectiveness and efficiency on benchmark datasets by integrating it with four representative NA models.

Abstract: Network alignment (NA) identifies corresponding nodes across multiple
networks, with applications in domains like social networks, co-authorship, and
biology. Despite advances in alignment models, their interpretability remains
limited, making it difficult to understand alignment decisions and posing
challenges in building trust, particularly in high-stakes domains. To address
this, we introduce NAEx, a plug-and-play, model-agnostic framework that
explains alignment models by identifying key subgraphs and features influencing
predictions. NAEx addresses the key challenge of preserving the joint
cross-network dependencies on alignment decisions by: (1) jointly
parameterizing graph structures and feature spaces through learnable edge and
feature masks, and (2) introducing an optimization objective that ensures
explanations are both faithful to the original predictions and enable
meaningful comparisons of structural and feature-based similarities between
networks. NAEx is an inductive framework that efficiently generates NA
explanations for previously unseen data. We introduce evaluation metrics
tailored to alignment explainability and demonstrate NAEx's effectiveness and
efficiency on benchmark datasets by integrating it with four representative NA
models.

</details>


### [81] [LumiGen: An LVLM-Enhanced Iterative Framework for Fine-Grained Text-to-Image Generation](https://arxiv.org/abs/2508.04732)
*Xiaoqi Dong,Xiangyu Zhou,Nicholas Evans,Yujia Lin*

Main category: cs.LG

TL;DR: LumiGen, an LVLM-enhanced framework, improves T2I generation, especially in fine-grained control, using a closed-loop feedback mechanism.


<details>
  <summary>Details</summary>
Motivation: Existing T2I models often struggle with tasks like accurate text rendering, precise pose generation, or intricate compositional coherence.

Method: LumiGen, a novel LVLM-enhanced iterative framework with an Intelligent Prompt Parsing & Augmentation (IPPA) module and an Iterative Visual Feedback & Refinement (IVFR) module.

Result: LumiGen achieves a superior average score of 3.08, outperforming state-of-the-art baselines. Significant improvements are seen in text rendering and pose expression.

Conclusion: LumiGen achieves a superior average score of 3.08 on the challenging LongBench-T2I Benchmark, outperforming state-of-the-art baselines. The framework demonstrates significant improvements in critical dimensions such as text rendering and pose expression.

Abstract: Text-to-Image (T2I) generation has made significant advancements with
diffusion models, yet challenges persist in handling complex instructions,
ensuring fine-grained content control, and maintaining deep semantic
consistency. Existing T2I models often struggle with tasks like accurate text
rendering, precise pose generation, or intricate compositional coherence.
Concurrently, Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in cross-modal understanding and instruction following. We propose
LumiGen, a novel LVLM-enhanced iterative framework designed to elevate T2I
model performance, particularly in areas requiring fine-grained control,
through a closed-loop, LVLM-driven feedback mechanism. LumiGen comprises an
Intelligent Prompt Parsing & Augmentation (IPPA) module for proactive prompt
enhancement and an Iterative Visual Feedback & Refinement (IVFR) module, which
acts as a "visual critic" to iteratively correct and optimize generated images.
Evaluated on the challenging LongBench-T2I Benchmark, LumiGen achieves a
superior average score of 3.08, outperforming state-of-the-art baselines.
Notably, our framework demonstrates significant improvements in critical
dimensions such as text rendering and pose expression, validating the
effectiveness of LVLM integration for more controllable and higher-quality
image generation.

</details>


### [82] [MissMecha: An All-in-One Python Package for Studying Missing Data Mechanisms](https://arxiv.org/abs/2508.04740)
*Youran Zhou,Mohamed Reda Bouadjenek,Sunil Aryal*

Main category: cs.LG

TL;DR: MissMecha: a Python toolkit for simulating, visualizing, and evaluating missing data in mixed-type tabular datasets.


<details>
  <summary>Details</summary>
Motivation: Incomplete data is a persistent challenge in real-world datasets, often governed by complex and unobservable missing mechanisms. Simulating missingness has become a standard approach for understanding its impact on learning and analysis. However, existing tools are fragmented, mechanism-limited, and typically focus only on numerical variables, overlooking the heterogeneous nature of real-world tabular data.

Method: an open-source Python toolkit for simulating, visualizing, and evaluating missing data under MCAR, MAR, and MNAR assumptions. MissMecha supports both numerical and categorical features, enabling mechanism-aware studies across mixed-type tabular datasets. It includes visual diagnostics, MCAR testing utilities, and type-aware imputation evaluation metrics.

Result: MissMecha supports both numerical and categorical features, enabling mechanism-aware studies across mixed-type tabular datasets. It includes visual diagnostics, MCAR testing utilities, and type-aware imputation evaluation metrics.

Conclusion: MissMecha is a unified platform for researchers and practitioners working with incomplete data.

Abstract: Incomplete data is a persistent challenge in real-world datasets, often
governed by complex and unobservable missing mechanisms. Simulating missingness
has become a standard approach for understanding its impact on learning and
analysis. However, existing tools are fragmented, mechanism-limited, and
typically focus only on numerical variables, overlooking the heterogeneous
nature of real-world tabular data. We present MissMecha, an open-source Python
toolkit for simulating, visualizing, and evaluating missing data under MCAR,
MAR, and MNAR assumptions. MissMecha supports both numerical and categorical
features, enabling mechanism-aware studies across mixed-type tabular datasets.
It includes visual diagnostics, MCAR testing utilities, and type-aware
imputation evaluation metrics. Designed to support data quality research,
benchmarking, and education,MissMecha offers a unified platform for researchers
and practitioners working with incomplete data.

</details>


### [83] [Edge-Assisted Collaborative Fine-Tuning for Multi-User Personalized Artificial Intelligence Generated Content (AIGC)](https://arxiv.org/abs/2508.04745)
*Nan Li,Wanting Yang,Marie Siew,Zehui Xiong,Binbin Chen,Shiwen Mao,Kwok-Yan Lam*

Main category: cs.LG

TL;DR: 提出了一种新的集群感知分层联邦聚合框架，以解决边缘设备上扩散模型推理的计算挑战，同时解决隐私风险和个性化效率问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型 (DM) 已成为高质量内容生成的强大工具，但其密集的计算需求对推理提出了挑战，尤其是在资源受限的边缘设备上。云解决方案有助于计算，但通常无法解决多用户边缘 AIGC 场景中的隐私风险、个性化效率和通信成本。

Method: 提出了一种新的集群感知分层联邦聚合框架，该框架基于通过低秩适应 (LoRA) 进行的参数高效本地微调。

Result: 该框架实现了加速收敛，同时保持了在边缘约束下可扩展的多用户个性化 AIGC 服务的实际可行性。

Conclusion: 该框架实现了加速收敛，同时保持了在边缘约束下可扩展的多用户个性化 AIGC 服务的实际可行性。

Abstract: Diffusion models (DMs) have emerged as powerful tools for high-quality
content generation, yet their intensive computational requirements for
inference pose challenges for resource-constrained edge devices. Cloud-based
solutions aid in computation but often fall short in addressing privacy risks,
personalization efficiency, and communication costs in multi-user edge-AIGC
scenarios. To bridge this gap, we first analyze existing edge-AIGC applications
in personalized content synthesis, revealing their limitations in efficiency
and scalability. We then propose a novel cluster-aware hierarchical federated
aggregation framework. Based on parameter-efficient local fine-tuning via
Low-Rank Adaptation (LoRA), the framework first clusters clients based on the
similarity of their uploaded task requirements, followed by an intra-cluster
aggregation for enhanced personalization at the server-side. Subsequently, an
inter-cluster knowledge interaction paradigm is implemented to enable
hybrid-style content generation across diverse clusters.Building upon federated
learning (FL) collaboration, our framework simultaneously trains personalized
models for individual users at the devices and a shared global model enhanced
with multiple LoRA adapters on the server,enabling efficient edge inference;
meanwhile, all prompts for clustering and inference are encoded prior to
transmission, thereby further mitigating the risk of plaintext leakage. Our
evaluations demonstrate that the framework achieves accelerated convergence
while maintaining practical viability for scalable multi-user personalized AIGC
services under edge constraints.

</details>


### [84] [A Foundational Multi-Modal Model for Few-Shot Learning](https://arxiv.org/abs/2508.04746)
*Pengtao Dang,Tingbo Guo,Sha Cao,Chi Zhang*

Main category: cs.LG

TL;DR: This paper presents a new framework and dataset for few-shot learning using large multi-modal models, which improves performance in data-scarce scientific domains.


<details>
  <summary>Details</summary>
Motivation: Few-shot learning (FSL) is crucial in sciences where samples are limited and data collection is costly. The study aims to improve the generalization of FSL models using a Large Multi-Modal Model (LMMM).

Method: The authors constructed the M3FD dataset and introduced the M3F framework, fine-tuning the model on M3FD.

Result: M3F improves model performance, making LMMM feasible for real-world FSL deployment. The dataset and framework offer a unified, scalable solution.

Conclusion: The study introduces M3F, a novel Large Multi-Modal Model framework, and M3FD, a Multi-Modal Model Few-shot Dataset, to improve model performance and lower the barrier to applying LMMMs in data-scarce scientific domains.

Abstract: Few-shot learning (FSL) is a machine learning paradigm that aims to
generalize models from a small number of labeled examples, typically fewer than
10 per class. FSL is particularly crucial in biomedical, environmental,
materials, and mechanical sciences, where samples are limited and data
collection is often prohibitively costly, time-consuming, or ethically
constrained. In this study, we present an innovative approach to FSL by
demonstrating that a Large Multi-Modal Model (LMMM), trained on a set of
independent tasks spanning diverse domains, task types, and input modalities,
can substantially improve the generalization of FSL models, outperforming
models based on conventional meta-learning on tasks of the same type. To
support this, we first constructed a Multi-Modal Model Few-shot Dataset (M3FD,
over 10K+ few-shot samples), which includes 2D RGB images, 2D/3D medical scans,
tabular and time-course datasets, from which we manually curated FSL tasks such
as classification. We further introduced M3F (Multi-Modal Model for Few-shot
learning framework), a novel Large Multi-Modal Model framework tailored for
data-constrained scientific applications. M3F supports a wide range of
scientific data types through a modular pipeline. By fine-tuning the model on
M3FD, M3F improves model performance, making LMMM feasible for real-world FSL
deployment. The source code is located at https://github.com/ptdang1001/M3F. To
democratize access to complex FSL data and promote reproducibility for public
usage, M3FD is paired with a flexible and user-friendly tool that enables
efficient querying, task-specific sampling, and preprocessing. Together, our
dataset and framework offer a unified, scalable solution that significantly
lowers the barrier to applying LMMMs in data-scarce scientific domains.

</details>


### [85] [AttriLens-Mol: Attribute Guided Reinforcement Learning for Molecular Property Prediction with Large Language Models](https://arxiv.org/abs/2508.04748)
*Xuan Lin,Long Chen,Yile Wang*

Main category: cs.LG

TL;DR: AttriLens-Mol, an attribute-guided reinforcement learning framework, improves molecular property prediction with LLMs by eliciting relevant molecular attributes, leading to enhanced performance and interpretability.


<details>
  <summary>Details</summary>
Motivation: LLMs show promise in molecular property prediction but often rely on human-crafted prompts. Advanced reasoning models can be verbose and lack relevance.

Method: This paper introduces AttriLens-Mol, an attribute-guided reinforcement learning framework for molecular property prediction with LLMs. It uses a format reward, a count reward, and a rationality reward to steer the model's reasoning.

Result: Training 7B-size R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with AttriLens-Mol significantly boosts performance, achieving comparable or better results than supervised fine-tuning and advanced models.  The extracted attributes also improve the performance of decision tree models.

Conclusion: AttriLens-Mol effectively elicits more relevant and predictive molecular attributes, leading to enhanced interpretability and performance for property prediction. Further, when these extracted attributes are used as features for an interpretable decision tree model, they yield superior performance compared to attributes generated by prompting LLMs.

Abstract: Large Language Models (LLMs) have shown promise in assisting molecular
property prediction tasks but often rely on human-crafted prompts and
chain-of-thought templates. While recent advanced large reasoning models like
DeepSeek-R1 employ reinforcement learning for an extended ``thinking'' process,
their reasoning can be verbose and lack relevance. We introduce AttriLens-Mol,
an attribute-guided reinforcement learning framework for molecular property
prediction with LLMs. AttriLens-Mol steers the model's reasoning by using: (1)
a format reward encouraging attribute-based structured output, (2) a count
reward to avoid enumerating irrelevant attributes, and (3) a rationality reward
using advanced LLMs and RDKit to verify the relatedness of the generated
attributes. This approach implicitly elicits the model's inherent knowledge of
relevant molecular attributes during reasoning, enables making predictions for
the molecular property more effectively. Experiments on both in-distribution
and out-of-distribution datasets show that, training both 7B-size
R1-Distilled-Qwen2.5 and R1-Distilled-LLaMA3.1 models on 4,000 samples with our
proposed AttriLens-Mol method significantly boosts the performance, getting
comparable or better results than supervised fine-tuning models
(Mol-Instructions, ChemDFM, etc.) and advanced models (GPT-3.5, GPT-4o,
DeepSeek-V3, DeepSeek-R1, etc.). Further, our extracted attributes for the
target property, when used as features for an interpretable decision tree
model, yield superior performance compared to attributes generated by prompting
LLMs. This shows that AttriLens-Mol effectively elicits more relevant and
predictive molecular attributes, leading to enhanced interpretability and
performance for property prediction. We release the code in
https://github.com/szu-tera/AttriLens-Mol.

</details>


### [86] [PA-RNet: Perturbation-Aware Reasoning Network for Multimodal Time Series Forecasting](https://arxiv.org/abs/2508.04750)
*Chanjuan Liu,Shengzhi Wang,Enqiang Zhu*

Main category: cs.LG

TL;DR: PA-RNet通过分离文本噪声并保持语义表示来提高模型在多模态时间序列预测中的泛化能力，优于现有方法，并在噪声条件下提供稳定性保证。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态时间序列预测方法通常忽略文本数据中固有的扰动，其中不相关、嘈杂或模糊的内容会显着降低模型性能，尤其是在噪声表现出不同的强度或源于结构不一致时。

Method: PA-RNet具有扰动感知投影模块和跨模态注意力机制，以有效地将噪声与文本嵌入分离，同时保持语义上有意义的表示。

Result: 我们建立了PA-RNet关于文本输入的Lipschitz连续性，并证明了所提出的扰动模块可以减少预期的预测误差，为噪声条件下的稳定性提供了有力的保证。此外，我们还引入了一个文本扰动管道，可以无缝地集成到现有的多模态时间序列预测任务中，从而可以在存在不同级别的文本噪声的情况下对模型的鲁棒性进行系统评估。

Conclusion: PA-RNet在各种领域和时间设置中始终优于最先进的基线。

Abstract: In real-world applications, multimodal time series data often suffer from
interference, especially in the textual modality. Existing methods for
multimodal time series forecasting often neglect the inherent perturbations
within textual data, where irrelevant, noisy, or ambiguous content can
significantly degrade model performance, particularly when the noise exhibits
varying intensity or stems from structural inconsistencies. To address this
challenge, we propose PA-RNet (Perturbation-Aware Reasoning Network for
Multimodal Time Series Forecasting), a robust multimodal forecasting framework.
PA-RNet features a perturbation-aware projection module and a cross-modal
attention mechanism to effectively separate noise from the textual embeddings
while maintaining semantically meaningful representations, thereby enhancing
the model's generalization ability. Theoretically, we establish the Lipschitz
continuity of PA-RNet with respect to textual inputs and prove that the
proposed perturbation module can reduce expected prediction error, offering
strong guarantees of stability under noisy conditions. Furthermore, we
introduce a textual perturbation pipeline that can be seamlessly incorporated
into existing multimodal time series forecasting tasks, allowing for systematic
evaluation of the model's robustness in the presence of varying levels of
textual noise. Extensive experiments across diverse domains and temporal
settings demonstrate that PA-RNet consistently outperforms state-of-the-art
baselines.

</details>


### [87] [InfoQ: Mixed-Precision Quantization via Global Information Flow](https://arxiv.org/abs/2508.04753)
*Mehmet Emre Akbulut,Hazem Hesham Yousef Shalby,Fabrizio Pittorino,Manuel Roveri*

Main category: cs.LG

TL;DR: InfoQ是一种用于混合精度量化的新框架，它通过测量量化对网络信息流的影响来评估层敏感度，从而实现更好的精度和压缩率。


<details>
  <summary>Details</summary>
Motivation: 当前的方法依赖于计算成本高的搜索算法或局部敏感性启发式代理，无法捕捉量化误差的级联全局效应。

Method: InfoQ通过量化每一层并测量后续层互信息的变化来评估层敏感度，然后使用整数线性规划来分配位宽。

Result: InfoQ在位宽搜索阶段是免训练的，与最先进的方法相比，使用了更少的数据，并实现了更好的搜索时间/精度权衡。

Conclusion: InfoQ在ImageNet上对MobileNetV2和ResNet18实现了高达1%的精度提升，同时实现了更高的压缩率。

Abstract: Mixed-precision quantization (MPQ) is crucial for deploying deep neural
networks on resource-constrained devices, but finding the optimal bit-width for
each layer represents a complex combinatorial optimization problem. Current
state-of-the-art methods rely on computationally expensive search algorithms or
local sensitivity heuristic proxies like the Hessian, which fail to capture the
cascading global effects of quantization error. In this work, we argue that the
quantization sensitivity of a layer should not be measured by its local
properties, but by its impact on the information flow throughout the entire
network. We introduce InfoQ, a novel framework for MPQ that is training-free in
the bit-width search phase. InfoQ assesses layer sensitivity by quantizing each
layer at different bit-widths and measuring, through a single forward pass, the
resulting change in mutual information in the subsequent layers. This
quantifies how much each layer quantization impacts the network information
flow. The resulting scores are used to formulate bit-width allocation as an
integer linear programming problem, which is solved efficiently to minimize
total sensitivity under a given budget (e.g., model size or BitOps). Our
retraining-free search phase provides a superior search-time/accuracy trade-off
(using two orders of magnitude less data compared to state-of-the-art methods
such as LIMPQ), while yielding up to a 1% accuracy improvement for MobileNetV2
and ResNet18 on ImageNet at high compression rates (14X and 10.66X).

</details>


### [88] [Are Large Language Models Dynamic Treatment Planners? An In Silico Study from a Prior Knowledge Injection Angle](https://arxiv.org/abs/2508.04755)
*Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: LLM在动态胰岛素剂量调整方面有潜力，但在临床应用中需要谨慎，并需要进一步的改进和验证。


<details>
  <summary>Details</summary>
Motivation: 基于强化学习(RL)的动态治疗方案(DTR)在自动化复杂临床决策方面具有前景，但其部署仍然受到需要大量工程来注入临床知识和确保患者安全的限制。大型语言模型(LLM)的最新进展表明了一种互补的方法，其中隐含的先验知识和临床启发式方法通过语言提示自然嵌入，而不需要特定于环境的训练。

Method: 使用in silico 1型糖尿病模拟器评估开源LLM作为动态胰岛素剂量调整agent，并将其zero-shot推理性能与经过专门训练的小型神经网络RL agent进行比较。

Result: 精心设计的zero-shot提示使较小的LLM(例如，Qwen2.5-7B)能够实现与经过广泛训练的SRA相当或优越的临床性能，尤其是在稳定的患者队列中。然而，LLM表现出明显的局限性，例如在使用思维链(CoT)推理时，胰岛素剂量过于激进，突出了包括算术幻觉、时间误解和不一致的临床逻辑等关键失败模式。结合对潜在临床状态(如膳食)的显式推理产生的性能提升最小，这突显了当前模型仅通过文本推理捕获复杂、隐藏的生理动态的局限性。

Conclusion: 谨慎乐观地将LLM整合到临床工作流程中，强调有针对性的prompt工程、仔细的验证以及可能将语言推理与结构化生理建模相结合的混合方法对于实现安全、稳健和临床有效的决策支持系统是必要的。

Abstract: Reinforcement learning (RL)-based dynamic treatment regimes (DTRs) hold
promise for automating complex clinical decision-making, yet their practical
deployment remains hindered by the intensive engineering required to inject
clinical knowledge and ensure patient safety. Recent advancements in large
language models (LLMs) suggest a complementary approach, where implicit prior
knowledge and clinical heuristics are naturally embedded through linguistic
prompts without requiring environment-specific training. In this study, we
rigorously evaluate open-source LLMs as dynamic insulin dosing agents in an in
silico Type 1 diabetes simulator, comparing their zero-shot inference
performance against small neural network-based RL agents (SRAs) explicitly
trained for the task. Our results indicate that carefully designed zero-shot
prompts enable smaller LLMs (e.g., Qwen2.5-7B) to achieve comparable or
superior clinical performance relative to extensively trained SRAs,
particularly in stable patient cohorts. However, LLMs exhibit notable
limitations, such as overly aggressive insulin dosing when prompted with
chain-of-thought (CoT) reasoning, highlighting critical failure modes including
arithmetic hallucination, temporal misinterpretation, and inconsistent clinical
logic. Incorporating explicit reasoning about latent clinical states (e.g.,
meals) yielded minimal performance gains, underscoring the current model's
limitations in capturing complex, hidden physiological dynamics solely through
textual inference. Our findings advocate for cautious yet optimistic
integration of LLMs into clinical workflows, emphasising the necessity of
targeted prompt engineering, careful validation, and potentially hybrid
approaches that combine linguistic reasoning with structured physiological
modelling to achieve safe, robust, and clinically effective decision-support
systems.

</details>


### [89] [Uncertainty-aware Predict-Then-Optimize Framework for Equitable Post-Disaster Power Restoration](https://arxiv.org/abs/2508.04780)
*Lin Jiang,Dahai Yu,Rongchao Xu,Tian Tang,Guang Wang*

Main category: cs.LG

TL;DR: 电力恢复决策通常基于各地区的电力恢复请求量，但弱势群体提交的请求较少，导致恢复方案不公平。提出了一个名为EPOPR的框架，该框架使用不确定性感知修复持续时间预测和时空注意力强化学习，以减少平均停电持续时间并减少社区之间的不平等。


<details>
  <summary>Details</summary>
Motivation: the current restoration solution inequitable, leaving these communities vulnerable to extended power outages. To address this, we aim to propose an equity-aware power restoration strategy that balances both restoration efficiency and equity across communities. However, achieving this goal is challenging for two reasons: the difficulty of predicting repair durations under dataset heteroscedasticity, and the tendency of reinforcement learning agents to favor low-uncertainty actions, which potentially undermine equity.

Method: design a predict-then-optimize framework called EPOPR with two key components: (1) Equity-Conformalized Quantile Regression for uncertainty-aware repair duration prediction, and (2) Spatial-Temporal Attentional RL that adapts to varying uncertainty levels across regions for equitable decision-making.

Result: EPOPR effectively reduces the average power outage duration by 3.60% and decreases inequity between different communities by 14.19% compared to state-of-the-art baselines.

Conclusion: EPOPR effectively reduces the average power outage duration by 3.60% and decreases inequity between different communities by 14.19% compared to state-of-the-art baselines.

Abstract: The increasing frequency of extreme weather events, such as hurricanes,
highlights the urgent need for efficient and equitable power system
restoration. Many electricity providers make restoration decisions primarily
based on the volume of power restoration requests from each region. However,
our data-driven analysis reveals significant disparities in request submission
volume, as disadvantaged communities tend to submit fewer restoration requests.
This disparity makes the current restoration solution inequitable, leaving
these communities vulnerable to extended power outages. To address this, we aim
to propose an equity-aware power restoration strategy that balances both
restoration efficiency and equity across communities. However, achieving this
goal is challenging for two reasons: the difficulty of predicting repair
durations under dataset heteroscedasticity, and the tendency of reinforcement
learning agents to favor low-uncertainty actions, which potentially undermine
equity. To overcome these challenges, we design a predict-then-optimize
framework called EPOPR with two key components: (1) Equity-Conformalized
Quantile Regression for uncertainty-aware repair duration prediction, and (2)
Spatial-Temporal Attentional RL that adapts to varying uncertainty levels
across regions for equitable decision-making. Experimental results show that
our EPOPR effectively reduces the average power outage duration by 3.60% and
decreases inequity between different communities by 14.19% compared to
state-of-the-art baselines.

</details>


### [90] [Federated Continual Recommendation](https://arxiv.org/abs/2508.04792)
*Jaehyung Lim,Wonbin Kweon,Woojoo Kim,Junyoung Kim,Seongjin Choi,Dongha Kim,Hwanjo Yu*

Main category: cs.LG

TL;DR: 提出了联邦持续推荐 (FCRec) 任务和 F3CRec 框架，以解决联邦学习推荐中数据非静态和隐私保护的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦推荐方法难以处理非静态数据流，无法保持推荐质量。持续学习推荐方法通常假设中心化数据访问，与联邦学习约束不兼容。

Method: Adaptive Replay Memory (客户端) 和 Item-wise Temporal Mean (服务端)

Result: F3CRec在联邦环境中，在保持推荐质量方面优于现有方法。

Conclusion: F3CRec在联邦环境中，在保持推荐质量方面优于现有方法。

Abstract: The increasing emphasis on privacy in recommendation systems has led to the
adoption of Federated Learning (FL) as a privacy-preserving solution, enabling
collaborative training without sharing user data. While Federated
Recommendation (FedRec) effectively protects privacy, existing methods struggle
with non-stationary data streams, failing to maintain consistent recommendation
quality over time. On the other hand, Continual Learning Recommendation (CLRec)
methods address evolving user preferences but typically assume centralized data
access, making them incompatible with FL constraints. To bridge this gap, we
introduce Federated Continual Recommendation (FCRec), a novel task that
integrates FedRec and CLRec, requiring models to learn from streaming data
while preserving privacy. As a solution, we propose F3CRec, a framework
designed to balance knowledge retention and adaptation under the strict
constraints of FCRec. F3CRec introduces two key components: Adaptive Replay
Memory on the client side, which selectively retains past preferences based on
user-specific shifts, and Item-wise Temporal Mean on the server side, which
integrates new knowledge while preserving prior information. Extensive
experiments demonstrate that F3CRec outperforms existing approaches in
maintaining recommendation quality over time in a federated environment.

</details>


### [91] [HCRide: Harmonizing Passenger Fairness and Driver Preference for Human-Centered Ride-Hailing](https://arxiv.org/abs/2508.04811)
*Lin Jiang,Yu Yang,Guang Wang*

Main category: cs.LG

TL;DR: 设计了一个名为 HCRide 的以人为中心的 ride-hailing 系统，该系统在提高系统效率的同时，还考虑了乘客的公平性和驾驶员的偏好。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数工作侧重于提高运营商收入方面的系统效率，这可能会导致乘客和驾驶员的糟糕体验。因此，在这项工作中，我们的目标是通过考虑乘客公平性和驾驶员偏好来设计一个以人为中心的ride-hailing系统，同时不影响整体系统效率。

Method: 基于一种名为面向和谐的 Actor-Bi-Critic (Habic) 的新型多智能体强化学习算法设计了一个以人为中心的 Ride-hailing 系统 HCRide

Result: HCRide 有效地将系统效率提高了 2.02%，公平性提高了 5.39%，驾驶员偏好提高了 10.21%。

Conclusion: HCRide 有效地提高了系统效率、公平性和驾驶员偏好。

Abstract: Order dispatch systems play a vital role in ride-hailing services, which
directly influence operator revenue, driver profit, and passenger experience.
Most existing work focuses on improving system efficiency in terms of operator
revenue, which may cause a bad experience for both passengers and drivers.
Hence, in this work, we aim to design a human-centered ride-hailing system by
considering both passenger fairness and driver preference without compromising
the overall system efficiency. However, it is nontrivial to achieve this target
due to the potential conflicts between passenger fairness and driver preference
since optimizing one may sacrifice the other. To address this challenge, we
design HCRide, a Human-Centered Ride-hailing system based on a novel
multi-agent reinforcement learning algorithm called Harmonization-oriented
Actor-Bi-Critic (Habic), which includes three major components (i.e., a
multi-agent competition mechanism, a dynamic Actor network, and a Bi-Critic
network) to optimize system efficiency and passenger fairness with driver
preference consideration. We extensively evaluate our HCRide using two
real-world ride-hailing datasets from Shenzhen and New York City. Experimental
results show our HCRide effectively improves system efficiency by 2.02%,
fairness by 5.39%, and driver preference by 10.21% compared to state-of-the-art
baselines.

</details>


### [92] [Unified Flow Matching for Long Horizon Event Forecasting](https://arxiv.org/abs/2508.04843)
*Xiao Shou*

Main category: cs.LG

TL;DR: This paper presents a non-autoregressive flow matching framework for modeling long horizon marked event sequences, improving accuracy and efficiency compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Modeling long horizon marked event sequences is a fundamental challenge in many real-world applications, but existing autoregressive models suffer from efficiency limitations and error accumulation in long-range forecasting.

Method: The paper proposes a continuous and discrete flow matching approach to learn continuous-time flows for both inter-event times and event types, enabling non-autoregressive generation of coherent long horizon event trajectories.

Result: The proposed model achieves significant improvements over autoregressive and diffusion-based baselines in both accuracy and generation efficiency on six real-world benchmarks.

Conclusion: The paper introduces a unified flow matching framework for marked temporal point processes, enabling non-autoregressive, joint modeling of inter-event times and event types. The model demonstrates significant improvements over autoregressive and diffusion-based baselines in both accuracy and generation efficiency on six real-world benchmarks.

Abstract: Modeling long horizon marked event sequences is a fundamental challenge in
many real-world applications, including healthcare, finance, and user behavior
modeling. Existing neural temporal point process models are typically
autoregressive, predicting the next event one step at a time, which limits
their efficiency and leads to error accumulation in long-range forecasting. In
this work, we propose a unified flow matching framework for marked temporal
point processes that enables non-autoregressive, joint modeling of inter-event
times and event types, via continuous and discrete flow matching. By learning
continuous-time flows for both components, our method generates coherent long
horizon event trajectories without sequential decoding. We evaluate our model
on six real-world benchmarks and demonstrate significant improvements over
autoregressive and diffusion-based baselines in both accuracy and generation
efficiency.

</details>


### [93] [Multi-Stage Knowledge-Distilled VGAE and GAT for Robust Controller-Area-Network Intrusion Detection](https://arxiv.org/abs/2508.04845)
*Robert Frenken,Sidra Ghayour Bhatti,Hanqin Zhang,Qadeer Ahmed*

Main category: cs.LG

TL;DR: Presents a multi-stage intrusion detection framework using Variational Graph Autoencoder (VGAE) and Knowledge-Distilled Graph Attention Network (KD-GAT) for automotive CAN traffic, achieving competitive accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: The Controller Area Network (CAN) protocol is a standard for in-vehicle communication but remains susceptible to cyber-attacks due to its lack of built-in security.

Method: a multi-stage intrusion detection framework leveraging unsupervised anomaly detection and supervised graph learning tailored for automotive CAN traffic. Our architecture combines a Variational Graph Autoencoder (VGAE) for structural anomaly detection with a Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack classification.

Result: The compact student GAT achieves 96% parameter reduction compared to the teacher model while maintaining strong predictive performance. , with average improvements of 16.2% in F1-score over existing methods, particularly excelling on highly imbalanced datasets with up to 55% F1-score improvements.

Conclusion: Experiments on six public CAN intrusion datasets demonstrate competitive accuracy and efficiency, with average improvements of 16.2% in F1-score over existing methods.

Abstract: The Controller Area Network (CAN) protocol is a standard for in-vehicle
communication but remains susceptible to cyber-attacks due to its lack of
built-in security. This paper presents a multi-stage intrusion detection
framework leveraging unsupervised anomaly detection and supervised graph
learning tailored for automotive CAN traffic. Our architecture combines a
Variational Graph Autoencoder (VGAE) for structural anomaly detection with a
Knowledge-Distilled Graph Attention Network (KD-GAT) for robust attack
classification. CAN bus activity is encoded as graph sequences to model
temporal and relational dependencies. The pipeline applies VGAE-based selective
undersampling to address class imbalance, followed by GAT classification with
optional score-level fusion. The compact student GAT achieves 96% parameter
reduction compared to the teacher model while maintaining strong predictive
performance. Experiments on six public CAN intrusion datasets--Car-Hacking,
Car-Survival, and can-train-and-test--demonstrate competitive accuracy and
efficiency, with average improvements of 16.2% in F1-score over existing
methods, particularly excelling on highly imbalanced datasets with up to 55%
F1-score improvements.

</details>


### [94] [Provable Post-Training Quantization: Theoretical Analysis of OPTQ and Qronos](https://arxiv.org/abs/2508.04853)
*Haoyu Zhang,Shihao Zhang,Ian Colbert,Rayan Saab*

Main category: cs.LG

TL;DR: 本文为OPTQ算法提供了首个定量误差界限，并分析了其设计选择的理论依据。


<details>
  <summary>Details</summary>
Motivation: OPTQ框架由于其计算效率和强大的经验性能，已成为一种领先的方法。然而，OPTQ缺乏严格的定量理论保证。

Method: 我们分析了OPTQ的迭代过程如何导致量化误差，并推导出非渐近2-范数误差界限，该误差界限明确取决于校准数据和OPTQ使用的正则化参数。

Result: 对于随机变体，我们建立了更强的无穷范数误差界限，这使得能够控制所需的量化字母表，并且对于下游层和非线性特别有用。最后，我们将分析扩展到Qronos，为其确定性和随机变体提供了新的理论界限，这有助于解释其经验优势。

Conclusion: 本文为OPTQ的确定性和随机变体以及Qronos提出了第一个定量误差界限，并为实际设计选择提供了理论依据，包括通过减少范数对特征进行排序的常用启发式方法，以及选择正则化参数的指导。

Abstract: Post-training quantization (PTQ) has become a crucial tool for reducing the
memory and compute costs of modern deep neural networks, including large
language models (LLMs). Among PTQ algorithms, the OPTQ framework-also known as
GPTQ-has emerged as a leading method due to its computational efficiency and
strong empirical performance. Despite its widespread adoption, however, OPTQ
lacks rigorous quantitative theoretical guarantees. This paper presents the
first quantitative error bounds for both deterministic and stochastic variants
of OPTQ, as well as for Qronos, a recent related state-of-the-art PTQ
algorithm. We analyze how OPTQ's iterative procedure induces quantization error
and derive non-asymptotic 2-norm error bounds that depend explicitly on the
calibration data and a regularization parameter that OPTQ uses. Our analysis
provides theoretical justification for several practical design choices,
including the widely used heuristic of ordering features by decreasing norm, as
well as guidance for selecting the regularization parameter. For the stochastic
variant, we establish stronger infinity-norm error bounds, which enable control
over the required quantization alphabet and are particularly useful for
downstream layers and nonlinearities. Finally, we extend our analysis to
Qronos, providing new theoretical bounds, for both its deterministic and
stochastic variants, that help explain its empirical advantages.

</details>


### [95] [Agnostics: Learning to Code in Any Programming Language via Reinforcement with a Universal Learning Environment](https://arxiv.org/abs/2508.04865)
*Aleksander Boruch-Gruszecki,Yangtian Zi,Zixuan Wu,Tejas Oberoi,Carolyn Jane Anderson,Joydeep Biswas,Arjun Guha*

Main category: cs.LG

TL;DR: Agnostics is a language-agnostic post-training pipeline that improves code generation in low-resource languages by using verifiable rewards and a single verifier for all languages.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with code generation in low-resource languages due to data scarcity and the need for language-specific post-training infrastructure.

Method: A language-agnostic post-training pipeline that judges code by its externally observable behavior, using an LLM to rewrite unit-test datasets into an I/O format and reinforcement learning with verifiable rewards (RLVR).

Result: Agnostics improves Qwen-3 4B to performance rivaling 16B-70B models, scales to larger models, and sets new state-of-the-art pass@1 results on MultiPL-E and LiveCodeBench for smaller models.

Conclusion: Agnostics improves code generation performance in low-resource languages, achieving state-of-the-art results on MultiPL-E and LiveCodeBench.

Abstract: Large language models (LLMs) already excel at writing code in high-resource
languages such as Python and JavaScript, yet stumble on low-resource languages
that remain essential to science and engineering. Besides the obvious shortage
of pre-training data, post-training itself is a bottleneck: every new language
seems to require new datasets, test harnesses, and reinforcement-learning (RL)
infrastructure.
  We introduce Agnostics, a language-agnostic post-training pipeline that
eliminates this per-language engineering. The key idea is to judge code solely
by its externally observable behavior, so a single verifier can test solutions
written in any language. Concretely, we (i) use an LLM to rewrite existing
unit-test datasets into an I/O format, (ii) supply a short configuration that
tells the verifier how to compile and run a target language, and (iii) apply
reinforcement learning with verifiable rewards (RLVR) in a robust code
execution environment.
  Applied to five low-resource languages--Lua, Julia, R, OCaml, and
Fortran--Agnostics (1) improves Qwen-3 4B to performance that rivals other
16B-70B open-weight models; (2) scales cleanly to larger and diverse model
families (Qwen-3 8B, DeepSeek Coder 6.7B Instruct, Phi 4 Mini); and (3) for
${\le} 16$B parameter models, sets new state-of-the-art pass@1 results on
MultiPL-E and a new multi-language version LiveCodeBench that we introduce.
  We will release the language-agnostic training datasets (Ag-MBPP-X,
Ag-Codeforces-X, Ag-LiveCodeBench-X), training code, and ready-to-use
configurations, making RL post-training in any programming language as simple
as editing a short YAML file.

</details>


### [96] [Hilbert Neural Operator: Operator Learning in the Analytic Signal Domain](https://arxiv.org/abs/2508.04882)
*Saman Pordanesh,Pejman Shahsavari,Hossein Ghadjari*

Main category: cs.LG

TL;DR: Introduces Hilbert Neural Operator (HNO) to improve upon Fourier Neural Operator (FNO) by using Hilbert transform to explicitly represent amplitude and phase information, which may be more effective for causal, phase-sensitive, and non-stationary systems.


<details>
  <summary>Details</summary>
Motivation: Neural operators have emerged as a powerful, data-driven paradigm for learning solution operators of partial differential equations (PDEs). State-of-the-art architectures, such as the Fourier Neural Operator (FNO), have achieved remarkable success by performing convolutions in the frequency domain, making them highly effective for a wide range of problems. However, this method has some limitations, including the periodicity assumption of the Fourier transform. In addition, there are other methods of analysing a signal, beyond phase and amplitude perspective, and provide us with other useful information to learn an effective network.

Method: HNO operates by first mapping the input signal to its analytic representation via the Hilbert transform, thereby making instantaneous amplitude and phase information explicit features for the learning process. The core learnable operation -- a spectral convolution -- is then applied to this Hilbert-transformed representation.

Result: We hypothesize that this architecture enables HNO to model operators more effectively for causal, phase-sensitive, and non-stationary systems.

Conclusion: We introduce the Hilbert Neural Operator (HNO), a new neural operator architecture to address some advantages by incorporating a strong inductive bias from signal processing. We formalize the HNO architecture and provide the theoretical motivation for its design, rooted in analytic signal theory.

Abstract: Neural operators have emerged as a powerful, data-driven paradigm for
learning solution operators of partial differential equations (PDEs).
State-of-the-art architectures, such as the Fourier Neural Operator (FNO), have
achieved remarkable success by performing convolutions in the frequency domain,
making them highly effective for a wide range of problems. However, this method
has some limitations, including the periodicity assumption of the Fourier
transform. In addition, there are other methods of analysing a signal, beyond
phase and amplitude perspective, and provide us with other useful information
to learn an effective network. We introduce the \textbf{Hilbert Neural Operator
(HNO)}, a new neural operator architecture to address some advantages by
incorporating a strong inductive bias from signal processing. HNO operates by
first mapping the input signal to its analytic representation via the Hilbert
transform, thereby making instantaneous amplitude and phase information
explicit features for the learning process. The core learnable operation -- a
spectral convolution -- is then applied to this Hilbert-transformed
representation. We hypothesize that this architecture enables HNO to model
operators more effectively for causal, phase-sensitive, and non-stationary
systems. We formalize the HNO architecture and provide the theoretical
motivation for its design, rooted in analytic signal theory.

</details>


### [97] [Gaussian mixture layers for neural networks](https://arxiv.org/abs/2508.04883)
*Sinho Chewi,Philippe Rigollet,Yuling Yan*

Main category: cs.LG

TL;DR: This paper introduces a new type of layer, the Gaussian Mixture (GM) layer, and derives training dynamics for probability measures. GM layers achieve comparable performance to fully connected networks but exhibit different behavior.


<details>
  <summary>Details</summary>
Motivation: The mean-field theory for two-layer neural networks considers infinitely wide networks that are linearly parameterized by a probability measure over the parameter space. This nonparametric perspective has significantly advanced both the theoretical and conceptual understanding of neural networks, with substantial efforts made to validate its applicability to networks of moderate width. In this work, we explore the opposite direction, investigating whether dynamics can be directly implemented over probability measures.

Method: employ Gaussian mixture models as a flexible and expressive parametric family of distributions together with the theory of Wasserstein gradient flows to derive training dynamics for such measures. Our approach introduces a new type of layer -- the Gaussian mixture (GM) layer -- that can be integrated into neural network architectures.

Result: GM layers achieve test performance comparable to that of a two-layer fully connected network. GM layers exhibit markedly different behavior compared to classical fully connected layers, even when the latter are large enough to be considered in the mean-field regime.

Conclusion: A Gaussian mixture (GM) layer achieves test performance comparable to that of a two-layer fully connected network on simple classification tasks and exhibit markedly different behavior compared to classical fully connected layers, even when the latter are large enough to be considered in the mean-field regime.

Abstract: The mean-field theory for two-layer neural networks considers infinitely wide
networks that are linearly parameterized by a probability measure over the
parameter space. This nonparametric perspective has significantly advanced both
the theoretical and conceptual understanding of neural networks, with
substantial efforts made to validate its applicability to networks of moderate
width. In this work, we explore the opposite direction, investigating whether
dynamics can be directly implemented over probability measures. Specifically,
we employ Gaussian mixture models as a flexible and expressive parametric
family of distributions together with the theory of Wasserstein gradient flows
to derive training dynamics for such measures. Our approach introduces a new
type of layer -- the Gaussian mixture (GM) layer -- that can be integrated into
neural network architectures. As a proof of concept, we validate our proposal
through experiments on simple classification tasks, where a GM layer achieves
test performance comparable to that of a two-layer fully connected network.
Furthermore, we examine the behavior of these dynamics and demonstrate
numerically that GM layers exhibit markedly different behavior compared to
classical fully connected layers, even when the latter are large enough to be
considered in the mean-field regime.

</details>


### [98] [Bidding-Aware Retrieval for Multi-Stage Consistency in Online Advertising](https://arxiv.org/abs/2508.05206)
*Bin Liu,Yunfei Liu,Ziru Xu,Zhaoyu Zhou,Zhi Kou,Yeqiu Yang,Han Zhu,Jian Xu,Bo Zheng*

Main category: cs.LG

TL;DR: 提出了一种名为Bidding-Aware Retrieval (BAR)的框架，通过将广告出价纳入检索评分函数来解决多阶段不一致性问题，经验证该框架有效，能够增加平台收入。


<details>
  <summary>Details</summary>
Motivation: 随着自动出价策略的日益普及，计算敏感的检索阶段和排序阶段之间的不一致性变得更加明显，因为前者无法访问大量广告语料库的精确的实时出价。这种差异导致平台收入和广告商结果欠佳。

Method: Bidding-Aware Retrieval (BAR)，一个基于模型的检索框架，通过将广告出价纳入检索评分函数来解决多阶段不一致性问题。核心创新是Bidding-Aware Modeling，通过单调约束学习和多任务蒸馏结合出价信号，以确保经济上连贯的表征，而异步近线推理则支持对嵌入进行实时更新，以实现市场响应。此外，任务关注细化模块选择性地增强特征交互，以解开用户兴趣和商业价值信号。

Result: 平台收入增加了4.32%，正面运营广告的展示次数增加了22.2%。

Conclusion: BAR在阿里巴巴的展示广告平台上进行了广泛的离线实验和全面部署，验证了其有效性：平台收入增加了4.32%，正面运营广告的展示次数增加了22.2%。

Abstract: Online advertising systems typically use a cascaded architecture to manage
massive requests and candidate volumes, where the ranking stages allocate
traffic based on eCPM (predicted CTR $\times$ Bid). With the increasing
popularity of auto-bidding strategies, the inconsistency between the
computationally sensitive retrieval stage and the ranking stages becomes more
pronounced, as the former cannot access precise, real-time bids for the vast ad
corpus. This discrepancy leads to sub-optimal platform revenue and advertiser
outcomes. To tackle this problem, we propose Bidding-Aware Retrieval (BAR), a
model-based retrieval framework that addresses multi-stage inconsistency by
incorporating ad bid value into the retrieval scoring function. The core
innovation is Bidding-Aware Modeling, incorporating bid signals through
monotonicity-constrained learning and multi-task distillation to ensure
economically coherent representations, while Asynchronous Near-Line Inference
enables real-time updates to the embedding for market responsiveness.
Furthermore, the Task-Attentive Refinement module selectively enhances feature
interactions to disentangle user interest and commercial value signals.
Extensive offline experiments and full-scale deployment across Alibaba's
display advertising platform validated BAR's efficacy: 4.32% platform revenue
increase with 22.2% impression lift for positively-operated advertisements.

</details>


### [99] [Uncertainty Quantification for Surface Ozone Emulators using Deep Learning](https://arxiv.org/abs/2508.04885)
*Kelsey Doerksen,Yuliya Marchetti,Steven Lu,Kevin Bowman,James Montgomery,Kazuyuki Miyazaki,Yarin Gal,Freddie Kalaitzis*

Main category: cs.LG

TL;DR: This paper uses an uncertainty-aware U-Net to predict surface ozone bias, showing promising results for regional estimation and uncertainty quantification.


<details>
  <summary>Details</summary>
Motivation: Air pollution is a global hazard, Surface Ozone (O3) is an important pollutant, and the drivers of its trends are difficult to model. Traditional physics-based models fall short, and Deep Learning-based emulators lack interpretability.

Method: The study implements an uncertainty-aware U-Net architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian and quantile regression methods.

Result: The study shows results regarding regional estimation of bias, uncertainty quantification scores, optimal ground station candidates, and the impact of land-use information in surface ozone residual modeling.

Conclusion: The study demonstrates the capability of uncertainty-aware U-Net architecture in regional estimation of bias in North America and Europe for June 2019, highlights the uncertainty quantification (UQ) scores between two UQ methodologies, discerns optimal and sub-optimal ground stations for bias correction, and evaluates the impact of land-use information in surface ozone residual modeling.

Abstract: Air pollution is a global hazard, and as of 2023, 94\% of the world's
population is exposed to unsafe pollution levels. Surface Ozone (O3), an
important pollutant, and the drivers of its trends are difficult to model, and
traditional physics-based models fall short in their practical use for scales
relevant to human-health impacts. Deep Learning-based emulators have shown
promise in capturing complex climate patterns, but overall lack the
interpretability necessary to support critical decision making for policy
changes and public health measures. We implement an uncertainty-aware U-Net
architecture to predict the Multi-mOdel Multi-cOnstituent Chemical data
assimilation (MOMO-Chem) model's surface ozone residuals (bias) using Bayesian
and quantile regression methods. We demonstrate the capability of our
techniques in regional estimation of bias in North America and Europe for June
2019. We highlight the uncertainty quantification (UQ) scores between our two
UQ methodologies and discern which ground stations are optimal and sub-optimal
candidates for MOMO-Chem bias correction, and evaluate the impact of land-use
information in surface ozone residual modeling.

</details>
