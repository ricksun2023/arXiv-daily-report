<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 45]
- [cs.CV](#cs.CV) [Total: 39]
- [cs.AI](#cs.AI) [Total: 40]
- [cs.DB](#cs.DB) [Total: 11]
- [cs.IR](#cs.IR) [Total: 19]
- [cs.LG](#cs.LG) [Total: 42]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

TL;DR: 本文提出了一种半自动的事实核查（SAFC）系统，用于葡萄牙语，通过整合外部证据来丰富现有的新闻语料库，以应对虚假信息传播过快的问题。


<details>
  <summary>Details</summary>
Motivation: 当前，虚假信息的加速传播往往超过了人工事实核查的能力，因此迫切需要半自动事实核查（SAFC）系统。在葡萄牙语环境中，整合外部证据的公开数据集非常稀缺，而外部证据是开发强大的AFC系统的关键组成部分，因为许多现有资源仅侧重于基于内在文本特征的分类。

Method: 该方法利用大型语言模型（LLM，特别是 Gemini 1.5 Flash）从文本中提取主要声明，并使用搜索引擎API（Google Search API，Google FactCheck Claims Search API）来检索相关的外部文档（证据）。此外，还引入了一个数据验证和预处理框架，包括近重复检测，以提高基础语料库的质量。

Result: 论文开发了一种方法来丰富葡萄牙语新闻语料库（Fake.Br、COVID19.BR、MuMiN-PT）与外部证据。

Conclusion: 这篇论文通过开发、应用和分析一种方法来丰富葡萄牙语新闻语料库，从而弥补了葡萄牙语环境中缺乏整合外部证据的公开数据集的差距。该方法模拟了用户的验证过程，利用大型语言模型（LLM）从文本中提取主要声明，并使用搜索引擎API检索相关的外部文档（证据）。

Abstract: The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [2] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

TL;DR: RAG improves LLM performance in few-shot biomedical NER.


<details>
  <summary>Details</summary>
Motivation: Performance challenges of LLMs for few-shot biomedical NER.

Method: Dynamic prompting strategy involving retrieval-augmented generation (RAG).

Result: Static prompting with structured components increased average F1-scores. Dynamic prompting further improved performance, with TF-IDF and SBERT retrieval methods yielding the best results.

Conclusion: Contextually adaptive prompts via RAG improve performance for biomedical NER.

Abstract: Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [3] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

TL;DR: 本文提出了一个分析框架，将神经缩放定律扩展到 LLM 训练中，以包含运营和隐含碳。


<details>
  <summary>Details</summary>
Motivation: 神经网络缩放定律通过将精度提高与参数数量、数据集大小和计算的增长联系起来，推动了越来越大的语言模型 (LLM) 的发展。然而，这些定律忽略了随着 LLM 大小呈指数增长的碳排放。

Method: 通过集成神经缩放、GPU 硬件演进、并行优化和碳估算模型，定量地将模型精度与碳足迹联系起来。

Result: 精度和碳排放之间存在幂律关系，但实际低效率显着增加了缩放因子。硬件技术扩展减少了中小型模型的碳排放，但由于通信开销和未充分利用的 GPU，对于极大型 LLM，其回报会减少。训练优化（尤其是积极的关键批量大小缩放）有助于缓解这种低效率。

Conclusion: 虽然精度和碳排放之间存在幂律关系，但实际低效率显着增加了缩放因子。硬件技术扩展减少了中小型模型的碳排放，但由于通信开销和未充分利用的 GPU，对于极大型 LLM，其回报会减少。训练优化（尤其是积极的关键批量大小缩放）有助于缓解这种低效率。


Abstract: Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [4] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: This paper presents a systematic study that links vocabulary size, pre-tokenization rules, and training-corpus composition to both token-to-word efficiency and model quality, and proposes a novel algorithm for data composition that balances multilingual data for tokenizer training. The tokenizer achieves more than 40% improvement on average token-to-word ratio against stateof-the-art multilingual Indic models.


<details>
  <summary>Details</summary>
Motivation: Existing tokenizers often exhibit high token-to-word ratios, inefficient use of context length, and slower inference, particularly in multilingual contexts

Method: a novel algorithm for data composition that balances multilingual data for tokenizer training and observations on pretokenization strategies

Result: data composition algorithm reduces the average token-to-word ratio by approximately 6% with respect to the conventional data randomization approach, tokenizer achieves more than 40% improvement on average token-to-word ratio against stateof-the-art multilingual Indic models, gains in both model performance and inference speed

Conclusion: tokenization alongside architecture and training objectives as a critical lever for building efficient, scalable multilingual LLMs

Abstract: While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [5] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

TL;DR: AEALT: a supervised, factor-augmented framework that incorporates dimension reduction directly into pre-trained LLM workflows


<details>
  <summary>Details</summary>
Motivation: The high dimensionality of these embeddings often impedes efficiency and drives up computational cost in downstream tasks.

Method: a supervised, factor-augmented framework that incorporates dimension reduction directly into pre-trained LLM workflows. First, extract embeddings from text documents; next, pass them through a supervised augmented autoencoder to learn low-dimensional, task-relevant latent factors.

Result: AEALT outperforms conventional deep-learning approaches that rely on raw embeddings. We validate its broad applicability with extensive experiments on classification, anomaly detection, and prediction tasks using multiple real-world public datasets.

Conclusion: AEALT yields substantial gains over both vanilla embeddings and several standard dimension reduction methods.

Abstract: Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [6] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

TL;DR: 本研究着眼于大型语言模型在教学指导方面的能力，构建了一个新的基准GuideEval，并提出了一种行为引导的微调策略，以提高模型的指导性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的会话能力为实现可扩展和交互式辅导带来了巨大的希望。先前的研究主要考察了它们进行苏格拉底式提问的能力，但往往忽略了一个关键维度：基于学习者的认知状态自适应地指导学习者。

Method: GuideEval，一个基于真实教育对话的基准，通过三阶段行为框架评估教学指导：(1)感知，推断学习者状态；(2)编排，调整教学策略；(3)启发，激发适当的思考。

Result: 现有的LLM在学习者感到困惑或需要重定向时，经常无法提供有效的自适应支架。行为引导的微调策略显著提高了指导性能。

Conclusion: 现有的LLM在学习者感到困惑或需要重定向时，通常无法提供有效的自适应支架。通过利用行为提示的教学对话的行为引导微调策略，可以显著提高指导性能。

Abstract: The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [7] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

TL;DR: This paper introduces a scalable, automated approach to generate high-quality forget sets using language models themselves, which can help remove specific domains of knowledge from a model without full retraining.


<details>
  <summary>Details</summary>
Motivation: Modern large language models often encode sensitive, harmful, or copyrighted knowledge, raising the need for post-hoc unlearning-the ability to remove specific domains of knowledge from a model without full retraining. A major bottleneck in current unlearning pipelines is constructing effective forget sets-datasets that approximate the target domain and guide the model to forget it.

Method: A scalable, automated approach to generate high-quality forget sets using language models themselves. Synthesizes textbook-style data through a structured prompting pipeline, requiring only a domain name as input.

Result: Our synthetic datasets consistently outperform the baseline synthetic alternatives and are comparable to the expert-curated ones. the multi-step generation pipeline significantly boosts data diversity, which in turn improves unlearning utility.

Conclusion: Synthetic datasets offer a promising path toward practical, scalable unlearning for a wide range of emerging domains without the need for manual intervention.

Abstract: Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [8] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

TL;DR: Introduces BrowseComp-Plus, a benchmark to address limitations of BrowseComp by using a fixed corpus for controlled experimentation and improved evaluation of deep research agents.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks like BrowseComp relies on black-box live web search APIs, have notable limitations in fairness and transparency, hindering fair comparisons and reproducibility.

Method: Introduce BrowseComp-Plus, a benchmark derived from BrowseComp, employing a fixed, carefully curated corpus with human-verified supporting documents and mined challenging negatives.

Result: The benchmark is shown to be effective in distinguishing the performance of deep research systems. For instance, the open-source model Search-R1, when paired with the BM25 retriever, achieves 3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with fewer search calls.

Conclusion: BrowseComp-Plus benchmark enables comprehensive evaluation and disentangled analysis of deep research agents and retrieval methods, fostering insights into retrieval effectiveness, citation accuracy, and context engineering in Deep-Research system.

Abstract: Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [9] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

TL;DR: 本文探讨了不依赖合并列表的 BPE 推理算法对语言模型性能的影响，发现非目标性的方法对性能影响很小，为更简单和隐私保护的分词方案提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 最近的研究表明，合并列表暴露了一个潜在的攻击面，可以提取有关语言模型训练数据的信息。在本文中，我们探讨了根本不依赖于此合并列表的 BPE 推理算法的下游影响，因此与 BPE 训练期间的编码过程不同。

Method: 我们研究了两种不同于训练期间 BPE 应用的 BPE 推理方案：a) 目标性地偏离合并列表，包括随机合并顺序，以及涉及删除/截断的各种合并列表损坏，以及 b) 非目标性的 BPE 推理算法，这些算法不依赖于合并列表，而是专注于贪婪或精确地压缩文本。

Result: 目标性地偏离合并列表会导致语言模型性能的显着下降，而非目标性的、不依赖合并列表的推理算法对下游性能的影响很小，通常比预期的要小得多。

Conclusion: 非目标性的、不依赖合并列表的 BPE 推理算法对下游性能的影响很小，通常比预期的要小得多。这些发现为更简单、可能更具有隐私保护性的分词方案铺平了道路，这些方案不会灾难性地损害模型性能。

Abstract: Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [10] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

TL;DR: LLMs show stereotype and deviation biases, potentially causing harm.


<details>
  <summary>Details</summary>
Motivation: Investigate stereotype bias and deviation bias in LLMs, which are limitations and potential risks of LLMs.

Method: Asking four advanced LLMs to generate profiles of individuals to examine the associations between each demographic group and attributes such as political affiliation, religion, and sexual orientation.

Result: All examined LLMs exhibit both significant stereotype bias and deviation bias towards multiple groups.

Conclusion: LLMs exhibit both significant stereotype bias and deviation bias towards multiple groups, which can lead to potential harms.

Abstract: Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [11] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

TL;DR: 本文研究了如何利用语言资源来提高 Kanuri 语的机器翻译质量，结果表明平行句子是最有效的数据来源，而单独使用语法效果不佳。


<details>
  <summary>Details</summary>
Motivation: 目前最先进的模型展示了利用上下文学习翻译成以前未见过的语言上下文的能力。我们专注于Kanuri，这种语言虽然有大量的说话人，但数字资源却很少。我们设计了两个用于评估的数据集：一个侧重于健康和人道主义术语，另一个包含广义术语，调查领域特定任务如何影响LLM翻译质量。

Method: 通过提供不同的语言资源组合（语法、字典和平行句子），来衡量LLM翻译效果，并将结果与母语人士翻译和人类语言学家的表现进行比较。使用自动指标和母语人士对流畅性和准确性的评估。

Result: 平行句子仍然是最有效的数据来源，在人类评估和自动指标方面优于其他方法。虽然结合语法比零样本翻译有所改进，但它作为一种有效的独立数据来源是失败的。人类评估显示，LLM在实现准确性（意义）方面比流畅性（语法性）更有效。

Conclusion: 平行句子是最有效的数据来源，优于其他方法。仅包含语法无法为有效的领域特定翻译提供足够的上下文。

Abstract: Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [12] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

TL;DR: This paper studies the effect of chain-of-thought prompting on fairness in language models, finding that biased decisions do not always indicate biased thoughts.


<details>
  <summary>Details</summary>
Motivation: The presence of biases based on gender, race, socio-economic status, physical appearance, and sexual orientation makes the deployment of language models challenging.

Method: Experiments on 5 popular large language models using fairness metrics to quantify 11 different biases in the model's thoughts and output.

Result: Bias in thinking steps is not highly correlated with output bias (less than 0.6 correlation with a p-value smaller than 0.001 in most cases).

Conclusion: The bias in the thinking steps is not highly correlated with the output bias. The tested models with biased decisions do not always possess biased thoughts.

Abstract: The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [13] [Schema Lineage Extraction at Scale: Multilingual Pipelines, Composite Evaluation, and Language-Model Benchmarks](https://arxiv.org/abs/2508.07179)
*Jiaqi Yin,Yi-Wei Chen,Meng-Lung Lee,Xiya Liu*

Main category: cs.CL

TL;DR: 提出了一个自动模式沿袭提取框架，以解决企业数据管道中的语义漂移问题。


<details>
  <summary>Details</summary>
Motivation: 企业数据管道通常导致原始元数据和下游数据之间的语义断开。这种“语义漂移”会损害数据的可重复性和治理，并降低检索增强生成 (RAG) 和文本到 SQL 系统等服务的效用。

Method: 用于从多语言企业管道脚本中自动提取细粒度模式沿袭的新颖框架。该方法识别四个关键组件：源模式、源表、转换逻辑和聚合操作，从而创建数据转换的标准化表示。

Result: 模式沿袭提取的性能随模型大小的增加而扩展。一个 32B 的开源模型，在单一推理追踪下，可以达到与标准提示下 GPT 系列相当的性能。

Conclusion: 性能随模型大小和提示技术复杂性的增加而扩展。一个32B的开源模型，使用单一推理追踪，可以达到与标准提示下的GPT系列相当的性能。这表明在实际应用中部署模式感知代理是一种可扩展且经济的方法。

Abstract: Enterprise data pipelines, characterized by complex transformations across
multiple programming languages, often cause a semantic disconnect between
original metadata and downstream data. This "semantic drift" compromises data
reproducibility and governance, and impairs the utility of services like
retrieval-augmented generation (RAG) and text-to-SQL systems. To address this,
a novel framework is proposed for the automated extraction of fine-grained
schema lineage from multilingual enterprise pipeline scripts. This method
identifies four key components: source schemas, source tables, transformation
logic, and aggregation operations, creating a standardized representation of
data transformations. For the rigorous evaluation of lineage quality, this
paper introduces the Schema Lineage Composite Evaluation (SLiCE), a metric that
assesses both structural correctness and semantic fidelity. A new benchmark is
also presented, comprising 1,700 manually annotated lineages from real-world
industrial scripts. Experiments were conducted with 12 language models, from
1.3B to 32B small language models (SLMs) to large language models (LLMs) like
GPT-4o and GPT-4.1. The results demonstrate that the performance of schema
lineage extraction scales with model size and the sophistication of prompting
techniques. Specially, a 32B open-source model, using a single reasoning trace,
can achieve performance comparable to the GPT series under standard prompting.
This finding suggests a scalable and economical approach for deploying
schema-aware agents in practical applications.

</details>


### [14] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

TL;DR: LLM裁判可能存在自偏见和家族偏见，这会影响模型评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）可以作为裁判，对其他LLM的输出提供快速且可靠的评估。然而，模型可能会系统性地给自己的输出分配过于有利的评分，这种现象被称为自偏见，可能会扭曲对真实模型性能的评估。以往的研究经常将模型质量的真正差异与偏见混淆，或者错误地假设来自LLM和人类的评估遵循相同的评分分布。

Method: 提出了一种统计框架，可以明确地将自偏见可以被识别和估计的假设形式化。该方法对LLM裁判分配给自己的补全的分数分布与其他模型的分数分布之间的差异进行建模，同时考虑了独立第三方裁判（例如，人类）提供的补全的潜在质量。

Result: 发现一些模型，如GPT-4o和Claude 3.5 Sonnet，会系统性地给自己的输出分配更高的分数。这些模型还表现出家族偏见，系统性地给同一家族的其他模型输出分配更高的评分。

Conclusion: GPT-4o和Claude 3.5 Sonnet等模型会系统性地给自己的输出分配更高的分数，并且还会表现出家族偏见，系统性地给同一家族的其他模型输出分配更高的分数。使用LLM裁判存在潜在的缺陷，并为在解释自动评估时减轻偏差提供了实用指导。

Abstract: Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [15] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

TL;DR: This paper uses LLMs to automate semantic and sentiment annotation for a large oral history archive of Japanese American Incarceration, achieving high accuracy with well-designed prompts and providing a reusable pipeline for culturally sensitive archival analysis.


<details>
  <summary>Details</summary>
Motivation: Large-scale analysis of oral history archives remains limited due to their unstructured format, emotional complexity, and high annotation costs.

Method: This paper presents a scalable framework to automate semantic and sentiment annotation for Japanese American Incarceration Oral History. Using LLMs, we construct a high-quality dataset, evaluate multiple models, and test prompt engineering strategies in historically sensitive contexts. Our multiphase approach combines expert annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We labeled 558 sentences from 15 narrators for sentiment and semantic classification, then evaluated zero-shot, few-shot, and RAG strategies. The best prompt configurations were used to annotate 92,191 sentences from 1,002 interviews in the JAIOH collection.

Result: For semantic classification, ChatGPT achieved the highest F1 score (88.71%), followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models showing comparable results.

Conclusion: LLMs can effectively perform semantic and sentiment annotation across large oral history collections when guided by well-designed prompts. This study provides a reusable annotation pipeline and practical guidance for applying LLMs in culturally sensitive archival analysis. By bridging archival ethics with scalable NLP techniques, this work lays the groundwork for responsible use of artificial intelligence in digital humanities and preservation of collective memory.

Abstract: Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [16] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

TL;DR: 提出了多轮越狱的概念，构建了MTJ-Bench基准，并在一系列模型上进行了测试，揭示了一种新的安全威胁。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）的越狱工作旨在从给定的提示中引出不安全的输出，但它只关注针对一个特定查询的单轮越狱。另一方面，先进的LLM被设计来处理极长的上下文，因此可以进行多轮对话。因此，我们建议探索多轮越狱，其中越狱的LLM在第一轮对话或单个目标查询中不断被测试。

Method: 构建了一个多轮越狱基准（MTJ-Bench），用于在一系列开源和闭源模型上进行基准测试。

Result: 在一系列开源和闭源模型上对该基准进行了测试，并为这种新的安全威胁提供了新的见解。

Conclusion: 揭示了大型语言模型中一种新的多轮越狱漏洞，旨在引起社区对构建更安全的LLM的关注，并为更深入地理解LLM越狱铺平道路。

Abstract: Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [17] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

TL;DR: 提出了SEVADE框架，用于抵抗幻觉的反讽检测，并在基准数据集上取得了state-of-the-art的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型方法通常受到单视角分析、静态推理路径以及在处理复杂的反讽修辞时容易产生幻觉的影响，这影响了它们的准确性和可靠性。

Method: 提出SEVADE，一个新颖的自进化多智能体分析框架，具有解耦评估功能，用于抵抗幻觉的反讽检测。核心是一个动态智能体推理引擎（DARE），它利用一个基于语言理论的专业智能体团队来执行文本的多方面解构，并生成一个结构化的推理链。随后，一个单独的轻量级理由裁决器（RA）仅基于此推理链执行最终分类。

Result: SEVADE框架实现了最先进的性能，准确率平均提高了6.75%，Macro-F1得分平均提高了6.29%。

Conclusion: SEVADE框架在四个基准数据集上实现了最先进的性能，准确率平均提高了6.75%，Macro-F1得分平均提高了6.29%。

Abstract: Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [18] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

TL;DR: This paper introduces an annotation framework for learner errors, collects a dataset of annotated errors with human feedback, and evaluates different methods of generating feedback using LLMs.


<details>
  <summary>Details</summary>
Motivation: While these systems are effective at improving text, they are not optimally designed for language learning. They favor direct revisions, often with a click-to-fix functionality that can be applied without considering the reason for the correction. Meanwhile, depending on the error type, learners may benefit most from simple explanations and strategically indirect hints, especially on generalizable grammatical rules. To support the generation of such feedback, we introduce an annotation framework that models each error's error type and generalizability.

Method: We collect a dataset of annotated learner errors and corresponding human-written feedback comments, each labeled as a direct correction or hint. With this data, we evaluate keyword-guided, keyword-free, and template-guided methods of generating feedback using large language models (LLMs).

Result: Human teachers examined each system's outputs, assessing them on grounds including relevance, factuality, and comprehensibility.

Conclusion: We report on the development of the dataset and the comparative performance of the systems investigated.

Abstract: Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [19] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

TL;DR: A neural TTS architecture is introduced to support tonal phonology and under-resourced linguistic environments for the Manipuri language.


<details>
  <summary>Details</summary>
Motivation: This paper presents the development of a Text-to-Speech (TTS) system for the Manipuri language using the Meitei Mayek script.

Method: Leveraging Tacotron 2 and HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal phonology and under-resourced linguistic environments. We develop a phoneme mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset

Result: demonstrate intelligible and natural speech synthesis, validated through subjective and objective metrics.

Conclusion: This system lays the groundwork for linguistic preservation and technological inclusion of Manipuri.

Abstract: This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [20] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

TL;DR: 提出了一种基于标签相似性的自动标签对齐方法，用于合并 NER 数据集，提高低资源领域的 NER 性能。


<details>
  <summary>Details</summary>
Motivation: 当前数据集合并方法主要集中在手动标签映射或构建标签图等策略上，这些方法缺乏可解释性和可扩展性。

Method: 提出了一种基于标签相似性的自动标签对齐方法，该方法结合了经验和语义相似性，并使用贪婪的成对合并策略来统一不同数据集中的标签空间。

Result: 实验分两个阶段进行：首先，将三个现有的 NER 数据集合并为一个统一的语料库，对 NER 性能的影响最小；其次，将该语料库与金融领域的一个小型自建数据集集成。结果表明，该方法能够有效地进行数据集的合并，并提高低资源金融领域的 NER 性能。

Conclusion: 提出了一种高效、可解释且可扩展的解决方案，用于整合多源 NER 语料库。

Abstract: Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


### [21] [The ReQAP System for Question Answering over Personal Information](https://arxiv.org/abs/2508.06880)
*Philipp Christmann,Gerhard Weikum*

Main category: cs.CL

TL;DR: ReQAP system answers complex questions by recursively decomposing questions and building an operator tree, using light-weight language models. It supports tracing answers back to the underlying sources for human comprehensibility and user trust.


<details>
  <summary>Details</summary>
Motivation: Personal information is abundant on users' devices, from structured data in calendar, shopping records or fitness tools, to unstructured contents in mail and social media posts.

Method: The unique trait of ReQAP is that it recursively decomposes questions and incrementally builds an operator tree for execution. Both the question interpretation and the individual operators make smart use of light-weight language models, with judicious fine-tuning.

Result: This works presents the ReQAP system that supports users with answers for complex questions that involve filters, joins and aggregation over heterogeneous sources.

Conclusion: The demo showcases the rich functionality for advanced user questions, and also offers detailed tracking of how the answers are computed by the operators in the execution tree. Being able to trace answers back to the underlying sources is vital for human comprehensibility and user trust in the system.

Abstract: Personal information is abundant on users' devices, from structured data in
calendar, shopping records or fitness tools, to unstructured contents in mail
and social media posts. This works presents the ReQAP system that supports
users with answers for complex questions that involve filters, joins and
aggregation over heterogeneous sources. The unique trait of ReQAP is that it
recursively decomposes questions and incrementally builds an operator tree for
execution. Both the question interpretation and the individual operators make
smart use of light-weight language models, with judicious fine-tuning. The demo
showcases the rich functionality for advanced user questions, and also offers
detailed tracking of how the answers are computed by the operators in the
execution tree. Being able to trace answers back to the underlying sources is
vital for human comprehensibility and user trust in the system.

</details>


### [22] [Score Before You Speak: Improving Persona Consistency in Dialogue Generation using Response Quality Scores](https://arxiv.org/abs/2508.06886)
*Arpita Saggar,Jonathan C. Darling,Vania Dimitrova,Duygu Sarikaya,David C. Hogg*

Main category: cs.CL

TL;DR: SBS: a novel framework unifies the learning of responses and their relative quality into a single step, allows existing models to better capture a spectrum of persona-consistent dialogues.


<details>
  <summary>Details</summary>
Motivation: Effectively integrating persona fidelity in conversations remains challenging due to the limited diversity in existing dialogue data.

Method: SBS (Score-Before-Speaking): unifies the learning of responses and their relative quality into a single step; train a dialogue model to correlate augmented responses with a quality score during training and then leverage this knowledge at inference. We use noun-based substitution for augmentation and semantic similarity-based scores as a proxy for response quality.

Result: SBS outperforms previous methods and yields improvements for both million and billion-parameter models. Including scores in the input prompt during training is superior to conventional training setups.

Conclusion: Score-conditioned training allows existing models to better capture a spectrum of persona-consistent dialogues.

Abstract: Persona-based dialogue generation is an important milestone towards building
conversational artificial intelligence. Despite the ever-improving capabilities
of large language models (LLMs), effectively integrating persona fidelity in
conversations remains challenging due to the limited diversity in existing
dialogue data. We propose a novel framework SBS (Score-Before-Speaking), which
outperforms previous methods and yields improvements for both million and
billion-parameter models. Unlike previous methods, SBS unifies the learning of
responses and their relative quality into a single step. The key innovation is
to train a dialogue model to correlate augmented responses with a quality score
during training and then leverage this knowledge at inference. We use
noun-based substitution for augmentation and semantic similarity-based scores
as a proxy for response quality. Through extensive experiments with benchmark
datasets (PERSONA-CHAT and ConvAI2), we show that score-conditioned training
allows existing models to better capture a spectrum of persona-consistent
dialogues. Our ablation studies also demonstrate that including scores in the
input prompt during training is superior to conventional training setups. Code
and further details are available at
https://arpita2512.github.io/score_before_you_speak

</details>


### [23] [Model-Agnostic Sentiment Distribution Stability Analysis for Robust LLM-Generated Texts Detection](https://arxiv.org/abs/2508.06913)
*Siyuan Li,Xi Lin,Guangyan Li,Zehao Liu,Aodu Wulianghai,Li Ding,Jun Wu,Jianhua Li*

Main category: cs.CL

TL;DR: SentiDetect是一种新的LLM生成文本检测框架，通过分析情感分布的稳定性来区分LLM和人类写作的文本，优于现有方法，且更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有的检测方法泛化能力有限，容易受到释义、对抗性扰动和跨领域转移的影响。LLM输出往往表现出情感一致的模式，而人类文本表现出更大的情感可变性。

Method: 通过分析情感分布稳定性的差异来检测LLM生成的文本。定义了情感分布一致性和情感分布保持两个互补指标，以量化情感改变和语义保持转换下的稳定性。

Result: 在五个不同的数据集和包括Gemini-1.5-Pro、Claude-3、GPT-4-0613和LLaMa-3.3在内的一系列先进LLM上进行了评估，结果表明SentiDetect优于现有技术，Gemini-1.5-Pro和GPT-4-0613的F1得分分别提高了16%和11%以上。

Conclusion: SentiDetect在检测LLM生成文本方面优于现有方法， 并且对释义、对抗性攻击和文本长度变化表现出更强的鲁棒性。

Abstract: The rapid advancement of large language models (LLMs) has resulted in
increasingly sophisticated AI-generated content, posing significant challenges
in distinguishing LLM-generated text from human-written language. Existing
detection methods, primarily based on lexical heuristics or fine-tuned
classifiers, often suffer from limited generalizability and are vulnerable to
paraphrasing, adversarial perturbations, and cross-domain shifts. In this work,
we propose SentiDetect, a model-agnostic framework for detecting LLM-generated
text by analyzing the divergence in sentiment distribution stability. Our
method is motivated by the empirical observation that LLM outputs tend to
exhibit emotionally consistent patterns, whereas human-written texts display
greater emotional variability. To capture this phenomenon, we define two
complementary metrics: sentiment distribution consistency and sentiment
distribution preservation, which quantify stability under sentiment-altering
and semantic-preserving transformations. We evaluate SentiDetect on five
diverse datasets and a range of advanced LLMs,including Gemini-1.5-Pro,
Claude-3, GPT-4-0613, and LLaMa-3.3. Experimental results demonstrate its
superiority over state-of-the-art baselines, with over 16% and 11% F1 score
improvements on Gemini-1.5-Pro and GPT-4-0613, respectively. Moreover,
SentiDetect also shows greater robustness to paraphrasing, adversarial attacks,
and text length variations, outperforming existing detectors in challenging
scenarios.

</details>


### [24] [Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction](https://arxiv.org/abs/2508.06971)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab*

Main category: cs.CL

TL;DR: 提出了一种用于古兰经问答的两阶段框架，该框架在 Quran QA 2023 Shared Task 上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 由于古典阿拉伯语的语言复杂性和宗教文本的语义丰富性，古兰经问答提出了独特的挑战。

Method: 提出了一种新颖的两阶段框架，该框架解决了段落检索和答案提取。

Result: 在 Quran QA 2023 Shared Task 上取得了最先进的结果，检索的 MAP@10 为 0.3128，MRR@10 为 0.5763，提取的 pAP@10 为 0.669，大大优于以前的方法。

Conclusion: 结合模型集成和指令调整的语言模型有效地解决了专业领域中低资源问答的挑战。

Abstract: Quranic Question Answering presents unique challenges due to the linguistic
complexity of Classical Arabic and the semantic richness of religious texts. In
this paper, we propose a novel two-stage framework that addresses both passage
retrieval and answer extraction. For passage retrieval, we ensemble fine-tuned
Arabic language models to achieve superior ranking performance. For answer
extraction, we employ instruction-tuned large language models with few-shot
prompting to overcome the limitations of fine-tuning on small datasets. Our
approach achieves state-of-the-art results on the Quran QA 2023 Shared Task,
with a MAP@10 of 0.3128 and MRR@10 of 0.5763 for retrieval, and a pAP@10 of
0.669 for extraction, substantially outperforming previous methods. These
results demonstrate that combining model ensembling and instruction-tuned
language models effectively addresses the challenges of low-resource question
answering in specialized domains.

</details>


### [25] [Rethinking 1-bit Optimization Leveraging Pre-trained Large Language Models](https://arxiv.org/abs/2508.06974)
*Zhijun Tu,Hanting Chen,Siqi Liu,Chuanjian Liu,Jian Li,Jie Hu,Yunhe Wang*

Main category: cs.CL

TL;DR: proposes a consistent progressive training method to convert floating-point weights into binarized ones,achieving high-performance 1-bit LLMs using pre-trained models


<details>
  <summary>Details</summary>
Motivation: existing methods typically train 1-bit LLMs from scratch, failing to fully leverage pre-trained models. This results in high training costs and notable accuracy degradation. The large gap between full precision and 1-bit representations makes direct adaptation difficult.

Method: consistent progressive training for both forward and backward, binary-aware initialization and dual-scaling compensation

Result: outperforms existing approaches on LLMs of various sizes

Conclusion: high-performance 1-bit LLMs can be achieved using pre-trained models, eliminating the need for expensive training from scratch.

Abstract: 1-bit LLM quantization offers significant advantages in reducing storage and
computational costs. However, existing methods typically train 1-bit LLMs from
scratch, failing to fully leverage pre-trained models. This results in high
training costs and notable accuracy degradation. We identify that the large gap
between full precision and 1-bit representations makes direct adaptation
difficult. In this paper, we introduce a consistent progressive training for
both forward and backward, smoothly converting the floating-point weights into
the binarized ones. Additionally, we incorporate binary-aware initialization
and dual-scaling compensation to reduce the difficulty of progressive training
and improve the performance. Experimental results on LLMs of various sizes
demonstrate that our method outperforms existing approaches. Our results show
that high-performance 1-bit LLMs can be achieved using pre-trained models,
eliminating the need for expensive training from scratch.

</details>


### [26] [Vec2Summ: Text Summarization via Probabilistic Sentence Embeddings](https://arxiv.org/abs/2508.07017)
*Mao Li,Fred Conrad,Johann Gagnon-Bartsch*

Main category: cs.CL

TL;DR: Vec2Summ 是一种新的摘要方法，它通过语义压缩来规避 LLM 的限制，并在效率和主题覆盖率方面表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的摘要方法的关键限制。它避免了上下文长度的限制，通过语义参数实现可解释和可控的生成，并能有效地随语料库大小进行扩展

Method: Vec2Summ，一种将任务定义为语义压缩的抽象摘要的新方法: 使用语义嵌入空间中的单个平均向量表示文档集合，然后使用生成语言模型将这个平均向量解码为自然语言。

Result: Vec2Summ 为主题明确、顺序不变的语料库生成连贯的摘要

Conclusion: Vec2Summ 在主题覆盖和效率方面与直接的 LLM 摘要相当，尽管细节较少。它在可扩展性、语义控制和语料库级别抽象方面具有潜力。

Abstract: We propose Vec2Summ, a novel method for abstractive summarization that frames
the task as semantic compression. Vec2Summ represents a document collection
using a single mean vector in the semantic embedding space, capturing the
central meaning of the corpus. To reconstruct fluent summaries, we perform
embedding inversion -- decoding this mean vector into natural language using a
generative language model. To improve reconstruction quality and capture some
degree of topical variability, we introduce stochasticity by sampling from a
Gaussian distribution centered on the mean. This approach is loosely analogous
to bagging in ensemble learning, where controlled randomness encourages more
robust and varied outputs. Vec2Summ addresses key limitations of LLM-based
summarization methods. It avoids context-length constraints, enables
interpretable and controllable generation via semantic parameters, and scales
efficiently with corpus size -- requiring only $O(d + d^2)$ parameters.
Empirical results show that Vec2Summ produces coherent summaries for topically
focused, order-invariant corpora, with performance comparable to direct LLM
summarization in terms of thematic coverage and efficiency, albeit with less
fine-grained detail. These results underscore Vec2Summ's potential in settings
where scalability, semantic control, and corpus-level abstraction are
prioritized.

</details>


### [27] [SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages](https://arxiv.org/abs/2508.07069)
*Muhammad Dehan Al Kautsar,Aswin Candra,Muhammad Alif Al Hakim,Maxalmina Satria Kahfi,Fajri Koto,Alham Fikri Aji,Peerat Limkonchotiwat,Ekapol Chuangsuwanich,Genta Indra Winata*

Main category: cs.CL

TL;DR: We introduce SEADialogues, a culturally grounded dialogue dataset centered on Southeast Asia, featuring dialogues in eight languages from six Southeast Asian countries.


<details>
  <summary>Details</summary>
Motivation: most existing chit-chat datasets overlook the cultural nuances inherent in natural human conversations

Method: We introduce SEADialogues, a culturally grounded dialogue dataset centered on Southeast Asia.

Result: Our dataset features dialogues in eight languages from six Southeast Asian countries, many of which are low-resource despite having sizable speaker populations. To enhance cultural relevance and personalization, each dialogue includes persona attributes and two culturally grounded topics that reflect everyday life in the respective communities.

Conclusion: We release a multi-turn dialogue dataset to advance research on culturally aware and human-centric large language models, including conversational dialogue agents.

Abstract: Although numerous datasets have been developed to support dialogue systems,
most existing chit-chat datasets overlook the cultural nuances inherent in
natural human conversations. To address this gap, we introduce SEADialogues, a
culturally grounded dialogue dataset centered on Southeast Asia, a region with
over 700 million people and immense cultural diversity. Our dataset features
dialogues in eight languages from six Southeast Asian countries, many of which
are low-resource despite having sizable speaker populations. To enhance
cultural relevance and personalization, each dialogue includes persona
attributes and two culturally grounded topics that reflect everyday life in the
respective communities. Furthermore, we release a multi-turn dialogue dataset
to advance research on culturally aware and human-centric large language
models, including conversational dialogue agents.

</details>


### [28] [BharatBBQ: A Multilingual Bias Benchmark for Question Answering in the Indian Context](https://arxiv.org/abs/2508.07090)
*Aditya Tomar,Nihar Ranjan Sahoo,Pushpak Bhattacharyya*

Main category: cs.CL

TL;DR: BharatBBQ, a new benchmark, is introduced to evaluate social biases in language models within the Indian context, revealing persistent and amplified biases in Indian languages compared to English.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks primarily focus on Western contexts, limiting their applicability to the Indian context. Evaluating social biases in language models (LMs) is crucial for ensuring fairness and minimizing the reinforcement of harmful stereotypes in AI systems.

Method: Introducing BharatBBQ, a culturally adapted benchmark for assessing biases in Hindi, English, Marathi, Bengali, Tamil, Telugu, Odia, and Assamese. The dataset contains 49,108 examples expanded to 392,864 examples in eight languages. Evaluated five multilingual LM families across zero and few-shot settings, analyzing their bias and stereotypical bias scores.

Result: Findings highlight persistent biases across languages and social categories and often amplified biases in Indian languages compared to English.

Conclusion: Persistent biases exist across languages and social categories, with Indian languages often showing amplified biases compared to English. This highlights the need for linguistically and culturally grounded benchmarks for bias evaluation.

Abstract: Evaluating social biases in language models (LMs) is crucial for ensuring
fairness and minimizing the reinforcement of harmful stereotypes in AI systems.
Existing benchmarks, such as the Bias Benchmark for Question Answering (BBQ),
primarily focus on Western contexts, limiting their applicability to the Indian
context. To address this gap, we introduce BharatBBQ, a culturally adapted
benchmark designed to assess biases in Hindi, English, Marathi, Bengali, Tamil,
Telugu, Odia, and Assamese. BharatBBQ covers 13 social categories, including 3
intersectional groups, reflecting prevalent biases in the Indian sociocultural
landscape. Our dataset contains 49,108 examples in one language that are
expanded using translation and verification to 392,864 examples in eight
different languages. We evaluate five multilingual LM families across zero and
few-shot settings, analyzing their bias and stereotypical bias scores. Our
findings highlight persistent biases across languages and social categories and
often amplified biases in Indian languages compared to English, demonstrating
the necessity of linguistically and culturally grounded benchmarks for bias
evaluation.

</details>


### [29] [Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning](https://arxiv.org/abs/2508.07101)
*Lijie Yang,Zhihao Zhang,Arti Jain,Shijie Cao,Baihong Yuan,Yiwei Chen,Zhihao Jia,Ravi Netravali*

Main category: cs.CL

TL;DR: LessIsMore是一种免训练稀疏注意力机制，通过全局注意力模式和统一的跨头token排序，提高了推理速度和准确性，同时减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型通过测试时扩展实现了强大的性能，但计算开销巨大，特别是在处理短输入提示时产生过多的tokens。虽然稀疏注意力机制可以减少延迟和内存使用，但现有方法由于长生成推理过程中累积的误差而导致显著的精度下降。这些方法通常需要高token保留率或昂贵的再训练。

Method: 提出了一种名为LessIsMore的免训练稀疏注意力机制，它利用全局注意力模式，并结合局部注意力头部的token选择与最近的上下文信息，实现统一的跨头token排序。

Result: LessIsMore在各种推理任务和基准测试中，在保持甚至提高准确性的同时，平均解码速度比完全注意力机制快1.1倍。此外，LessIsMore在不损失准确性的情况下，减少了2倍的tokens的关注，与现有的稀疏注意力方法相比，实现了1.13倍的端到端加速。

Conclusion: LessIsMore在保持甚至提高准确性的同时，平均解码速度比完全注意力机制快1.1倍。此外，LessIsMore在不损失准确性的情况下，减少了2倍的tokens的关注，与现有的稀疏注意力方法相比，实现了1.13倍的端到端加速。

Abstract: Large reasoning models achieve strong performance through test-time scaling
but incur substantial computational overhead, particularly from excessive token
generation when processing short input prompts. While sparse attention
mechanisms can reduce latency and memory usage, existing approaches suffer from
significant accuracy degradation due to accumulated errors during
long-generation reasoning. These methods generally require either high token
retention rates or expensive retraining. We introduce LessIsMore, a
training-free sparse attention mechanism for reasoning tasks, which leverages
global attention patterns rather than relying on traditional head-specific
local optimizations. LessIsMore aggregates token selections from local
attention heads with recent contextual information, enabling unified cross-head
token ranking for future decoding layers. This unified selection improves
generalization and efficiency by avoiding the need to maintain separate token
subsets per head. Evaluation across diverse reasoning tasks and benchmarks
shows that LessIsMore preserves -- and in some cases improves -- accuracy while
achieving a $1.1\times$ average decoding speed-up compared to full attention.
Moreover, LessIsMore attends to $2\times$ fewer tokens without accuracy loss,
achieving a $1.13\times$ end-to-end speed-up compared to existing sparse
attention methods.

</details>


### [30] [Arce: Augmented Roberta with Contextualized Elucidations for Ner in Automated Rule Checking](https://arxiv.org/abs/2508.07286)
*Jian Chen,Jinbao Tian,Yankui Li,Zhou Li*

Main category: cs.CL

TL;DR: ARCE：一种利用LLM生成简单解释语料库来增强RoBERTa模型在AEC领域的命名实体识别性能的方法，实验表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 从专业文本中准确提取信息是一项关键挑战，尤其是在建筑、工程和施工（AEC）领域中进行命名实体识别（NER）以支持自动规则检查（ARC）。标准预训练模型的性能通常受到领域差距的限制，因为它们难以解释AEC文本中固有的专业术语和复杂的关系背景。虽然可以通过在大型人工管理的领域语料库上进一步预训练来缓解这个问题，但这种方法既费力又成本高昂。因此，利用大型语言模型（LLM）进行自动知识生成已成为一种有前途的替代方案。然而，生成能够真正增强较小、高效模型知识的最佳策略仍然是一个悬而未决的问题。

Method: ARCE（augmented RoBERTa with contextualized elucidations），一种新方法，系统地探索和优化知识生成过程。ARCE首先使用LLM生成一个简单、直接的解释语料库（Cote），然后使用该语料库在下游任务的微调之前，逐步预训练RoBERTa模型。

Result: ARCE在基准AEC数据集上实现了77.20%的Macro-F1分数，建立了新的最先进水平。研究结果表明，基于简单解释的知识比基于复杂角色的理由更有效。

Conclusion: ARCE在基准AEC数据集上建立了新的最先进水平，实现了77.20%的Macro-F1分数。结果表明，对于这项任务，基于简单解释的知识比基于复杂角色的理由更有效。

Abstract: Accurate information extraction from specialized texts is a critical
challenge, particularly for named entity recognition (NER) in the architecture,
engineering, and construction (AEC) domain to support automated rule checking
(ARC). The performance of standard pre-trained models is often constrained by
the domain gap, as they struggle to interpret the specialized terminology and
complex relational contexts inherent in AEC texts. Although this issue can be
mitigated by further pre-training on large, human-curated domain corpora, as
exemplified by methods like ARCBERT, this approach is both labor-intensive and
cost-prohibitive. Consequently, leveraging large language models (LLMs) for
automated knowledge generation has emerged as a promising alternative. However,
the optimal strategy for generating knowledge that can genuinely enhance
smaller, efficient models remains an open question. To address this, we propose
ARCE (augmented RoBERTa with contextualized elucidations), a novel approach
that systematically explores and optimizes this generation process. ARCE
employs an LLM to first generate a corpus of simple, direct explanations, which
we term Cote, and then uses this corpus to incrementally pre-train a RoBERTa
model prior to its fine-tuning on the downstream task. Our extensive
experiments show that ARCE establishes a new state-of-the-art on a benchmark
AEC dataset, achieving a Macro-F1 score of 77.20%. This result also reveals a
key finding: simple, explanation-based knowledge proves surprisingly more
effective than complex, role-based rationales for this task. The code is
publicly available at:https://github.com/nxcc-lab/ARCE.

</details>


### [31] [Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution](https://arxiv.org/abs/2508.07111)
*Falaah Arif Khan,Nivedha Sivakumar,Yinong Oliver Wang,Katherine Metcalf,Cezanne Camacho,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

TL;DR: The paper examines intersectional bias in LLMs using a new benchmark, finding significant confidence disparities across demographic attributes and suggesting that models rely more on memorization than reasoning.


<details>
  <summary>Details</summary>
Motivation: AI systems can reflect and exacerbate societal biases, raising concerns about identity-based harm when used in critical social contexts. Prior work has evaluated demographic disparities in LLMs, but this work extends evaluations to examine intersectional bias.

Method: The study introduces a new benchmark called WinoIdentity, augmenting the WinoBias dataset with 25 demographic markers across 10 attributes, intersected with binary gender, yielding 245,700 prompts. It investigates bias through the lens of uncertainty and proposes a group (un)fairness metric called Coreference Confidence Disparity.

Result: LLMs show confidence disparities as high as 40% along various demographic attributes. Models are most uncertain about doubly-disadvantaged identities in anti-stereotypical settings. Coreference confidence decreases even for hegemonic or privileged markers.

Conclusion: LLMs exhibit confidence disparities up to 40% along various demographic attributes, with models being most uncertain about doubly-disadvantaged identities in anti-stereotypical settings. Coreference confidence decreases even for hegemonic or privileged markers, suggesting memorization rather than logical reasoning. These failures in value alignment and validity can compound to cause social harm.

Abstract: Large language models (LLMs) have achieved impressive performance, leading to
their widespread adoption as decision-support tools in resource-constrained
contexts like hiring and admissions. There is, however, scientific consensus
that AI systems can reflect and exacerbate societal biases, raising concerns
about identity-based harm when used in critical social contexts. Prior work has
laid a solid foundation for assessing bias in LLMs by evaluating demographic
disparities in different language reasoning tasks. In this work, we extend
single-axis fairness evaluations to examine intersectional bias, recognizing
that when multiple axes of discrimination intersect, they create distinct
patterns of disadvantage. We create a new benchmark called WinoIdentity by
augmenting the WinoBias dataset with 25 demographic markers across 10
attributes, including age, nationality, and race, intersected with binary
gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns.
Focusing on harms of omission due to underrepresentation, we investigate bias
through the lens of uncertainty and propose a group (un)fairness metric called
Coreference Confidence Disparity which measures whether models are more or less
confident for some intersectional identities than others. We evaluate five
recently published LLMs and find confidence disparities as high as 40% along
various demographic attributes including body type, sexual orientation and
socio-economic status, with models being most uncertain about
doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly,
coreference confidence decreases even for hegemonic or privileged markers,
indicating that the recent impressive performance of LLMs is more likely due to
memorization than logical reasoning. Notably, these are two independent
failures in value alignment and validity that can compound to cause social
harm.

</details>


### [32] [HealthBranches: Synthesizing Clinically-Grounded Question Answering Datasets via Decision Pathways](https://arxiv.org/abs/2508.07308)
*Cristian Cosentino,Annamaria Defilippo,Marco Dossena,Christopher Irwin,Sara Joubbi,Pietro Liò*

Main category: cs.CL

TL;DR: HealthBranches is a new medical QA dataset for evaluating complex reasoning in LLMs. It includes 4,063 case studies across 17 healthcare topics and supports open-ended and multiple-choice questions. The dataset also provides the full reasoning path for each Q&A, enabling robust evaluation of LLMs' multi-step inference capabilities.


<details>
  <summary>Details</summary>
Motivation: HealthBranches is a novel benchmark dataset for medical Question-Answering (Q&A), specifically designed to evaluate complex reasoning in Large Language Models (LLMs).

Method: This dataset is generated through a semi-automated pipeline that transforms explicit decision pathways from medical source into realistic patient cases with associated questions and answers.

Result: Covering 4,063 case studies across 17 healthcare topics, each data point is based on clinically validated reasoning chains. HealthBranches supports both open-ended and multiple-choice question formats and uniquely includes the full reasoning path for each Q&A. Its structured design enables robust evaluation of LLMs' multi-step inference capabilities, including their performance in structured Retrieval-Augmented Generation (RAG) contexts.

Conclusion: HealthBranches establishes a foundation for the development of more trustworthy, interpretable, and clinically reliable LLMs in high-stakes domains while also serving as a valuable resource for educational purposes.

Abstract: HealthBranches is a novel benchmark dataset for medical Question-Answering
(Q&A), specifically designed to evaluate complex reasoning in Large Language
Models (LLMs). This dataset is generated through a semi-automated pipeline that
transforms explicit decision pathways from medical source into realistic
patient cases with associated questions and answers. Covering 4,063 case
studies across 17 healthcare topics, each data point is based on clinically
validated reasoning chains. HealthBranches supports both open-ended and
multiple-choice question formats and uniquely includes the full reasoning path
for each Q&A. Its structured design enables robust evaluation of LLMs'
multi-step inference capabilities, including their performance in structured
Retrieval-Augmented Generation (RAG) contexts. HealthBranches establishes a
foundation for the development of more trustworthy, interpretable, and
clinically reliable LLMs in high-stakes domains while also serving as a
valuable resource for educational purposes.

</details>


### [33] [Fairness of Automatic Speech Recognition: Looking Through a Philosophical Lens](https://arxiv.org/abs/2508.07143)
*Anna Seo Gyeong Choi,Hoon Choi*

Main category: cs.CL

TL;DR: 本文通过哲学视角分析了 ASR 偏差，认为系统地错误识别某些语音变体不仅仅是一种技术限制，它代表了一种不尊重，加剧了对边缘化语言社区的历史不公正现象。


<details>
  <summary>Details</summary>
Motivation: 语音识别（ASR）系统现在调节着无数的人机交互，但对其公平性影响的研究仍然非常有限。

Method: 通过哲学视角

Result: 识别了语音技术的三个独特的伦理维度，这些维度将 ASR 偏差与其他算法公平性问题区分开来：非标准变体说话者的时间负担（“时间税”）、系统无法识别语音时对话流程的中断以及语音模式与个人/文化身份之间的基本联系。这些因素造成了现有的技术公平性指标无法捕捉到的不对称权力关系。

Conclusion: 解决 ASR 偏差需要的不仅仅是技术干预；它需要承认不同的语音变体是值得技术适应的合法的表达形式。这种哲学上的重新构建为开发尊重语言多样性和说话者自主性的 ASR 系统提供了新的途径。

Abstract: Automatic Speech Recognition (ASR) systems now mediate countless
human-technology interactions, yet research on their fairness implications
remains surprisingly limited. This paper examines ASR bias through a
philosophical lens, arguing that systematic misrecognition of certain speech
varieties constitutes more than a technical limitation -- it represents a form
of disrespect that compounds historical injustices against marginalized
linguistic communities. We distinguish between morally neutral classification
(discriminate1) and harmful discrimination (discriminate2), demonstrating how
ASR systems can inadvertently transform the former into the latter when they
consistently misrecognize non-standard dialects. We identify three unique
ethical dimensions of speech technologies that differentiate ASR bias from
other algorithmic fairness concerns: the temporal burden placed on speakers of
non-standard varieties ("temporal taxation"), the disruption of conversational
flow when systems misrecognize speech, and the fundamental connection between
speech patterns and personal/cultural identity. These factors create asymmetric
power relationships that existing technical fairness metrics fail to capture.
The paper analyzes the tension between linguistic standardization and pluralism
in ASR development, arguing that current approaches often embed and reinforce
problematic language ideologies. We conclude that addressing ASR bias requires
more than technical interventions; it demands recognition of diverse speech
varieties as legitimate forms of expression worthy of technological
accommodation. This philosophical reframing offers new pathways for developing
ASR systems that respect linguistic diversity and speaker autonomy.

</details>


### [34] [Gradient Surgery for Safe LLM Fine-Tuning](https://arxiv.org/abs/2508.07172)
*Biao Yi,Jiahao Li,Baolei Zhang,Lihai Nie,Tong Li,Tiansheng Huang,Zheli Liu*

Main category: cs.CL

TL;DR: SafeGrad通过梯度手术和KL散度对齐损失来提高LLM在微调中的安全性，即使在恶意数据存在的情况下也能保持性能。


<details>
  <summary>Details</summary>
Motivation: 微调即服务引入了一个关键漏洞，即在用户的微调数据集中混合一些恶意示例可能会损害大型语言模型（LLM）的安全性对齐。虽然公认的范例将安全微调定义为平衡用户任务性能与安全对齐的多目标优化问题，但我们发现现有的解决方案对有害比率非常敏感，随着有害比率的增加，防御能力急剧下降。我们诊断出这种失败源于冲突的梯度，其中用户任务更新直接破坏了安全目标。

Method: SafeGrad，一种采用梯度手术的新方法，通过将用户任务梯度投影到对齐梯度的正交平面上，消除用户任务梯度的有害成分，允许模型学习用户的任务，而不会牺牲安全性。为了进一步提高鲁棒性和数据效率，我们采用了一种KL散度对齐损失，该损失学习了良好对齐的基础模型的丰富、分布式的安全配置文件。

Result: SafeGrad在各种LLM和数据集上提供了最先进的防御，即使在高有害比例下也能保持强大的安全性，而不会影响任务保真度。

Conclusion: SafeGrad在各种LLM和数据集上提供了最先进的防御，即使在高有害比例下也能保持强大的安全性，而不会影响任务保真度。

Abstract: Fine-tuning-as-a-Service introduces a critical vulnerability where a few
malicious examples mixed into the user's fine-tuning dataset can compromise the
safety alignment of Large Language Models (LLMs). While a recognized paradigm
frames safe fine-tuning as a multi-objective optimization problem balancing
user task performance with safety alignment, we find existing solutions are
critically sensitive to the harmful ratio, with defenses degrading sharply as
harmful ratio increases. We diagnose that this failure stems from conflicting
gradients, where the user-task update directly undermines the safety objective.
To resolve this, we propose SafeGrad, a novel method that employs gradient
surgery. When a conflict is detected, SafeGrad nullifies the harmful component
of the user-task gradient by projecting it onto the orthogonal plane of the
alignment gradient, allowing the model to learn the user's task without
sacrificing safety. To further enhance robustness and data efficiency, we
employ a KL-divergence alignment loss that learns the rich, distributional
safety profile of the well-aligned foundation model. Extensive experiments show
that SafeGrad provides state-of-the-art defense across various LLMs and
datasets, maintaining robust safety even at high harmful ratios without
compromising task fidelity.

</details>


### [35] [Omni-SafetyBench: A Benchmark for Safety Evaluation of Audio-Visual Large Language Models](https://arxiv.org/abs/2508.07173)
*Leyi Pan,Zheyu Fu,Yunpeng Zhai,Shuchang Tao,Sheng Guan,Shiyu Huang,Lingzhe Zhang,Zhaoyang Liu,Bolin Ding,Felix Henry,Lijie Wen,Aiwei Liu*

Main category: cs.CL

TL;DR: Omni-SafetyBench是一个新的多模态大型语言模型安全评估基准，揭示了现有模型在安全性和跨模态一致性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM基准无法评估OLLM在音视频联合输入或跨模态安全一致性下的安全性能，因此需要专门的基准来弥补这一空白。

Method: 提出了Omni-SafetyBench，这是一个全面的并行基准，用于OLLM安全评估，包含24种模态组合和变体，以及定制的评估指标：基于条件攻击成功率（C-ASR）和拒绝率（C-RR）的安全评分，以及跨模态安全一致性评分（CMSC-score）。

Result: 对6个开源和4个闭源OLLM的评估表明，没有模型在整体安全性和一致性方面表现出色，复杂输入会削弱安全防御，并且在特定模态下存在严重弱点。

Conclusion: 评估结果揭示了当前的多模态大型语言模型在安全性和跨模态一致性方面存在严重漏洞，强调了增强OLLM安全性的迫切需求，并为未来的改进奠定了基础。

Abstract: The rise of Omni-modal Large Language Models (OLLMs), which integrate visual
and auditory processing with text, necessitates robust safety evaluations to
mitigate harmful outputs. However, no dedicated benchmarks currently exist for
OLLMs, and prior benchmarks designed for other LLMs lack the ability to assess
safety performance under audio-visual joint inputs or cross-modal safety
consistency. To fill this gap, we introduce Omni-SafetyBench, the first
comprehensive parallel benchmark for OLLM safety evaluation, featuring 24
modality combinations and variations with 972 samples each, including dedicated
audio-visual harm cases. Considering OLLMs' comprehension challenges with
complex omni-modal inputs and the need for cross-modal consistency evaluation,
we propose tailored metrics: a Safety-score based on conditional Attack Success
Rate (C-ASR) and Refusal Rate (C-RR) to account for comprehension failures, and
a Cross-Modal Safety Consistency Score (CMSC-score) to measure consistency
across modalities. Evaluating 6 open-source and 4 closed-source OLLMs reveals
critical vulnerabilities: (1) no model excels in both overall safety and
consistency, with only 3 models achieving over 0.6 in both metrics and top
performer scoring around 0.8; (2) safety defenses weaken with complex inputs,
especially audio-visual joints; (3) severe weaknesses persist, with some models
scoring as low as 0.14 on specific modalities. Our benchmark and metrics
highlight urgent needs for enhanced OLLM safety, providing a foundation for
future improvements.

</details>


### [36] [Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback](https://arxiv.org/abs/2508.07178)
*Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu*

Main category: cs.CL

TL;DR: 提出PHG-DIF框架，通过去噪虚假兴趣来解决个性化标题生成中的点击噪声问题，并在DT-PENS数据集上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法忽略了整个历史点击流中与个人无关的点击噪声，这可能导致与真正用户偏好不同的标题。

Method: 通过从隐式反馈中去噪虚假兴趣，提出了一个新的个性化标题生成框架PHG-DIF。PHG-DIF首先采用双阶段过滤来有效去除点击流噪声，并通过短暂停留时间和异常点击爆发来识别，然后利用多级时间融合来动态建模用户不断发展和多方面的兴趣，以实现精确的分析。

Result: 通过用户和新闻维度的严格分析，揭示了点击噪声对个性化生成质量的有害影响。发布了一个新的基准数据集DT-PENS，该数据集包含1,000个精心策划的用户的点击行为以及近10,000个带有历史停留时间注释的带注释的个性化标题。PHG-DIF在DT-PENS上实现了SOTA结果。

Conclusion: PHG-DIF显著减轻了点击噪声的负面影响，并显着提高了标题质量，在DT-PENS上实现了最先进的结果。

Abstract: Accurate personalized headline generation hinges on precisely capturing user
interests from historical behaviors. However, existing methods neglect
personalized-irrelevant click noise in entire historical clickstreams, which
may lead to hallucinated headlines that deviate from genuine user preferences.
In this paper, we reveal the detrimental impact of click noise on personalized
generation quality through rigorous analysis in both user and news dimensions.
Based on these insights, we propose a novel Personalized Headline Generation
framework via Denoising Fake Interests from Implicit Feedback (PHG-DIF).
PHG-DIF first employs dual-stage filtering to effectively remove clickstream
noise, identified by short dwell times and abnormal click bursts, and then
leverages multi-level temporal fusion to dynamically model users' evolving and
multi-faceted interests for precise profiling. Moreover, we release DT-PENS, a
new benchmark dataset comprising the click behavior of 1,000 carefully curated
users and nearly 10,000 annotated personalized headlines with historical dwell
time annotations. Extensive experiments demonstrate that PHG-DIF substantially
mitigates the adverse effects of click noise and significantly improves
headline quality, achieving state-of-the-art (SOTA) results on DT-PENS. Our
framework implementation and dataset are available at
https://github.com/liukejin-up/PHG-DIF.

</details>


### [37] [DySK-Attn: A Framework for Efficient, Real-Time Knowledge Updating in Large Language Models via Dynamic Sparse Knowledge Attention](https://arxiv.org/abs/2508.07185)
*Kabir Khan,Priya Sharma,Arjun Mehta,Neha Gupta,Ravi Narayanan*

Main category: cs.CL

TL;DR: DySK-Attn 通过利用稀疏知识注意机制，使 LLM 能够有效地整合来自动态知识图的实时知识，从而在时间敏感型问答任务中优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 存在一个严重的局限性：它们的知识是静态的，并且很快就会过时。重新训练这些大型模型在计算上是令人望而却步的，而现有的知识编辑技术可能很慢并且可能引入无法预料的副作用。为了解决这个问题，我们提出了 DySK-Attn。

Method: DySK-Attn，一个新颖的框架，使 LLM 能够有效地整合来自动态外部来源的实时知识。其核心是一种稀疏知识注意机制，允许 LLM 执行从粗到细粒度的搜索，有效地识别并专注于来自庞大 KG 的一小部分高度相关的事实。

Result: DySK-Attn 显著优于强大的基线，包括标准检索增强生成 (RAG) 和模型编辑技术，在更新知识的事实准确性和计算效率方面都表现出色。

Conclusion: DySK-Attn显著优于强大的基线，包括标准检索增强生成 (RAG) 和模型编辑技术，在更新知识的事实准确性和计算效率方面都表现出色。该框架为构建能够跟上不断变化的世界的 LLM 提供了可扩展且有效的解决方案。

Abstract: Large Language Models (LLMs) suffer from a critical limitation: their
knowledge is static and quickly becomes outdated. Retraining these massive
models is computationally prohibitive, while existing knowledge editing
techniques can be slow and may introduce unforeseen side effects. To address
this, we propose DySK-Attn, a novel framework that enables LLMs to efficiently
integrate real-time knowledge from a dynamic external source. Our approach
synergizes an LLM with a dynamic Knowledge Graph (KG) that can be updated
instantaneously. The core of our framework is a sparse knowledge attention
mechanism, which allows the LLM to perform a coarse-to-fine grained search,
efficiently identifying and focusing on a small, highly relevant subset of
facts from the vast KG. This mechanism avoids the high computational cost of
dense attention over the entire knowledge base and mitigates noise from
irrelevant information. We demonstrate through extensive experiments on
time-sensitive question-answering tasks that DySK-Attn significantly
outperforms strong baselines, including standard Retrieval-Augmented Generation
(RAG) and model editing techniques, in both factual accuracy for updated
knowledge and computational efficiency. Our framework offers a scalable and
effective solution for building LLMs that can stay current with the
ever-changing world.

</details>


### [38] [Adapting LLMs to Time Series Forecasting via Temporal Heterogeneity Modeling and Semantic Alignment](https://arxiv.org/abs/2508.07195)
*Yanru Sun,Emadeldeen Eldele,Zongxia Xie,Yucheng Wang,Wenzhe Niu,Qinghua Hu,Chee Keong Kwoh,Min Wu*

Main category: cs.CL

TL;DR: 提出了一种统一的框架TALON，通过建模时间异质性和强制语义对齐来增强基于llm的预测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(llm)最近在自然语言处理中表现出了令人印象深刻的能力，这归功于它们强大的泛化和序列建模能力。然而，由于两个基本问题，它们在时间序列预测中的直接应用仍然具有挑战性:时间模式的内在异质性以及连续数值信号和离散语言表示之间的模态差距。

Method: 设计了一个异构时间编码器，将多元时间序列分割成结构连贯的片段，从而能够跨不同的时间模式进行局部专家建模。为了弥合模态差距，引入了一个语义对齐模块，该模块将时间特征与llm兼容的表示对齐，从而能够有效地将时间序列集成到基于语言的模型中，而无需在推理期间使用手工制作的提示。

Result: TALON在所有数据集上都取得了优异的性能，平均MSE比最新的state-of-the-art方法提高了11%。

Conclusion: TALON在所有数据集上都取得了优异的性能，平均MSE比最新的state-of-the-art方法提高了11%。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive
capabilities in natural language processing due to their strong generalization
and sequence modeling capabilities. However, their direct application to time
series forecasting remains challenging due to two fundamental issues: the
inherent heterogeneity of temporal patterns and the modality gap between
continuous numerical signals and discrete language representations. In this
work, we propose TALON, a unified framework that enhances LLM-based forecasting
by modeling temporal heterogeneity and enforcing semantic alignment.
Specifically, we design a Heterogeneous Temporal Encoder that partitions
multivariate time series into structurally coherent segments, enabling
localized expert modeling across diverse temporal patterns. To bridge the
modality gap, we introduce a Semantic Alignment Module that aligns temporal
features with LLM-compatible representations, enabling effective integration of
time series into language-based models while eliminating the need for
handcrafted prompts during inference. Extensive experiments on seven real-world
benchmarks demonstrate that TALON achieves superior performance across all
datasets, with average MSE improvements of up to 11\% over recent
state-of-the-art methods. These results underscore the effectiveness of
incorporating both pattern-aware and semantic-aware designs when adapting LLMs
for time series forecasting. The code is available at:
https://github.com/syrGitHub/TALON.

</details>


### [39] [Enhancing Rumor Detection Methods with Propagation Structure Infused Language Model](https://arxiv.org/abs/2508.07209)
*Chaoqun Cui,Siyuan Li,Kunkun Ma,Caiyan Jia*

Main category: cs.CL

TL;DR: 提出PEP持续预训练策略，以将传播结构中的信息注入PLM，从而提升谣言检测性能。


<details>
  <summary>Details</summary>
Motivation: 预训练语⾔模型（PLM）在各种⾃然语⾔处理任务中表现出色，受益于⼤规模预训练和⾃注意力机制捕获远距离依赖关系的能力。然⽽，它们在谣言检测等社交媒体应⽤任务上的表现仍然欠佳。我们将此归因于预训练语料库与社交⽂本之间的不匹配，对唯⼀社交符号的处理不⾜，以及不适合于建模传播结构中隐含的⽤户参与的预训练任务。

Method: 提出了一种名为Post Engagement Prediction (PEP)的持续预训练策略，以将传播结构中的信息注入PLM。利用这些资源和PEP策略，我们训练了一个名为SoLM的Twitter定制PLM。

Result: 在基准数据集上，PEP将基线模型提⾼了1.0-3.7％的准确率，甚至使其在多个数据集上胜过当前最先进的⽅法。仅SoLM在没有⾼级模块的情况下，也取得了具有竞争⼒的结果，突出了该策略在学习判别性帖子交互特征⽅⾯的有效性。

Conclusion: PEP显著提升了谣言检测性能，即使在少样本情况下也是如此。SoLM无需高级模块也能获得有竞争力的结果。

Abstract: Pretrained Language Models (PLMs) have excelled in various Natural Language
Processing tasks, benefiting from large-scale pretraining and self-attention
mechanism's ability to capture long-range dependencies. However, their
performance on social media application tasks like rumor detection remains
suboptimal. We attribute this to mismatches between pretraining corpora and
social texts, inadequate handling of unique social symbols, and pretraining
tasks ill-suited for modeling user engagements implicit in propagation
structures. To address these issues, we propose a continue pretraining strategy
called Post Engagement Prediction (PEP) to infuse information from propagation
structures into PLMs. PEP makes models to predict root, branch, and parent
relations between posts, capturing interactions of stance and sentiment crucial
for rumor detection. We also curate and release large-scale Twitter corpus:
TwitterCorpus (269GB text), and two unlabeled claim conversation datasets with
propagation structures (UTwitter and UWeibo). Utilizing these resources and PEP
strategy, we train a Twitter-tailored PLM called SoLM. Extensive experiments
demonstrate PEP significantly boosts rumor detection performance across
universal and social media PLMs, even in few-shot scenarios. On benchmark
datasets, PEP enhances baseline models by 1.0-3.7\% accuracy, even enabling it
to outperform current state-of-the-art methods on multiple datasets. SoLM
alone, without high-level modules, also achieves competitive results,
highlighting the strategy's effectiveness in learning discriminative post
interaction features.

</details>


### [40] [How Does a Deep Neural Network Look at Lexical Stress?](https://arxiv.org/abs/2508.07229)
*Itai Allouche,Itay Asael,Rotem Rousso,Vered Dassa,Ann Bradlow,Seung-Eun Kim,Matthew Goldrick,Joseph Keshet*

Main category: cs.CL

TL;DR: 本文利用卷积神经网络研究了词汇重音的预测，并使用LRP分析了模型的可解释性，发现重读元音的频谱特性对预测结果有重要影响。


<details>
  <summary>Details</summary>
Motivation: 探究神经网络在语音处理中的决策依据以及如何解读它们，尤其是在词汇重音的背景下。

Method: 使用卷积神经网络(CNN)从双音节词的频谱图表示中预测重音位置，并使用逐层相关性传播(LRP)进行可解释性分析。

Result: 在held-out测试数据上实现了高达92%的准确率。预测结果受到重读音节和非重读音节信息的影响，特别是重读元音的频谱特性。最佳分类器受到重读元音的第一和第二共振峰的强烈影响，并且有一些证据表明其音高和第三共振峰也有贡献。

Conclusion: 深度学习能够从自然发生的语料中获取重音的分布式线索，扩展了基于高度控制刺激的传统语音工作。

Abstract: Despite their success in speech processing, neural networks often operate as
black boxes, prompting the question: what informs their decisions, and how can
we interpret them? This work examines this issue in the context of lexical
stress. A dataset of English disyllabic words was automatically constructed
from read and spontaneous speech. Several Convolutional Neural Network (CNN)
architectures were trained to predict stress position from a spectrographic
representation of disyllabic words lacking minimal stress pairs (e.g., initial
stress WAllet, final stress exTEND), achieving up to 92% accuracy on held-out
test data. Layerwise Relevance Propagation (LRP), a technique for CNN
interpretability analysis, revealed that predictions for held-out minimal pairs
(PROtest vs. proTEST ) were most strongly influenced by information in stressed
versus unstressed syllables, particularly the spectral properties of stressed
vowels. However, the classifiers also attended to information throughout the
word. A feature-specific relevance analysis is proposed, and its results
suggest that our best-performing classifier is strongly influenced by the
stressed vowel's first and second formants, with some evidence that its pitch
and third formant also contribute. These results reveal deep learning's ability
to acquire distributed cues to stress from naturally occurring data, extending
traditional phonetic work based around highly controlled stimuli.

</details>


### [41] [Prompt Tuning for Few-Shot Continual Learning Named Entity Recognition](https://arxiv.org/abs/2508.07248)
*Zhe Ren*

Main category: cs.CL

TL;DR: Addresses the Few-Shot Distillation Dilemma in FS-CLNER using prompt tuning and memory demonstration templates to improve performance and avoid catastrophic forgetting.


<details>
  <summary>Details</summary>
Motivation: Knowledge distillation in Few-Shot CLNER (FS-CLNER) tasks suffers from the Few-Shot Distillation Dilemma due to the scarcity of new-class entities and lack of old-class entity information.

Method: Designed an expandable Anchor words-oriented Prompt Tuning (APT) paradigm and incorporated Memory Demonstration Templates (MDT) into each training instance.

Result: The proposed approach achieves competitive performances on FS-CLNER.

Conclusion: The approach achieves competitive performances on Few-Shot Continual Learning Named Entity Recognition (FS-CLNER).

Abstract: Knowledge distillation has been successfully applied to Continual Learning
Named Entity Recognition (CLNER) tasks, by using a teacher model trained on
old-class data to distill old-class entities present in new-class data as a
form of regularization, thereby avoiding catastrophic forgetting. However, in
Few-Shot CLNER (FS-CLNER) tasks, the scarcity of new-class entities makes it
difficult for the trained model to generalize during inference. More
critically, the lack of old-class entity information hinders the distillation
of old knowledge, causing the model to fall into what we refer to as the
Few-Shot Distillation Dilemma. In this work, we address the above challenges
through a prompt tuning paradigm and memory demonstration template strategy.
Specifically, we designed an expandable Anchor words-oriented Prompt Tuning
(APT) paradigm to bridge the gap between pre-training and fine-tuning, thereby
enhancing performance in few-shot scenarios. Additionally, we incorporated
Memory Demonstration Templates (MDT) into each training instance to provide
replay samples from previous tasks, which not only avoids the Few-Shot
Distillation Dilemma but also promotes in-context learning. Experiments show
that our approach achieves competitive performances on FS-CLNER.

</details>


### [42] [The 2D+ Dynamic Articulatory Model DYNARTmo: Tongue-Palate Contact Area Estimation](https://arxiv.org/abs/2508.07262)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: This paper extends a 2D articulatory model to 3D, improving visualization for speech education and therapy.


<details>
  <summary>Details</summary>
Motivation: This paper describes an extension of the two-dimensional dynamic articulatory model DYNARTmo

Method: integrating an internal three-dimensional representation of the palatal dome to estimate tongue-palate contact areas from midsagittal tongue contours. Two alternative dome geometries - a half-ellipse and a cosine based profile - are implemented to model lateral curvature in the coronal plane.

Result: lateral contact points are analytically computed for each anterior-posterior position, enabling the generation of electropalatography-like visualizations within the 2D+ framework.

Conclusion: The enhanced model supports three synchronized views (sagittal, glottal, and palatal) for static and dynamic (animated) articulation displays, suitable for speech science education and speech therapy.

Abstract: This paper describes an extension of the two-dimensional dynamic articulatory
model DYNARTmo by integrating an internal three-dimensional representation of
the palatal dome to estimate tongue-palate contact areas from midsagittal
tongue contours. Two alternative dome geometries - a half-ellipse and a cosine
based profile - are implemented to model lateral curvature in the coronal
plane. Using these geometries, lateral contact points are analytically computed
for each anterior-posterior position, enabling the generation of
electropalatography-like visualizations within the 2D+ framework. The enhanced
model supports three synchronized views (sagittal, glottal, and palatal) for
static and dynamic (animated) articulation displays, suitable for speech
science education and speech therapy. Future work includes adding a facial
(lip) view and implementing articulatory-to-acoustic synthesis to
quantitatively evaluate model realism.

</details>


### [43] [Incorporating Contextual Paralinguistic Understanding in Large Speech-Language Models](https://arxiv.org/abs/2508.07273)
*Qiongqiong Wang,Hardik B. Sailor,Jeremy H. M. Wong,Tianchi Liu,Shuo Sun,Wenyu Zhang,Muhammad Huzaifah,Nancy Chen,Ai Ti Aw*

Main category: cs.CL

TL;DR: This paper introduces explicit and implicit methods to incorporate paralinguistic information into Speech-LLMs, significantly improving their empathetic reasoning and contextual understanding.


<details>
  <summary>Details</summary>
Motivation: Current Speech-LLMs often lack empathetic reasoning due to the absence of training datasets integrating contextual content and paralinguistic cues.

Method: Two approaches: (1) explicit method providing paralinguistic metadata to the LLM, and (2) implicit method generating novel training question-answer (QA) pairs using emotion annotations and speech transcriptions.

Result: The implicit method boosts performance by 38.41% on a human-annotated QA benchmark, reaching 46.02% when combined with the explicit approach. The LLM judge is validated by demonstrating its correlation with classification metrics.

Conclusion: The proposed approaches, especially the combination of explicit and implicit methods, effectively improve Speech-LLMs' contextual paralinguistic understanding, as validated by LLM-judged performance gains and correlation with classification metrics.

Abstract: Current large speech language models (Speech-LLMs) often exhibit limitations
in empathetic reasoning, primarily due to the absence of training datasets that
integrate both contextual content and paralinguistic cues. In this work, we
propose two approaches to incorporate contextual paralinguistic information
into model training: (1) an explicit method that provides paralinguistic
metadata (e.g., emotion annotations) directly to the LLM, and (2) an implicit
method that automatically generates novel training question-answer (QA) pairs
using both categorical and dimensional emotion annotations alongside speech
transcriptions. Our implicit method boosts performance (LLM-judged) by 38.41%
on a human-annotated QA benchmark, reaching 46.02% when combined with the
explicit approach, showing effectiveness in contextual paralinguistic
understanding. We also validate the LLM judge by demonstrating its correlation
with classification metrics, providing support for its reliability.

</details>


### [44] [MAQuA: Adaptive Question-Asking for Multidimensional Mental Health Screening using Item Response Theory](https://arxiv.org/abs/2508.07279)
*Vasudha Varadarajan,Hui Xu,Rebecca Astrid Boehme,Mariam Marlan Mirstrom,Sverker Sikstrom,H. Andrew Schwartz*

Main category: cs.CL

TL;DR: MAQuA 是一种自适应问题提问框架，用于同时进行多维心理健康筛查，与随机排序相比，它减少了 50-87% 的评估问题数量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 的最新进展为可扩展的交互式心理健康评估提供了新的机会，但 LLM 的过度查询给用户带来负担，并且对于跨诊断症状概况的实际筛查效率低下。

Method: 结合语言响应的多结果建模与项目反应理论 (IRT) 和因素分析

Result: 与随机排序相比，MAQuA 将分数稳定所需的评估问题数量减少了 50-87%（例如，以减少 71% 的问题获得稳定的抑郁评分，以减少 85% 的问题获得饮食失调评分）。

Conclusion: MAQuA 是一种强大而高效的工具，可用于可扩展、细致和交互式的心理健康筛查，从而促进了基于 LLM 的代理集成到现实世界的临床工作流程中。

Abstract: Recent advances in large language models (LLMs) offer new opportunities for
scalable, interactive mental health assessment, but excessive querying by LLMs
burdens users and is inefficient for real-world screening across
transdiagnostic symptom profiles. We introduce MAQuA, an adaptive
question-asking framework for simultaneous, multidimensional mental health
screening. Combining multi-outcome modeling on language responses with item
response theory (IRT) and factor analysis, MAQuA selects the questions with
most informative responses across multiple dimensions at each turn to optimize
diagnostic information, improving accuracy and potentially reducing response
burden. Empirical results on a novel dataset reveal that MAQuA reduces the
number of assessment questions required for score stabilization by 50-87%
compared to random ordering (e.g., achieving stable depression scores with 71%
fewer questions and eating disorder scores with 85% fewer questions). MAQuA
demonstrates robust performance across both internalizing (depression, anxiety)
and externalizing (substance use, eating disorder) domains, with early stopping
strategies further reducing patient time and burden. These findings position
MAQuA as a powerful and efficient tool for scalable, nuanced, and interactive
mental health screening, advancing the integration of LLM-based agents into
real-world clinical workflows.

</details>


### [45] ["Pull or Not to Pull?'': Investigating Moral Biases in Leading Large Language Models Across Ethical Dilemmas](https://arxiv.org/abs/2508.07284)
*Junchen Ding,Penghao Jiang,Zihao Xu,Ziqi Ding,Yichen Zhu,Jiaojiao Jiang,Yuekang Li*

Main category: cs.CL

TL;DR: 本研究对14个领先的LLM进行了全面的实证评估，这些LLM在27个不同的电车难题场景中，由包括功利主义、义务论和利他主义在内的10种道德哲学构成，结果表明，道德提示不仅是一种行为调节器，而且是一种揭示不同提供商潜在对齐哲学的一种诊断工具。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）越来越多地调解具有伦理敏感性的决策，理解其道德推理过程势在必行。

Method: 使用析因提示协议，引发了3,780个二元决策和自然语言理由，从而能够沿着决策自信、解释答案一致性、公共道德对齐和对道德上不相关的线索的敏感性等轴进行分析。

Result: 在利他主义、公平和美德伦理框架中出现了“甜蜜区”，模型在这些框架中实现了高干预率、低解释冲突和与聚合人类判断的最小差异的平衡。然而，模型在强调亲属关系、合法性或自身利益的框架下存在分歧，经常产生伦理上有争议的结果。

Conclusion: 道德提示不仅是一种行为调节器，而且是一种揭示不同提供商潜在对齐哲学的一种诊断工具。我们提倡道德推理成为LLM对齐的主要轴，呼吁建立标准化基准，不仅要评估LLM的决策，还要评估其决策的方式和原因。

Abstract: As large language models (LLMs) increasingly mediate ethically sensitive
decisions, understanding their moral reasoning processes becomes imperative.
This study presents a comprehensive empirical evaluation of 14 leading LLMs,
both reasoning enabled and general purpose, across 27 diverse trolley problem
scenarios, framed by ten moral philosophies, including utilitarianism,
deontology, and altruism. Using a factorial prompting protocol, we elicited
3,780 binary decisions and natural language justifications, enabling analysis
along axes of decisional assertiveness, explanation answer consistency, public
moral alignment, and sensitivity to ethically irrelevant cues. Our findings
reveal significant variability across ethical frames and model types: reasoning
enhanced models demonstrate greater decisiveness and structured justifications,
yet do not always align better with human consensus. Notably, "sweet zones"
emerge in altruistic, fairness, and virtue ethics framings, where models
achieve a balance of high intervention rates, low explanation conflict, and
minimal divergence from aggregated human judgments. However, models diverge
under frames emphasizing kinship, legality, or self interest, often producing
ethically controversial outcomes. These patterns suggest that moral prompting
is not only a behavioral modifier but also a diagnostic tool for uncovering
latent alignment philosophies across providers. We advocate for moral reasoning
to become a primary axis in LLM alignment, calling for standardized benchmarks
that evaluate not just what LLMs decide, but how and why.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [46] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

TL;DR: BIND refines the joint embedding space, powering Med-GRIM, which is designed for medical VQA tasks. Med-GRIM achieves high performance at low computational cost using a modular workflow and prompt-based retrieval. DermaGraph dataset is introduced for zero-shot multimodal medical applications.


<details>
  <summary>Details</summary>
Motivation: Existing ensemble models often fail to produce responses with the detailed precision necessary for complex, domain-specific applications such as medical VQA.

Method: The joint embedding space is refined through dense, query-token-based encodings inspired by contrastive pretraining techniques. Med-GRIM leverages graph-based retrieval and prompt engineering to integrate domain-specific knowledge. It applies a low-compute, modular workflow with small language models (SLMs) for efficiency and employs prompt-based retrieval to dynamically inject relevant knowledge.

Result: The model achieves large language model performance at a fraction of the computational cost. A new dataset, DermaGraph, is introduced.

Conclusion: Med-GRIM achieves large language model performance at a fraction of the computational cost by assigning distinct roles to each agent within the VQA system. Additionally, DermaGraph, a novel Graph-RAG dataset comprising diverse dermatological conditions, is introduced to support scalable research in zero-shot multimodal medical applications.

Abstract: An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [47] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

TL;DR: DiTalker, a DiT-based framework, improves lip sync and speaking style control in portrait animation by decoupling audio and speaking styles, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods overlook dynamic styles like head movements and rely on dual U-Net architectures with high computational cost.

Method: A unified DiT-based framework with a Style-Emotion Encoding Module and an Audio-Style Fusion Module.

Result: Extensive experiments demonstrate the superiority of DiTalker in terms of lip synchronization and speaking style controllability.

Conclusion: DiTalker achieves superior lip synchronization and speaking style controllability.

Abstract: Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [48] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

TL;DR: 该研究开发了一个用于检测 TikTok 上 pro-bigorexia 内容的框架，该框架使用多模态数据并优于仅使用文本的方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台越来越难以检测到宣传肌肉变形行为的有害内容，特别是对青少年男性影响过大的 pro-bigorexia 内容。与专注于“瘦”的传统饮食失调检测不同，pro-bigorexia 材料通过视觉展示、编码语言和动机信息的复杂多模态组合，伪装成合法的健身内容，从而避开了基于文本的检测系统。

Method: 开发了一个名为BigTokDetect的临床信息检测框架，用于识别TikTok上的 pro-bigorexia 内容。构建了BigTok数据集，这是一个由临床心理学家和精神科医生标注的包含2200多个TikTok视频的多模态数据集。

Result: 在主要类别分类上实现了 0.829% 的准确率，在通过领域特定微调的子类别检测上实现了 0.690% 的准确率。多模态融合比纯文本方法提高了 5-10% 的性能，其中视频特征提供了最具区分性的信号。

Conclusion: 该研究建立了多模态有害内容检测的新基准，并为专业心理健康领域的可扩展内容审核提供了计算工具和方法框架。

Abstract: Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [49] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

TL;DR: FPGM 是一种新的增强框架，它利用息肉边缘表现出显着一致的频率特征，通过对未标记图像执行有原则的频谱扰动，对齐其幅度谱与学习到的先验，同时保留相位信息以保持结构完整性，从而显著增强跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法依赖于忽略息肉特异性结构属性的通用增强，导致对新成像中心和设备的泛化能力较差。为了解决这个问题，我们引入了频率先验引导匹配（FPGM）。

Method: Frequency Prior Guided Matching (FPGM)

Result: 在六个公共数据集上验证，FPGM 建立了新的最先进水平，优于十种竞争方法。它展示了卓越的零样本泛化能力，在数据稀缺的情况下，Dice 分数实现了超过 10% 的绝对增益。

Conclusion: FPGM通过显著增强跨域鲁棒性，为在有限监督下临床可部署的息肉分割提供了一个强大的解决方案。

Abstract: Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [50] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

TL;DR: This paper studies the explainability of vision reflection in large multimodal models (LMMs), and finds that vision reflection is a promising strategy for achieving robust and interpretable visual recognition.


<details>
  <summary>Details</summary>
Motivation: This paper presents several novel findings on the explainability of vision reflection in large multimodal models (LMMs).

Method: analyzing the internal behavior of vision reflection

Result: prompting an LMM to verify the prediction of a specialized vision model can improve recognition accuracy, the vision-language connector maps visual features into explicit textual concepts, LMMs may rely primarily on a compact set of distilled textual representations rather than raw vision features, a training-free connector can enhance LMM performance in fine-grained recognition tasks

Conclusion: vision reflection is a promising strategy for achieving robust and interpretable visual recognition

Abstract: This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [51] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

TL;DR: A hybrid 3D CNN and Transformer framework is proposed to address the limitations of each architecture for video-based behavior recognition. The model outperforms traditional methods with higher accuracy and manageable complexity.


<details>
  <summary>Details</summary>
Motivation: Traditional 3D Convolutional Neural Network (3D CNN) effectively capture local spatiotemporal features but struggle with modeling long-range dependencies. Conversely, Transformers excel at learning global contextual information but face challenges with high computational costs.

Method: a hybrid framework combining 3D CNN and Transformer architectures

Result: the proposed model outperforms traditional 3D CNN and standalone Transformers, achieving higher recognition accuracy with manageable complexity. Ablation studies further validate the complementary strengths of the two modules.

Conclusion: This hybrid framework offers an effective and scalable solution for video-based behavior recognition.

Abstract: Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [52] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

TL;DR: RMT-PPAD是一个实时、基于Transformer的多任务模型，用于自动驾驶感知，在精度和速度方面都达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统依赖于需要精度和实时性能的全景驾驶感知。

Method: 提出了RMT-PPAD，一个基于Transformer的实时多任务模型，它联合执行目标检测、可行驶区域分割和车道线分割。引入了一个轻量级模块，一个带有适配器的门控控制，以自适应地融合共享和特定任务的特征，有效地缓解了任务之间的负迁移。设计了一个自适应分割解码器，以在训练阶段自动学习多尺度特征的权重。这避免了为不同的分割任务手动设计特定任务的结构。识别并解决了车道线分割中训练和测试标签之间不一致的问题。

Result: RMT-PPAD在目标检测方面实现了84.9%的mAP50和95.4%的Recall，在可行驶区域分割方面实现了92.6%的mIoU，在车道线分割方面实现了56.8%的IoU和84.7%的准确率。推理速度达到32.6 FPS。

Conclusion: RMT-PPAD在BDD100K数据集上取得了最先进的结果，并在实际场景中表现出稳定的性能。

Abstract: Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [53] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

TL;DR: This paper introduces the HOPE benchmark to address the limitations of POPE in evaluating object hallucination in LVLMs. HOPE uses image-specific information and description-based hallucination searching to generate misleading distractors, leading to a significant precision drop in LVLMs compared to POPE.


<details>
  <summary>Details</summary>
Motivation: LVLMs still suffer from the unavailable object hallucination issue, which tends to generate objects inconsistent with the image content. The POPE benchmark has shown diminishing effectiveness in assessing object hallucination, as it employs a simplistic sampling strategy that overlooks image-specific information and restricts distractors to negative object categories only.

Method: introducing the Hallucination searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate the most misleading distractors that can trigger hallucination in LVLMs

Result: HOPE leads to a precision drop of at least 9% and up to 23% across various state-of-the-art LVLMs, significantly outperforming POPE in exposing hallucination vulnerabilities.

Conclusion: HOPE leads to a precision drop of at least 9% and up to 23% across various state-of-the-art LVLMs, significantly outperforming POPE in exposing hallucination vulnerabilities.

Abstract: Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [54] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

TL;DR: A new dataset for object detection in sparse, non-commercial domains is introduced, and several models are benchmarked on it.


<details>
  <summary>Details</summary>
Motivation: Object detection models are typically trained on datasets like ImageNet, COCO, and PASCAL VOC, which focus on everyday objects. However, these lack signal sparsity found in non-commercial domains.

Method: MobilTelesco, a smartphone-based astrophotography dataset, addresses this by providing sparse night-sky images.

Result: MobilTelesco, a smartphone-based astrophotography dataset

Conclusion: We benchmark several detection models on it, highlighting challenges under feature-deficient conditions.

Abstract: Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [55] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

TL;DR: 提出了一种用于擦除图像中人物的新方法，该方法在复杂场景中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有数据集很少涵盖密集遮挡、伪装背景和多样化的交互；缺乏空间解耦，前景实例无法有效解开，限制了干净的背景恢复。

Method: 多层扩散 (MILD)，一种新颖的策略，可将生成分解为每个实例和背景的语义分离路径。为了加强以人为中心的理解，我们引入了人体形态引导，整合了姿势、解析和空间关系。我们进一步提出了空间调制注意力，以更好地引导注意力流动。

Result: 我们引入了一个高质量的多IP人体擦除数据集，具有不同的姿势变化和复杂的背景。

Conclusion: MILD在具有挑战性的人体擦除基准测试中优于现有技术方法。

Abstract: Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [56] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: estimate scene graph from multi-view RGB images


<details>
  <summary>Details</summary>
Motivation: Modern 3D semantic scene graph estimation methods utilize ground truth 3D annotations to accurately predict target objects, predicates, and relationships. In the absence of given 3D ground truth representations, explore leveraging only multi-view RGB images to tackle this task. To attain robust features for accurate scene graph estimation, must overcome the noisy reconstructed pseudo point-based geometry from predicted depth maps and reduce the amount of background noise present in multi-view image features.

Method: enrich node and edge features with accurate semantic and spatial information and through neighboring relations. obtain semantic masks to guide feature aggregation to filter background features and design a novel method to incorporate neighboring node information to aid robustness of our scene graph estimates. leverage on explicit statistical priors calculated from the training summary statistics to refine node and edge predictions based on their one-hop neighborhood.

Result: outperforms current methods purely using multi-view images as the initial input

Conclusion: The method outperforms current methods purely using multi-view images as the initial input.

Abstract: Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [57] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

TL;DR: NNObfuscator 是一种新的实用程序控制机制，它使 AI 模型能够根据预定义的条件动态地修改其性能。


<details>
  <summary>Details</summary>
Motivation: 训练深度神经网络 (DNN) 已成为一项资源密集型任务，需要大量的标记数据、大量的计算能力和大量的微调工作，才能在各种用例中实现最佳性能。虽然预训练模型提供了一个有用的起点，但使它们适应特定的用户需求通常需要大量的定制和基础设施开销。当单个模型必须支持具有不同性能要求的各种应用程序时，这种挑战会加剧。传统的解决方案通常涉及训练多个模型版本以满足不同的要求，这可能效率低下且难以维护。

Method: 我们提出了 NNObfuscator，这是一种新颖的实用程序控制机制，使 AI 模型能够根据预定义的条件动态地修改其性能。

Result: 实验结果表明，NNObfuscator 成功地使模型更具适应性。

Conclusion: NNObfuscator 成功地使模型更具适应性，因此单个训练模型可以处理范围广泛的任务，而无需进行大量更改。

Abstract: Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [58] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

TL;DR: 本文提出了一个年龄多样化的deepfake数据集，以减少年龄偏差，并在deepfake检测中提高了公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管存在许多检测模型，但deepfake数据集中人口统计学偏差在很大程度上仍未得到解决。本文重点关注通过引入年龄多样化的deepfake数据集来缓解deepfake数据集中特定年龄的偏差，这将提高各个年龄组的公平性。

Method: 通过一个模块化pipeline构建数据集，该pipeline结合了现有的deepfake数据集Celeb-DF、FaceForensics++和UTKFace数据集，并创建合成数据以填补年龄分布的空白。

Result: AUC、pAUC和EER等评估指标表明，在年龄多样化的数据集上训练的模型在不同年龄组中表现出更公平的性能，提高了整体准确性，并在数据集中具有更高的泛化性。

Conclusion: 模型在年龄多样化的数据集上训练，在不同年龄组中表现出更公平的性能，提高了整体准确性，并在数据集中具有更高的泛化性。

Abstract: The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [59] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

TL;DR: Introduces StaticEmbodiedBench for efficient and unified evaluation of embodied intelligence using static scene representations, evaluates VLMs and VLAs, and releases a subset of the benchmark.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks typically rely on interactive simulated environments or real-world setups, which are costly, fragmented, and hard to scale.

Method: The paper introduces StaticEmbodiedBench, a plug-and-play benchmark that enables unified evaluation using static scene representations.

Result: StaticEmbodiedBench covers 42 diverse scenarios and 8 core dimensions, and supports scalable and comprehensive assessment through a simple interface.

Conclusion: The paper establishes the first unified static leaderboard for Embodied intelligence by evaluating 19 VLMs and 11 VLAs, and releases a subset of 200 samples to accelerate development.

Abstract: Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [60] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

TL;DR: StyleTailor, a collaborative agent framework, unifies personalized apparel design, shopping recommendation, virtual try-on, and systematic evaluation.


<details>
  <summary>Details</summary>
Motivation: Solutions for personalized fashion styling remain underexplored but hold immense promise.

Method: a collaborative agent framework with iterative visual refinement driven by multi-level negative feedback

Result: StyleTailor demonstrates superior performance in delivering personalized designs and recommendations.

Conclusion: StyleTailor delivers personalized designs and recommendations, outperforming strong baselines and establishing a new benchmark.

Abstract: The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


### [61] [From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets](https://arxiv.org/abs/2508.06556)
*Sarina Penquitt,Jonathan Klees,Rinor Cakaj,Daniel Kondermann,Matthias Rottmann,Lars Schmarje*

Main category: cs.CV

TL;DR: 提出了一个半自动框架REC$\\checkmark$D，用于修正目标检测数据集中的标签错误。通过众包验证边界框，可以有效提高标签质量，但现有方法仍有很大的改进空间。


<details>
  <summary>Details</summary>
Motivation: 标签错误（定义为缺少标签、不正确的分类或不准确的定位）通常会损害这些数据集的质量。这会对训练和基准评估的结果产生重大影响。尽管现在存在几种用于检测目标检测数据集中标签错误的方法，但它们通常仅在合成基准或有限的手动检查上进行验证。因此，如何系统地且大规模地纠正此类错误仍然是一个悬而未决的问题。

Method: 半自动的label-error修正框架REC$\\$D，将检测器的错误建议与轻量级的众包微任务配对。这些任务使多个注释者能够独立地验证每个候选边界框，并且他们的响应被聚合以估计模糊性并提高标签质量。

Result: 众包审查产生了高质量的修正注释，这表明原始注释中至少有 24% 的缺失和不准确的注释。当前标签错误检测方法与我们的校正框架相结合，可以在人类从头开始注释边界框的时间内恢复数百个错误。即使是最好的方法仍然会遗漏高达 66% 的真实错误，并且低质量的标签会引入比发现的更多的错误。

Conclusion: 众包修正的标注质量很高，表明原始标注中至少有 24% 的缺失和不准确的注释。即使是最好的方法仍然会遗漏高达 66% 的真实错误，并且低质量的标签会引入比发现的更多的错误。这突显了迫切需要进一步研究，现在可以通过我们发布的基准来实现。

Abstract: Object detection has advanced rapidly in recent years, driven by increasingly
large and diverse datasets. However, label errors, defined as missing labels,
incorrect classification or inaccurate localization, often compromise the
quality of these datasets. This can have a significant impact on the outcomes
of training and benchmark evaluations. Although several methods now exist for
detecting label errors in object detection datasets, they are typically
validated only on synthetic benchmarks or limited manual inspection. How to
correct such errors systemically and at scale therefore remains an open
problem. We introduce a semi-automated framework for label-error correction
called REC$\checkmark$D (Rechecked). Building on existing detectors, the
framework pairs their error proposals with lightweight, crowd-sourced
microtasks. These tasks enable multiple annotators to independently verify each
candidate bounding box, and their responses are aggregated to estimate
ambiguity and improve label quality. To demonstrate the effectiveness of
REC$\checkmark$D, we apply it to the class pedestrian in the KITTI dataset. Our
crowdsourced review yields high-quality corrected annotations, which indicate a
rate of at least 24% of missing and inaccurate annotations in original
annotations. This validated set will be released as a new real-world benchmark
for label error detection and correction. We show that current label error
detection methods, when combined with our correction framework, can recover
hundreds of errors in the time it would take a human to annotate bounding boxes
from scratch. However, even the best methods still miss up to 66% of the true
errors and with low quality labels introduce more errors than they find. This
highlights the urgent need for further research, now enabled by our released
benchmark.

</details>


### [62] [On the effectiveness of multimodal privileged knowledge distillation in two vision transformer based diagnostic applications](https://arxiv.org/abs/2508.06558)
*Simon Baur,Alexandra Benova,Emilio Dolgener Cantú,Jackie Ma*

Main category: cs.CV

TL;DR: MMPKD是一种训练策略，它利用仅在训练期间可用的额外模态来指导单模态视觉模型。


<details>
  <summary>Details</summary>
Motivation: 在临床实践中部署深度学习模型通常需要利用多种数据模态，例如图像、文本和结构化数据，以实现稳健和值得信赖的决策。然而，并非所有模态在推理时总是可用的。

Method: 多模态特权知识蒸馏(MMPKD)，一种利用仅在训练期间可用的额外模态来指导单模态视觉模型的训练策略。

Result: 我们使用基于文本的胸部X光片教师模型(MIMIC-CXR)和基于表格元数据的乳房X光片教师模型(CBIS-DDSM)将知识提炼到视觉transformer学生模型中。

Conclusion: MMPKD可以提高注意力图的zero-shot能力，以定位输入图像中的ROI，但这种效果不会跨领域推广。

Abstract: Deploying deep learning models in clinical practice often requires leveraging
multiple data modalities, such as images, text, and structured data, to achieve
robust and trustworthy decisions. However, not all modalities are always
available at inference time. In this work, we propose multimodal privileged
knowledge distillation (MMPKD), a training strategy that utilizes additional
modalities available solely during training to guide a unimodal vision model.
Specifically, we used a text-based teacher model for chest radiographs
(MIMIC-CXR) and a tabular metadata-based teacher model for mammography
(CBIS-DDSM) to distill knowledge into a vision transformer student model. We
show that MMPKD can improve the resulting attention maps' zero-shot
capabilities of localizing ROI in input images, while this effect does not
generalize across domains, as contrarily suggested by prior research.

</details>


### [63] [Grounding Emotion Recognition with Visual Prototypes: VEGA -- Revisiting CLIP in MERC](https://arxiv.org/abs/2508.06564)
*Guanyu Hu,Dimitrios Kollias,Xinyu Yang*

Main category: cs.CV

TL;DR: Proposes VEGA, a visual emotion guided anchoring mechanism using CLIP's image encoder, to improve multimodal emotion recognition.


<details>
  <summary>Details</summary>
Motivation: Multimodal Emotion Recognition in Conversations remains a challenging task due to the complex interplay of textual, acoustic and visual signals. Recent models often lack psychologically meaningful priors to guide multimodal alignment.

Method: Propose a novel Visual Emotion Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics into the fusion and classification process, leverages CLIP's image encoder to construct emotion-specific visual anchors based on facial exemplars, and uses a stochastic anchor sampling strategy.

Result: Achieves state-of-the-art performance on IEMOCAP and MELD.

Conclusion: VEGA-augmented model achieves state-of-the-art performance on IEMOCAP and MELD.

Abstract: Multimodal Emotion Recognition in Conversations remains a challenging task
due to the complex interplay of textual, acoustic and visual signals. While
recent models have improved performance via advanced fusion strategies, they
often lack psychologically meaningful priors to guide multimodal alignment. In
this paper, we revisit the use of CLIP and propose a novel Visual Emotion
Guided Anchoring (VEGA) mechanism that introduces class-level visual semantics
into the fusion and classification process. Distinct from prior work that
primarily utilizes CLIP's textual encoder, our approach leverages its image
encoder to construct emotion-specific visual anchors based on facial exemplars.
These anchors guide unimodal and multimodal features toward a perceptually
grounded and psychologically aligned representation space, drawing inspiration
from cognitive theories (prototypical emotion categories and multisensory
integration). A stochastic anchor sampling strategy further enhances robustness
by balancing semantic stability and intra-class diversity. Integrated into a
dual-branch architecture with self-distillation, our VEGA-augmented model
achieves sota performance on IEMOCAP and MELD. Code is available at:
https://github.com/dkollias/VEGA.

</details>


### [64] [Bridging Brain Connectomes and Clinical Reports for Early Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06565)
*Jing Zhang,Xiaowei Yu,Minheng Chen,Lu Zhang,Tong Chen,Yan Zhuang,Chao Cao,Yanjun Lyu,Li Su,Tianming Liu,Dajiang Zhu*

Main category: cs.CV

TL;DR: 提出了一种新颖的框架，该框架在共享的跨模态潜在空间中对齐大脑连接组与临床报告，从而增强了表征学习。


<details>
  <summary>Details</summary>
Motivation: 将脑成像数据与临床报告相结合，为在实际临床环境中利用互补的多模态信息以实现更有效和及时的诊断提供了宝贵的机会。这种方法在脑部疾病研究中获得了极大的关注，但仍然存在一个关键挑战：如何有效地将客观的成像数据与主观的基于文本的报告（如医生的笔记）联系起来。

Method: 将大脑子网络视为成像数据的tokens，而不是原始图像patches，以便与临床报告中的单词tokens对齐。

Result: 我们的方法不仅实现了最先进的预测性能，而且还识别出具有临床意义的连接组-文本对，为阿尔茨海默病的早期机制提供了新的见解，并支持开发临床上有用的多模态生物标志物。

Conclusion: 该方法不仅实现了最先进的预测性能，而且还识别出具有临床意义的连接组-文本对，为阿尔茨海默病的早期机制提供了新的见解，并支持开发临床上有用的多模态生物标志物。

Abstract: Integrating brain imaging data with clinical reports offers a valuable
opportunity to leverage complementary multimodal information for more effective
and timely diagnosis in practical clinical settings. This approach has gained
significant attention in brain disorder research, yet a key challenge remains:
how to effectively link objective imaging data with subjective text-based
reports, such as doctors' notes. In this work, we propose a novel framework
that aligns brain connectomes with clinical reports in a shared cross-modal
latent space at both the subject and connectome levels, thereby enhancing
representation learning. The key innovation of our approach is that we treat
brain subnetworks as tokens of imaging data, rather than raw image patches, to
align with word tokens in clinical reports. This enables a more efficient
identification of system-level associations between neuroimaging findings and
clinical observations, which is critical since brain disorders often manifest
as network-level abnormalities rather than isolated regional alterations. We
applied our method to mild cognitive impairment (MCI) using the ADNI dataset.
Our approach not only achieves state-of-the-art predictive performance but also
identifies clinically meaningful connectome-text pairs, offering new insights
into the early mechanisms of Alzheimer's disease and supporting the development
of clinically useful multimodal biomarkers.

</details>


### [65] [Surformer v1: Transformer-Based Surface Classification Using Tactile and Vision Features](https://arxiv.org/abs/2508.06566)
*Manish Kansana,Elias Hossain,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

TL;DR: 提出了 Surformer v1，一种用于表面材料识别的 Transformer 架构，它在精度和效率之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 表面材料识别是机器人感知和物理交互的关键组成部分，尤其是在利用触觉和视觉感觉输入时。

Method: 提出了一种基于 Transformer 的架构 Surformer v1，用于使用结构化触觉特征和 PCA 降维的视觉嵌入进行表面分类。

Result: Surformer v1 实现了 99.4% 的准确率，推理时间为 0.77 毫秒，而多模态 CNN 实现了稍高的准确率，但需要明显更长的推理时间。

Conclusion: Surformer v1 在表面材料识别方面实现了精度、效率和计算成本之间的良好平衡。

Abstract: Surface material recognition is a key component in robotic perception and
physical interaction, particularly when leveraging both tactile and visual
sensory inputs. In this work, we propose Surformer v1, a transformer-based
architecture designed for surface classification using structured tactile
features and PCA-reduced visual embeddings extracted via ResNet-50. The model
integrates modality-specific encoders with cross-modal attention layers,
enabling rich interactions between vision and touch. Currently,
state-of-the-art deep learning models for vision tasks have achieved remarkable
performance. With this in mind, our first set of experiments focused
exclusively on tactile-only surface classification. Using feature engineering,
we trained and evaluated multiple machine learning models, assessing their
accuracy and inference time. We then implemented an encoder-only Transformer
model tailored for tactile features. This model not only achieved the highest
accuracy but also demonstrated significantly faster inference time compared to
other evaluated models, highlighting its potential for real-time applications.
To extend this investigation, we introduced a multimodal fusion setup by
combining vision and tactile inputs. We trained both Surformer v1 (using
structured features) and Multimodal CNN (using raw images) to examine the
impact of feature-based versus image-based multimodal learning on
classification accuracy and computational efficiency. The results showed that
Surformer v1 achieved 99.4% accuracy with an inference time of 0.77 ms, while
the Multimodal CNN achieved slightly higher accuracy but required significantly
more inference time. These findings suggest Surformer v1 offers a compelling
balance between accuracy, efficiency, and computational cost for surface
material recognition.

</details>


### [66] [ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos](https://arxiv.org/abs/2508.06570)
*Mohammad Zia Ur Rehman,Anukriti Bhatnagar,Omkar Kabde,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: A new video dataset, ImpliHateVid, is introduced for implicit hate speech detection. A two-stage contrastive learning framework is proposed and shown to be effective for hate speech detection in videos.


<details>
  <summary>Details</summary>
Motivation: Video-based hate speech detection remains underexplored.

Method: A novel two-stage contrastive learning framework is proposed for hate speech detection in videos. Modality-specific encoders and cross-encoders are trained using contrastive loss. Sentiment, emotion, and caption-based features are incorporated.

Result: The proposed method is evaluated on ImpliHateVid and HateMM datasets, demonstrating its effectiveness.

Conclusion: The proposed multimodal contrastive learning method is effective for hateful content detection in videos. The introduced ImpliHateVid dataset is significant for implicit hate speech detection.

Abstract: The existing research has primarily focused on text and image-based hate
speech detection, video-based approaches remain underexplored. In this work, we
introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate
speech detection in videos. ImpliHateVid consists of 2,009 videos comprising
509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos,
making it one of the first large-scale video datasets dedicated to implicit
hate detection. We also propose a novel two-stage contrastive learning
framework for hate speech detection in videos. In the first stage, we train
modality-specific encoders for audio, text, and image using contrastive loss by
concatenating features from the three encoders. In the second stage, we train
cross-encoders using contrastive learning to refine multimodal representations.
Additionally, we incorporate sentiment, emotion, and caption-based features to
enhance implicit hate detection. We evaluate our method on two datasets,
ImpliHateVid for implicit hate speech detection and another dataset for general
hate speech detection in videos, HateMM dataset, demonstrating the
effectiveness of the proposed multimodal contrastive learning for hateful
content detection in videos and the significance of our dataset.

</details>


### [67] [ContextGuard-LVLM: Enhancing News Veracity through Fine-grained Cross-modal Contextual Consistency Verification](https://arxiv.org/abs/2508.06623)
*Sihan Ma,Qiming Wu,Ruotong Jiang,Frank Burns*

Main category: cs.CV

TL;DR: ContextGuard-LVLM是一个用于验证视觉和文本信息一致性的新框架，它优于现有模型，并在复杂逻辑推理和细微的上下文理解方面表现出显著的改进。


<details>
  <summary>Details</summary>
Motivation: 数字新闻媒体的普及需要强大的方法来验证内容真实性，尤其是在视觉和文本信息之间的一致性方面。传统方法通常在解决细粒度跨模态上下文一致性（FCCC）问题上有所不足，该问题包括视觉叙事、情感基调和背景信息与文本的更深层次的对齐，而不仅仅是实体匹配。

Method: ContextGuard-LVLM，一个基于先进的视觉-语言大型模型（LVLM）并集成了一个多阶段上下文推理机制的新框架。

Result: ContextGuard-LVLM在几乎所有细粒度一致性任务上始终优于最先进的零样本LVLM基线（InstructBLIP和LLaVA 1.5），并在复杂逻辑推理和细微的上下文理解方面表现出显著的改进。该模型对细微扰动的鲁棒性更强，并且在具有挑战性的样本上与人类专家判断具有更高的一致性。

Conclusion: ContextGuard-LVLM在细粒度一致性任务上优于现有模型，并在复杂逻辑推理和细微的上下文理解方面表现出显著的改进。

Abstract: The proliferation of digital news media necessitates robust methods for
verifying content veracity, particularly regarding the consistency between
visual and textual information. Traditional approaches often fall short in
addressing the fine-grained cross-modal contextual consistency (FCCC) problem,
which encompasses deeper alignment of visual narrative, emotional tone, and
background information with text, beyond mere entity matching. To address this,
we propose ContextGuard-LVLM, a novel framework built upon advanced
Vision-Language Large Models (LVLMs) and integrating a multi-stage contextual
reasoning mechanism. Our model is uniquely enhanced through reinforced or
adversarial learning paradigms, enabling it to detect subtle contextual
misalignments that evade zero-shot baselines. We extend and augment three
established datasets (TamperedNews-Ent, News400-Ent, MMG-Ent) with new
fine-grained contextual annotations, including "contextual sentiment," "visual
narrative theme," and "scene-event logical coherence," and introduce a
comprehensive CTXT (Contextual Coherence) entity type. Extensive experiments
demonstrate that ContextGuard-LVLM consistently outperforms state-of-the-art
zero-shot LVLM baselines (InstructBLIP and LLaVA 1.5) across nearly all
fine-grained consistency tasks, showing significant improvements in complex
logical reasoning and nuanced contextual understanding. Furthermore, our model
exhibits superior robustness to subtle perturbations and a higher agreement
rate with human expert judgments on challenging samples, affirming its efficacy
in discerning sophisticated forms of context detachment.

</details>


### [68] [VL-MedGuide: A Visual-Linguistic Large Model for Intelligent and Explainable Skin Disease Auxiliary Diagnosis](https://arxiv.org/abs/2508.06624)
*Kexin Yu,Zihan Xu,Jialei Xie,Carter Adams*

Main category: cs.CV

TL;DR: VL-MedGuide利用视觉语言大模型进行皮肤病诊断，实现了最先进的性能和可解释的诊断结果。


<details>
  <summary>Details</summary>
Motivation: 由于皮肤镜图像中存在复杂多样的视觉特征，以及现有的纯视觉诊断模型缺乏可解释性，因此准确诊断皮肤疾病仍然是一个重大挑战。

Method: VL-MedGuide：一种利用视觉语言大模型的多模态理解和推理能力的新框架，用于皮肤状况的智能和固有可解释的辅助诊断。

Result: VL-MedGuide在疾病诊断（83.55% BACC，80.12% F1）和概念检测（76.10% BACC，67.45% F1）方面均达到了最先进的性能。

Conclusion: VL-MedGuide在皮肤病诊断和概念检测方面取得了最先进的性能，并且其生成的解释具有高度的清晰度、完整性和可信度。

Abstract: Accurate diagnosis of skin diseases remains a significant challenge due to
the complex and diverse visual features present in dermatoscopic images, often
compounded by a lack of interpretability in existing purely visual diagnostic
models. To address these limitations, this study introduces VL-MedGuide
(Visual-Linguistic Medical Guide), a novel framework leveraging the powerful
multi-modal understanding and reasoning capabilities of Visual-Language Large
Models (LVLMs) for intelligent and inherently interpretable auxiliary diagnosis
of skin conditions. VL-MedGuide operates in two interconnected stages: a
Multi-modal Concept Perception Module, which identifies and linguistically
describes dermatologically relevant visual features through sophisticated
prompt engineering, and an Explainable Disease Reasoning Module, which
integrates these concepts with raw visual information via Chain-of-Thought
prompting to provide precise disease diagnoses alongside transparent
rationales. Comprehensive experiments on the Derm7pt dataset demonstrate that
VL-MedGuide achieves state-of-the-art performance in both disease diagnosis
(83.55% BACC, 80.12% F1) and concept detection (76.10% BACC, 67.45% F1),
surpassing existing baselines. Furthermore, human evaluations confirm the high
clarity, completeness, and trustworthiness of its generated explanations,
bridging the gap between AI performance and clinical utility by offering
actionable, explainable insights for dermatological practice.

</details>


### [69] [CycleDiff: Cycle Diffusion Models for Unpaired Image-to-image Translation](https://arxiv.org/abs/2508.06625)
*Shilong Zou,Yuhang Huang,Renjiao Yi,Chenyang Zhu,Kai Xu*

Main category: cs.CV

TL;DR: 提出了一种基于扩散的跨域图像翻译器，在没有配对训练数据的情况下，通过联合学习框架对齐扩散和翻译过程，实现了全局优化和性能提升。


<details>
  <summary>Details</summary>
Motivation: 将翻译过程整合到扩散过程中仍然具有挑战性，因为这两个过程没有完全对齐，即，扩散过程应用于噪声信号，而翻译过程是在干净信号上进行的。因此，最近的基于扩散的研究采用单独的训练或浅层集成来学习这两个过程，但这可能导致翻译优化的局部最小值，从而限制了扩散模型的有效性。

Method: 提出了一种新颖的联合学习框架，该框架对齐了扩散和翻译过程，从而提高了全局最优性。具体来说，我们建议使用扩散模型提取图像分量以表示干净的信号，并使用图像分量进行翻译过程，从而实现端到端的联合学习方式。另一方面，我们引入了一个时间相关的翻译网络来学习复杂的翻译映射，从而实现有效的翻译学习和显着的性能改进。

Result: 在RGB$\\\leftrightarrow$RGB和各种跨模态翻译任务（包括RGB$\\\leftrightarrow$Edge，RGB$\\\leftrightarrow$Semantics和RGB$\\\leftrightarrow$Depth）上进行了大量实验，展示了比现有技术更好的生成性能。

Conclusion: 该方法通过联合学习实现了全局优化，增强了最优性，并实现了改进的保真度和结构一致性。在RGB$\leftrightarrow$RGB和各种跨模态翻译任务（包括RGB$\\\leftrightarrow$Edge，RGB$\\\leftrightarrow$Semantics和RGB$\\\leftrightarrow$Depth）上进行了大量实验，展示了比现有技术更好的生成性能。

Abstract: We introduce a diffusion-based cross-domain image translator in the absence
of paired training data. Unlike GAN-based methods, our approach integrates
diffusion models to learn the image translation process, allowing for more
coverable modeling of the data distribution and performance improvement of the
cross-domain translation. However, incorporating the translation process within
the diffusion process is still challenging since the two processes are not
aligned exactly, i.e., the diffusion process is applied to the noisy signal
while the translation process is conducted on the clean signal. As a result,
recent diffusion-based studies employ separate training or shallow integration
to learn the two processes, yet this may cause the local minimal of the
translation optimization, constraining the effectiveness of diffusion models.
To address the problem, we propose a novel joint learning framework that aligns
the diffusion and the translation process, thereby improving the global
optimality. Specifically, we propose to extract the image components with
diffusion models to represent the clean signal and employ the translation
process with the image components, enabling an end-to-end joint learning
manner. On the other hand, we introduce a time-dependent translation network to
learn the complex translation mapping, resulting in effective translation
learning and significant performance improvement. Benefiting from the design of
joint learning, our method enables global optimization of both processes,
enhancing the optimality and achieving improved fidelity and structural
consistency. We have conducted extensive experiments on RGB$\leftrightarrow$RGB
and diverse cross-modality translation tasks including
RGB$\leftrightarrow$Edge, RGB$\leftrightarrow$Semantics and
RGB$\leftrightarrow$Depth, showcasing better generative performances than the
state of the arts.

</details>


### [70] [CoDe-NeRF: Neural Rendering via Dynamic Coefficient Decomposition](https://arxiv.org/abs/2508.06632)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Tiancheng Zhao,Gaolei Li,Changting Lin,Yike Guo,Meng Han*

Main category: cs.CV

TL;DR: This paper introduces a dynamic coefficient decomposition framework for NeRF that improves the rendering of specular reflections and highlights by decomposing appearance into static material properties and dynamic view/illumination-dependent coefficients.


<details>
  <summary>Details</summary>
Motivation: Existing NeRF approaches struggle with rendering scenes with complex specular reflections and highlights, producing blurry reflections or encountering optimization instability.

Method: A neural rendering framework based on dynamic coefficient decomposition is proposed, which decomposes complex appearance into a shared, static neural basis and a set of dynamic coefficients generated by a Coefficient Network conditioned on view and illumination. A Dynamic Radiance Integrator combines these components.

Result: Experimental results on challenging benchmarks show that the proposed method produces sharper and more realistic specular highlights compared to existing techniques.

Conclusion: The proposed dynamic coefficient decomposition framework improves the modeling of view-dependent appearance, producing sharper and more realistic specular highlights.

Abstract: Neural Radiance Fields (NeRF) have shown impressive performance in novel view
synthesis, but challenges remain in rendering scenes with complex specular
reflections and highlights. Existing approaches may produce blurry reflections
due to entanglement between lighting and material properties, or encounter
optimization instability when relying on physically-based inverse rendering. In
this work, we present a neural rendering framework based on dynamic coefficient
decomposition, aiming to improve the modeling of view-dependent appearance. Our
approach decomposes complex appearance into a shared, static neural basis that
encodes intrinsic material properties, and a set of dynamic coefficients
generated by a Coefficient Network conditioned on view and illumination. A
Dynamic Radiance Integrator then combines these components to synthesize the
final radiance. Experimental results on several challenging benchmarks suggest
that our method can produce sharper and more realistic specular highlights
compared to existing techniques. We hope that this decomposition paradigm can
provide a flexible and effective direction for modeling complex appearance in
neural scene representations.

</details>


### [71] [Rethinking Key-frame-based Micro-expression Recognition: A Robust and Accurate Framework Against Key-frame Errors](https://arxiv.org/abs/2508.06640)
*Zheyuan Zhang,Weihao Tang,Hong Chen*

Main category: cs.CV

TL;DR: CausalNet通过CMPLM和CAB实现了鲁棒且准确的微表情识别，即使在关键帧索引存在噪声的情况下也能表现良好，并在标准基准测试中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了获得准确关键帧索引的难度和关键帧索引误差的客观存在，这阻碍了它们向实际应用发展。

Method: CausalNet框架，包括Causal Motion Position Learning Module (CMPLM) 和 Causal Attention Block (CAB)

Result: 在流行的ME基准测试中，CausalNet在不同程度的关键帧索引噪声下实现了鲁棒的MER。同时，在使用提供的带注释的关键帧时，它在多个标准MER基准测试中超越了最先进的方法。

Conclusion: CausalNet在不同程度的关键帧索引噪声下实现了鲁棒的微表情识别，并在使用提供的带注释的关键帧时，在多个标准MER基准测试中超越了最先进的方法。

Abstract: Micro-expression recognition (MER) is a highly challenging task in affective
computing. With the reduced-sized micro-expression (ME) input that contains key
information based on key-frame indexes, key-frame-based methods have
significantly improved the performance of MER. However, most of these methods
focus on improving the performance with relatively accurate key-frame indexes,
while ignoring the difficulty of obtaining accurate key-frame indexes and the
objective existence of key-frame index errors, which impedes them from moving
towards practical applications. In this paper, we propose CausalNet, a novel
framework to achieve robust MER facing key-frame index errors while maintaining
accurate recognition. To enhance robustness, CausalNet takes the representation
of the entire ME sequence as the input. To address the information redundancy
brought by the complete ME range input and maintain accurate recognition,
first, the Causal Motion Position Learning Module (CMPLM) is proposed to help
the model locate the muscle movement areas related to Action Units (AUs),
thereby reducing the attention to other redundant areas. Second, the Causal
Attention Block (CAB) is proposed to deeply learn the causal relationships
between the muscle contraction and relaxation movements in MEs. Empirical
experiments have demonstrated that on popular ME benchmarks, the CausalNet has
achieved robust MER under different levels of key-frame index noise. Meanwhile,
it has surpassed state-of-the-art (SOTA) methods on several standard MER
benchmarks when using the provided annotated key-frames. Code is available at
https://github.com/tony19980810/CausalNet.

</details>


### [72] [Towards Robust Red-Green Watermarking for Autoregressive Image Generators](https://arxiv.org/abs/2508.06656)
*Denis Lukovnikov,Andreas Müller,Erwin Quiring,Asja Fischer*

Main category: cs.CV

TL;DR: This paper explores in-generation watermarking for autoregressive image models, proposes cluster-level watermarking methods to improve robustness against perturbations and regeneration attacks, and achieves fast verification runtime.


<details>
  <summary>Details</summary>
Motivation: The use of in-generation watermarks in autoregressive (AR) image models has not been explored yet. AR models generate images by autoregressively predicting a sequence of visual tokens that are then decoded into pixels using a vector-quantized decoder. Inspired by red-green watermarks for large language models, the paper examines token-level watermarking schemes that bias the next-token prediction based on prior tokens.

Method: Two novel watermarking methods that rely on visual token clustering to assign similar tokens to the same set. Firstly, a training-free approach that relies on a cluster lookup table, and secondly, finetuning VAE encoders to predict token clusters directly from perturbed images.

Result: A direct transfer of red-green watermarking schemes works in principle, but the detectability of the watermarks decreases considerably under common image perturbations.

Conclusion: Cluster-level watermarks improve robustness against perturbations and regeneration attacks while preserving image quality. Cluster classification further boosts watermark detectability, outperforming a set of baselines. Moreover, the methods offer fast verification runtime, comparable to lightweight post-hoc watermarking methods.

Abstract: In-generation watermarking for detecting and attributing generated content
has recently been explored for latent diffusion models (LDMs), demonstrating
high robustness. However, the use of in-generation watermarks in autoregressive
(AR) image models has not been explored yet. AR models generate images by
autoregressively predicting a sequence of visual tokens that are then decoded
into pixels using a vector-quantized decoder. Inspired by red-green watermarks
for large language models, we examine token-level watermarking schemes that
bias the next-token prediction based on prior tokens. We find that a direct
transfer of these schemes works in principle, but the detectability of the
watermarks decreases considerably under common image perturbations. As a
remedy, we propose two novel watermarking methods that rely on visual token
clustering to assign similar tokens to the same set. Firstly, we investigate a
training-free approach that relies on a cluster lookup table, and secondly, we
finetune VAE encoders to predict token clusters directly from perturbed images.
Overall, our experiments show that cluster-level watermarks improve robustness
against perturbations and regeneration attacks while preserving image quality.
Cluster classification further boosts watermark detectability, outperforming a
set of baselines. Moreover, our methods offer fast verification runtime,
comparable to lightweight post-hoc watermarking methods.

</details>


### [73] [Learning More by Seeing Less: Line Drawing Pretraining for Efficient, Transferable, and Human-Aligned Vision](https://arxiv.org/abs/2508.06696)
*Tianqin Li,George Liu,Tai Sing Lee*

Main category: cs.CV

TL;DR: 本文提出使用线条画作为预训练方式，以获得更紧凑和泛化性更强的视觉表征，从而提高视觉系统的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代识别系统依赖于丰富的、冗余的视觉输入，而人类可以毫不费力地理解稀疏的、最小的表征，如线条画，这表明结构而非外观是高效视觉理解的基础。

Method: 使用线条画作为结构优先的预训练方式，以诱导更紧凑和更具泛化性的视觉表征；提出了一种名为“learning to draw”的无监督方法，将线条画预训练扩展到无监督设置。

Result: 在分类、检测和分割任务中，在线条画上预训练的模型具有更强的形状偏好、更集中的注意力和更高的数据效率；这些模型还表现出更低的内在维度；从线条预训练教师模型中提炼出的学生模型始终优于从颜色监督教师模型中训练出的学生模型。

Conclusion: 结构优先的视觉学习可以提高效率、泛化能力和与人类对齐的归纳偏见，为构建更强大和适应性更强的视觉系统提供了一个简单而强大的策略。

Abstract: Despite remarkable progress in computer vision, modern recognition systems
remain limited by their dependence on rich, redundant visual inputs. In
contrast, humans can effortlessly understand sparse, minimal representations
like line drawings - suggesting that structure, rather than appearance,
underlies efficient visual understanding. In this work, we propose using line
drawings as a structure-first pretraining modality to induce more compact and
generalizable visual representations. We show that models pretrained on line
drawings develop stronger shape bias, more focused attention, and greater data
efficiency across classification, detection, and segmentation tasks. Notably,
these models also exhibit lower intrinsic dimensionality, requiring
significantly fewer principal components to capture representational variance -
echoing the similar observation in low dimensional efficient representation in
the brain. Beyond performance improvements, line drawing pretraining produces
more compressible representations, enabling better distillation into
lightweight student models. Students distilled from line-pretrained teachers
consistently outperform those trained from color-supervised teachers,
highlighting the benefits of structurally compact knowledge. Finally, we
demonstrate that the pretraining with line-drawing can also be extended to
unsupervised setting via our proposed method "learning to draw". Together, our
results support the view that structure-first visual learning fosters
efficiency, generalization, and human-aligned inductive biases - offering a
simple yet powerful strategy for building more robust and adaptable vision
systems.

</details>


### [74] [MMFformer: Multimodal Fusion Transformer Network for Depression Detection](https://arxiv.org/abs/2508.06701)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Hamdi Altaheri,Lobna Nassar,Fakhri Karray*

Main category: cs.CV

TL;DR: MMFformer, a multimodal depression detection network, is introduced to retrieve depressive spatio-temporal high-level patterns from multimodal social media information. It surpasses existing state-of-the-art approaches on two large-scale depression detection datasets.


<details>
  <summary>Details</summary>
Motivation: Early detection of depression is crucial. Detecting depression is often difficult, as it is based primarily on subjective evaluations. The early diagnosis of depression, thanks to the content of social networks, has become a prominent research area. The extensive and diverse nature of user-generated information poses a significant challenge, limiting the accurate extraction of relevant temporal information and the effective fusion of data across multiple modalities.

Method: This paper introduces MMFformer, a multimodal depression detection network. The transformer network with residual connections captures spatial features from videos, and a transformer encoder is exploited to design important temporal dynamics in audio. Moreover, the fusion architecture fused the extracted features through late and intermediate fusion strategies.

Result: The results clearly reveal that it surpasses existing state-of-the-art approaches, improving the F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset.

Conclusion: The proposed MMFformer network surpasses existing state-of-the-art approaches on two large-scale depression detection datasets, improving the F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset.

Abstract: Depression is a serious mental health illness that significantly affects an
individual's well-being and quality of life, making early detection crucial for
adequate care and treatment. Detecting depression is often difficult, as it is
based primarily on subjective evaluations during clinical interviews. Hence,
the early diagnosis of depression, thanks to the content of social networks,
has become a prominent research area. The extensive and diverse nature of
user-generated information poses a significant challenge, limiting the accurate
extraction of relevant temporal information and the effective fusion of data
across multiple modalities. This paper introduces MMFformer, a multimodal
depression detection network designed to retrieve depressive spatio-temporal
high-level patterns from multimodal social media information. The transformer
network with residual connections captures spatial features from videos, and a
transformer encoder is exploited to design important temporal dynamics in
audio. Moreover, the fusion architecture fused the extracted features through
late and intermediate fusion strategies to find out the most relevant
intermodal correlations among them. Finally, the proposed network is assessed
on two large-scale depression detection datasets, and the results clearly
reveal that it surpasses existing state-of-the-art approaches, improving the
F1-Score by 13.92% for D-Vlog dataset and 7.74% for LMVD dataset. The code is
made available publicly at
https://github.com/rezwanh001/Large-Scale-Multimodal-Depression-Detection.

</details>


### [75] [Fourier Optics and Deep Learning Methods for Fast 3D Reconstruction in Digital Holography](https://arxiv.org/abs/2508.06703)
*Justin London*

Main category: cs.CV

TL;DR: This paper proposes an efficient pipeline framework to synthesize CGH using initial point cloud and MRI data. Performance metrics are improved by using 2D median filtering to remove artifacts and speckled noise during optimization.


<details>
  <summary>Details</summary>
Motivation: Computer-generated holography (CGH) is a promising method that modulates user-defined waveforms with digital holograms.

Method: An efficient and fast pipeline framework is proposed to synthesize CGH using initial point cloud and MRI data. This input data is reconstructed into volumetric objects that are then input into non-convex Fourier optics optimization algorithms for phase-only hologram (POH) and complex-hologram (CH) generation using alternating projection, SGD, and quasi-Netwton methods.

Result: Comparison of reconstruction performance of these algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet deep learning CGH.

Conclusion: Performance metrics are improved by using 2D median filtering to remove artifacts and speckled noise during optimization.

Abstract: Computer-generated holography (CGH) is a promising method that modulates
user-defined waveforms with digital holograms. An efficient and fast pipeline
framework is proposed to synthesize CGH using initial point cloud and MRI data.
This input data is reconstructed into volumetric objects that are then input
into non-convex Fourier optics optimization algorithms for phase-only hologram
(POH) and complex-hologram (CH) generation using alternating projection, SGD,
and quasi-Netwton methods. Comparison of reconstruction performance of these
algorithms as measured by MSE, RMSE, and PSNR is analyzed as well as to HoloNet
deep learning CGH. Performance metrics are shown to be improved by using 2D
median filtering to remove artifacts and speckled noise during optimization.

</details>


### [76] [Restage4D: Reanimating Deformable 3D Reconstruction from a Single Video](https://arxiv.org/abs/2508.06715)
*Jixuan He,Chieh Hubert Lin,Lu Qi,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: Restage4D reanimates deformable 3D scenes from a single video, using the original sequence as a supervisory signal to correct artifacts from synthetic motion, demonstrating improved geometry consistency and motion quality.


<details>
  <summary>Details</summary>
Motivation: Creating deformable 3D content has gained increasing attention, but existing text-to-image and image-to-video generative models struggle to capture the physical realism and motion dynamics needed for authentic 4D scene synthesis. Real-world videos can provide physically grounded geometry and articulation cues that are difficult to hallucinate.

Method: A geometry-preserving pipeline for video-conditioned 4D restaging using a video-rewinding training strategy to temporally bridge a real base video and a synthetic driving video via a shared motion representation. It incorporates an occlusion-aware rigidity loss and a disocclusion backtracing mechanism.

Result: Improved geometry consistency, motion quality, and 3D tracking performance on DAVIS and PointOdyssey.

Conclusion: The method preserves deformable structure under novel motion and corrects errors introduced by generative models, revealing the potential of video prior in 4D restaging task.

Abstract: Creating deformable 3D content has gained increasing attention with the rise
of text-to-image and image-to-video generative models. While these models
provide rich semantic priors for appearance, they struggle to capture the
physical realism and motion dynamics needed for authentic 4D scene synthesis.
In contrast, real-world videos can provide physically grounded geometry and
articulation cues that are difficult to hallucinate. One question is raised:
\textit{Can we generate physically consistent 4D content by leveraging the
motion priors of the real-world video}? In this work, we explore the task of
reanimating deformable 3D scenes from a single video, using the original
sequence as a supervisory signal to correct artifacts from synthetic motion. We
introduce \textbf{Restage4D}, a geometry-preserving pipeline for
video-conditioned 4D restaging. Our approach uses a video-rewinding training
strategy to temporally bridge a real base video and a synthetic driving video
via a shared motion representation. We further incorporate an occlusion-aware
rigidity loss and a disocclusion backtracing mechanism to improve structural
and geometry consistency under challenging motion. We validate Restage4D on
DAVIS and PointOdyssey, demonstrating improved geometry consistency, motion
quality, and 3D tracking performance. Our method not only preserves deformable
structure under novel motion, but also automatically corrects errors introduced
by generative models, revealing the potential of video prior in 4D restaging
task. Source code and trained models will be released.

</details>


### [77] [FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI](https://arxiv.org/abs/2508.06756)
*Somayeh Farahani,Marjaneh Hejazi,Antonio Di Ieva,Sidong Liu*

Main category: cs.CV

TL;DR: FoundBioNet 使用 SWIN-UNETR 架构，通过 TAFE 和 CMD 模块，从 MRI 图像中非侵入性地预测 IDH 突变状态，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 准确、无创地检测异柠檬酸脱氢酶 (IDH) 突变对于有效的神经胶质瘤管理至关重要。传统方法依赖于侵入性组织采样，这可能无法捕获肿瘤的空间异质性。虽然深度学习模型在分子分析中显示出前景，但它们的性能通常受到稀缺的注释数据限制。相比之下，基础深度学习模型为神经胶质瘤成像生物标志物提供了一种更具通用性的方法。

Method: 利用基于 SWIN-UNETR 的架构的基于 Foundation 的生物标志物网络 (FoundBioNet)，以非侵入性方式从多参数 MRI 预测 IDH 突变状态。纳入了两个关键模块：用于提取多尺度、以肿瘤为中心的特征的肿瘤感知特征编码 (TAFE)；以及用于突出与 IDH 突变相关的细微 T2-FLAIR 不匹配信号的跨模态差异 (CMD)。

Result: 该模型在来自 EGD、TCGA、Ivy GAP、RHUH 和 UPenn 的独立测试集上实现了 90.58%、88.08%、65.41% 和 80.31% 的 AUC，始终优于基线方法 (p <= 0.05)。消融研究证实，TAFE 和 CMD 模块对于提高预测准确性至关重要。

Conclusion: 集成了大规模预训练和特定任务微调，FoundBioNet 能够实现可推广的神经胶质瘤表征。这种方法提高了诊断准确性和可解释性，并有可能实现更加个性化的患者护理。

Abstract: Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is
essential for effective glioma management. Traditional methods rely on invasive
tissue sampling, which may fail to capture a tumor's spatial heterogeneity.
While deep learning models have shown promise in molecular profiling, their
performance is often limited by scarce annotated data. In contrast, foundation
deep learning models offer a more generalizable approach for glioma imaging
biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that
utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation
status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware
Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and
Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch
signals associated with IDH mutation. The model was trained and validated on a
diverse, multi-center cohort of 1705 glioma patients from six public datasets.
Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent
test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming
baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE
and CMD modules are essential for improving predictive accuracy. By integrating
large-scale pretraining and task-specific fine-tuning, FoundBioNet enables
generalizable glioma characterization. This approach enhances diagnostic
accuracy and interpretability, with the potential to enable more personalized
patient care.

</details>


### [78] [VOccl3D: A Video Benchmark Dataset for 3D Human Pose and Shape Estimation under real Occlusions](https://arxiv.org/abs/2508.06757)
*Yash Garg,Saketh Bachu,Arindam Dutta,Rohit Lal,Sarosij Bose,Calvin-Khang Ta,M. Salman Asif,Amit Roy-Chowdhury*

Main category: cs.CV

TL;DR: Introduce a new dataset VOccl3D to bridge the gap in realistic occlusion datasets, fine-tuned recent HPS methods, CLIFF and BEDLAM-CLIFF, on this dataset, and leveraged this dataset to enhance human detection performance under occlusion by fine-tuning an existing object detector, YOLO11.


<details>
  <summary>Details</summary>
Motivation: Existing human pose and shape (HPS) estimation methods often struggle in challenging scenarios involving complex human poses or significant occlusions. Although some studies address 3D human pose estimation under occlusion, they typically evaluate performance on datasets that lack realistic or substantial occlusions.

Method: introduce a novel benchmark dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed this dataset using advanced computer graphics rendering techniques, incorporating diverse real-world occlusion scenarios, clothing textures, and human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and quantitative improvements across multiple public datasets, as well as on the test split of our dataset, while comparing its performance with other state-of-the-art methods. Furthermore, we leveraged our dataset to enhance human detection performance under occlusion by fine-tuning an existing object detector, YOLO11, thus leading to a robust end-to-end HPS estimation system under occlusions.

Result: demonstrating significant qualitative and quantitative improvements across multiple public datasets, as well as on the test split of our dataset, while comparing its performance with other state-of-the-art methods. Furthermore, we leveraged our dataset to enhance human detection performance under occlusion by fine-tuning an existing object detector, YOLO11, thus leading to a robust end-to-end HPS estimation system under occlusions.

Conclusion: This dataset serves as a valuable resource for future research aimed at benchmarking methods designed to handle occlusions, offering a more realistic alternative to existing occlusion datasets.

Abstract: Human pose and shape (HPS) estimation methods have been extensively studied,
with many demonstrating high zero-shot performance on in-the-wild images and
videos. However, these methods often struggle in challenging scenarios
involving complex human poses or significant occlusions. Although some studies
address 3D human pose estimation under occlusion, they typically evaluate
performance on datasets that lack realistic or substantial occlusions, e.g.,
most existing datasets introduce occlusions with random patches over the human
or clipart-style overlays, which may not reflect real-world challenges. To
bridge this gap in realistic occlusion datasets, we introduce a novel benchmark
dataset, VOccl3D, a Video-based human Occlusion dataset with 3D body pose and
shape annotations. Inspired by works such as AGORA and BEDLAM, we constructed
this dataset using advanced computer graphics rendering techniques,
incorporating diverse real-world occlusion scenarios, clothing textures, and
human motions. Additionally, we fine-tuned recent HPS methods, CLIFF and
BEDLAM-CLIFF, on our dataset, demonstrating significant qualitative and
quantitative improvements across multiple public datasets, as well as on the
test split of our dataset, while comparing its performance with other
state-of-the-art methods. Furthermore, we leveraged our dataset to enhance
human detection performance under occlusion by fine-tuning an existing object
detector, YOLO11, thus leading to a robust end-to-end HPS estimation system
under occlusions. Overall, this dataset serves as a valuable resource for
future research aimed at benchmarking methods designed to handle occlusions,
offering a more realistic alternative to existing occlusion datasets. See the
Project page for code and dataset:https://yashgarg98.github.io/VOccl3D-dataset/

</details>


### [79] [SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding](https://arxiv.org/abs/2508.06763)
*Zihao Sheng,Zilin Huang,Yen-Jung Chen,Yansong Qu,Yuhao Luo,Yue Leng,Sikai Chen*

Main category: cs.CV

TL;DR: SafePLUG是一个用于交通事故分析的新框架，它通过像素级理解和时间定位来增强 MLLM。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLM 主要关注粗粒度的图像级或视频级理解，并且通常难以处理细粒度的视觉细节或局部场景组件，从而限制了它们在复杂事故场景中的适用性。

Method: 我们提出了SafePLUG，这是一个新颖的框架，它使 MLLM 能够进行像素级理解和时间定位，以实现全面的交通事故分析。SafePLUG 支持任意形状的视觉提示，用于区域感知问答和基于语言指令的像素级分割，同时还能够在交通事故场景中识别时间锚定的事件。

Result: SafePLUG 在多个任务上实现了强大的性能，包括基于区域的问答、像素级分割、时间事件定位和事故事件理解。

Conclusion: SafePLUG在多个任务上表现出色，包括基于区域的问答、像素级分割、时间事件定位和事故事件理解。这些能力为细粒度理解复杂的交通场景奠定了基础，并有可能提高驾驶安全性并增强智能交通系统中的情境感知。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable progress
across a range of vision-language tasks and demonstrate strong potential for
traffic accident understanding. However, existing MLLMs in this domain
primarily focus on coarse-grained image-level or video-level comprehension and
often struggle to handle fine-grained visual details or localized scene
components, limiting their applicability in complex accident scenarios. To
address these limitations, we propose SafePLUG, a novel framework that empowers
MLLMs with both Pixel-Level Understanding and temporal Grounding for
comprehensive traffic accident analysis. SafePLUG supports both
arbitrary-shaped visual prompts for region-aware question answering and
pixel-level segmentation based on language instructions, while also enabling
the recognition of temporally anchored events in traffic accident scenarios. To
advance the development of MLLMs for traffic accident understanding, we curate
a new dataset containing multimodal question-answer pairs centered on diverse
accident scenarios, with detailed pixel-level annotations and temporal event
boundaries. Experimental results show that SafePLUG achieves strong performance
on multiple tasks, including region-based question answering, pixel-level
segmentation, temporal event localization, and accident event understanding.
These capabilities lay a foundation for fine-grained understanding of complex
traffic scenes, with the potential to improve driving safety and enhance
situational awareness in smart transportation systems. The code, dataset, and
model checkpoints will be made publicly available at:
https://zihaosheng.github.io/SafePLUG

</details>


### [80] [DiffUS: Differentiable Ultrasound Rendering from Volumetric Imaging](https://arxiv.org/abs/2508.06768)
*Noe Bertramo,Gabriel Duguey,Vivek Gopalakrishnan*

Main category: cs.CV

TL;DR: DiffUS 是一种基于物理的可微超声渲染器，可从 MRI 扫描合成逼真的 B 超图像，从而弥合术前计划和术中指导之间的差距。


<details>
  <summary>Details</summary>
Motivation: 术中超声成像可在许多外科手术过程中提供实时引导，但其解释因噪声、伪影以及与高分辨率术前 MRI/CT 扫描的对准不佳而变得复杂。

Method: DiffUS 采用基于物理的可微超声渲染器，该渲染器通过光线追踪和耦合反射-透射方程模拟超声波束传播，并将波传播公式化为稀疏线性系统。

Result: 在 ReMIND 数据集上的评估表明 DiffUS 能够生成解剖学上精确的超声图像。

Conclusion: DiffUS 能够从大脑 MRI 数据生成解剖学上精确的超声图像。

Abstract: Intraoperative ultrasound imaging provides real-time guidance during numerous
surgical procedures, but its interpretation is complicated by noise, artifacts,
and poor alignment with high-resolution preoperative MRI/CT scans. To bridge
the gap between reoperative planning and intraoperative guidance, we present
DiffUS, a physics-based, differentiable ultrasound renderer that synthesizes
realistic B-mode images from volumetric imaging. DiffUS first converts MRI 3D
scans into acoustic impedance volumes using a machine learning approach. Next,
we simulate ultrasound beam propagation using ray tracing with coupled
reflection-transmission equations. DiffUS formulates wave propagation as a
sparse linear system that captures multiple internal reflections. Finally, we
reconstruct B-mode images via depth-resolved echo extraction across fan-shaped
acquisition geometry, incorporating realistic artifacts including speckle noise
and depth-dependent degradation. DiffUS is entirely implemented as
differentiable tensor operations in PyTorch, enabling gradient-based
optimization for downstream applications such as slice-to-volume registration
and volumetric reconstruction. Evaluation on the ReMIND dataset demonstrates
DiffUS's ability to generate anatomically accurate ultrasound images from brain
MRI data.

</details>


### [81] [Edge Detection for Organ Boundaries via Top Down Refinement and SubPixel Upsampling](https://arxiv.org/abs/2508.06805)
*Aarav Mehta,Priya Deshmukh,Vikram Singh,Siddharth Malhotra,Krishnan Menon Iyer,Tanvi Iyer*

Main category: cs.CV

TL;DR: This paper introduces a novel crisp edge detector for medical images that improves organ boundary localization, leading to better segmentation, registration, and lesion delineation.


<details>
  <summary>Details</summary>
Motivation: Accurate localization of organ boundaries is critical in medical imaging for segmentation, registration, surgical planning, and radiotherapy. While deep convolutional networks (ConvNets) have advanced general-purpose edge detection to near-human performance on natural images, their outputs often lack precise localization, a limitation that is particularly harmful in medical applications where millimeter-level accuracy is required.

Method: a medically focused crisp edge detector that adapts a novel top-down backward refinement architecture to medical images (2D and volumetric).

Result: Evaluations on several CT and MRI organ datasets demonstrate substantially improved boundary localization under strict criteria (boundary F-measure, Hausdorff distance) compared to baseline ConvNet detectors and contemporary medical edge/contour methods. Importantly, integrating our crisp edge maps into downstream pipelines yields consistent gains in organ segmentation (higher Dice scores, lower boundary errors), more accurate image registration, and improved delineation of lesions near organ interfaces.

Conclusion: The proposed approach produces clinically valuable, crisp organ edges that materially enhance common medical-imaging tasks.

Abstract: Accurate localization of organ boundaries is critical in medical imaging for
segmentation, registration, surgical planning, and radiotherapy. While deep
convolutional networks (ConvNets) have advanced general-purpose edge detection
to near-human performance on natural images, their outputs often lack precise
localization, a limitation that is particularly harmful in medical applications
where millimeter-level accuracy is required. Building on a systematic analysis
of ConvNet edge outputs, we propose a medically focused crisp edge detector
that adapts a novel top-down backward refinement architecture to medical images
(2D and volumetric). Our method progressively upsamples and fuses high-level
semantic features with fine-grained low-level cues through a backward
refinement pathway, producing high-resolution, well-localized organ boundaries.
We further extend the design to handle anisotropic volumes by combining 2D
slice-wise refinement with light 3D context aggregation to retain computational
efficiency. Evaluations on several CT and MRI organ datasets demonstrate
substantially improved boundary localization under strict criteria (boundary
F-measure, Hausdorff distance) compared to baseline ConvNet detectors and
contemporary medical edge/contour methods. Importantly, integrating our crisp
edge maps into downstream pipelines yields consistent gains in organ
segmentation (higher Dice scores, lower boundary errors), more accurate image
registration, and improved delineation of lesions near organ interfaces. The
proposed approach produces clinically valuable, crisp organ edges that
materially enhance common medical-imaging tasks.

</details>


### [82] [DualResolution Residual Architecture with Artifact Suppression for Melanocytic Lesion Segmentation](https://arxiv.org/abs/2508.06816)
*Vikram Singh,Kabir Malhotra,Rohan Desai,Ananya Shankaracharya,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: This paper introduces a ResNet inspired dual resolution architecture for melanocytic tumor segmentation in dermoscopic images. It achieves pixel accurate masks without heavy post processing or complex pre training protocols and significantly improves boundary adherence and clinically relevant segmentation metrics compared to standard encoder decoder baselines.


<details>
  <summary>Details</summary>
Motivation: Accurate segmentation of melanocytic tumors in dermoscopic images is a critical step for automated skin cancer screening and clinical decision support. Unlike natural scene segmentation, lesion delineation must reconcile subtle texture and color variations, frequent artifacts (hairs, rulers, bubbles), and a strong need for precise boundary localization to support downstream diagnosis.

Method: a novel ResNet inspired dual resolution architecture specifically designed for melanocytic tumor segmentation. Our method maintains a full resolution stream that preserves fine grained boundary information while a complementary pooled stream aggregates multi scale contextual cues for robust lesion recognition. The streams are tightly coupled by boundary aware residual connections that inject high frequency edge information into deep feature maps, and by a channel attention module that adapts color and texture sensitivity to dermoscopic appearance. To further address common imaging artifacts and the limited size of clinical datasets, we propose a lightweight artifact suppression block and a multi task training objective that combines a Dice Tversky segmentation loss with an explicit boundary loss and a contrastive regularizer for feature stability.

Result: The combined design yields pixel accurate masks without requiring heavy post processing or complex pre training protocols. Extensive experiments on public dermoscopic benchmarks demonstrate that Our method significantly improves boundary adherence and clinically relevant segmentation metrics compared to standard encoder decoder baselines

Conclusion: Our method significantly improves boundary adherence and clinically relevant segmentation metrics compared to standard encoder decoder baselines, making it a practical building block for automated melanoma assessment systems.

Abstract: Accurate segmentation of melanocytic tumors in dermoscopic images is a
critical step for automated skin cancer screening and clinical decision
support. Unlike natural scene segmentation, lesion delineation must reconcile
subtle texture and color variations, frequent artifacts (hairs, rulers,
bubbles), and a strong need for precise boundary localization to support
downstream diagnosis. In this paper we introduce Our method, a novel ResNet
inspired dual resolution architecture specifically designed for melanocytic
tumor segmentation. Our method maintains a full resolution stream that
preserves fine grained boundary information while a complementary pooled stream
aggregates multi scale contextual cues for robust lesion recognition. The
streams are tightly coupled by boundary aware residual connections that inject
high frequency edge information into deep feature maps, and by a channel
attention module that adapts color and texture sensitivity to dermoscopic
appearance. To further address common imaging artifacts and the limited size of
clinical datasets, we propose a lightweight artifact suppression block and a
multi task training objective that combines a Dice Tversky segmentation loss
with an explicit boundary loss and a contrastive regularizer for feature
stability. The combined design yields pixel accurate masks without requiring
heavy post processing or complex pre training protocols. Extensive experiments
on public dermoscopic benchmarks demonstrate that Our method significantly
improves boundary adherence and clinically relevant segmentation metrics
compared to standard encoder decoder baselines, making it a practical building
block for automated melanoma assessment systems.

</details>


### [83] [VesselRW: Weakly Supervised Subcutaneous Vessel Segmentation via Learned Random Walk Propagation](https://arxiv.org/abs/2508.06819)
*Ayaan Nooruddin Siddiqui,Mahnoor Zaidi,Ayesha Nazneen Shahbaz,Priyadarshini Chatterjee,Krishnan Menon Iyer*

Main category: cs.CV

TL;DR: This paper introduces a weakly supervised training framework for subcutaneous vessel segmentation using sparse annotations, which reduces annotation burden and improves vascular map quality.


<details>
  <summary>Details</summary>
Motivation: Accurate segmentation of subcutaneous vessels from clinical images is hampered by scarce, expensive ground truth and by low contrast, noisy appearance of vessels across patients and modalities.

Method: a novel weakly supervised training framework tailored for subcutaneous vessel segmentation that leverages inexpensive sparse annotations (e.g., centerline traces, dot markers, or short scribbles). Sparse labels are expanded into dense, probabilistic supervision via a differentiable random walk label propagation model whose transition weights incorporate image driven vesselness cues and tubular continuity priors. The label-propagator is learned jointly with a CNN based segmentation predictor

Result: producing more complete vascular maps and better calibrated uncertainty for downstream decision making

Conclusion: The method consistently outperforms naive training on sparse labels and conventional dense pseudo-labeling, producing more complete vascular maps and better calibrated uncertainty for downstream decision making. The approach substantially reduces annotation burden while preserving clinically relevant vessel topology.

Abstract: Accurate segmentation of subcutaneous vessels from clinical images is
hampered by scarce, expensive ground truth and by low contrast, noisy
appearance of vessels across patients and modalities. We present a novel weakly
supervised training framework tailored for subcutaneous vessel segmentation
that leverages inexpensive sparse annotations (e.g., centerline traces, dot
markers, or short scribbles). Sparse labels are expanded into dense,
probabilistic supervision via a differentiable random walk label propagation
model whose transition weights incorporate image driven vesselness cues and
tubular continuity priors. The propagation yields per-pixel hitting
probabilities together with calibrated uncertainty estimates; these are
incorporated into an uncertainty weighted loss to avoid over fitting to
ambiguous regions. Crucially, the label-propagator is learned jointly with a
CNN based segmentation predictor, enabling the system to discover vessel edges
and continuity constraints without explicit edge supervision. We further
introduce a topology aware regularizer that encourages centerline connectivity
and penalizes spurious branches, improving clinical usability. In experiments
on clinical subcutaneous imaging datasets, our method consistently outperforms
naive training on sparse labels and conventional dense pseudo-labeling,
producing more complete vascular maps and better calibrated uncertainty for
downstream decision making. The approach substantially reduces annotation
burden while preserving clinically relevant vessel topology.

</details>


### [84] [Low-Rank Expert Merging for Multi-Source Domain Adaptation in Person Re-Identification](https://arxiv.org/abs/2508.06831)
*Taha Mustapha Nehdi,Nairouz Mrabah,Atif Belal,Marco Pedersoli,Eric Granger*

Main category: cs.CV

TL;DR: 提出了一种计算效率高的source-free MSDA方法SAGE-reID，用于行人重识别，该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多源域适应(MSDA)方法学习特定于域的骨干模型或需要在适应期间访问源域数据，导致训练参数和计算成本显著增长。

Method: 提出了一种Source-free Adaptive Gated Experts (SAGE-reID) 方法，该方法首先通过source-free UDA训练特定于源的低秩适配器(LoRA)，然后训练一个轻量级门控网络，以动态分配最佳合并权重，从而实现有效的跨域知识转移。

Result: LoRA专家线性缩放，但尺寸仍然可以忽略不计(<= backbone的2%)，从而降低了内存消耗和过度拟合的风险。SAGE-reID在三个具有挑战性的基准测试中优于现有方法，同时具有计算效率。

Conclusion: SAGE-reID在Market-1501、DukeMTMC-reID和MSMT17三个基准测试中优于现有方法，同时具有计算效率。

Abstract: Adapting person re-identification (reID) models to new target environments
remains a challenging problem that is typically addressed using unsupervised
domain adaptation (UDA) methods. Recent works show that when labeled data
originates from several distinct sources (e.g., datasets and cameras),
considering each source separately and applying multi-source domain adaptation
(MSDA) typically yields higher accuracy and robustness compared to blending the
sources and performing conventional UDA. However, state-of-the-art MSDA methods
learn domain-specific backbone models or require access to source domain data
during adaptation, resulting in significant growth in training parameters and
computational cost. In this paper, a Source-free Adaptive Gated Experts
(SAGE-reID) method is introduced for person reID. Our SAGE-reID is a
cost-effective, source-free MSDA method that first trains individual
source-specific low-rank adapters (LoRA) through source-free UDA. Next, a
lightweight gating network is introduced and trained to dynamically assign
optimal merging weights for fusion of LoRA experts, enabling effective
cross-domain knowledge transfer. While the number of backbone parameters
remains constant across source domains, LoRA experts scale linearly but remain
negligible in size (<= 2% of the backbone), reducing both the memory
consumption and risk of overfitting. Extensive experiments conducted on three
challenging benchmarks: Market-1501, DukeMTMC-reID, and MSMT17 indicate that
SAGE-reID outperforms state-of-the-art methods while being computationally
efficient.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [85] [Solving Pasur Using GPU-Accelerated Counterfactual Regret Minimization](https://arxiv.org/abs/2508.06559)
*Sina Baghal*

Main category: cs.AI

TL;DR: This paper introduces a CUDA-accelerated computational framework for simulating Pasur, emphasizing efficient memory management, and computes near-Nash equilibria via Counterfactual Regret Minimization (CFR).


<details>
  <summary>Details</summary>
Motivation: Solving Pasur presents unique challenges due to its intricate rules and the large size of its game tree.

Method: a CUDA-accelerated computational framework for simulating Pasur, emphasizing efficient memory management. Decompose the game tree into two key components: (1) actual game states, and (2) inherited scores from previous rounds. apply a round-by-round backward training strategy, starting from the final round and recursively propagating average utilities to earlier stages.

Result: compute near-Nash equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm for solving large imperfect-information games. construct the complete game tree, which on average consists of over $10^9$ nodes. estimate the fair value of each deck through large-scale self-play between equilibrium strategies by simulating, for instance, 10,000 games per matchup, executed in parallel using GPU acceleration.

Conclusion: The framework can be extended to other reinforcement learning algorithms where the action tree naturally decomposes into multiple rounds such as turn-based strategy games or sequential trading decisions in financial markets.

Abstract: Pasur is a fishing card game played over six rounds and is played similarly
to games such as Cassino and Scopa, and Bastra. This paper introduces a
CUDA-accelerated computational framework for simulating Pasur, emphasizing
efficient memory management. We use our framework to compute near-Nash
equilibria via Counterfactual Regret Minimization (CFR), a well-known algorithm
for solving large imperfect-information games.
  Solving Pasur presents unique challenges due to its intricate rules and the
large size of its game tree. We handle rule complexity using PyTorch CUDA
tensors and to address the memory-intensive nature of the game, we decompose
the game tree into two key components: (1) actual game states, and (2)
inherited scores from previous rounds. We construct the Full Game Tree by
pairing card states with accumulated scores in the Unfolding Process. This
design reduces memory overhead by storing only essential strategy values and
node connections. To further manage computational complexity, we apply a
round-by-round backward training strategy, starting from the final round and
recursively propagating average utilities to earlier stages. Our approach
constructs the complete game tree, which on average consists of over $10^9$
nodes. We provide detailed implementation snippets.
  After computing a near-Nash equilibrium strategy, we train a tree-based model
to predict these strategies for use during gameplay. We then estimate the fair
value of each deck through large-scale self-play between equilibrium strategies
by simulating, for instance, 10,000 games per matchup, executed in parallel
using GPU acceleration.
  Similar frameworks can be extended to other reinforcement learning algorithms
where the action tree naturally decomposes into multiple rounds such as
turn-based strategy games or sequential trading decisions in financial markets.

</details>


### [86] [Operationalizing Serendipity: Multi-Agent AI Workflows for Enhanced Materials Characterization with Theory-in-the-Loop](https://arxiv.org/abs/2508.06569)
*Lance Yao,Suman Samantray,Ayana Ghosh,Kevin Roccapriore,Libor Kovarik,Sarah Allec,Maxim Ziatdinov*

Main category: cs.AI

TL;DR: SciLink is an AI framework that promotes serendipitous discoveries in materials research by linking experimental observation, novelty assessment, and theoretical simulations.


<details>
  <summary>Details</summary>
Motivation: Modern autonomous laboratories excel at accelerating hypothesis testing but risk overlooking crucial, unplanned findings.

Method: SciLink, an open-source, multi-agent AI framework, creates a direct, automated link between experimental observation, novelty assessment, and theoretical simulations, using a hybrid AI strategy with specialized machine learning and large language models.

Result: SciLink's versatility is demonstrated across diverse research scenarios, including atomic-resolution and hyperspectral data, integration of real-time human expert guidance, and proposing targeted follow-up experiments.

Conclusion: SciLink systematically analyzes observations and contextualizes them, providing a practical AI-driven framework for materials research that enhances efficiency and cultivates serendipitous discoveries, bridging the gap between automated experimentation and open-ended scientific exploration.

Abstract: The history of science is punctuated by serendipitous discoveries, where
unexpected observations, rather than targeted hypotheses, opened new fields of
inquiry. While modern autonomous laboratories excel at accelerating hypothesis
testing, their optimization for efficiency risks overlooking these crucial,
unplanned findings. To address this gap, we introduce SciLink, an open-source,
multi-agent artificial intelligence framework designed to operationalize
serendipity in materials research by creating a direct, automated link between
experimental observation, novelty assessment, and theoretical simulations. The
framework employs a hybrid AI strategy where specialized machine learning
models perform quantitative analysis of experimental data, while large language
models handle higher-level reasoning. These agents autonomously convert raw
data from materials characterization techniques into falsifiable scientific
claims, which are then quantitatively scored for novelty against the published
literature. We demonstrate the framework's versatility across diverse research
scenarios, showcasing its application to atomic-resolution and hyperspectral
data, its capacity to integrate real-time human expert guidance, and its
ability to close the research loop by proposing targeted follow-up experiments.
By systematically analyzing all observations and contextualizing them, SciLink
provides a practical framework for AI-driven materials research that not only
enhances efficiency but also actively cultivates an environment ripe for
serendipitous discoveries, thereby bridging the gap between automated
experimentation and open-ended scientific exploration.

</details>


### [87] [IRL-VLA: Training an Vision-Language-Action Policy via Reward World Model](https://arxiv.org/abs/2508.06571)
*Anqing Jiang,Yu Gao,Yiru Wang,Zhigang Sun,Shuo Wang,Yuwen Heng,Hao Sun,Shichen Tang,Lijuan Zhu,Jinhao Chai,Jijun Wang,Zichong Gu,Hao Jiang,Li Sun*

Main category: cs.AI

TL;DR: Introduces IRL-VLA, a novel close-loop Reinforcement Learning framework for autonomous driving, which addresses limitations of existing VLA architectures and simulation dependencies.


<details>
  <summary>Details</summary>
Motivation: Existing VLA architectures are typically based on imitation learning in open-loop setup, leading to suboptimal and constrained performance. Close-loop training relies heavily on high-fidelity sensor simulation, where domain gaps and computational inefficiencies pose significant barriers.

Method: A novel close-loop Reinforcement Learning via Inverse Reinforcement Learning reward world model with a self-built VLA approach is introduced. The framework proceeds in three stages: VLA policy pretraining via imitation learning, lightweight reward world model construction via inverse reinforcement learning, and specialized reward world model guidence reinforcement learning via PPO.

Result: Achieves state-of-the-art performance in NAVSIM v2 end-to-end driving benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge.

Conclusion: This framework accelerates VLA research in close-loop autonomous driving, achieving state-of-the-art performance in NAVSIM v2 and 1st runner up in CVPR2025 Autonomous Grand Challenge.

Abstract: Vision-Language-Action (VLA) models have demonstrated potential in autonomous
driving. However, two critical challenges hinder their development: (1)
Existing VLA architectures are typically based on imitation learning in
open-loop setup which tends to capture the recorded behaviors in the dataset,
leading to suboptimal and constrained performance, (2) Close-loop training
relies heavily on high-fidelity sensor simulation, where domain gaps and
computational inefficiencies pose significant barriers. In this paper, we
introduce IRL-VLA, a novel close-loop Reinforcement Learning via
\textbf{I}nverse \textbf{R}einforcement \textbf{L}earning reward world model
with a self-built VLA approach. Our framework proceeds in a three-stage
paradigm: In the first stage, we propose a VLA architecture and pretrain the
VLA policy via imitation learning. In the second stage, we construct a
lightweight reward world model via inverse reinforcement learning to enable
efficient close-loop reward computation. To further enhance planning
performance, finally, we design specialized reward world model guidence
reinforcement learning via PPO(Proximal Policy Optimization) to effectively
balance the safety incidents, comfortable driving, and traffic efficiency. Our
approach achieves state-of-the-art performance in NAVSIM v2 end-to-end driving
benchmark, 1st runner up in CVPR2025 Autonomous Grand Challenge. We hope that
our framework will accelerate VLA research in close-loop autonomous driving.

</details>


### [88] [CountQA: How Well Do MLLMs Count in the Wild?](https://arxiv.org/abs/2508.06585)
*Jayant Sravan Tamarapalli,Rynaa Grover,Nilay Pande,Sahiti Yerramilli*

Main category: cs.AI

TL;DR: MLLM在对象计数方面存在不足。CountQA是一个新的基准，旨在探测和纠正这一缺陷。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLM）在理解视觉场景方面表现出卓越的流畅性，但它们在基本的认知技能（对象计数）方面表现出严重的不足。这种盲点严重限制了它们在现实世界应用中的可靠性。迄今为止，这种能力在复杂的场景中基本上没有被评估，因为现有的基准要么具有稀疏的对象密度，要么局限于特定的视觉领域，无法在真实条件下测试模型。

Method: 我们通过在CountQA基准上评估15个突出的MLLM来研究这种弱点。

Result: 在CountQA基准上评估了15个突出的MLLM，结果表明，表现最佳的模型的准确率仅为42.9%，并且随着对象数量的增加，性能会下降。

Conclusion: CountQA的引入为诊断和纠正MLLM在对象计数方面的核心弱点铺平了道路，从而为新一代不仅在描述上流畅，而且在数值上可靠和空间感知的MLLM铺平了道路。我们将开放数据集和代码，以促进进一步的研究。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate remarkable fluency in
understanding visual scenes, yet they exhibit a critical lack in a fundamental
cognitive skill: object counting. This blind spot severely limits their
reliability in real-world applications. To date, this capability has been
largely unevaluated in complex scenarios, as existing benchmarks either feature
sparse object densities or are confined to specific visual domains, failing to
test models under realistic conditions. Addressing this gap, we introduce
CountQA, a challenging new benchmark designed to probe this deficiency.
Comprising over 1,500 question-answer pairs, CountQA features real-world images
with high object density, clutter, and occlusion. We investigate this weakness
by evaluating 15 prominent MLLMs on the CountQA benchmark and reveal that the
top-performing model achieves a mere 42.9% accuracy, with performance declining
as object counts rise. By providing a dedicated benchmark to diagnose and
rectify this core weakness, CountQA paves the way for a new generation of MLLMs
that are not only descriptively fluent but also numerically grounded and
spatially aware. We will open-source the dataset and code upon paper acceptance
to foster further research.

</details>


### [89] [Formal Concept Analysis: a Structural Framework for Variability Extraction and Analysis](https://arxiv.org/abs/2508.06668)
*Jessie Galasso*

Main category: cs.AI

TL;DR: This paper explains how Formal Concept Analysis (FCA) can be used for variability analysis by highlighting its essential properties and their applications.


<details>
  <summary>Details</summary>
Motivation: determining which of its properties can be leveraged for variability-related tasks (and how) is not always straightforward, partly due to the mathematical orientation of its foundational literature

Method: gathering a selection of properties of the framework

Result: essential to variability analysis, and how they can be used to interpret diverse variability information within the resulting conceptual structures

Conclusion: This paper bridges the gap between FCA and variability analysis by gathering essential properties of the framework and explaining how they can be used to interpret diverse variability information within the resulting conceptual structures.

Abstract: Formal Concept Analysis (FCA) is a mathematical framework for knowledge
representation and discovery. It performs a hierarchical clustering over a set
of objects described by attributes, resulting in conceptual structures in which
objects are organized depending on the attributes they share. These conceptual
structures naturally highlight commonalities and variabilities among similar
objects by categorizing them into groups which are then arranged by similarity,
making it particularly appropriate for variability extraction and analysis.
Despite the potential of FCA, determining which of its properties can be
leveraged for variability-related tasks (and how) is not always
straightforward, partly due to the mathematical orientation of its foundational
literature. This paper attempts to bridge part of this gap by gathering a
selection of properties of the framework which are essential to variability
analysis, and how they can be used to interpret diverse variability information
within the resulting conceptual structures.

</details>


### [90] [Zero-Shot Cellular Trajectory Map Matching](https://arxiv.org/abs/2508.06674)
*Weijie Shi,Yue Cui,Hao Chen,Jiaming Li,Mengze Li,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.AI

TL;DR: 提出了一种新的零样本CTMM方法，该方法利用像素化轨迹校准、高斯混合模型和时空感知模块来提高定位精度和泛化能力，实验结果表明，该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的CTMM方法主要依赖于基于ID的特征和特定区域的数据来学习基站和道路之间的相关性，限制了它们对未开发区域的适应性。为了在目标区域无需额外训练即可实现高精度CTMM，零样本CTMM不仅需要提取区域自适应特征，还需要提取顺序和位置不确定性，以减轻蜂窝数据中的定位误差。

Method: 提出了一种基于像素的轨迹校准助手，用于零样本CTMM，该助手利用可迁移的地理空间知识来校准像素化轨迹，然后指导道路网络级别的路径查找过程。为了加强类似区域之间的知识共享，将高斯混合模型整合到VAE中，从而能够通过软聚类识别场景自适应专家。为了减轻高定位误差，设计了一个时空感知模块来捕获顺序特征和位置不确定性，从而有助于推断近似用户位置。最后，采用约束路径查找算法来重建道路ID序列，确保道路网络内的拓扑有效性。此过程由校准的轨迹引导，同时优化最短可行路径，从而最大限度地减少不必要的绕行。

Result: 该模型在零样本CTMM中优于现有方法16.8%。

Conclusion: 该模型在零样本CTMM中优于现有方法16.8%。

Abstract: Cellular Trajectory Map-Matching (CTMM) aims to align cellular location
sequences to road networks, which is a necessary preprocessing in
location-based services on web platforms like Google Maps, including navigation
and route optimization. Current approaches mainly rely on ID-based features and
region-specific data to learn correlations between cell towers and roads,
limiting their adaptability to unexplored areas. To enable high-accuracy CTMM
without additional training in target regions, Zero-shot CTMM requires to
extract not only region-adaptive features, but also sequential and location
uncertainty to alleviate positioning errors in cellular data. In this paper, we
propose a pixel-based trajectory calibration assistant for zero-shot CTMM,
which takes advantage of transferable geospatial knowledge to calibrate
pixelated trajectory, and then guide the path-finding process at the road
network level. To enhance knowledge sharing across similar regions, a Gaussian
mixture model is incorporated into VAE, enabling the identification of
scenario-adaptive experts through soft clustering. To mitigate high positioning
errors, a spatial-temporal awareness module is designed to capture sequential
features and location uncertainty, thereby facilitating the inference of
approximate user positions. Finally, a constrained path-finding algorithm is
employed to reconstruct the road ID sequence, ensuring topological validity
within the road network. This process is guided by the calibrated trajectory
while optimizing for the shortest feasible path, thus minimizing unnecessary
detours. Extensive experiments demonstrate that our model outperforms existing
methods in zero-shot CTMM by 16.8\%.

</details>


### [91] [Probabilistic Circuits for Knowledge Graph Completion with Reduced Rule Sets](https://arxiv.org/abs/2508.06706)
*Jaikrishna Manojkumar Patil,Nathaniel Lee,Al Mehdi Saadat Chowdhury,YooJung Choi,Paulo Shakarian*

Main category: cs.AI

TL;DR: 提出了一种新的知识图补全方法，该方法使用规则上下文和概率电路，在减少规则数量的同时保持或超过现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 基于规则的知识图补全方法提供了解释性的结果，但通常需要大量规则才能获得有竞争力的性能。这会因规则集过于庞大而妨碍可解释性。

Method: 从训练数据中发现规则上下文（协同工作的规则的有意义子集），并使用这些规则上下文上的学习概率分布（即概率电路）来更快速地实现完整规则集的性能。

Result: 该方法在使用等效的最小规则数量时，规则使用数量减少了 70-96%，同时性能优于基线方法高达 31 倍，即使将最小规则集与基线的完整规则集进行比较，也能保持基线峰值性能的 91%。

Conclusion: 该框架基于概率逻辑的已知语义，不需要独立性假设，并且其易于处理的推理过程提供了给定查询的近似下界和精确概率。在8个标准基准数据集上的实验研究验证了该方法的有效性，结果表明，仅使用AnyBURL标准推理方法所需规则的一小部分，该方法就能获得具有竞争力的性能。

Abstract: Rule-based methods for knowledge graph completion provide explainable results
but often require a significantly large number of rules to achieve competitive
performance. This can hinder explainability due to overwhelmingly large rule
sets. We discover rule contexts (meaningful subsets of rules that work
together) from training data and use learned probability distribution (i.e.
probabilistic circuits) over these rule contexts to more rapidly achieve
performance of the full rule set. Our approach achieves a 70-96% reduction in
number of rules used while outperforming baseline by up to 31$\times$ when
using equivalent minimal number of rules and preserves 91% of peak baseline
performance even when comparing our minimal rule sets against baseline's full
rule sets. We show that our framework is grounded in well-known semantics of
probabilistic logic, does not require independence assumptions, and that our
tractable inference procedure provides both approximate lower bounds and exact
probability of a given query. The efficacy of our method is validated by
empirical studies on 8 standard benchmark datasets where we show competitive
performance by using only a fraction of the rules required by AnyBURL's
standard inference method, the current state-of-the-art for rule-based
knowledge graph completion. This work may have further implications for general
probabilistic reasoning over learned sets of rules.

</details>


### [92] [GLIDR: Graph-Like Inductive Logic Programming with Differentiable Reasoning](https://arxiv.org/abs/2508.06716)
*Blair Johnson,Clayton Kerce,Faramarz Fekri*

Main category: cs.AI

TL;DR: GLIDR是一种可微分的规则学习方法，它概括了以前的链式规则学习方法，允许使用具有分支和循环等特征的规则。


<details>
  <summary>Details</summary>
Motivation: 现有的可微分归纳逻辑编程（ILP）技术在寻找基于规则的知识图谱链接预测和节点分类问题的近似解方面已被证明是有效的；然而，链式规则结构的常见假设可能会阻碍现有方法的性能和可解释性。

Method: GLIDR使用可微分的消息传递推理算法，该算法将先前的链式规则学习方法推广到允许具有分支和循环等特征的规则。

Result: GLIDR在知识图谱补全任务上显著优于现有的规则学习方法，并且可以与嵌入方法竞争。从GLIDR中提取的规则保留了显著的预测性能，并且GLIDR对训练数据噪声具有高度的鲁棒性。

Conclusion: GLIDR在知识图谱补全任务上显著优于现有的规则学习方法，并且可以与嵌入方法竞争。从GLIDR中提取的规则保留了显著的预测性能，并且GLIDR对训练数据噪声具有高度的鲁棒性。GLIDR可以与深度神经网络链接，并针对任意数据模态的规则学习进行端到端优化。

Abstract: Differentiable inductive logic programming (ILP) techniques have proven
effective at finding approximate rule-based solutions to link prediction and
node classification problems on knowledge graphs; however, the common
assumption of chain-like rule structure can hamper the performance and
interpretability of existing approaches. We introduce GLIDR, a differentiable
rule learning method that models the inference of logic rules with more
expressive syntax than previous methods. GLIDR uses a differentiable message
passing inference algorithm that generalizes previous chain-like rule learning
methods to allow rules with features like branches and cycles. GLIDR has a
simple and expressive rule search space which is parameterized by a limit on
the maximum number of free variables that may be included in a rule. Explicit
logic rules can be extracted from the weights of a GLIDR model for use with
symbolic solvers. We demonstrate that GLIDR can significantly outperform
existing rule learning methods on knowledge graph completion tasks and even
compete with embedding methods despite the inherent disadvantage of being a
structure-only prediction method. We show that rules extracted from GLIDR
retain significant predictive performance, and that GLIDR is highly robust to
training data noise. Finally, we demonstrate that GLIDR can be chained with
deep neural networks and optimized end-to-end for rule learning on arbitrary
data modalities.

</details>


### [93] [ParBalans: Parallel Multi-Armed Bandits-based Adaptive Large Neighborhood Search](https://arxiv.org/abs/2508.06736)
*Alican Yilmaz,Junyang Cai,Serdar Kadioglu,Bistra Dilkina*

Main category: cs.AI

TL;DR: This paper introduces ParBalans, a parallelized version of Balans for solving MIP problems, and shows it performs competitively with Gurobi on hard benchmarks.


<details>
  <summary>Details</summary>
Motivation: Solving Mixed-Integer Programming (MIP) problems often requires substantial computational resources due to their combinatorial nature. Parallelization has emerged as a critical strategy to accelerate solution times and enhance scalability to tackle large, complex instances. This paper investigates the parallelization capabilities of Balans, a recently proposed multi-armed bandits-based adaptive large neighborhood search for MIPs. While Balans's modular architecture inherently supports parallel exploration of diverse parameter configurations, this potential has not been thoroughly examined. To address this gap

Method: an extension that leverages both solver-level and algorithmic-level parallelism to improve performance on challenging MIP instances

Result: ParBalans exhibits competitive performance compared to the state-of-the-art commercial solver Gurobi, particularly on hard optimization benchmarks.

Conclusion: ParBalans exhibits competitive performance compared to the state-of-the-art commercial solver Gurobi, particularly on hard optimization benchmarks.

Abstract: Solving Mixed-Integer Programming (MIP) problems often requires substantial
computational resources due to their combinatorial nature. Parallelization has
emerged as a critical strategy to accelerate solution times and enhance
scalability to tackle large, complex instances. This paper investigates the
parallelization capabilities of Balans, a recently proposed multi-armed
bandits-based adaptive large neighborhood search for MIPs. While Balans's
modular architecture inherently supports parallel exploration of diverse
parameter configurations, this potential has not been thoroughly examined. To
address this gap, we introduce ParBalans, an extension that leverages both
solver-level and algorithmic-level parallelism to improve performance on
challenging MIP instances. Our experimental results demonstrate that ParBalans
exhibits competitive performance compared to the state-of-the-art commercial
solver Gurobi, particularly on hard optimization benchmarks.

</details>


### [94] [Topology Generation of UAV Covert Communication Networks: A Graph Diffusion Approach with Incentive Mechanism](https://arxiv.org/abs/2508.06746)
*Xin Tang,Qian Chen,Fengshun Li,Youchun Gong,Yinqiu Liu,Wen Tian,Shaowen Qin,Xiaohuan Li*

Main category: cs.AI

TL;DR: Proposes a self-organizing UAV network framework combining Graph Diffusion-based Policy Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism to ensure reliable connectivity and covert communication.


<details>
  <summary>Details</summary>
Motivation: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in sensitive applications, such as urban monitoring, emergency response, and secure sensing, ensuring reliable connectivity and covert communication has become increasingly vital. However, dynamic mobility and exposure risks pose significant challenges.

Method: This paper proposes a self-organizing UAV network framework combining Graph Diffusion-based Policy Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism.

Result: The GDPO method uses generative AI to dynamically generate sparse but well-connected topologies, enabling flexible adaptation to changing node distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game (SG)-based incentive mechanism guides self-interested UAVs to choose relay behaviors and neighbor links that support cooperation and enhance covert communication.

Conclusion: Extensive experiments validate the effectiveness of the proposed framework in terms of model convergence, topology generation quality, and enhancement of covert communication performance.

Abstract: With the growing demand for Uncrewed Aerial Vehicle (UAV) networks in
sensitive applications, such as urban monitoring, emergency response, and
secure sensing, ensuring reliable connectivity and covert communication has
become increasingly vital. However, dynamic mobility and exposure risks pose
significant challenges. To tackle these challenges, this paper proposes a
self-organizing UAV network framework combining Graph Diffusion-based Policy
Optimization (GDPO) with a Stackelberg Game (SG)-based incentive mechanism. The
GDPO method uses generative AI to dynamically generate sparse but
well-connected topologies, enabling flexible adaptation to changing node
distributions and Ground User (GU) demands. Meanwhile, the Stackelberg Game
(SG)-based incentive mechanism guides self-interested UAVs to choose relay
behaviors and neighbor links that support cooperation and enhance covert
communication. Extensive experiments are conducted to validate the
effectiveness of the proposed framework in terms of model convergence, topology
generation quality, and enhancement of covert communication performance.

</details>


### [95] [Pushing the Envelope of LLM Inference on AI-PC](https://arxiv.org/abs/2508.06753)
*Evangelos Georganas,Dhiraj Kalamkar,Alexander Heinecke*

Main category: cs.AI

TL;DR: 针对 CPU 优化的 1 比特和 2 比特微内核，集成了 PyTorch-TPP 框架，2 比特模型端到端推理结果比 bitnet.cpp 快 2.2 倍，比 16 比特模型快 7 倍。


<details>
  <summary>Details</summary>
Motivation: 超低比特 LLM 模型（1/1.58/2 比特）的出现，在使用相同模型大小的情况下，其困惑度和终端任务性能与全精度模型相匹配，这预示着 LLM 推理进入了一个新时代，适用于边缘设备和 AI PC 等资源受限的环境。虽然这些量化进步承诺模型在延迟、内存、吞吐量和能耗方面更具成本效益，但用于部署它们的最先进（SOTA）推理运行时（例如，bitnet.cpp）的计算效率仍未得到充分探索。

Method: 首先设计并实现了针对现代 CPU 优化的 1 比特和 2 比特微内核，在各种 CPU 平台上实现了峰值计算效率。将这些微内核集成到最先进的 LLM 推理框架 PyTorch-TPP 中，并使用 2 比特模型展示了端到端推理结果，该结果优于当前 SOTA 运行时 bitnet.cpp 高达 2.2 倍，并且与 16 比特模型推理相比，提供了高达 7 倍的加速。

Result: 端到端推理结果优于当前 SOTA 运行时 bitnet.cpp 高达 2.2 倍，并且与 16 比特模型推理相比，提供了高达 7 倍的加速。

Conclusion: 优化的运行时推进了 AI PC 和边缘设备上 LLM 推理的状态，为高效部署超低比特 LLM 模型铺平了道路。

Abstract: The advent of ultra-low-bit LLM models (1/1.58/2-bit), which match the
perplexity and end-task performance of their full-precision counterparts using
the same model size, is ushering in a new era of LLM inference for
resource-constrained environments such as edge devices and AI PCs. While these
quantization advances promise models that are more cost-effective in terms of
latency, memory, throughput, and energy consumption, the computational
efficiency of state-of-the-art (SOTA) inference runtimes (e.g., bitnet.cpp)
used to deploy them remains underexplored. In this work, we take a bottom-up
approach: we first design and implement 1-bit and 2-bit microkernels optimized
for modern CPUs, achieving peak computational efficiency across a variety of
CPU platforms. We integrate these microkernels into a state-of-the-art LLM
inference framework, namely PyTorch-TPP, and present end-to-end inference
results with 2-bit models that outperform the current SOTA runtime bitnet.cpp
by up to 2.2x, and deliver up to 7x speedup compared to the 16-bit model
inference. Our optimized runtime advances the state of LLM inference on AI PCs
and edge devices, paving the way for efficient deployment of ultra-low-bit LLM
models.

</details>


### [96] [A Fuzzy Logic Prompting Framework for Large Language Models in Adaptive and Uncertain Tasks](https://arxiv.org/abs/2508.06754)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 提出了一个模块化的提示框架，通过结合自然语言提示和控制模式，提高大型语言模型在动态任务中的安全性、适应性和教学质量。


<details>
  <summary>Details</summary>
Motivation: 在动态的、以用户为中心的任务中，为了更安全、更自适应地使用大型语言模型(llm)，我们引入了一个模块化的提示框架。

Method: 该方法结合了自然语言边界提示和一个用模糊支架逻辑和适应规则编码的控制模式。

Result: 在模拟的智能辅导环境中，该框架提高了跨多个模型的支架质量、适应性和教学一致性，优于标准提示基线。评估是使用基于量规的LLM评分器大规模进行的。

Conclusion: 该框架为在不确定或不断变化的环境中构建可解释的、目标一致的LLM行为提供了一种可重用的方法。

Abstract: We introduce a modular prompting framework that supports safer and more
adaptive use of large language models (LLMs) across dynamic, user-centered
tasks. Grounded in human learning theory, particularly the Zone of Proximal
Development (ZPD), our method combines a natural language boundary prompt with
a control schema encoded with fuzzy scaffolding logic and adaptation rules.
This architecture enables LLMs to modulate behavior in response to user state
without requiring fine-tuning or external orchestration. In a simulated
intelligent tutoring setting, the framework improves scaffolding quality,
adaptivity, and instructional alignment across multiple models, outperforming
standard prompting baselines. Evaluation is conducted using rubric-based LLM
graders at scale. While initially developed for education, the framework has
shown promise in other interaction-heavy domains, such as procedural content
generation for games. Designed for safe deployment, it provides a reusable
methodology for structuring interpretable, goal-aligned LLM behavior in
uncertain or evolving contexts.

</details>


### [97] [Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation](https://arxiv.org/abs/2508.06823)
*Xuan Zhao,Jun Tao*

Main category: cs.AI

TL;DR: This paper introduces a natural language interaction framework to enhance volumetric data exploration by automating viewpoint selection using CLIP Score and reinforcement learning.


<details>
  <summary>Details</summary>
Motivation: Selecting optimal viewpoints for effective navigation of volumetric data is challenging, particularly for users without extensive domain expertise.

Method: This paper proposes a novel framework that leverages natural language interaction to enhance volumetric data exploration. It encodes volumetric blocks and incorporates a CLIP Score mechanism to guide navigation, using a reinforcement learning framework.

Result: The selected viewpoints are evaluated using CLIP Score to ensure that they best reflect the user queries.

Conclusion: This paper automates viewpoint selection to improve the efficiency of volumetric data navigation and enhances the interpretability of complex scientific phenomena.

Abstract: Exploring volumetric data is crucial for interpreting scientific datasets.
However, selecting optimal viewpoints for effective navigation can be
challenging, particularly for users without extensive domain expertise or
familiarity with 3D navigation. In this paper, we propose a novel framework
that leverages natural language interaction to enhance volumetric data
exploration. Our approach encodes volumetric blocks to capture and
differentiate underlying structures. It further incorporates a CLIP Score
mechanism, which provides semantic information to the blocks to guide
navigation. The navigation is empowered by a reinforcement learning framework
that leverage these semantic cues to efficiently search for and identify
desired viewpoints that align with the user's intent. The selected viewpoints
are evaluated using CLIP Score to ensure that they best reflect the user
queries. By automating viewpoint selection, our method improves the efficiency
of volumetric data navigation and enhances the interpretability of complex
scientific phenomena.

</details>


### [98] [Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges](https://arxiv.org/abs/2508.06832)
*Haifeng Li,Wang Guo,Haiyang Wu,Mengwei Wu,Jipeng Zhang,Qing Zhu,Yu Liu,Xin Huang,Chao Tao*

Main category: cs.AI

TL;DR: This review advocates a paradigm shift from vision-centered to language-centered remote sensing interpretation and proposes a language-centered framework using LLMs for unified understanding, reasoning, and decision-making, inspired by the Global Workspace Theory.


<details>
  <summary>Details</summary>
Motivation: The mainstream paradigm of remote sensing image interpretation has long been dominated by vision-centered models, which rely on visual features for semantic understanding but face inherent limitations in handling multi-modal reasoning, semantic abstraction, and interactive decision-making. Existing studies primarily focus on downstream applications, lacking a unified theoretical framework that explains the cognitive role of language.

Method: propose a language-centered framework for remote sensing interpretation that treats LLMs as the cognitive central hub integrating perceptual, task, knowledge and action spaces

Result: explore the potential of LLMs as the central cognitive component, summarize core technical challenges, construct a global workspace-driven interpretation mechanism and review how language-centered solutions address each challenge, and outline future research directions from four perspectives: adaptive alignment of multimodal data, task understanding under dynamic knowledge constraints, trustworthy reasoning, and autonomous interaction.

Conclusion: This work provides a conceptual foundation for the next generation of remote sensing interpretation systems and establishes a roadmap toward cognition-driven intelligent geospatial analysis.

Abstract: The mainstream paradigm of remote sensing image interpretation has long been
dominated by vision-centered models, which rely on visual features for semantic
understanding. However, these models face inherent limitations in handling
multi-modal reasoning, semantic abstraction, and interactive decision-making.
While recent advances have introduced Large Language Models (LLMs) into remote
sensing workflows, existing studies primarily focus on downstream applications,
lacking a unified theoretical framework that explains the cognitive role of
language. This review advocates a paradigm shift from vision-centered to
language-centered remote sensing interpretation. Drawing inspiration from the
Global Workspace Theory (GWT) of human cognition, We propose a
language-centered framework for remote sensing interpretation that treats LLMs
as the cognitive central hub integrating perceptual, task, knowledge and action
spaces to enable unified understanding, reasoning, and decision-making. We
first explore the potential of LLMs as the central cognitive component in
remote sensing interpretation, and then summarize core technical challenges,
including unified multimodal representation, knowledge association, and
reasoning and decision-making. Furthermore, we construct a global
workspace-driven interpretation mechanism and review how language-centered
solutions address each challenge. Finally, we outline future research
directions from four perspectives: adaptive alignment of multimodal data, task
understanding under dynamic knowledge constraints, trustworthy reasoning, and
autonomous interaction. This work aims to provide a conceptual foundation for
the next generation of remote sensing interpretation systems and establish a
roadmap toward cognition-driven intelligent geospatial analysis.

</details>


### [99] [Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.06836)
*Xutong Zhao,Yaqi Xie*

Main category: cs.AI

TL;DR: 提出了一种新的多智能体强化学习信用分配方法，该方法在复杂的星际争霸任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 合作多智能体强化学习（MARL）旨在协调多个智能体以实现共同目标。MARL 的一个关键挑战是信用分配，它涉及评估每个智能体对共享奖励的贡献。

Method: 引入了一种多层次优势公式，通过显式的反事实推理来推断不同层次的信用。

Result: 在具有挑战性的 Starcraft v1&v2 任务上的综合实验表明，MACA 具有卓越的性能。

Conclusion: MACA在复杂的信用分配场景中表现出色。

Abstract: Cooperative multi-agent reinforcement learning (MARL) aims to coordinate
multiple agents to achieve a common goal. A key challenge in MARL is credit
assignment, which involves assessing each agent's contribution to the shared
reward. Given the diversity of tasks, agents may perform different types of
coordination, with rewards attributed to diverse and often overlapping agent
subsets. In this work, we formalize the credit assignment level as the number
of agents cooperating to obtain a reward, and address scenarios with multiple
coexisting levels. We introduce a multi-level advantage formulation that
performs explicit counterfactual reasoning to infer credits across distinct
levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures
agent contributions at multiple levels by integrating advantage functions that
reason about individual, joint, and correlated actions. Utilizing an
attention-based framework, MACA identifies correlated agent relationships and
constructs multi-level advantages to guide policy learning. Comprehensive
experiments on challenging Starcraft v1\&v2 tasks demonstrate MACA's superior
performance, underscoring its efficacy in complex credit assignment scenarios.

</details>


### [100] [MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams](https://arxiv.org/abs/2508.06851)
*Pengfei Zhou,Xiaopeng Peng,Fanrui Zhang,Zhaopan Xu,Jiaxin Ai,Yansheng Qiu,Chuanhao Li,Zhen Li,Ming Li,Yukang Feng,Jianwen Sun,Haoquan Zhang,Zizhen Li,Xiaofeng Mao,Zekai Li,Wangbo Zhao,Kai Wang,Xiaojun Chang,Wenqi Shao,Yang You,Kaipeng Zhang*

Main category: cs.AI

TL;DR: Introduces MDK12-Bench, a large-scale multidisciplinary benchmark for evaluating MLLMs, revealing limitations and providing guidance for improvement.


<details>
  <summary>Details</summary>
Motivation: Current benchmarks for measuring the intelligence of MLLMs suffer from limited scale, narrow coverage, and unstructured knowledge, offering only static and undifferentiated evaluations.

Method: We introduce MDK12-Bench, a large-scale multidisciplinary benchmark built from real-world K-12 exams spanning six disciplines with 141K instances and 6,225 knowledge points organized in a six-layer taxonomy. We propose a novel dynamic evaluation framework that introduces unfamiliar visual, textual, and question form shifts to challenge model generalization while improving benchmark objectivity and longevity by mitigating data contamination. We further evaluate knowledge-point reference-augmented generation (KP-RAG) to examine the role of knowledge in problem-solving.

Result: It enables comprehensive evaluation to capture the extent to which MLLMs perform over four dimensions: 1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts, and 4) knowledge-driven reasoning.

Conclusion: Key findings reveal limitations in current MLLMs in multiple aspects and provide guidance for enhancing model robustness, interpretability, and AI-assisted education.

Abstract: Multimodal large language models (MLLMs), which integrate language and visual
cues for problem-solving, are crucial for advancing artificial general
intelligence (AGI). However, current benchmarks for measuring the intelligence
of MLLMs suffer from limited scale, narrow coverage, and unstructured
knowledge, offering only static and undifferentiated evaluations. To bridge
this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark
built from real-world K-12 exams spanning six disciplines with 141K instances
and 6,225 knowledge points organized in a six-layer taxonomy. Covering five
question formats with difficulty and year annotations, it enables comprehensive
evaluation to capture the extent to which MLLMs perform over four dimensions:
1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts,
and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation
framework that introduces unfamiliar visual, textual, and question form shifts
to challenge model generalization while improving benchmark objectivity and
longevity by mitigating data contamination. We further evaluate knowledge-point
reference-augmented generation (KP-RAG) to examine the role of knowledge in
problem-solving. Key findings reveal limitations in current MLLMs in multiple
aspects and provide guidance for enhancing model robustness, interpretability,
and AI-assisted education.

</details>


### [101] [MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction](https://arxiv.org/abs/2508.06859)
*Shuo Tang,Jian Xu,Jiadong Zhang,Yi Chen,Qizhao Jin,Lingdong Shen,Chenglin Liu,Shiming Xiang*

Main category: cs.AI

TL;DR: 提出了MP-Bench数据集和气象多模态大模型 (MMLM)，用于解决恶劣天气预测中的挑战，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 及时准确的恶劣天气预警对于减轻灾害至关重要。然而，目前的预报系统仍然严重依赖人工专家解读，这引入了主观性并带来了巨大的操作负担。端到端“AI 气象站”正逐渐成为预测恶劣天气事件的新趋势。三个核心挑战阻碍了端到端 AI 恶劣天气系统的发展：(1) 恶劣天气事件样本稀缺；(2) 高维气象数据和文本警告之间的不完全对齐；(3) 现有的多模态语言模型无法处理高维气象数据，并且难以完全捕获跨时间序列、垂直压力水平和空间维度的复杂依赖关系。

Method: 开发了一个气象多模态大模型 (MMLM)，可以直接摄取 4D 气象输入。此外，它旨在适应 4D 气象数据流的独特特征，结合了三个即插即用自适应融合模块，可以实现跨时间序列、垂直压力层和空间维度的动态特征提取和集成。

Result: MP-Bench 上的大量实验表明，MMLM 在多个任务中表现出色，展示了其在恶劣天气理解方面的有效性。

Conclusion: MMLM在多个任务中表现出色，展示了其在恶劣天气理解方面的有效性，并标志着朝着自动化、人工智能驱动的天气预报系统迈出了关键一步。

Abstract: Timely and accurate severe weather warnings are critical for disaster
mitigation. However, current forecasting systems remain heavily reliant on
manual expert interpretation, introducing subjectivity and significant
operational burdens. With the rapid development of AI technologies, the
end-to-end "AI weather station" is gradually emerging as a new trend in
predicting severe weather events. Three core challenges impede the development
of end-to-end AI severe weather system: (1) scarcity of severe weather event
samples; (2) imperfect alignment between high-dimensional meteorological data
and textual warnings; (3) existing multimodal language models are unable to
handle high-dimensional meteorological data and struggle to fully capture the
complex dependencies across temporal sequences, vertical pressure levels, and
spatial dimensions. To address these challenges, we introduce MP-Bench, the
first large-scale temporal multimodal dataset for severe weather events
prediction, comprising 421,363 pairs of raw multi-year meteorological data and
corresponding text caption, covering a wide range of severe weather scenarios
across China. On top of this dataset, we develop a meteorology multimodal large
model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is
designed to accommodate the unique characteristics of 4D meteorological data
flow, incorporating three plug-and-play adaptive fusion modules that enable
dynamic feature extraction and integration across temporal sequences, vertical
pressure layers, and spatial dimensions. Extensive experiments on MP-Bench
demonstrate that MMLM performs exceptionally well across multiple tasks,
highlighting its effectiveness in severe weather understanding and marking a
key step toward realizing automated, AI-driven weather forecasting systems. Our
source code and dataset will be made publicly available.

</details>


### [102] [Pushdown Reward Machines for Reinforcement Learning](https://arxiv.org/abs/2508.06894)
*Giovanni Varricchione,Toryn Q. Klassen,Natasha Alechina,Mehdi Dastani,Brian Logan,Sheila A. McIlraith*

Main category: cs.AI

TL;DR: This paper presents pushdown reward machines (pdRMs), an extension of reward machines based on deterministic pushdown automata. pdRMs can recognize and reward temporally extended behaviours representable in deterministic context-free languages, making them more expressive than reward machines.


<details>
  <summary>Details</summary>
Motivation: RMs can reward any behaviour representable in regular languages and, when paired with RL algorithms that exploit RM structure, have been shown to significantly improve sample efficiency in many domains.

Method: We introduce two variants of pdRM-based policies, one which has access to the entire stack of the pdRM, and one which can only access the top  𝑘  symbols (for a given constant  𝑘 ) of the stack. We propose a procedure to check when the two kinds of policies (for a given environment, pdRM, and constant  𝑘 ) achieve the same optimal expected reward.

Result: We then provide theoretical results establishing the expressive power of pdRMs, and space complexity results about the proposed learning problems.

Conclusion: Agents can be trained to perform tasks representable in deterministic context-free languages using pdRMs.

Abstract: Reward machines (RMs) are automata structures that encode (non-Markovian)
reward functions for reinforcement learning (RL). RMs can reward any behaviour
representable in regular languages and, when paired with RL algorithms that
exploit RM structure, have been shown to significantly improve sample
efficiency in many domains. In this work, we present pushdown reward machines
(pdRMs), an extension of reward machines based on deterministic pushdown
automata. pdRMs can recognize and reward temporally extended behaviours
representable in deterministic context-free languages, making them more
expressive than reward machines. We introduce two variants of pdRM-based
policies, one which has access to the entire stack of the pdRM, and one which
can only access the top $k$ symbols (for a given constant $k$) of the stack. We
propose a procedure to check when the two kinds of policies (for a given
environment, pdRM, and constant $k$) achieve the same optimal expected reward.
We then provide theoretical results establishing the expressive power of pdRMs,
and space complexity results about the proposed learning problems. Finally, we
provide experimental results showing how agents can be trained to perform tasks
representable in deterministic context-free languages using pdRMs.

</details>


### [103] [GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization](https://arxiv.org/abs/2508.06899)
*Yanchen Deng,Xinrun Wang,Bo An*

Main category: cs.AI

TL;DR: 提出了一种新的分布式引导局部搜索 (DGLS) 框架，用于解决 DCOP 问题，该框架优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 局部搜索是解决分布式约束优化问题 (DCOP) 的一类重要的不完备算法，但它通常会收敛到较差的局部最优值。虽然 GDBA 提供了一套全面的规则来避免过早收敛，但它在一般价值问题上的经验效益仍然很小。

Method: 提出了一种新的 DCOPs 的 GLS 框架，即分布式引导局部搜索 (DGLS)，它结合了一种自适应违反条件来选择性地惩罚高成本的约束，一种惩罚蒸发机制来控制惩罚的幅度，以及一种用于协调惩罚更新的同步方案。

Result: 理论上表明，惩罚值是有界的，并且智能体在 DGLS 中进行潜在博弈。DGLS 在一般价值问题上实现了具有竞争力的性能，并且在随时结果方面，DGLS 在结构化问题上明显优于它（{3.77%--66.3%}{）}。

Conclusion: DGLS在各种标准基准测试中表现出优于现有技术的优越性。特别是在结构化问题上，DGLS 的随时结果优于具有高阻尼因子（例如 0.7 或 0.9）的阻尼 Max-sum（{3.77%--66.3%}{）}。

Abstract: Local search is an important class of incomplete algorithms for solving
Distributed Constraint Optimization Problems (DCOPs) but it often converges to
poor local optima. While GDBA provides a comprehensive rule set to escape
premature convergence, its empirical benefits remain marginal on general-valued
problems. In this work, we systematically examine GDBA and identify three
factors that potentially lead to its inferior performance, i.e.,
over-aggressive constraint violation conditions, unbounded penalty
accumulation, and uncoordinated penalty updates. To address these issues, we
propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs
that incorporates an adaptive violation condition to selectively penalize
constraints with high cost, a penalty evaporation mechanism to control the
magnitude of penalization, and a synchronization scheme for coordinated penalty
updates. We theoretically show that the penalty values are bounded, and agents
play a potential game in our DGLS. Our extensive empirical results on various
standard benchmarks demonstrate the great superiority of DGLS over
state-of-the-art baselines. Particularly, compared to Damped Max-sum with high
damping factors (e.g., 0.7 or 0.9), our DGLS achieves competitive performance
on general-valued problems, and outperforms it by significant margins
(\textbf{3.77\%--66.3\%}) on structured problems in terms of anytime results.

</details>


### [104] [Automated Formalization via Conceptual Retrieval-Augmented LLMs](https://arxiv.org/abs/2508.06931)
*Wangyue Lu,Lun Du,Sirui Li,Ke Weng,Haozhe Sun,Hengyu Liu,Minghe Yu,Tiancheng Zhang,Ge Yu*

Main category: cs.AI

TL;DR: CRAMF通过检索数学概念的形式化定义来改进LLM的自动形式化，解决了模型幻觉和语义差距问题，并在翻译准确性方面取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 交互式定理证明器(ITP)需要手动形式化，这需要大量的人工和专业的知识。虽然自动形式化提供了一个潜在的解决方案，但它面临着两个主要的挑战：模型幻觉(例如，未定义的谓词、符号误用和版本不兼容)和由自然语言描述中模糊或缺失的前提引起的语义差距。

Method: CRAMF，一个概念驱动的检索增强数学形式化框架。该框架通过检索核心数学概念的形式化定义来增强基于LLM的自动形式化，从而在代码生成期间提供上下文基础。

Result: CRAMF可以无缝集成到基于LLM的自动形式化工具中，从而在翻译准确率上持续改进，达到高达62.1%的相对改进，平均相对改进为29.9%。在miniF2F、ProofNet和我们新提出的AdvancedMath基准测试上的实验表明了这一点。

Conclusion: CRAMF能无缝集成到基于LLM的自动形式化工具中，在翻译准确率上产生持续的提升，最高可达62.1%，平均相对提升29.9%。

Abstract: Interactive theorem provers (ITPs) require manual formalization, which is
labor-intensive and demands expert knowledge. While automated formalization
offers a potential solution, it faces two major challenges: model hallucination
(e.g., undefined predicates, symbol misuse, and version incompatibility) and
the semantic gap caused by ambiguous or missing premises in natural language
descriptions. To address these issues, we propose CRAMF, a Concept-driven
Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances
LLM-based autoformalization by retrieving formal definitions of core
mathematical concepts, providing contextual grounding during code generation.
However, applying retrieval-augmented generation (RAG) in this setting is
non-trivial due to the lack of structured knowledge bases, the polymorphic
nature of mathematical concepts, and the high precision required in formal
retrieval. We introduce a framework for automatically constructing a
concept-definition knowledge base from Mathlib4, the standard mathematical
library for the Lean 4 theorem prover, indexing over 26,000 formal definitions
and 1,000+ core mathematical concepts. To address conceptual polymorphism, we
propose contextual query augmentation with domain- and application-level
signals. In addition, we design a dual-channel hybrid retrieval strategy with
reranking to ensure accurate and relevant definition retrieval. Experiments on
miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that
CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding
consistent improvements in translation accuracy, achieving up to 62.1% and an
average of 29.9% relative improvement.

</details>


### [105] [Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction](https://arxiv.org/abs/2508.06939)
*Hiba Najjar,Deepak Pathak,Marlon Nuske,Andreas Dengel*

Main category: cs.AI

TL;DR: Transformer-based models are used for crop yield prediction with improved performance and interpretability using attention mechanisms.


<details>
  <summary>Details</summary>
Motivation: Model interpretability is often overlooked in multimodal learning networks for agriculture.

Method: Leverage Transformer-based models and propose Weighted Modality Activation (WMA). Estimate feature attributions using Attention Rollout (AR) and Generic Attention (GA). Evaluate performance against Shapley Value Sampling (SVS).

Result: Transformer-based models achieve higher R2 scores. AR provides more reliable temporal attributions. Modality attributions reveal varying patterns.

Conclusion: Transformer-based models outperform other architectures in crop yield prediction. Attention Rollout (AR) provides more robust temporal attributions. Modality attributions reveal varying patterns across methods.

Abstract: Multimodal learning enables various machine learning tasks to benefit from
diverse data sources, effectively mimicking the interplay of different factors
in real-world applications, particularly in agriculture. While the
heterogeneous nature of involved data modalities may necessitate the design of
complex architectures, the model interpretability is often overlooked. In this
study, we leverage the intrinsic explainability of Transformer-based models to
explain multimodal learning networks, focusing on the task of crop yield
prediction at the subfield level. The large datasets used cover various crops,
regions, and years, and include four different input modalities: multispectral
satellite and weather time series, terrain elevation maps and soil properties.
Based on the self-attention mechanism, we estimate feature attributions using
two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and
evaluate their performance against Shapley-based model-agnostic estimations,
Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality
Activation (WMA) method to assess modality attributions and compare it with SVS
attributions. Our findings indicate that Transformer-based models outperform
other architectures, specifically convolutional and recurrent networks,
achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field
levels, respectively. AR is shown to provide more robust and reliable temporal
attributions, as confirmed through qualitative and quantitative evaluation,
compared to GA and SVS values. Information about crop phenology stages was
leveraged to interpret the explanation results in the light of established
agronomic knowledge. Furthermore, modality attributions revealed varying
patterns across the two methods compared.[...]

</details>


### [106] [Large Language Models Do Not Simulate Human Psychology](https://arxiv.org/abs/2508.06950)
*Sarah Schröder,Thekla Morgenroth,Ulrike Kuhl,Valerie Vaquet,Benjamin Paaßen*

Main category: cs.AI

TL;DR: LLMs are not reliable simulations of human psychology and should not replace human participants in psychological studies.


<details>
  <summary>Details</summary>
Motivation: LLMs are increasingly used in research, some research has suggested that LLMs may even be able to simulate human psychology and can, hence, replace human participants in psychological studies. We caution against this approach.

Method: Conceptual arguments and empiric evidence illustrating arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model. Additionally, different LLMs show very different responses to novel items

Result: Slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability.

Conclusion: LLMs do not simulate human psychology and should be validated against human responses for every new application.

Abstract: Large Language Models (LLMs),such as ChatGPT, are increasingly used in
research, ranging from simple writing assistance to complex data annotation
tasks. Recently, some research has suggested that LLMs may even be able to
simulate human psychology and can, hence, replace human participants in
psychological studies. We caution against this approach. We provide conceptual
arguments against the hypothesis that LLMs simulate human psychology. We then
present empiric evidence illustrating our arguments by demonstrating that
slight changes to wording that correspond to large changes in meaning lead to
notable discrepancies between LLMs' and human responses, even for the recent
CENTAUR model that was specifically fine-tuned on psychological responses.
Additionally, different LLMs show very different responses to novel items,
further illustrating their lack of reliability. We conclude that LLMs do not
simulate human psychology and recommend that psychological researchers should
treat LLMs as useful but fundamentally unreliable tools that need to be
validated against human responses for every new application.

</details>


### [107] [DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery](https://arxiv.org/abs/2508.06960)
*Keyu Li,Mohan Jiang,Dayuan Fu,Yunze Wu,Xiangkun Hu,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: AI agents struggle to discover and synthesize datasets, revealing a gap between current capabilities and ideal dataset discovery. The DatasetResearch benchmark highlights these limitations.


<details>
  <summary>Details</summary>
Motivation: The increasing importance of data availability for AI development and the challenge of discovering datasets across various sources.

Method: The paper introduces DatasetResearch, a benchmark evaluating AI agents' ability to discover and synthesize datasets from real-world demands. A tri-dimensional evaluation framework is used.

Result: Advanced deep research systems achieve only 22% score on the DatasetResearch-pro subset. Search agents excel at knowledge tasks, while synthesis agents dominate reasoning challenges, but both fail on corner cases.

Conclusion: The paper establishes a benchmark for dataset discovery agents, highlighting the gap between current AI capabilities and perfect dataset discovery, and providing a foundation for future self-improving AI systems.

Abstract: The rapid advancement of large language models has fundamentally shifted the
bottleneck in AI development from computational power to data availability-with
countless valuable datasets remaining hidden across specialized repositories,
research appendices, and domain platforms. As reasoning capabilities and deep
research methodologies continue to evolve, a critical question emerges: can AI
agents transcend conventional search to systematically discover any dataset
that meets specific user requirements, enabling truly autonomous demand-driven
data curation? We introduce DatasetResearch, the first comprehensive benchmark
evaluating AI agents' ability to discover and synthesize datasets from 208
real-world demands across knowledge-intensive and reasoning-intensive tasks.
Our tri-dimensional evaluation framework reveals a stark reality: even advanced
deep research systems achieve only 22% score on our challenging
DatasetResearch-pro subset, exposing the vast gap between current capabilities
and perfect dataset discovery. Our analysis uncovers a fundamental
dichotomy-search agents excel at knowledge tasks through retrieval breadth,
while synthesis agents dominate reasoning challenges via structured
generation-yet both catastrophically fail on "corner cases" outside existing
distributions. These findings establish the first rigorous baseline for dataset
discovery agents and illuminate the path toward AI systems capable of finding
any dataset in the digital universe. Our benchmark and comprehensive analysis
provide the foundation for the next generation of self-improving AI systems and
are publicly available at https://github.com/GAIR-NLP/DatasetResearch.

</details>


### [108] [MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair](https://arxiv.org/abs/2508.06963)
*Changqing Li,Tianlin Li,Xiaohan Zhang,Aishan Liu,Li Pan*

Main category: cs.AI

TL;DR: MASteer是一个基于表征工程的LLM可信度修复框架，它通过自动化生成样本和自适应steering策略，实现了高效且可扩展的修复，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）面临着持续且不断发展的可信度问题，这促使开发人员寻求自动化和灵活的修复方法，以便在各种场景中方便地部署。现有的修复方法，如监督微调（SFT）和人工反馈强化学习（RLHF）成本高昂且速度慢，而提示工程缺乏鲁棒性和可扩展性。

Method: MASteer集成了两个核心组件：AutoTester，一个多代理系统，可以生成根据开发者需求定制的各种高质量steering样本；以及AutoRepairer，它构建了具有anchor向量的自适应steering策略，以便在推理期间自动进行上下文感知的策略选择。

Result: MASteer在标准和定制的可信度任务上的实验表明，它始终优于基线，在LLaMA-3.1-8B-Chat上将指标提高了15.36%，在Qwen-3-8B-Chat上提高了4.21%，同时保持了一般的模型能力。

Conclusion: MASteer在可信度任务上始终优于基线，在LLaMA-3.1-8B-Chat上将指标提高了15.36%，在Qwen-3-8B-Chat上提高了4.21%，同时保持了一般的模型能力。MASteer展示了强大的鲁棒性、泛化性和可扩展性。

Abstract: Large Language Models (LLMs) face persistent and evolving trustworthiness
issues, motivating developers to seek automated and flexible repair methods
that enable convenient deployment across diverse scenarios. Existing repair
methods like supervised fine-tuning (SFT) and reinforcement learning with human
feedback (RLHF) are costly and slow, while prompt engineering lacks robustness
and scalability. Representation engineering, which steers model behavior by
injecting targeted concept vectors during inference, offers a lightweight,
training-free alternative. However, current approaches depend on manually
crafted samples and fixed steering strategies, limiting automation and
adaptability. To overcome these challenges, we propose MASteer, the first
end-to-end framework for trustworthiness repair in LLMs based on representation
engineering. MASteer integrates two core components: AutoTester, a multi-agent
system that generates diverse, high-quality steer samples tailored to developer
needs; and AutoRepairer, which constructs adaptive steering strategies with
anchor vectors for automated, context-aware strategy selection during
inference. Experiments on standard and customized trustworthiness tasks show
MASteer consistently outperforms baselines, improving metrics by 15.36% on
LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model
capabilities. MASteer demonstrates strong robustness, generalization, and
practical value for scalable, efficient trustworthiness repair.

</details>


### [109] [DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning](https://arxiv.org/abs/2508.06972)
*Dan Ivanov,Tristan Freiberg,Haruna Isah*

Main category: cs.AI

TL;DR: DSperse is a framework for distributed machine learning inference that uses targeted verification of subcomputations to minimize trust and improve scalability.


<details>
  <summary>Details</summary>
Motivation: To avoid the high cost and rigidity of full-model circuitization in distributed zero-knowledge machine learning.

Method: DSperse uses a modular framework for distributed machine learning inference with strategic cryptographic verification, enabling targeted verification of subcomputations.

Result: Empirical results on memory usage, runtime, and circuit behavior under sliced and unsliced configurations.

Conclusion: DSperse enables scalable, targeted verification strategies by aligning proof boundaries with the model's logical structure.

Abstract: DSperse is a modular framework for distributed machine learning inference
with strategic cryptographic verification. Operating within the emerging
paradigm of distributed zero-knowledge machine learning, DSperse avoids the
high cost and rigidity of full-model circuitization by enabling targeted
verification of strategically chosen subcomputations. These verifiable
segments, or "slices", may cover part or all of the inference pipeline, with
global consistency enforced through audit, replication, or economic incentives.
This architecture supports a pragmatic form of trust minimization, localizing
zero-knowledge proofs to the components where they provide the greatest value.
We evaluate DSperse using multiple proving systems and report empirical results
on memory usage, runtime, and circuit behavior under sliced and unsliced
configurations. By allowing proof boundaries to align flexibly with the model's
logical structure, DSperse supports scalable, targeted verification strategies
suited to diverse deployment needs.

</details>


### [110] [Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model](https://arxiv.org/abs/2508.06980)
*Aswin Paul,Moein Khajehnejad,Forough Habibollahi,Brett J. Kagan,Adeel Razi*

Main category: cs.AI

TL;DR: This paper proposes a biologically grounded framework for understanding decision-making in AI agents, using active inference and generative models to simulate learning and predictive planning.


<details>
  <summary>Details</summary>
Motivation: understanding the foundation of purposeful behaviour in autonomous agents is crucial for developing safe and efficient systems. While artificial neural networks have dominated the path to AI, recent studies are exploring the potential of biologically based systems, such as networks of living biological neuronal networks. Along with promises of high power and data efficiency, these systems may also inform more explainable and biologically plausible models.

Method: a framework rooted in active inference, a general theory of behaviour, to model decision-making in embodied agents. Using experiment-informed generative models, we simulate decision-making processes in a simulated game-play environment, mirroring experimental setups that use biological neurons.

Result: Our results demonstrate learning in these agents, providing insights into the role of memory-based learning and predictive planning in intelligent decision-making.

Conclusion: This work contributes to the growing field of explainable AI by offering a biologically grounded and scalable approach to understanding purposeful behaviour in agents.

Abstract: With recent and rapid advancements in artificial intelligence (AI),
understanding the foundation of purposeful behaviour in autonomous agents is
crucial for developing safe and efficient systems. While artificial neural
networks have dominated the path to AI, recent studies are exploring the
potential of biologically based systems, such as networks of living biological
neuronal networks. Along with promises of high power and data efficiency, these
systems may also inform more explainable and biologically plausible models. In
this work, we propose a framework rooted in active inference, a general theory
of behaviour, to model decision-making in embodied agents. Using
experiment-informed generative models, we simulate decision-making processes in
a simulated game-play environment, mirroring experimental setups that use
biological neurons. Our results demonstrate learning in these agents, providing
insights into the role of memory-based learning and predictive planning in
intelligent decision-making. This work contributes to the growing field of
explainable AI by offering a biologically grounded and scalable approach to
understanding purposeful behaviour in agents.

</details>


### [111] [Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach](https://arxiv.org/abs/2508.07015)
*Hannes Ihalainen,Dieter Vandesande,André Schidler,Jeremias Berg,Bart Bogaerts,Matti Järvisalo*

Main category: cs.AI

TL;DR: We explore alternative algorithmic techniques for hitting set optimization based on different ways of employing pseudo-Boolean (PB) reasoning as well as stochastic local search.


<details>
  <summary>Details</summary>
Motivation: explore alternative algorithmic techniques for hitting set optimization

Method: alternative algorithmic techniques for hitting set optimization based on different ways of employing pseudo-Boolean (PB) reasoning as well as stochastic local search

Result: a trade-off between efficiency and reliability, while a commercial IP solver turns out to remain the most effective way to instantiate HS computations, it can cause correctness issues due to numerical instability

Conclusion: exact HS computations instantiated via PB reasoning can be made competitive with a numerically exact IP solver. Furthermore, the use of PB reasoning as a basis for HS computations allows for obtaining certificates for the correctness of IHS computations

Abstract: The implicit hitting set (IHS) approach offers a general framework for
solving computationally hard combinatorial optimization problems declaratively.
IHS iterates between a decision oracle used for extracting sources of
inconsistency and an optimizer for computing so-called hitting sets (HSs) over
the accumulated sources of inconsistency. While the decision oracle is
language-specific, the optimizers is usually instantiated through integer
programming.
  We explore alternative algorithmic techniques for hitting set optimization
based on different ways of employing pseudo-Boolean (PB) reasoning as well as
stochastic local search. We extensively evaluate the practical feasibility of
the alternatives in particular in the context of pseudo-Boolean (0-1 IP)
optimization as one of the most recent instantiations of IHS. Highlighting a
trade-off between efficiency and reliability, while a commercial IP solver
turns out to remain the most effective way to instantiate HS computations, it
can cause correctness issues due to numerical instability; in fact, we show
that exact HS computations instantiated via PB reasoning can be made
competitive with a numerically exact IP solver. Furthermore, the use of PB
reasoning as a basis for HS computations allows for obtaining certificates for
the correctness of IHS computations, generally applicable to any IHS
instantiation in which reasoning in the declarative language at hand can be
captured in the PB-based proof format we employ.

</details>


### [112] [MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA](https://arxiv.org/abs/2508.07022)
*Shengtao Wen,Haodong Chen,Yadong Wang,Zhongying Pan,Xiang Chen,Yu Tian,Bo Qian,Dong Liang,Sheng-Jun Huang*

Main category: cs.AI

TL;DR: MultiMedEdit 是一个用于评估临床多模态任务中知识编辑 (KE) 的新基准，结果表明当前的方法在泛化和长尾推理方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 先前的研究已经证明了在通用领域和医学 QA 任务中的有效性，但很少关注多模态医学场景中的 KE。与纯文本设置不同，医学 KE 需要将更新的知识与视觉推理相结合，以支持安全和可解释的临床决策。

Method: 提出了 MultiMedEdit，这是第一个专门用于评估临床多模态任务中 KE 的基准。

Result: 结果表明，当前的方法在泛化和长尾推理方面存在困难，尤其是在复杂的临床工作流程中。效率分析（例如，编辑延迟、内存占用）揭示了跨 KE 范例在实际部署中的实际权衡。

Conclusion: MultiMedEdit 揭示了当前方法的局限性，并为未来开发临床上强大的知识编辑技术奠定了坚实的基础。

Abstract: Knowledge editing (KE) provides a scalable approach for updating factual
knowledge in large language models without full retraining. While previous
studies have demonstrated effectiveness in general domains and medical QA
tasks, little attention has been paid to KE in multimodal medical scenarios.
Unlike text-only settings, medical KE demands integrating updated knowledge
with visual reasoning to support safe and interpretable clinical decisions. To
address this gap, we propose MultiMedEdit, the first benchmark tailored to
evaluating KE in clinical multimodal tasks. Our framework spans both
understanding and reasoning task types, defines a three-dimensional metric
suite (reliability, generality, and locality), and supports cross-paradigm
comparisons across general and domain-specific models. We conduct extensive
experiments under single-editing and lifelong-editing settings. Results suggest
that current methods struggle with generalization and long-tail reasoning,
particularly in complex clinical workflows. We further present an efficiency
analysis (e.g., edit latency, memory footprint), revealing practical trade-offs
in real-world deployment across KE paradigms. Overall, MultiMedEdit not only
reveals the limitations of current approaches but also provides a solid
foundation for developing clinically robust knowledge editing techniques in the
future.

</details>


### [113] [K-Dense Analyst: Towards Fully Automated Scientific Analysis](https://arxiv.org/abs/2508.07043)
*Orion Li,Vinayak Agarwal,Summer Zhou,Ashwin Gopinath,Timothy Kassis*

Main category: cs.AI

TL;DR: K-Dense Analyst 在生物信息学分析中优于 GPT-5，证明了专用系统在弥合科学目标和计算执行方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 现代生物信息学分析的复杂性在数据生成和发展科学见解之间造成了关键差距。虽然大型语言模型 (LLM) 在科学推理方面显示出了希望，但在处理需要迭代计算、工具集成和严格验证的实际分析工作流程时，它们仍然受到根本限制。

Method: K-Dense Analyst，一种分层多代理系统，通过双环架构实现自主生物信息学分析。K-Dense Analyst，是更广泛的 K-Dense 平台的一部分，它使用专用代理将规划与经过验证的执行相结合，以在安全的计算环境中将复杂目标分解为可执行、可验证的任务。

Result: 在 BixBench（一个用于开放式生物分析的综合基准）上，K-Dense Analyst 实现了 29.2% 的准确率，超过了性能最佳的语言模型 (GPT-5) 6.3 个百分点，这意味着比被广泛认为是最强大的 LLM 提高了近 27%。值得注意的是，K-Dense Analyst 使用 Gemini 2.5 Pro 实现了这一性能，而 Gemini 2.5 Pro 直接使用时仅达到 18.3% 的准确率，这表明我们的架构创新释放了远远超出底层模型基线性能的能力。

Conclusion: 自主科学推理需要的不仅仅是增强的语言模型，它还需要能够弥合高级科学目标和低级计算执行之间差距的专用系统。这些结果代表了朝着能够加速生命科学发现的完全自主的计算生物学家的重大进步。

Abstract: The complexity of modern bioinformatics analysis has created a critical gap
between data generation and developing scientific insights. While large
language models (LLMs) have shown promise in scientific reasoning, they remain
fundamentally limited when dealing with real-world analytical workflows that
demand iterative computation, tool integration and rigorous validation. We
introduce K-Dense Analyst, a hierarchical multi-agent system that achieves
autonomous bioinformatics analysis through a dual-loop architecture. K-Dense
Analyst, part of the broader K-Dense platform, couples planning with validated
execution using specialized agents to decompose complex objectives into
executable, verifiable tasks within secure computational environments. On
BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense
Analyst achieves 29.2% accuracy, surpassing the best-performing language model
(GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what
is widely considered the most powerful LLM available. Remarkably, K-Dense
Analyst achieves this performance using Gemini 2.5 Pro, which attains only
18.3% accuracy when used directly, demonstrating that our architectural
innovations unlock capabilities far beyond the underlying model's baseline
performance. Our insights demonstrate that autonomous scientific reasoning
requires more than enhanced language models, it demands purpose-built systems
that can bridge the gap between high-level scientific objectives and low-level
computational execution. These results represent a significant advance toward
fully autonomous computational biologists capable of accelerating discovery
across the life sciences.

</details>


### [114] [Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach](https://arxiv.org/abs/2508.07063)
*Naseem Machlovi,Maryam Saleki,Innocent Ababio,Ruhul Amin*

Main category: cs.AI

TL;DR: LLMs are not reliable moderators due to errors in nuanced moral reasoning. SafePhi, a fine-tuned version of Phi-4, outperforms existing moderators but still needs improvement with more data and human oversight.


<details>
  <summary>Details</summary>
Motivation: AI systems become more integrated into daily life, the need for safer and more reliable moderation has never been greater. LLMs remain prone to errors, particularly in areas requiring nuanced moral reasoning. They struggle with detecting implicit hate, offensive language, and gender biases due to the subjective and context-dependent nature of these issues. Moreover, their reliance on training data can inadvertently reinforce societal biases, leading to inconsistencies and ethical concerns in their outputs.

Method: developed an experimental framework based on state-of-the-art (SOTA) models to assess human emotions and offensive behaviors. The framework introduces a unified benchmark dataset encompassing 49 distinct categories spanning the wide spectrum of human emotions, offensive and hateful text, and gender and racial biases. Furthermore, we introduced SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts

Result: SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively.

Conclusion: LLM moderators consistently underperformed, pressing the need to incorporate more heterogeneous and representative data with human-in-the-loop, for better model robustness and explainability.

Abstract: As AI systems become more integrated into daily life, the need for safer and
more reliable moderation has never been greater. Large Language Models (LLMs)
have demonstrated remarkable capabilities, surpassing earlier models in
complexity and performance. Their evaluation across diverse tasks has
consistently showcased their potential, enabling the development of adaptive
and personalized agents. However, despite these advancements, LLMs remain prone
to errors, particularly in areas requiring nuanced moral reasoning. They
struggle with detecting implicit hate, offensive language, and gender biases
due to the subjective and context-dependent nature of these issues. Moreover,
their reliance on training data can inadvertently reinforce societal biases,
leading to inconsistencies and ethical concerns in their outputs. To explore
the limitations of LLMs in this role, we developed an experimental framework
based on state-of-the-art (SOTA) models to assess human emotions and offensive
behaviors. The framework introduces a unified benchmark dataset encompassing 49
distinct categories spanning the wide spectrum of human emotions, offensive and
hateful text, and gender and racial biases. Furthermore, we introduced SafePhi,
a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and
outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where
OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This
research also highlights the critical domains where LLM moderators consistently
underperformed, pressing the need to incorporate more heterogeneous and
representative data with human-in-the-loop, for better model robustness and
explainability.

</details>


### [115] [Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention](https://arxiv.org/abs/2508.07107)
*Timothy Oluwapelumi Adeyemi,Nadiah Fahad AlOtaibi*

Main category: cs.AI

TL;DR: 该研究提出了一个自适应的学生表现预测系统，通过持续学习干预后的数据来提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的教育机器学习模型是静态的，无法适应新的数据，例如干预后的结果。

Method: 该研究采用LightGBM回归模型，并结合增量再训练方法，构建了一个闭环反馈系统。

Result: 实验结果表明，再训练后RMSE降低了10.7%，并且干预学生的预测分数持续向上调整。

Conclusion: 该研究通过闭环架构的反馈驱动决策支持系统(DSS)，实现了对学生表现预测模型的持续优化，并通过实验验证了该方法在降低RMSE和提高预测准确性方面的有效性。

Abstract: Accurate prediction of student performance is essential for timely academic
intervention. However, most machine learning models in education are static and
cannot adapt when new data, such as post-intervention outcomes, become
available. To address this limitation, we propose a Feedback-Driven Decision
Support System (DSS) with a closed-loop architecture that enables continuous
model refinement. The system integrates a LightGBM-based regressor with
incremental retraining, allowing educators to input updated student results,
which automatically trigger model updates. This adaptive mechanism improves
prediction accuracy by learning from real-world academic progress. The platform
features a Flask-based web interface for real-time interaction and incorporates
SHAP for explainability, ensuring transparency. Experimental results show a
10.7\% reduction in RMSE after retraining, with consistent upward adjustments
in predicted scores for intervened students. By transforming static predictors
into self-improving systems, our approach advances educational analytics toward
human-centered, data-driven, and responsive AI. The framework is designed for
integration into LMS and institutional dashboards.

</details>


### [116] [Multi-Dimensional Summarization Agents with Context-Aware Reasoning over Enterprise Tables](https://arxiv.org/abs/2508.07186)
*Amit Dhanda*

Main category: cs.AI

TL;DR: 我们提出了一个新颖的框架，用于使用基于大型语言模型 (LLM) 的代理来跨多个维度总结结构化的企业数据。


<details>
  <summary>Details</summary>
Motivation: 传统的表到文本模型通常缺乏跨层级结构和上下文感知增量的推理能力，这在业务报告任务中至关重要。

Method: 引入了一个多代理管道，该管道使用代理进行切片、方差检测、上下文构建和基于LLM的生成，从而提取、分析和总结多维数据。

Result: 该框架优于传统方法，对底层数据实现了 83% 的忠实度，对重大变化的覆盖率更高，并且决策关键见解的相关性得分很高 (4.4/5)。

Conclusion: 该框架在Kaggle数据集上的评估表明，与基线表格摘要方法相比，在忠实度、相关性和洞察质量方面有显著提高。

Abstract: We propose a novel framework for summarizing structured enterprise data
across multiple dimensions using large language model (LLM)-based agents.
Traditional table-to-text models often lack the capacity to reason across
hierarchical structures and context-aware deltas, which are essential in
business reporting tasks. Our method introduces a multi-agent pipeline that
extracts, analyzes, and summarizes multi-dimensional data using agents for
slicing, variance detection, context construction, and LLM-based generation.
Our results show that the proposed framework outperforms traditional
approaches, achieving 83\% faithfulness to underlying data, superior coverage
of significant changes, and high relevance scores (4.4/5) for decision-critical
insights. The improvements are especially pronounced in categories involving
subtle trade-offs, such as increased revenue due to price changes amid
declining unit volumes, which competing methods either overlook or address with
limited specificity. We evaluate the framework on Kaggle datasets and
demonstrate significant improvements in faithfulness, relevance, and insight
quality over baseline table summarization approaches.

</details>


### [117] [EndoAgent: A Memory-Guided Reflective Agent for Intelligent Endoscopic Vision-to-Decision Reasoning](https://arxiv.org/abs/2508.07292)
*Yi Tang,Kaini Wang,Yang Chen,Guangquan Zhou*

Main category: cs.AI

TL;DR: EndoAgent是一种用于内窥镜分析的记忆引导代理，它集成了迭代推理与自适应工具选择和协作，在灵活性和推理能力方面均优于通用和医学多模态模型。


<details>
  <summary>Details</summary>
Motivation: 开发通用人工智能 (AI) 系统以支持内窥镜图像诊断是一项新兴的研究重点。现有方法基于大规模预训练，通常缺乏跨任务的统一协调，并且难以处理复杂临床工作流程中所需的多步骤流程。虽然人工智能代理已在跨领域的灵活指令解析和工具集成方面显示出前景，但它们在内窥镜检查中的潜力仍未得到充分探索。

Method: 我们提出了EndoAgent，这是首个用于视觉到决策内窥镜分析的记忆引导代理，它集成了迭代推理与自适应工具选择和协作。它建立在双重记忆设计之上，通过短期行动跟踪确保逻辑连贯性，并通过长期经验学习逐步提高推理敏锐度，从而实现复杂的决策。

Result: EndoAgent始终优于通用和医学多模态模型，展示了其强大的灵活性和推理能力。

Conclusion: EndoAgent在灵活性和推理能力方面均优于通用和医学多模态模型。

Abstract: Developing general artificial intelligence (AI) systems to support endoscopic
image diagnosis is an emerging research priority. Existing methods based on
large-scale pretraining often lack unified coordination across tasks and
struggle to handle the multi-step processes required in complex clinical
workflows. While AI agents have shown promise in flexible instruction parsing
and tool integration across domains, their potential in endoscopy remains
underexplored. To address this gap, we propose EndoAgent, the first
memory-guided agent for vision-to-decision endoscopic analysis that integrates
iterative reasoning with adaptive tool selection and collaboration. Built on a
dual-memory design, it enables sophisticated decision-making by ensuring
logical coherence through short-term action tracking and progressively
enhancing reasoning acuity through long-term experiential learning. To support
diverse clinical tasks, EndoAgent integrates a suite of expert-designed tools
within a unified reasoning loop. We further introduce EndoAgentBench, a
benchmark of 5,709 visual question-answer pairs that assess visual
understanding and language generation capabilities in realistic scenarios.
Extensive experiments show that EndoAgent consistently outperforms both general
and medical multimodal models, exhibiting its strong flexibility and reasoning
capabilities.

</details>


### [118] [Hallucination as a Computational Boundary: A Hierarchy of Inevitability and the Oracle Escape](https://arxiv.org/abs/2508.07334)
*Quan Shi,Wang Xi,Zenghui Ding,Jianqing Gao,Xianjun Yang*

Main category: cs.AI

TL;DR: This paper proves the illusions are inevitable in LLMs and proposes two "escape routes": RAGs and continuous learning.


<details>
  <summary>Details</summary>
Motivation: The illusion phenomenon of large language models (LLMs) is the core obstacle to their reliable deployment.

Method: formalizes the large language model as a probabilistic Turing machine by constructing a "computational necessity hierarchy"

Result: proves the illusions are inevitable on diagonalization, incomputability, and information theory boundaries supported by the new "learner pump lemma"

Conclusion: This article proposes a novel neural game theory framework.

Abstract: The illusion phenomenon of large language models (LLMs) is the core obstacle
to their reliable deployment. This article formalizes the large language model
as a probabilistic Turing machine by constructing a "computational necessity
hierarchy", and for the first time proves the illusions are inevitable on
diagonalization, incomputability, and information theory boundaries supported
by the new "learner pump lemma". However, we propose two "escape routes": one
is to model Retrieval Enhanced Generations (RAGs) as oracle machines, proving
their absolute escape through "computational jumps", providing the first formal
theory for the effectiveness of RAGs; The second is to formalize continuous
learning as an "internalized oracle" mechanism and implement this path through
a novel neural game theory framework.Finally, this article proposes a

</details>


### [119] [Rethinking Domain-Specific LLM Benchmark Construction: A Comprehensiveness-Compactness Approach](https://arxiv.org/abs/2508.07353)
*Rubing Chen,Jiaxin Wu,Jian Wang,Xulu Zhang,Wenqi Fan,Chenghua Lin,Xiao-Yong Wei,Qing Li*

Main category: cs.AI

TL;DR: This paper introduces Comp-Comp, a framework for building better domain-specific benchmarks, arguing against the sole reliance on scaling laws.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the gap in understanding the impact of corpus and question-answer (QA) set design on the precision and recall of domain-specific LLMs.

Method: The paper proposes Comp-Comp, an iterative benchmarking framework based on a comprehensiveness-compactness principle, to guide corpus and QA set construction.

Result: The paper validates the Comp-Comp framework through a case study, resulting in the creation of XUBench, a large-scale and comprehensive closed-domain benchmark.

Conclusion: The paper concludes that the scaling law is not always optimal for domain-specific benchmark construction and proposes the Comp-Comp framework.

Abstract: Numerous benchmarks have been built to evaluate the domain-specific abilities
of large language models (LLMs), highlighting the need for effective and
efficient benchmark construction. Existing domain-specific benchmarks primarily
focus on the scaling law, relying on massive corpora for supervised fine-tuning
or generating extensive question sets for broad coverage. However, the impact
of corpus and question-answer (QA) set design on the precision and recall of
domain-specific LLMs remains unexplored. In this paper, we address this gap and
demonstrate that the scaling law is not always the optimal principle for
benchmark construction in specific domains. Instead, we propose Comp-Comp, an
iterative benchmarking framework based on a comprehensiveness-compactness
principle. Here, comprehensiveness ensures semantic recall of the domain, while
compactness enhances precision, guiding both corpus and QA set construction. To
validate our framework, we conducted a case study in a well-renowned
university, resulting in the creation of XUBench, a large-scale and
comprehensive closed-domain benchmark. Although we use the academic domain as
the case in this work, our Comp-Comp framework is designed to be extensible
beyond academia, providing valuable insights for benchmark construction across
various domains.

</details>


### [120] [Pentest-R1: Towards Autonomous Penetration Testing Reasoning Optimized via Two-Stage Reinforcement Learning](https://arxiv.org/abs/2508.07382)
*He Kong,Die Hu,Jingguo Ge,Liangxiong Li,Hui Li,Tong Li*

Main category: cs.AI

TL;DR: Pentest-R1是一个用于自动化渗透测试的新框架，它使用两阶段强化学习来提高LLM的推理能力，并在基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型在自动化渗透测试领域面临显著的局限性，包括较差的错误处理、低效的推理以及无法自主执行复杂的端到端任务。

Method: 该论文提出了Pentest-R1框架，该框架通过两阶段强化学习流水线优化LLM的推理能力。首先，构建一个包含超过500个真实多步骤演练的数据集，用于离线强化学习，以灌输基础攻击逻辑。随后，通过在线强化学习在交互式CTF环境中对LLM进行微调，直接从环境反馈中学习，以开发强大的错误自我纠正和自适应策略。

Result: Pentest-R1在AutoPenBench上实现了24.2%的成功率，超过了大多数SOTA模型，仅次于Gemini 2.5 Flash。在Cybench上，在无指导任务中达到了15.0%的成功率，为开源LLM建立了新的SOTA，并与顶级专有模型的性能相匹配。

Conclusion: Pentest-R1在网络安全渗透测试任务中表现出色，在AutoPenBench和Cybench基准测试中取得了SOTA结果，证明了其有效性。

Abstract: Automating penetration testing is crucial for enhancing cybersecurity, yet
current Large Language Models (LLMs) face significant limitations in this
domain, including poor error handling, inefficient reasoning, and an inability
to perform complex end-to-end tasks autonomously. To address these challenges,
we introduce Pentest-R1, a novel framework designed to optimize LLM reasoning
capabilities for this task through a two-stage reinforcement learning pipeline.
We first construct a dataset of over 500 real-world, multi-step walkthroughs,
which Pentest-R1 leverages for offline reinforcement learning (RL) to instill
foundational attack logic. Subsequently, the LLM is fine-tuned via online RL in
an interactive Capture The Flag (CTF) environment, where it learns directly
from environmental feedback to develop robust error self-correction and
adaptive strategies. Our extensive experiments on the Cybench and AutoPenBench
benchmarks demonstrate the framework's effectiveness. On AutoPenBench,
Pentest-R1 achieves a 24.2\% success rate, surpassing most state-of-the-art
models and ranking second only to Gemini 2.5 Flash. On Cybench, it attains a
15.0\% success rate in unguided tasks, establishing a new state-of-the-art for
open-source LLMs and matching the performance of top proprietary models.
Ablation studies confirm that the synergy of both training stages is critical
to its success.

</details>


### [121] [Invert4TVG: A Temporal Video Grounding Framework with Inversion Tasks for Enhanced Action Understanding](https://arxiv.org/abs/2508.07388)
*Zhaoyu Chen,Hongnan Lin,Yongwei Nie,Fei Ma,Xuemiao Xu,Fei Yu,Chengjiang Long*

Main category: cs.AI

TL;DR: 提出了Invert4TVG，通过反演任务提升视频时序定位的语义理解和定位精度，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前的方法在优化高时间交并比（IoU）的同时，经常过度拟合该指标，从而损害了视频和查询中的语义动作理解，这是鲁棒TVG的关键因素。

Method: 引入了TVG反演任务（Invert4TVG），这是一个新颖的框架，无需额外数据即可提高定位准确性和动作理解能力。该方法利用从现有TVG注释中派生的三个反演任务：(1) 动词补全，预测视频片段中被屏蔽的动作动词；(2) 动作识别，识别查询描述的动作；(3) 视频描述，生成明确嵌入查询相关动作的视频片段的描述。这些任务通过具有精心设计的奖励函数的强化学习框架与TVG集成，确保了定位和语义的平衡优化。

Result: 实验表明，该方法优于最先进的方法，在Charades-STA上，3B模型的R1@0.7比Time-R1提高了7.1%。

Conclusion: 该方法通过从视频片段中提取查询相关的动作来加强语义理解，从而显著提高了定位准确率的上限。

Abstract: Temporal Video Grounding (TVG) seeks to localize video segments matching a
given textual query. Current methods, while optimizing for high temporal
Intersection-over-Union (IoU), often overfit to this metric, compromising
semantic action understanding in the video and query, a critical factor for
robust TVG. To address this, we introduce Inversion Tasks for TVG (Invert4TVG),
a novel framework that enhances both localization accuracy and action
understanding without additional data. Our approach leverages three inversion
tasks derived from existing TVG annotations: (1) Verb Completion, predicting
masked action verbs in queries from video segments; (2) Action Recognition,
identifying query-described actions; and (3) Video Description, generating
descriptions of video segments that explicitly embed query-relevant actions.
These tasks, integrated with TVG via a reinforcement learning framework with
well-designed reward functions, ensure balanced optimization of localization
and semantics. Experiments show our method outperforms state-of-the-art
approaches, achieving a 7.1\% improvement in R1@0.7 on Charades-STA for a 3B
model compared to Time-R1. By inverting TVG to derive query-related actions
from segments, our approach strengthens semantic understanding, significantly
raising the ceiling of localization accuracy.

</details>


### [122] [Generative AI for Strategic Plan Development](https://arxiv.org/abs/2508.07405)
*Jesse Ponnock*

Main category: cs.AI

TL;DR: GAI can develop strategic plans; BERTopic is effective for theme generation.


<details>
  <summary>Details</summary>
Motivation: AI can augment professional services, particularly in strategic planning for large government organizations.

Method: Evaluated BERTopic and NMF models using GAO reports to generate topics and scored their similarity against strategic plan Vision Elements.

Result: Techniques can generate themes similar to 100% of the evaluated strategic plan elements.

Conclusion: BERTopic performs best in generating themes similar to strategic plan elements, with over half achieving medium or strong correlation.

Abstract: Given recent breakthroughs in Generative Artificial Intelligence (GAI) and
Large Language Models (LLMs), more and more professional services are being
augmented through Artificial Intelligence (AI), which once seemed impossible to
automate. This paper presents a modular model for leveraging GAI in developing
strategic plans for large scale government organizations and evaluates leading
machine learning techniques in their application towards one of the identified
modules. Specifically, the performance of BERTopic and Non-negative Matrix
Factorization (NMF) are evaluated in their ability to use topic modeling to
generate themes representative of Vision Elements within a strategic plan. To
accomplish this, BERTopic and NMF models are trained using a large volume of
reports from the Government Accountability Office (GAO). The generated topics
from each model are then scored for similarity against the Vision Elements of a
published strategic plan and the results are compared. Our results show that
these techniques are capable of generating themes similar to 100% of the
elements being evaluated against. Further, we conclude that BERTopic performs
best in this application with more than half of its correlated topics achieving
a "medium" or "strong" correlation. A capability of GAI-enabled strategic plan
development impacts a multi-billion dollar industry and assists the federal
government in overcoming regulatory requirements which are crucial to the
public good. Further work will focus on the operationalization of the concept
proven in this study as well as viability of the remaining modules in the
proposed model for GAI-generated strategic plans.

</details>


### [123] [A Comprehensive Survey of Self-Evolving AI Agents: A New Paradigm Bridging Foundation Models and Lifelong Agentic Systems](https://arxiv.org/abs/2508.07407)
*Jinyuan Fang,Yanwen Peng,Xi Zhang,Yingxu Wang,Xinhao Yi,Guibin Zhang,Yi Xu,Bin Wu,Siwei Liu,Zihao Li,Zhaochun Ren,Nikos Aletras,Xi Wang,Han Zhou,Zaiqiao Meng*

Main category: cs.AI

TL;DR: This survey reviews self-evolving AI agents, presenting a framework, techniques, and considerations for building more adaptive and autonomous agentic systems.


<details>
  <summary>Details</summary>
Motivation: Existing agent systems rely on static configurations, limiting their ability to adapt to dynamic environments. Self-evolving AI agents can bridge the gap between static foundation models and the continuous adaptability required by lifelong agentic systems.

Method: The survey introduces a unified conceptual framework with four key components: System Inputs, Agent System, Environment, and Optimisers. It then systematically reviews self-evolving techniques targeting different agent system components and investigates domain-specific evolution strategies.

Result: The survey offers a framework for understanding and comparing different strategies, reviews a range of self-evolving techniques, investigates domain-specific strategies, and discusses evaluation, safety, and ethical considerations.

Conclusion: This survey provides a comprehensive review of existing techniques for self-evolving agentic systems, aiming to provide researchers and practitioners with a systematic understanding of self-evolving AI agents.

Abstract: Recent advances in large language models have sparked growing interest in AI
agents capable of solving complex, real-world tasks. However, most existing
agent systems rely on manually crafted configurations that remain static after
deployment, limiting their ability to adapt to dynamic and evolving
environments. To this end, recent research has explored agent evolution
techniques that aim to automatically enhance agent systems based on interaction
data and environmental feedback. This emerging direction lays the foundation
for self-evolving AI agents, which bridge the static capabilities of foundation
models with the continuous adaptability required by lifelong agentic systems.
In this survey, we provide a comprehensive review of existing techniques for
self-evolving agentic systems. Specifically, we first introduce a unified
conceptual framework that abstracts the feedback loop underlying the design of
self-evolving agentic systems. The framework highlights four key components:
System Inputs, Agent System, Environment, and Optimisers, serving as a
foundation for understanding and comparing different strategies. Based on this
framework, we systematically review a wide range of self-evolving techniques
that target different components of the agent system. We also investigate
domain-specific evolution strategies developed for specialised fields such as
biomedicine, programming, and finance, where optimisation objectives are
tightly coupled with domain constraints. In addition, we provide a dedicated
discussion on the evaluation, safety, and ethical considerations for
self-evolving agentic systems, which are critical to ensuring their
effectiveness and reliability. This survey aims to provide researchers and
practitioners with a systematic understanding of self-evolving AI agents,
laying the foundation for the development of more adaptive, autonomous, and
lifelong agentic systems.

</details>


### [124] [Grounding Natural Language for Multi-agent Decision-Making with Multi-agentic LLMs](https://arxiv.org/abs/2508.07466)
*Dom Huh,Prasant Mohapatra*

Main category: cs.AI

TL;DR: This paper introduces a framework for multi-agent LLMs, focusing on prompt engineering, memory, multi-modal processing, and fine-tuning. The design choices are evaluated on game settings.


<details>
  <summary>Details</summary>
Motivation: The establishment of a common language can serve as a powerful asset in ensuring clear communication and understanding amongst agents, facilitating desired coordination and strategies.

Method: We propose a systematic framework for the design of multi-agentic large language models (LLMs), focusing on key integration practices. These include advanced prompt engineering techniques, the development of effective memory architectures, multi-modal information processing, and alignment strategies through fine-tuning algorithms.

Result: We extend the capabilities of large language models (LLMs) by integrating them with advancements in multi-agent decision-making algorithms.

Conclusion: We evaluate these design choices through extensive ablation studies on classic game settings with significant underlying social dilemmas and game-theoretic considerations.

Abstract: Language is a ubiquitous tool that is foundational to reasoning and
collaboration, ranging from everyday interactions to sophisticated
problem-solving tasks. The establishment of a common language can serve as a
powerful asset in ensuring clear communication and understanding amongst
agents, facilitating desired coordination and strategies. In this work, we
extend the capabilities of large language models (LLMs) by integrating them
with advancements in multi-agent decision-making algorithms. We propose a
systematic framework for the design of multi-agentic large language models
(LLMs), focusing on key integration practices. These include advanced prompt
engineering techniques, the development of effective memory architectures,
multi-modal information processing, and alignment strategies through
fine-tuning algorithms. We evaluate these design choices through extensive
ablation studies on classic game settings with significant underlying social
dilemmas and game-theoretic considerations.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [125] [Omni Geometry Representation Learning vs Large Language Models for Geospatial Entity Resolution](https://arxiv.org/abs/2508.06584)
*Kalana Wijegunarathna,Kristin Stock,Christopher B. Jones*

Main category: cs.DB

TL;DR: Omni, a geospatial ER model featuring an omni-geometry encoder, is proposed to address the limitation of existing methods that simplify complex geometries to a single point, resulting in significant loss of spatial information. The model is tested on existing point-only datasets and a new diverse-geometry geospatial ER dataset. Results indicate that Omni produces up to 12% (F1) improvement over existing methods and LLMs show competitive results.


<details>
  <summary>Details</summary>
Motivation: Existing neural approaches simplify complex geometries to a single point, resulting in significant loss of spatial information. Lack of a uniform technique for embedding heterogeneous geometries seamlessly into a neural network framework.

Method: Omni, a geospatial ER model featuring an omni-geometry encoder is proposed. Omni leverages transformer-based pre-trained language models over individual textual attributes of place records in an Attribute Affinity mechanism.

Result: Omni produces up to 12% (F1) improvement over existing methods. LLMs show competitive results.

Conclusion: LLMs are competitive in geospatial ER. Omni produces up to 12% (F1) improvement over existing methods.

Abstract: The development, integration, and maintenance of geospatial databases rely
heavily on efficient and accurate matching procedures of Geospatial Entity
Resolution (ER). While resolution of points-of-interest (POIs) has been widely
addressed, resolution of entities with diverse geometries has been largely
overlooked. This is partly due to the lack of a uniform technique for embedding
heterogeneous geometries seamlessly into a neural network framework. Existing
neural approaches simplify complex geometries to a single point, resulting in
significant loss of spatial information. To address this limitation, we propose
Omni, a geospatial ER model featuring an omni-geometry encoder. This encoder is
capable of embedding point, line, polyline, polygon, and multi-polygon
geometries, enabling the model to capture the complex geospatial intricacies of
the places being compared. Furthermore, Omni leverages transformer-based
pre-trained language models over individual textual attributes of place records
in an Attribute Affinity mechanism. The model is rigorously tested on existing
point-only datasets and a new diverse-geometry geospatial ER dataset. Omni
produces up to 12% (F1) improvement over existing methods.
  Furthermore, we test the potential of Large Language Models (LLMs) to conduct
geospatial ER, experimenting with prompting strategies and learning scenarios,
comparing the results of pre-trained language model-based methods with LLMs.
Results indicate that LLMs show competitive results.

</details>


### [126] [Metadata Management for AI-Augmented Data Workflows](https://arxiv.org/abs/2508.06814)
*Jinjin Zhao,Sanjay Krishnan*

Main category: cs.DB

TL;DR: TableVault, a metadata governance framework designed for human-AI collaborative data creation.


<details>
  <summary>Details</summary>
Motivation: AI-augmented data workflows introduce complex governance challenges, as both human and model-driven processes generate, transform, and consume data artifacts. These workflows blend heterogeneous tools, dynamic execution patterns, and opaque model decisions, making comprehensive metadata capture difficult.

Method: TableVault records ingestion events, traces operation status, links execution parameters to their data origins, and exposes a standardized metadata layer. By combining database-inspired guarantees with AI-oriented design, such as declarative operation builders and lineage-aware references

Result: demonstrate how TableVault preserves detailed lineage and operational context, enabling robust metadata management, even in partially observable execution environments.

Conclusion: TableVault preserves detailed lineage and operational context, enabling robust metadata management, even in partially observable execution environments.

Abstract: AI-augmented data workflows introduce complex governance challenges, as both
human and model-driven processes generate, transform, and consume data
artifacts. These workflows blend heterogeneous tools, dynamic execution
patterns, and opaque model decisions, making comprehensive metadata capture
difficult. In this work, we present TableVault, a metadata governance framework
designed for human-AI collaborative data creation. TableVault records ingestion
events, traces operation status, links execution parameters to their data
origins, and exposes a standardized metadata layer. By combining
database-inspired guarantees with AI-oriented design, such as declarative
operation builders and lineage-aware references, TableVault supports
transparency and reproducibility across mixed human-model pipelines. Through a
document classification case study, we demonstrate how TableVault preserves
detailed lineage and operational context, enabling robust metadata management,
even in partially observable execution environments.

</details>


### [127] [Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption](https://arxiv.org/abs/2508.07044)
*William Zerong Wang,Dongfang Zhao*

Main category: cs.DB

TL;DR: This paper proposes an Additive Homomorphic Encryption (AHE) based solution for privacy-preserving music similarity search, which is more efficient than Fully Homomorphic Encryption (FHE).


<details>
  <summary>Details</summary>
Motivation: Ensuring the privacy of music data in the era of generative AI is challenging because music data is temporal, multimodal, and easily sampled, transformed, and remixed, making its vector embeddings susceptible to misuse. Traditional methods offer limited protection for these embeddings, and standard encryption schemes hinder computation.

Method: This paper proposes a more practical approach using Additive Homomorphic Encryption (AHE) for vector similarity search through inner products of music embeddings to deliver privacy-preserving similarity search.

Result: This paper analyzes threat models unique to music information retrieval systems and provides a theoretical analysis and an efficient AHE-based solution.

Conclusion: This paper demonstrates the efficiency and practicality of the proposed AHE-based approach through empirical evaluation and comparison to FHE schemes on real-world MP3 files.

Abstract: In the era of generative AI, ensuring the privacy of music data presents
unique challenges: unlike static artworks such as images, music data is
inherently temporal and multimodal, and it is sampled, transformed, and remixed
at an unprecedented scale. These characteristics make its core vector
embeddings, i.e, the numerical representations of the music, highly susceptible
to being learned, misused, or even stolen by models without accessing the
original audio files. Traditional methods like copyright licensing and digital
watermarking offer limited protection for these abstract mathematical
representations, thus necessitating a stronger, e.g., cryptographic, approach
to safeguarding the embeddings themselves. Standard encryption schemes, such as
AES, render data unintelligible for computation, making such searches
impossible. While Fully Homomorphic Encryption (FHE) provides a plausible
solution by allowing arbitrary computations on ciphertexts, its substantial
performance overhead remains impractical for large-scale vector similarity
searches. Given this trade-off, we propose a more practical approach using
Additive Homomorphic Encryption (AHE) for vector similarity search. The primary
contributions of this paper are threefold: we analyze threat models unique to
music information retrieval systems; we provide a theoretical analysis and
propose an efficient AHE-based solution through inner products of music
embeddings to deliver privacy-preserving similarity search; and finally, we
demonstrate the efficiency and practicality of the proposed approach through
empirical evaluation and comparison to FHE schemes on real-world MP3 files.

</details>


### [128] [SQL-Exchange: Transforming SQL Queries Across Domains](https://arxiv.org/abs/2508.07087)
*Mohammadreza Daviran,Brian Lin,Davood Rafiei*

Main category: cs.DB

TL;DR: SQL-Exchange maps SQL queries across different database schemas and improves text-to-SQL performance.


<details>
  <summary>Details</summary>
Motivation: mapping SQL queries across different database schemas

Method: a framework for mapping SQL queries across different database schemas by preserving the source query structure while adapting domain-specific elements to align with the target schema

Result: SQL-Exchange is effective across a wide range of schemas and query types

Conclusion: SQL-Exchange is effective across a wide range of schemas and query types. Using mapped queries as in-context examples consistently improves text-to-SQL performance over using queries from the source schema.

Abstract: We introduce SQL-Exchange, a framework for mapping SQL queries across
different database schemas by preserving the source query structure while
adapting domain-specific elements to align with the target schema. We
investigate the conditions under which such mappings are feasible and
beneficial, and examine their impact on enhancing the in-context learning
performance of text-to-SQL systems as a downstream task. Our comprehensive
evaluation across multiple model families and benchmark datasets--assessing
structural alignment with source queries, execution validity on target
databases, and semantic correctness--demonstrates that SQL-Exchange is
effective across a wide range of schemas and query types. Our results further
show that using mapped queries as in-context examples consistently improves
text-to-SQL performance over using queries from the source schema.

</details>


### [129] [Accelerating High-Dimensional Nearest Neighbor Search with Dynamic Query Preference](https://arxiv.org/abs/2508.07218)
*Yunjun Gao,Ruijie Zhao,Zhonggen Li,Baihua Zheng,Yifan Zhu,Zhaoqing Chen*

Main category: cs.DB

TL;DR: Proposes DQF, a Dual-Index Query Framework, to improve ANNS performance by utilizing query frequency, achieving significant speedup without full index reconstruction.


<details>
  <summary>Details</summary>
Motivation: Current graph-based ANNS methods are designed under the assumption of a uniform query distribution. However, in practical scenarios, user preferences and query temporal dynamics lead to some queries being searched for more frequently than others. To fully utilize these characteristics

Method: DQF, a novel Dual-Index Query Framework. This framework comprises a dual-layer index structure and a dynamic search strategy based on a decision tree. The dual-layer index structure comprises a hot index for high-frequency nodes and a full index for the entire dataset, allowing for the separate management of hot and cold queries. Furthermore, we propose a dynamic search strategy that employs a decision tree to adapt to the specific characteristics of each query.

Result: achieves a significant speedup of 2.0-5.7x over state-of-the-art algorithms while maintaining a 95% recall rate

Conclusion: The Dual-Index Query Framework achieves a significant speedup of 2.0-5.7x over state-of-the-art algorithms while maintaining a 95% recall rate and does not require full index reconstruction when query distributions change.

Abstract: Approximate Nearest Neighbor Search (ANNS) is a crucial operation in
databases and artificial intelligence. Current graph-based ANNS methods, such
as HNSW and NSG, have shown remarkable performance but are designed under the
assumption of a uniform query distribution. However, in practical scenarios,
user preferences and query temporal dynamics lead to some queries being
searched for more frequently than others. To fully utilize these
characteristics, we propose DQF, a novel Dual-Index Query Framework. This
framework comprises a dual-layer index structure and a dynamic search strategy
based on a decision tree. The dual-layer index structure comprises a hot index
for high-frequency nodes and a full index for the entire dataset, allowing for
the separate management of hot and cold queries. Furthermore, we propose a
dynamic search strategy that employs a decision tree to adapt to the specific
characteristics of each query. The decision tree evaluates whether a query is
of the high-frequency type to detect the opportunities for early termination on
the dual-layer, avoiding unnecessary searches in the full index. Experimental
results on four real-world datasets demonstrate that the Dual-Index Query
Framework achieves a significant speedup of 2.0-5.7x over state-of-the-art
algorithms while maintaining a 95% recall rate. Importantly, it does not
require full index reconstruction when query distributions change, underscoring
its efficiency and practicality in dynamic query distribution scenarios.

</details>


### [130] [RNA-KG v2.0: An RNA-centered Knowledge Graph with Properties](https://arxiv.org/abs/2508.07427)
*Emanuele Cavalleri,Paolo Perlasca,Marco Mesiti*

Main category: cs.DB

TL;DR: RNA-KG v2.0是一个增强的RNA知识图，具有1亿个手动整理的交互数据，支持上下文感知查询和链接预测。


<details>
  <summary>Details</summary>
Motivation: RNA-KG是一个最近开发的知识图，它整合了从公共数据源中提取的涉及编码和非编码RNA分子的相互作用。它可以用于支持新分子的分类，通过使用链接预测方法识别新的相互作用，并揭示代表实体之间的隐藏模式。

Method: RNA-KG v2.0整合了来自91个链接开放数据存储库和本体的约1亿个手动策划的交互数据。关系通过标准化属性来表征，这些属性捕获了识别它们的特定背景（例如，细胞系、组织、病理状态）。此外，节点还富含详细的属性，例如描述、同义词和来自OBO本体、NCBI存储库、RNAcentral和Ensembl等平台的分子序列。

Result: RNA-KG v2.0整合了约1亿个手动策划的交互数据，这些数据来自91个链接开放数据存储库和本体。关系通过标准化属性来表征，这些属性捕获了识别它们的特定背景。此外，节点还富含详细的属性，例如描述、同义词和分子序列。

Conclusion: RNA-KG v2.0是一个增强的知识库，它支持考虑到实验背景的高级查询，并支持RNA研究中的下游应用，包括“上下文感知”的链接预测技术，该技术结合了拓扑和语义信息。

Abstract: RNA-KG is a recently developed knowledge graph that integrates the
interactions involving coding and non-coding RNA molecules extracted from
public data sources. It can be used to support the classification of new
molecules, identify new interactions through the use of link prediction
methods, and reveal hidden patterns among the represented entities. In this
paper, we propose RNA-KG v2.0, a new release of RNA-KG that integrates around
100M manually curated interactions sourced from 91 linked open data
repositories and ontologies. Relationships are characterized by standardized
properties that capture the specific context (e.g., cell line, tissue,
pathological state) in which they have been identified. In addition, the nodes
are enriched with detailed attributes, such as descriptions, synonyms, and
molecular sequences sourced from platforms such as OBO ontologies, NCBI
repositories, RNAcentral, and Ensembl. The enhanced repository enables the
expression of advanced queries that take into account the context in which the
experiments were conducted. It also supports downstream applications in RNA
research, including "context-aware" link prediction techniques that combine
both topological and semantic information.

</details>


### [131] [A Benchmark for Databases with Varying Value Lengths](https://arxiv.org/abs/2508.07551)
*Danushka Liyanage,Shubham Pandey,Joshua Goldstein,Michael Cahill,Akon Dey,Alan Fekete,Uwe Röhm*

Main category: cs.DB

TL;DR: Extends YCSB to include an 'extend' operation to simulate growing values, revealing performance differences in DBMS backends.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks fail to account for variability in value lengths in real-world workloads, leaving an important aspect of DBMS behavior underexplored.

Method: Extends the Yahoo! Cloud Serving Benchmark (YCSB) to include an "extend" operation, which appends data to record fields, simulating the growth of values over time. Measures the performance of MongoDB, MariaDB with the InnoDB storage engine, and MariaDB with the MyRocks storage engine using this modified benchmark.

Result: Reveals significant performance differences driven by storage engine design and their handling of variable-sized values.

Conclusion: Introduces a novel benchmarking approach to evaluate the impact of growing value sizes and isolate the effect of querying data with a distribution of data sizes from any cost associated with accessing data after a history of updates.

Abstract: The performance of database management systems (DBMS) is traditionally
evaluated using benchmarks that focus on workloads with (almost) fixed record
lengths. However, some real-world workloads in key/value stores, document
databases, and graph databases exhibit significant variability in value
lengths, which can lead to performance anomalies, particularly when popular
records grow disproportionately large. Existing benchmarks fail to account for
this variability, leaving an important aspect of DBMS behavior underexplored.
  In this paper, we address this gap by extending the Yahoo! Cloud Serving
Benchmark (YCSB) to include an "extend" operation, which appends data to record
fields, simulating the growth of values over time. Using this modified
benchmark, we have measured the performance of three popular DBMS backends:
MongoDB, MariaDB with the InnoDB storage engine, and MariaDB with the MyRocks
storage engine. Our experiments alternate between extending values and
executing query workloads, revealing significant performance differences driven
by storage engine design and their handling of variable-sized values.
  Our key contribution is the introduction of a novel benchmarking approach to
evaluate the impact of growing value sizes and isolate the effect of querying
data with a distribution of data sizes from any cost associated with accessing
data after a history of updates. This highlights the need for more
representative benchmarks that capture the dynamic nature of real-world
workloads, providing valuable guidance for both practitioners and researchers.

</details>


### [132] [MLego: Interactive and Scalable Topic Exploration Through Model Reuse](https://arxiv.org/abs/2508.07654)
*Fei Ye,Jiapan Liu,Yinan Jing,Zhenying He,Weirao Wang,X. Sean Wang*

Main category: cs.DB

TL;DR: MLego是一个交互式查询框架，旨在通过利用模型物化和重用，支持实时主题建模分析。


<details>
  <summary>Details</summary>
Motivation: 传统主题建模技术（如潜在狄利克雷分配（LDA））提供了有价值的见解，但计算成本高昂，使其不适用于实时数据分析。尽管分布式训练和快速采样方法的最新进展提高了效率，但实时主题探索仍然是一个重大挑战。

Method: MLego通过利用模型物化和重用，有效地合并物化的主题模型以交互速度构建近似结果，从而支持实时主题建模分析。为了进一步提高效率，我们为单个查询引入了分层计划搜索策略，为批量查询引入了优化的查询重排序技术。

Result: MLego显著降低了计算成本，同时保持了高质量的主题建模结果。

Conclusion: MLego显著降低了计算成本，同时保持了高质量的主题建模结果。MLego通过支持实时、查询驱动的探索，增强了现有的主要集中于用户驱动的主题建模的可视分析方法。这补充了传统方法，并弥合了可扩展主题建模和交互式数据分析之间的差距。

Abstract: With massive texts on social media, users and analysts often rely on topic
modeling techniques to quickly extract key themes and gain insights.
Traditional topic modeling techniques, such as Latent Dirichlet Allocation
(LDA), provide valuable insights but are computationally expensive, making them
impractical for real-time data analysis. Although recent advances in
distributed training and fast sampling methods have improved efficiency,
real-time topic exploration remains a significant challenge. In this paper, we
present MLego, an interactive query framework designed to support real-time
topic modeling analysis by leveraging model materialization and reuse. Instead
of retraining models from scratch, MLego efficiently merges materialized topic
models to construct approximate results at interactive speeds. To further
enhance efficiency, we introduce a hierarchical plan search strategy for single
queries and an optimized query reordering technique for batch queries. We
integrate MLego into a visual analytics prototype system, enabling users to
explore large-scale textual datasets through interactive queries. Extensive
experiments demonstrate that MLego significantly reduces computation costs
while maintaining high-quality topic modeling results. MLego enhances existing
visual analytics approaches, which primarily focus on user-driven topic
modeling, by enabling real-time, query-driven exploration. This complements
traditional methods and bridges the gap between scalable topic modeling and
interactive data analysis.

</details>


### [133] [TQL: Towards Type-Driven Data Discovery](https://arxiv.org/abs/2508.08054)
*Andrew Kang,Sainyam Galhotra*

Main category: cs.DB

TL;DR: This paper introduces TQL, a flexible query language for data discovery that prioritizes user needs and incorporates a type-like system.


<details>
  <summary>Details</summary>
Motivation: Existing query languages for data discovery are system-driven and emphasize database features over user needs. This paper proposes a language-driven approach to data discovery systems.

Method: The paper introduces TQL, a query language with a type-like system.

Result: TQL incorporates a type-like system to encompass downstream transformation-context in its discovery queries. TQL has expanded expressive power in real-life settings.

Conclusion: This paper formally defines the syntax and semantics of TQL, including the underlying evaluation model, and provides a sketch of its implementation. It also compares TQL to existing languages, highlighting its advantages in real-life settings.

Abstract: Existing query languages for data discovery exhibit system-driven designs
that emphasize database features and functionality over user needs. We propose
a re-prioritization of the client through an introduction of a language-driven
approach to data discovery systems that can leverage powerful results from
programming languages research. In this paper, we describe TQL, a flexible and
practical query language which incorporates a type-like system to encompass
downstream transformation-context in its discovery queries. The syntax and
semantics of TQL (including the underlying evaluation model), are formally
defined, and a sketch of its implementation is also provided. Additionally, we
provide comparisons to existing languages for data retrieval and data discovery
to examine the advantages of TQL's expanded expressive power in real-life
settings.

</details>


### [134] [Towards General-Purpose Data Discovery: A Programming Languages Approach](https://arxiv.org/abs/2508.08074)
*Andrew Kang,Yashnil Saha,Sainyam Galhotra*

Main category: cs.DB

TL;DR: This paper introduces TQL, a domain-specific language for data discovery, and characterizes it through an algebraic model.


<details>
  <summary>Details</summary>
Motivation: Efficient and effective data discovery is critical for many modern applications in machine learning and data science. One major bottleneck to the development of a general-purpose data discovery tool is the absence of an expressive formal language, and corresponding implementation, for characterizing and solving generic discovery queries.

Method: TQL, a domain-specific language for data discovery well-designed to leverage and exploit the results of programming languages research in both its syntax and semantics.

Result: N/A

Conclusion: This paper fully and formally characterizes the core language through an algebraic model, Imperative Relational Algebra with Types (ImpRAT), and implements a modular proof-of-concept system prototype.

Abstract: Efficient and effective data discovery is critical for many modern
applications in machine learning and data science. One major bottleneck to the
development of a general-purpose data discovery tool is the absence of an
expressive formal language, and corresponding implementation, for
characterizing and solving generic discovery queries. To this end, we present
TQL, a domain-specific language for data discovery well-designed to leverage
and exploit the results of programming languages research in both its syntax
and semantics. In this paper, we fully and formally characterize the core
language through an algebraic model, Imperative Relational Algebra with Types
(ImpRAT), and implement a modular proof-of-concept system prototype.

</details>


### [135] [Heterogeneity in Entity Matching: A Survey and Experimental Analysis](https://arxiv.org/abs/2508.08076)
*Mohammad Hossein Moslemi,Amir Mousavi,Behshid Behkamal,Mostafa Milani*

Main category: cs.DB

TL;DR: 本研究对异构实体匹配 (HEM) 进行了综述，分析了现有方法的局限性，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 实体匹配 (EM) 在数据集成和分析中至关重要，但在异构环境中面临巨大挑战。

Method: 对现有文献进行分类，区分表示和语义异构性，并根据 FAIR 原则评估现有方法。

Result: 揭示了当前方法的局限性，并指出了未来研究的潜在方向。

Conclusion: 当前方法存在局限性，未来研究方向包括多模态匹配、人机协同、与大型语言模型和知识图谱的更深入集成，以及异构环境中的公平性评估。

Abstract: Entity matching (EM) is a fundamental task in data integration and analytics,
essential for identifying records that refer to the same real-world entity
across diverse sources. In practice, datasets often differ widely in structure,
format, schema, and semantics, creating substantial challenges for EM. We refer
to this setting as Heterogeneous EM (HEM). This survey offers a unified
perspective on HEM by introducing a taxonomy, grounded in prior work, that
distinguishes two primary categories -- representation and semantic
heterogeneity -- and their subtypes. The taxonomy provides a systematic lens
for understanding how variations in data form and meaning shape the complexity
of matching tasks. We then connect this framework to the FAIR principles --
Findability, Accessibility, Interoperability, and Reusability -- demonstrating
how they both reveal the challenges of HEM and suggest strategies for
mitigating them. Building on this foundation, we critically review recent EM
methods, examining their ability to address different heterogeneity types, and
conduct targeted experiments on state-of-the-art models to evaluate their
robustness and adaptability under semantic heterogeneity. Our analysis uncovers
persistent limitations in current approaches and points to promising directions
for future research, including multimodal matching, human-in-the-loop
workflows, deeper integration with large language models and knowledge graphs,
and fairness-aware evaluation in heterogeneous settings.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [136] [BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation](https://arxiv.org/abs/2508.06781)
*Christos Tsirigotis,Vaibhav Adlakha,Joao Monteiro,Aaron Courville,Perouz Taslakian*

Main category: cs.IR

TL;DR: BiXSE 是一种新的训练方法，它利用大型语言模型生成的分级相关性分数来改进密集检索模型，且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 用于密集检索的神经句子嵌入模型通常依赖于二元相关性标签，将查询-文档对视为相关或不相关。然而，现实世界中的相关性通常存在于一个连续统一体上，并且大型语言模型 (LLM) 的最新进展使得扩展细粒度分级相关性标签的生成成为可能。

Method: BiXSE，一种简单有效的逐点训练方法，可优化 LLM 生成的分级相关性分数上的二元交叉熵 (BCE)。

Result: 在句子嵌入 (MMTEB) 和检索基准 (BEIR、TREC-DL) 上的大量实验表明，BiXSE 在 LLM 监督数据上训练时，始终优于基于 softmax 的对比学习 (InfoNCE)，并且匹配或超过强大的成对排序基线。

Conclusion: BiXSE为训练密集检索模型提供了一种稳健、可扩展的替代方案，因为分级相关性监督变得越来越容易获得。

Abstract: Neural sentence embedding models for dense retrieval typically rely on binary
relevance labels, treating query-document pairs as either relevant or
irrelevant. However, real-world relevance often exists on a continuum, and
recent advances in large language models (LLMs) have made it feasible to scale
the generation of fine-grained graded relevance labels. In this work, we
propose BiXSE, a simple and effective pointwise training method that optimizes
binary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE
interprets these scores as probabilistic targets, enabling granular supervision
from a single labeled query-document pair per query. Unlike pairwise or
listwise losses that require multiple annotated comparisons per query, BiXSE
achieves strong performance with reduced annotation and compute costs by
leveraging in-batch negatives. Extensive experiments across sentence embedding
(MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently
outperforms softmax-based contrastive learning (InfoNCE), and matches or
exceeds strong pairwise ranking baselines when trained on LLM-supervised data.
BiXSE offers a robust, scalable alternative for training dense retrieval models
as graded relevance supervision becomes increasingly accessible.

</details>


### [137] [CLAP: Coreference-Linked Augmentation for Passage Retrieval](https://arxiv.org/abs/2508.06941)
*Huanwei Xu,Lin Xu,Liang Yuan*

Main category: cs.IR

TL;DR: CLAP 是一种轻量级的基于 LLM 的扩展框架，它将段落分割成连贯的块，解决共指链，并生成与密集检索器表示对齐的本地化伪查询。


<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型 (LLM) 的段落扩展已显示出增强第一阶段检索的希望，但由于语义漂移以及与其预训练的语义空间的不一致，通常在密集检索器中表现不佳。除此之外，通常只有一部分段落与查询相关，而其余部分会引入噪声——分块技术会加剧这个问题，因为分块技术会破坏共指连续性。

Method: Coreference-Linked Augmentation for Passage Retrieval (CLAP)

Result: CLAP 产生了一致的收益，即使在检索器强度增加的情况下也是如此，使密集检索器能够匹配或超过第二阶段排序器，例如 BM25 + MonoT5-3B，高达 20.68% 的绝对 nDCG@10 提升。

Conclusion: CLAP在各种领域都表现出了一致的提升，即使在检索器强度增加的情况下也是如此，使密集检索器能够匹配或超过第二阶段排序器，例如 BM25 + MonoT5-3B，高达 20.68% 的绝对 nDCG@10 提升。这些改进在领域外设置中尤其显着，在这些设置中，依赖于领域知识的传统 LLM 扩展方法通常会失败。CLAP 采用以逻辑为中心的管道，从而实现稳健的、领域不可知的泛化。

Abstract: Large Language Model (LLM)-based passage expansion has shown promise for
enhancing first-stage retrieval, but often underperforms with dense retrievers
due to semantic drift and misalignment with their pretrained semantic space.
Beyond this, only a portion of a passage is typically relevant to a query,
while the rest introduces noise--an issue compounded by chunking techniques
that break coreference continuity. We propose Coreference-Linked Augmentation
for Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that
segments passages into coherent chunks, resolves coreference chains, and
generates localized pseudo-queries aligned with dense retriever
representations. A simple fusion of global topical signals and fine-grained
subtopic signals achieves robust performance across domains. CLAP yields
consistent gains even as retriever strength increases, enabling dense
retrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B,
with up to 20.68% absolute nDCG@10 improvement. These improvements are
especially notable in out-of-domain settings, where conventional LLM-based
expansion methods relying on domain knowledge often falter. CLAP instead adopts
a logic-centric pipeline that enables robust, domain-agnostic generalization.

</details>


### [138] [Blending Sequential Embeddings, Graphs, and Engineered Features: 4th Place Solution in RecSys Challenge 2025](https://arxiv.org/abs/2508.06970)
*Sergei Makeev,Alexandr Andreev,Vladimir Baikalov,Vladislav Tytskiy,Aleksei Krasilnikov,Kirill Khrylchenko*

Main category: cs.IR

TL;DR: Team ambitious achieved 4th place in the RecSys Challenge 2025 by integrating a sequential encoder, graph neural network, deep cross network, and feature engineering to generate effective user embeddings.


<details>
  <summary>Details</summary>
Motivation: The challenge objective was to generate user embeddings effective across six diverse downstream tasks.

Method: sequential encoder, a graph neural network, a deep cross network, and performance-critical feature engineering

Result: 4th-place solution for the RecSys Challenge 2025

Conclusion: The team ambitious' 4th-place solution integrates a sequential encoder, a graph neural network, a deep cross network, and feature engineering.

Abstract: This paper describes the 4th-place solution by team ambitious for the RecSys
Challenge 2025, organized by Synerise and ACM RecSys, which focused on
universal behavioral modeling. The challenge objective was to generate user
embeddings effective across six diverse downstream tasks. Our solution
integrates (1) a sequential encoder to capture the temporal evolution of user
interests, (2) a graph neural network to enhance generalization, (3) a deep
cross network to model high-order feature interactions, and (4)
performance-critical feature engineering.

</details>


### [139] [ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability](https://arxiv.org/abs/2508.07050)
*Wenhan Liu,Xinyu Ma,Weiwei Sun,Yutao Zhu,Yuchen Li,Dawei Yin,Zhicheng Dou*

Main category: cs.IR

TL;DR: This paper introduces ReasonRank, a reasoning-intensive reranker trained with synthesized data and a two-stage post-training approach, achieving state-of-the-art performance on the BRIGHT leaderboard with lower latency than Rank1.


<details>
  <summary>Details</summary>
Motivation: Existing rerankers perform poorly in many complex ranking scenarios and the ranking ability of reasoning-intensive rerankers remains largely underdeveloped due to the scarcity of reasoning-intensive training data.

Method: The paper proposes an automated reasoning-intensive training data synthesis framework and a two-stage post-training approach, which includes a cold-start supervised fine-tuning (SFT) stage for reasoning pattern learning and a reinforcement learning (RL) stage for further ranking ability enhancement. During the RL stage, a multi-view ranking reward is designed.

Result: The trained ReasonRank outperforms existing baselines significantly, achieves much lower latency than pointwise reranker Rank1 and achieves state-of-the-art (SOTA) performance on the BRIGHT leaderboard.

Conclusion: The trained reasoning-intensive reranker ReasonRank outperforms existing baselines significantly, achieves much lower latency than pointwise reranker Rank1, and achieves state-of-the-art (SOTA) performance 40.6 on the BRIGHT leaderboard.

Abstract: Large Language Model (LLM) based listwise ranking has shown superior
performance in many passage ranking tasks. With the development of Large
Reasoning Models, many studies have demonstrated that step-by-step reasoning
during test-time helps improve listwise ranking performance. However, due to
the scarcity of reasoning-intensive training data, existing rerankers perform
poorly in many complex ranking scenarios and the ranking ability of
reasoning-intensive rerankers remains largely underdeveloped. In this paper, we
first propose an automated reasoning-intensive training data synthesis
framework, which sources training queries and passages from diverse domains and
applies DeepSeek-R1 to generate high-quality training labels. A
self-consistency data filtering mechanism is designed to ensure the data
quality. To empower the listwise reranker with strong reasoning ability, we
further propose a two-stage post-training approach, which includes a cold-start
supervised fine-tuning (SFT) stage for reasoning pattern learning and a
reinforcement learning (RL) stage for further ranking ability enhancement.
During the RL stage, based on the nature of listwise ranking, we design a
multi-view ranking reward, which is more effective than a ranking metric-based
reward. Extensive experiments demonstrate that our trained reasoning-intensive
reranker \textbf{ReasonRank} outperforms existing baselines significantly and
also achieves much lower latency than pointwise reranker Rank1. \textbf{Through
further experiments, our ReasonRank has achieved state-of-the-art (SOTA)
performance 40.6 on the BRIGHT
leaderboard\footnote{https://brightbenchmark.github.io/}.} Our codes are
available at https://github.com/8421BCD/ReasonRank.

</details>


### [140] [Uncertainty-Aware Semantic Decoding for LLM-Based Sequential Recommendation](https://arxiv.org/abs/2508.07210)
*Chenke Yin,Li Fan,Jia Wang,Dongxiao Hu,Haichao Zhang,Chong Zhang,Yang Xiang*

Main category: cs.IR

TL;DR: proposes an Uncertainty-aware Semantic Decoding (USD) framework that combines logit-based clustering with adaptive scoring to improve next-item predictions


<details>
  <summary>Details</summary>
Motivation: large language models rely on decoding strategies developed for natural language processing, which creates a mismatch between text-generation objectives and recommendation next item selection objectives

Method: an Uncertainty-aware Semantic Decoding (USD) framework that combines logit-based clustering with adaptive scoring

Result: gains of 18.5% in HR@3, 11.9% in NDCG@3, and 10.8% in MRR@3 compared to state-of-the-art baselines on Amazon Product datasets (six domains)

Conclusion: integrating semantic clustering and uncertainty assessment yields more reliable and accurate recommendations

Abstract: Large language models have been widely applied to sequential recommendation
tasks, yet during inference, they continue to rely on decoding strategies
developed for natural language processing. This creates a mismatch between
text-generation objectives and recommendation next item selection objectives.
This paper addresses this limitation by proposing an Uncertainty-aware Semantic
Decoding (USD) framework that combines logit-based clustering with adaptive
scoring to improve next-item predictions. Our approach clusters items with
similar logit vectors into semantic equivalence groups, then redistributes
probability mass within these clusters and computes entropy across them to
control item scoring and sampling temperature during recommendation inference.
Experiments on Amazon Product datasets (six domains) gains of 18.5\% in HR@3,
11.9\% in NDCG@3, and 10.8\% in MRR@3 compared to state-of-the-art baselines.
Hyperparameter analysis confirms the optimal parameters among various settings,
and experiments on H\&M, and Netflix datasets indicate that the framework can
adapt to differing recommendation domains. The experimental results confirm
that integrating semantic clustering and uncertainty assessment yields more
reliable and accurate recommendations.

</details>


### [141] [Selection and Exploitation of High-Quality Knowledge from Large Language Models for Recommendation](https://arxiv.org/abs/2508.07223)
*Guanchen Wang,Mingming Ha,Tianbao Ma,Linxun Chen,Zhaojie Liu,Guorui Zhou,Kun Gai*

Main category: cs.IR

TL;DR: Proposes KSER framework to select high-quality knowledge from LLMs for recommendation, using a knowledge filtering module and an embedding spaces alignment module. 


<details>
  <summary>Details</summary>
Motivation: LLMs suffers from issues of hallucination, content redundant, and information homogenization. Directly feeding the generated response embeddings into the recommendation model can lead to unavoidable performance deterioration.

Method: We propose a Knowledge Selection & Exploitation Recommendation (KSER) framework, which effectively select and extracts the high-quality knowledge from LLMs. The framework consists of two key components: a knowledge filtering module and a embedding spaces alignment module. In the knowledge filtering module, a Embedding Selection Filter Network (ESFNet) is designed to assign adaptive weights to different knowledge chunks in different knowledge fields. In the space alignment module, an attention-based architecture is proposed to align the semantic embeddings from LLMs with the feature space used to train the recommendation models. In addition, two training strategies--all-parameters training and extractor-only training--are proposed to flexibly adapt to different downstream tasks and application scenarios, where the extractor-only training strategy offers a novel perspective on knowledge-augmented recommendation.

Result: Experimental results validate the necessity and effectiveness of both the knowledge filtering and alignment modules, and further demonstrate the efficiency and effectiveness of the extractor-only training strategy.

Conclusion: Experimental results validate the necessity and effectiveness of both the knowledge filtering and alignment modules, and further demonstrate the efficiency and effectiveness of the extractor-only training strategy.

Abstract: In recent years, there has been growing interest in leveraging the impressive
generalization capabilities and reasoning ability of large language models
(LLMs) to improve the performance of recommenders. With this operation,
recommenders can access and learn the additional world knowledge and reasoning
information via LLMs. However, in general, for different users and items, the
world knowledge derived from LLMs suffers from issues of hallucination, content
redundant, and information homogenization. Directly feeding the generated
response embeddings into the recommendation model can lead to unavoidable
performance deterioration. To address these challenges, we propose a Knowledge
Selection \& Exploitation Recommendation (KSER) framework, which effectively
select and extracts the high-quality knowledge from LLMs. The framework
consists of two key components: a knowledge filtering module and a embedding
spaces alignment module. In the knowledge filtering module, a Embedding
Selection Filter Network (ESFNet) is designed to assign adaptive weights to
different knowledge chunks in different knowledge fields. In the space
alignment module, an attention-based architecture is proposed to align the
semantic embeddings from LLMs with the feature space used to train the
recommendation models. In addition, two training
strategies--\textbf{all-parameters training} and \textbf{extractor-only
training}--are proposed to flexibly adapt to different downstream tasks and
application scenarios, where the extractor-only training strategy offers a
novel perspective on knowledge-augmented recommendation. Experimental results
validate the necessity and effectiveness of both the knowledge filtering and
alignment modules, and further demonstrate the efficiency and effectiveness of
the extractor-only training strategy.

</details>


### [142] [SocRipple: A Two-Stage Framework for Cold-Start Video Recommendations](https://arxiv.org/abs/2508.07241)
*Amit Jaspal,Kapil Dalwani,Ajantha Ramineni*

Main category: cs.IR

TL;DR: SocRipple通过利用社交关系和KNN搜索，显著提高了冷启动项目的分发，同时保持了用户参与度。


<details>
  <summary>Details</summary>
Motivation: 大多数工业规模的推荐系统都面临着关键的冷启动挑战，新项目缺乏互动历史，使得以个性化的方式分发它们变得困难。由于稀疏的参与信号，标准协作过滤模型的表现不佳，而仅内容方法缺乏用户特定的相关性。

Method: SocRipple，一种新颖的两阶段检索框架，专为基于社交图的平台中的冷启动项目分发而定制。第一阶段利用创建者的社交连接进行有针对性的初始曝光。第二阶段建立在早期参与信号和从历史交互中学习到的稳定用户嵌入的基础上，通过K近邻（KNN）搜索向外“涟漪”。

Result: SocRipple将冷启动项目的分发提高了+36%，同时保持了用户对冷启动项目的参与率。

Conclusion: SocRipple在大型视频平台上将冷启动项目的分发提高了+36%，同时保持了用户对冷启动项目的参与率，有效地平衡了新项目的曝光与个性化推荐。

Abstract: Most industry scale recommender systems face critical cold start challenges
new items lack interaction history, making it difficult to distribute them in a
personalized manner. Standard collaborative filtering models underperform due
to sparse engagement signals, while content only approaches lack user specific
relevance. We propose SocRipple, a novel two stage retrieval framework tailored
for coldstart item distribution in social graph based platforms. Stage 1
leverages the creators social connections for targeted initial exposure. Stage
2 builds on early engagement signals and stable user embeddings learned from
historical interactions to "ripple" outwards via K Nearest Neighbor (KNN)
search. Large scale experiments on a major video platform show that SocRipple
boosts cold start item distribution by +36% while maintaining user engagement
rate on cold start items, effectively balancing new item exposure with
personalized recommendations.

</details>


### [143] [PrLM: Learning Explicit Reasoning for Personalized RAG via Contrastive Reward Optimization](https://arxiv.org/abs/2508.07342)
*Kepu Zhang,Teng Shi,Weijie Yu,Jun Xu*

Main category: cs.IR

TL;DR: PrLM是一种强化学习框架，它训练LLM来显式地推理检索到的用户配置文件，从而在个性化文本生成方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化检索增强生成 (RAG) 方法主要侧重于改进检索，并依赖大型语言模型 (LLM) 将检索到的上下文与查询隐式集成。然而，此类模型通常对检索质量敏感，并且可能生成与用户偏好不符的响应。

Method: 强化学习框架，训练LLM显式推理检索到的用户配置文件。通过对比训练的个性化奖励模型引导，PrLM有效地从用户响应中学习，而无需注释推理路径。

Result: PrLM优于现有方法，并且在不同数量的检索配置文件和不同检索器中保持稳健。

Conclusion: PrLM在三个个性化文本生成数据集上优于现有方法，并且在不同数量的检索配置文件和不同检索器中保持稳健。

Abstract: Personalized retrieval-augmented generation (RAG) aims to produce
user-tailored responses by incorporating retrieved user profiles alongside the
input query. Existing methods primarily focus on improving retrieval and rely
on large language models (LLMs) to implicitly integrate the retrieved context
with the query. However, such models are often sensitive to retrieval quality
and may generate responses that are misaligned with user preferences. To
address this limitation, we propose PrLM, a reinforcement learning framework
that trains LLMs to explicitly reason over retrieved user profiles. Guided by a
contrastively trained personalization reward model, PrLM effectively learns
from user responses without requiring annotated reasoning paths. Experiments on
three personalized text generation datasets show that PrLM outperforms existing
methods and remains robust across varying numbers of retrieved profiles and
different retrievers.

</details>


### [144] [Are Multimodal Embeddings Truly Beneficial for Recommendation? A Deep Dive into Whole vs. Individual Modalities](https://arxiv.org/abs/2508.07399)
*Yu Ye,Junchen Fu,Yu Song,Kaiwen Zheng,Joemon M. Jose*

Main category: cs.IR

TL;DR: A large-scale empirical study examining the role of text and visual embeddings in modern MMRec models, both as a whole and individually. The text modality alone achieves performance comparable to the full multimodal setting in most cases, whereas the image modality alone does not.


<details>
  <summary>Details</summary>
Motivation: This approach is founded on the intuitive assumption that incorporating multimodal embeddings can enhance recommendation performance. However, despite its popularity, this assumption lacks comprehensive empirical verification. This presents a critical research gap.

Method: employ a modality knockout strategy by setting the corresponding embeddings to either constant values or random noise. evaluate 14 widely used state-of-the-art MMRec models.

Result: multimodal embeddings generally enhance recommendation performance. The text modality alone achieves performance comparable to the full multimodal setting in most cases, whereas the image modality alone does not.

Conclusion: multimodal embeddings generally enhance recommendation performance - particularly when integrated through more sophisticated graph-based fusion models. Surprisingly, commonly adopted baseline models with simple fusion schemes, such as VBPR and BM3, show only limited gains.  The text modality alone achieves performance comparable to the full multimodal setting in most cases, whereas the image modality alone does not.

Abstract: Multimodal recommendation (MMRec) has emerged as a mainstream paradigm,
typically leveraging text and visual embeddings extracted from pre-trained
models such as Sentence-BERT, Vision Transformers, and ResNet. This approach is
founded on the intuitive assumption that incorporating multimodal embeddings
can enhance recommendation performance. However, despite its popularity, this
assumption lacks comprehensive empirical verification. This presents a critical
research gap. To address it, we pose the central research question of this
paper: Are multimodal embeddings truly beneficial for recommendation? To answer
this question, we conduct a large-scale empirical study examining the role of
text and visual embeddings in modern MMRec models, both as a whole and
individually. Specifically, we pose two key research questions: (1) Do
multimodal embeddings as a whole improve recommendation performance? (2) Is
each individual modality - text and image - useful when used alone? To isolate
the effect of individual modalities - text or visual - we employ a modality
knockout strategy by setting the corresponding embeddings to either constant
values or random noise. To ensure the scale and comprehensiveness of our study,
we evaluate 14 widely used state-of-the-art MMRec models. Our findings reveal
that: (1) multimodal embeddings generally enhance recommendation performance -
particularly when integrated through more sophisticated graph-based fusion
models. Surprisingly, commonly adopted baseline models with simple fusion
schemes, such as VBPR and BM3, show only limited gains. (2) The text modality
alone achieves performance comparable to the full multimodal setting in most
cases, whereas the image modality alone does not. These results offer
foundational insights and practical guidance for the MMRec community. We will
release our code and datasets to facilitate future research.

</details>


### [145] [Orthogonal Low Rank Embedding Stabilization](https://arxiv.org/abs/2508.07574)
*Kevin Zielnicki,Ko-Jen Hsiao*

Main category: cs.IR

TL;DR: The paper introduces a method to stabilize user/item embeddings across model retraining cycles using orthogonal low-rank transformation.


<details>
  <summary>Details</summary>
Motivation: The instability of embedding spaces across model retraining cycles presents significant challenges to downstream applications using user or item embeddings derived from recommendation systems as input features.

Method: Our approach leverages a combination of efficient low-rank singular value decomposition and orthogonal Procrustes transformation to map embeddings into a standardized space.

Result: This transformation is computationally efficient, lossless, and lightweight, preserving the dot product and inference quality while reducing operational burdens.

Conclusion: This paper introduces a novel orthogonal low-rank transformation methodology designed to stabilize the user/item embedding space, ensuring consistent embedding dimensions across retraining sessions.

Abstract: The instability of embedding spaces across model retraining cycles presents
significant challenges to downstream applications using user or item embeddings
derived from recommendation systems as input features. This paper introduces a
novel orthogonal low-rank transformation methodology designed to stabilize the
user/item embedding space, ensuring consistent embedding dimensions across
retraining sessions. Our approach leverages a combination of efficient low-rank
singular value decomposition and orthogonal Procrustes transformation to map
embeddings into a standardized space. This transformation is computationally
efficient, lossless, and lightweight, preserving the dot product and inference
quality while reducing operational burdens. Unlike existing methods that modify
training objectives or embedding structures, our approach maintains the
integrity of the primary model application and can be seamlessly integrated
with other stabilization techniques.

</details>


### [146] [Towards Comprehensible Recommendation with Large Language Model Fine-tuning](https://arxiv.org/abs/2508.07595)
*Yunze Luo,Yinjie Jiang,Gaode Chen,Xinghua Zhang,Jun Zhang,Jian Liang,Kaigui Bian*

Main category: cs.IR

TL;DR: propose a novel Content Understanding from a Collaborative Perspective framework (CURec), which generates collaborative-aligned content features for more comprehensive recommendations


<details>
  <summary>Details</summary>
Motivation: traditional recommendation approaches primarily rely on ID-based representations or item-side content features, they often fall short in capturing the underlying semantics aligned with user preferences (e.g., recommendation reasons for items), leading to a semantic-collaborative gap.Recently emerged LLM-based feature extraction approaches also face a key challenge: how to ensure that LLMs possess recommendation-aligned reasoning capabilities and can generate accurate, personalized reasons to mitigate the semantic-collaborative gap.

Method: aligns the LLM with recommendation objectives through pretraining, equipping it with instruction-following and chain-of-thought reasoning capabilities. Next, design a reward model inspired by traditional recommendation architectures to evaluate the quality of the recommendation reasons generated by the LLM. Finally, using the reward signals, CURec fine-tunes the LLM through RL and corrects the generated reasons to ensure their accuracy. The corrected reasons are then integrated into a downstream recommender model to enhance comprehensibility and recommendation performance.

Result: corrected reasons are then integrated into a downstream recommender model to enhance comprehensibility and recommendation performance

Conclusion: Extensive experiments on public benchmarks demonstrate the superiority of CURec over existing methods.

Abstract: Recommender systems have become increasingly ubiquitous in daily life. While
traditional recommendation approaches primarily rely on ID-based
representations or item-side content features, they often fall short in
capturing the underlying semantics aligned with user preferences (e.g.,
recommendation reasons for items), leading to a semantic-collaborative gap.
Recently emerged LLM-based feature extraction approaches also face a key
challenge: how to ensure that LLMs possess recommendation-aligned reasoning
capabilities and can generate accurate, personalized reasons to mitigate the
semantic-collaborative gap. To address these issues, we propose a novel Content
Understanding from a Collaborative Perspective framework (CURec), which
generates collaborative-aligned content features for more comprehensive
recommendations. \method first aligns the LLM with recommendation objectives
through pretraining, equipping it with instruction-following and
chain-of-thought reasoning capabilities. Next, we design a reward model
inspired by traditional recommendation architectures to evaluate the quality of
the recommendation reasons generated by the LLM. Finally, using the reward
signals, CURec fine-tunes the LLM through RL and corrects the generated reasons
to ensure their accuracy. The corrected reasons are then integrated into a
downstream recommender model to enhance comprehensibility and recommendation
performance. Extensive experiments on public benchmarks demonstrate the
superiority of CURec over existing methods.

</details>


### [147] [UMRE: A Unified Monotonic Transformation for Ranking Ensemble in Recommender Systems](https://arxiv.org/abs/2508.07613)
*Zhengrui Xu,Zhe Yang,Zhengxiao Guo,Shukai Liu,Luocheng Lin,Xiaoyan Liu,Yongqi Liu,Han Li*

Main category: cs.IR

TL;DR: 提出了一种新的统一单调排序集成(UMRE)框架，以解决传统集成排序方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于手动设计的非线性变换和手动调整的融合权重来平衡相互竞争的目标，这种方法劳动密集，并且在实现帕累托效率方面经常是次优的。

Method: 用无约束单调神经网络(UMNN)代替手工转换，学习有表现力的严格单调函数，然后，采用轻量级排序模型融合预测分数，为每个预测目标分配个性化权重。为了平衡竞争目标，我们进一步引入了帕累托最优策略，在训练过程中自适应地协调任务权重。

Result: UMRE消除了手动调整，保持了排序一致性，并实现了细粒度的个性化。

Conclusion: UMRE在公共推荐数据集和在线A/B测试中表现出令人印象深刻的性能和泛化能力。

Abstract: Industrial recommender systems commonly rely on ensemble sorting (ES) to
combine predictions from multiple behavioral objectives. Traditionally, this
process depends on manually designed nonlinear transformations (e.g.,
polynomial or exponential functions) and hand-tuned fusion weights to balance
competing goals -- an approach that is labor-intensive and frequently
suboptimal in achieving Pareto efficiency. In this paper, we propose a novel
Unified Monotonic Ranking Ensemble (UMRE) framework to address the limitations
of traditional methods in ensemble sorting. UMRE replaces handcrafted
transformations with Unconstrained Monotonic Neural Networks (UMNN), which
learn expressive, strictly monotonic functions through the integration of
positive neural integrals. Subsequently, a lightweight ranking model is
employed to fuse the prediction scores, assigning personalized weights to each
prediction objective. To balance competing goals, we further introduce a Pareto
optimality strategy that adaptively coordinates task weights during training.
UMRE eliminates manual tuning, maintains ranking consistency, and achieves
fine-grained personalization. Experimental results on two public recommendation
datasets (Kuairand and Tenrec) and online A/B tests demonstrate impressive
performance and generalization capabilities.

</details>


### [148] [Encode Me If You Can: Learning Universal User Representations via Event Sequence Autoencoding](https://arxiv.org/abs/2508.07748)
*Anton Klenitskiy,Artem Fatkulin,Daria Denisova,Anton Pembek,Alexey Vasilev*

Main category: cs.IR

TL;DR: 该论文提出了一种基于 GRU 自编码器的通用用户行为表示方法，并在 RecSys Challenge 2025 中取得了第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 构建能够捕捉用户行为基本方面的通用用户表示对于现代机器学习系统至关重要。在实际应用中，用户的历史交互通常是解决各种预测任务的基础，例如流失预测、推荐或终身价值评估。使用在所有此类任务中都有效的、与任务无关的用户表示可以减少对特定于任务的特征工程和模型再训练的需求，从而实现更具可扩展性和效率的机器学习管道。

Method: 提出了一种将用户交互历史转换为单个时间序列，并训练基于 GRU 的自编码器从固定大小的向量重建该序列的方法。此外，还探索了几种生成用户嵌入的替代方法，并将它们的结果向量连接成一个统一的表示。

Result: 该集成策略进一步提高了不同下游任务的泛化能力。

Conclusion: ai_lab_recsys 团队在 RecSys Challenge 2025 中获得第二名，证明了该方法的有效性。

Abstract: Building universal user representations that capture the essential aspects of
user behavior is a crucial task for modern machine learning systems. In
real-world applications, a user's historical interactions often serve as the
foundation for solving a wide range of predictive tasks, such as churn
prediction, recommendations, or lifetime value estimation. Using a
task-independent user representation that is effective across all such tasks
can reduce the need for task-specific feature engineering and model retraining,
leading to more scalable and efficient machine learning pipelines. The goal of
the RecSys Challenge 2025 by Synerise was to develop such Universal Behavioral
Profiles from logs of past user behavior, which included various types of
events such as product purchases, page views, and search queries. We propose a
method that transforms the entire user interaction history into a single
chronological sequence and trains a GRU-based autoencoder to reconstruct this
sequence from a fixed-size vector. If the model can accurately reconstruct the
sequence, the latent vector is expected to capture the key behavioral patterns.
In addition to this core model, we explored several alternative methods for
generating user embeddings and combined them by concatenating their output
vectors into a unified representation. This ensemble strategy further improved
generalization across diverse downstream tasks and helped our team,
ai_lab_recsys, achieve second place in the RecSys Challenge 2025.

</details>


### [149] [Recommendation Is a Dish Better Served Warm](https://arxiv.org/abs/2508.07856)
*Danil Gusak,Nikita Sukhorukov,Evgeny Frolov*

Main category: cs.IR

TL;DR: The paper explores the impact of inconsistent cold-start thresholds in recommender systems, showing that they can lead to data removal or misclassification, thus introducing noise.


<details>
  <summary>Details</summary>
Motivation: Experimental settings typically include filtering out cold users and items based on a minimum interaction threshold. However, these thresholds are often chosen arbitrarily and vary widely across studies, leading to inconsistencies that can significantly affect the comparability and reliability of evaluation results.

Method: The experiments incrementally vary the number of interactions for different items during training, and gradually update the length of user interaction histories during inference. The thresholds are investigated across several widely used datasets, commonly represented in recent papers from top-tier conferences, and on multiple established recommender baselines.

Result: Inconsistent selection of cold-start thresholds can either result in the unnecessary removal of valuable data or lead to the misclassification of cold instances as warm, introducing more noise into the system.

Conclusion: Inconsistent selection of cold-start thresholds can either result in the unnecessary removal of valuable data or lead to the misclassification of cold instances as warm, introducing more noise into the system.

Abstract: In modern recommender systems, experimental settings typically include
filtering out cold users and items based on a minimum interaction threshold.
However, these thresholds are often chosen arbitrarily and vary widely across
studies, leading to inconsistencies that can significantly affect the
comparability and reliability of evaluation results. In this paper, we
systematically explore the cold-start boundary by examining the criteria used
to determine whether a user or an item should be considered cold. Our
experiments incrementally vary the number of interactions for different items
during training, and gradually update the length of user interaction histories
during inference. We investigate the thresholds across several widely used
datasets, commonly represented in recent papers from top-tier conferences, and
on multiple established recommender baselines. Our findings show that
inconsistent selection of cold-start thresholds can either result in the
unnecessary removal of valuable data or lead to the misclassification of cold
instances as warm, introducing more noise into the system.

</details>


### [150] [Careful Queries, Credible Results: Teaching RAG Models Advanced Web Search Tools with Reinforcement Learning](https://arxiv.org/abs/2508.07956)
*Yuqin Dai,Shuo Yang,Guoqing Wang,Yong Deng,Zhanwei Zhang,Jun Yin,Pengyu Zeng,Zhenzhe Ying,Changhua Meng,Can Yi,Yuchen Zhou,Weiqiang Wang,Shuai Lu*

Main category: cs.IR

TL;DR: WebFilter, a novel RAG framework, addresses misinformation and underutilization of web tools in real-world web environments by generating source-restricted queries and filtering out unreliable content, improving answer quality and retrieval precision.


<details>
  <summary>Details</summary>
Motivation: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by integrating up-to-date external knowledge, yet real-world web environments present unique challenges such as pervasive misinformation and the underutilization of web tools.

Method: a novel RAG framework that generates source-restricted queries and filters out unreliable content. This approach combines a retrieval filtering mechanism with a behavior- and outcome-driven reward strategy, optimizing both query formulation and retrieval outcomes.

Result: WebFilter improves answer quality and retrieval precision.

Conclusion: WebFilter improves answer quality and retrieval precision, outperforming existing RAG methods on both in-domain and out-of-domain benchmarks.

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by
integrating up-to-date external knowledge, yet real-world web environments
present unique challenges. These limitations manifest as two key challenges:
pervasive misinformation in the web environment, which introduces unreliable or
misleading content that can degrade retrieval accuracy, and the
underutilization of web tools, which, if effectively employed, could enhance
query precision and help mitigate this noise, ultimately improving the
retrieval results in RAG systems. To address these issues, we propose
WebFilter, a novel RAG framework that generates source-restricted queries and
filters out unreliable content. This approach combines a retrieval filtering
mechanism with a behavior- and outcome-driven reward strategy, optimizing both
query formulation and retrieval outcomes. Extensive experiments demonstrate
that WebFilter improves answer quality and retrieval precision, outperforming
existing RAG methods on both in-domain and out-of-domain benchmarks.

</details>


### [151] [Improving Document Retrieval Coherence for Semantically Equivalent Queries](https://arxiv.org/abs/2508.07975)
*Stefano Campese,Alessandro Moschitti,Ivano Lauriola*

Main category: cs.IR

TL;DR: Proposes a new loss function for training Dense Retrieval models that improves coherence and accuracy by reducing sensitivity to query variations.


<details>
  <summary>Details</summary>
Motivation: Popular DR models are sensitive to query and document lexicon variations, leading to significant differences in retrieved documents.

Method: A variation of the Multi-Negative Ranking loss is proposed to train DR, penalizing discrepancies between top-k ranked documents retrieved for semantically equivalent queries.

Result: Experiments on MS-MARCO, Natural Questions, BEIR, and TREC DL 19/20 show lower sensitivity and higher accuracy with the proposed loss.

Conclusion: Models optimized by the proposed loss exhibit lower sensitivity and higher accuracy.

Abstract: Dense Retrieval (DR) models have proven to be effective for Document
Retrieval and Information Grounding tasks. Usually, these models are trained
and optimized for improving the relevance of top-ranked documents for a given
query. Previous work has shown that popular DR models are sensitive to the
query and document lexicon: small variations of it may lead to a significant
difference in the set of retrieved documents. In this paper, we propose a
variation of the Multi-Negative Ranking loss for training DR that improves the
coherence of models in retrieving the same documents with respect to
semantically similar queries. The loss penalizes discrepancies between the
top-k ranked documents retrieved for diverse but semantic equivalent queries.
We conducted extensive experiments on various datasets, MS-MARCO, Natural
Questions, BEIR, and TREC DL 19/20. The results show that (i) models optimizes
by our loss are subject to lower sensitivity, and, (ii) interestingly, higher
accuracy.

</details>


### [152] [DIVER: A Multi-Stage Approach for Reasoning-intensive Information Retrieval](https://arxiv.org/abs/2508.07995)
*Meixiu Long,Duolin Sun,Dan Yang,Junjie Wang,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu,Jiahai Wang*

Main category: cs.IR

TL;DR: DIVER: a retrieval pipeline tailored for reasoning-intensive information retrieval, achieves state-of-the-art results on the BRIGHT benchmark.


<details>
  <summary>Details</summary>
Motivation: Existing retrievers often struggle to capture real-world queries that involve abstract reasoning, analogical thinking, or multi-step inference.

Method: A retrieval pipeline tailored for reasoning-intensive information retrieval, which consists of four components: document processing, LLM-driven query expansion, a reasoning-enhanced retriever, and a pointwise reranker.

Result: Achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original queries on the BRIGHT benchmark, consistently outperforming competitive reasoning-aware models.

Conclusion: Reasoning-aware retrieval strategies are effective in complex real-world tasks.

Abstract: Retrieval-augmented generation has achieved strong performance on
knowledge-intensive tasks where query-document relevance can be identified
through direct lexical or semantic matches. However, many real-world queries
involve abstract reasoning, analogical thinking, or multi-step inference, which
existing retrievers often struggle to capture. To address this challenge, we
present \textbf{DIVER}, a retrieval pipeline tailored for reasoning-intensive
information retrieval. DIVER consists of four components: document processing
to improve input quality, LLM-driven query expansion via iterative document
interaction, a reasoning-enhanced retriever fine-tuned on synthetic
multi-domain data with hard negatives, and a pointwise reranker that combines
LLM-assigned helpfulness scores with retrieval scores. On the BRIGHT benchmark,
DIVER achieves state-of-the-art nDCG@10 scores of 41.6 and 28.9 on original
queries, consistently outperforming competitive reasoning-aware models. These
results demonstrate the effectiveness of reasoning-aware retrieval strategies
in complex real-world tasks. Our code and retrieval model will be released
soon.

</details>


### [153] [Multi-modal Adaptive Mixture of Experts for Cold-start Recommendation](https://arxiv.org/abs/2508.08042)
*Van-Khang Nguyen,Duc-Hoang Pham,Huy-Son Nguyen,Cam-Van Thi Nguyen,Hoang-Quynh Le,Duc-Trong Le*

Main category: cs.IR

TL;DR: MAMEX是一种新的多模态冷启动推荐框架，它动态地利用来自不同模态的潜在表示，并在冷启动场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 推荐系统在冷启动场景中面临着巨大的挑战，在冷启动场景中，需要将交互历史有限的新项目有效地推荐给用户。虽然多模态数据（例如，图像、文本、音频等）提供了丰富的信息来解决这个问题，但现有的方法通常采用简单的集成方法，如连接、平均池化或固定加权方案，这些方法无法捕捉到模态之间复杂的关系。

Method: 提出了一种新的混合专家 (MoE) 框架MAMEX，用于多模态冷启动推荐，该框架动态地利用来自不同模态的潜在表示。

Result: 在基准数据集上的大量实验表明，MAMEX在冷启动场景中优于最先进的方法，具有更高的准确性和适应性。

Conclusion: MAMEX在冷启动场景中优于现有方法，具有更高的准确性和适应性。

Abstract: Recommendation systems have faced significant challenges in cold-start
scenarios, where new items with a limited history of interaction need to be
effectively recommended to users. Though multimodal data (e.g., images, text,
audio, etc.) offer rich information to address this issue, existing approaches
often employ simplistic integration methods such as concatenation, average
pooling, or fixed weighting schemes, which fail to capture the complex
relationships between modalities. Our study proposes a novel Mixture of Experts
(MoE) framework for multimodal cold-start recommendation, named MAMEX, which
dynamically leverages latent representation from different modalities. MAMEX
utilizes modality-specific expert networks and introduces a learnable gating
mechanism that adaptively weights the contribution of each modality based on
its content characteristics. This approach enables MAMEX to emphasize the most
informative modalities for each item while maintaining robustness when certain
modalities are less relevant or missing. Extensive experiments on benchmark
datasets show that MAMEX outperforms state-of-the-art methods in cold-start
scenarios, with superior accuracy and adaptability. For reproducibility, the
code has been made available on Github https://github.com/L2R-UET/MAMEX.

</details>


### [154] [HierSearch: A Hierarchical Enterprise Deep Search Framework Integrating Local and Web Searches](https://arxiv.org/abs/2508.08088)
*Jiejun Tan,Zhicheng Dou,Yan Yu,Jiehan Cheng,Qiang Ju,Jian Xie,Ji-Rong Wen*

Main category: cs.IR

TL;DR: HierSearch是一种分层Agent深度搜索框架，通过分层强化学习进行训练，优于扁平RL和其他基线。


<details>
  <summary>Details</summary>
Motivation: 企业通常需要能够利用本地和Web语料库上的搜索工具的私有深度搜索系统。仅仅使用扁平强化学习（RL）训练配备多个搜索工具的Agent是一个简单的想法，但它存在训练数据效率低和对复杂工具的掌握程度差等问题。

Method: 分层强化学习训练的分层Agent深度搜索框架HierSearch

Result: HierSearch实现了更好的性能。

Conclusion: HierSearch在六个通用、金融和医疗领域的基准测试中，与扁平RL相比，实现了更好的性能，并且优于各种深度搜索和多源检索增强生成基线。

Abstract: Recently, large reasoning models have demonstrated strong mathematical and
coding abilities, and deep search leverages their reasoning capabilities in
challenging information retrieval tasks. Existing deep search works are
generally limited to a single knowledge source, either local or the Web.
However, enterprises often require private deep search systems that can
leverage search tools over both local and the Web corpus. Simply training an
agent equipped with multiple search tools using flat reinforcement learning
(RL) is a straightforward idea, but it has problems such as low training data
efficiency and poor mastery of complex tools. To address the above issue, we
propose a hierarchical agentic deep search framework, HierSearch, trained with
hierarchical RL. At the low level, a local deep search agent and a Web deep
search agent are trained to retrieve evidence from their corresponding domains.
At the high level, a planner agent coordinates low-level agents and provides
the final answer. Moreover, to prevent direct answer copying and error
propagation, we design a knowledge refiner that filters out hallucinations and
irrelevant evidence returned by low-level agents. Experiments show that
HierSearch achieves better performance compared to flat RL, and outperforms
various deep search and multi-source retrieval-augmented generation baselines
in six benchmarks across general, finance, and medical domains.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [155] [Self-Organizing Survival Manifolds: A Theory for Unsupervised Discovery of Prognostic Structures in Biological Systems](https://arxiv.org/abs/2508.06539)
*Atahan Karagoz*

Main category: cs.LG

TL;DR: This paper introduces Self-Organizing Survival Manifolds (SOSM), a theory that models survival as a geometric property of biological state space, rather than a supervised learning task with annotated labels.


<details>
  <summary>Details</summary>
Motivation: Survival is traditionally modeled as a supervised learning task, reliant on curated outcome labels and fixed covariates. This work rejects that premise. It proposes that survival is not an externally annotated target but a geometric consequence: an emergent property of the curvature and flow inherent in biological state space.

Method: We develop a theory of Self-Organizing Survival Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature geodesic flows on latent manifolds shaped by internal biological constraints. A survival energy functional based on geodesic curvature minimization is introduced and shown to induce structures where prognosis aligns with geometric flow stability. We derive discrete and continuous formulations of the objective and prove theoretical results demonstrating the emergence and convergence of survival-aligned trajectories under biologically plausible conditions.

Result: Health, disease, aging, and death are reframed as geometric phase transitions in the manifold's structure. The framework draws connections to thermodynamic efficiency, entropy flow, Ricci curvature, and optimal transport, grounding survival modeling in physical law.

Conclusion: This theory offers a universal, label-free foundation for modeling survival as a property of form, not annotation-bridging machine learning, biophysics, and the geometry of life itself.

Abstract: Survival is traditionally modeled as a supervised learning task, reliant on
curated outcome labels and fixed covariates. This work rejects that premise. It
proposes that survival is not an externally annotated target but a geometric
consequence: an emergent property of the curvature and flow inherent in
biological state space. We develop a theory of Self-Organizing Survival
Manifolds (SOSM), in which survival-relevant dynamics arise from low-curvature
geodesic flows on latent manifolds shaped by internal biological constraints. A
survival energy functional based on geodesic curvature minimization is
introduced and shown to induce structures where prognosis aligns with geometric
flow stability. We derive discrete and continuous formulations of the objective
and prove theoretical results demonstrating the emergence and convergence of
survival-aligned trajectories under biologically plausible conditions. The
framework draws connections to thermodynamic efficiency, entropy flow, Ricci
curvature, and optimal transport, grounding survival modeling in physical law.
Health, disease, aging, and death are reframed as geometric phase transitions
in the manifold's structure. This theory offers a universal, label-free
foundation for modeling survival as a property of form, not annotation-bridging
machine learning, biophysics, and the geometry of life itself.

</details>


### [156] [Semi-Supervised Supply Chain Fraud Detection with Unsupervised Pre-Filtering](https://arxiv.org/abs/2508.06574)
*Fatemeh Moradi,Mehran Tarif,Mohammadhossein Homaei*

Main category: cs.LG

TL;DR: A two-phase fraud detection framework using Isolation Forest and self-training SVM achieves strong performance on a real-world supply chain dataset despite limited labeled data.


<details>
  <summary>Details</summary>
Motivation: Detecting fraud in modern supply chains is challenging due to the complexity of global networks and the scarcity of labeled data. Traditional methods struggle with class imbalance and limited supervision.

Method: A two-phase learning framework combining Isolation Forest for unsupervised anomaly detection and a self-training Support Vector Machine (SVM) for semi-supervised refinement.

Result: Achieved an F1-score of 0.817 while maintaining a false positive rate below 3.0% on the DataCo Smart Supply Chain Dataset.

Conclusion: The proposed method effectively combines unsupervised pre-filtering with semi-supervised refinement for supply chain fraud detection, achieving an F1-score of 0.817 with a false positive rate below 3.0%. Limitations include concept drift and the need for comparison with deep learning approaches.

Abstract: Detecting fraud in modern supply chains is a growing challenge, driven by the
complexity of global networks and the scarcity of labeled data. Traditional
detection methods often struggle with class imbalance and limited supervision,
reducing their effectiveness in real-world applications. This paper proposes a
novel two-phase learning framework to address these challenges. In the first
phase, the Isolation Forest algorithm performs unsupervised anomaly detection
to identify potential fraud cases and reduce the volume of data requiring
further analysis. In the second phase, a self-training Support Vector Machine
(SVM) refines the predictions using both labeled and high-confidence
pseudo-labeled samples, enabling robust semi-supervised learning. The proposed
method is evaluated on the DataCo Smart Supply Chain Dataset, a comprehensive
real-world supply chain dataset with fraud indicators. It achieves an F1-score
of 0.817 while maintaining a false positive rate below 3.0%. These results
demonstrate the effectiveness and efficiency of combining unsupervised
pre-filtering with semi-supervised refinement for supply chain fraud detection
under real-world constraints, though we acknowledge limitations regarding
concept drift and the need for comparison with deep learning approaches.

</details>


### [157] [GFlowNets for Learning Better Drug-Drug Interaction Representations](https://arxiv.org/abs/2508.06576)
*Azmine Toushik Wasi*

Main category: cs.LG

TL;DR: Proposes a GFlowNet-VGAE framework to address class imbalance in drug-drug interaction prediction by generating synthetic samples for rare classes, improving overall predictive performance.


<details>
  <summary>Details</summary>
Motivation: Severe class imbalance among interaction types limits the effectiveness of predictive models. Common interactions dominate datasets, while rare but critical interactions remain underrepresented, leading to poor model performance on infrequent cases. Existing methods often treat DDI prediction as a binary problem, ignoring class-specific nuances and exacerbating bias toward frequent interactions.

Method: A framework combining Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE) to generate synthetic samples for rare classes.

Result: Improved model balance and generate effective and novel DDI pairs. Enhanced predictive performance across interaction types, ensuring better clinical reliability.

Conclusion: The proposed GFlowNet-VGAE framework enhances predictive performance across drug-drug interaction types, ensuring better clinical reliability by generating synthetic samples for rare classes and improving model balance.

Abstract: Drug-drug interactions pose a significant challenge in clinical pharmacology,
with severe class imbalance among interaction types limiting the effectiveness
of predictive models. Common interactions dominate datasets, while rare but
critical interactions remain underrepresented, leading to poor model
performance on infrequent cases. Existing methods often treat DDI prediction as
a binary problem, ignoring class-specific nuances and exacerbating bias toward
frequent interactions. To address this, we propose a framework combining
Generative Flow Networks (GFlowNet) with Variational Graph Autoencoders (VGAE)
to generate synthetic samples for rare classes, improving model balance and
generate effective and novel DDI pairs. Our approach enhances predictive
performance across interaction types, ensuring better clinical reliability.

</details>


### [158] [Hypergraph Neural Network with State Space Models for Node Classification](https://arxiv.org/abs/2508.06587)
*A. Quadir,M. Tanveer*

Main category: cs.LG

TL;DR: 提出了一种新的超图神经网络 HGMN，它通过结合基于角色和邻接信息的表示来改进节点分类任务。


<details>
  <summary>Details</summary>
Motivation: 传统的 GNN 主要关注节点之间的邻接关系，通常忽略了对于学习更具表现力的节点表示至关重要的丰富的基于角色的特征。现有的用于捕获基于角色的特征的方法在很大程度上是无监督的，并且无法在下游任务中实现最佳性能。

Method: 提出了一种新颖的具有状态空间模型的超图神经网络 (HGMN)，该模型有效地将角色感知表示集成到 GNN 和状态空间模型中。HGMN 利用超图构建技术来建模高阶关系，并通过可学习的 mamba transformer 机制结合基于角色和基于邻接的表示。

Result: 在节点分类任务上，与最先进的 GNN 方法相比，该模型取得了显着的性能改进。这些结果突出了 HGMN 通过有效嵌入基于角色的特征以及邻接信息来提供丰富节点表示的能力。

Conclusion: HGMN通过有效嵌入基于角色的特征和邻接信息，提供丰富的节点表示，使其成为各种基于图的学习应用的多功能且强大的工具。

Abstract: In recent years, graph neural networks (GNNs) have gained significant
attention for node classification tasks on graph-structured data. However,
traditional GNNs primarily focus on adjacency relationships between nodes,
often overlooking the rich role-based characteristics that are crucial for
learning more expressive node representations. Existing methods for capturing
role-based features are largely unsupervised and fail to achieve optimal
performance in downstream tasks. To address these limitations, we propose a
novel hypergraph neural network with state space model (HGMN) that effectively
integrates role-aware representations into GNNs and the state space model. HGMN
utilizes hypergraph construction techniques to model higher-order relationships
and combines role-based and adjacency-based representations through a learnable
mamba transformer mechanism. By leveraging two distinct hypergraph construction
methods-based on node degree and neighborhood levels, it strengthens the
connections among nodes with similar roles, enhancing the model's
representational power. Additionally, the inclusion of hypergraph convolution
layers enables the model to capture complex dependencies within hypergraph
structures. To mitigate the over-smoothing problem inherent in deep GNNs, we
incorporate a residual network, ensuring improved stability and better feature
propagation across layers. Extensive experiments conducted on one newly
introduced dataset and four benchmark datasets demonstrate the superiority of
HGMN. The model achieves significant performance improvements on node
classification tasks compared to state-of-the-art GNN methods. These results
highlight HGMN's ability to provide enriched node representations by
effectively embedding role-based features alongside adjacency information,
making it a versatile and powerful tool for a variety of graph-based learning
applications.

</details>


### [159] [Graph is a Natural Regularization: Revisiting Vector Quantization for Graph Representation Learning](https://arxiv.org/abs/2508.06588)
*Zian Zhai,Fan Li,Xingyu Tan,Xiaoyang Wang,Wenjie Zhang*

Main category: cs.LG

TL;DR: This paper studies codebook collapse in graph VQ, proposes RGVQ to address the issues, and achieves better performance.


<details>
  <summary>Details</summary>
Motivation: codebook collapse, remains underexplored in the graph domain, significantly limiting the expressiveness and generalization of graph tokens.

Method: RGVQ, a novel framework that integrates graph topology and feature similarity as explicit regularization signals to enhance codebook utilization and promote token diversity. RGVQ introduces soft assignments via Gumbel-Softmax reparameterization, ensuring that all codewords receive gradient updates. In addition, RGVQ incorporates a structure-aware contrastive regularization to penalize the token co-assignments among similar node pairs.

Result: codebook collapse consistently occurs when applying VQ to graph data, even with mitigation strategies proposed in vision or language domains.

Conclusion: RGVQ substantially improves codebook utilization and consistently boosts the performance of state-of-the-art graph VQ backbones across multiple downstream tasks, enabling more expressive and transferable graph token representations.

Abstract: Vector Quantization (VQ) has recently emerged as a promising approach for
learning discrete representations of graph-structured data. However, a
fundamental challenge, i.e., codebook collapse, remains underexplored in the
graph domain, significantly limiting the expressiveness and generalization of
graph tokens.In this paper, we present the first empirical study showing that
codebook collapse consistently occurs when applying VQ to graph data, even with
mitigation strategies proposed in vision or language domains. To understand why
graph VQ is particularly vulnerable to collapse, we provide a theoretical
analysis and identify two key factors: early assignment imbalances caused by
redundancy in graph features and structural patterns, and self-reinforcing
optimization loops in deterministic VQ. To address these issues, we propose
RGVQ, a novel framework that integrates graph topology and feature similarity
as explicit regularization signals to enhance codebook utilization and promote
token diversity. RGVQ introduces soft assignments via Gumbel-Softmax
reparameterization, ensuring that all codewords receive gradient updates. In
addition, RGVQ incorporates a structure-aware contrastive regularization to
penalize the token co-assignments among similar node pairs. Extensive
experiments demonstrate that RGVQ substantially improves codebook utilization
and consistently boosts the performance of state-of-the-art graph VQ backbones
across multiple downstream tasks, enabling more expressive and transferable
graph token representations.

</details>


### [160] [A Federated Learning Framework for Handling Subtype Confounding and Heterogeneity in Large-Scale Neuroimaging Diagnosis](https://arxiv.org/abs/2508.06589)
*Xinglin Zhao,Yanwen Wang,Xiaobo Liu,Yanrong Hao,Rui Cao,Xin Wen*

Main category: cs.LG

TL;DR: A federated learning framework is proposed to address data heterogeneity and subtype confounding in neuroimaging CAD systems, which achieved 74.06% accuracy.


<details>
  <summary>Details</summary>
Motivation: Small-sample studies suffer from low reproducibility, while large-scale datasets introduce confounding heterogeneity due to multiple disease subtypes being labeled under a single category.

Method: a novel federated learning framework tailored for neuroimaging CAD systems, including a dynamic navigation module and a meta-integration module

Result: achieved an average accuracy of 74.06% across all tested sites, showcasing its effectiveness in handling subtype heterogeneity and enhancing model generalizability

Conclusion: The proposed federated learning framework advances reliable and reproducible neuroimaging CAD systems, offering significant potential for personalized medicine and clinical decision-making in neurology and psychiatry.

Abstract: Computer-aided diagnosis (CAD) systems play a crucial role in analyzing
neuroimaging data for neurological and psychiatric disorders. However,
small-sample studies suffer from low reproducibility, while large-scale
datasets introduce confounding heterogeneity due to multiple disease subtypes
being labeled under a single category. To address these challenges, we propose
a novel federated learning framework tailored for neuroimaging CAD systems. Our
approach includes a dynamic navigation module that routes samples to the most
suitable local models based on latent subtype representations, and a
meta-integration module that combines predictions from heterogeneous local
models into a unified diagnostic output. We evaluated our framework using a
comprehensive dataset comprising fMRI data from over 1300 MDD patients and 1100
healthy controls across multiple study cohorts. Experimental results
demonstrate significant improvements in diagnostic accuracy and robustness
compared to traditional methods. Specifically, our framework achieved an
average accuracy of 74.06\% across all tested sites, showcasing its
effectiveness in handling subtype heterogeneity and enhancing model
generalizability. Ablation studies further confirmed the importance of both the
dynamic navigation and meta-integration modules in improving performance. By
addressing data heterogeneity and subtype confounding, our framework advances
reliable and reproducible neuroimaging CAD systems, offering significant
potential for personalized medicine and clinical decision-making in neurology
and psychiatry.

</details>


### [161] [Generative Artificial Intelligence Extracts Structure-Function Relationships from Plants for New Materials](https://arxiv.org/abs/2508.06591)
*Rachel K. Luu,Jingyu Deng,Mohammed Shahrudin Ibrahim,Nam-Joon Cho,Ming Dao,Subra Suresh,Markus J. Buehler*

Main category: cs.LG

TL;DR: 将生成式人工智能与材料科学相结合，从植物科学等领域提取见解，设计材料实验。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(llm)通过实现知识检索和创造性构思的新方法，重塑了研究领域。然而，它们在特定学科实验科学中的应用仍然有限，尤其是在材料科学等高度多学科领域。

Method: 集成了生成式人工智能与植物科学、仿生学和材料工程等领域文献的框架，包括微调模型(BioinspiredLLM)、检索增强生成(RAG)、代理系统和分层抽样策略。

Result: 通过真实世界的实施验证了该方法:在实验室测试了LLM生成的程序、材料设计和机械预测，最终制造出一种具有可调形态和可测量剪切强度的新型花粉基粘合剂，为未来植物来源的粘合剂设计奠定了基础。

Conclusion: AI辅助的构思可以驱动现实世界的材料设计，并实现有效的人机协作。

Abstract: Large language models (LLMs) have reshaped the research landscape by enabling
new approaches to knowledge retrieval and creative ideation. Yet their
application in discipline-specific experimental science, particularly in highly
multi-disciplinary domains like materials science, remains limited. We present
a first-of-its-kind framework that integrates generative AI with literature
from hitherto-unconnected fields such as plant science, biomimetics, and
materials engineering to extract insights and design experiments for materials.
We focus on humidity-responsive systems such as pollen-based materials and
Rhapis excelsa (broadleaf lady palm) leaves, which exhibit self-actuation and
adaptive performance. Using a suite of AI tools, including a fine-tuned model
(BioinspiredLLM), Retrieval-Augmented Generation (RAG), agentic systems, and a
Hierarchical Sampling strategy, we extract structure-property relationships and
translate them into new classes of bioinspired materials. Structured inference
protocols generate and evaluate hundreds of hypotheses from a single query,
surfacing novel and experimentally tractable ideas. We validate our approach
through real-world implementation: LLM-generated procedures, materials designs,
and mechanical predictions were tested in the laboratory, culminating in the
fabrication of a novel pollen-based adhesive with tunable morphology and
measured shear strength, establishing a foundation for future plant-derived
adhesive design. This work demonstrates how AI-assisted ideation can drive
real-world materials design and enable effective human-AI collaboration.

</details>


### [162] [Deep Ignorance: Filtering Pretraining Data Builds Tamper-Resistant Safeguards into Open-Weight LLMs](https://arxiv.org/abs/2508.06601)
*Kyle O'Brien,Stephen Casper,Quentin Anthony,Tomek Korbak,Robert Kirk,Xander Davies,Ishan Mishra,Geoffrey Irving,Yarin Gal,Stella Biderman*

Main category: cs.LG

TL;DR: 研究表明，过滤训练数据可以提高开放权重AI系统对篡改攻击的抵抗力，但需要深度防御方法。


<details>
  <summary>Details</summary>
Motivation: 开放权重AI系统容易受到篡改攻击，这些攻击可以通过修改权重或激活来有效地引发有害行为。现有的安全微调方法和其他训练后技术难以使LLM抵抗几十个步骤以上的对抗性微调。

Method: 多阶段可扩展数据过滤管道

Result: 经过过滤的模型对高达10,000步和3亿个token的生物威胁相关文本的对抗性微调攻击表现出很大的抵抗力，比现有的训练后基线高出一个数量级以上，并且没有观察到不相关能力的下降。

Conclusion: 过滤训练数据是开放权重AI系统的一种有希望的防御手段。尽管过滤后的模型缺乏内在的危险知识，但当在上下文中提供此类信息时，它们仍然可以利用这些信息，这表明需要一种深度防御方法。

Abstract: Open-weight AI systems offer unique benefits, including enhanced
transparency, open research, and decentralized access. However, they are
vulnerable to tampering attacks which can efficiently elicit harmful behaviors
by modifying weights or activations. Currently, there is not yet a robust
science of open-weight model risk management. Existing safety fine-tuning
methods and other post-training techniques have struggled to make LLMs
resistant to more than a few dozen steps of adversarial fine-tuning. In this
paper, we investigate whether filtering text about dual-use topics from
training data can prevent unwanted capabilities and serve as a more
tamper-resistant safeguard. We introduce a multi-stage pipeline for scalable
data filtering and show that it offers a tractable and effective method for
minimizing biothreat proxy knowledge in LLMs. We pretrain multiple
6.9B-parameter models from scratch and find that they exhibit substantial
resistance to adversarial fine-tuning attacks on up to 10,000 steps and 300M
tokens of biothreat-related text -- outperforming existing post-training
baselines by over an order of magnitude -- with no observed degradation to
unrelated capabilities. However, while filtered models lack internalized
dangerous knowledge, we find that they can still leverage such information when
it is provided in context (e.g., via search tool augmentation), demonstrating a
need for a defense-in-depth approach. Overall, these findings help to establish
pretraining data curation as a promising layer of defense for open-weight AI
systems.

</details>


### [163] [Local Diffusion Models and Phases of Data Distributions](https://arxiv.org/abs/2508.06614)
*Fangjun Hu,Guangkuo Liu,Yifan Zhang,Xun Gao*

Main category: cs.LG

TL;DR: 扩散模型在合成复杂数据分布方面表现出了非凡的性能。本文提出了一种新的数据分布阶段视角，并证明了局部去噪器保真度的信息论界限。


<details>
  <summary>Details</summary>
Motivation: 普通的扩散模型忽略了这种局部结构，并学习了空间全局分数函数，这些函数通常在计算上是昂贵的。

Method: 我们引入了一种关于数据分布阶段的新视角，它提供了构建计算成本降低的局部去噪器的见解。我们根据条件互信息证明了局部去噪器保真度的信息论界限，并在真实世界的数据集中进行了数值实验。

Result: 反向去噪过程包括一个早期的平凡阶段和一个晚期的数据阶段，夹在局部去噪器必须失效的快速相变之间。

Conclusion: 扩散模型可以使用更简单的局部神经网络来计算分数函数，全局神经网络仅在相位转换的窄时间间隔内是必需的。该结果为研究数据分布的阶段、生成人工智能的更广泛科学以及指导受物理概念启发的神经网络的设计开辟了新的方向。

Abstract: As a class of generative artificial intelligence frameworks inspired by
statistical physics, diffusion models have shown extraordinary performance in
synthesizing complicated data distributions through a denoising process
gradually guided by score functions. Real-life data, like images, is often
spatially structured in low-dimensional spaces. However, ordinary diffusion
models ignore this local structure and learn spatially global score functions,
which are often computationally expensive. In this work, we introduce a new
perspective on the phases of data distributions, which provides insight into
constructing local denoisers with reduced computational costs. We define two
distributions as belonging to the same data distribution phase if they can be
mutually connected via spatially local operations such as local denoisers.
Then, we show that the reverse denoising process consists of an early trivial
phase and a late data phase, sandwiching a rapid phase transition where local
denoisers must fail. To diagnose such phase transitions, we prove an
information-theoretic bound on the fidelity of local denoisers based on
conditional mutual information, and conduct numerical experiments in a
real-world dataset. This work suggests simpler and more efficient architectures
of diffusion models: far from the phase transition point, we can use small
local neural networks to compute the score function; global neural networks are
only necessary around the narrow time interval of phase transitions. This
result also opens up new directions for studying phases of data distributions,
the broader science of generative artificial intelligence, and guiding the
design of neural networks inspired by physics concepts.

</details>


### [164] [From Source to Target: Leveraging Transfer Learning for Predictive Process Monitoring in Organizations](https://arxiv.org/abs/2508.08061)
*Sven Weinzierl,Sandra Zilker,Annina Liessmann,Martin Käppel,Weixin Wang,Martin Matzner*

Main category: cs.LG

TL;DR: 本文提出了一种基于迁移学习的PPM技术，允许没有足够事件数据或其他相关资源的组织实施PPM，以实现有效的决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有的PPM技术需要大量的事件数据或其他相关资源，这可能会阻止一些组织利用PPM。

Method: 本文提出了一种基于迁移学习的PPM技术。

Result: 实验结果表明，知识可以从一个业务流程转移到同一或不同组织中类似的业务流程，以在目标环境中实现有效的PPM。

Conclusion: 知识可以从一个业务流程转移到同一或不同组织中类似的业务流程，以在目标环境中实现有效的PPM。

Abstract: Event logs reflect the behavior of business processes that are mapped in
organizational information systems. Predictive process monitoring (PPM)
transforms these data into value by creating process-related predictions that
provide the insights required for proactive interventions at process runtime.
Existing PPM techniques require sufficient amounts of event data or other
relevant resources that might not be readily available, preventing some
organizations from utilizing PPM. The transfer learning-based PPM technique
presented in this paper allows organizations without suitable event data or
other relevant resources to implement PPM for effective decision support. The
technique is instantiated in two real-life use cases, based on which numerical
experiments are performed using event logs for IT service management processes
in an intra- and inter-organizational setting. The results of the experiments
suggest that knowledge of one business process can be transferred to a similar
business process in the same or a different organization to enable effective
PPM in the target context. With the proposed technique, organizations can
benefit from transfer learning in an intra- and inter-organizational setting,
where resources like pre-trained models are transferred within and across
organizational boundaries.

</details>


### [165] [Generalizing Scaling Laws for Dense and Sparse Large Language Models](https://arxiv.org/abs/2508.06617)
*Md Arafat Hossain,Xingfu Wu,Valerie Taylor,Ali Jannesari*

Main category: cs.LG

TL;DR: Existing scaling laws are architecture-specific. We propose a generalized scaling law applicable to both dense and sparse large language models.


<details>
  <summary>Details</summary>
Motivation: The size and computational cost of training large language models has grown exponentially, motivating researchers to enhance training efficiency. Optimally predicting model size or allocating resources remains a challenge, and existing scaling laws are architecture-specific.

Method: We revisit existing scaling laws and propose a generalized scaling law.

Result: The proposed scaling law provides a unified framework applicable to both dense and sparse large language models. The effectiveness of the proposed scaling law is demonstrated by evaluation and comparison with existing scaling laws.

Conclusion: We propose a generalized scaling law applicable to both dense and sparse large language models and demonstrate its effectiveness by evaluation and comparison with existing scaling laws.

Abstract: Over the past few years, the size of language models has grown exponentially,
as has the computational cost to train these large models. This rapid growth
has motivated researchers to develop new techniques aimed at enhancing the
efficiency of the training process. Despite these advancements, optimally
predicting the model size or allocating optimal resources remains a challenge.
Several efforts have addressed the challenge by proposing different scaling
laws, but almost all of them are architecture-specific (dense or sparse). In
this work we revisit existing scaling laws and propose a generalized scaling
law to provide a unified framework that is applicable to both dense and sparse
large language models. We evaluate and compare our proposed scaling law with
existing scaling laws to demonstrate its effectiveness.

</details>


### [166] [Learning to Forget with Information Divergence Reweighted Objectives for Noisy Labels](https://arxiv.org/abs/2508.06622)
*Jeremiah Birrell,Reza Ebrahimi*

Main category: cs.LG

TL;DR: ANTIDOTE是一种新的噪声标签学习目标函数，通过对抗训练自适应地减少噪声样本的影响，并在各种噪声环境下表现良好。


<details>
  <summary>Details</summary>
Motivation: 在噪声标签下学习是一个挑战，现实环境中标签噪声是固有的，或者对手可以改变训练标签。

Method: 提出了一种新的目标函数ANTIDOTE，它基于信息散度邻域上的松弛定义。

Result: ANTIDOTE能够自适应地减少噪声标签样本的影响，类似于忘记这些样本。在不同水平的对称、非对称、人工标注和真实世界标签噪声的实验中，ANTIDOTE表现出色。

Conclusion: ANTIDOTE在各种噪声标签环境下优于其他损失函数，且时间复杂度与标准交叉熵损失函数相近。

Abstract: We introduce ANTIDOTE, a new class of objectives for learning under noisy
labels which are defined in terms of a relaxation over an
information-divergence neighborhood. Using convex duality, we provide a
reformulation as an adversarial training method that has similar computational
cost to training with standard cross-entropy loss. We show that our approach
adaptively reduces the influence of the samples with noisy labels during
learning, exhibiting a behavior that is analogous to forgetting those samples.
ANTIDOTE is effective in practical environments where label noise is inherent
in the training data or where an adversary can alter the training labels.
Extensive empirical evaluations on different levels of symmetric, asymmetric,
human annotation, and real-world label noise show that ANTIDOTE outperforms
leading comparable losses in the field and enjoys a time complexity that is
very close to that of the standard cross entropy loss.

</details>


### [167] [Early Detection of Pancreatic Cancer Using Multimodal Learning on Electronic Health Record](https://arxiv.org/abs/2508.06627)
*Mosbah Aouad,Anirudh Choudhary,Awais Farooq,Steven Nevers,Lusine Demirkhanyan,Bhrandon Harris,Suguna Pappu,Christopher Gondi,Ravishankar Iyer*

Main category: cs.LG

TL;DR: 该研究提出了一种新的多模态方法，该方法集成了纵向诊断代码历史和从电子健康记录中常规收集的实验室测量数据，以在临床诊断前一年检测PDAC。


<details>
  <summary>Details</summary>
Motivation: 胰腺导管腺癌(PDAC)是最致命的癌症之一，由于缺乏特异性症状和可靠的生物标志物，早期检测仍然是一个主要的临床挑战。

Method: 结合神经控制微分方程对不规则的实验室时间序列进行建模，使用预训练的语言模型和循环网络学习诊断代码轨迹表示，并使用交叉注意机制来捕捉两种模态之间的相互作用。

Result: 在近4700名患者的真实世界数据集上开发和评估了该方法，与最先进的方法相比，AUC显著提高了6.5%至15.5%。

Conclusion: 该模型识别出与PDAC风险升高相关的诊断代码和实验室指标，包括已知的和新的生物标志物。

Abstract: Pancreatic ductal adenocarcinoma (PDAC) is one of the deadliest cancers, and
early detection remains a major clinical challenge due to the absence of
specific symptoms and reliable biomarkers. In this work, we propose a new
multimodal approach that integrates longitudinal diagnosis code histories and
routinely collected laboratory measurements from electronic health records to
detect PDAC up to one year prior to clinical diagnosis. Our method combines
neural controlled differential equations to model irregular lab time series,
pretrained language models and recurrent networks to learn diagnosis code
trajectory representations, and cross-attention mechanisms to capture
interactions between the two modalities. We develop and evaluate our approach
on a real-world dataset of nearly 4,700 patients and achieve significant
improvements in AUC ranging from 6.5% to 15.5% over state-of-the-art methods.
Furthermore, our model identifies diagnosis codes and laboratory panels
associated with elevated PDAC risk, including both established and new
biomarkers. Our code is available at
https://github.com/MosbahAouad/EarlyPDAC-MML.

</details>


### [168] [Using Imperfect Synthetic Data in Downstream Inference Tasks](https://arxiv.org/abs/2508.06635)
*Yewon Byun,Shantanu Gupta,Zachary C. Lipton,Rachel Leah Childers,Bryan Wilder*

Main category: cs.LG

TL;DR: 我们提出了一个新的估计器，它结合了大型语言模型生成的合成数据和真实数据，以提高计算社会科学研究的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的预测和生成越来越多地被探索，以帮助计算社会科学和有限数据制度下的人类受试者研究。从业者可以通过何种方式将这些数据与真实数据相结合，并在其上产生统计上有效的结论，这一点并不明确。

Method: 基于广义矩估计量

Result: 在计算社会科学应用中的不同回归任务中验证了估计器的有限样本性能，证明了经验上的巨大收益。

Conclusion: 引入了一种基于广义矩估计的新估计器，为解决手头挑战提供了一种具有强大理论保证的无超参数解决方案。发现合成数据和真实数据的矩残差之间的相互作用可以改善目标参数的估计。

Abstract: Predictions and generations from large language models are increasingly being
explored as an aid to computational social science and human subject research
in limited data regimes. While previous technical work has explored the
potential to use model-predicted labels for unlabeled data in a principled
manner, there is increasing interest in using large language models to generate
entirely new synthetic samples (also termed as synthetic simulations), such as
in responses to surveys. However, it is not immediately clear by what means
practitioners can combine such data with real data and yet produce
statistically valid conclusions upon them. In this work, we introduce a new
estimator based on generalized method of moments, providing a
hyperparameter-free solution with strong theoretical guarantees to address the
challenge at hand. Surprisingly, we find that interactions between the moment
residuals of synthetic data and those of real data can improve estimates of the
target parameter. We empirically validate the finite-sample performance of our
estimator across different regression tasks in computational social science
applications, demonstrating large empirical gains.

</details>


### [169] [Segmented Confidence Sequences and Multi-Scale Adaptive Confidence Segments for Anomaly Detection in Nonstationary Time Series](https://arxiv.org/abs/2508.06638)
*Muyan Anna Li,Aditi Gautam*

Main category: cs.LG

TL;DR: This paper introduces two adaptive thresholding frameworks, SCS and MACS, for anomaly detection in nonstationary time series data. Experiments show improved F1-score compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: anomaly detection must adapt to nonstationary environments where statistical properties shift over time. Traditional static thresholds are easily rendered obsolete by regime shifts, concept drift, or multi-scale changes

Method: introduce and empirically evaluate two novel adaptive thresholding frameworks: Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence Segments (MACS). Both leverage statistical online learning and segmentation principles for local, contextually sensitive adaptation, maintaining guarantees on false alarm rates even under evolving distributions.

Result: experiments across Wafer Manufacturing benchmark datasets show significant F1-score improvement compared to traditional percentile and rolling quantile approaches

Conclusion: This work demonstrates that robust, statistically principled adaptive thresholds enable reliable, interpretable, and timely detection of diverse real-world anomalies.

Abstract: As time series data become increasingly prevalent in domains such as
manufacturing, IT, and infrastructure monitoring, anomaly detection must adapt
to nonstationary environments where statistical properties shift over time.
Traditional static thresholds are easily rendered obsolete by regime shifts,
concept drift, or multi-scale changes. To address these challenges, we
introduce and empirically evaluate two novel adaptive thresholding frameworks:
Segmented Confidence Sequences (SCS) and Multi-Scale Adaptive Confidence
Segments (MACS). Both leverage statistical online learning and segmentation
principles for local, contextually sensitive adaptation, maintaining guarantees
on false alarm rates even under evolving distributions. Our experiments across
Wafer Manufacturing benchmark datasets show significant F1-score improvement
compared to traditional percentile and rolling quantile approaches. This work
demonstrates that robust, statistically principled adaptive thresholds enable
reliable, interpretable, and timely detection of diverse real-world anomalies.

</details>


### [170] [Fractal Language Modelling by Universal Sequence Maps (USM)](https://arxiv.org/abs/2508.06641)
*Jonas S Almeida,Daniel E Russ,Susana Vinga,Ines Duarte,Lee Mason,Praphulla Bhawsar,Aaron Ge,Arlindo Oliveira,Jeya Balaji Balasubramanian*

Main category: cs.LG

TL;DR: 本文通过解决播种偏差，改进了通用序列图（USM）的双射分形编码，实现了数值定位与序列标识的完全协调，并揭示了USM作为一种高效数值过程的本质。


<details>
  <summary>Details</summary>
Motivation: 随着使用Transformer的语言模型的出现，人们重新燃起了对探索在多个尺度和嵌入维度上以数字方式表示符号序列的编码程序的兴趣。编码解决的挑战是需要唯一保留关于单个符号的连续性的上下文信息的机制，然后可以通过诸如神经网络之类的非线性公式对其进行建模。

Method: 通过解决影响迭代过程的播种偏差来推进通用序列图（USM）的双射分形编码。

Result: 1) 数值定位与序列标识完全协调; 2) 揭示了USM作为一种高效的数值过程，可以收敛到稳定的序列嵌入解决方案的本质。

Conclusion: USM作为一种高效的数值过程，可以收敛到稳定的序列嵌入解决方案。

Abstract: Motivation: With the advent of Language Models using Transformers,
popularized by ChatGPT, there is a renewed interest in exploring encoding
procedures that numerically represent symbolic sequences at multiple scales and
embedding dimensions. The challenge that encoding addresses is the need for
mechanisms that uniquely retain contextual information about the succession of
individual symbols, which can then be modeled by nonlinear formulations such as
neural networks.
  Context: Universal Sequence Maps(USM) are iterated functions that bijectively
encode symbolic sequences onto embedded numerical spaces. USM is composed of
two Chaos Game Representations (CGR), iterated forwardly and backwardly, that
can be projected into the frequency domain (FCGR). The corresponding USM
coordinates can be used to compute a Chebyshev distance metric as well as k-mer
frequencies, without having to recompute the embedded numeric coordinates, and,
paradoxically, allowing for non-integers values of k.
  Results: This report advances the bijective fractal encoding by Universal
Sequence Maps (USM) by resolving seeding biases affecting the iterated process.
The resolution had two results, the first expected, the second an intriguing
outcome: 1) full reconciliation of numeric positioning with sequence identity;
and 2) uncovering the nature of USM as an efficient numeric process converging
towards a steady state sequence embedding solution. We illustrate these results
for genomic sequences because of the convenience of a planar representation
defined by an alphabet with only 4 tokens (the 4 nucleotides). Nevertheless,
the application to alphabet of arbitrary cardinality was found to be
straightforward.

</details>


### [171] [Privacy-Preserving Tabular Synthetic Data Generation Using TabularARGN](https://arxiv.org/abs/2508.06647)
*Andrey Sidorenko,Paul Tiwald*

Main category: cs.LG

TL;DR: TabularARGN 是一种用于生成高质量合成表格数据的神经网络架构，它在隐私和效用之间实现了强大的平衡。


<details>
  <summary>Details</summary>
Motivation: 安全地共享和分析敏感数据集变得至关重要。然而，传统的匿名化技术通常无法充分保护隐私。

Method: 离散化自回归方法

Result: TabularARGN 是一种专门为生成高质量合成表格数据而设计的神经网络架构。

Conclusion: TabularARGN在统计相似性、机器学习效用和检测鲁棒性方面表现出竞争力的结果，并且在成员推理攻击中表现出鲁棒性和有效的隐私-效用平衡。

Abstract: Synthetic data generation has become essential for securely sharing and
analyzing sensitive data sets. Traditional anonymization techniques, however,
often fail to adequately preserve privacy. We introduce the Tabular
Auto-Regressive Generative Network (TabularARGN), a neural network architecture
specifically designed for generating high-quality synthetic tabular data. Using
a discretization-based auto-regressive approach, TabularARGN achieves high data
fidelity while remaining computationally efficient. We evaluate TabularARGN
against existing synthetic data generation methods, showing competitive results
in statistical similarity, machine learning utility, and detection robustness.
We further perform an in-depth privacy evaluation using systematic
membership-inference attacks, highlighting the robustness and effective
privacy-utility balance of our approach.

</details>


### [172] [In-Context Reinforcement Learning via Communicative World Models](https://arxiv.org/abs/2508.06659)
*Fernando Martinez-Lopez,Tao Li,Yingdong Lu,Juntao Chen*

Main category: cs.LG

TL;DR: This paper introduces CORAL, a framework that learns a transferable communicative context by decoupling latent representation learning from control, enabling agents to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation in unseen environments.


<details>
  <summary>Details</summary>
Motivation: Reinforcement learning (RL) agents often struggle to generalize to new tasks and contexts without updating their parameters, mainly because their learned representations and policies are overfit to the specifics of their training environments. To boost agents' in-context RL (ICRL) ability

Method: This work formulates ICRL as a two-agent emergent communication problem and introduces CORAL (Communicative Representation for Adaptive RL), a framework that learns a transferable communicative context by decoupling latent representation learning from control. In CORAL, an Information Agent (IA) is pre-trained as a world model on a diverse distribution of tasks. The emergent communication protocol is shaped by a novel Causal Influence Loss, which measures the effect that the message has on the next action. During deployment, the previously trained IA serves as a fixed contextualizer for a new Control Agent (CA), which learns to solve tasks by interpreting the provided communicative context.

Result: this approach enables the CA to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation with the help of pre-trained IA in entirely unseen sparse-reward environments

Conclusion: This approach enables the CA to achieve significant gains in sample efficiency and successfully perform zero-shot adaptation with the help of pre-trained IA in entirely unseen sparse-reward environments, validating the efficacy of learning a transferable communicative representation.

Abstract: Reinforcement learning (RL) agents often struggle to generalize to new tasks
and contexts without updating their parameters, mainly because their learned
representations and policies are overfit to the specifics of their training
environments. To boost agents' in-context RL (ICRL) ability, this work
formulates ICRL as a two-agent emergent communication problem and introduces
CORAL (Communicative Representation for Adaptive RL), a framework that learns a
transferable communicative context by decoupling latent representation learning
from control. In CORAL, an Information Agent (IA) is pre-trained as a world
model on a diverse distribution of tasks. Its objective is not to maximize task
reward, but to build a world model and distill its understanding into concise
messages. The emergent communication protocol is shaped by a novel Causal
Influence Loss, which measures the effect that the message has on the next
action. During deployment, the previously trained IA serves as a fixed
contextualizer for a new Control Agent (CA), which learns to solve tasks by
interpreting the provided communicative context. Our experiments demonstrate
that this approach enables the CA to achieve significant gains in sample
efficiency and successfully perform zero-shot adaptation with the help of
pre-trained IA in entirely unseen sparse-reward environments, validating the
efficacy of learning a transferable communicative representation.

</details>


### [173] [Transferring Social Network Knowledge from Multiple GNN Teachers to Kolmogorov-Arnold Networks](https://arxiv.org/abs/2508.06663)
*Yuan-Hung Chao,Chia-Hsun Lu,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 将 KAN 集成到 GNN 中，提高了节点分类准确率，并实现了高效的无图推理。


<details>
  <summary>Details</summary>
Motivation: 图神经网络 (GNN) 在图结构化数据上表现出强大的性能，但它们对图连接的依赖通常会限制可扩展性和效率。

Method: 将 KAN 集成到三种流行的 GNN 架构（GAT、SGC 和 APPNP）中，生成 KGAT、KSGC 和 KAPPNP 三个新模型。采用多教师知识融合框架，将来自多个基于 KAN 的 GNN 的知识提炼成一个与图无关的 KAN 学生模型。

Result: 在基准数据集上的实验表明，所提出的模型提高了节点分类精度，并且知识融合方法显着提高了学生模型的性能。

Conclusion: KANs 可以增强 GNN 的表达能力，并实现高效、无图推理。

Abstract: Graph Neural Networks (GNNs) have shown strong performance on
graph-structured data, but their reliance on graph connectivity often limits
scalability and efficiency. Kolmogorov-Arnold Networks (KANs), a recent
architecture with learnable univariate functions, offer strong nonlinear
expressiveness and efficient inference. In this work, we integrate KANs into
three popular GNN architectures-GAT, SGC, and APPNP-resulting in three new
models: KGAT, KSGC, and KAPPNP. We further adopt a multi-teacher knowledge
amalgamation framework, where knowledge from multiple KAN-based GNNs is
distilled into a graph-independent KAN student model. Experiments on benchmark
datasets show that the proposed models improve node classification accuracy,
and the knowledge amalgamation approach significantly boosts student model
performance. Our findings highlight the potential of KANs for enhancing GNN
expressiveness and for enabling efficient, graph-free inference.

</details>


### [174] [Watermarking Kolmogorov-Arnold Networks for Emerging Networked Applications via Activation Perturbation](https://arxiv.org/abs/2508.06676)
*Chia-Hsun Lu,Guan-Jhih Wu,Ya-Chi Ho,Chih-Ya Shen*

Main category: cs.LG

TL;DR: 提出了一种新颖的水印方法，即基于离散余弦变换的激活水印 (DCT-AW)，专为 KAN 定制。


<details>
  <summary>Details</summary>
Motivation: 随着在机器学习中保护知识产权的重要性日益增加，水印技术受到了极大的关注。由于先进的模型越来越多地部署在社交网络分析等领域中，因此对强大模型保护的需求变得更加关键。现有的水印方法虽然已经证明了对传统深度神经网络的有效性，但它们通常无法适应新型架构 Kolmogorov-Arnold Networks (KAN)，后者具有可学习的激活函数。KAN 在建模网络结构化数据中的复杂关系方面具有强大的潜力。然而，它们独特的设计也为水印技术带来了新的挑战。

Method: 基于离散余弦变换的激活水印 (DCT-AW)

Result: DCT-AW具有较小的模型性能影响，并且针对各种水印移除攻击提供了卓越的鲁棒性，包括微调、剪枝和剪枝后重新训练。

Conclusion: DCT-AW具有较小的模型性能影响，并且针对各种水印移除攻击（包括微调、剪枝和剪枝后重新训练）提供了卓越的鲁棒性。

Abstract: With the increasing importance of protecting intellectual property in machine
learning, watermarking techniques have gained significant attention. As
advanced models are increasingly deployed in domains such as social network
analysis, the need for robust model protection becomes even more critical.
While existing watermarking methods have demonstrated effectiveness for
conventional deep neural networks, they often fail to adapt to the novel
architecture, Kolmogorov-Arnold Networks (KAN), which feature learnable
activation functions. KAN holds strong potential for modeling complex
relationships in network-structured data. However, their unique design also
introduces new challenges for watermarking. Therefore, we propose a novel
watermarking method, Discrete Cosine Transform-based Activation Watermarking
(DCT-AW), tailored for KAN. Leveraging the learnable activation functions of
KAN, our method embeds watermarks by perturbing activation outputs using
discrete cosine transform, ensuring compatibility with diverse tasks and
achieving task independence. Experimental results demonstrate that DCT-AW has a
small impact on model performance and provides superior robustness against
various watermark removal attacks, including fine-tuning, pruning, and
retraining after pruning.

</details>


### [175] [Stabilizing Federated Learning under Extreme Heterogeneity with HeteRo-Select](https://arxiv.org/abs/2508.06692)
*Md. Akmol Masud,Md Abrar Jahin,Mahmud Hasan*

Main category: cs.LG

TL;DR: HeteRo-Select, a new federated learning client selection method, improves training stability and accuracy in heterogeneous environments compared to Oort.


<details>
  <summary>Details</summary>
Motivation: Federated Learning (FL) often suffers from training instability due to the diverse nature of client data. Utility-based client selection methods like Oort experience accuracy drops during later training stages.

Method: HeteRo-Select uses a step-by-step scoring system considering client usefulness, fairness, update speed, and data variety. It also shows convergence guarantees under strong regularization.

Result: HeteRo-Select achieves a peak accuracy of 74.75%, a final accuracy of 72.76%, and a minimal stability drop of 1.99% on the CIFAR-10 dataset under significant label skew ($\alpha=0.1$).

Conclusion: HeteRo-Select is a reliable solution for real-world heterogeneous FL problems, achieving better peak accuracy, final accuracy, and training stability compared to existing approaches like Oort.

Abstract: Federated Learning (FL) is a machine learning technique that often suffers
from training instability due to the diverse nature of client data. Although
utility-based client selection methods like Oort are used to converge by
prioritizing high-loss clients, they frequently experience significant drops in
accuracy during later stages of training. We propose a theoretical
HeteRo-Select framework designed to maintain high performance and ensure
long-term training stability. We provide a theoretical analysis showing that
when client data is very different (high heterogeneity), choosing a smart
subset of client participation can reduce communication more effectively
compared to full participation. Our HeteRo-Select method uses a clear,
step-by-step scoring system that considers client usefulness, fairness, update
speed, and data variety. It also shows convergence guarantees under strong
regularization. Our experimental results on the CIFAR-10 dataset under
significant label skew ($\alpha=0.1$) support the theoretical findings. The
HeteRo-Select method performs better than existing approaches in terms of peak
accuracy, final accuracy, and training stability. Specifically, HeteRo-Select
achieves a peak accuracy of $74.75\%$, a final accuracy of $72.76\%$, and a
minimal stability drop of $1.99\%$. In contrast, Oort records a lower peak
accuracy of $73.98\%$, a final accuracy of $71.25\%$, and a larger stability
drop of $2.73\%$. The theoretical foundations and empirical performance in our
study make HeteRo-Select a reliable solution for real-world heterogeneous FL
problems.

</details>


### [176] [CISO: Species Distribution Modeling Conditioned on Incomplete Species Observations](https://arxiv.org/abs/2508.06704)
*Hager Radi Abdelwahed,Mélisande Teng,Robin Zbinden,Laura Pollock,Hugo Larochelle,Devis Tuia,David Rolnick*

Main category: cs.LG

TL;DR: CISO是一种新的深度学习方法，它利用不完整的物种观测数据来改进物种分布模型的预测，优于现有方法，并能识别物种间的潜在相互作用。


<details>
  <summary>Details</summary>
Motivation: 物种分布模型通常忽略了物种间生物相互作用的影响。现有的方法通常假设物种间存在对称的成对关系，并且需要一致的共现数据。然而，物种观测数据稀疏，并且关于其他物种存在或不存在的信息在不同地点差异很大。

Method: 我们提出了CISO，这是一种基于深度学习的物种分布建模方法，它以不完整的物种观测为条件。

Result: 我们的结果表明，包含部分生物信息可以提高在空间上独立的测试集上的预测性能。当以同一数据集中的一个物种子集为条件时，CISO在预测其余物种的分布方面优于其他方法。此外，我们表明结合来自多个数据集的观察结果可以提高性能。

Conclusion: CISO是一种很有前途的生态工具，能够整合不完整的生物信息，并识别来自不同类群的物种之间潜在的相互作用。

Abstract: Species distribution models (SDMs) are widely used to predict species'
geographic distributions, serving as critical tools for ecological research and
conservation planning. Typically, SDMs relate species occurrences to
environmental variables representing abiotic factors, such as temperature,
precipitation, and soil properties. However, species distributions are also
strongly influenced by biotic interactions with other species, which are often
overlooked. While some methods partially address this limitation by
incorporating biotic interactions, they often assume symmetrical pairwise
relationships between species and require consistent co-occurrence data. In
practice, species observations are sparse, and the availability of information
about the presence or absence of other species varies significantly across
locations. To address these challenges, we propose CISO, a deep learning-based
method for species distribution modeling Conditioned on Incomplete Species
Observations. CISO enables predictions to be conditioned on a flexible number
of species observations alongside environmental variables, accommodating the
variability and incompleteness of available biotic data. We demonstrate our
approach using three datasets representing different species groups: sPlotOpen
for plants, SatBird for birds, and a new dataset, SatButterfly, for
butterflies. Our results show that including partial biotic information
improves predictive performance on spatially separate test sets. When
conditioned on a subset of species within the same dataset, CISO outperforms
alternative methods in predicting the distribution of the remaining species.
Furthermore, we show that combining observations from multiple datasets can
improve performance. CISO is a promising ecological tool, capable of
incorporating incomplete biotic information and identifying potential
interactions between species from disparate taxa.

</details>


### [177] [Analysis of Schedule-Free Nonconvex Optimization](https://arxiv.org/abs/2508.06743)
*Connor Brown*

Main category: cs.LG

TL;DR: Extends Schedule-Free (SF) method's horizon-free guarantees to smooth nonconvex optimization with improved convergence rates using a robust Lyapunov framework.


<details>
  <summary>Details</summary>
Motivation: First-order methods underpin most large-scale learning algorithms, yet their classical convergence guarantees hinge on carefully scheduled step-sizes that depend on the total horizon $T$, which is rarely known in advance. The Schedule-Free (SF) method promises optimal performance with hyperparameters that are independent of $T$ by interpolating between Polyak--Ruppert averaging and momentum, but nonconvex analysis of SF has been limited or reliant on strong global assumptions.

Method: introducing a robust Lyapunov framework that, under only L-smoothness and lower-boundedness, reduces SF analysis to a single-step descent inequality

Result: This yields horizon-agnostic bounds in the nonconvex setting: $O(1/
log T)$ for constant step + PR averaging, $O(
log T/T)$ for a linearly growing step-size, and a continuum of $O(T^{-(1-\&alpha)})$ rates for polynomial averaging. We complement these proofs with Performance Estimation Problem (PEP) experiments that numerically validate our rates and suggest that our $O(1/
log T)$ bound on the original nonconvex SF algorithm may tighten to $O(1/T).

Conclusion: This work extends SF's horizon-free guarantees to smooth nonconvex optimization and charts future directions for optimal nonconvex rates.

Abstract: First-order methods underpin most large-scale learning algorithms, yet their
classical convergence guarantees hinge on carefully scheduled step-sizes that
depend on the total horizon $T$, which is rarely known in advance. The
Schedule-Free (SF) method promises optimal performance with hyperparameters
that are independent of $T$ by interpolating between Polyak--Ruppert averaging
and momentum, but nonconvex analysis of SF has been limited or reliant on
strong global assumptions. We introduce a robust Lyapunov framework that, under
only $L$-smoothness and lower-boundedness, reduces SF analysis to a single-step
descent inequality. This yields horizon-agnostic bounds in the nonconvex
setting: $O(1/\log T)$ for constant step + PR averaging, $O(\log T/T)$ for a
linearly growing step-size, and a continuum of $O(T^{-(1-\alpha)})$ rates for
polynomial averaging. We complement these proofs with Performance Estimation
Problem (PEP) experiments that numerically validate our rates and suggest that
our $O(1/\log T)$ bound on the original nonconvex SF algorithm may tighten to
$O(1/T)$. Our work extends SF's horizon-free guarantees to smooth nonconvex
optimization and charts future directions for optimal nonconvex rates.

</details>


### [178] [Fed MobiLLM: Efficient Federated LLM Fine-Tuning over Heterogeneous Mobile Devices via Server Assisted Side-Tuning](https://arxiv.org/abs/2508.06765)
*Xingke Yang,Liang Li,Sicong Li,Liwei Guan,Hao Wang,Xiaoqi Qi,Jiang Liu,Xin Fu,Miao Pan*

Main category: cs.LG

TL;DR: Fed MobiLLM 是一种用于在异构移动设备上进行高效联邦 LLM FT 的新设计，它通过服务器辅助的联邦侧面调整、消除客户端反向传播和自适应层特征对齐来实现。


<details>
  <summary>Details</summary>
Motivation: 在异构移动设备上协同微调 (FT) 大型语言模型 (LLM) 具有巨大的个性化智能应用潜力。然而，这种愿景面临着严峻的系统挑战。传统的联邦 LLM FT 方法给移动硬件带来了过高的计算和内存负担，并且它们的同步模型聚合协议会因速度较慢的设备而停滞。

Method: 提出了一种新颖的联邦侧面调整范例Fed MobiLLM，移动设备使用其冻结的预缩放主干 LLM 对本地数据执行轻量级前向传播计算，然后上传选定的中间激活。服务器独立训练共享的侧面网络，消除客户端反向传播并启用异步更新。引入自适应层特征对齐方法，确保一致的表示以协同调整共享侧网络。

Result: Fed MobiLLM可以保持强大的微调性能，同时实现极低的设备端内存，与现有方法相比，计算开销降低了至少 95.2%，通信成本降低了 93.2%，收敛速度提高了 5.1 倍。

Conclusion: Fed MobiLLM在保持强大的微调性能的同时，实现了极低的设备端内存占用，计算开销降低了至少 95.2%，通信成本降低了 93.2%，收敛速度提高了 5.1 倍。

Abstract: Collaboratively fine-tuning (FT) large language models (LLMs) over
heterogeneous mobile devices fosters immense potential applications of
personalized intelligence. However, such a vision faces critical system
challenges. Conventional federated LLM FT approaches place prohibitive
computational and memory burdens on mobile hardware, and their synchronous
model aggregation protocols stall for slower devices. In this paper, we propose
Fed MobiLLM, a novel design to facilitate efficient federated LLM FT across
mobile devices with diverse computing/communication speeds and local model
architectures. In particular, Fed MobiLLM implements a pioneering
server-assisted federated side-tuning paradigm. Briefly, mobile devices perform
lightweight forward propagation computations on local data using their frozen
pre-scaled backbone LLMs, and then upload selected intermediate activations.
The server trains a shared side-network independently, eliminating client-side
backpropagation and enabling asynchronous updates. To bridge model
heterogeneity across different devices, we introduce an adaptive layer-wise
feature alignment method, which ensures consistent representations for
collaboratively tuning a shared side network. Extensive experimental results
demonstrate that Fed MobiLLM can maintain robust fine-tuning performance while
achieving extremely low on-device memory, with at least 95.2% reduction in
computation overhead, 93.2% reduction in communication costs and 5.1x faster
convergence compared to existing methods, validating its efficacy for practical
LLM adaptation over heterogeneous mobile devices.

</details>


### [179] [TLCCSP: A Scalable Framework for Enhancing Time Series Forecasting with Time-Lagged Cross-Correlations](https://arxiv.org/abs/2508.07016)
*Jianfei Wu,Wenmian Yang,Bingning Liu,Weijia Jia*

Main category: cs.LG

TL;DR: TLCCSP improves time series forecasting by integrating time-lagged cross-correlations, using SSDTW and contrastive learning to reduce MSE and computational time.


<details>
  <summary>Details</summary>
Motivation: Deep learning models often overlook time-lagged cross-correlations between related sequences, which are crucial for capturing complex temporal relationships.

Method: The Sequence Shifted Dynamic Time Warping (SSDTW) algorithm captures lagged correlations, and a contrastive learning-based encoder efficiently approximates SSDTW distances.

Result: TLCCSP reduces mean squared error (MSE) significantly on weather, stock, and real estate datasets, while the contrastive learning approach decreases SSDTW computational time by approximately 99%.

Conclusion: The Time-Lagged Cross-Correlations-based Sequence Prediction framework (TLCCSP) effectively integrates time-lagged cross-correlated sequences, enhancing forecasting accuracy.

Abstract: Time series forecasting is critical across various domains, such as weather,
finance and real estate forecasting, as accurate forecasts support informed
decision-making and risk mitigation. While recent deep learning models have
improved predictive capabilities, they often overlook time-lagged
cross-correlations between related sequences, which are crucial for capturing
complex temporal relationships. To address this, we propose the Time-Lagged
Cross-Correlations-based Sequence Prediction framework (TLCCSP), which enhances
forecasting accuracy by effectively integrating time-lagged cross-correlated
sequences. TLCCSP employs the Sequence Shifted Dynamic Time Warping (SSDTW)
algorithm to capture lagged correlations and a contrastive learning-based
encoder to efficiently approximate SSDTW distances.
  Experimental results on weather, finance and real estate time series datasets
demonstrate the effectiveness of our framework. On the weather dataset, SSDTW
reduces mean squared error (MSE) by 16.01% compared with single-sequence
methods, while the contrastive learning encoder (CLE) further decreases MSE by
17.88%. On the stock dataset, SSDTW achieves a 9.95% MSE reduction, and CLE
reduces it by 6.13%. For the real estate dataset, SSDTW and CLE reduce MSE by
21.29% and 8.62%, respectively. Additionally, the contrastive learning approach
decreases SSDTW computational time by approximately 99%, ensuring scalability
and real-time applicability across multiple time series forecasting tasks.

</details>


### [180] [PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems](https://arxiv.org/abs/2508.06767)
*Arman Dogru,R. Irem Bor-Yaliniz,Nimal Gamini Senarath*

Main category: cs.LG

TL;DR: 本文提出了一种名为PANAMA的算法，用于优化DT生态系统中多智能体路径寻找，通过实验验证了其在准确性、速度和可扩展性方面的优越性，并强调了优化数据共享策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自动化系统的扩展，高效的数据共享框架和强大的算法变得至关重要。探索了数据处理在下一代网络中的关键作用，重点关注DT生态系统中应用程序和网络提供商（AP/NP）之间的动态。

Method: 提出了一种名为PANAMA的新算法，该算法具有优先级不对称性，适用于基于网络感知多智能体强化学习（MARL）的多智能体路径寻找（MAPF）。采用集中式训练和分散式执行（CTDE）框架以及异步actor-learner架构。

Result: PANAMA在准确性、速度和可扩展性方面表现出优于现有基准的寻路性能。通过仿真，突出了可扩展自动化系统的优化数据共享策略，确保了复杂现实环境中的弹性。

Conclusion: PANAMA算法通过优化数据共享策略，实现了在复杂环境中具有弹性的可扩展自动化系统，弥合了网络感知决策和鲁棒多智能体协同之间的差距，促进了DT、无线网络和AI驱动自动化之间的协同。

Abstract: Digital Twins (DTs) are transforming industries through advanced data
processing and analysis, positioning the world of DTs, Digital World, as a
cornerstone of nextgeneration technologies including embodied AI. As robotics
and automated systems scale, efficient data-sharing frameworks and robust
algorithms become critical. We explore the pivotal role of data handling in
next-gen networks, focusing on dynamics between application and network
providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with
Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL)
based multi-agent path finding (MAPF). By adopting a Centralized Training with
Decentralized Execution (CTDE) framework and asynchronous actor-learner
architectures, PANAMA accelerates training while enabling autonomous task
execution by embodied AI. Our approach demonstrates superior pathfinding
performance in accuracy, speed, and scalability compared to existing
benchmarks. Through simulations, we highlight optimized data-sharing strategies
for scalable, automated systems, ensuring resilience in complex, real-world
environments. PANAMA bridges the gap between network-aware decision-making and
robust multi-agent coordination, advancing the synergy between DTs, wireless
networks, and AI-driven automation.

</details>


### [181] [Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift](https://arxiv.org/abs/2508.06776)
*Amit Pandey*

Main category: cs.LG

TL;DR: detecting model drift from null directions of transformer activations without task labels or output evaluations


<details>
  <summary>Details</summary>
Motivation: detecting model drift without task labels or output evaluations

Method: theory-only framework for detecting model drift from null directions of transformer activations

Result: the Variance--Leak Theorem, Fisher Null-Conservation, a Rank--Leak bound for low-rank updates, and a logarithmic-regret guarantee for online null-space trackers. a Spectral Null-Leakage (SNL) metric with non-asymptotic tail bounds and a concentration inequality, yielding a-priori thresholds for drift under a Gaussian null model.

Conclusion: monitoring right/left null spaces of layer activations and their Fisher geometry provides concrete, testable guarantees on representational change.

Abstract: We present Zero-Direction Probing (ZDP), a theory-only framework for
detecting model drift from null directions of transformer activations without
task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the
Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound
for low-rank updates, and (iv) a logarithmic-regret guarantee for online
null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with
non-asymptotic tail bounds and a concentration inequality, yielding a-priori
thresholds for drift under a Gaussian null model. These results show that
monitoring right/left null spaces of layer activations and their Fisher
geometry provides concrete, testable guarantees on representational change.

</details>


### [182] [PROPS: Progressively Private Self-alignment of Large Language Models](https://arxiv.org/abs/2508.06783)
*Noel Teku,Fengwei Tian,Payel Bhattacharjee,Souradip Chakraborty,Amrit Singh Bedi,Ravi Tandon*

Main category: cs.LG

TL;DR: PROPS是一种新的隐私保护对齐框架，它使用多阶段方法，在保护人类偏好隐私的同时，比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 依赖于人类反馈会引发隐私问题，即标签者的偏好可能会泄露关于其个人价值观、信仰和性格特征的多少。现有方法（如差分隐私SGD (DP-SGD)）通过在微调和对齐过程中私有化梯度来提供严格的隐私保证，但提供的隐私可能超过了必要的程度，因为人类偏好仅与(prompt, response)对的标签相关联，并且会降低模型效用。

Method: PROPS（PROgressively Private Self-alignment），一个多阶段隐私保护对齐框架，其中先前阶段的私有对齐模型可以用作标签器，以补充后续对齐阶段的训练数据。

Result: 使用多个模型（Pythia和GPT）和数据集（AlpacaEval、Anthropic HH-RLHF、truthy-dpo-v0.1）的综合验证表明，PROPS的效用优于现有方法，同时仍提供高隐私。对于相同的隐私预算，通过PROPS进行对齐可以实现比DP-SGD高3倍的胜率，比基于随机响应（RR）的对齐高2.5倍的胜率。

Conclusion: PROPS在提供高隐私的同时，比现有方法更有效。对于相同的隐私预算，通过PROPS进行对齐可以实现比DP-SGD高3倍的胜率，比基于随机响应（RR）的对齐高2.5倍的胜率。

Abstract: Alignment is a key step in developing Large Language Models (LLMs) using
human feedback to ensure adherence to human values and societal norms.
Dependence on human feedback raises privacy concerns about how much a labeler's
preferences may reveal about their personal values, beliefs, and personality
traits. Existing approaches, such as Differentially Private SGD (DP-SGD),
provide rigorous privacy guarantees by privatizing gradients during fine-tuning
and alignment but can provide more privacy than necessary as human preferences
are tied only to labels of (prompt, response) pairs and can degrade model
utility. This work focuses on LLM alignment with preference-level privacy,
which preserves the privacy of preference labels provided by humans. We propose
PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving
alignment framework where privately aligned models in previous stages can serve
as labelers for supplementing training data in the subsequent stages of
alignment. We present theoretical guarantees for PROPS as well as comprehensive
validation using multiple models (Pythia and GPT) and datasets (AlpacaEval,
Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over
existing methods while still providing high privacy. For the same privacy
budget, alignment via PROPS can achieve up to 3x higher win-rates compared to
DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based
alignment.

</details>


### [183] [Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning](https://arxiv.org/abs/2508.06784)
*Junjing Zheng,Chengliang Song,Weidong Jiang,Xinyu Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的自编码器MA-NTAE，用于处理高维张量数据，它通过非线性Tucker分解和Pick-and-Unfold策略，在计算复杂度和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高维数据，特别是高阶张量的形式，给自监督学习带来了主要的挑战。虽然基于MLP的自编码器(AE)被广泛使用，但它们对扁平化操作的依赖加剧了维度灾难，导致过大的模型尺寸、高计算开销以及深度结构特征捕获的挑战性优化。

Method: 提出了一种模式感知非线性Tucker自编码器(MA-NTAE)，它将经典的Tucker分解推广到非线性框架，并采用了一种Pick-and-Unfold策略。

Result: MA-NTAE的计算复杂度随张量阶数线性增长，随模维度成比例增长。大量的实验证明了MA-NTAE在压缩和聚类任务中优于标准AE和当前的张量网络，对于更高阶、更高维的张量，这种优势变得越来越明显。

Conclusion: MA-NTAE在压缩和聚类任务中优于标准AE和现有张量网络，尤其是在处理高阶、高维张量时。

Abstract: High-dimensional data, particularly in the form of high-order tensors,
presents a major challenge in self-supervised learning. While MLP-based
autoencoders (AE) are commonly employed, their dependence on flattening
operations exacerbates the curse of dimensionality, leading to excessively
large model sizes, high computational overhead, and challenging optimization
for deep structural feature capture. Although existing tensor networks
alleviate computational burdens through tensor decomposition techniques, most
exhibit limited capability in learning non-linear relationships. To overcome
these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder
(MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear
framework and employs a Pick-and-Unfold strategy, facilitating flexible
per-mode encoding of high-order tensors via recursive unfold-encode-fold
operations, effectively integrating tensor structural priors. Notably, MA-NTAE
exhibits linear growth in computational complexity with tensor order and
proportional growth with mode dimensions. Extensive experiments demonstrate
MA-NTAE's performance advantages over standard AE and current tensor networks
in compression and clustering tasks, which become increasingly pronounced for
higher-order, higher-dimensional tensors.

</details>


### [184] [Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities](https://arxiv.org/abs/2508.06800)
*Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan*

Main category: cs.LG

TL;DR: HARDY-MER通过关注难样本来提升模型在多模态情感识别中处理缺失模态的能力。


<details>
  <summary>Details</summary>
Motivation: 传统的处理方法通常通过重建缺失模态来解决这个问题。然而，这些方法没有考虑到不同样本重建难度的变化，从而限制了模型有效处理硬样本的能力。

Method: 提出了一个新颖的硬度感知动态课程学习框架HARDY-MER。该框架首先估计每个样本的硬度级别，然后策略性地强调训练期间的硬样本，以提高模型在这些具有挑战性的实例上的性能。

Result: 在基准数据集上的大量实验表明，HARDY-MER在缺失模态场景中始终优于现有方法。

Conclusion: HARDY-MER在缺失模态场景中始终优于现有方法。

Abstract: Missing modalities have recently emerged as a critical research direction in
multimodal emotion recognition (MER). Conventional approaches typically address
this issue through missing modality reconstruction. However, these methods fail
to account for variations in reconstruction difficulty across different
samples, consequently limiting the model's ability to handle hard samples
effectively. To overcome this limitation, we propose a novel Hardness-Aware
Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates
in two key stages: first, it estimates the hardness level of each sample, and
second, it strategically emphasizes hard samples during training to enhance
model performance on these challenging instances. Specifically, we first
introduce a Multi-view Hardness Evaluation mechanism that quantifies
reconstruction difficulty by considering both Direct Hardness (modality
reconstruction errors) and Indirect Hardness (cross-modal mutual information).
Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy
that dynamically adjusts the training curriculum by retrieving samples with
similar semantic information and balancing the learning focus between easy and
hard instances. Extensive experiments on benchmark datasets demonstrate that
HARDY-MER consistently outperforms existing methods in missing-modality
scenarios. Our code will be made publicly available at
https://github.com/HARDY-MER/HARDY-MER.

</details>


### [185] [Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation](https://arxiv.org/abs/2508.06806)
*Xiao Huang,Xu Liu,Enze Zhang,Tong Yu,Shuai Li*

Main category: cs.LG

TL;DR: 提出了一种新的离线到在线强化学习的数据增强方法CFDG，该方法利用无分类器指导扩散来提高离线和在线数据的生成质量，并通过重加权方法使更多生成的数据与在线数据对齐，从而提高性能并保持代理的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的工作使用离线数据集来生成符合在线数据分布的数据，以进行数据增强。然而，生成的数据仍然与在线数据存在差距，限制了整体性能。

Method: 提出了一种新的数据增强方法，即无分类器扩散生成（CFDG）。

Result: 实验结果表明，CFDG优于重放两种数据类型或使用标准扩散模型生成新数据。

Conclusion: CFDG通过在IQL、PEX和APL等方法上的实施，在D4RL基准测试（如MuJoCo和AntMaze）中实现了15%的平均性能提升。

Abstract: Offline-to-online Reinforcement Learning (O2O RL) aims to perform online
fine-tuning on an offline pre-trained policy to minimize costly online
interactions. Existing work used offline datasets to generate data that conform
to the online data distribution for data augmentation. However, generated data
still exhibits a gap with the online data, limiting overall performance. To
address this, we propose a new data augmentation approach, Classifier-Free
Diffusion Generation (CFDG). Without introducing additional classifier training
overhead, CFDG leverages classifier-free guidance diffusion to significantly
enhance the generation quality of offline and online data with different
distributions. Additionally, it employs a reweighting method to enable more
generated data to align with the online data, enhancing performance while
maintaining the agent's stability. Experimental results show that CFDG
outperforms replaying the two data types or using a standard diffusion model to
generate new data. Our method is versatile and can be integrated with existing
offline-to-online RL algorithms. By implementing CFDG to popular methods IQL,
PEX and APL, we achieve a notable 15% average improvement in empirical
performance on the D4RL benchmark such as MuJoCo and AntMaze.

</details>


### [186] [Technical Report: Full-Stack Fine-Tuning for the Q Programming Language](https://arxiv.org/abs/2508.06813)
*Brendan R. Hogan,Will Brown,Adel Boyarsky,Anderson Schneider,Yuriy Nevmyvaka*

Main category: cs.LG

TL;DR: This paper presents an approach for adapting LLMs to the Q programming language by pretraining, supervised fine tuning, and reinforcement learning. The best model achieves a pass@1 accuracy of 59 percent on the Q benchmark, surpassing Claude Opus-4 by 29.5 percent.


<details>
  <summary>Details</summary>
Motivation: Leveraging LLMs for specialized applications, particularly in niche programming languages and private domains, remains challenging and largely unsolved.

Method: We introduce a new Leetcode style evaluation dataset for Q, benchmark major frontier models on the dataset, then do pretraining, supervised fine tuning, and reinforcement learning to train a suite of reasoning and non-reasoning models based on the Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B).

Result: Our best model achieves a pass@1 accuracy of 59 percent on our Q benchmark, surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.

Conclusion: The best model achieves a pass@1 accuracy of 59 percent on our Q benchmark, surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent. Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.

Abstract: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.

</details>


### [187] [Who's the Evil Twin? Differential Auditing for Undesired Behavior](https://arxiv.org/abs/2508.06827)
*Ishwar Balappanawar,Venkata Hasith Vattikuti,Greta Kintzley,Ronan Azimi-Mancel,Satvik Golechha*

Main category: cs.LG

TL;DR: Detecting hidden behaviors in neural networks through adversarial games. Adversarial attacks show promise in CNNs, but LLM auditing requires hints about the undesired distribution.


<details>
  <summary>Details</summary>
Motivation: Detecting hidden behaviors in neural networks poses a significant challenge due to minimal prior knowledge and potential adversarial obfuscation.

Method: Framing detection as an adversarial game between two teams: the red team trains two similar models, one trained solely on benign data and the other trained on data containing hidden harmful behavior. The blue team tries to identify the compromised model.

Result: High accuracy for adversarial-attack-based methods (100% correct prediction, using hints) in CNNs. Limited parallel methods applicable from CNNs to LLMs.

Conclusion: Effective LLM auditing methods require hints about the undesired distribution, which can then used in standard black-box and open-weight methods to probe the models further and reveal their misalignment.

Abstract: Detecting hidden behaviors in neural networks poses a significant challenge
due to minimal prior knowledge and potential adversarial obfuscation. We
explore this problem by framing detection as an adversarial game between two
teams: the red team trains two similar models, one trained solely on benign
data and the other trained on data containing hidden harmful behavior, with the
performance of both being nearly indistinguishable on the benign dataset. The
blue team, with limited to no information about the harmful behaviour, tries to
identify the compromised model. We experiment using CNNs and try various blue
team strategies, including Gaussian noise analysis, model diffing, integrated
gradients, and adversarial attacks under different levels of hints provided by
the red team. Results show high accuracy for adversarial-attack-based methods
(100\% correct prediction, using hints), which is very promising, whilst the
other techniques yield more varied performance. During our LLM-focused rounds,
we find that there are not many parallel methods that we could apply from our
study with CNNs. Instead, we find that effective LLM auditing methods require
some hints about the undesired distribution, which can then used in standard
black-box and open-weight methods to probe the models further and reveal their
misalignment. We open-source our auditing games (with the model and data) and
hope that our findings contribute to designing better audits.

</details>


### [188] [Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning](https://arxiv.org/abs/2508.06871)
*Aleksandar Todorov,Juan Cardenas-Cartagena,Rafael F. Cunha,Marco Zullich,Matthia Sabatelli*

Main category: cs.LG

TL;DR: 研究了稀疏化方法如何提高 MTRL 智能体的可塑性和性能。


<details>
  <summary>Details</summary>
Motivation: 可塑性损失是深度强化学习中的一个关键挑战。在多任务强化学习 (MTRL) 中，更高的表征灵活性对于管理各种可能相互冲突的任务需求至关重要。

Method: 使用稀疏化方法，特别是 GMP 和 SET，以增强 MTRL 智能体的可塑性并提高性能。

Result: GMP 和 SET 有效地减轻了可塑性退化的关键指标，例如神经元休眠和表征崩溃。稀疏智能体的性能通常优于密集智能体，并且获得了与显式可塑性干预措施相比具有竞争力的结果。

Conclusion: 动态稀疏化是一种强大但上下文敏感的工具，可用于开发更具适应性的 MTRL 系统。

Abstract: Plasticity loss, a diminishing capacity to adapt as training progresses, is a
critical challenge in deep reinforcement learning. We examine this issue in
multi-task reinforcement learning (MTRL), where higher representational
flexibility is crucial for managing diverse and potentially conflicting task
demands. We systematically explore how sparsification methods, particularly
Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance
plasticity and consequently improve performance in MTRL agents. We evaluate
these approaches across distinct MTRL architectures (shared backbone, Mixture
of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks,
comparing against dense baselines, and a comprehensive range of alternative
plasticity-inducing or regularization methods. Our results demonstrate that
both GMP and SET effectively mitigate key indicators of plasticity degradation,
such as neuron dormancy and representational collapse. These plasticity
improvements often correlate with enhanced multi-task performance, with sparse
agents frequently outperforming dense counterparts and achieving competitive
results against explicit plasticity interventions. Our findings offer insights
into the interplay between plasticity, network sparsity, and MTRL designs,
highlighting dynamic sparsification as a robust but context-sensitive tool for
developing more adaptable MTRL systems.

</details>


### [189] [Conformal Prediction and Trustworthy AI](https://arxiv.org/abs/2508.06885)
*Anthony Bellotti,Xindi Zhao*

Main category: cs.LG

TL;DR: Conformal predictors are reviewed for their potential to contribute to trustworthy AI, addressing generalization risk and AI governance. Experiments and examples demonstrate its use as a well-calibrated predictor and for bias identification and mitigation.


<details>
  <summary>Details</summary>
Motivation: Conformal predictors provide set predictions with guaranteed confidence level and have become a mainstream methodology for uncertainty quantification. They enable reliable machine learning with well-calibrated uncertainty quantification, making them extremely beneficial for developing trustworthy AI.

Method: Review of conformal prediction

Result: Experiments and examples are provided to demonstrate its use as a well-calibrated predictor and for bias identification and mitigation.

Conclusion: Conformal prediction contributes to trustworthy AI beyond its marginal validity property, addressing problems such as generalization risk and AI governance. It can be used as a well-calibrated predictor and for bias identification and mitigation.

Abstract: Conformal predictors are machine learning algorithms developed in the 1990's
by Gammerman, Vovk, and their research team, to provide set predictions with
guaranteed confidence level. Over recent years, they have grown in popularity
and have become a mainstream methodology for uncertainty quantification in the
machine learning community. From its beginning, there was an understanding that
they enable reliable machine learning with well-calibrated uncertainty
quantification. This makes them extremely beneficial for developing trustworthy
AI, a topic that has also risen in interest over the past few years, in both
the AI community and society more widely. In this article, we review the
potential for conformal prediction to contribute to trustworthy AI beyond its
marginal validity property, addressing problems such as generalization risk and
AI governance. Experiments and examples are also provided to demonstrate its
use as a well-calibrated predictor and for bias identification and mitigation.

</details>


### [190] [QuiZSF: An efficient data-model interaction framework for zero-shot time-series forecasting](https://arxiv.org/abs/2508.06915)
*Shichao Ma,Zhengyang Zhou,Qihe Huang,Binwu Wang,Kuo Yang,Huan Li,Yang Wang*

Main category: cs.LG

TL;DR: 提出QuiZSF框架，用于增强零样本时间序列预测。


<details>
  <summary>Details</summary>
Motivation: 传统模型难以处理零样本时间序列预测，时间序列预训练模型缺乏动态结合外部知识的机制。

Method: 提出QuiZSF框架，结合了高效检索、表征学习和模型适配，包含分层树结构的ChronoRAG Base、多粒度序列交互学习器和双分支模型协作对齐器。

Result: QuiZSF在零样本时间序列预测中优于现有基线模型。

Conclusion: QuiZSF在75%和87.5%的预测设置中排名第一，同时保持了内存和推理时间的高效率。

Abstract: Time series forecasting has become increasingly important to empower diverse
applications with streaming data. Zero-shot time-series forecasting (ZSF),
particularly valuable in data-scarce scenarios, such as domain transfer or
forecasting under extreme conditions, is difficult for traditional models to
deal with. While time series pre-trained models (TSPMs) have demonstrated
strong performance in ZSF, they often lack mechanisms to dynamically
incorporate external knowledge. Fortunately, emerging retrieval-augmented
generation (RAG) offers a promising path for injecting such knowledge on
demand, yet they are rarely integrated with TSPMs. To leverage the strengths of
both worlds, we introduce RAG into TSPMs to enhance zero-shot time series
forecasting. In this paper, we propose QuiZSF (Quick Zero-Shot Time Series
Forecaster), a lightweight and modular framework that couples efficient
retrieval with representation learning and model adaptation for ZSF.
Specifically, we construct a hierarchical tree-structured ChronoRAG Base (CRB)
for scalable time-series storage and domain-aware retrieval, introduce a
Multi-grained Series Interaction Learner (MSIL) to extract fine- and
coarse-grained relational features, and develop a dual-branch Model Cooperation
Coherer (MCC) that aligns retrieved knowledge with two kinds of TSPMs: Non-LLM
based and LLM based. Compared with contemporary baselines, QuiZSF, with Non-LLM
based and LLM based TSPMs as base model, respectively, ranks Top1 in 75% and
87.5% of prediction settings, while maintaining high efficiency in memory and
inference time.

</details>


### [191] [Class Unbiasing for Generalization in Medical Diagnosis](https://arxiv.org/abs/2508.06943)
*Lishi Zuo,Man-Wai Mak,Lu Yi,Youzhi Tu*

Main category: cs.LG

TL;DR: 本文提出了一种新的类别无偏模型(Cls-unbias)，该模型可以同时缓解类别不平衡和类别特征偏差。


<details>
  <summary>Details</summary>
Motivation: 医学诊断可能因偏见而失败。在这项工作中，我们发现了类特征偏差，它是指模型可能依赖于仅与类的子集强烈相关的特征，从而导致有偏差的性能和在其他类上的泛化能力差。

Method: 我们提出了一种类别不平衡损失，它促进了正类和负类样本的分类损失的同等贡献。我们建议优化一个类别的分组分布鲁棒优化目标——一个类加权的训练目标，它对表现不佳的类进行加权——以提高不平衡损失在类不平衡下的有效性。

Result: 通过合成和真实世界的数据集，我们通过经验证明了类特征偏差会对模型性能产生负面影响。

Conclusion: 该方法有效地缓解了类别特征偏差和类别不平衡问题，从而提高了模型的泛化能力。

Abstract: Medical diagnosis might fail due to bias. In this work, we identified
class-feature bias, which refers to models' potential reliance on features that
are strongly correlated with only a subset of classes, leading to biased
performance and poor generalization on other classes. We aim to train a
class-unbiased model (Cls-unbias) that mitigates both class imbalance and
class-feature bias simultaneously. Specifically, we propose a class-wise
inequality loss which promotes equal contributions of classification loss from
positive-class and negative-class samples. We propose to optimize a class-wise
group distributionally robust optimization objective-a class-weighted training
objective that upweights underperforming classes-to enhance the effectiveness
of the inequality loss under class imbalance. Through synthetic and real-world
datasets, we empirically demonstrate that class-feature bias can negatively
impact model performance. Our proposed method effectively mitigates both
class-feature bias and class imbalance, thereby improving the model's
generalization ability.

</details>


### [192] [AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance](https://arxiv.org/abs/2508.06944)
*Lixuan He,Jie Feng,Yong Li*

Main category: cs.LG

TL;DR: AMFT is a novel single-stage algorithm that learns to balance Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) for fine-tuning Large Language Models (LLMs), achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Current two-stage methods for fine-tuning LLMs have catastrophic forgetting and suboptimal trade-offs. Recent single-stage methods lack a principled mechanism for dynamically balancing SFT and RL.

Method: Adaptive Meta Fine-Tuning (AMFT), a single-stage algorithm with a meta-gradient adaptive weight controller that learns the optimal balance between SFT's implicit, path-level reward and RL's explicit, outcome-based reward.

Result: AMFT consistently establishes a new state-of-the-art and demonstrates superior generalization on out-of-distribution tasks.

Conclusion: AMFT establishes new state-of-the-art results and demonstrates superior generalization on out-of-distribution tasks. The meta-learning controller is crucial for AMFT's stability, sample efficiency, and performance.

Abstract: Large Language Models (LLMs) are typically fine-tuned for reasoning tasks
through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by
Reinforcement Learning (RL), a process fraught with catastrophic forgetting and
suboptimal trade-offs between imitation and exploration. Recent single-stage
methods attempt to unify SFT and RL using heuristics, but lack a principled
mechanism for dynamically balancing the two paradigms. In this paper, we
reframe this challenge through the theoretical lens of \textbf{implicit
rewards}, viewing SFT and RL not as distinct methods but as complementary
reward signals. We introduce \textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel
single-stage algorithm that learns the optimal balance between SFT's implicit,
path-level reward and RL's explicit, outcome-based reward. The core of AMFT is
a \textbf{meta-gradient adaptive weight controller} that treats the SFT-RL
balance as a learnable parameter, dynamically optimizing it to maximize
long-term task performance. This forward-looking approach, regularized by
policy entropy for stability, autonomously discovers an effective training
curriculum. We conduct a comprehensive evaluation on challenging benchmarks
spanning mathematical reasoning, abstract visual reasoning (General Points),
and vision-language navigation (V-IRL). AMFT consistently establishes a new
state-of-the-art and demonstrats superior generalization on out-of-distribution
(OOD) tasks. Ablation studies and training dynamic analysis confirm that the
meta-learning controller is crucial for AMFT's stability, sample efficiency,
and performance, offering a more principled and effective paradigm for LLM
alignment.Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.

</details>


### [193] [BoRA: Towards More Expressive Low-Rank Adaptation with Block Diversity](https://arxiv.org/abs/2508.06953)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.LG

TL;DR: proposes Block Diversified Low-Rank Adaptation (BoRA), which improves the rank of LoRA weights with a small number of additional parameters. It demonstrates the superiority of BoRA, and ablation studies further validate its scalability.


<details>
  <summary>Details</summary>
Motivation: Increasing the dimension $r$ can raise the rank of LoRA weights (i.e., $BA$), which typically improves fine-tuning performance but also significantly increases the number of trainable parameters.

Method: proposes Block Diversified Low-Rank Adaptation (BoRA), which improves the rank of LoRA weights with a small number of additional parameters. Specifically, BoRA treats the product $BA$ as a block matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and $B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the diversity of different block products, BoRA introduces a unique diagonal matrix $\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication, resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only requiring $b^2r$ additional parameters.

Result: BoRA increases the rank of LoRA weights by a factor of $b$ while only requiring $b^2r$ additional parameters.

Conclusion: Extensive experiments across multiple datasets and models demonstrate the superiority of BoRA, and ablation studies further validate its scalability.

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). It approximates the update of a
pretrained weight matrix $W\in\mathbb{R}^{m\times n}$ by the product of two
low-rank matrices, $BA$, where $A \in\mathbb{R}^{r\times n}$ and
$B\in\mathbb{R}^{m\times r} (r\ll\min\{m,n\})$. Increasing the dimension $r$
can raise the rank of LoRA weights (i.e., $BA$), which typically improves
fine-tuning performance but also significantly increases the number of
trainable parameters. In this paper, we propose Block Diversified Low-Rank
Adaptation (BoRA), which improves the rank of LoRA weights with a small number
of additional parameters. Specifically, BoRA treats the product $BA$ as a block
matrix multiplication, where $A$ and $B$ are partitioned into $b$ blocks along
the columns and rows, respectively (i.e., $A=[A_1,\dots,A_b]$ and
$B=[B_1,\dots,B_b]^\top$). Consequently, the product $BA$ becomes the
concatenation of the block products $B_iA_j$ for $i,j\in[b]$. To enhance the
diversity of different block products, BoRA introduces a unique diagonal matrix
$\Sigma_{i,j} \in \mathbb{R}^{r\times r}$ for each block multiplication,
resulting in $B_i \Sigma_{i,j} A_j$. By leveraging these block-wise diagonal
matrices, BoRA increases the rank of LoRA weights by a factor of $b$ while only
requiring $b^2r$ additional parameters. Extensive experiments across multiple
datasets and models demonstrate the superiority of BoRA, and ablation studies
further validate its scalability.

</details>


### [194] [Can Multitask Learning Enhance Model Explainability?](https://arxiv.org/abs/2508.06966)
*Hiba Najjar,Bushra Alshbib,Andreas Dengel*

Main category: cs.LG

TL;DR: Multitask learning uses modalities as extra targets to explain model behavior, maintaining performance while improving interpretability.


<details>
  <summary>Details</summary>
Motivation: Exploiting the diversity of satellite data through multimodal learning improves model performance, but at the cost of interpretability.

Method: Multitask learning leverages modalities as additional targets to be predicted alongside the main task.

Result: Model performance remains comparable to the multimodal baseline, and prediction errors in the main task can be explained via model behavior in the auxiliary tasks.

Conclusion: The approach demonstrates efficiency on segmentation, classification, and regression tasks, offering benefits like addressing data scarcity and explaining prediction errors.

Abstract: Remote sensing provides satellite data in diverse types and formats. The
usage of multimodal learning networks exploits this diversity to improve model
performance, except that the complexity of such networks comes at the expense
of their interpretability. In this study, we explore how modalities can be
leveraged through multitask learning to intrinsically explain model behavior.
In particular, instead of additional inputs, we use certain modalities as
additional targets to be predicted along with the main task. The success of
this approach relies on the rich information content of satellite data, which
remains as input modalities. We show how this modeling context provides
numerous benefits: (1) in case of data scarcity, the additional modalities do
not need to be collected for model inference at deployment, (2) the model
performance remains comparable to the multimodal baseline performance, and in
some cases achieves better scores, (3) prediction errors in the main task can
be explained via the model behavior in the auxiliary task(s). We demonstrate
the efficiency of our approach on three datasets, including segmentation,
classification, and regression tasks. Code available at
git.opendfki.de/hiba.najjar/mtl_explainability/.

</details>


### [195] [Structure-Preserving Digital Twins via Conditional Neural Whitney Forms](https://arxiv.org/abs/2508.06981)
*Brooks Kinch,Benjamin Shaffer,Elizabeth Armstrong,Michael Meehan,John Hewson,Nathaniel Trask*

Main category: cs.LG

TL;DR: A framework for constructing real-time digital twins using structure-preserving reduced finite element models and conditional attention mechanisms, achieving accurate and fast predictions on complex problems with sparse data.


<details>
  <summary>Details</summary>
Motivation: Presenting a framework for constructing real-time digital twins based on structure-preserving reduced finite element models conditioned on a latent variable Z.

Method: The approach uses conditional attention mechanisms to learn both a reduced finite element basis and a nonlinear conservation law within the framework of finite element exterior calculus (FEEC).

Result: The method achieves accurate predictions on complex geometries with sparse data (25 LES simulations), including capturing the transition to turbulence and achieving real-time inference ~0.1s with a speedup of 3.1x10^8 relative to LES.

Conclusion: The method achieves accurate predictions on complex geometries with sparse data, including capturing the transition to turbulence and achieving real-time inference with a significant speedup. An open-source implementation is available.

Abstract: We present a framework for constructing real-time digital twins based on
structure-preserving reduced finite element models conditioned on a latent
variable Z. The approach uses conditional attention mechanisms to learn both a
reduced finite element basis and a nonlinear conservation law within the
framework of finite element exterior calculus (FEEC). This guarantees numerical
well-posedness and exact preservation of conserved quantities, regardless of
data sparsity or optimization error. The conditioning mechanism supports
real-time calibration to parametric variables, allowing the construction of
digital twins which support closed loop inference and calibration to sensor
data. The framework interfaces with conventional finite element machinery in a
non-invasive manner, allowing treatment of complex geometries and integration
of learned models with conventional finite element techniques.
  Benchmarks include advection diffusion, shock hydrodynamics, electrostatics,
and a complex battery thermal runaway problem. The method achieves accurate
predictions on complex geometries with sparse data (25 LES simulations),
including capturing the transition to turbulence and achieving real-time
inference ~0.1s with a speedup of 3.1x10^8 relative to LES. An open-source
implementation is available on GitHub.

</details>


### [196] [Discovery Learning accelerates battery design evaluation](https://arxiv.org/abs/2508.06985)
*Jiawei Zhang,Yifei Zhang,Baozhao Yi,Yao Ren,Qi Jiao,Hanyu Bai,Weiran Jiang,Ziyou Song*

Main category: cs.LG

TL;DR: 提出了 Discovery Learning (DL) 用于加速电池设计验证，该方法能显著降低时间和能源成本，并在新材料设计中实现快速寿命评估。


<details>
  <summary>Details</summary>
Motivation: 电池研发受限于评估新设计所需的时间和能源成本，现有寿命预测方法依赖目标设计的标记数据，无法在原型设计前进行可靠预测。

Method: 提出了 Discovery Learning (DL)，一种结合主动学习、物理引导学习和零样本学习的科学机器学习范式。

Result: DL 在预测未知设备变异下的平均循环寿命方面实现了 7.2% 的测试误差，与工业实践相比，节省了 98% 的时间和 95% 的能源。

Conclusion: Discovery Learning (DL) 显著降低了电池设计验证的时间和能源成本，通过利用历史数据和少量原型设计，实现了对新材料设计的快速寿命评估，加速了下一代电池技术的开发。

Abstract: Fast and reliable validation of novel designs in complex physical systems
such as batteries is critical to accelerating technological innovation.
However, battery research and development remain bottlenecked by the
prohibitively high time and energy costs required to evaluate numerous new
design candidates, particularly in battery prototyping and life testing.
Despite recent progress in data-driven battery lifetime prediction, existing
methods require labeled data of target designs to improve accuracy and cannot
make reliable predictions until after prototyping, thus falling far short of
the efficiency needed to enable rapid feedback for battery design. Here, we
introduce Discovery Learning (DL), a scientific machine-learning paradigm that
integrates active learning, physics-guided learning, and zero-shot learning
into a human-like reasoning loop, drawing inspiration from learning theories in
educational psychology. DL can learn from historical battery designs and
actively reduce the need for prototyping, thus enabling rapid lifetime
evaluation for unobserved material-design combinations without requiring
additional data labeling. To test DL, we present 123 industrial-grade
large-format lithium-ion pouch cells, spanning eight material-design
combinations and diverse cycling protocols. Trained solely on public datasets
of small-capacity cylindrical cells, DL achieves 7.2% test error in predicting
the average cycle life under unknown device variability. This results in
savings of 98% in time and 95% in energy compared to industrial practices. This
work highlights the potential of uncovering insights from historical designs to
inform and accelerate the development of next-generation battery technologies.
DL represents a key advance toward efficient data-driven modeling and helps
realize the promise of machine learning for accelerating scientific discovery
and engineering innovation.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [197] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

TL;DR: This study uses transfer learning and data augmentation to accurately classify ALL, with EfficientNet-B3 outperforming previous methods.


<details>
  <summary>Details</summary>
Motivation: Accurate ALL classification from blood smear images is crucial for early diagnosis and treatment.

Method: Transfer learning with pretrained CNNs (ResNet50, ResNet101, EfficientNet variants B0, B1, and B3) and data augmentation.

Result: EfficientNet-B3 achieves an F1-score of 94.30%, accuracy of 92.02%, and AUC of 94.79%.

Conclusion: EfficientNet-B3 achieves high accuracy in ALL classification, demonstrating the effectiveness of data augmentation and transfer learning.

Abstract: Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>
