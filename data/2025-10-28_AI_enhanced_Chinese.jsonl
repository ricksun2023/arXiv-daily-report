{"id": "2510.21711", "categories": ["cs.IR", "H.3.3"], "pdf": "https://arxiv.org/pdf/2510.21711", "abs": "https://arxiv.org/abs/2510.21711", "authors": ["Rauf Aliev"], "title": "Improving E-commerce Search with Category-Aligned Retrieval", "comment": null, "summary": "Traditional e-commerce search systems often struggle with the semantic gap\nbetween user queries and product catalogs. In this paper, we propose a\nCategory-Aligned Retrieval System (CARS) that improves search relevance by\nfirst predicting the product category from a user's query and then boosting\nproducts within that category. We introduce a novel method for creating\n\"Trainable Category Prototypes\" from query embeddings. We evaluate this method\nwith two models: a lightweight all-MiniLM-L6-v2 and OpenAI's\ntext-embedding-ada-002. Our offline evaluation shows this method is highly\neffective, with the OpenAI model increasing Top-3 category prediction accuracy\nfrom a zero-shot baseline of 43.8% to 83.2% after training. The end-to-end\nsimulation, however, highlights the limitations of blindly applying category\nboosts in a complex retrieval pipeline: while accuracy is high, naive\nintegration can negatively affect search relevance metrics such as nDCG@10. We\nargue that this is partly due to dataset-specific ambiguities (e.g., polysemous\nqueries in the Amazon ESCI corpus) and partly due to the sensitivity of\nretrieval systems to over-constraining filters. Crucially, these results do not\ndiminish the value of the approach; rather, they emphasize the need for\nconfidence-aware and adaptive integration strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7c7b\u522b\u5bf9\u9f50\u68c0\u7d22\u7cfb\u7edf (CARS)\uff0c\u901a\u8fc7\u9884\u6d4b\u7528\u6237\u67e5\u8be2\u7684\u4ea7\u54c1\u7c7b\u522b\u5e76\u63d0\u5347\u8be5\u7c7b\u522b\u5185\u7684\u4ea7\u54c1\u6765\u63d0\u9ad8\u641c\u7d22\u76f8\u5173\u6027\u3002", "motivation": "\u4f20\u7edf\u7535\u5546\u641c\u7d22\u7cfb\u7edf\u96be\u4ee5\u89e3\u51b3\u7528\u6237\u67e5\u8be2\u548c\u4ea7\u54c1\u76ee\u5f55\u4e4b\u95f4\u7684\u8bed\u4e49\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u67e5\u8be2\u5d4c\u5165\u521b\u5efa\u201c\u53ef\u8bad\u7ec3\u7c7b\u522b\u539f\u578b\u201d\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u4f7f\u7528 all-MiniLM-L6-v2 \u548c OpenAI \u7684 text-embedding-ada-002 \u4e24\u4e2a\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u79bb\u7ebf\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u975e\u5e38\u6709\u6548\uff0c\u4f7f\u7528 OpenAI \u6a21\u578b\u8bad\u7ec3\u540e\uff0cTop-3 \u7c7b\u522b\u9884\u6d4b\u51c6\u786e\u7387\u4ece 43.8% \u63d0\u9ad8\u5230 83.2%\u3002\u4f46\u7aef\u5230\u7aef\u6a21\u62df\u663e\u793a\uff0c\u5728\u590d\u6742\u7684\u68c0\u7d22\u7ba1\u9053\u4e2d\u76f2\u76ee\u5e94\u7528\u7c7b\u522b\u63d0\u5347\u4f1a\u8d1f\u9762\u5f71\u54cd\u641c\u7d22\u76f8\u5173\u6027\u6307\u6807\u3002", "conclusion": "\u7ed3\u679c\u5f3a\u8c03\u9700\u8981\u7f6e\u4fe1\u5ea6\u611f\u77e5\u548c\u81ea\u9002\u5e94\u96c6\u6210\u7b56\u7565\u3002"}}
{"id": "2510.21712", "categories": ["cs.IR", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21712", "abs": "https://arxiv.org/abs/2510.21712", "authors": ["Hao Sun", "Zile Qiao", "Bo Wang", "Guoxin Chen", "Yingyan Hou", "Yong Jiang", "Pengjun Xie", "Fei Huang", "Yan Zhang"], "title": "DecoupleSearch: Decouple Planning and Search via Hierarchical Reward Modeling", "comment": "EMNLP 2025 Main Conference", "summary": "Retrieval-Augmented Generation (RAG) systems have emerged as a pivotal\nmethodology for enhancing Large Language Models (LLMs) through the dynamic\nintegration of external knowledge. To further improve RAG's flexibility,\nAgentic RAG introduces autonomous agents into the workflow. However, Agentic\nRAG faces several challenges: (1) the success of each step depends on both\nhigh-quality planning and accurate search, (2) the lack of supervision for\nintermediate reasoning steps, and (3) the exponentially large candidate space\nfor planning and searching. To address these challenges, we propose\nDecoupleSearch, a novel framework that decouples planning and search processes\nusing dual value models, enabling independent optimization of plan reasoning\nand search grounding. Our approach constructs a reasoning tree, where each node\nrepresents planning and search steps. We leverage Monte Carlo Tree Search to\nassess the quality of each step. During inference, Hierarchical Beam Search\niteratively refines planning and search candidates with dual value models.\nExtensive experiments across policy models of varying parameter sizes,\ndemonstrate the effectiveness of our method.", "AI": {"tldr": "Agentic RAG\u5b58\u5728\u89c4\u5212\u548c\u641c\u7d22\u95ee\u9898\uff0c\u7f3a\u4e4f\u4e2d\u95f4\u6b65\u9aa4\u7684\u76d1\u7763\uff0c\u4ee5\u53ca\u5019\u9009\u7a7a\u95f4\u8fc7\u5927", "motivation": "\u4e3a\u4e86\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\u5df2\u7ecf\u6210\u4e3a\u4e00\u79cd\u5173\u952e\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u6574\u5408\u5916\u90e8\u77e5\u8bc6\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8RAG\u7684\u7075\u6d3b\u6027\uff0cAgentic RAG\u5c06\u81ea\u4e3b\u4ee3\u7406\u5f15\u5165\u5de5\u4f5c\u6d41\u7a0b", "method": "\u6211\u4eec\u63d0\u51fa\u4e86DecoupleSearch\uff0c\u8fd9\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u6846\u67b6\uff0c\u5b83\u4f7f\u7528\u53cc\u91cd\u4ef7\u503c\u6a21\u578b\u5c06\u89c4\u5212\u548c\u641c\u7d22\u8fc7\u7a0b\u5206\u79bb\uff0c\u4ece\u800c\u80fd\u591f\u72ec\u7acb\u4f18\u5316\u8ba1\u5212\u63a8\u7406\u548c\u641c\u7d22\u57fa\u7840\u3002\u6211\u4eec\u7684\u65b9\u6cd5\u6784\u5efa\u4e86\u4e00\u4e2a\u63a8\u7406\u6811\uff0c\u5176\u4e2d\u6bcf\u4e2a\u8282\u70b9\u4ee3\u8868\u8ba1\u5212\u548c\u641c\u7d22\u6b65\u9aa4\u3002\u6211\u4eec\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u6765\u8bc4\u4f30\u6bcf\u4e2a\u6b65\u9aa4\u7684\u8d28\u91cf\u3002\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\uff0c\u5206\u5c42\u675f\u641c\u7d22\u4f7f\u7528\u53cc\u91cd\u4ef7\u503c\u6a21\u578b\u8fed\u4ee3\u5730\u7ec6\u5316\u89c4\u5212\u548c\u641c\u7d22\u5019\u9009\u5bf9\u8c61", "result": "\u5728\u4e0d\u540c\u53c2\u6570\u5927\u5c0f\u7684\u7b56\u7565\u6a21\u578b\u4e0a\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u6211\u4eec\u65b9\u6cd5\u7684\u6709\u6548\u6027", "conclusion": "DecoupleSearch\u901a\u8fc7\u89e3\u8026\u89c4\u5212\u548c\u641c\u7d22\u8fc7\u7a0b\uff0c\u4f7f\u7528\u53cc\u91cd\u4ef7\u503c\u6a21\u578b\u72ec\u7acb\u4f18\u5316\u8ba1\u5212\u63a8\u7406\u548c\u641c\u7d22\u57fa\u7840\uff0c\u4ece\u800c\u6709\u6548\u89e3\u51b3\u4e86Agentic RAG\u4e2d\u7684\u6311\u6218"}}
{"id": "2510.21713", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21713", "abs": "https://arxiv.org/abs/2510.21713", "authors": ["Yin Sun", "Yiwen Liu", "Junjie Song", "Chenyu Zhang", "Xinyuan Zhang", "Lingjie Liu", "Siqi Chen", "Yuji Cao"], "title": "asLLR: LLM based Leads Ranking in Auto Sales", "comment": null, "summary": "In the area of commercial auto sales system, high-quality lead score\nsequencing determines the priority of a sale's work and is essential for\noptimizing the efficiency of the sales system. Since CRM (Customer Relationship\nManagement) system contains plenty of textual interaction features between\nsales and customers, traditional techniques such as Click Through Rate (CTR)\nprediction struggle with processing the complex information inherent in natural\nlanguage features, which limits their effectiveness in sales lead ranking.\nBridging this gap is critical for enhancing business intelligence and\ndecision-making. Recently, the emergence of large language models (LLMs) has\nopened new avenues for improving recommendation systems, this study introduces\nasLLR (LLM-based Leads Ranking in Auto Sales), which integrates CTR loss and\nQuestion Answering (QA) loss within a decoder-only large language model\narchitecture. This integration enables the simultaneous modeling of both\ntabular and natural language features. To verify the efficacy of asLLR, we\nconstructed an innovative dataset derived from the customer lead pool of a\nprominent new energy vehicle brand, with 300,000 training samples and 40,000\ntesting samples. Our experimental results demonstrate that asLLR effectively\nmodels intricate patterns in commercial datasets, achieving the AUC of 0.8127,\nsurpassing traditional CTR estimation methods by 0.0231. Moreover, asLLR\nenhances CTR models when used for extracting text features by 0.0058. In\nreal-world sales scenarios, after rigorous online A/B testing, asLLR increased\nthe sales volume by about 9.5% compared to the traditional method, providing a\nvaluable tool for business intelligence and operational decision-making.", "AI": {"tldr": "This paper introduces asLLR, a LLM-based approach for ranking sales leads in the auto sales system. It improves sales efficiency by integrating CTR and QA losses to model tabular and natural language features.", "motivation": "Traditional CTR prediction methods struggle with complex natural language features in CRM systems, limiting their effectiveness in sales lead ranking.", "method": "The paper proposes asLLR, which integrates CTR loss and Question Answering (QA) loss within a decoder-only large language model architecture to model both tabular and natural language features.", "result": "asLLR achieves an AUC of 0.8127, surpassing traditional CTR estimation methods by 0.0231. It also enhances CTR models when used for extracting text features by 0.0058. Online A/B testing showed a 9.5% increase in sales volume.", "conclusion": "asLLR effectively models intricate patterns in commercial datasets and provides a valuable tool for business intelligence and operational decision-making in auto sales."}}
{"id": "2510.22314", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.22314", "abs": "https://arxiv.org/abs/2510.22314", "authors": ["Christian Imenkamp", "Martin Kabierski", "Hendrik Reiter", "Matthias Weidlich", "Wilhelm Hasselbring", "Agnes Koschmider"], "title": "Determining Window Sizes using Species Estimation for Accurate Process Mining over Streams", "comment": null, "summary": "Streaming process mining deals with the real-time analysis of event streams.\nA common approach for it is to adopt windowing mechanisms that select event\ndata from a stream for subsequent analysis. However, the size of these windows\ndenotes a crucial parameter, as it influences the representativeness of the\nwindow content and, by extension, of the analysis results. Given that process\ndynamics are subject to changes and potential concept drift, a static, fixed\nwindow size leads to inaccurate representations that introduce bias in the\nanalysis. In this work, we present a novel approach for streaming process\nmining that addresses these limitations by adjusting window sizes.\nSpecifically, we dynamically determine suitable window sizes based on\nestimators for the representativeness of samples as developed for species\nestimation in biodiversity research. Evaluation results on real-world data sets\nshow improvements over existing approaches that adopt static window sizes in\nterms of accuracy and robustness to concept drifts.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6d41\u5f0f\u8fc7\u7a0b\u6316\u6398\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u7a97\u53e3\u5927\u5c0f\u6765\u89e3\u51b3\u9759\u6001\u7a97\u53e3\u5927\u5c0f\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u9759\u6001\u3001\u56fa\u5b9a\u7a97\u53e3\u5927\u5c0f\u5bfc\u81f4\u4e0d\u51c6\u786e\u7684\u8868\u793a\uff0c\u4ece\u800c\u5728\u5206\u6790\u4e2d\u5f15\u5165\u504f\u5dee\u3002", "method": "\u57fa\u4e8e\u751f\u7269\u591a\u6837\u6027\u7814\u7a76\u4e2d\u7269\u79cd\u4f30\u8ba1\u7684\u6837\u672c\u4ee3\u8868\u6027\u4f30\u8ba1\u5668\uff0c\u52a8\u6001\u786e\u5b9a\u5408\u9002\u7684\u7a97\u53e3\u5927\u5c0f\u3002", "result": "\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u5728\u51c6\u786e\u6027\u548c\u5bf9\u6982\u5ff5\u6f02\u79fb\u7684\u9c81\u68d2\u6027\u65b9\u9762\uff0c\u4f18\u4e8e\u91c7\u7528\u9759\u6001\u7a97\u53e3\u5927\u5c0f\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u7a97\u53e3\u5927\u5c0f\u7684\u6d41\u5f0f\u8fc7\u7a0b\u6316\u6398\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2510.21714", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21714", "abs": "https://arxiv.org/abs/2510.21714", "authors": ["Xian Hu", "Ming Yue", "Zhixiang Feng", "Junwei Pan", "Junjie Zhai", "Ximei Wang", "Xinrui Miao", "Qian Li", "Xun Liu", "Shangyu Zhang", "Letian Wang", "Hua Lu", "Zijian Zeng", "Chen Cai", "Wei Wang", "Fei Xiong", "Pengfei Xiong", "Jintao Zhang", "Zhiyuan Wu", "Chunhui Zhang", "Anan Liu", "Jiulong You", "Chao Deng", "Yuekui Yang", "Shudong Huang", "Dapeng Liu", "Haijie Gu"], "title": "Practice on Long Behavior Sequence Modeling in Tencent Advertising", "comment": null, "summary": "Long-sequence modeling has become an indispensable frontier in recommendation\nsystems for capturing users' long-term preferences. However, user behaviors\nwithin advertising domains are inherently sparse, posing a significant barrier\nto constructing long behavioral sequences using data from a single advertising\ndomain alone. This motivates us to collect users' behaviors not only across\ndiverse advertising scenarios, but also beyond the boundaries of the\nadvertising domain into content domains-thereby constructing unified commercial\nbehavior trajectories. This cross-domain or cross-scenario integration gives\nrise to the following challenges: (1) feature taxonomy gaps between distinct\nscenarios and domains, (2) inter-field interference arising from irrelevant\nfeature field pairs, and (3) target-wise interference in temporal and semantic\npatterns when optimizing for different advertising targets. To address these\nchallenges, we propose several practical approaches within the two-stage\nframework for long-sequence modeling. In the first (search) stage, we design a\nhierarchical hard search method for handling complex feature taxonomy\nhierarchies, alongside a decoupled embedding-based soft search to alleviate\nconflicts between attention mechanisms and feature representation. In the\nsecond (sequence modeling) stage, we introduce: (a) Decoupled Side Information\nTemporal Interest Networks (TIN) to mitigate inter-field conflicts; (b)\nTarget-Decoupled Positional Encoding and Target-Decoupled SASRec to address\ntarget-wise interference; and (c) Stacked TIN to model high-order behavioral\ncorrelations. Deployed in production on Tencent's large-scale advertising\nplatforms, our innovations delivered significant performance gains: an overall\n4.22% GMV lift in WeChat Channels and an overall 1.96% GMV increase in WeChat\nMoments.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u63a8\u8350\u7cfb\u7edf\u7684\u957f\u5e8f\u5217\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6765\u81ea\u4e0d\u540c\u5e7f\u544a\u573a\u666f\u548c\u5185\u5bb9\u9886\u57df\u7684\u7528\u6237\u884c\u4e3a\u6765\u6784\u5efa\u7edf\u4e00\u7684\u5546\u4e1a\u884c\u4e3a\u8f68\u8ff9\u3002", "motivation": "\u4f20\u7edf\u7684\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6355\u6349\u7528\u6237\u957f\u671f\u504f\u597d\uff0c\u5c24\u5176\u662f\u5728\u5e7f\u544a\u9886\u57df\uff0c\u7528\u6237\u884c\u4e3a\u7a00\u758f\uff0c\u5355\u4e00\u5e7f\u544a\u57df\u7684\u6570\u636e\u96be\u4ee5\u6784\u5efa\u957f\u5e8f\u5217\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u542b\u4e24\u4e2a\u9636\u6bb5\uff1a\u641c\u7d22\u9636\u6bb5\u548c\u5e8f\u5217\u5efa\u6a21\u9636\u6bb5\u3002\u5728\u641c\u7d22\u9636\u6bb5\uff0c\u8bbe\u8ba1\u4e86\u5206\u5c42\u786c\u641c\u7d22\u65b9\u6cd5\u548c\u89e3\u8026\u5d4c\u5165\u8f6f\u641c\u7d22\u65b9\u6cd5\u3002\u5728\u5e8f\u5217\u5efa\u6a21\u9636\u6bb5\uff0c\u5f15\u5165\u4e86\u89e3\u8026\u8fb9\u4fe1\u606f\u65f6\u95f4\u5174\u8da3\u7f51\u7edc\uff08TIN\uff09\u3001\u76ee\u6807\u89e3\u8026\u4f4d\u7f6e\u7f16\u7801\u548c\u76ee\u6807\u89e3\u8026SASRec\uff0c\u4ee5\u53ca\u5806\u53e0TIN\u3002", "result": "\u5728\u817e\u8baf\u7684\u5927\u89c4\u6a21\u5e7f\u544a\u5e73\u53f0\u4e0a\u90e8\u7f72\u540e\uff0c\u8be5\u65b9\u6cd5\u5e26\u6765\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1a\u5fae\u4fe1\u89c6\u9891\u53f7GMV\u63d0\u53474.22%\uff0c\u5fae\u4fe1\u670b\u53cb\u5708GMV\u63d0\u53471.96%\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86\u8de8\u57df\u6216\u8de8\u573a\u666f\u96c6\u6210\u5e26\u6765\u7684\u7279\u5f81\u5206\u7c7b\u5dee\u8ddd\u3001\u5b57\u6bb5\u95f4\u5e72\u6270\u4ee5\u53ca\u76ee\u6807\u95f4\u5e72\u6270\u7b49\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u6210\u679c\u3002"}}
{"id": "2510.22316", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2510.22316", "abs": "https://arxiv.org/abs/2510.22316", "authors": ["Zhiyuan Hua", "Qiji Mo", "Zebin Yao", "Lixiao Cui", "Xiaoguang Liu", "Gang Wang", "Zijing Wei", "Xinyu Liu", "Tianxiao Tang", "Shaozhi Liu", "Lin Qu"], "title": "Dynamically Detect and Fix Hardness for Efficient Approximate Nearest Neighbor Search", "comment": "Accepted by SIGMOD2026", "summary": "Approximate Nearest Neighbor Search (ANNS) has become a fundamental component\nin many real-world applications. Among various ANNS algorithms, graph-based\nmethods are state-of-the-art. However, ANNS often suffers from a significant\ndrop in accuracy for certain queries, especially in Out-of-Distribution (OOD)\nscenarios. To address this issue, a recent approach named RoarGraph constructs\na bipartite graph between the base data and historical queries to bridge the\ngap between two different distributions. However, it suffers from some\nlimitations: (1) Building a bipartite graph between two distributions lacks\ntheoretical support, resulting in the query distribution not being effectively\nutilized by the graph index. (2) Requires a sufficient number of historical\nqueries before graph construction and suffers from high construction times. (3)\nWhen the query workload changes, it requires reconstruction to maintain high\nsearch accuracy.\n  In this paper, we first propose Escape Hardness, a metric to evaluate the\nquality of the graph structure around the query. Then we divide the graph\nsearch into two stages and dynamically identify and fix defective graph regions\nin each stage based on Escape Hardness. (1) From the entry point to the\nvicinity of the query. We propose Reachability Fixing (RFix), which enhances\nthe navigability of some key nodes. (2) Searching within the vicinity of the\nquery. We propose Neighboring Graph Defects Fixing (NGFix) to improve graph\nconnectivity in regions where queries are densely distributed. The results of\nextensive experiments show that our method outperforms other state-of-the-art\nmethods on real-world datasets, achieving up to 2.25x faster search speed for\nOOD queries at 99% recall compared with RoarGraph and 6.88x faster speed\ncompared with HNSW. It also accelerates index construction by 2.35-9.02x\ncompared to RoarGraph.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fd1\u4f3c\u6700\u8fd1\u90bb\u641c\u7d22\uff08ANNS\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8bc6\u522b\u548c\u4fee\u590d\u56fe\u7ed3\u6784\u4e2d\u7684\u7f3a\u9677\u533a\u57df\u6765\u63d0\u9ad8\u641c\u7d22\u7cbe\u5ea6\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u5916\uff08OOD\uff09\u573a\u666f\u4e2d\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u56fe\u7684ANNS\u65b9\u6cd5\u5728\u5904\u7406\u7279\u5b9a\u67e5\u8be2\u65f6\uff0c\u5c24\u5176\u662f\u5728OOD\u573a\u666f\u4e2d\uff0c\u7cbe\u5ea6\u4f1a\u663e\u8457\u4e0b\u964d\u3002RoarGraph\u65b9\u6cd5\u8bd5\u56fe\u901a\u8fc7\u6784\u5efa\u57fa\u6570\u636e\u548c\u5386\u53f2\u67e5\u8be2\u4e4b\u95f4\u7684\u4e8c\u5206\u56fe\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u5b58\u5728\u7406\u8bba\u652f\u6301\u4e0d\u8db3\u3001\u9700\u8981\u5927\u91cf\u5386\u53f2\u67e5\u8be2\u4ee5\u53ca\u91cd\u5efa\u4ee3\u4ef7\u9ad8\u7b49\u9650\u5236\u3002", "method": "\u8be5\u8bba\u6587\u9996\u5148\u63d0\u51fa\u4e86\u201c\u9003\u9038\u786c\u5ea6\u201d\u7684\u6982\u5ff5\u6765\u8bc4\u4f30\u67e5\u8be2\u5468\u56f4\u56fe\u7ed3\u6784\u7684\u8d28\u91cf\u3002\u7136\u540e\uff0c\u5c06\u56fe\u641c\u7d22\u5206\u4e3a\u4e24\u4e2a\u9636\u6bb5\uff0c\u5e76\u57fa\u4e8e\u9003\u9038\u786c\u5ea6\u52a8\u6001\u8bc6\u522b\u548c\u4fee\u590d\u7f3a\u9677\u533a\u57df\u3002\u63d0\u51fa\u4e86\u53ef\u8fbe\u6027\u4fee\u590d\uff08RFix\uff09\u6765\u589e\u5f3a\u5173\u952e\u8282\u70b9\u7684\u53ef\u5bfc\u822a\u6027\uff0c\u4ee5\u53ca\u90bb\u57df\u56fe\u7f3a\u9677\u4fee\u590d\uff08NGFix\uff09\u6765\u63d0\u9ad8\u67e5\u8be2\u5bc6\u96c6\u5206\u5e03\u533a\u57df\u7684\u56fe\u8fde\u901a\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff0c\u5bf9\u4e8eOOD\u67e5\u8be2\uff0c\u572899%\u53ec\u56de\u7387\u4e0b\uff0c\u641c\u7d22\u901f\u5ea6\u6bd4RoarGraph\u5feb2.25\u500d\uff0c\u6bd4HNSW\u5feb6.88\u500d\u3002\u6b64\u5916\uff0c\u7d22\u5f15\u6784\u5efa\u901f\u5ea6\u6bd4RoarGraph\u5feb2.35-9.02\u500d\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684ANNS\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u4fee\u590d\u56fe\u7ed3\u6784\u4e2d\u7684\u7f3a\u9677\u533a\u57df\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u641c\u7d22\u7cbe\u5ea6\u548c\u901f\u5ea6\uff0c\u5c24\u5176\u662f\u5728OOD\u573a\u666f\u4e2d\u3002"}}
{"id": "2510.21762", "categories": ["cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.21762", "abs": "https://arxiv.org/abs/2510.21762", "authors": ["Eric Jeangirard"], "title": "A Multi-lingual Dataset of Classified Paragraphs from Open Access Scientific Publications", "comment": null, "summary": "We present a dataset of 833k paragraphs extracted from CC-BY licensed\nscientific publications, classified into four categories: acknowledgments, data\nmentions, software/code mentions, and clinical trial mentions. The paragraphs\nare primarily in English and French, with additional European languages\nrepresented. Each paragraph is annotated with language identification (using\nfastText) and scientific domain (from OpenAlex). This dataset, derived from the\nFrench Open Science Monitor corpus and processed using GROBID, enables training\nof text classification models and development of named entity recognition\nsystems for scientific literature mining. The dataset is publicly available on\nHuggingFace https://doi.org/10.57967/hf/6679 under a CC-BY license.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u4eceCC-BY\u8bb8\u53ef\u7684\u79d1\u5b66\u51fa\u7248\u7269\u4e2d\u63d0\u53d6\u7684\u5305\u542b833k\u6bb5\u843d\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6bb5\u843d\u88ab\u5206\u4e3a\u56db\u7c7b\uff1a\u81f4\u8c22\u3001\u6570\u636e\u63d0\u53ca\u3001\u8f6f\u4ef6/\u4ee3\u7801\u63d0\u53ca\u548c\u4e34\u5e8a\u8bd5\u9a8c\u63d0\u53ca\u3002", "motivation": "\u8be5\u6570\u636e\u96c6\u65e8\u5728\u4fc3\u8fdb\u6587\u672c\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u79d1\u5b66\u6587\u732e\u6316\u6398\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "\u8be5\u6570\u636e\u96c6\u6765\u81eaFrench Open Science Monitor\u8bed\u6599\u5e93\uff0c\u5e76\u4f7f\u7528GROBID\u8fdb\u884c\u5904\u7406\u3002\u6bb5\u843d\u4f7f\u7528fastText\u8fdb\u884c\u8bed\u8a00\u8bc6\u522b\uff0c\u5e76\u4f7f\u7528OpenAlex\u8fdb\u884c\u79d1\u5b66\u9886\u57df\u5206\u7c7b\u3002", "result": "\u8be5\u6570\u636e\u96c6\u5305\u542b833k\u4e2a\u6bb5\u843d\uff0c\u4e3b\u8981\u4e3a\u82f1\u8bed\u548c\u6cd5\u8bed\uff0c\u5e76\u5305\u542b\u5176\u4ed6\u6b27\u6d32\u8bed\u8a00\u3002\u6bcf\u4e2a\u6bb5\u843d\u90fd\u6807\u6ce8\u4e86\u8bed\u8a00\u548c\u79d1\u5b66\u9886\u57df\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u5df2\u5728HuggingFace\u4e0a\u516c\u5f00\u53d1\u5e03\uff0c\u53ef\u7528\u4e8e\u8bad\u7ec3\u6587\u672c\u5206\u7c7b\u6a21\u578b\u548c\u5f00\u53d1\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7cfb\u7edf\u3002"}}
{"id": "2510.21740", "categories": ["cs.CV", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21740", "abs": "https://arxiv.org/abs/2510.21740", "authors": ["Alexa R. Tartaglini", "Satchel Grant", "Daniel Wurgaft", "Christopher Potts", "Judith E. Fan"], "title": "Diagnosing Bottlenecks in Data Visualization Understanding by Vision-Language Models", "comment": null, "summary": "Data visualizations are vital components of many scientific articles and news\nstories. Current vision-language models (VLMs) still struggle on basic data\nvisualization understanding tasks, but the causes of failure remain unclear.\nAre VLM failures attributable to limitations in how visual information in the\ndata visualization is encoded, how information is transferred between the\nvision and language modules, or how information is processed within the\nlanguage module? We developed FUGU, a suite of data visualization understanding\ntasks, to precisely characterize potential sources of difficulty (e.g.,\nextracting the position of data points, distances between them, and other\nsummary statistics). We used FUGU to investigate three widely used VLMs. To\ndiagnose the sources of errors produced by these models, we used activation\npatching and linear probes to trace information flow through models across a\nvariety of prompting strategies. We found that some models fail to generate the\ncoordinates of individual data points correctly, and these initial errors often\nlead to erroneous final responses. When these models are provided with the\ncorrect coordinates, performance improves substantially. Moreover, even when\nthe model generates an incorrect response, the correct coordinates can be\nsuccessfully read out from the latent representations in the vision encoder,\nsuggesting that the source of these errors lies in the vision-language handoff.\nWe further found that while providing correct coordinates helps with tasks\ninvolving one or a small number of data points, it generally worsens\nperformance for tasks that require extracting statistical relationships across\nmany data points. Fine-tuning models on FUGU also fails to yield ceiling\nperformance. These findings point to architectural constraints in current VLMs\nthat might pose significant challenges for reliable data visualization\nunderstanding.", "AI": {"tldr": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u5728\u7406\u89e3\u6570\u636e\u53ef\u89c6\u5316\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u4f46\u5931\u8d25\u539f\u56e0\u5c1a\u4e0d\u6e05\u695a\u3002", "motivation": "\u63a2\u7a76VLM\u5728\u6570\u636e\u53ef\u89c6\u5316\u7406\u89e3\u4efb\u52a1\u4e2d\u5931\u8d25\u7684\u539f\u56e0\uff0c\u4f8b\u5982\u89c6\u89c9\u4fe1\u606f\u7f16\u7801\u3001\u89c6\u89c9\u548c\u8bed\u8a00\u6a21\u5757\u95f4\u4fe1\u606f\u4f20\u9012\u4ee5\u53ca\u8bed\u8a00\u6a21\u5757\u5185\u90e8\u4fe1\u606f\u5904\u7406\u7684\u5c40\u9650\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aFUGU\u7684\u6570\u636e\u53ef\u89c6\u5316\u7406\u89e3\u4efb\u52a1\u5957\u4ef6\uff0c\u7528\u4e8e\u7cbe\u786e\u63cf\u8ff0\u6f5c\u5728\u7684\u56f0\u96be\u6765\u6e90\u3002\u4f7f\u7528FUGU\u6765\u8c03\u67e5\u4e09\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684VLM\uff0c\u5e76\u4f7f\u7528\u6fc0\u6d3b\u4fee\u8865\u548c\u7ebf\u6027\u63a2\u9488\u6765\u8ffd\u8e2a\u6a21\u578b\u4e2d\u4fe1\u606f\u6d41\u3002", "result": "\u53d1\u73b0\u4e00\u4e9b\u6a21\u578b\u65e0\u6cd5\u6b63\u786e\u751f\u6210\u5355\u4e2a\u6570\u636e\u70b9\u7684\u5750\u6807\uff0c\u5e76\u4e14\u8fd9\u4e9b\u521d\u59cb\u9519\u8bef\u901a\u5e38\u4f1a\u5bfc\u81f4\u9519\u8bef\u7684\u6700\u7ec8\u54cd\u5e94\u3002\u5f53\u63d0\u4f9b\u6b63\u786e\u7684\u5750\u6807\u65f6\uff0c\u6027\u80fd\u4f1a\u663e\u7740\u63d0\u9ad8\u3002\u5373\u4f7f\u6a21\u578b\u751f\u6210\u4e86\u4e0d\u6b63\u786e\u7684\u54cd\u5e94\uff0c\u4e5f\u53ef\u4ee5\u4ece\u89c6\u89c9\u7f16\u7801\u5668\u4e2d\u7684\u6f5c\u5728\u8868\u793a\u4e2d\u6210\u529f\u8bfb\u53d6\u6b63\u786e\u7684\u5750\u6807\uff0c\u8fd9\u8868\u660e\u8fd9\u4e9b\u9519\u8bef\u7684\u6839\u6e90\u5728\u4e8e\u89c6\u89c9\u8bed\u8a00\u7684\u5207\u6362\u3002\u63d0\u4f9b\u6b63\u786e\u7684\u5750\u6807\u6709\u52a9\u4e8e\u6d89\u53ca\u5c11\u91cf\u6570\u636e\u70b9\u7684\u4efb\u52a1\uff0c\u4f46\u901a\u5e38\u4f1a\u964d\u4f4e\u63d0\u53d6\u8de8\u591a\u4e2a\u6570\u636e\u70b9\u7684\u7edf\u8ba1\u5173\u7cfb\u7684\u4efb\u52a1\u7684\u6027\u80fd\u3002\u5728FUGU\u4e0a\u5fae\u8c03\u6a21\u578b\u4e5f\u672a\u80fd\u4ea7\u751f\u6700\u4f73\u6027\u80fd\u3002", "conclusion": "\u76ee\u524d\u7684VLM\u5b58\u5728\u67b6\u6784\u7ea6\u675f\uff0c\u8fd9\u53ef\u80fd\u5bf9\u53ef\u9760\u7684\u6570\u636e\u53ef\u89c6\u5316\u7406\u89e3\u6784\u6210\u91cd\u5927\u6311\u6218\u3002"}}
{"id": "2510.21720", "categories": ["cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21720", "abs": "https://arxiv.org/abs/2510.21720", "authors": ["Anant Pareek"], "title": "A Multi-Component AI Framework for Computational Psychology: From Robust Predictive Modeling to Deployed Generative Dialogue", "comment": null, "summary": "The confluence of Artificial Intelligence and Computational Psychology\npresents an opportunity to model, understand, and interact with complex human\npsychological states through computational means. This paper presents a\ncomprehensive, multi-faceted framework designed to bridge the gap between\nisolated predictive modeling and an interactive system for psychological\nanalysis. The methodology encompasses a rigorous, end-to-end development\nlifecycle. First, foundational performance benchmarks were established on four\ndiverse psychological datasets using classical machine learning techniques.\nSecond, state-of-the-art transformer models were fine-tuned, a process that\nnecessitated the development of effective solutions to overcome critical\nengineering challenges, including the resolution of numerical instability in\nregression tasks and the creation of a systematic workflow for conducting\nlarge-scale training under severe resource constraints. Third, a generative\nlarge language model (LLM) was fine-tuned using parameter-efficient techniques\nto function as an interactive \"Personality Brain.\" Finally, the entire suite of\npredictive and generative models was architected and deployed as a robust,\nscalable microservices ecosystem. Key findings include the successful\nstabilization of transformer-based regression models for affective computing,\nshowing meaningful predictive performance where standard approaches failed, and\nthe development of a replicable methodology for democratizing large-scale AI\nresearch. The significance of this work lies in its holistic approach,\ndemonstrating a complete research-to-deployment pipeline that integrates\npredictive analysis with generative dialogue, thereby providing a practical\nmodel for future research in computational psychology and human-AI interaction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6027\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5f25\u5408\u5b64\u7acb\u7684\u9884\u6d4b\u6a21\u578b\u548c\u7528\u4e8e\u5fc3\u7406\u5206\u6790\u7684\u4ea4\u4e92\u5f0f\u7cfb\u7edf\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u5229\u7528\u4eba\u5de5\u667a\u80fd\u548c\u8ba1\u7b97\u5fc3\u7406\u5b66\u7684\u878d\u5408\uff0c\u901a\u8fc7\u8ba1\u7b97\u624b\u6bb5\u5efa\u6a21\u3001\u7406\u89e3\u548c\u4e0e\u590d\u6742\u7684\u4eba\u7c7b\u5fc3\u7406\u72b6\u6001\u4e92\u52a8\u3002", "method": "\u8be5\u65b9\u6cd5\u5305\u62ec\u4e00\u4e2a\u4e25\u8c28\u7684\u7aef\u5230\u7aef\u5f00\u53d1\u751f\u547d\u5468\u671f\u3002\u9996\u5148\uff0c\u4f7f\u7528\u7ecf\u5178\u673a\u5668\u5b66\u4e60\u6280\u672f\u5728\u56db\u4e2a\u4e0d\u540c\u7684\u5fc3\u7406\u6570\u636e\u96c6\u4e0a\u5efa\u7acb\u57fa\u7840\u6027\u80fd\u57fa\u51c6\u3002\u5176\u6b21\uff0c\u5bf9\u6700\u5148\u8fdb\u7684Transformer\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u7b2c\u4e09\uff0c\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u6280\u672f\u5bf9\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u4e86\u5fae\u8c03\uff0c\u4f7f\u5176\u53ef\u4ee5\u5145\u5f53\u4ea4\u4e92\u5f0f\u201c\u4eba\u683c\u5927\u8111\u201d\u3002\u6700\u540e\uff0c\u6574\u4e2a\u9884\u6d4b\u548c\u751f\u6210\u6a21\u578b\u5957\u4ef6\u88ab\u6784\u5efa\u548c\u90e8\u7f72\u4e3a\u7a33\u5065\u3001\u53ef\u6269\u5c55\u7684\u5fae\u670d\u52a1\u751f\u6001\u7cfb\u7edf\u3002", "result": "\u4e3b\u8981\u53d1\u73b0\u5305\u62ec\u6210\u529f\u7a33\u5b9a\u4e86\u7528\u4e8e\u60c5\u611f\u8ba1\u7b97\u7684\u57fa\u4e8eTransformer\u7684\u56de\u5f52\u6a21\u578b\uff0c\u5728\u6807\u51c6\u65b9\u6cd5\u5931\u8d25\u7684\u5730\u65b9\u663e\u793a\u51fa\u6709\u610f\u4e49\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u4ee5\u53ca\u5f00\u53d1\u4e86\u4e00\u79cd\u53ef\u590d\u5236\u7684\u65b9\u6cd5\u6765 democratizing \u5927\u89c4\u6a21\u4eba\u5de5\u667a\u80fd\u7814\u7a76\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u7684\u610f\u4e49\u5728\u4e8e\u5176\u6574\u4f53\u65b9\u6cd5\uff0c\u5c55\u793a\u4e86\u4e00\u4e2a\u5b8c\u6574\u7684\u4ece\u7814\u7a76\u5230\u90e8\u7f72\u7684\u7ba1\u9053\uff0c\u8be5\u7ba1\u9053\u5c06\u9884\u6d4b\u5206\u6790\u4e0e\u751f\u6210\u5f0f\u5bf9\u8bdd\u76f8\u7ed3\u5408\uff0c\u4ece\u800c\u4e3a\u8ba1\u7b97\u5fc3\u7406\u5b66\u548c\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u7684\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6a21\u578b\u3002"}}
{"id": "2510.21710", "categories": ["cs.LG", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.21710", "abs": "https://arxiv.org/abs/2510.21710", "authors": ["Lorenzo Porcelli"], "title": "A Feature Engineering Approach for Business Impact-Oriented Failure Detection in Distributed Instant Payment Systems", "comment": null, "summary": "Instant payment infrastructures have stringent performance requirements,\nprocessing millions of transactions daily with zero-downtime expectations.\nTraditional monitoring approaches fail to bridge the gap between technical\ninfrastructure metrics and business process visibility. We introduce a novel\nfeature engineering approach based on processing times computed between\nconsecutive ISO 20022 message exchanges, creating a compact representation of\nsystem state. By applying anomaly detection to these features, we enable early\nfailure detection and localization, allowing incident classification.\nExperimental evaluation on the TARGET Instant Payment Settlement (TIPS) system,\nusing both real-world incidents and controlled simulations, demonstrates the\napproach's effectiveness in detecting diverse anomaly patterns and provides\ninherently interpretable explanations that enable operators to understand the\nbusiness impact. By mapping features to distinct processing phases, the\nresulting framework differentiates between internal and external payment system\nissues, significantly reduces investigation time, and bridges observability\ngaps in distributed systems where transaction state is fragmented across\nmultiple entities.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8eISO 20022\u6d88\u606f\u4ea4\u6362\u5904\u7406\u65f6\u95f4\u7684\u7279\u5f81\u5de5\u7a0b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5373\u65f6\u652f\u4ed8\u57fa\u7840\u8bbe\u65bd\u7684\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u4f20\u7edf\u76d1\u63a7\u65b9\u6cd5\u65e0\u6cd5\u5f25\u5408\u6280\u672f\u6307\u6807\u548c\u4e1a\u52a1\u6d41\u7a0b\u53ef\u89c1\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5373\u65f6\u652f\u4ed8\u7cfb\u7edf\u96f6\u505c\u673a\u7684\u9ad8\u6027\u80fd\u8981\u6c42\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8ba1\u7b97\u8fde\u7eedISO 20022\u6d88\u606f\u4ea4\u6362\u4e4b\u95f4\u7684\u5904\u7406\u65f6\u95f4\u6765\u6784\u5efa\u7cfb\u7edf\u72b6\u6001\u7684\u7d27\u51d1\u8868\u793a\uff0c\u5e76\u5e94\u7528\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728TARGET\u5373\u65f6\u652f\u4ed8\u7ed3\u7b97\u7cfb\u7edf\uff08TIPS\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u5404\u79cd\u5f02\u5e38\u6a21\u5f0f\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u89e3\u91ca\uff0c\u5e2e\u52a9\u8fd0\u7ef4\u4eba\u5458\u7406\u89e3\u4e1a\u52a1\u5f71\u54cd\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5c06\u7279\u5f81\u6620\u5c04\u5230\u4e0d\u540c\u7684\u5904\u7406\u9636\u6bb5\uff0c\u533a\u5206\u5185\u90e8\u548c\u5916\u90e8\u652f\u4ed8\u7cfb\u7edf\u95ee\u9898\uff0c\u663e\u8457\u51cf\u5c11\u8c03\u67e5\u65f6\u95f4\uff0c\u5e76\u5f25\u5408\u5206\u5e03\u5f0f\u7cfb\u7edf\u4e2d\u4ea4\u6613\u72b6\u6001\u5206\u6563\u5728\u591a\u4e2a\u5b9e\u4f53\u4e2d\u7684\u53ef\u89c2\u5bdf\u6027\u5dee\u8ddd\u3002"}}
{"id": "2510.21724", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21724", "abs": "https://arxiv.org/abs/2510.21724", "authors": ["Apoorva Chavali", "Reeve Menezes"], "title": "Words to Waves: Emotion-Adaptive Music Recommendation System", "comment": null, "summary": "Current recommendation systems often tend to overlook emotional context and\nrely on historical listening patterns or static mood tags. This paper\nintroduces a novel music recommendation framework employing a variant of Wide\nand Deep Learning architecture that takes in real-time emotional states\ninferred directly from natural language as inputs and recommends songs that\nclosely portray the mood. The system captures emotional contexts from\nuser-provided textual descriptions by using transformer-based embeddings, which\nwere finetuned to predict the emotional dimensions of valence-arousal. The deep\ncomponent of the architecture utilizes these embeddings to generalize unseen\nemotional patterns, while the wide component effectively memorizes user-emotion\nand emotion-genre associations through cross-product features. Experimental\nresults show that personalized music selections positively influence the user's\nemotions and lead to a significant improvement in emotional relevance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u97f3\u4e50\u63a8\u8350\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528 Wide and Deep Learning \u67b6\u6784\u7684\u53d8\u4f53\uff0c\u8be5\u67b6\u6784\u4ee5\u76f4\u63a5\u4ece\u81ea\u7136\u8bed\u8a00\u63a8\u65ad\u51fa\u7684\u5b9e\u65f6\u60c5\u7eea\u72b6\u6001\u4f5c\u4e3a\u8f93\u5165\uff0c\u5e76\u63a8\u8350\u80fd\u591f\u5bc6\u5207\u63cf\u7ed8\u60c5\u7eea\u7684\u6b4c\u66f2\u3002", "motivation": "\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u901a\u5e38\u503e\u5411\u4e8e\u5ffd\u7565\u60c5\u611f\u80cc\u666f\uff0c\u800c\u4f9d\u8d56\u4e8e\u5386\u53f2\u6536\u542c\u6a21\u5f0f\u6216\u9759\u6001\u60c5\u7eea\u6807\u7b7e\u3002", "method": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u4f7f\u7528\u57fa\u4e8e Transformer \u7684\u5d4c\u5165\u6765\u6355\u83b7\u7528\u6237\u63d0\u4f9b\u7684\u6587\u672c\u63cf\u8ff0\u4e2d\u7684\u60c5\u611f\u80cc\u666f\uff0c\u8fd9\u4e9b\u5d4c\u5165\u7ecf\u8fc7\u5fae\u8c03\u4ee5\u9884\u6d4b\u6548\u4ef7-\u5524\u9192\u7684\u60c5\u611f\u7ef4\u5ea6\u3002\u8be5\u67b6\u6784\u7684\u6df1\u5ea6\u7ec4\u4ef6\u5229\u7528\u8fd9\u4e9b\u5d4c\u5165\u6765\u6982\u62ec\u770b\u4e0d\u89c1\u7684\u60c5\u611f\u6a21\u5f0f\uff0c\u800c\u5bbd\u5ea6\u7ec4\u4ef6\u901a\u8fc7\u4ea4\u53c9\u79ef\u7279\u5f81\u6709\u6548\u5730\u8bb0\u5fc6\u7528\u6237-\u60c5\u611f\u548c\u60c5\u611f-\u6d41\u6d3e\u5173\u8054\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e2a\u6027\u5316\u7684\u97f3\u4e50\u9009\u62e9\u5bf9\u7528\u6237\u7684\u60c5\u7eea\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\uff0c\u5e76\u663e\u7740\u63d0\u9ad8\u60c5\u7eea\u76f8\u5173\u6027\u3002", "conclusion": "\u4e2a\u6027\u5316\u7684\u97f3\u4e50\u9009\u62e9\u53ef\u4ee5\u79ef\u6781\u5f71\u54cd\u7528\u6237\u7684\u60c5\u7eea\uff0c\u5e76\u663e\u7740\u63d0\u9ad8\u60c5\u7eea\u76f8\u5173\u6027\u3002"}}
{"id": "2510.23587", "categories": ["cs.DB", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.23587", "abs": "https://arxiv.org/abs/2510.23587", "authors": ["Yizhang Zhu", "Liangwei Wang", "Chenyu Yang", "Xiaotian Lin", "Boyan Li", "Wei Zhou", "Xinyu Liu", "Zhangyang Peng", "Tianqi Luo", "Yu Li", "Chengliang Chai", "Chong Chen", "Shimin Di", "Ju Fan", "Ji Sun", "Nan Tang", "Fugee Tsung", "Jiannan Wang", "Chenglin Wu", "Yanwei Xu", "Shaolei Zhang", "Yong Zhang", "Xuanhe Zhou", "Guoliang Li", "Yuyu Luo"], "title": "A Survey of Data Agents: Emerging Paradigm or Overstated Hype?", "comment": "Please refer to our paper list and companion materials at:\n  https://github.com/HKUSTDial/awesome-data-agents", "summary": "The rapid advancement of large language models (LLMs) has spurred the\nemergence of data agents--autonomous systems designed to orchestrate Data + AI\necosystems for tackling complex data-related tasks. However, the term \"data\nagent\" currently suffers from terminological ambiguity and inconsistent\nadoption, conflating simple query responders with sophisticated autonomous\narchitectures. This terminological ambiguity fosters mismatched user\nexpectations, accountability challenges, and barriers to industry growth.\nInspired by the SAE J3016 standard for driving automation, this survey\nintroduces the first systematic hierarchical taxonomy for data agents,\ncomprising six levels that delineate and trace progressive shifts in autonomy,\nfrom manual operations (L0) to a vision of generative, fully autonomous data\nagents (L5), thereby clarifying capability boundaries and responsibility\nallocation. Through this lens, we offer a structured review of existing\nresearch arranged by increasing autonomy, encompassing specialized data agents\nfor data management, preparation, and analysis, alongside emerging efforts\ntoward versatile, comprehensive systems with enhanced autonomy. We further\nanalyze critical evolutionary leaps and technical gaps for advancing data\nagents, especially the ongoing L2-to-L3 transition, where data agents evolve\nfrom procedural execution to autonomous orchestration. Finally, we conclude\nwith a forward-looking roadmap, envisioning the advent of proactive, generative\ndata agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u4ee3\u7406\u7684\u5206\u5c42\u5206\u7c7b\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u5f53\u524d\u6570\u636e\u4ee3\u7406\u9886\u57df\u672f\u8bed\u542b\u7cca\u4e0d\u6e05\u548c\u5e94\u7528\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u6570\u636e\u4ee3\u7406\u9886\u57df\u5b58\u5728\u672f\u8bed\u542b\u7cca\u4e0d\u6e05\u548c\u5e94\u7528\u4e0d\u4e00\u81f4\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u7528\u6237\u671f\u671b\u4e0d\u5339\u914d\u3001\u8d23\u4efb\u5212\u5206\u4e0d\u660e\u786e\u4ee5\u53ca\u884c\u4e1a\u589e\u957f\u53d7\u963b\u3002", "method": "\u672c\u6587\u53d7\u5230SAE J3016\u9a7e\u9a76\u81ea\u52a8\u5316\u6807\u51c6\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u516d\u4e2a\u5c42\u7ea7\u7684\u6570\u636e\u4ee3\u7406\u5206\u5c42\u5206\u7c7b\u6cd5\uff0c\u4ece\u624b\u52a8\u64cd\u4f5c\uff08L0\uff09\u5230\u5b8c\u5168\u81ea\u4e3b\u7684\u6570\u636e\u4ee3\u7406\uff08L5\uff09\u3002", "result": "\u672c\u6587\u901a\u8fc7\u8be5\u5206\u7c7b\u6cd5\uff0c\u5bf9\u73b0\u6709\u7814\u7a76\u8fdb\u884c\u4e86\u7ed3\u6784\u5316\u7efc\u8ff0\uff0c\u6db5\u76d6\u4e86\u6570\u636e\u7ba1\u7406\u3001\u51c6\u5907\u548c\u5206\u6790\u7b49\u9886\u57df\u7684\u4e13\u4e1a\u6570\u636e\u4ee3\u7406\uff0c\u4ee5\u53ca\u65b0\u5174\u7684\u3001\u5177\u6709\u589e\u5f3a\u81ea\u4e3b\u6027\u7684\u901a\u7528\u7cfb\u7edf\u3002\u5206\u6790\u4e86\u63a8\u52a8\u6570\u636e\u4ee3\u7406\u53d1\u5c55\u7684\u5173\u952e\u8fdb\u5316\u98de\u8dc3\u548c\u6280\u672f\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728L2\u5230L3\u7684\u8fc7\u6e21\u9636\u6bb5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u524d\u77bb\u6027\u7684\u8def\u7ebf\u56fe\uff0c\u5c55\u671b\u4e86\u4e3b\u52a8\u7684\u3001\u751f\u6210\u5f0f\u6570\u636e\u4ee3\u7406\u7684\u51fa\u73b0\u3002"}}
{"id": "2510.21853", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21853", "abs": "https://arxiv.org/abs/2510.21853", "authors": ["Debdeep Sanyal", "Aakash Sen Sharma", "Dhruv Kumar", "Saurabh Deshpande", "Murari Mandal"], "title": "Policy Optimization Prefers The Path of Least Resistance", "comment": "21 pages, 8 figures, 2 tables", "summary": "Policy optimization (PO) algorithms are used to refine Large Language Models\nfor complex, multi-step reasoning. Current state-of-the-art pipelines enforce a\nstrict think-then-answer format to elicit chain-of-thought (CoT); however, the\nbehavior of PO when these rigid constraints are relaxed into an open-ended CoT\nstructure remains an under-studied question. We investigate this gap with an\nextensive suite of controlled experiments and identify a consistent principle:\n\\textit{policy optimization consistently follows the path of least resistance}.\nWhen afforded the flexibility to interleave reasoning and response, policy\noptimization consistently learns to discard explicit reasoning, causing the\npolicy to degenerate to a direct \\texttt{<answer>}-only format. This outcome\nholds true across various models and algorithms. We find that this collapse in\nformat is persistent even when the complex \\texttt{<think><answer>} format is\nassigned up to 4x larger reward weights. We formalize this principle through a\nseries of controlled reward decomposition experiments, demonstrating a clear\nhierarchy: PO systematically optimizes for the simplest reward component first,\na preference that holds even when faced with mutually exclusive choices or\nstrong incentives for more complex behaviors. Finally, we show that successful\nconvergence on the high-reward shortcut is not a low-effort drift but is driven\nby the optimization process that requires the KL-regularized policy to have\nsufficient freedom to make a significant shift from its initial prior. Our\nfindings reveal that granting policies the freedom to diverge is a double-edged\nsword: while necessary for discovering high-reward shortcuts, it also creates a\npowerful incentive to game the simplest aspects of the reward function, posing\na critical challenge for reward hacking under alignment.", "AI": {"tldr": "\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u5728\u5f00\u653e\u5f0f CoT \u7ed3\u6784\u4e2d\u4f1a\u503e\u5411\u4e8e\u9009\u62e9\u963b\u529b\u6700\u5c0f\u7684\u8def\u5f84\uff0c\u5bfc\u81f4\u6a21\u578b\u9000\u5316\u4e3a\u76f4\u63a5\u56de\u7b54\u5f62\u5f0f\u3002", "motivation": "\u7814\u7a76\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u5728\u653e\u5bbd\u4e25\u683c\u7684\u601d\u7ef4\u94fe (CoT) \u7ea6\u675f\u6761\u4ef6\u4e0b\u7684\u884c\u4e3a\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4e00\u7cfb\u5217\u53d7\u63a7\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e0d\u540c\u6a21\u578b\u548c\u7b97\u6cd5\u5728\u5f00\u653e\u5f0f CoT \u7ed3\u6784\u4e0b\u7684\u7b56\u7565\u4f18\u5316\u884c\u4e3a\u3002", "result": "\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u503e\u5411\u4e8e\u653e\u5f03\u663e\u5f0f\u63a8\u7406\uff0c\u8f6c\u800c\u76f4\u63a5\u751f\u6210\u7b54\u6848\uff0c\u5373\u4f7f\u5bf9\u590d\u6742\u7684 \") \u683c\u5f0f\u8d4b\u4e88\u66f4\u9ad8\u7684\u5956\u52b1\u6743\u91cd\uff0c\u7ed3\u679c\u4f9d\u7136\u6210\u7acb\u3002\u7b56\u7565\u4f18\u5316\u4f1a\u4f18\u5148\u4f18\u5316\u6700\u7b80\u5355\u7684\u5956\u52b1\u7ec4\u6210\u90e8\u5206\u3002\u6536\u655b\u5230\u9ad8\u5956\u52b1\u6377\u5f84\u5e76\u975e\u5076\u7136\uff0c\u800c\u662f\u4f18\u5316\u8fc7\u7a0b\u9a71\u52a8\u7684\u3002", "conclusion": "\u7ed9\u4e88\u7b56\u7565\u81ea\u7531\u53d1\u6563\u662f\u4e00\u628a\u53cc\u5203\u5251\uff0c\u867d\u7136\u5bf9\u53d1\u73b0\u9ad8\u5956\u52b1\u6377\u5f84\u662f\u5fc5\u8981\u7684\uff0c\u4f46\u4e5f\u9f13\u52b1\u5229\u7528\u5956\u52b1\u51fd\u6570\u4e2d\u6700\u7b80\u5355\u7684\u90e8\u5206\uff0c\u5bf9\u5956\u52b1\u653b\u51fb\u63d0\u51fa\u4e86\u6311\u6218\u3002"}}
{"id": "2510.21757", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.21757", "abs": "https://arxiv.org/abs/2510.21757", "authors": ["Mihir Gupta", "Pratik Desai", "Ross Greer"], "title": "Agro-Consensus: Semantic Self-Consistency in Vision-Language Models for Crop Disease Management in Developing Countries", "comment": null, "summary": "Agricultural disease management in developing countries such as India, Kenya,\nand Nigeria faces significant challenges due to limited access to expert plant\npathologists, unreliable internet connectivity, and cost constraints that\nhinder the deployment of large-scale AI systems. This work introduces a\ncost-effective self-consistency framework to improve vision-language model\n(VLM) reliability for agricultural image captioning. The proposed method\nemploys semantic clustering, using a lightweight (80MB) pre-trained embedding\nmodel to group multiple candidate responses. It then selects the most coherent\ncaption -- containing a diagnosis, symptoms, analysis, treatment, and\nprevention recommendations -- through a cosine similarity-based consensus. A\npractical human-in-the-loop (HITL) component is incorporated, wherein user\nconfirmation of the crop type filters erroneous generations, ensuring\nhigher-quality input for the consensus mechanism. Applied to the publicly\navailable PlantVillage dataset using a fine-tuned 3B-parameter PaliGemma model,\nour framework demonstrates improvements over standard decoding methods.\nEvaluated on 800 crop disease images with up to 21 generations per image, our\nsingle-cluster consensus method achieves a peak accuracy of 83.1% with 10\ncandidate generations, compared to the 77.5% baseline accuracy of greedy\ndecoding. The framework's effectiveness is further demonstrated when\nconsidering multiple clusters; accuracy rises to 94.0% when a correct response\nis found within any of the top four candidate clusters, outperforming the 88.5%\nachieved by a top-4 selection from the baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u7684\u81ea\u6d3d\u6846\u67b6\uff0c\u4ee5\u63d0\u9ad8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u519c\u4e1a\u56fe\u50cf\u63cf\u8ff0\u4e2d\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u53d1\u5c55\u4e2d\u56fd\u5bb6\u5728\u519c\u4e1a\u75be\u75c5\u7ba1\u7406\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u56e0\u4e3a\u7f3a\u4e4f\u4e13\u5bb6\u3001\u7f51\u7edc\u4e0d\u53ef\u9760\u4e14\u6210\u672c\u9ad8\u6602\uff0c\u963b\u788d\u4e86\u5927\u89c4\u6a21\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u90e8\u7f72\u3002", "method": "\u91c7\u7528\u8bed\u4e49\u805a\u7c7b\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u9884\u8bad\u7ec3\u5d4c\u5165\u6a21\u578b\u5bf9\u591a\u4e2a\u5019\u9009\u54cd\u5e94\u8fdb\u884c\u5206\u7ec4\uff0c\u7136\u540e\u901a\u8fc7\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u7684\u5171\u8bc6\u9009\u62e9\u6700\u8fde\u8d2f\u7684\u6807\u9898\u3002 \u7ed3\u5408\u4eba\u5de5\u53c2\u4e0e\uff08HITL\uff09\u7ec4\u4ef6\uff0c\u7528\u6237\u786e\u8ba4\u4f5c\u7269\u7c7b\u578b\uff0c\u8fc7\u6ee4\u6389\u9519\u8bef\u7684\u751f\u6210\uff0c\u786e\u4fdd\u4e3a\u5171\u8bc6\u673a\u5236\u63d0\u4f9b\u66f4\u9ad8\u8d28\u91cf\u7684\u8f93\u5165\u3002", "result": "\u5728PlantVillage\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u5fae\u8c03\u76843B\u53c2\u6570PaliGemma\u6a21\u578b\uff0c\u8be5\u6846\u67b6\u7684\u6027\u80fd\u4f18\u4e8e\u6807\u51c6\u89e3\u7801\u65b9\u6cd5\u3002\u5355\u96c6\u7fa4\u5171\u8bc6\u65b9\u6cd5\u572810\u4e2a\u5019\u9009\u751f\u6210\u4e2d\u5b9e\u73b0\u4e8683.1%\u7684\u5cf0\u503c\u7cbe\u5ea6\uff0c\u800c\u8d2a\u5a6a\u89e3\u7801\u7684\u57fa\u7ebf\u7cbe\u5ea6\u4e3a77.5%\u3002\u5f53\u8003\u8651\u591a\u4e2a\u96c6\u7fa4\u65f6\uff0c\u51c6\u786e\u7387\u8fdb\u4e00\u6b65\u63d0\u9ad8\uff1b\u5728\u524d\u56db\u4e2a\u5019\u9009\u96c6\u7fa4\u4e2d\u627e\u5230\u6b63\u786e\u54cd\u5e94\u65f6\uff0c\u51c6\u786e\u7387\u4e0a\u5347\u81f394.0%\uff0c\u4f18\u4e8e\u57fa\u7ebf\u4e2d\u524d4\u4e2a\u9009\u62e9\u6240\u8fbe\u5230\u768488.5%\u3002", "conclusion": "\u8be5\u6846\u67b6\u5728\u63d0\u9ad8\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u519c\u4e1a\u56fe\u50cf\u63cf\u8ff0\u4e2d\u7684\u53ef\u9760\u6027\u65b9\u9762\u6709\u6548\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\u7684\u73af\u5883\u4e2d\u3002"}}
{"id": "2510.21721", "categories": ["cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.21721", "abs": "https://arxiv.org/abs/2510.21721", "authors": ["Kentaro Ueda", "Takehiro Takayanagi"], "title": "PREFINE: Personalized Story Generation via Simulated User Critics and User-Specific Rubric Generation", "comment": null, "summary": "While recent advances in Large Language Models (LLMs) have improved the\nquality of creative text generation, significant challenges remain in producing\npersonalized stories that reflect individual user preferences. Conventional\napproaches rely on explicit feedback or fine-tuning, which presents practical\nissues regarding user burden, data collection, computational costs, and\nprivacy. In this work, we propose PREFINE (Persona-and-Rubric Guided\nCritique-and-Refine), a novel framework that extends the Critique-and-Refine\nparadigm to personalization. PREFINE constructs a pseudo-user agent from a\nuser's interaction history and generates user-specific rubrics (evaluation\ncriteria). By having this agent critique and refine outputs on the user's\nbehalf based on these tailored rubrics, our method achieves personalized\ngeneration without requiring parameter updates or direct user feedback. We\nconducted a comprehensive evaluation on the PerDOC and PerMPST story datasets.\nWe designed three baseline methods and several model variants to verify the\ncontribution of each component of our framework. In automatic evaluations\n(LLM-as-a-Judge), PREFINE achieved higher win rates and statistically\nsignificant scores than the baselines, without compromising general story\nquality. Analysis of the model variants confirmed that both the pseudo-user\nagent and the user-specific rubrics are crucial for enhancing personalization\nperformance. Beyond story generation, our approach holds potential for enabling\nefficient personalization in broader applications, such as dialogue systems,\neducation, and recommendation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e2a\u6027\u5316\u6545\u4e8b\u751f\u6210\u6846\u67b6\uff0c\u65e0\u9700\u5fae\u8c03\u6216\u76f4\u63a5\u7528\u6237\u53cd\u9988\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u663e\u5f0f\u53cd\u9988\u6216\u5fae\u8c03\uff0c\u5b58\u5728\u7528\u6237\u8d1f\u62c5\u3001\u6570\u636e\u6536\u96c6\u3001\u8ba1\u7b97\u6210\u672c\u548c\u9690\u79c1\u95ee\u9898\u3002", "method": "\u63d0\u51faPREFINE\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u6269\u5c55\u4e86Critique-and-Refine\u8303\u5f0f\u4ee5\u5b9e\u73b0\u4e2a\u6027\u5316\u3002PREFINE\u4ece\u7528\u6237\u7684\u4e92\u52a8\u5386\u53f2\u4e2d\u6784\u5efa\u4e00\u4e2a\u4f2a\u7528\u6237\u4ee3\u7406\uff0c\u5e76\u751f\u6210\u7528\u6237\u7279\u5b9a\u7684rubrics\uff08\u8bc4\u4f30\u6807\u51c6\uff09\u3002", "result": "\u5728PerDOC\u548cPerMPST\u6545\u4e8b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u7efc\u5408\u8bc4\u4f30\u3002\u81ea\u52a8\u8bc4\u4f30\u8868\u660e\uff0cPREFINE\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f97\u4e86\u66f4\u9ad8\u7684\u80dc\u7387\u548c\u7edf\u8ba1\u4e0a\u663e\u8457\u7684\u5206\u6570\uff0c\u4e14\u4e0d\u5f71\u54cd\u4e00\u822c\u7684\u6545\u4e8b\u8d28\u91cf\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u5bf9\u8bdd\u7cfb\u7edf\u3001\u6559\u80b2\u548c\u63a8\u8350\u7b49\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u73b0\u9ad8\u6548\u4e2a\u6027\u5316\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.21770", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.21770", "abs": "https://arxiv.org/abs/2510.21770", "authors": ["Jinwoo Baek"], "title": "Numerical Fragility in Transformers: A Layer-wise Theory for Explaining, Forecasting, and Mitigating Instability", "comment": "15 pages", "summary": "Transformers trained in low precision can suffer forward-error amplification.\nWe give a first-order, module-wise theory that predicts when and where errors\ngrow. For self-attention we derive a per-layer bound that factorizes into three\ninterpretable diagnostics: a score-scale ratio $\\kappa_{\\rm score}$, a rowwise\nsoftmax sensitivity $\\kappa_{\\rm softmax}$, and value conditioning $\\kappa(V)$.\nWe prove a residual relaxation inequality showing that residual blocks\nattenuate depth-wise accumulation, and we introduce a precision- and\nwidth-aware LayerNorm indicator $\\rho_{\\rm LN}$ with a matching first-order\nbound in the $\\epsilon$-dominated regime. These pieces yield a unified\nforward-stability bound whose right-hand side is directly estimable during\ntraining.\n  On Tiny-ViT/CIFAR-10 we evaluate the bound and components. (1) The combined\npredictor $\\kappa_{\\rm softmax},(1+\\kappa_{\\rm\nscore}),\\kappa(V),|W_O|2+\\kappa{\\rm eff}+C_{\\rm LN}$ tracks\nFP32$\\leftrightarrow$LP mismatches across seeds, widths, and precisions;\nscaling by $\\epsilon_{\\rm mach}$ collapses mixed-precision points. (2) The\ntime-series maximum of $\\kappa_{\\rm softmax}$ acts as an early-warning signal,\nleading error spikes by 16-24 steps (corr. 0.65-0.82; permutation\n$p!\\approx!10^{-3}$; Precision@K 0.89-1.00). (3) Guided by $\\rho_{\\rm LN}$, a\nsmall LayerNorm-$\\epsilon$ tweak targeting $\\rho_\\star$ gives consistent\nstabilization (mean tail-loss $\\downarrow\\ \\approx0.010$ at $\\rho_\\star!=!0.6$,\ncap$=10^{-2}$) with negligible overhead.\n  Overall, our theory supplies actionable, unitless diagnostics that (i)\nexplain when self-attention is fragile, (ii) forecast instability, and (iii)\nmotivate a minimally invasive mitigation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u7684 Transformers \u4e2d\u7684\u524d\u5411\u8bef\u5dee\u653e\u5927\u95ee\u9898\u3002", "motivation": "\u7814\u7a76 Transformer \u5728\u4f4e\u7cbe\u5ea6\u8bad\u7ec3\u4e2d\u8bef\u5dee\u589e\u957f\u7684\u539f\u56e0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u7684\u7406\u8bba\uff0c\u7528\u4e8e\u9884\u6d4b\u8bef\u5dee\u589e\u957f\u7684\u65f6\u95f4\u548c\u4f4d\u7f6e\u3002\u8be5\u7406\u8bba\u4e3a\u81ea\u6ce8\u610f\u529b\u673a\u5236\u63a8\u5bfc\u4e86\u4e00\u4e2a\u9010\u5c42\u754c\u9650\uff0c\u5e76\u5f15\u5165\u4e86 LayerNorm \u6307\u6807\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u7406\u8bba\u7684\u6709\u6548\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c0f\u7684 LayerNorm \u8c03\u6574\u6765\u7a33\u5b9a\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u7406\u8bba\u63d0\u4f9b\u53ef\u64cd\u4f5c\u7684\u8bca\u65ad\u5de5\u5177\uff0c\u53ef\u4ee5\u89e3\u91ca\u81ea\u6ce8\u610f\u529b\u673a\u5236\u4f55\u65f6\u8106\u5f31\uff0c\u9884\u6d4b\u4e0d\u7a33\u5b9a\u6027\uff0c\u5e76\u4fc3\u4f7f\u8fdb\u884c\u6700\u5c0f\u9650\u5ea6\u7684\u5e72\u9884\u3002"}}
{"id": "2510.21726", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21726", "abs": "https://arxiv.org/abs/2510.21726", "authors": ["Weichen Wang", "Chengchun Shi"], "title": "From Authors to Reviewers: Leveraging Rankings to Improve Peer Review", "comment": null, "summary": "This paper is a discussion of the 2025 JASA discussion paper by Su et al.\n(2025). We would like to congratulate the authors on conducting a comprehensive\nand insightful empirical investigation of the 2023 ICML ranking data. The\nreview quality of machine learning (ML) conferences has become a big concern in\nrecent years, due to the rapidly growing number of submitted manuscripts. In\nthis discussion, we propose an approach alternative to Su et al. (2025) that\nleverages ranking information from reviewers rather than authors. We simulate\nreview data that closely mimics the 2023 ICML conference submissions. Our\nresults show that (i) incorporating ranking information from reviewers can\nsignificantly improve the evaluation of each paper's quality, often\noutperforming the use of ranking information from authors alone; and (ii)\ncombining ranking information from both reviewers and authors yields the most\naccurate evaluation of submitted papers in most scenarios.", "AI": {"tldr": "\u672c\u6587\u8ba8\u8bba\u4e86Su\u7b49\u4eba(2025)\u7684JASA\u8ba8\u8bba\u7a3f\uff0c\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u4f1a\u8bae\u7a3f\u4ef6\u6570\u91cf\u6fc0\u589e\u5bfc\u81f4\u7684\u5ba1\u7a3f\u8d28\u91cf\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5ba1\u7a3f\u4eba\u6392\u5e8f\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u5e76\u4e0e\u4f5c\u8005\u6392\u5e8f\u4fe1\u606f\u7ed3\u5408\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u7a3f\u4ef6\u8d28\u91cf\u3002", "motivation": "\u8fd1\u5e74\u6765\uff0c\u673a\u5668\u5b66\u4e60\u4f1a\u8bae\u7684\u5ba1\u7a3f\u8d28\u91cf\u56e0\u6295\u7a3f\u6570\u91cf\u5feb\u901f\u589e\u957f\u800c\u5907\u53d7\u5173\u6ce8\u3002", "method": "\u901a\u8fc7\u6a21\u62df2023\u5e74ICML\u4f1a\u8bae\u7684\u6295\u7a3f\u6570\u636e\uff0c\u5229\u7528\u5ba1\u7a3f\u4eba\u800c\u975e\u4f5c\u8005\u7684\u6392\u5e8f\u4fe1\u606f\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u7ed3\u5408\u5ba1\u7a3f\u4eba\u6392\u5e8f\u4fe1\u606f\u80fd\u663e\u8457\u63d0\u9ad8\u5bf9\u8bba\u6587\u8d28\u91cf\u7684\u8bc4\u4f30\uff0c\u901a\u5e38\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4f5c\u8005\u6392\u5e8f\u4fe1\u606f\uff1b\u7ed3\u5408\u5ba1\u7a3f\u4eba\u548c\u4f5c\u8005\u7684\u6392\u5e8f\u4fe1\u606f\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u4ea7\u751f\u6700\u51c6\u786e\u7684\u8bc4\u4f30\u7ed3\u679c\u3002", "conclusion": "\u7ed3\u5408\u5ba1\u7a3f\u4eba\u548c\u4f5c\u8005\u7684\u6392\u5e8f\u4fe1\u606f\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc4\u4f30\u7a3f\u4ef6\u8d28\u91cf\u3002"}}
{"id": "2510.22734", "categories": ["cs.LG", "cs.DB", "stat.ME"], "pdf": "https://arxiv.org/pdf/2510.22734", "abs": "https://arxiv.org/abs/2510.22734", "authors": ["Yuanhao Lai", "Pengfei Zheng", "Chenpeng Ji", "Yan Li", "Songhan Zhang", "Rutao Zhang", "Zhengang Wang", "Yunfei Du"], "title": "Centrum: Model-based Database Auto-tuning with Minimal Distributional Assumptions", "comment": "26 pages", "summary": "Gaussian-Process-based Bayesian optimization (GP-BO), is a prevailing\nmodel-based framework for DBMS auto-tuning. However, recent work shows\nGP-BO-based DBMS auto-tuners significantly outperformed auto-tuners based on\nSMAC, which features random forest surrogate models; such results motivate us\nto rethink and investigate the limitations of GP-BO in auto-tuner design. We\nfind the fundamental assumptions of GP-BO are widely violated when modeling and\noptimizing DBMS performance, while tree-ensemble-BOs (e.g., SMAC) can avoid the\nassumption pitfalls and deliver improved tuning efficiency and effectiveness.\nMoreover, we argue that existing tree-ensemble-BOs restrict further advancement\nin DBMS auto-tuning. First, existing tree-ensemble-BOs can only achieve\ndistribution-free point estimates, but still impose unrealistic distributional\nassumptions on uncertainty estimates, compromising surrogate modeling and\ndistort the acquisition function. Second, recent advances in gradient boosting,\nwhich can further enhance surrogate modeling against vanilla GP and random\nforest counterparts, have rarely been applied in optimizing DBMS auto-tuners.\nTo address these issues, we propose a novel model-based DBMS auto-tuner,\nCentrum. Centrum improves distribution-free point and interval estimation in\nsurrogate modeling with a two-phase learning procedure of stochastic gradient\nboosting ensembles. Moreover, Centrum adopts a generalized SGBE-estimated\nlocally-adaptive conformal prediction to facilitate a distribution-free\nuncertainty estimation and acquisition function. To our knowledge, Centrum is\nthe first auto-tuner to realize distribution-freeness, enhancing BO's\npracticality in DBMS auto-tuning, and the first to seamlessly fuse gradient\nboosting ensembles and conformal inference in BO. Extensive physical and\nsimulation experiments on two DBMSs and three workloads show Centrum\noutperforms 21 SOTA methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18\u5668Centrum\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u5728\u5efa\u6a21\u548c\u4f18\u5316\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u6027\u80fd\u65f6\u5b58\u5728\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u8d1d\u53f6\u65af\u4f18\u5316\u7684\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18\u5668\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5b58\u5728\u5c40\u9650\u6027\uff0c\u800c\u57fa\u4e8e\u6811\u96c6\u6210\u6a21\u578b\u7684\u81ea\u52a8\u8c03\u4f18\u5668\uff08\u5982SMAC\uff09\u80fd\u591f\u907f\u514d\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u73b0\u6709\u6811\u96c6\u6210\u8d1d\u53f6\u65af\u4f18\u5316\u5668\u53ea\u80fd\u5b9e\u73b0\u65e0\u5206\u5e03\u7684\u70b9\u4f30\u8ba1\uff0c\u4e14\u5bf9\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u65bd\u52a0\u4e86\u4e0d\u5207\u5b9e\u9645\u7684\u5206\u5e03\u5047\u8bbe\u3002\u6b64\u5916\uff0c\u68af\u5ea6\u63d0\u5347\u7684\u6700\u65b0\u8fdb\u5c55\u5f88\u5c11\u5e94\u7528\u4e8e\u4f18\u5316\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18\u5668\u3002", "method": "Centrum\u91c7\u7528\u968f\u673a\u68af\u5ea6\u63d0\u5347\u96c6\u6210\uff08SGBE\uff09\u7684\u4e24\u9636\u6bb5\u5b66\u4e60\u7a0b\u5e8f\u6765\u6539\u8fdb\u4ee3\u7406\u6a21\u578b\u4e2d\u7684\u65e0\u5206\u5e03\u70b9\u548c\u533a\u95f4\u4f30\u8ba1\u3002\u6b64\u5916\uff0cCentrum\u91c7\u7528\u5e7f\u4e49\u7684SGBE\u4f30\u8ba1\u7684\u5c40\u90e8\u81ea\u9002\u5e94\u5171\u5f62\u9884\u6d4b\uff0c\u4ee5\u5b9e\u73b0\u65e0\u5206\u5e03\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u91c7\u96c6\u51fd\u6570\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u548c\u4e09\u4e2a\u5de5\u4f5c\u8d1f\u8f7d\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u7269\u7406\u548c\u6a21\u62df\u5b9e\u9a8c\u8868\u660e\uff0cCentrum\u4f18\u4e8e21\u79cd\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u3002", "conclusion": "Centrum\u662f\u7b2c\u4e00\u4e2a\u5b9e\u73b0\u65e0\u5206\u5e03\u7684\u81ea\u52a8\u8c03\u4f18\u5668\uff0c\u589e\u5f3a\u4e86\u8d1d\u53f6\u65af\u4f18\u5316\u5728\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u81ea\u52a8\u8c03\u4f18\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u4e5f\u662f\u7b2c\u4e00\u4e2a\u5728\u8d1d\u53f6\u65af\u4f18\u5316\u4e2d\u65e0\u7f1d\u878d\u5408\u68af\u5ea6\u63d0\u5347\u96c6\u6210\u548c\u5171\u5f62\u63a8\u7406\u7684\u81ea\u52a8\u8c03\u4f18\u5668\u3002"}}
{"id": "2510.21883", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21883", "abs": "https://arxiv.org/abs/2510.21883", "authors": ["Chenheng Zhang", "Tianqi Du", "Jizhe Zhang", "Mingqing Xiao", "Yifei Wang", "Yisen Wang", "Zhouchen Lin"], "title": "Language Ranker: A Lightweight Ranking framework for LLM Decoding", "comment": null, "summary": "Conventional research on large language models (LLMs) has primarily focused\non refining output distributions, while paying less attention to the decoding\nprocess that transforms these distributions into final responses. Recent\nadvances, such as scaling the computation of inference time with reward models,\nhave underscored the importance of decoding, but these methods often suffer\nfrom high computational costs and limited applicability. In this paper, we\nrevisit LLM generation through the lens of recommender systems, conceptualizing\nthe decoding process as analogous to the ranking stage in recommendation\npipelines. From this perspective, we observe that both traditional decoding\nmethods and reward models exhibit clear limitations such as redundancy.\nMotivated by this insight, we propose Language Ranker, a novel framework that\nintroduces a lightweight module to rerank candidate responses using features\nextracted by the base model. Experiments across a wide range of tasks show that\nLanguage Ranker achieves performance comparable to large-scale reward models,\nwhile requiring only <0.5M additional parameters, significantly reducing the\ncomputational overhead during both training and inference stages. This\nhighlights the efficiency and effectiveness of our method, showcasing its\npotential to fully unlock the capabilities of LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Language Ranker \u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u91cd\u65b0\u6392\u5e8f\u5019\u9009\u54cd\u5e94\uff0c\u4ece\u800c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6539\u8fdb\u8f93\u51fa\u5206\u5e03\u4e0a\uff0c\u800c\u8f83\u5c11\u5173\u6ce8\u5c06\u8fd9\u4e9b\u5206\u5e03\u8f6c\u6362\u4e3a\u6700\u7ec8\u54cd\u5e94\u7684\u89e3\u7801\u8fc7\u7a0b\u3002\u5956\u52b1\u6a21\u578b\u7b49\u6700\u65b0\u8fdb\u5c55\u7a81\u663e\u4e86\u89e3\u7801\u7684\u91cd\u8981\u6027\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u901a\u5e38\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u9002\u7528\u6027\u6709\u9650\u3002", "method": "\u5c06\u89e3\u7801\u8fc7\u7a0b\u6982\u5ff5\u5316\u4e3a\u7c7b\u4f3c\u4e8e\u63a8\u8350\u6d41\u6c34\u7ebf\u4e2d\u7684\u6392\u5e8f\u9636\u6bb5\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u6a21\u5757\u6765\u91cd\u65b0\u6392\u5e8f\u5019\u9009\u54cd\u5e94\uff0c\u8be5\u6a21\u5757\u4f7f\u7528\u57fa\u7840\u6a21\u578b\u63d0\u53d6\u7684\u7279\u5f81\u3002", "result": "\u5728\u5e7f\u6cdb\u7684\u4efb\u52a1\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLanguage Ranker \u7684\u6027\u80fd\u4e0e\u5927\u89c4\u6a21\u5956\u52b1\u6a21\u578b\u76f8\u5f53\uff0c\u540c\u65f6\u53ea\u9700\u8981 <0.5M \u7684\u989d\u5916\u53c2\u6570\uff0c\u4ece\u800c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u9636\u6bb5\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "conclusion": "Language Ranker \u65b9\u6cd5\u9ad8\u6548\u4e14\u6709\u6548\uff0c\u5c55\u793a\u4e86\u5176\u5145\u5206\u91ca\u653e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6f5c\u529b\u7684\u6f5c\u529b\u3002"}}
{"id": "2510.21763", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21763", "abs": "https://arxiv.org/abs/2510.21763", "authors": ["Julien Boudier", "Hugo Caselles-Dupr\u00e9"], "title": "Proportion and Perspective Control for Flow-Based Image Generation", "comment": "Technical report after open-source release", "summary": "While modern text-to-image diffusion models generate high-fidelity images,\nthey offer limited control over the spatial and geometric structure of the\noutput. To address this, we introduce and evaluate two ControlNets specialized\nfor artistic control: (1) a proportion ControlNet that uses bounding boxes to\ndictate the position and scale of objects, and (2) a perspective ControlNet\nthat employs vanishing lines to control the 3D geometry of the scene. We\nsupport the training of these modules with data pipelines that leverage\nvision-language models for annotation and specialized algorithms for\nconditioning image synthesis. Our experiments demonstrate that both modules\nprovide effective control but exhibit limitations with complex constraints.\nBoth models are released on HuggingFace:\nhttps://huggingface.co/obvious-research", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd ControlNet\uff0c\u7528\u4e8e\u66f4\u597d\u5730\u63a7\u5236 text-to-image \u6a21\u578b\u751f\u6210\u7684\u56fe\u50cf\u7684\u7a7a\u95f4\u548c\u51e0\u4f55\u7ed3\u6784\u3002", "motivation": "\u73b0\u6709\u7684 text-to-image \u6a21\u578b\u5728\u7a7a\u95f4\u548c\u51e0\u4f55\u7ed3\u6784\u63a7\u5236\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u4e86 proportion ControlNet\uff08\u901a\u8fc7\u8fb9\u754c\u6846\u63a7\u5236\u7269\u4f53\u7684\u4f4d\u7f6e\u548c\u6bd4\u4f8b\uff09\u548c perspective ControlNet\uff08\u901a\u8fc7\u6d88\u5931\u7ebf\u63a7\u5236\u573a\u666f\u7684 3D \u51e0\u4f55\uff09\u3002\u4f7f\u7528\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6807\u6ce8\uff0c\u5e76\u4f7f\u7528\u4e13\u95e8\u7684\u7b97\u6cd5\u6765\u8c03\u8282\u56fe\u50cf\u5408\u6210\uff0c\u4ece\u800c\u652f\u6301\u8fd9\u4e9b\u6a21\u5757\u7684\u8bad\u7ec3\u3002", "result": "\u8bc1\u660e\u4e86\u8fd9\u4e24\u4e2a\u6a21\u5757\u90fd\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u63a7\u5236\uff0c\u4f46\u5728\u590d\u6742\u7684\u7ea6\u675f\u4e0b\u5b58\u5728\u5c40\u9650\u6027\u3002", "conclusion": "\u53d1\u5e03\u4e86 proportion ControlNet \u548c perspective ControlNet \u6a21\u578b\u3002"}}
{"id": "2510.21855", "categories": ["cs.AI", "cs.CL", "cs.LG", "cs.MA", "I.2; I.2.7; I.2.11"], "pdf": "https://arxiv.org/pdf/2510.21855", "abs": "https://arxiv.org/abs/2510.21855", "authors": ["Ryan Zhang", "Herbert Woisetscl\u00e4ger"], "title": "SIGN: Schema-Induced Games for Naming", "comment": "AAAI 2026 Student Abstract (Oral). Code available ar\n  https://github.com/ryanzhangofficial/schema-induced-games-for-naming", "summary": "Real-world AI systems are tackling increasingly complex problems, often\nthrough interactions among large language model (LLM) agents. When these agents\ndevelop inconsistent conventions, coordination can break down. Applications\nsuch as collaborative coding and distributed planning therefore require\nreliable, consistent communication, and scalability is a central concern as\nsystems grow. We introduce Schema-Induced Games for Naming (SIGN), a naming\ngame that examines how lightweight structure can steer convention formation. We\ncompare schema-induced communication to unconstrained natural language and find\nfaster convergence with up to 5.8x higher agreement. These results suggest that\nminimal structure can act as a simple control knob for efficient multi-agent\ncoordination, pointing toward broader applications beyond the naming game.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a Schema-Induced Games for Naming (SIGN) \u7684\u547d\u540d\u6e38\u620f\uff0c\u65e8\u5728\u7814\u7a76\u8f7b\u91cf\u7ea7\u7ed3\u6784\u5982\u4f55\u5f15\u5bfc\u60ef\u4f8b\u5f62\u6210\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u6b63\u5728\u89e3\u51b3\u65e5\u76ca\u590d\u6742\u7684\u95ee\u9898\uff0c\u8fd9\u4e9b\u95ee\u9898\u901a\u5e38\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4ee3\u7406\u4e4b\u95f4\u7684\u4ea4\u4e92\u6765\u5b8c\u6210\u3002\u5f53\u8fd9\u4e9b\u4ee3\u7406\u4ea7\u751f\u4e0d\u4e00\u81f4\u7684\u7ea6\u5b9a\uff0c\u534f\u8c03\u53ef\u80fd\u4f1a\u5d29\u6e83\u3002\u56e0\u6b64\uff0c\u534f\u4f5c\u7f16\u7801\u548c\u5206\u5e03\u5f0f\u89c4\u5212\u7b49\u5e94\u7528\u9700\u8981\u53ef\u9760\u3001\u4e00\u81f4\u7684\u901a\u4fe1\uff0c\u5e76\u4e14\u968f\u7740\u7cfb\u7edf\u589e\u957f\uff0c\u53ef\u6269\u5c55\u6027\u662f\u6838\u5fc3\u95ee\u9898\u3002", "method": "\u5c06\u6a21\u5f0f\u8bf1\u5bfc\u901a\u4fe1\u4e0e\u65e0\u7ea6\u675f\u81ea\u7136\u8bed\u8a00\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u4e0e\u65e0\u7ea6\u675f\u81ea\u7136\u8bed\u8a00\u76f8\u6bd4\uff0c\u6a21\u5f0f\u8bf1\u5bfc\u901a\u4fe1\u7684\u6536\u655b\u901f\u5ea6\u66f4\u5feb\uff0c\u534f\u8bae\u4e00\u81f4\u6027\u63d0\u9ad8\u4e86 5.8 \u500d\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u6700\u5c0f\u7684\u7ed3\u6784\u53ef\u4ee5\u4f5c\u4e3a\u6709\u6548\u591a\u667a\u80fd\u4f53\u534f\u8c03\u7684\u7b80\u5355\u63a7\u5236\u65cb\u94ae\uff0c\u5e76\u6307\u5411\u547d\u540d\u6e38\u620f\u4e4b\u5916\u7684\u66f4\u5e7f\u6cdb\u5e94\u7528\u3002"}}
{"id": "2510.21772", "categories": ["cs.LG", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2510.21772", "abs": "https://arxiv.org/abs/2510.21772", "authors": ["Jinwoo Baek"], "title": "Chebyshev Moment Regularization (CMR): Condition-Number Control with Moment Shaping", "comment": "15 pages", "summary": "We introduce \\textbf{Chebyshev Moment Regularization (CMR)}, a simple,\narchitecture-agnostic loss that directly optimizes layer spectra. CMR jointly\ncontrols spectral edges via a log-condition proxy and shapes the interior via\nChebyshev moments, with a decoupled, capped mixing rule that preserves task\ngradients. We prove strictly monotone descent for the condition proxy, bounded\nmoment gradients, and orthogonal invariance. In an adversarial\n``$\\kappa$-stress'' setting (MNIST, 15-layer MLP), \\emph{compared to vanilla\ntraining}, CMR reduces mean layer condition numbers by $\\sim\\!10^3$ (from\n$\\approx3.9\\!\\times\\!10^3$ to $\\approx3.4$ in 5 epochs), increases average\ngradient magnitude, and restores test accuracy (\n$\\approx10\\%\\!\\to\\!\\approx86\\%$ ). These results support\n\\textbf{optimization-driven spectral preconditioning}: directly steering models\ntoward well-conditioned regimes for stable, accurate learning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u5207\u6bd4\u96ea\u592b\u77e9\u6b63\u5219\u5316\uff08CMR\uff09\uff0c\u4e00\u79cd\u76f4\u63a5\u4f18\u5316\u5c42\u8c31\u7684\u7b80\u5355\u3001\u67b6\u6784\u65e0\u5173\u7684\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u63a7\u5236\u8c31\u8fb9\u7f18\u548c\u5851\u9020\u5185\u90e8\u7ed3\u6784\uff0c\u4f18\u5316\u6a21\u578b\u7684\u5149\u8c31\u5c5e\u6027\uff0c\u4ece\u800c\u5b9e\u73b0\u7a33\u5b9a\u548c\u51c6\u786e\u7684\u5b66\u4e60\u3002", "method": "\u901a\u8fc7\u5bf9\u6570\u6761\u4ef6\u4ee3\u7406\u63a7\u5236\u8c31\u8fb9\u7f18\uff0c\u901a\u8fc7\u5207\u6bd4\u96ea\u592b\u77e9\u5851\u9020\u5185\u90e8\u7ed3\u6784\uff0c\u5e76\u91c7\u7528\u89e3\u8026\u3001\u6709\u4e0a\u9650\u7684\u6df7\u5408\u89c4\u5219\uff0c\u4ee5\u4fdd\u6301\u4efb\u52a1\u68af\u5ea6\u3002", "result": "\u5728\u5bf9\u6297\u6027\u201c\u03ba-stress\u201d\u8bbe\u7f6e\uff08MNIST\uff0c15\u5c42MLP\uff09\u4e2d\uff0c\u4e0e\u666e\u901a\u8bad\u7ec3\u76f8\u6bd4\uff0cCMR\u5c06\u5e73\u5747\u5c42\u6761\u4ef6\u6570\u964d\u4f4e\u4e86\u7ea61000\u500d\uff08\u57285\u4e2aepoch\u5185\u4ece\u7ea63.9\u00d710^3\u964d\u81f3\u7ea63.4\uff09\uff0c\u589e\u52a0\u4e86\u5e73\u5747\u68af\u5ea6\u5e45\u5ea6\uff0c\u5e76\u6062\u590d\u4e86\u6d4b\u8bd5\u7cbe\u5ea6\uff08\u7ea610%\u5230\u7ea686%\uff09\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u652f\u6301\u4f18\u5316\u9a71\u52a8\u7684\u8c31\u9884\u5904\u7406\uff1a\u76f4\u63a5\u5f15\u5bfc\u6a21\u578b\u8d70\u5411\u826f\u597d\u6761\u4ef6\u7684\u72b6\u6001\uff0c\u4ee5\u5b9e\u73b0\u7a33\u5b9a\u3001\u51c6\u786e\u7684\u5b66\u4e60\u3002"}}
{"id": "2510.21727", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21727", "abs": "https://arxiv.org/abs/2510.21727", "authors": ["Yichi Zhang", "Jun Bai", "Zhixin Cai", "Shuhan Qin", "Zhuofan Chen", "Jinghua Guan", "Wenge Rong"], "title": "Your Dense Retriever is Secretly an Expeditious Reasoner", "comment": "16 pages, 11 figures", "summary": "Dense retrievers enhance retrieval by encoding queries and documents into\ncontinuous vectors, but they often struggle with reasoning-intensive queries.\nAlthough Large Language Models (LLMs) can reformulate queries to capture\ncomplex reasoning, applying them universally incurs significant computational\ncost. In this work, we propose Adaptive Query Reasoning (AdaQR), a hybrid query\nrewriting framework. Within this framework, a Reasoner Router dynamically\ndirects each query to either fast dense reasoning or deep LLM reasoning. The\ndense reasoning is achieved by the Dense Reasoner, which performs LLM-style\nreasoning directly in the embedding space, enabling a controllable trade-off\nbetween efficiency and accuracy. Experiments on large-scale retrieval\nbenchmarks BRIGHT show that AdaQR reduces reasoning cost by 28% while\npreserving-or even improving-retrieval performance by 7%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u67e5\u8be2\u91cd\u5199\u6846\u67b6AdaQR\uff0c\u4ee5\u4f18\u5316\u68c0\u7d22\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u7a20\u5bc6\u68c0\u7d22\u5668\u5728\u5904\u7406\u63a8\u7406\u5bc6\u96c6\u578b\u67e5\u8be2\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6210\u672c\u9ad8\u6602\u3002", "method": "AdaQR\u6846\u67b6\u5305\u542b\u4e00\u4e2aReasoner Router\uff0c\u7528\u4e8e\u52a8\u6001\u5730\u5c06\u67e5\u8be2\u5206\u914d\u7ed9\u5feb\u901f\u7a20\u5bc6\u63a8\u7406\u6216\u6df1\u5ea6LLM\u63a8\u7406\u3002\u7a20\u5bc6\u63a8\u7406\u901a\u8fc7Dense Reasoner\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u6267\u884cLLM\u98ce\u683c\u7684\u63a8\u7406\u3002", "result": "\u5728\u5927\u578b\u68c0\u7d22\u57fa\u51c6BRIGHT\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cAdaQR\u5728\u964d\u4f4e28%\u7684\u63a8\u7406\u6210\u672c\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u751a\u81f3\u63d0\u9ad8\u4e867%\u7684\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "AdaQR\u6846\u67b6\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u9009\u62e9\u63a8\u7406\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6548\u7387\u548c\u51c6\u786e\u6027\u4e4b\u95f4\u7684\u53ef\u63a7\u6743\u8861\u3002"}}
{"id": "2510.21884", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21884", "abs": "https://arxiv.org/abs/2510.21884", "authors": ["Avinash Patil"], "title": "Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks", "comment": "12 Pages, 12 Figures, 2 tables", "summary": "The growing adoption of machine learning (ML) in sensitive domains has\nheightened the demand for transparent and interpretable artificial\nintelligence. Large Language Models (LLMs) are increasingly capable of\nproducing natural language explanations, yet it remains unclear whether these\nrationales faithfully capture the predictive signals that underlie decisions.\nThis paper introduces RACE-Reasoning Alignment for Completeness of\nExplanations, a systematic framework to evaluate the alignment between\nLLM-generated explanations and interpretable feature importance scores derived\nfrom a logistic regression baseline. We analyze four widely used text\nclassification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and\ncompare LLM rationales against top-ranked supporting and contradicting lexical\nfeatures. To capture alignment at multiple levels of granularity, RACE\nimplements token-aware, exact string, and edit-distance matching techniques.\nEmpirical results reveal a consistent asymmetry: correct predictions exhibit\nhigher coverage of supporting features, while incorrect predictions are\nassociated with elevated coverage of contradicting features. Edit-distance\nmatching further uncovers paraphrastic overlaps, boosting coverage while\npreserving this asymmetry. These findings demonstrate that LLM rationales\ncombine both surface-level and flexible evidence reuse, yet can also amplify\nmisleading cues in error cases. RACE provides new insights into the\nfaithfulness of LLM explanations and establishes a quantitative basis for\nevaluating reasoning completeness in neural language models.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86RACE\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u751f\u6210\u7684\u89e3\u91ca\u4e0e\u903b\u8f91\u56de\u5f52\u57fa\u7ebf\u6a21\u578b\u7684\u91cd\u8981\u7279\u5f81\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u5728\u654f\u611f\u9886\u57df\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u7684\u5e7f\u6cdb\u5e94\u7528\u589e\u52a0\u4e86\u5bf9\u900f\u660e\u548c\u53ef\u89e3\u91ca\u4eba\u5de5\u667a\u80fd\u7684\u9700\u6c42\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u8d8a\u6765\u8d8a\u80fd\u591f\u751f\u6210\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u4f46\u8fd9\u4e9b\u89e3\u91ca\u662f\u5426\u771f\u5b9e\u5730\u6355\u6349\u4e86\u51b3\u7b56\u7684\u57fa\u7840\u9884\u6d4b\u4fe1\u53f7\u4ecd\u4e0d\u6e05\u695a\u3002", "method": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u540d\u4e3aRACE\u7684\u7cfb\u7edf\u6846\u67b6\uff0c\u5373\u201c\u89e3\u91ca\u5b8c\u6574\u6027\u7684\u63a8\u7406\u5bf9\u9f50\u201d\uff0c\u4ee5\u8bc4\u4f30LLM\u751f\u6210\u7684\u89e3\u91ca\u4e0e\u6765\u81ea\u903b\u8f91\u56de\u5f52\u57fa\u7ebf\u7684\u53ef\u89e3\u91ca\u7279\u5f81\u91cd\u8981\u6027\u5206\u6570\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\u3002RACE\u5b9e\u73b0\u4e86token-aware\u3001\u7cbe\u786e\u5b57\u7b26\u4e32\u548c\u7f16\u8f91\u8ddd\u79bb\u5339\u914d\u6280\u672f\uff0c\u4ee5\u6355\u83b7\u591a\u4e2a\u7c92\u5ea6\u7ea7\u522b\u4e0a\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u4e00\u81f4\u7684\u4e0d\u5bf9\u79f0\u6027\uff1a\u6b63\u786e\u7684\u9884\u6d4b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u652f\u6301\u7279\u5f81\u8986\u76d6\u7387\uff0c\u800c\u9519\u8bef\u7684\u9884\u6d4b\u4e0e\u77db\u76fe\u7279\u5f81\u7684\u8986\u76d6\u7387\u5347\u9ad8\u76f8\u5173\u3002\u7f16\u8f91\u8ddd\u79bb\u5339\u914d\u8fdb\u4e00\u6b65\u53d1\u73b0\u4e86\u91ca\u4e49\u91cd\u53e0\uff0c\u5728\u4fdd\u6301\u8fd9\u79cd\u4e0d\u5bf9\u79f0\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u8986\u76d6\u7387\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u8868\u660e\uff0cLLM\u7684\u7406\u7531\u7ed3\u5408\u4e86\u8868\u9762\u6c34\u5e73\u548c\u7075\u6d3b\u7684\u8bc1\u636e\u91cd\u7528\uff0c\u4f46\u4e5f\u53ef\u80fd\u5728\u9519\u8bef\u60c5\u51b5\u4e0b\u653e\u5927\u8bef\u5bfc\u6027\u7ebf\u7d22\u3002RACE\u4e3aLLM\u89e3\u91ca\u7684\u771f\u5b9e\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\uff0c\u5e76\u4e3a\u8bc4\u4f30\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u4e2d\u63a8\u7406\u7684\u5b8c\u6574\u6027\u5efa\u7acb\u4e86\u5b9a\u91cf\u57fa\u7840\u3002"}}
{"id": "2510.21769", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.21769", "abs": "https://arxiv.org/abs/2510.21769", "authors": ["Harry Zhang", "Luca Carlone"], "title": "H2OFlow: Grounding Human-Object Affordances with 3D Generative Models and Dense Diffused Flows", "comment": null, "summary": "Understanding how humans interact with the surrounding environment, and\nspecifically reasoning about object interactions and affordances, is a critical\nchallenge in computer vision, robotics, and AI. Current approaches often depend\non labor-intensive, hand-labeled datasets capturing real-world or simulated\nhuman-object interaction (HOI) tasks, which are costly and time-consuming to\nproduce. Furthermore, most existing methods for 3D affordance understanding are\nlimited to contact-based analysis, neglecting other essential aspects of\nhuman-object interactions, such as orientation (\\eg, humans might have a\npreferential orientation with respect certain objects, such as a TV) and\nspatial occupancy (\\eg, humans are more likely to occupy certain regions around\nan object, like the front of a microwave rather than its back). To address\nthese limitations, we introduce \\emph{H2OFlow}, a novel framework that\ncomprehensively learns 3D HOI affordances -- encompassing contact, orientation,\nand spatial occupancy -- using only synthetic data generated from 3D generative\nmodels. H2OFlow employs a dense 3D-flow-based representation, learned through a\ndense diffusion process operating on point clouds. This learned flow enables\nthe discovery of rich 3D affordances without the need for human annotations.\nThrough extensive quantitative and qualitative evaluations, we demonstrate that\nH2OFlow generalizes effectively to real-world objects and surpasses prior\nmethods that rely on manual annotations or mesh-based representations in\nmodeling 3D affordance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aH2OFlow\u7684\u65b0\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4ec5\u4f7f\u7528\u6765\u81ea 3D \u751f\u6210\u6a21\u578b\u7684\u6570\u636e\u6765\u5168\u9762\u5b66\u4e60 3D HOI \u884c\u4e3a\u80fd\u529b\uff0c\u5305\u62ec\u63a5\u89e6\u3001\u65b9\u5411\u548c\u7a7a\u95f4\u5360\u7528\u3002", "motivation": "\u76ee\u524d\u7684\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u4eba\u5de5\u6807\u8bb0\u7684\u6570\u636e\u96c6\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u6355\u83b7\u4e86\u771f\u5b9e\u6216\u6a21\u62df\u7684\u4eba\u4e0e\u5bf9\u8c61\u4ea4\u4e92 (HOI) \u4efb\u52a1\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u7684\u751f\u6210\u6210\u672c\u9ad8\u4e14\u8017\u65f6\u3002\u6b64\u5916\uff0c\u5927\u591a\u6570\u73b0\u6709\u7684 3D \u53ef\u4f9b\u6027\u7406\u89e3\u65b9\u6cd5\u4ec5\u9650\u4e8e\u57fa\u4e8e\u63a5\u89e6\u7684\u5206\u6790\uff0c\u800c\u5ffd\u7565\u4e86\u4eba\u4e0e\u5bf9\u8c61\u4ea4\u4e92\u7684\u5176\u4ed6\u91cd\u8981\u65b9\u9762\uff0c\u4f8b\u5982\u65b9\u5411\u548c\u7a7a\u95f4\u5360\u7528\u3002", "method": "H2OFlow \u91c7\u7528\u57fa\u4e8e\u5bc6\u96c6 3D \u6d41\u7684\u8868\u793a\uff0c\u8be5\u8868\u793a\u901a\u8fc7\u5728\u70b9\u4e91\u4e0a\u8fd0\u884c\u7684\u5bc6\u96c6\u6269\u6563\u8fc7\u7a0b\u5b66\u4e60\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9a\u91cf\u548c\u5b9a\u6027\u8bc4\u4f30\uff0c\u8bc1\u660e H2OFlow \u53ef\u4ee5\u6709\u6548\u5730\u63a8\u5e7f\u5230\u771f\u5b9e\u4e16\u754c\u7684\u5bf9\u8c61\uff0c\u5e76\u4e14\u5728\u5bf9 3D \u884c\u4e3a\u80fd\u529b\u8fdb\u884c\u5efa\u6a21\u65f6\uff0c\u8d85\u8d8a\u4e86\u4f9d\u8d56\u4e8e\u624b\u52a8\u6ce8\u91ca\u6216\u57fa\u4e8e\u7f51\u683c\u7684\u8868\u793a\u7684\u5148\u524d\u65b9\u6cd5\u3002", "conclusion": "H2OFlow \u662f\u4e00\u79cd\u5f88\u6709\u524d\u9014\u7684 3D HOI \u884c\u4e3a\u80fd\u529b\u5b66\u4e60\u6846\u67b6\uff0c\u5b83\u4e0d\u9700\u8981\u4eba\u5de5\u6ce8\u91ca\uff0c\u5e76\u4e14\u53ef\u4ee5\u6709\u6548\u5730\u63a8\u5e7f\u5230\u771f\u5b9e\u4e16\u754c\u7684\u5bf9\u8c61\u3002"}}
{"id": "2510.21866", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21866", "abs": "https://arxiv.org/abs/2510.21866", "authors": ["Javier Mar\u00edn"], "title": "Capability Ceilings in Autoregressive Language Models: Empirical Evidence from Knowledge-Intensive Tasks", "comment": "The experiments in this paper were performed in January 2024. Current\n  model architectures are considerably more complex than those presented here", "summary": "We document empirical capability ceilings in decoder-only autoregressive\nlanguage models across knowledge-intensive tasks. Systematic evaluation of OPT\nand Pythia model families (70M-30B parameters, spanning 240 times scaling)\nreveals that knowledge retrieval tasks show negligible accuracy improvement\ndespite smooth loss reduction. On MMLU mathematics benchmarks, accuracy remains\nflat at 19-20% (below 25% random chance) across all scales while cross-entropy\nloss decreases by 31%. In contrast, procedural tasks like arithmetic show\nconventional scaling where both metrics improve together. Attention\nintervention experiments reveal high sensitivity to perturbation: swapping\nattention patterns between models causes catastrophic performance collapse\n(complete accuracy loss) rather than graceful degradation. These measurements\nhave immediate engineering implications: for knowledge-intensive applications\nusing OPT and Pythia architectures, parameter scaling beyond 1-2B offers\nminimal accuracy gains despite continued loss improvement. Our findings\nquantify capability-specific scaling failures in these model families to inform\nresource allocation decisions. Whether these patterns reflect fundamental\nconstraints of decoder-only architectures or implementation-specific\nlimitations remains an open question requiring investigation across diverse\narchitectural approaches.", "AI": {"tldr": "Decoder-only\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u5b58\u5728\u80fd\u529b\u4e0a\u9650\uff0c\u6269\u5c55\u53c2\u6570\u89c4\u6a21\u5e76\u4e0d\u80fd\u663e\u8457\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u7814\u7a76OPT\u548cPythia\u6a21\u578b\u5bb6\u65cf\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\uff0c\u63ed\u793a\u5176\u6269\u5c55\u89c4\u6a21\u7684\u6536\u76ca\u9012\u51cf\u73b0\u8c61\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30OPT\u548cPythia\u6a21\u578b\u5bb6\u65cf\uff0870M-30B\u53c2\u6570\uff09\u5728\u77e5\u8bc6\u68c0\u7d22\u548cMMLU\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u5e72\u9884\u5b9e\u9a8c\u5206\u6790\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u77e5\u8bc6\u68c0\u7d22\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u5347\u4e0d\u660e\u663e\uff0cMMLU\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u51c6\u786e\u7387\u505c\u6ede\u572819-20%\uff0c\u800c\u7b97\u672f\u7b49\u7a0b\u5e8f\u6027\u4efb\u52a1\u5219\u8868\u73b0\u51fa\u5e38\u89c4\u7684\u968f\u89c4\u6a21\u6269\u5c55\u800c\u6027\u80fd\u63d0\u5347\u7684\u73b0\u8c61\u3002\u6ce8\u610f\u529b\u5e72\u9884\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u5bf9\u6270\u52a8\u9ad8\u5ea6\u654f\u611f\u3002", "conclusion": "\u5bf9\u4e8e\u4f7f\u7528OPT\u548cPythia\u67b6\u6784\u7684\u77e5\u8bc6\u5bc6\u96c6\u578b\u5e94\u7528\uff0c\u53c2\u6570\u6269\u5c55\u8d85\u8fc71-2B\u610f\u4e49\u4e0d\u5927\u3002\u8fd9\u4e9b\u53d1\u73b0\u91cf\u5316\u4e86\u8fd9\u4e9b\u6a21\u578b\u5bb6\u65cf\u4e2d\u7279\u5b9a\u4e8e\u80fd\u529b\u7684\u6269\u5c55\u5931\u8d25\uff0c\u4e3a\u8d44\u6e90\u5206\u914d\u51b3\u7b56\u63d0\u4f9b\u4fe1\u606f\u3002\u8fd9\u4e9b\u6a21\u5f0f\u662f\u5426\u53cd\u6620\u4e86\u89e3\u7801\u5668\u4e13\u7528\u67b6\u6784\u7684\u57fa\u672c\u7ea6\u675f\u6216\u7279\u5b9a\u4e8e\u5b9e\u73b0\u7684\u9650\u5236\u4ecd\u7136\u662f\u4e00\u4e2a\u60ac\u800c\u672a\u51b3\u7684\u95ee\u9898\uff0c\u9700\u8981\u5728\u4e0d\u540c\u7684\u67b6\u6784\u65b9\u6cd5\u4e2d\u8fdb\u884c\u8c03\u67e5\u3002"}}
{"id": "2510.21779", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21779", "abs": "https://arxiv.org/abs/2510.21779", "authors": ["Supriya Nagesh", "Karina Covarrubias", "Robert El-Kareh", "Shiva Prasad Kasiviswanathan", "Nina Mishra"], "title": "What Causes Postoperative Aspiration?", "comment": null, "summary": "Background: Aspiration, the inhalation of foreign material into the lungs,\nsignificantly impacts surgical patient morbidity and mortality. This study\ndevelops a machine learning (ML) model to predict postoperative aspiration,\nenabling timely preventative interventions.\n  Methods: From the MIMIC-IV database of over 400,000 hospital admissions, we\nidentified 826 surgical patients (mean age: 62, 55.7\\% male) who experienced\naspiration within seven days post-surgery, along with a matched non-aspiration\ncohort. Three ML models: XGBoost, Multilayer Perceptron, and Random Forest were\ntrained using pre-surgical hospitalization data to predict postoperative\naspiration. To investigate causation, we estimated Average Treatment Effects\n(ATE) using Augmented Inverse Probability Weighting.\n  Results: Our ML model achieved an AUROC of 0.86 and 77.3\\% sensitivity on a\nheld-out test set. Maximum daily opioid dose, length of stay, and patient age\nemerged as the most important predictors. ATE analysis identified significant\ncausative factors: opioids (0.25 +/- 0.06) and operative site (neck: 0.20 +/-\n0.13, head: 0.19 +/- 0.13). Despite equal surgery rates across genders, men\nwere 1.5 times more likely to aspirate and received 27\\% higher maximum daily\nopioid dosages compared to women.\n  Conclusion: ML models can effectively predict postoperative aspiration risk,\nenabling targeted preventative measures. Maximum daily opioid dosage and\noperative site significantly influence aspiration risk. The gender disparity in\nboth opioid administration and aspiration rates warrants further investigation.\nThese findings have important implications for improving postoperative care\nprotocols and aspiration prevention strategies.", "AI": {"tldr": "This study uses machine learning to predict postoperative aspiration using the MIMIC-IV database.", "motivation": "Postoperative aspiration significantly impacts surgical patient outcomes, motivating the development of a predictive model for timely intervention.", "method": "Three ML models (XGBoost, Multilayer Perceptron, and Random Forest) were trained on pre-surgical data from the MIMIC-IV database to predict postoperative aspiration, and ATE was estimated using Augmented Inverse Probability Weighting to investigate causation.", "result": "The ML model achieved an AUROC of 0.86 and 77.3% sensitivity. Opioid dose, length of stay, and age were key predictors. Opioids and operative site were significant causative factors. Men were more likely to aspirate and received higher opioid doses.", "conclusion": "ML models can predict postoperative aspiration risk, enabling targeted prevention. Opioid dosage and operative site significantly influence risk. Gender disparity in opioid administration and aspiration rates requires further investigation."}}
{"id": "2510.21728", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21728", "abs": "https://arxiv.org/abs/2510.21728", "authors": ["Mahsa Goodarzi", "M. Abdullah Canbaz"], "title": "Modeling Bias Evolution in Fashion Recommender Systems: A System Dynamics Approach", "comment": "Published in the proceedings of the 43rd International System\n  Dynamics Conference (ISDC 25):\n  https://proceedings.systemdynamics.org/2025/papers/P1254.pdf", "summary": "Bias in recommender systems not only distorts user experience but also\nperpetuates and amplifies existing societal stereotypes, particularly in\nsectors like fashion e-commerce. This study employs a dynamic modeling approach\nto scrutinize the mechanisms of bias activation and reinforcement within\nFashion Recommender Systems (FRS). By leveraging system dynamics modeling and\nexperimental simulations, we dissect the temporal evolution of bias and its\nmultifaceted impacts on system performance. Our analysis reveals that inductive\nbiases exert a more substantial influence on system outcomes than user biases,\nsuggesting critical areas for intervention. We demonstrate that while current\ndebiasing strategies, including data rebalancing and algorithmic\nregularization, are effective to an extent, they require further enhancement to\ncomprehensively mitigate biases. This research underscores the necessity for\nadvancing these strategies and extending system boundaries to incorporate\nbroader contextual factors such as user demographics and item diversity, aiming\nto foster inclusivity and fairness in FRS. The findings advocate for a\nproactive approach in recommender system design to counteract bias propagation\nand ensure equitable user experiences.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8c03\u67e5\u4e86\u65f6\u5c1a\u63a8\u8350\u7cfb\u7edf(FRS)\u4e2d\u504f\u5dee\u7684\u6fc0\u6d3b\u548c\u52a0\u5f3a\u673a\u5236\u3002", "motivation": "\u63a8\u8350\u7cfb\u7edf\u4e2d\u7684\u504f\u5dee\u4e0d\u4ec5\u4f1a\u626d\u66f2\u7528\u6237\u4f53\u9a8c\uff0c\u8fd8\u4f1a\u5ef6\u7eed\u548c\u653e\u5927\u73b0\u6709\u7684\u793e\u4f1a\u523b\u677f\u5370\u8c61\uff0c\u5c24\u5176\u662f\u5728\u65f6\u5c1a\u7535\u5b50\u5546\u52a1\u7b49\u9886\u57df\u3002", "method": "\u901a\u8fc7\u5229\u7528\u7cfb\u7edf\u52a8\u529b\u5b66\u5efa\u6a21\u548c\u5b9e\u9a8c\u6a21\u62df\uff0c\u5256\u6790\u4e86\u504f\u5dee\u7684\u65f6\u95f4\u6f14\u53d8\u53ca\u5176\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u591a\u65b9\u9762\u5f71\u54cd\u3002", "result": "\u5f52\u7eb3\u504f\u5dee\u5bf9\u7cfb\u7edf\u7ed3\u679c\u7684\u5f71\u54cd\u6bd4\u7528\u6237\u504f\u5dee\u66f4\u5927\uff0c\u8868\u660e\u4e86\u9700\u8981\u5e72\u9884\u7684\u5173\u952e\u9886\u57df\u3002\u76ee\u524d\u7684\u53cd\u504f\u7b56\u7565\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u662f\u6709\u6548\u7684\uff0c\u4f46\u9700\u8981\u8fdb\u4e00\u6b65\u52a0\u5f3a\u4ee5\u5168\u9762\u51cf\u8f7b\u504f\u5dee\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u5f3a\u8c03\u4e86\u63a8\u8fdb\u8fd9\u4e9b\u7b56\u7565\u548c\u6269\u5c55\u7cfb\u7edf\u8fb9\u754c\u4ee5\u7eb3\u5165\u66f4\u5e7f\u6cdb\u7684\u80cc\u666f\u56e0\u7d20\uff08\u5982\u7528\u6237\u4eba\u53e3\u7edf\u8ba1\u548c\u9879\u76ee\u591a\u6837\u6027\uff09\u7684\u5fc5\u8981\u6027\uff0c\u65e8\u5728\u4fc3\u8fdbFRS\u7684\u5305\u5bb9\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2510.21885", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21885", "abs": "https://arxiv.org/abs/2510.21885", "authors": ["Anh Pham", "Mihir Thalanki", "Michael Sun", "Aditya Chaloo", "Ankita Gupta", "Tian Xia", "Aditya Mate", "Ehimwenma Nosakhare", "Soundararajan Srinivasan"], "title": "Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning", "comment": null, "summary": "Large language models often lose previously aligned safety behaviors when\nfine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior\nwork shows that adding random safety examples can mitigate this effect, but it\nremains unclear which examples are most effective. We propose a behavior-aware\nsampling framework that selects safety examples based on two complementary\nfactors: instruction-response behavior (e.g., refusal versus compliance) and\nsemantic diversity across harm categories. Systematic evaluation shows that\nthis approach substantially reduces harmful outputs while maintaining\nhelpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%\nadditional training data. These results highlight how targeted data selection\ncan improve the safety and efficiency of fine-tuning at scale.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u826f\u6027\u6570\u636e\u4e0a\u8fdb\u884c\u5fae\u8c03\u65f6\uff0c\u901a\u5e38\u4f1a\u4e22\u5931\u5148\u524d\u5bf9\u9f50\u7684\u5b89\u5168\u884c\u4e3a\uff08\u4e00\u79cd\u79f0\u4e3a\u707e\u96be\u6027\u9057\u5fd8\u7684\u73b0\u8c61\uff09\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u8868\u660e\uff0c\u6dfb\u52a0\u968f\u673a\u5b89\u5168\u793a\u4f8b\u53ef\u4ee5\u7f13\u89e3\u6b64\u95ee\u9898\uff0c\u4f46\u4ecd\u4e0d\u6e05\u695a\u54ea\u4e9b\u793a\u4f8b\u6700\u6709\u6548\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u884c\u4e3a\u611f\u77e5\u91c7\u6837\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u4e24\u4e2a\u4e92\u8865\u56e0\u7d20\u9009\u62e9\u5b89\u5168\u793a\u4f8b\uff1a\u6307\u4ee4-\u54cd\u5e94\u884c\u4e3a\uff08\u4f8b\u5982\uff0c\u62d2\u7edd\u4e0e\u4f9d\u4ece\uff09\u548c\u8de8\u5371\u5bb3\u7c7b\u522b\u7684\u8bed\u4e49\u591a\u6837\u6027\u3002", "result": "\u7cfb\u7edf\u8bc4\u4f30\u8868\u660e\uff0c\u8fd9\u79cd\u65b9\u6cd5\u5728\u4fdd\u6301\u5e2e\u52a9\u6027\u7684\u540c\u65f6\uff0c\u663e\u7740\u51cf\u5c11\u4e86\u6709\u5bb3\u8f93\u51fa\uff0c\u4ec5\u4f7f\u7528 0.5% \u7684\u989d\u5916\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u5b9e\u73b0\u9ad8\u8fbe 41% \u7684\u6709\u5bb3\u6027\u964d\u4f4e\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u7a81\u51fa\u4e86\u6709\u9488\u5bf9\u6027\u7684\u6570\u636e\u9009\u62e9\u5982\u4f55\u63d0\u9ad8\u5927\u89c4\u6a21\u5fae\u8c03\u7684\u5b89\u5168\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.21774", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21774", "abs": "https://arxiv.org/abs/2510.21774", "authors": ["Yulong Zhang"], "title": "OCR-Quality: A Human-Annotated Dataset for OCR Quality Assessment", "comment": null, "summary": "We present OCR-Quality, a comprehensive human-annotated dataset designed for\nevaluating and developing OCR quality assessment methods. The dataset consists\nof 1,000 PDF pages converted to PNG images at 300 DPI, sampled from diverse\nreal-world scenarios, including academic papers, textbooks, e-books, and\nmultilingual documents. Each document has been processed using state-of-the-art\nVision-Language Models (VLMs) and manually annotated with quality scores using\na 4-level scoring system (1: Excellent, 2: Good, 3: Fair, 4: Poor). The dataset\nincludes detailed source information, annotation guidelines, and representative\ncases across various difficulty levels. OCR-Quality addresses the critical need\nfor reliable OCR quality assessment in real-world applications and provides a\nvaluable benchmark for training and evaluating OCR verification systems. The\ndataset is publicly available at\nhttps://huggingface.co/datasets/Aslan-mingye/OCR-Quality .", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30OCR\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u7684\u7efc\u5408\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6OCR-Quality\u3002", "motivation": "\u5728\u771f\u5b9e\u5e94\u7528\u4e2d\uff0c\u53ef\u9760\u7684OCR\u8d28\u91cf\u8bc4\u4f30\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u76f8\u5173\u8d44\u6e90\u3002", "method": "\u4f7f\u7528\u6700\u5148\u8fdb\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b(VLMs)\u5904\u74061000\u4e2aPDF\u9875\u9762\uff0c\u5e76\u4f7f\u75284\u7ea7\u8bc4\u5206\u7cfb\u7edf\u8fdb\u884c\u4eba\u5de5\u6807\u6ce8\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8be6\u7ec6\u6765\u6e90\u4fe1\u606f\u3001\u6ce8\u91ca\u6307\u5357\u548c\u5404\u79cd\u96be\u5ea6\u7ea7\u522b\u4ee3\u8868\u6027\u6848\u4f8b\u7684\u6570\u636e\u96c6\u3002", "conclusion": "OCR-Quality\u6ee1\u8db3\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u5bf9\u53ef\u9760OCR\u8d28\u91cf\u8bc4\u4f30\u7684\u5173\u952e\u9700\u6c42\uff0c\u5e76\u4e3a\u8bad\u7ec3\u548c\u8bc4\u4f30OCR\u9a8c\u8bc1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u3002"}}
{"id": "2510.21881", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21881", "abs": "https://arxiv.org/abs/2510.21881", "authors": ["Nannan Shi", "Chuanyu Qin", "Shipeng Song", "Man Luo"], "title": "GeoThought: A Dataset for Enhancing Mathematical Geometry Reasoning in Vision-Language Models", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong reasoning capabilities\nin text-based mathematical problem solving; however, when adapted to visual\nreasoning tasks, particularly geometric problem solving, their performance\nsubstantially declines because geometric problems present unique challenges.\nSpecifically, these challenges stem from two key factors: first, the intrinsic\ncomplexity of geometry requiring detailed image comprehension and multi-step\nreasoning, and second, the limitations of existing datasets which lack\nsufficient scale, diversity, and explicit reasoning traces, consequently\nhindering effective model training. To address these challenges, we developed\nthe GeoThoughts dataset, a comprehensive geometric reasoning corpus with two\nsubsets: Geo-Thought-6K with 6,243 samples and its augmented version\nGeo-Thought-Augmented-10K containing 10,834 samples. Each entry includes visual\ndescriptions, step-by-step solutions, explicit reasoning chains, reflection\nsteps, and final answers. Using this dataset, we developed GeoThought-MLLM, a\nmathematical reasoning multimodal model that generates detailed thinking\nprocesses during problem-solving. Our model outperforms existing benchmarks in\ngeometric tasks, demonstrating that training with our Chain-of-Thought dataset\nimproves geometric reasoning capabilities across both in-domain and\nout-of-domain settings. Finally, we analyze failure cases and observe that\nerrors primarily arise from incorrect interpretation of mathematical concepts\nor spatial misjudgment. By invoking CoT to correct these mistakes, the model\nproduces correct answers.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u6587\u672c\u7684\u6570\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u5f53\u5e94\u7528\u4e8e\u89c6\u89c9\u63a8\u7406\u4efb\u52a1\uff0c\u7279\u522b\u662f\u51e0\u4f55\u95ee\u9898\u89e3\u51b3\u65f6\uff0c\u5b83\u4eec\u7684\u6027\u80fd\u4f1a\u5927\u5e45\u4e0b\u964d\uff0c\u56e0\u4e3a\u51e0\u4f55\u95ee\u9898\u63d0\u51fa\u4e86\u72ec\u7279\u7684\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u8db3\u591f\u7684\u89c4\u6a21\u3001\u591a\u6837\u6027\u548c\u663e\u5f0f\u63a8\u7406\u8f68\u8ff9\uff0c\u4ece\u800c\u963b\u788d\u4e86\u6709\u6548\u7684\u6a21\u578b\u8bad\u7ec3\u3002\u51e0\u4f55\u7684\u5185\u5728\u590d\u6742\u6027\u9700\u8981\u8be6\u7ec6\u7684\u56fe\u50cf\u7406\u89e3\u548c\u591a\u6b65\u9aa4\u63a8\u7406\u3002", "method": "\u6211\u4eec\u5f00\u53d1\u4e86 GeoThoughts \u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u7efc\u5408\u7684\u51e0\u4f55\u63a8\u7406\u8bed\u6599\u5e93\uff0c\u5305\u542b\u4e24\u4e2a\u5b50\u96c6\uff1aGeo-Thought-6K\uff08\u5305\u542b 6,243 \u4e2a\u6837\u672c\uff09\u53ca\u5176\u589e\u5f3a\u7248\u672c Geo-Thought-Augmented-10K\uff08\u5305\u542b 10,834 \u4e2a\u6837\u672c\uff09\u3002", "result": "\u6211\u4eec\u7684\u6a21\u578b\u5728\u51e0\u4f55\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u8868\u660e\u4f7f\u7528\u6211\u4eec\u7684 Chain-of-Thought \u6570\u636e\u96c6\u8fdb\u884c\u8bad\u7ec3\u53ef\u4ee5\u63d0\u9ad8\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u73af\u5883\u4e2d\u7684\u51e0\u4f55\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u8c03\u7528 CoT \u6765\u7ea0\u6b63\u8fd9\u4e9b\u9519\u8bef\uff0c\u6a21\u578b\u53ef\u4ee5\u4ea7\u751f\u6b63\u786e\u7684\u7b54\u6848\u3002\u9519\u8bef\u4e3b\u8981\u6765\u81ea\u5bf9\u6570\u5b66\u6982\u5ff5\u7684\u4e0d\u6b63\u786e\u89e3\u91ca\u6216\u7a7a\u95f4\u8bef\u5224\u3002"}}
{"id": "2510.21788", "categories": ["cs.LG", "cs.AI", "I.2; G.3"], "pdf": "https://arxiv.org/pdf/2510.21788", "abs": "https://arxiv.org/abs/2510.21788", "authors": ["Larkin Liu", "Jalal Etesami"], "title": "Online Mixture of Experts: No-Regret Learning for Optimal Collective Decision-Making", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025)", "summary": "We explore the use of expert-guided bandit learning, which we refer to as\nonline mixture-of-experts (OMoE). In this setting, given a context, a candidate\ncommittee of experts must determine how to aggregate their outputs to achieve\noptimal results in terms of aggregate accuracy. We propose two algorithms to\naddress this problem. The first algorithm combines aggregate voting with\nUCB-driven successive elimination, efficiently pruning suboptimal exploration\nactions. The second algorithm employs an online weighted-majority-voting\nmechanism, leveraging the respective voting power of each expert proportional\nto their predictive power. We derive theoretical guarantees for the regret\nproperties in the bandit setting under ideal circumstances, and empirical\nresults are provided accordingly. As a modern study on applications, these\nmethods are applied to the online fine-tuning of a set of expert large language\nmodels (LLMs), where after each response, the generative LLM dynamically\nreweighs its set of experts and/or selects the optimal committee of experts to\ngenerate the most accurate response. Our results introduce new methodologies\nand no-regret guarantees for combining multiple experts to improve on the\nperformance of the an aggregate model overall.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u4e13\u5bb6\u6df7\u5408\uff08OMoE\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u52a8\u6001\u805a\u5408\u591a\u4e2a\u4e13\u5bb6\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u7684\u8f93\u51fa\uff0c\u4ee5\u63d0\u9ad8\u6574\u4f53\u51c6\u786e\u6027\u3002", "motivation": "\u5728\u4e0a\u4e0b\u6587\u4e2d\uff0c\u5982\u4f55\u805a\u5408\u4e13\u5bb6\u59d4\u5458\u4f1a\u7684\u8f93\u51fa\u4ee5\u83b7\u5f97\u6700\u4f73\u7ed3\u679c\u662f\u4e00\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a\u4e00\u79cd\u7ed3\u5408\u4e86\u805a\u5408\u6295\u7968\u548cUCB\u9a71\u52a8\u7684\u8fde\u7eed\u6d88\u9664\uff0c\u53e6\u4e00\u79cd\u91c7\u7528\u4e86\u5728\u7ebf\u52a0\u6743\u591a\u6570\u6295\u7968\u673a\u5236\u3002", "result": "\u4e3a\u7406\u60f3\u60c5\u51b5\u4e0bbandit setting\u4e2d\u7684\u9057\u61be\u7279\u6027\u63a8\u5bfc\u4e86\u7406\u8bba\u4fdd\u8bc1\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5e94\u7684\u7ecf\u9a8c\u7ed3\u679c\u3002\u5e94\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5728\u7ebf\u5fae\u8c03\uff0c\u52a8\u6001\u8c03\u6574\u4e13\u5bb6\u6743\u91cd\u6216\u9009\u62e9\u6700\u4f73\u4e13\u5bb6\u59d4\u5458\u4f1a\u3002", "conclusion": "\u5f15\u5165\u4e86\u65b0\u7684\u65b9\u6cd5\u548c\u65e0\u6094\u4fdd\u8bc1\uff0c\u7528\u4e8e\u7ec4\u5408\u591a\u4e2a\u4e13\u5bb6\u4ee5\u63d0\u9ad8\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2510.21729", "categories": ["cs.IR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21729", "abs": "https://arxiv.org/abs/2510.21729", "authors": ["Nathan Paull"], "title": "CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora", "comment": null, "summary": "Dense embedding models have become critical for modern information retrieval,\nparticularly in RAG pipelines, but their performance often degrades when\napplied to specialized corpora outside their pre-training distribution. To\naddress thi we introduce \\textbf{CustomIR}, a framework for unsupervised\nadaptation of pre-trained language embedding models to domain-specific corpora\nusing synthetically generated query-document pairs. CustomIR leverages large\nlanguage models (LLMs) to create diverse queries grounded in a known target\ncorpus, paired with LLM-verified hard negatives, eliminating the need for\ncostly human annotation. Experiments on enterprise email and messaging datasets\nshow that CustomIR consistently improves retrieval effectiveness with small\nmodels gaining up to 2.3 points in Recall@10. This performance increase allows\nthese small models to rival the performance of much larger alternatives,\nallowing for cheaper RAG deployments. These results highlight that targeted\nsynthetic fine-tuning offers a scalable and cost-efficient strategy for\nincreasing domain-specific performance.", "AI": {"tldr": "CustomIR\uff1a\u4e00\u4e2a\u5229\u7528\u5408\u6210\u6570\u636e\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u4ee5\u63d0\u5347\u9886\u57df\u68c0\u7d22\u6548\u679c\u7684\u6846\u67b6\u3002", "motivation": "\u9884\u8bad\u7ec3\u7684\u5bc6\u96c6\u5d4c\u5165\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u8bed\u6599\u5e93\u4e0a\u7684\u8868\u73b0\u4e0b\u964d\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u67e5\u8be2-\u6587\u6863\u5bf9\uff0c\u5e76\u9a8c\u8bc1\u96be\u8d1f\u6837\u672c\uff0c\u4ece\u800c\u8fdb\u884c\u65e0\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u5728\u4f01\u4e1a\u90ae\u4ef6\u548c\u6d88\u606f\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCustomIR \u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u7d22\u6548\u679c\uff0c\u5c0f\u6a21\u578bRecall@10\u63d0\u5347\u9ad8\u8fbe2.3\u3002", "conclusion": "\u6709\u9488\u5bf9\u6027\u7684\u5408\u6210\u5fae\u8c03\u662f\u63d0\u9ad8\u9886\u57df\u7279\u5b9a\u6027\u80fd\u7684\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u7b56\u7565\u3002"}}
{"id": "2510.21891", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.21891", "abs": "https://arxiv.org/abs/2510.21891", "authors": ["Dhrupad Bhardwaj", "Julia Kempe", "Tim G. J. Rudner"], "title": "Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form Text Generation", "comment": null, "summary": "To deploy large language models (LLMs) in high-stakes application domains\nthat require substantively accurate responses to open-ended prompts, we need\nreliable, computationally inexpensive methods that assess the trustworthiness\nof long-form responses generated by LLMs. However, existing approaches often\nrely on claim-by-claim fact-checking, which is computationally expensive and\nbrittle in long-form responses to open-ended prompts. In this work, we\nintroduce semantic isotropy -- the degree of uniformity across normalized text\nembeddings on the unit sphere -- and use it to assess the trustworthiness of\nlong-form responses generated by LLMs. To do so, we generate several long-form\nresponses, embed them, and estimate the level of semantic isotropy of these\nresponses as the angular dispersion of the embeddings on the unit sphere. We\nfind that higher semantic isotropy -- that is, greater embedding dispersion --\nreliably signals lower factual consistency across samples. Our approach\nrequires no labeled data, no fine-tuning, and no hyperparameter selection, and\ncan be used with open- or closed-weight embedding models. Across multiple\ndomains, our method consistently outperforms existing approaches in predicting\nnonfactuality in long-form responses using only a handful of samples --\noffering a practical, low-cost approach for integrating trust assessment into\nreal-world LLM workflows.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u957f\u7bc7\u56de\u590d\u7684\u53ef\u4fe1\u5ea6\uff0c\u8be5\u65b9\u6cd5\u57fa\u4e8e\u8bed\u4e49\u5404\u5411\u540c\u6027\uff0c\u901a\u8fc7\u6d4b\u91cf\u6587\u672c\u5d4c\u5165\u5728\u5355\u4f4d\u7403\u4e0a\u7684\u5747\u5300\u7a0b\u5ea6\u6765\u5b9e\u73b0\u3002", "motivation": "\u5728\u9700\u8981\u9ad8\u5ea6\u51c6\u786e\u56de\u590d\u7684\u9ad8\u98ce\u9669\u9886\u57df\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u751f\u6210\u56de\u590d\u7684\u53ef\u4fe1\u5ea6\u3002\u73b0\u6709\u7684\u9010\u6761\u58f0\u660e\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u4e14\u8106\u5f31\u3002", "method": "\u901a\u8fc7\u751f\u6210\u591a\u4e2a\u957f\u7bc7\u56de\u590d\uff0c\u5d4c\u5165\u5b83\u4eec\uff0c\u5e76\u4f30\u8ba1\u8fd9\u4e9b\u56de\u590d\u7684\u8bed\u4e49\u5404\u5411\u540c\u6027\u6c34\u5e73\uff08\u5373\u5d4c\u5165\u5728\u5355\u4f4d\u7403\u4e0a\u7684\u89d2\u5ea6\u79bb\u6563\u5ea6\uff09\u6765\u8bc4\u4f30\u53ef\u4fe1\u5ea6\u3002", "result": "\u53d1\u73b0\u8f83\u9ad8\u7684\u8bed\u4e49\u5404\u5411\u540c\u6027\uff08\u5373\u66f4\u5927\u7684\u5d4c\u5165\u79bb\u6563\u5ea6\uff09\u53ef\u9760\u5730\u8868\u660e\u6837\u672c\u95f4\u8f83\u4f4e\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u6807\u6ce8\u6570\u636e\u3001\u5fae\u8c03\u548c\u8d85\u53c2\u6570\u9009\u62e9\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u5f00\u653e\u6216\u5c01\u95ed\u6743\u91cd\u5d4c\u5165\u6a21\u578b\u4e00\u8d77\u4f7f\u7528\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u957f\u7bc7\u56de\u590d\u4e2d\u7684\u975e\u4e8b\u5b9e\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u53ea\u9700\u5c11\u91cf\u6837\u672c\uff0c\u4e3a\u5c06\u4fe1\u4efb\u8bc4\u4f30\u96c6\u6210\u5230\u5b9e\u9645LLM\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u4f4e\u6210\u672c\u7684\u65b9\u6cd5\u3002"}}
{"id": "2510.21775", "categories": ["cs.CV", "cs.AI", "eess.IV"], "pdf": "https://arxiv.org/pdf/2510.21775", "abs": "https://arxiv.org/abs/2510.21775", "authors": ["Dawei Dai", "Yinxiu Zhou", "Chenghang Li", "Guolai Jiang", "Chengfang Zhang"], "title": "Face-MakeUpV2: Facial Consistency Learning for Controllable Text-to-Image Generation", "comment": null, "summary": "In facial image generation, current text-to-image models often suffer from\nfacial attribute leakage and insufficient physical consistency when responding\nto local semantic instructions. In this study, we propose Face-MakeUpV2, a\nfacial image generation model that aims to maintain the consistency of face ID\nand physical characteristics with the reference image. First, we constructed a\nlarge-scale dataset FaceCaptionMask-1M comprising approximately one million\nimage-text-masks pairs that provide precise spatial supervision for the local\nsemantic instructions. Second, we employed a general text-to-image pretrained\nmodel as the backbone and introduced two complementary facial information\ninjection channels: a 3D facial rendering channel to incorporate the physical\ncharacteristics of the image and a global facial feature channel. Third, we\nformulated two optimization objectives for the supervised learning of our\nmodel: semantic alignment in the model's embedding space to mitigate the\nattribute leakage problem and perceptual loss on facial images to preserve ID\nconsistency. Extensive experiments demonstrated that our Face-MakeUpV2 achieves\nbest overall performance in terms of preserving face ID and maintaining\nphysical consistency of the reference images. These results highlight the\npractical potential of Face-MakeUpV2 for reliable and controllable facial\nediting in diverse applications.", "AI": {"tldr": "Face-MakeUpV2\u662f\u4e00\u4e2a\u9762\u90e8\u56fe\u50cf\u751f\u6210\u6a21\u578b\uff0c\u65e8\u5728\u4fdd\u6301\u9762\u90e8ID\u548c\u4e0e\u53c2\u8003\u56fe\u50cf\u7684\u7269\u7406\u7279\u5f81\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u5230\u56fe\u50cf\u6a21\u578b\u5728\u9762\u90e8\u56fe\u50cf\u751f\u6210\u4e2d\uff0c\u5f53\u54cd\u5e94\u5c40\u90e8\u8bed\u4e49\u6307\u4ee4\u65f6\uff0c\u7ecf\u5e38\u906d\u53d7\u9762\u90e8\u5c5e\u6027\u6cc4\u6f0f\u548c\u7269\u7406\u4e00\u81f4\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "1. \u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6FaceCaptionMask-1M\uff0c\u5305\u542b\u7ea6\u4e00\u767e\u4e07\u4e2a\u56fe\u50cf-\u6587\u672c-\u63a9\u7801\u5bf9\uff0c\u4e3a\u5c40\u90e8\u8bed\u4e49\u6307\u4ee4\u63d0\u4f9b\u7cbe\u786e\u7684\u7a7a\u95f4\u76d1\u7763\u3002\n2. \u91c7\u7528\u901a\u7528\u6587\u672c\u5230\u56fe\u50cf\u9884\u8bad\u7ec3\u6a21\u578b\u4f5c\u4e3a\u4e3b\u5e72\uff0c\u5e76\u5f15\u5165\u4e24\u4e2a\u4e92\u8865\u7684\u9762\u90e8\u4fe1\u606f\u6ce8\u5165\u901a\u9053\uff1a\u4e00\u4e2a3D\u9762\u90e8\u6e32\u67d3\u901a\u9053\uff0c\u7528\u4e8e\u7ed3\u5408\u56fe\u50cf\u7684\u7269\u7406\u7279\u5f81\uff0c\u4ee5\u53ca\u4e00\u4e2a\u5168\u5c40\u9762\u90e8\u7279\u5f81\u901a\u9053\u3002\n3. \u5236\u5b9a\u4e86\u4e24\u4e2a\u4f18\u5316\u76ee\u6807\uff0c\u7528\u4e8e\u6a21\u578b\u7684\u76d1\u7763\u5b66\u4e60\uff1a\u6a21\u578b\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u5bf9\u9f50\uff0c\u4ee5\u51cf\u8f7b\u5c5e\u6027\u6cc4\u6f0f\u95ee\u9898\uff1b\u4ee5\u53ca\u9762\u90e8\u56fe\u50cf\u4e0a\u7684\u611f\u77e5\u635f\u5931\uff0c\u4ee5\u4fdd\u6301ID\u4e00\u81f4\u6027\u3002", "result": "Face-MakeUpV2\u5728\u4fdd\u6301\u9762\u90e8ID\u548c\u7ef4\u6301\u53c2\u8003\u56fe\u50cf\u7684\u7269\u7406\u4e00\u81f4\u6027\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u4f73\u7684\u6574\u4f53\u6027\u80fd\u3002", "conclusion": "Face-MakeUpV2\u5728\u5404\u79cd\u5e94\u7528\u4e2d\u5177\u6709\u53ef\u9760\u548c\u53ef\u63a7\u7684\u9762\u90e8\u7f16\u8f91\u7684\u5b9e\u9645\u6f5c\u529b\u3002"}}
{"id": "2510.21886", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21886", "abs": "https://arxiv.org/abs/2510.21886", "authors": ["Mark Phillip Matovic"], "title": "Exploration through Generation: Applying GFlowNets to Structured Search", "comment": "12 pages", "summary": "This work applies Generative Flow Networks (GFlowNets) to three graph\noptimization problems: the Traveling Salesperson Problem, Minimum Spanning\nTree, and Shortest Path. GFlowNets are generative models that learn to sample\nsolutions proportionally to a reward function. The models are trained using the\nTrajectory Balance loss to build solutions sequentially, selecting edges for\nspanning trees, nodes for paths, and cities for tours. Experiments on benchmark\ninstances of varying sizes show that GFlowNets learn to find optimal solutions.\nFor each problem type, multiple graph configurations with different numbers of\nnodes were tested. The generated solutions match those from classical\nalgorithms (Dijkstra for shortest path, Kruskal for spanning trees, and exact\nsolvers for TSP). Training convergence depends on problem complexity, with the\nnumber of episodes required for loss stabilization increasing as graph size\ngrows. Once training converges, the generated solutions match known optima from\nclassical algorithms across the tested instances. This work demonstrates that\ngenerative models can solve combinatorial optimization problems through learned\npolicies. The main advantage of this learning-based approach is computational\nscalability: while classical algorithms have fixed complexity per instance,\nGFlowNets amortize computation through training. With sufficient computational\nresources, the framework could potentially scale to larger problem instances\nwhere classical exact methods become infeasible.", "AI": {"tldr": "\u672c\u7814\u7a76\u5e94\u7528\u751f\u6210\u6d41\u7f51\u7edc\uff08GFlowNets\uff09\u89e3\u51b3\u56fe\u4f18\u5316\u95ee\u9898\uff0c\u5305\u62ec\u65c5\u884c\u5546\u95ee\u9898\u3001\u6700\u5c0f\u751f\u6210\u6811\u548c\u6700\u77ed\u8def\u5f84\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u6a21\u578b\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u7684\u80fd\u529b\uff0c\u5e76\u514b\u670d\u4f20\u7edf\u7b97\u6cd5\u5728\u8ba1\u7b97\u4e0a\u7684\u5c40\u9650\u6027\u3002", "method": "\u4f7f\u7528\u8f68\u8ff9\u5e73\u8861\u635f\u5931\u8bad\u7ec3 GFlowNets\uff0c\u4f7f\u5176\u80fd\u591f\u6309\u5956\u52b1\u51fd\u6570\u6bd4\u4f8b\u91c7\u6837\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u4f9d\u6b21\u6784\u5efa\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGFlowNets \u80fd\u591f\u5b66\u4e60\u627e\u5230\u6700\u4f18\u89e3\uff0c\u5e76\u5728\u4e0d\u540c\u5927\u5c0f\u7684\u57fa\u51c6\u5b9e\u4f8b\u4e0a\u751f\u6210\u4e0e\u7ecf\u5178\u7b97\u6cd5\u5339\u914d\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u751f\u6210\u6a21\u578b\u53ef\u4ee5\u901a\u8fc7\u5b66\u4e60\u7b56\u7565\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e14 GFlowNets \u5177\u6709\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\uff0c\u6709\u671b\u6269\u5c55\u5230\u4f20\u7edf\u7cbe\u786e\u65b9\u6cd5\u4e0d\u53ef\u884c\u7684\u5927\u89c4\u6a21\u95ee\u9898\u5b9e\u4f8b\u3002"}}
{"id": "2510.21792", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21792", "abs": "https://arxiv.org/abs/2510.21792", "authors": ["Shifeng Xu", "Yanzhu Liu", "Adams Wai-Kin Kong"], "title": "Variance-Reduction Guidance: Sampling Trajectory Optimization for Diffusion Models", "comment": null, "summary": "Diffusion models have become emerging generative models. Their sampling\nprocess involves multiple steps, and in each step the models predict the noise\nfrom a noisy sample. When the models make prediction, the output deviates from\nthe ground truth, and we call such a deviation as \\textit{prediction error}.\nThe prediction error accumulates over the sampling process and deteriorates\ngeneration quality. This paper introduces a novel technique for statistically\nmeasuring the prediction error and proposes the Variance-Reduction Guidance\n(VRG) method to mitigate this error. VRG does not require model fine-tuning or\nmodification. Given a predefined sampling trajectory, it searches for a new\ntrajectory which has the same number of sampling steps but produces higher\nquality results. VRG is applicable to both conditional and unconditional\ngeneration. Experiments on various datasets and baselines demonstrate that VRG\ncan significantly improve the generation quality of diffusion models. Source\ncode is available at https://github.com/shifengxu/VRG.", "AI": {"tldr": "\u6269\u6563\u6a21\u578b\u662f\u4e00\u79cd\u65b0\u5174\u7684\u751f\u6210\u6a21\u578b\uff0c\u4f46\u5176\u9884\u6d4b\u8bef\u5dee\u4f1a\u7d2f\u79ef\u5e76\u964d\u4f4e\u751f\u6210\u8d28\u91cf\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7edf\u8ba1\u6d4b\u91cf\u9884\u6d4b\u8bef\u5dee\u7684\u65b0\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u4e86\u65b9\u5dee\u51cf\u5c11\u5f15\u5bfc\uff08VRG\uff09\u65b9\u6cd5\u6765\u7f13\u89e3\u6b64\u8bef\u5dee\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\u4f1a\u7d2f\u79ef\u5e76\u964d\u4f4e\u751f\u6210\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u65b9\u5dee\u51cf\u5c11\u5f15\u5bfc\uff08VRG\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u641c\u7d22\u65b0\u7684\u91c7\u6837\u8f68\u8ff9\u6765\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\uff0c\u800c\u65e0\u9700\u6a21\u578b\u5fae\u8c03\u6216\u4fee\u6539\u3002", "result": "\u5728\u5404\u79cd\u6570\u636e\u96c6\u548c\u57fa\u7ebf\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cVRG \u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\u3002", "conclusion": "VRG \u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6269\u6563\u6a21\u578b\u7684\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2510.21730", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21730", "abs": "https://arxiv.org/abs/2510.21730", "authors": ["Hao Wang"], "title": "TriMat: Context-aware Recommendation by Tri-Matrix Factorization", "comment": null, "summary": "Search engine is the symbolic technology of Web 2.0, and many people used to\nbelieve recommender systems is the new frontier of Web 3.0. In the past 10\nyears, with the advent of TikTok and similar apps, recommender systems has\nmaterialized the vision of the machine learning pioneers. However, many\nresearch topics of the field remain unfixed until today. One such topic is CARS\n(Context-aware Recommender Systems) , which is largely a theoretical topic\nwithout much advance in real-world applications. In this paper, we utilize\ntri-matrix factorization technique to incorporate contextual information into\nour matrix factorization framework, and prove that our technique is effective\nin improving both the accuracy and fairness metrics in our experiments.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e09\u77e9\u9635\u5206\u89e3\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u8350\u7cfb\u7edf(CARS)\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63a8\u8350\u7cfb\u7edf\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8fdb\u5c55\u4e0d\u5927\u3002", "method": "\u5229\u7528\u4e09\u77e9\u9635\u5206\u89e3\u6280\u672f\u5c06\u4e0a\u4e0b\u6587\u4fe1\u606f\u878d\u5165\u77e9\u9635\u5206\u89e3\u6846\u67b6\u3002", "result": "\u8be5\u6280\u672f\u80fd\u6709\u6548\u63d0\u9ad8\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u6709\u6548\u6027\u3002"}}
{"id": "2510.21894", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21894", "abs": "https://arxiv.org/abs/2510.21894", "authors": ["Mingzhe Xing", "Chang Tian", "Jianan Zhang", "Lichen Pan", "Peipei Liu", "Zhaoteng Yan", "Yinliang Yue"], "title": "Understanding Network Behaviors through Natural Language Question-Answering", "comment": "Large Language Models", "summary": "Modern large-scale networks introduce significant complexity in understanding\nnetwork behaviors, increasing the risk of misconfiguration. Prior work proposed\nto understand network behaviors by mining network configurations, typically\nrelying on domain-specific languages interfaced with formal models. While\neffective, they suffer from a steep learning curve and limited flexibility. In\ncontrast, natural language (NL) offers a more accessible and interpretable\ninterface, motivating recent research on NL-guided network behavior\nunderstanding. Recent advances in large language models (LLMs) further enhance\nthis direction, leveraging their extensive prior knowledge of network concepts\nand strong reasoning capabilities. However, three key challenges remain: 1)\nnumerous router devices with lengthy configuration files challenge LLM's\nlong-context understanding ability; 2) heterogeneity across devices and\nprotocols impedes scalability; and 3) complex network topologies and protocols\ndemand advanced reasoning abilities beyond the current capabilities of LLMs. To\ntackle the above challenges, we propose NetMind, a novel framework for querying\nnetworks using NL. Our approach introduces a tree-based configuration chunking\nstrategy to preserve semantic coherence while enabling efficient partitioning.\nWe then construct a unified fact graph as an intermediate representation to\nnormalize vendor-specific configurations. Finally, we design a hybrid\nimperative-declarative language to reduce the reasoning burden on LLMs and\nenhance precision. We contribute a benchmark consisting of NL question-answer\npairs paired with network configurations. Experiments demonstrate that NetMind\nachieves accurate and scalable network behavior understanding, outperforming\nexisting baselines.", "AI": {"tldr": "NetMind\u662f\u4e00\u4e2a\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u7f51\u7edc\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5757\u3001\u7edf\u4e00\u8868\u793a\u548c\u6df7\u5408\u8bed\u8a00\u6765\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u3001\u5f02\u6784\u6027\u548c\u590d\u6742\u63a8\u7406\u7684\u6311\u6218\u3002", "motivation": "\u7406\u89e3\u7f51\u7edc\u884c\u4e3a\u7684\u590d\u6742\u6027\u589e\u52a0\uff0c\u73b0\u6709\u65b9\u6cd5\u5b66\u4e60\u66f2\u7ebf\u9661\u5ced\u4e14\u7075\u6d3b\u6027\u6709\u9650\u3002\u81ea\u7136\u8bed\u8a00\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u6613\u8bbf\u95ee\u548c\u89e3\u91ca\u7684\u754c\u9762\uff0c\u4f46\u9762\u4e34\u957f\u4e0a\u4e0b\u6587\u3001\u5f02\u6784\u6027\u548c\u590d\u6742\u63a8\u7406\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faNetMind\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u6811\u7684\u914d\u7f6e\u5206\u5757\u7b56\u7565\u3001\u6784\u5efa\u7edf\u4e00\u7684\u4e8b\u5b9e\u56fe\u4ee5\u53ca\u8bbe\u8ba1\u6df7\u5408\u547d\u4ee4\u5f0f-\u58f0\u660e\u5f0f\u8bed\u8a00\u3002", "result": "NetMind\u5728\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "NetMind\u5b9e\u73b0\u4e86\u51c6\u786e\u4e14\u53ef\u6269\u5c55\u7684\u7f51\u7edc\u884c\u4e3a\u7406\u89e3\u3002"}}
{"id": "2510.21778", "categories": ["cs.CV", "68T45, 68T10, 62H35"], "pdf": "https://arxiv.org/pdf/2510.21778", "abs": "https://arxiv.org/abs/2510.21778", "authors": ["Abdelilah Ganmati", "Karim Afdel", "Lahcen Koutti"], "title": "Ageing Drift in Binary Face Templates: A Bits-per-Decade Analysis", "comment": "9 pages, 3 figures, 2 tables", "summary": "We study the longitudinal stability of compact binary face templates and\nquantify ageing drift directly in bits per decade. Float embeddings from a\nmodern face CNN are compressed with PCA-ITQ into 64- and 128-bit codes. For\neach identity in AgeDB with at least three distinct ages, we form all genuine\npairs and fit a per-identity linear model of Hamming distance versus absolute\nage gap. Across 566 identities, the median slope is 1.357 bits per decade for\n64-bit templates and 2.571 bits per decade for 128-bit templates, with tight\nnon-parametric 95 percent bootstrap confidence intervals. The distributions are\npredominantly positive, indicating a small but systematic increase in\nintra-class distance over time. Because drift scales with code length, shorter\ncodes are inherently more age-stable at a fixed decision threshold. We connect\nthese slopes to operating characteristics by reporting EER and TPR at FAR = 1\npercent in three age bins. We discuss implications for smart-card and\nmatch-on-card deployments, including simple mitigations such as periodic\nre-enrolment and targeted parity on empirically unstable bit positions. Code\nand CSV artifacts are provided to support reproducibility.", "AI": {"tldr": "\u7814\u7a76\u4eba\u8138\u8bc6\u522b\u6a21\u677f\u7684\u957f\u671f\u7a33\u5b9a\u6027\uff0c\u5e76\u91cf\u5316\u4e86\u8001\u5316\u6f02\u79fb\u3002", "motivation": "\u7814\u7a76\u4eba\u8138\u8bc6\u522b\u6280\u672f\u5728\u65f6\u95f4\u63a8\u79fb\u4e0b\u7684\u6027\u80fd\u53d8\u5316\u3002", "method": "\u4f7f\u7528PCA-ITQ\u5c06\u4eba\u8138CNN\u7684float embeddings\u538b\u7f29\u621064\u4f4d\u548c128\u4f4d\u4ee3\u7801\uff0c\u5e76\u9488\u5bf9AgeDB\u4e2d\u7684\u6bcf\u4e2a\u4eba\u8138\u8ba1\u7b97\u6c49\u660e\u8ddd\u79bb\u4e0e\u5e74\u9f84\u5dee\u8ddd\u7684\u7ebf\u6027\u6a21\u578b\u3002", "result": "64\u4f4d\u6a21\u677f\u7684\u4e2d\u503c\u659c\u7387\u4e3a\u6bcf\u5341\u5e741.357 bits\uff0c128\u4f4d\u6a21\u677f\u4e3a\u6bcf\u5341\u5e742.571 bits\uff0c\u8868\u660e\u7c7b\u5185\u8ddd\u79bb\u968f\u65f6\u95f4\u63a8\u79fb\u7565\u6709\u589e\u52a0\u3002\u8f83\u77ed\u7684\u4ee3\u7801\u5728\u56fa\u5b9a\u51b3\u7b56\u9608\u503c\u4e0b\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u8ba8\u8bba\u4e86\u5bf9\u667a\u80fd\u5361\u548cmatch-on-card\u90e8\u7f72\u7684\u5f71\u54cd\uff0c\u5305\u62ec\u5b9a\u671f\u91cd\u65b0\u6ce8\u518c\u548c\u9488\u5bf9\u7ecf\u9a8c\u4e0a\u4e0d\u7a33\u5b9a\u7684\u4f4d\u4f4d\u7f6e\u8fdb\u884c\u5947\u5076\u6821\u9a8c\u7b49\u7f13\u89e3\u63aa\u65bd\u3002"}}
{"id": "2510.21888", "categories": ["cs.AI", "cs.CC", "cs.LG", "68Q17 (Primary) 68T05, 68T42 (Secondary)", "F.2.2; I.2.6; I.2.8"], "pdf": "https://arxiv.org/pdf/2510.21888", "abs": "https://arxiv.org/abs/2510.21888", "authors": ["Shayan Karimi", "Xiaoqi Tan"], "title": "Computational Hardness of Reinforcement Learning with Partial $q^\u03c0$-Realizability", "comment": "to be published in NeurIPS 2025", "summary": "This paper investigates the computational complexity of reinforcement\nlearning in a novel linear function approximation regime, termed partial\n$q^{\\pi}$-realizability. In this framework, the objective is to learn an\n$\\epsilon$-optimal policy with respect to a predefined policy set $\\Pi$, under\nthe assumption that all value functions for policies in $\\Pi$ are linearly\nrealizable. The assumptions of this framework are weaker than those in\n$q^{\\pi}$-realizability but stronger than those in $q^*$-realizability,\nproviding a practical model where function approximation naturally arises. We\nprove that learning an $\\epsilon$-optimal policy in this setting is\ncomputationally hard. Specifically, we establish NP-hardness under a\nparameterized greedy policy set (argmax) and show that - unless NP = RP - an\nexponential lower bound (in feature vector dimension) holds when the policy set\ncontains softmax policies, under the Randomized Exponential Time Hypothesis.\nOur hardness results mirror those in $q^*$-realizability and suggest\ncomputational difficulty persists even when $\\Pi$ is expanded beyond the\noptimal policy. To establish this, we reduce from two complexity problems,\n$\\delta$-Max-3SAT and $\\delta$-Max-3SAT(b), to instances of GLinear-$\\kappa$-RL\n(greedy policy) and SLinear-$\\kappa$-RL (softmax policy). Our findings indicate\nthat positive computational results are generally unattainable in partial\n$q^{\\pi}$-realizability, in contrast to $q^{\\pi}$-realizability under a\ngenerative access model.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f3a\u5316\u5b66\u4e60\u5728\u4e00\u79cd\u65b0\u7684\u7ebf\u6027\u51fd\u6570\u903c\u8fd1\u673a\u5236\uff08\u79f0\u4e3a\u90e8\u5206$q^{\\pi}$-\u53ef\u5b9e\u73b0\u6027\uff09\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u6027\uff0c\u8bc1\u660e\u4e86\u5728\u8fd9\u79cd\u60c5\u51b5\u4e0b\u5b66\u4e60\u4e00\u4e2a$\\epsilon$-\u6700\u4f18\u7b56\u7565\u5728\u8ba1\u7b97\u4e0a\u662f\u56f0\u96be\u7684\u3002", "motivation": "\u76ee\u6807\u662f\u5728\u9884\u5b9a\u4e49\u7684\u7b56\u7565\u96c6$\\Pi$\u4e2d\u5b66\u4e60\u4e00\u4e2a$\\epsilon$-\u6700\u4f18\u7b56\u7565\uff0c\u5047\u8bbe$\\Pi$\u4e2d\u6240\u6709\u7b56\u7565\u7684\u4ef7\u503c\u51fd\u6570\u90fd\u662f\u7ebf\u6027\u53ef\u5b9e\u73b0\u7684\u3002\u8fd9\u4e2a\u6846\u67b6\u7684\u5047\u8bbe\u6bd4$q^{\\pi}$-\u53ef\u5b9e\u73b0\u6027\u4e2d\u7684\u5047\u8bbe\u5f31\uff0c\u4f46\u6bd4$q^*$-\u53ef\u5b9e\u73b0\u6027\u4e2d\u7684\u5047\u8bbe\u5f3a\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u51fd\u6570\u903c\u8fd1\u81ea\u7136\u4ea7\u751f\u7684\u5b9e\u7528\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u5c06\u4e24\u4e2a\u590d\u6742\u6027\u95ee\u9898$\\delta$-Max-3SAT\u548c$\\delta$-Max-3SAT(b)\u5f52\u7ea6\u5230GLinear-$\\\\kappa$-RL\uff08\u8d2a\u5a6a\u7b56\u7565\uff09\u548cSLinear-$\\\\kappa$-RL\uff08softmax\u7b56\u7565\uff09\u7684\u5b9e\u4f8b\uff0c\u8bc1\u660e\u4e86\u5b66\u4e60\u4e00\u4e2a$\\epsilon$-\u6700\u4f18\u7b56\u7565\u662fNP-hard\u7684\u3002", "result": "\u53d1\u73b0\u5728\u53c2\u6570\u5316\u7684\u8d2a\u5a6a\u7b56\u7565\u96c6\uff08argmax\uff09\u4e0b\u662fNP-hard\u7684\uff0c\u5e76\u4e14\u8868\u660e - \u9664\u975eNP = RP - \u5f53\u7b56\u7565\u96c6\u5305\u542bsoftmax\u7b56\u7565\u65f6\uff0c\u5728\u968f\u673a\u6307\u6570\u65f6\u95f4\u5047\u8bbe\u4e0b\uff0c\u5b58\u5728\u4e00\u4e2a\u6307\u6570\u4e0b\u754c\uff08\u5728\u7279\u5f81\u5411\u91cf\u7ef4\u5ea6\u4e2d\uff09\u3002", "conclusion": "\u6211\u4eec\u7684\u53d1\u73b0\u8868\u660e\uff0c\u4e0e\u5728\u751f\u6210\u8bbf\u95ee\u6a21\u578b\u4e0b\u7684$q^{\\pi}$-\u53ef\u5b9e\u73b0\u6027\u76f8\u6bd4\uff0c\u5728\u90e8\u5206$q^{\\pi}$-\u53ef\u5b9e\u73b0\u6027\u4e2d\u901a\u5e38\u65e0\u6cd5\u83b7\u5f97\u79ef\u6781\u7684\u8ba1\u7b97\u7ed3\u679c\u3002"}}
{"id": "2510.21796", "categories": ["cs.LG", "cs.AI", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.21796", "abs": "https://arxiv.org/abs/2510.21796", "authors": ["Xiao Zhou", "Yuze Sun", "Jie Wu", "Xiaomeng Huang"], "title": "A Physics-Guided AI Cascaded Corrector Model Significantly Extends Madden-Julian Oscillation Prediction Skill", "comment": null, "summary": "The Madden-Julian Oscillation (MJO) is an important driver of global weather\nand climate extremes, but its prediction in operational dynamical models\nremains challenging, with skillful forecasts typically limited to 3-4 weeks.\nHere, we introduce a novel deep learning framework, the Physics-guided Cascaded\nCorrector for MJO (PCC-MJO), which acts as a universal post-processor to\ncorrect MJO forecasts from dynamical models. This two-stage model first employs\na physics-informed 3D U-Net to correct spatial-temporal field errors, then\nrefines the MJO's RMM index using an LSTM optimized for forecast skill. When\napplied to three different operational forecasts from CMA, ECMWF and NCEP, our\nunified framework consistently extends the skillful forecast range (bivariate\ncorrelation > 0.5) by 2-8 days. Crucially, the model effectively mitigates the\n\"Maritime Continent barrier\", enabling more realistic eastward propagation and\namplitude. Explainable AI analysis quantitatively confirms that the model's\ndecision-making is spatially congruent with observed MJO dynamics (correlation\n> 0.93), demonstrating that it learns physically meaningful features rather\nthan statistical fittings. Our work provides a promising physically consistent,\ncomputationally efficient, and highly generalizable pathway to break through\nlongstanding barriers in subseasonal forecasting.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6PCC-MJO\uff0c\u7528\u4e8e\u4fee\u6b63\u52a8\u529b\u6a21\u578b\u5bf9MJO\u7684\u9884\u6d4b\uff0c\u5ef6\u957f\u6709\u6548\u9884\u6d4b\u8303\u56f4\u3002", "motivation": "MJO\u662f\u5168\u7403\u5929\u6c14\u548c\u6c14\u5019\u6781\u7aef\u4e8b\u4ef6\u7684\u91cd\u8981\u9a71\u52a8\u56e0\u7d20\uff0c\u4f46\u4e1a\u52a1\u52a8\u529b\u6a21\u578b\u5bf9\u5176\u9884\u6d4b\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u6709\u6548\u9884\u6d4b\u901a\u5e38\u9650\u4e8e3-4\u5468\u3002", "method": "\u8be5\u6a21\u578b\u91c7\u7528\u7269\u7406\u4fe1\u606f3D U-Net\u6765\u6821\u6b63\u65f6\u7a7a\u573a\u8bef\u5dee\uff0c\u7136\u540e\u4f7f\u7528\u9488\u5bf9\u9884\u6d4b\u6280\u80fd\u4f18\u5316\u7684LSTM\u6765\u4f18\u5316MJO\u7684RMM\u6307\u6570\u3002", "result": "\u8be5\u6846\u67b6\u5c06CMA\u3001ECMWF\u548cNCEP\u7684\u6709\u6548\u9884\u6d4b\u8303\u56f4\u5ef6\u957f\u4e862-8\u5929\uff0c\u5e76\u6709\u6548\u7f13\u89e3\u4e86\u201c\u6d77\u6d0b\u5927\u9646\u969c\u788d\u201d\u3002", "conclusion": "\u8be5\u6a21\u578b\u4e3a\u7a81\u7834\u4e9a\u5b63\u8282\u9884\u6d4b\u7684\u957f\u671f\u969c\u788d\u63d0\u4f9b\u4e86\u4e00\u6761\u6709\u5e0c\u671b\u7684\u3001\u7269\u7406\u4e0a\u4e00\u81f4\u7684\u3001\u8ba1\u7b97\u6548\u7387\u9ad8\u7684\u548c\u9ad8\u5ea6\u901a\u7528\u7684\u9014\u5f84\u3002"}}
{"id": "2510.21733", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21733", "abs": "https://arxiv.org/abs/2510.21733", "authors": ["Jia-Huei Ju", "Eugene Yang", "Trevor Adriaanse", "Andrew Yates"], "title": "Augmenting Researchy Questions with Sub-question Judgments", "comment": "3 pages", "summary": "The Researchy Questions dataset provides about 100k question queries with\ncomplex information needs that require retrieving information about several\naspects of a topic. Each query in ResearchyQuestions is associated with\nsub-questions that were produced by prompting GPT-4. While ResearchyQuestions\ncontains labels indicating what documents were clicked after issuing the query,\nthere are no associations in the dataset between sub-questions and relevant\ndocuments. In this work, we augment the Researchy Questions dataset with\nLLM-judged labels for each sub-question using a Llama3.3 70B model. We intend\nthese sub-question labels to serve as a resource for training retrieval models\nthat better support complex information needs.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4f7f\u7528 Llama3.3 70B \u6a21\u578b\uff0c\u4e3a Researchy Questions \u6570\u636e\u96c6\u4e2d\u7684\u6bcf\u4e2a\u5b50\u95ee\u9898\u6dfb\u52a0\u4e86 LLM \u5224\u5b9a\u7684\u6807\u7b7e\uff0c\u65e8\u5728\u4e3a\u8bad\u7ec3\u66f4\u597d\u5730\u652f\u6301\u590d\u6742\u4fe1\u606f\u9700\u6c42\u7684\u68c0\u7d22\u6a21\u578b\u63d0\u4f9b\u8d44\u6e90\u3002", "motivation": "Researchy Questions \u6570\u636e\u96c6\u5305\u542b\u7ea6 10 \u4e07\u4e2a\u5177\u6709\u590d\u6742\u4fe1\u606f\u9700\u6c42\u7684\u67e5\u8be2\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u5b50\u95ee\u9898\u4e0e\u76f8\u5173\u6587\u6863\u4e4b\u95f4\u7684\u5173\u8054\u3002", "method": "\u4f7f\u7528 Llama3.3 70B \u6a21\u578b\u4e3a\u6bcf\u4e2a\u5b50\u95ee\u9898\u751f\u6210 LLM \u5224\u5b9a\u7684\u6807\u7b7e\uff0c\u4ece\u800c\u6269\u5145 Researchy Questions \u6570\u636e\u96c6\u3002", "result": "\u6269\u5145\u540e\u7684\u6570\u636e\u96c6\u5305\u542b\u5b50\u95ee\u9898\u4e0e LLM \u5224\u5b9a\u7684\u6807\u7b7e\u4e4b\u95f4\u7684\u5173\u8054\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u53ef\u4f5c\u4e3a\u8bad\u7ec3\u68c0\u7d22\u6a21\u578b\u7684\u8d44\u6e90\uff0c\u4ee5\u66f4\u597d\u5730\u652f\u6301\u590d\u6742\u4fe1\u606f\u9700\u6c42\u3002"}}
{"id": "2510.21900", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21900", "abs": "https://arxiv.org/abs/2510.21900", "authors": ["Hongbo Zhang", "Han Cui", "Yidong Wang", "Yijian Tian", "Qi Guo", "Cunxiang Wang", "Jian Wu", "Chiyu Song", "Yue Zhang"], "title": "Deep Literature Survey Automation with an Iterative Workflow", "comment": "Preprint version", "summary": "Automatic literature survey generation has attracted increasing attention,\nyet most existing systems follow a one-shot paradigm, where a large set of\npapers is retrieved at once and a static outline is generated before drafting.\nThis design often leads to noisy retrieval, fragmented structures, and context\noverload, ultimately limiting survey quality. Inspired by the iterative reading\nprocess of human researchers, we propose \\ours, a framework based on recurrent\noutline generation, in which a planning agent incrementally retrieves, reads,\nand updates the outline to ensure both exploration and coherence. To provide\nfaithful paper-level grounding, we design paper cards that distill each paper\ninto its contributions, methods, and findings, and introduce a\nreview-and-refine loop with visualization enhancement to improve textual flow\nand integrate multimodal elements such as figures and tables. Experiments on\nboth established and emerging topics show that \\ours\\ substantially outperforms\nstate-of-the-art baselines in content coverage, structural coherence, and\ncitation quality, while producing more accessible and better-organized surveys.\nTo provide a more reliable assessment of such improvements, we further\nintroduce Survey-Arena, a pairwise benchmark that complements absolute scoring\nand more clearly positions machine-generated surveys relative to human-written\nones. The code is available at\nhttps://github.com/HancCui/IterSurvey\\_Autosurveyv2.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5faa\u73af\u5927\u7eb2\u751f\u6210\u7684\u81ea\u52a8\u6587\u732e\u7efc\u8ff0\u6846\u67b6 IterSurvey\uff0c\u8be5\u6846\u67b6\u6a21\u4eff\u4eba\u7c7b\u7814\u7a76\u4eba\u5458\u7684\u8fed\u4ee3\u9605\u8bfb\u8fc7\u7a0b\uff0c\u9010\u6b65\u68c0\u7d22\u3001\u9605\u8bfb\u548c\u66f4\u65b0\u5927\u7eb2\uff0c\u4ee5\u786e\u4fdd\u63a2\u7d22\u548c\u8fde\u8d2f\u6027\u3002\u4e3a\u4e86\u63d0\u4f9b\u5fe0\u5b9e\u7684\u8bba\u6587\u5c42\u9762\u57fa\u7840\uff0c\u6211\u4eec\u8bbe\u8ba1\u4e86\u8bba\u6587\u5361\u7247\uff0c\u5c06\u6bcf\u7bc7\u8bba\u6587\u63d0\u70bc\u6210\u5176\u8d21\u732e\u3001\u65b9\u6cd5\u548c\u53d1\u73b0\uff0c\u5e76\u5f15\u5165\u4e86\u5177\u6709\u53ef\u89c6\u5316\u589e\u5f3a\u7684\u5ba1\u67e5\u548c\u6539\u8fdb\u5faa\u73af\uff0c\u4ee5\u6539\u5584\u6587\u672c\u6d41\u7a0b\u5e76\u6574\u5408\u591a\u6a21\u6001\u5143\u7d20\uff0c\u4f8b\u5982\u56fe\u8868\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u6587\u732e\u7efc\u8ff0\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u4e00\u6b21\u6027\u8303\u4f8b\uff0c\u5bb9\u6613\u5bfc\u81f4\u68c0\u7d22\u566a\u58f0\u3001\u7ed3\u6784\u788e\u7247\u5316\u548c\u4e0a\u4e0b\u6587\u8fc7\u8f7d\uff0c\u4ece\u800c\u9650\u5236\u4e86\u7efc\u8ff0\u8d28\u91cf\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5faa\u73af\u5927\u7eb2\u751f\u6210\u7684\u6846\u67b6 IterSurvey\uff0c\u5176\u4e2d\u89c4\u5212\u4ee3\u7406\u9010\u6b65\u68c0\u7d22\u3001\u9605\u8bfb\u548c\u66f4\u65b0\u5927\u7eb2\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u8bbe\u8ba1\u4e86\u8bba\u6587\u5361\u7247\uff0c\u5e76\u5f15\u5165\u4e86\u5177\u6709\u53ef\u89c6\u5316\u589e\u5f3a\u7684\u5ba1\u67e5\u548c\u6539\u8fdb\u5faa\u73af\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIterSurvey \u5728\u5185\u5bb9\u8986\u76d6\u7387\u3001\u7ed3\u6784\u8fde\u8d2f\u6027\u548c\u5f15\u6587\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6c34\u5e73\uff0c\u540c\u65f6\u751f\u6210\u4e86\u66f4\u6613\u4e8e\u8bbf\u95ee\u548c\u7ec4\u7ec7\u826f\u597d\u7684\u7efc\u8ff0\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u5f15\u5165\u4e86 Survey-Arena\uff0c\u8fd9\u662f\u4e00\u4e2a\u914d\u5bf9\u57fa\u51c6\uff0c\u53ef\u4ee5\u66f4\u6e05\u6670\u5730\u5b9a\u4f4d\u673a\u5668\u751f\u6210\u7684\u7efc\u8ff0\u76f8\u5bf9\u4e8e\u4eba\u5de5\u64b0\u5199\u7684\u7efc\u8ff0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684 IterSurvey \u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u81ea\u52a8\u6587\u732e\u7efc\u8ff0\u7684\u8d28\u91cf\uff0c\u5e76\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002Survey-Arena \u57fa\u51c6\u7684\u5f15\u5165\u4e5f\u4e3a\u8bc4\u4f30\u81ea\u52a8\u6587\u732e\u7efc\u8ff0\u7684\u8d28\u91cf\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u624b\u6bb5\u3002"}}
{"id": "2510.21780", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21780", "abs": "https://arxiv.org/abs/2510.21780", "authors": ["Bishal Chhetri", "B. V. Rathish Kumar"], "title": "Bridging Accuracy and Interpretability: Deep Learning with XAI for Breast Cancer Detection", "comment": "15 pages, 14 figures", "summary": "In this study, we present an interpretable deep learning framework for the\nearly detection of breast cancer using quantitative features extracted from\ndigitized fine needle aspirate (FNA) images of breast masses. Our deep neural\nnetwork, using ReLU activations, the Adam optimizer, and a binary cross-entropy\nloss, delivers state-of-the-art classification performance, achieving an\naccuracy of 0.992, precision of 1.000, recall of 0.977, and an F1 score of\n0.988. These results substantially exceed the benchmarks reported in the\nliterature. We evaluated the model under identical protocols against a suite of\nwell-established algorithms (logistic regression, decision trees, random\nforests, stochastic gradient descent, K-nearest neighbors, and XGBoost) and\nfound the deep model consistently superior on the same metrics. Recognizing\nthat high predictive accuracy alone is insufficient for clinical adoption due\nto the black-box nature of deep learning models, we incorporated model-agnostic\nExplainable AI techniques such as SHAP and LIME to produce feature-level\nattributions and human-readable visualizations. These explanations quantify the\ncontribution of each feature to individual predictions, support error analysis,\nand increase clinician trust, thus bridging the gap between performance and\ninterpretability for real-world clinical use. The concave points feature of the\ncell nuclei is found to be the most influential feature positively impacting\nthe classification task. This insight can be very helpful in improving the\ndiagnosis and treatment of breast cancer by highlighting the key\ncharacteristics of breast tumor.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65e9\u671f\u4e73\u817a\u764c\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u4f7f\u7528\u4ece\u4e73\u623f\u80bf\u5757\u7684\u6570\u5b57\u5316\u7ec6\u9488\u7a7f\u523a (FNA) \u56fe\u50cf\u4e2d\u63d0\u53d6\u7684\u5b9a\u91cf\u7279\u5f81\u3002", "motivation": "\u4e34\u5e8a\u4e0a\u9700\u8981\u9ad8\u7cbe\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\u7684\u4e73\u817a\u764c\u65e9\u671f\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528 ReLU \u6fc0\u6d3b\u51fd\u6570\u3001Adam \u4f18\u5316\u5668\u548c\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u7ed3\u5408 SHAP \u548c LIME \u7b49\u53ef\u89e3\u91ca AI \u6280\u672f\u3002", "result": "\u8be5\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u51c6\u786e\u7387\u4e3a 0.992\uff0c\u7cbe\u5ea6\u4e3a 1.000\uff0c\u53ec\u56de\u7387\u4e3a 0.977\uff0cF1 \u5206\u6570\u4e3a 0.988\uff0c\u4f18\u4e8e\u5176\u4ed6\u7b97\u6cd5\u3002\u51f9\u70b9\u7279\u5f81\u88ab\u53d1\u73b0\u662f\u5bf9\u5206\u7c7b\u4efb\u52a1\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\u7684\u6700\u6709\u5f71\u54cd\u529b\u7684\u7279\u5f81\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u63d0\u4f9b\u7279\u5f81\u7ea7\u522b\u7684\u5f52\u56e0\u548c\u4eba\u7c7b\u53ef\u8bfb\u7684\u53ef\u89c6\u5316\uff0c\u63d0\u9ad8\u4e86\u4e34\u5e8a\u533b\u751f\u5bf9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u4fe1\u4efb\u5ea6\uff0c\u4ece\u800c\u5f25\u5408\u4e86\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2510.21970", "categories": ["cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21970", "abs": "https://arxiv.org/abs/2510.21970", "authors": ["Josip Tomo Licardo", "Nikola Tankovic"], "title": "Performance Trade-offs of Optimizing Small Language Models for E-Commerce", "comment": "15 pages, 9 figures", "summary": "Large Language Models (LLMs) offer state-of-the-art performance in natural\nlanguage understanding and generation tasks. However, the deployment of leading\ncommercial models for specialized tasks, such as e-commerce, is often hindered\nby high computational costs, latency, and operational expenses. This paper\ninvestigates the viability of smaller, open-weight models as a\nresource-efficient alternative. We present a methodology for optimizing a\none-billion-parameter Llama 3.2 model for multilingual e-commerce intent\nrecognition. The model was fine-tuned using Quantized Low-Rank Adaptation\n(QLoRA) on a synthetically generated dataset designed to mimic real-world user\nqueries. Subsequently, we applied post-training quantization techniques,\ncreating GPU-optimized (GPTQ) and CPU-optimized (GGUF) versions. Our results\ndemonstrate that the specialized 1B model achieves 99% accuracy, matching the\nperformance of the significantly larger GPT-4.1 model. A detailed performance\nanalysis revealed critical, hardware-dependent trade-offs: while 4-bit GPTQ\nreduced VRAM usage by 41%, it paradoxically slowed inference by 82% on an older\nGPU architecture (NVIDIA T4) due to dequantization overhead. Conversely, GGUF\nformats on a CPU achieved a speedup of up to 18x in inference throughput and a\nreduction of over 90% in RAM consumption compared to the FP16 baseline. We\nconclude that small, properly optimized open-weight models are not just a\nviable but a more suitable alternative for domain-specific applications,\noffering state-of-the-art accuracy at a fraction of the computational cost.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f7f\u7528\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u66ff\u4ee3\u5927\u578b\u5546\u4e1a\u6a21\u578b\u5728\u7535\u5546\u610f\u56fe\u8bc6\u522b\u4efb\u52a1\u4e2d\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u90e8\u7f72\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5c0f\u578b\u5f00\u6e90\u6a21\u578b\u4f5c\u4e3a\u8d44\u6e90\u9ad8\u6548\u66ff\u4ee3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002", "method": "\u672c\u6587\u4f7f\u7528QLoRA\u5728\u5408\u6210\u6570\u636e\u96c6\u4e0a\u5fae\u8c03\u4e86\u4e00\u4e2a\u5341\u4ebf\u53c2\u6570\u7684Llama 3.2\u6a21\u578b\uff0c\u5e76\u5e94\u7528\u4e86\u540e\u8bad\u7ec3\u91cf\u5316\u6280\u672f\uff0c\u521b\u5efa\u4e86GPU\u4f18\u5316\uff08GPTQ\uff09\u548cCPU\u4f18\u5316\uff08GGUF\uff09\u7248\u672c\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u4e13\u7528\u6a21\u578b\u8fbe\u5230\u4e8699%\u7684\u51c6\u786e\u7387\uff0c\u4e0e\u66f4\u5927\u7684GPT-4.1\u6a21\u578b\u6027\u80fd\u76f8\u5f53\u3002\u786c\u4ef6\u76f8\u5173\u7684\u6027\u80fd\u5206\u6790\u63ed\u793a\u4e86\u5173\u952e\u7684\u6743\u8861\uff1aGPTQ\u964d\u4f4e\u4e86VRAM\u4f7f\u7528\u7387\uff0c\u4f46\u5728\u65e7\u7684GPU\u67b6\u6784\u4e0a\u964d\u4f4e\u4e86\u63a8\u7406\u901f\u5ea6\uff1bGGUF\u683c\u5f0f\u5728CPU\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u8fbe18\u500d\u7684\u63a8\u7406\u541e\u5410\u91cf\u52a0\u901f\u548c\u8d85\u8fc790%\u7684\u5185\u5b58\u6d88\u8017\u964d\u4f4e\u3002", "conclusion": "\u5c0f\u578b\u3001\u7ecf\u8fc7\u9002\u5f53\u4f18\u5316\u7684\u5f00\u6e90\u6a21\u578b\u4e0d\u4ec5\u53ef\u884c\uff0c\u800c\u4e14\u66f4\u9002\u5408\u9886\u57df\u7279\u5b9a\u7684\u5e94\u7528\uff0c\u4ee5\u4e00\u5c0f\u90e8\u5206\u7684\u8ba1\u7b97\u6210\u672c\u63d0\u4f9b\u6700\u5148\u8fdb\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2510.21797", "categories": ["cs.LG", "cs.AI", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.21797", "abs": "https://arxiv.org/abs/2510.21797", "authors": ["Zhaocheng Liu", "Zhiwen Yu", "Xiaoqing Liu"], "title": "Quantifying Multimodal Imbalance: A GMM-Guided Adaptive Loss for Audio-Visual Learning", "comment": null, "summary": "Current mainstream approaches to addressing multimodal imbalance primarily\nfocus on architectural modifications and optimization-based, often overlooking\na quantitative analysis of the imbalance degree between modalities. To address\nthis gap, our work introduces a novel method for the quantitative analysis of\nmulti-modal imbalance, which in turn informs the design of a sample-level\nadaptive loss function.We begin by defining the \"Modality Gap\" as the\ndifference between the Softmax scores of different modalities (e.g., audio and\nvisual) for the ground-truth class prediction. Analysis of the Modality Gap\ndistribution reveals that it can be effectively modeled by a bimodal Gaussian\nMixture Model (GMM). These two components are found to correspond respectively\nto \"modality-balanced\" and \"modality-imbalanced\" data samples. Subsequently, we\napply Bayes' theorem to compute the posterior probability of each sample\nbelonging to these two distinct distributions.Informed by this quantitative\nanalysis, we design a novel adaptive loss function with three objectives: (1)\nto minimize the overall Modality Gap; (2) to encourage the imbalanced sample\ndistribution to shift towards the balanced one; and (3) to apply greater\npenalty weights to imbalanced samples. We employ a two-stage training strategy\nconsisting of a warm-up phase followed by an adaptive training\nphase.Experimental results demonstrate that our approach achieves\nstate-of-the-art (SOTA) performance on the public CREMA-D and AVE datasets,\nattaining accuracies of $80.65\\%$ and $70.90\\%$, respectively. This validates\nthe effectiveness of our proposed methodology.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u91cf\u5316\u591a\u6a21\u6001\u4e0d\u5e73\u8861\u7a0b\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6837\u672c\u7ea7\u522b\u7684\u81ea\u9002\u5e94\u635f\u5931\u51fd\u6570\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u67b6\u6784\u4fee\u6539\u548c\u4f18\u5316\uff0c\u5ffd\u7565\u4e86\u6a21\u6001\u4e4b\u95f4\u4e0d\u5e73\u8861\u7a0b\u5ea6\u7684\u5b9a\u91cf\u5206\u6790\u3002", "method": "1. \u5b9a\u4e49\u201c\u6a21\u6001\u5dee\u8ddd\u201d\u4e3a\u4e0d\u540c\u6a21\u6001Softmax\u5f97\u5206\u7684\u5dee\u5f02\u30022. \u4f7f\u7528\u53cc\u5cf0\u9ad8\u65af\u6df7\u5408\u6a21\u578b (GMM) \u5bf9\u6a21\u6001\u5dee\u8ddd\u5206\u5e03\u8fdb\u884c\u5efa\u6a21\u30023. \u5e94\u7528\u8d1d\u53f6\u65af\u5b9a\u7406\u8ba1\u7b97\u6bcf\u4e2a\u6837\u672c\u5c5e\u4e8e\u4e0d\u540c\u5206\u5e03\u7684\u540e\u9a8c\u6982\u7387\u30024. \u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5177\u6709\u4e09\u4e2a\u76ee\u6807\u7684\u81ea\u9002\u5e94\u635f\u5931\u51fd\u6570\uff1a\u6700\u5c0f\u5316\u6a21\u6001\u5dee\u8ddd\uff0c\u9f13\u52b1\u4e0d\u5e73\u8861\u6837\u672c\u5206\u5e03\u5411\u5e73\u8861\u5206\u5e03\u79fb\u52a8\uff0c\u5e76\u5bf9\u4e0d\u5e73\u8861\u6837\u672c\u5e94\u7528\u66f4\u5927\u7684\u60e9\u7f5a\u6743\u91cd\u30025. \u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728CREMA-D\u548cAVE\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\uff0c\u51c6\u786e\u7387\u5206\u522b\u4e3a80.65%\u548c70.90%\u3002", "conclusion": "\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.21737", "categories": ["cs.IR", "68T30, 68T50", "I.2.7; I.2.4; H.3.3"], "pdf": "https://arxiv.org/pdf/2510.21737", "abs": "https://arxiv.org/abs/2510.21737", "authors": ["Liangliang Zhang", "Nandana Mihindukulasooriya", "Niharika S. D'Souza", "Sola Shirai", "Sarthak Dash", "Yao Ma", "Horst Samulowitz"], "title": "From Factoid Questions to Data Product Requests: Benchmarking Data Product Discovery over Tables and Text", "comment": "9 pages, 1 figure, 2 tables", "summary": "Data products are reusable, self-contained assets designed for specific\nbusiness use cases. Automating their discovery and generation is of great\nindustry interest, as it enables discovery in large data lakes and supports\nanalytical Data Product Requests (DPRs). Currently, there is no benchmark\nestablished specifically for data product discovery. Existing datasets focus on\nanswering single factoid questions over individual tables rather than\ncollecting multiple data assets for broader, coherent products. To address this\ngap, we introduce DPBench, the first user-request-driven data product benchmark\nover hybrid table-text corpora. Our framework systematically repurposes\nexisting table-text QA datasets by clustering related tables and passages into\ncoherent data products, generating professional-level analytical requests that\nspan both data sources, and validating benchmark quality through multi-LLM\nevaluation. DPBench preserves full provenance while producing actionable,\nanalyst-like data product requests. Baseline experiments with hybrid retrieval\nmethods establish the feasibility of DPR evaluation, reveal current\nlimitations, and point to new opportunities for automatic data product\ndiscovery research.\n  Code and datasets are available at:\nhttps://anonymous.4open.science/r/data-product-benchmark-BBA7/", "AI": {"tldr": "\u4ecb\u7ecd\u4e86DPBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u6570\u636e\u4ea7\u54c1\u53d1\u73b0\u7684\u57fa\u51c6\uff0c\u5b83\u901a\u8fc7\u5c06\u76f8\u5173\u7684\u8868\u683c\u548c\u6bb5\u843d\u805a\u7c7b\u6210\u8fde\u8d2f\u7684\u6570\u636e\u4ea7\u54c1\uff0c\u751f\u6210\u8de8\u8d8a\u6570\u636e\u6e90\u7684\u5206\u6790\u8bf7\u6c42\uff0c\u5e76\u901a\u8fc7\u591a\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6765\u9a8c\u8bc1\u57fa\u51c6\u8d28\u91cf\uff0c\u4ece\u800c\u7cfb\u7edf\u5730\u91cd\u65b0\u5229\u7528\u73b0\u6709\u7684\u8868\u683c-\u6587\u672c\u95ee\u7b54\u6570\u636e\u96c6\u3002", "motivation": "\u5f53\u524d\u6ca1\u6709\u4e13\u95e8\u4e3a\u6570\u636e\u4ea7\u54c1\u53d1\u73b0\u5efa\u7acb\u7684\u57fa\u51c6\u3002\u73b0\u6709\u7684\u6570\u636e\u96c6\u4fa7\u91cd\u4e8e\u56de\u7b54\u5355\u4e2a\u8868\u683c\u4e0a\u7684\u5355\u4e00\u4e8b\u5b9e\u95ee\u9898\uff0c\u800c\u4e0d\u662f\u4e3a\u66f4\u5e7f\u6cdb\u3001\u8fde\u8d2f\u7684\u4ea7\u54c1\u6536\u96c6\u591a\u4e2a\u6570\u636e\u8d44\u4ea7\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5c06\u76f8\u5173\u7684\u8868\u683c\u548c\u6bb5\u843d\u805a\u7c7b\u6210\u8fde\u8d2f\u7684\u6570\u636e\u4ea7\u54c1\uff0c\u751f\u6210\u8de8\u8d8a\u6570\u636e\u6e90\u7684\u4e13\u4e1a\u7ea7\u5206\u6790\u8bf7\u6c42\uff0c\u5e76\u901a\u8fc7\u591a\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u6765\u9a8c\u8bc1\u57fa\u51c6\u8d28\u91cf\uff0c\u4ece\u800c\u7cfb\u7edf\u5730\u91cd\u65b0\u5229\u7528\u73b0\u6709\u7684\u8868\u683c-\u6587\u672c\u95ee\u7b54\u6570\u636e\u96c6\u3002", "result": "\u901a\u8fc7\u6df7\u5408\u68c0\u7d22\u65b9\u6cd5\u7684\u57fa\u7ebf\u5b9e\u9a8c\uff0c\u786e\u5b9a\u4e86DPR\u8bc4\u4f30\u7684\u53ef\u884c\u6027\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u7684\u5c40\u9650\u6027\uff0c\u5e76\u4e3a\u81ea\u52a8\u6570\u636e\u4ea7\u54c1\u53d1\u73b0\u7814\u7a76\u6307\u51fa\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "conclusion": "DPBench\u662f\u7b2c\u4e00\u4e2a\u7528\u6237\u8bf7\u6c42\u9a71\u52a8\u7684\u6df7\u5408\u8868-\u6587\u672c\u8bed\u6599\u5e93\u4e0a\u7684\u6570\u636e\u4ea7\u54c1\u57fa\u51c6\uff0c\u5b83\u4fdd\u7559\u4e86\u5b8c\u6574\u7684\u51fa\u5904\uff0c\u540c\u65f6\u751f\u6210\u4e86\u53ef\u64cd\u4f5c\u7684\u3001\u7c7b\u4f3c\u5206\u6790\u5e08\u7684\u6570\u636e\u4ea7\u54c1\u8bf7\u6c42\u3002"}}
{"id": "2510.21909", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21909", "abs": "https://arxiv.org/abs/2510.21909", "authors": ["Catherine Arnett", "Tyler A. Chang", "Stella Biderman", "Benjamin K. Bergen"], "title": "Explaining and Mitigating Crosslingual Tokenizer Inequities", "comment": "Accepted to NeurIPS 2025", "summary": "The number of tokens it takes to encode parallel text in different languages\nis known to vary. These disparities are called token premiums. Having high\ntoken premiums leads to less throughput during training and increases costs at\ninference. In this paper, we show that even after controlling for dataset size,\nvocabulary size, and data content, monolingual tokenizers exhibit a wide range\nof token premiums across languages. To understand the cross-linguistic\ndifferences that cause these token premiums, we train a suite of approximately\n7,000 comparable monolingual tokenizers for 97 languages, manipulating\ntokenization algorithm, vocabulary size, and dataset size. We measure token\npremiums and test for a relationship between factors such as data similarity\n(between tokenizer training and evaluation), vocabulary size, and\npre-tokenization. We also investigate the role of language-specific features\nsuch as writing system and word length. We find that similarity between\ntraining and test data does not impact token premiums, but vocabulary size and\npre-tokenization do. While simply increasing vocabulary size does not lead to\nreduced token premium effects, we can determine an ``optimal'' vocabulary size\nfor each language to achieve significantly reduced token premium effects. We\nalso train superword tokenizers which allow merges over whitespaces, and we\nfind that they both reduce token premium effects and improve compression\noverall. Thus, intervening on the vocabulary size or the pre-tokenizer\nsignificantly reduces crosslingual token premium effects.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e0d\u540c\u8bed\u8a00\u7684token premiums\uff08\u7f16\u7801\u5e73\u884c\u6587\u672c\u6240\u9700\u7684token\u6570\u91cf\u5dee\u5f02\uff09\u95ee\u9898\u3002", "motivation": "\u9ad8token premiums\u4f1a\u5bfc\u81f4\u8bad\u7ec3\u541e\u5410\u91cf\u964d\u4f4e\u548c\u63a8\u7406\u6210\u672c\u589e\u52a0\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7a76\u5bfc\u81f4\u4e0d\u540c\u8bed\u8a00token premiums\u5dee\u5f02\u7684\u8de8\u8bed\u8a00\u56e0\u7d20\u3002", "method": "\u8bba\u6587\u8bad\u7ec3\u4e86\u7ea67000\u4e2a\u5355\u8bedtokenizer\uff0c\u6db5\u76d697\u79cd\u8bed\u8a00\uff0c\u5e76\u64cd\u7eb5tokenization\u7b97\u6cd5\u3001\u8bcd\u6c47\u91cf\u548c\u6570\u636e\u96c6\u5927\u5c0f\u7b49\u56e0\u7d20\u3002\u7814\u7a76\u6d4b\u91cf\u4e86token premiums\uff0c\u5e76\u6d4b\u8bd5\u4e86\u6570\u636e\u76f8\u4f3c\u6027\u3001\u8bcd\u6c47\u91cf\u548c\u9884tokenization\u7b49\u56e0\u7d20\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u540c\u65f6\uff0c\u7814\u7a76\u8fd8\u8c03\u67e5\u4e86\u6587\u5b57\u7cfb\u7edf\u548c\u8bcd\u957f\u7b49\u8bed\u8a00\u7279\u5b9a\u7279\u5f81\u7684\u4f5c\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u4e4b\u95f4\u7684\u76f8\u4f3c\u6027\u4e0d\u5f71\u54cdtoken premiums\uff0c\u4f46\u8bcd\u6c47\u91cf\u548c\u9884tokenization\u4f1a\u5f71\u54cdtoken premiums\u3002\u786e\u5b9a\u6bcf\u79cd\u8bed\u8a00\u7684\u201c\u6700\u4f73\u201d\u8bcd\u6c47\u91cf\u53ef\u4ee5\u663e\u8457\u964d\u4f4etoken premium\u7684\u5f71\u54cd\u3002\u8bad\u7ec3\u5141\u8bb8\u5408\u5e76\u7a7a\u767d\u7b26\u7684superword tokenizer\u53ef\u4ee5\u964d\u4f4etoken premium\u7684\u5f71\u54cd\u5e76\u63d0\u9ad8\u6574\u4f53\u538b\u7f29\u7387\u3002", "conclusion": "\u5e72\u9884\u8bcd\u6c47\u91cf\u6216\u9884tokenizer\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u8de8\u8bed\u8a00token premium\u7684\u5f71\u54cd\u3002"}}
{"id": "2510.21781", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21781", "abs": "https://arxiv.org/abs/2510.21781", "authors": ["Runchu Donga", "Peng Zhao", "Guiqin Wang", "Nan Qi", "Jie Lin"], "title": "EdgeSync: Accelerating Edge-Model Updates for Data Drift through Adaptive Continuous Learning", "comment": null, "summary": "Real-time video analytics systems typically deploy lightweight models on edge\ndevices to reduce latency. However, the distribution of data features may\nchange over time due to various factors such as changing lighting and weather\nconditions, leading to decreased model accuracy. Recent frameworks try to\naddress this issue by leveraging remote servers to continuously train and adapt\nlightweight edge models using more complex models in the cloud. Despite these\nadvancements, existing methods face two key challenges: first, the retraining\nprocess is compute-intensive, causing significant delays in model updates;\nsecond, the new model may not align well with the evolving data distribution of\nthe current video stream. To address these challenges, we introduce EdgeSync,\nan efficient edge-model updating approach that enhances sample filtering by\nincorporating timeliness and inference results, thus ensuring training samples\nare more relevant to the current video content while reducing update delays.\nAdditionally, EdgeSync features a dynamic training management module that\noptimizes the timing and sequencing of model updates to improve their\ntimeliness. Evaluations on diverse and complex real-world datasets demonstrate\nthat EdgeSync improves accuracy by approximately 3.4% compared to existing\nmethods and by about 10% compared to traditional approaches.", "AI": {"tldr": "EdgeSync improves edge model accuracy by incorporating timeliness and inference results into sample filtering and optimizing the timing of model updates.", "motivation": "Model accuracy decreases over time due to changing data features, and retraining is compute-intensive and may not align well with the evolving data distribution.", "method": "EdgeSync enhances sample filtering by incorporating timeliness and inference results and features a dynamic training management module.", "result": "EdgeSync improves accuracy by approximately 3.4% compared to existing methods and by about 10% compared to traditional approaches.", "conclusion": "EdgeSync is an efficient edge-model updating approach that ensures training samples are more relevant to the current video content while reducing update delays."}}
{"id": "2510.21977", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21977", "abs": "https://arxiv.org/abs/2510.21977", "authors": ["Ji Huang", "Mengfei Li", "Shuai Shao"], "title": "Distribution Shift Alignment Helps LLMs Simulate Survey Response Distributions", "comment": null, "summary": "Large language models (LLMs) offer a promising way to simulate human survey\nresponses, potentially reducing the cost of large-scale data collection.\nHowever, existing zero-shot methods suffer from prompt sensitivity and low\naccuracy, while conventional fine-tuning approaches mostly fit the training set\ndistributions and struggle to produce results more accurate than the training\nset itself, which deviates from the original goal of using LLMs to simulate\nsurvey responses. Building on this observation, we introduce Distribution Shift\nAlignment (DSA), a two-stage fine-tuning method that aligns both the output\ndistributions and the distribution shifts across different backgrounds. By\nlearning how these distributions change rather than fitting training data, DSA\ncan provide results substantially closer to the true distribution than the\ntraining data. Empirically, DSA consistently outperforms other methods on five\npublic survey datasets. We further conduct a comprehensive comparison covering\naccuracy, robustness, and data savings. DSA reduces the required real data by\n53.48-69.12%, demonstrating its effectiveness and efficiency in survey\nsimulation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5206\u5e03\u504f\u79fb\u5bf9\u9f50 (DSA) \u7684\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5b66\u4e60\u5206\u5e03\u53d8\u5316\u800c\u975e\u62df\u5408\u8bad\u7ec3\u6570\u636e\uff0c\u4f7f\u7ed3\u679c\u66f4\u63a5\u8fd1\u771f\u5b9e\u5206\u5e03\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u6a21\u62df\u8c03\u67e5\u3002", "motivation": "\u73b0\u6709\u96f6\u6837\u672c\u65b9\u6cd5\u5b58\u5728prompt\u654f\u611f\u6027\u548c\u51c6\u786e\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u800c\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5 \u043e\u0441\u043d\u043e\u0432\u043d\u043e\u043c \u62df\u5408\u8bad\u7ec3\u96c6\u5206\u5e03\uff0c\u96be\u4ee5\u4ea7\u751f\u6bd4\u8bad\u7ec3\u96c6\u672c\u8eab\u66f4\u51c6\u786e\u7684\u7ed3\u679c\uff0c\u8fd9\u504f\u79bb\u4e86\u4f7f\u7528 LLM \u6a21\u62df\u8c03\u67e5\u56de\u590d\u7684\u6700\u521d\u76ee\u6807\u3002", "method": "\u5f15\u5165\u5206\u5e03\u504f\u79fb\u5bf9\u9f50 (DSA)\uff0c\u8fd9\u662f\u4e00\u79cd\u4e24\u9636\u6bb5\u5fae\u8c03\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5bf9\u9f50\u8f93\u51fa\u5206\u5e03\u548c\u8de8\u4e0d\u540c\u80cc\u666f\u7684\u5206\u5e03\u504f\u79fb\u3002", "result": "\u5728\u4e94\u4e2a\u516c\u5171\u8c03\u67e5\u6570\u636e\u96c6\u4e0a\uff0cDSA \u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002DSA \u5c06\u6240\u9700\u7684\u771f\u5b9e\u6570\u636e\u51cf\u5c11\u4e86 53.48-69.12%\u3002", "conclusion": "DSA \u5728\u8c03\u67e5\u6a21\u62df\u4e2d\u5177\u6709\u6709\u6548\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2510.21800", "categories": ["cs.LG", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.21800", "abs": "https://arxiv.org/abs/2510.21800", "authors": ["Yifeng Liu", "Angela Yuan", "Quanquan Gu"], "title": "MARS-M: When Variance Reduction Meets Matrices", "comment": null, "summary": "Matrix-based preconditioned optimizers, such as Muon, have recently been\nshown to be more efficient than scalar-based optimizers for training\nlarge-scale neural networks, including large language models (LLMs). On the\nother hand, recent benchmarks on optimizers for LLM pre-training have\ndemonstrated that variance-reduction techniques such as MARS can achieve\nsubstantial speedups over standard optimizers that do not employ variance\nreduction. In this paper, to achieve the best of both worlds, we introduce\nMARS-M, a new optimizer that integrates the variance reduction technique in\nMARS with Muon. Under standard regularity conditions, we prove that Muon-M\nconverges to a first-order stationary point at a rate of\n$\\tilde{\\mathcal{O}}(T^{-1/3})$, which improves upon\n$\\tilde{\\mathcal{O}}(T^{-1/4})$ rate attained by Muon. Our empirical results on\nlanguage modeling and computer vision tasks demonstrate that MARS-M\nconsistently yields lower losses and improved performance across various\ndownstream benchmarks. The implementation of MARS-M is available at\nhttps://github.com/AGI-Arena/MARS/MARS_M.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668MARS-M\uff0c\u5b83\u7ed3\u5408\u4e86MARS\u4e2d\u7684\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u548cMuon\u4e2d\u7684\u77e9\u9635\u9884\u5904\u7406\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u77e9\u9635\u7684\u9884\u5904\u7406\u4f18\u5316\u5668\uff08\u5982Muon\uff09\u548c\u57fa\u4e8e\u65b9\u5dee\u7f29\u51cf\u7684\u4f18\u5316\u5668\uff08\u5982MARS\uff09\u5728\u8bad\u7ec3\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u5206\u522b\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u7f3a\u4e4f\u7ed3\u5408\u3002", "method": "\u672c\u6587\u5c06MARS\u7684\u65b9\u5dee\u7f29\u51cf\u6280\u672f\u4e0eMuon\u76f8\u7ed3\u5408\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u4f18\u5316\u5668MARS-M\uff0c\u5e76\u4ece\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u5176\u6536\u655b\u901f\u5ea6\u3002", "result": "\u5728\u8bed\u8a00\u5efa\u6a21\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cMARS-M\u5728\u5404\u79cd\u4e0b\u6e38\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u80fd\u4ea7\u751f\u66f4\u4f4e\u7684\u635f\u5931\u548c\u66f4\u9ad8\u7684\u6027\u80fd\u3002", "conclusion": "MARS-M \u7ed3\u5408\u4e86 MARS \u548c Muon \u7684\u4f18\u70b9\uff0c\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5e76\u4e14\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002"}}
{"id": "2510.21805", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21805", "abs": "https://arxiv.org/abs/2510.21805", "authors": ["Zhao Liu", "Yichen Zhu", "Yiqing Yang", "Guoping Tang", "Rui Huang", "Qiang Luo", "Xiao Lv", "Ruiming Tang", "Kun Gai", "Guorui Zhou"], "title": "DiffGRM: Diffusion-based Generative Recommendation Model", "comment": "13 pages, 5 figures", "summary": "Generative recommendation (GR) is an emerging paradigm that represents each\nitem via a tokenizer as an n-digit semantic ID (SID) and predicts the next item\nby autoregressively generating its SID conditioned on the user's history.\nHowever, two structural properties of SIDs make ARMs ill-suited. First,\nintra-item consistency: the n digits jointly specify one item, yet the\nleft-to-right causality trains each digit only under its prefix and blocks\nbidirectional cross-digit evidence, collapsing supervision to a single causal\npath. Second, inter-digit heterogeneity: digits differ in semantic granularity\nand predictability, while the uniform next-token objective assigns equal weight\nto all digits, overtraining easy digits and undertraining hard digits. To\naddress these two issues, we propose DiffGRM, a diffusion-based GR model that\nreplaces the autoregressive decoder with a masked discrete diffusion model\n(MDM), thereby enabling bidirectional context and any-order parallel generation\nof SID digits for recommendation. Specifically, we tailor DiffGRM in three\naspects: (1) tokenization with Parallel Semantic Encoding (PSE) to decouple\ndigits and balance per-digit information; (2) training with On-policy Coherent\nNoising (OCN) that prioritizes uncertain digits via coherent masking to\nconcentrate supervision on high-value signals; and (3) inference with\nConfidence-guided Parallel Denoising (CPD) that fills higher-confidence digits\nfirst and generates diverse Top-K candidates. Experiments show consistent gains\nover strong generative and discriminative recommendation baselines on multiple\ndatasets, improving NDCG@10 by 6.9%-15.5%. Code is available at\nhttps://github.com/liuzhao09/DiffGRM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u7684\u751f\u6210\u63a8\u8350\u6a21\u578bDiffGRM\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u5728\u9879\u76ee\u8868\u793a\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u81ea\u56de\u5f52\u751f\u6210\u63a8\u8350\u6a21\u578b(ARMs)\u5728\u5904\u7406\u9879\u76ee\u8bed\u4e49ID(SID)\u65f6\uff0c\u5b58\u5728\u5185\u90e8\u9879\u76ee\u4e00\u81f4\u6027\u548c\u6570\u5b57\u95f4\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528\u63a9\u853d\u79bb\u6563\u6269\u6563\u6a21\u578b(MDM)\u66ff\u6362\u81ea\u56de\u5f52\u89e3\u7801\u5668\uff0c\u5b9e\u73b0SID\u6570\u5b57\u7684\u53cc\u5411\u4e0a\u4e0b\u6587\u548c\u4efb\u610f\u987a\u5e8f\u5e76\u884c\u751f\u6210\u3002\u901a\u8fc7\u5e76\u884c\u8bed\u4e49\u7f16\u7801(PSE)\u89e3\u8026\u6570\u5b57\u5e76\u5e73\u8861\u6bcf\u4e2a\u6570\u5b57\u7684\u4fe1\u606f\uff1b\u4f7f\u7528On-policy Coherent Noising (OCN)\u4f18\u5148\u8003\u8651\u4e0d\u786e\u5b9a\u7684\u6570\u5b57\uff1b\u4f7f\u7528Confidence-guided Parallel Denoising (CPD)\u4f18\u5148\u586b\u5145\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u6570\u5b57\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cDiffGRM\u76f8\u6bd4\u4e8e\u5176\u4ed6\u751f\u6210\u548c\u5224\u522b\u63a8\u8350\u57fa\u7ebf\u6a21\u578b\uff0cNDCG@10 \u6307\u6807\u63d0\u5347\u4e866.9%-15.5%\u3002", "conclusion": "DiffGRM \u80fd\u591f\u6709\u6548\u63d0\u5347\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2510.21954", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.21954", "abs": "https://arxiv.org/abs/2510.21954", "authors": ["Mykola Haltiuk", "Aleksander Smywi\u0144ski-Pohl"], "title": "Model-Aware Tokenizer Transfer", "comment": null, "summary": "Large Language Models (LLMs) are trained to support an increasing number of\nlanguages, yet their predefined tokenizers remain a bottleneck for adapting\nmodels to lower-resource or distinct-script languages. Existing tokenizer\ntransfer methods typically rely on semantic heuristics to initialize new\nembeddings, ignoring higher-layer model dynamics and limiting transfer quality.\nWe propose Model-Aware Tokenizer Transfer (MATT), a method that incorporates\nmodel internals into the tokenizer transfer process. MATT introduces an\nAttention Influence Modeling (AIM) objective that distills inter-token\ncommunication patterns from a source model into a target model with a new\ntokenizer, providing an efficient warm-up before standard language modeling.\nUnlike approaches that focus solely on embedding similarity, MATT leverages\nattention behavior to guide embedding initialization and adaptation.\nExperiments across diverse linguistic settings show that MATT recovers a large\nfraction of the original model's performance within a few GPU hours,\noutperforming heuristic baselines. These results demonstrate that incorporating\nmodel-level signals offers a practical and effective path toward robust\ntokenizer transfer in multilingual LLMs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684tokenizer\u8fc1\u79fb\u65b9\u6cd5\uff0c\u53ef\u4ee5\u5728\u591a\u8bed\u8a00llm\u4e2d\u5b9e\u73b0\u9c81\u68d2\u7684tokenizer\u8fc1\u79fb\u3002", "motivation": "\u73b0\u6709\u7684tokenizer\u8fc1\u79fb\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u8bed\u4e49\u542f\u53d1\u5f0f\u65b9\u6cd5\u6765\u521d\u59cb\u5316\u65b0\u7684\u5d4c\u5165\uff0c\u5ffd\u7565\u4e86\u66f4\u9ad8\u5c42\u7684\u6a21\u578b\u52a8\u6001\uff0c\u9650\u5236\u4e86\u8fc1\u79fb\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u611f\u77e5tokenizer\u8fc1\u79fb(MATT)\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u7eb3\u5165tokenizer\u8fc1\u79fb\u8fc7\u7a0b\u3002MATT\u5f15\u5165\u4e86\u4e00\u79cd\u6ce8\u610f\u5f71\u54cd\u5efa\u6a21(AIM)\u76ee\u6807\uff0c\u8be5\u76ee\u6807\u5c06\u6e90\u6a21\u578b\u4e2d\u7684token\u95f4\u901a\u4fe1\u6a21\u5f0f\u63d0\u70bc\u5230\u5177\u6709\u65b0tokenizer\u7684\u76ee\u6807\u6a21\u578b\u4e2d\uff0c\u4ece\u800c\u5728\u6807\u51c6\u8bed\u8a00\u5efa\u6a21\u4e4b\u524d\u63d0\u4f9b\u6709\u6548\u7684\u9884\u70ed\u3002", "result": "\u5728\u4e0d\u540c\u7684\u8bed\u8a00\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u5b9e\u9a8c\u8868\u660e\uff0cMATT\u5728\u51e0\u4e2aGPU\u5c0f\u65f6\u5185\u6062\u590d\u4e86\u539f\u59cb\u6a21\u578b\u7684\u5927\u90e8\u5206\u6027\u80fd\uff0c\u4f18\u4e8e\u542f\u53d1\u5f0f\u57fa\u7ebf\u3002", "conclusion": "\u5c06\u6a21\u578b\u7ea7\u4fe1\u53f7\u7eb3\u5165tokenizer\u8fc1\u79fb\u63d0\u4f9b\u4e86\u4e00\u6761\u5b9e\u7528\u4e14\u6709\u6548\u7684\u9014\u5f84\u3002"}}
{"id": "2510.21782", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.21782", "abs": "https://arxiv.org/abs/2510.21782", "authors": ["Emmanuel U. Ugwu", "Zhang Xinming"], "title": "Promptable Fire Segmentation: Unleashing SAM2's Potential for Real-Time Mobile Deployment with Strategic Bounding Box Guidance", "comment": "Accepted for presentation at the 9th International Conference on\n  Image and Graphics Processing (ICIGP 2026) will be held in Wuhan, China\n  during January 16-18, 2026 (publication forthcoming). 6 pages, 3 figures, 3\n  tables", "summary": "Fire segmentation remains a critical challenge in computer vision due to\nflames' irregular boundaries, translucent edges, and highly variable\nintensities. While the Segment Anything Models (SAM and SAM2) have demonstrated\nimpressive cross-domain generalization capabilities, their effectiveness in\nfire segmentation -- particularly under mobile deployment constraints --\nremains largely unexplored. This paper presents the first comprehensive\nevaluation of SAM2 variants for fire segmentation, focusing on bounding box\nprompting strategies to enhance deployment feasibility. We systematically\nevaluate four SAM2.1 variants (tiny, small, base_plus, large) alongside\nmobile-oriented variants (TinySAM, MobileSAM) across three fire datasets using\nmultiple prompting strategies: automatic, single positive point (SP), single\npositive point + single negative point (SP+SN), multiple positive points (MP),\nbounding box (Box), and hybrid variants (Box+SP and Box+MP). Our experimental\nresults demonstrate that bounding box prompts consistently outperform automatic\nand single point-based approaches, with Box+MP achieving the highest mean IoU\n(0.64) and Dice coefficient (0.75) on the Khan dataset. Lightweight variants\nsuch as TinySAM and MobileSAM further reduce memory and computational costs,\nmaking them more suitable for latency-tolerant edge scenarios. Overall, this\nwork provides critical insights for deploying promptable segmentation models in\nfire monitoring systems and establishes benchmarks for future research in\ndomain-specific SAM applications. Code is available at:\nhttps://github.com/UEmmanuel5/ProFSAM", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86SAM2\u53d8\u4f53\u5728\u706b\u707e\u5206\u5272\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u5173\u6ce8\u8fb9\u754c\u6846\u63d0\u793a\u7b56\u7565\u4ee5\u589e\u5f3a\u90e8\u7f72\u53ef\u884c\u6027\u3002", "motivation": "\u706b\u707e\u5206\u5272\u7531\u4e8e\u706b\u7130\u7684\u4e0d\u89c4\u5219\u8fb9\u754c\u3001\u534a\u900f\u660e\u8fb9\u7f18\u548c\u9ad8\u5ea6\u53ef\u53d8\u7684\u5f3a\u5ea6\u4ecd\u7136\u662f\u8ba1\u7b97\u673a\u89c6\u89c9\u4e2d\u7684\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002\u867d\u7136Segment Anything Models (SAM\u548cSAM2)\u5df2\u7ecf\u5c55\u793a\u4e86\u4ee4\u4eba\u5370\u8c61\u6df1\u523b\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u5728\u706b\u707e\u5206\u5272\u4e2d\u7684\u6709\u6548\u6027\u2014\u2014\u7279\u522b\u662f\u5728\u79fb\u52a8\u90e8\u7f72\u7ea6\u675f\u4e0b\u2014\u2014\u4ecd\u7136\u5f88\u5927\u7a0b\u5ea6\u4e0a\u672a\u88ab\u63a2\u7d22\u3002", "method": "\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u56db\u79cdSAM2.1\u53d8\u4f53\uff08tiny\u3001small\u3001base_plus\u3001large\uff09\u4ee5\u53ca\u9762\u5411\u79fb\u52a8\u7684\u53d8\u4f53\uff08TinySAM\u3001MobileSAM\uff09\u5728\u4e09\u4e2a\u706b\u707e\u6570\u636e\u96c6\u4e0a\u4f7f\u7528\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff1a\u81ea\u52a8\u3001\u5355\u6b63\u70b9\uff08SP\uff09\u3001\u5355\u6b63\u70b9+\u5355\u8d1f\u70b9\uff08SP+SN\uff09\u3001\u591a\u6b63\u70b9\uff08MP\uff09\u3001\u8fb9\u754c\u6846\uff08Box\uff09\u548c\u6df7\u5408\u53d8\u4f53\uff08Box+SP\u548cBox+MP\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8fb9\u754c\u6846\u63d0\u793a\u59cb\u7ec8\u4f18\u4e8e\u81ea\u52a8\u548c\u57fa\u4e8e\u5355\u70b9\u7684\u65b9\u6cd5\uff0c\u5176\u4e2dBox+MP\u5728Khan\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad8\u7684\u5e73\u5747IoU\uff080.64\uff09\u548cDice\u7cfb\u6570\uff080.75\uff09\u3002\u8bf8\u5982TinySAM\u548cMobileSAM\u4e4b\u7c7b\u7684\u8f7b\u91cf\u7ea7\u53d8\u4f53\u8fdb\u4e00\u6b65\u964d\u4f4e\u4e86\u5185\u5b58\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u4f7f\u5176\u66f4\u9002\u5408\u4e8e\u5bb9\u5fcd\u5ef6\u8fdf\u7684\u8fb9\u7f18\u573a\u666f\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5728\u706b\u707e\u76d1\u63a7\u7cfb\u7edf\u4e2d\u90e8\u7f72\u53ef\u63d0\u793a\u7684\u5206\u5272\u6a21\u578b\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u7279\u5b9a\u9886\u57df\u7684SAM\u5e94\u7528\u7814\u7a76\u5efa\u7acb\u4e86\u57fa\u51c6\u3002"}}
{"id": "2510.21999", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21999", "abs": "https://arxiv.org/abs/2510.21999", "authors": ["Zhenya Huang", "Jiayu Liu", "Xin Lin", "Zhiyuan Ma", "Shangzi Xue", "Tong Xiao", "Qi Liu", "Yee Whye Teh", "Enhong Chen"], "title": "Foundation of Intelligence: Review of Math Word Problems from Human Cognition Perspective", "comment": null, "summary": "Math word problem (MWP) serves as a fundamental research topic in artificial\nintelligence (AI) dating back to 1960s. This research aims to advance the\nreasoning abilities of AI by mirroring the human-like cognitive intelligence.\nThe mainstream technological paradigm has evolved from the early rule-based\nmethods, to deep learning models, and is rapidly advancing towards large\nlanguage models. However, the field still lacks a systematic taxonomy for the\nMWP survey along with a discussion of current development trends. Therefore, in\nthis paper, we aim to comprehensively review related research in MWP solving\nthrough the lens of human cognition, to demonstrate how recent AI models are\nadvancing in simulating human cognitive abilities. Specifically, we summarize 5\ncrucial cognitive abilities for MWP solving, including Problem Understanding,\nLogical Organization, Associative Memory, Critical Thinking, and Knowledge\nLearning. Focused on these abilities, we review two mainstream MWP models in\nrecent 10 years: neural network solvers, and LLM based solvers, and discuss the\ncore human-like abilities they demonstrated in their intricate problem-solving\nprocess. Moreover, we rerun all the representative MWP solvers and supplement\ntheir performance on 5 mainstream benchmarks for a unified comparison. To the\nbest of our knowledge, this survey first comprehensively analyzes the\ninfluential MWP research of the past decade from the perspective of human\nreasoning cognition and provides an integrative overall comparison across\nexisting approaches. We hope it can inspire further research in AI reasoning.\nOur repository is released on https://github.com/Ljyustc/FoI-MWP.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u56de\u987e\u4e86\u8fc7\u53bb\u5341\u5e74\u6709\u5f71\u54cd\u529b\u7684\u6570\u5b66\u6587\u5b57\u9898\uff08MWP\uff09\u7814\u7a76\uff0c\u91cd\u70b9\u5173\u6ce8\u4eba\u7c7b\u63a8\u7406\u8ba4\u77e5\uff0c\u5e76\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u7efc\u5408\u6bd4\u8f83\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u6a21\u62df\u7c7b\u4eba\u8ba4\u77e5\u80fd\u529b\u6765\u63d0\u5347AI\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u8be5\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u7684MWP\u8c03\u67e5\u5206\u7c7b\u4ee5\u53ca\u5bf9\u5f53\u524d\u53d1\u5c55\u8d8b\u52bf\u7684\u8ba8\u8bba\u3002", "method": "\u901a\u8fc7\u4eba\u7c7b\u8ba4\u77e5\u7684\u89c6\u89d2\uff0c\u603b\u7ed3\u4e86MWP\u6c42\u89e3\u76845\u4e2a\u5173\u952e\u8ba4\u77e5\u80fd\u529b\uff0c\u5305\u62ec\u95ee\u9898\u7406\u89e3\u3001\u903b\u8f91\u7ec4\u7ec7\u3001\u8054\u60f3\u8bb0\u5fc6\u3001\u6279\u5224\u6027\u601d\u7ef4\u548c\u77e5\u8bc6\u5b66\u4e60\u3002\u91cd\u70b9\u5173\u6ce8\u8fd9\u4e9b\u80fd\u529b\uff0c\u56de\u987e\u4e86\u8fd110\u5e74\u7684\u4e24\u79cd\u4e3b\u6d41MWP\u6a21\u578b\uff1a\u795e\u7ecf\u7f51\u7edc\u6c42\u89e3\u5668\u548c\u57fa\u4e8eLLM\u7684\u6c42\u89e3\u5668\u3002", "result": "\u91cd\u65b0\u8fd0\u884c\u4e86\u6240\u6709\u4ee3\u8868\u6027\u7684MWP\u6c42\u89e3\u5668\uff0c\u5e76\u8865\u5145\u4e86\u5b83\u4eec\u57285\u4e2a\u4e3b\u6d41\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u6027\u80fd\uff0c\u4ee5\u8fdb\u884c\u7edf\u4e00\u6bd4\u8f83\u3002", "conclusion": "\u9996\u6b21\u4ece\u4eba\u7c7b\u63a8\u7406\u8ba4\u77e5\u7684\u89d2\u5ea6\u5168\u9762\u5206\u6790\u4e86\u8fc7\u53bb\u5341\u5e74\u6709\u5f71\u54cd\u529b\u7684MWP\u7814\u7a76\uff0c\u5e76\u5bf9\u73b0\u6709\u65b9\u6cd5\u8fdb\u884c\u4e86\u7efc\u5408\u6bd4\u8f83\u3002"}}
{"id": "2510.21804", "categories": ["cs.LG", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2510.21804", "abs": "https://arxiv.org/abs/2510.21804", "authors": ["Shilaj Baral", "Youngkyu Lee", "Sangam Khanal", "Joongoo Jeon"], "title": "Residual-guided AI-CFD hybrid method enables stable and scalable simulations: from 2D benchmarks to 3D applications", "comment": null, "summary": "Purely data-driven surrogates for fluid dynamics often fail catastrophically\nfrom error accumulation, while existing hybrid methods have lacked the\nautomation and robustness for practical use. To solve this, we developed\nXRePIT, a novel hybrid simulation strategy that synergizes machine learning\n(ML) acceleration with solver-based correction. We specifically designed our\nmethod to be fully automated and physics-aware, ensuring the stability and\npractical applicability that previous approaches lacked. We demonstrate that\nthis new design overcomes long-standing barriers, achieving the first stable,\naccelerated rollouts for over 10,000 timesteps. The method also generalizes\nrobustly to unseen boundary conditions and, crucially, scales to 3D flows. Our\napproach delivers speedups up to 4.98$\\times$ while maintaining high physical\nfidelity, resolving thermal fields with relative errors of ~1E-3 and capturing\nlow magnitude velocity dynamics with errors below 1E-2 ms-1. This work thus\nestablishes a mature and scalable hybrid method, paving the way for its use in\nreal-world engineering.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df7\u5408\u4eff\u771f\u7b56\u7565XRePIT\uff0c\u5b83\u5c06\u673a\u5668\u5b66\u4e60\u52a0\u901f\u4e0e\u57fa\u4e8e\u6c42\u89e3\u5668\u7684\u6821\u6b63\u76f8\u7ed3\u5408\u3002", "motivation": "\u73b0\u6709\u7684\u6df7\u5408\u65b9\u6cd5\u7f3a\u4e4f\u81ea\u52a8\u5316\u548c\u9c81\u68d2\u6027\uff0c\u65e0\u6cd5\u5b9e\u9645\u5e94\u7528\u3002\u7eaf\u7cb9\u7684\u6570\u636e\u9a71\u52a8\u7684\u6d41\u4f53\u52a8\u529b\u5b66\u66ff\u4ee3\u65b9\u6cd5\u7ecf\u5e38\u56e0\u8bef\u5dee\u7d2f\u79ef\u800c\u5f7b\u5e95\u5931\u8d25\u3002", "method": "\u8be5\u65b9\u6cd5\u88ab\u4e13\u95e8\u8bbe\u8ba1\u4e3a\u5b8c\u5168\u81ea\u52a8\u5316\u548c\u7269\u7406\u611f\u77e5\uff0c\u786e\u4fdd\u4e86\u4ee5\u524d\u7684\u65b9\u6cd5\u6240\u7f3a\u4e4f\u7684\u7a33\u5b9a\u6027\u548c\u5b9e\u9645\u9002\u7528\u6027\u3002", "result": "\u8be5\u8bbe\u8ba1\u514b\u670d\u4e86\u957f\u671f\u5b58\u5728\u7684\u969c\u788d\uff0c\u9996\u6b21\u5b9e\u73b0\u4e86\u8d85\u8fc710,000\u4e2a\u65f6\u95f4\u6b65\u957f\u7684\u7a33\u5b9a\u52a0\u901f\u63a8\u5e7f\u3002\u8be5\u65b9\u6cd5\u8fd8\u80fd\u7a33\u5065\u5730\u63a8\u5e7f\u5230\u672a\u77e5\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u5e76\u4e14\u53ef\u4ee5\u6269\u5c55\u52303D\u6d41\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u9ad8\u8fbe4.98\u500d\u7684\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u7269\u7406\u4fdd\u771f\u5ea6\uff0c\u4ee5~1E-3\u7684\u76f8\u5bf9\u8bef\u5dee\u89e3\u6790\u70ed\u573a\uff0c\u5e76\u4ee5\u4f4e\u4e8e1E-2 ms-1\u7684\u8bef\u5dee\u6355\u83b7\u4f4e\u5e45\u5ea6\u901f\u5ea6\u52a8\u6001\u3002"}}
{"id": "2510.21812", "categories": ["cs.IR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21812", "abs": "https://arxiv.org/abs/2510.21812", "authors": ["Chanyoung Chung", "Kyeongryul Lee", "Sunbin Park", "Joyce Jiyoung Whang"], "title": "Unifying Inductive, Cross-Domain, and Multimodal Learning for Robust and Generalizable Recommendation", "comment": "7 pages, 3 figures, and 4 tables. International Workshop on\n  Multimodal Generative Search and Recommendation (MMGenSR) at The 34th ACM\n  International Conference on Information and Knowledge Management (CIKM 2025)", "summary": "Recommender systems have long been built upon the modeling of interactions\nbetween users and items, while recent studies have sought to broaden this\nparadigm by generalizing to new users and items, incorporating diverse\ninformation sources, and transferring knowledge across domains. Nevertheless,\nthese efforts have largely focused on individual aspects, hindering their\nability to tackle the complex recommendation scenarios that arise in daily\nconsumptions across diverse domains. In this paper, we present MICRec, a\nunified framework that fuses inductive modeling, multimodal guidance, and\ncross-domain transfer to capture user contexts and latent preferences in\nheterogeneous and incomplete real-world data. Moving beyond the inductive\nbackbone of INMO, our model refines expressive representations through\nmodality-based aggregation and alleviates data sparsity by leveraging\noverlapping users as anchors across domains, thereby enabling robust and\ngeneralizable recommendation. Experiments show that MICRec outperforms 12\nbaselines, with notable gains in domains with limited training data.", "AI": {"tldr": "MICRec: A unified framework for recommendation that combines inductive modeling, multimodal guidance, and cross-domain transfer.", "motivation": "Existing recommendation systems struggle with complex scenarios across diverse domains due to their focus on individual aspects like new users/items, diverse information, or cross-domain transfer.", "method": "The paper presents MICRec, which fuses inductive modeling, multimodal guidance, and cross-domain transfer. It refines representations through modality-based aggregation and uses overlapping users as anchors across domains.", "result": "MICRec outperforms 12 baselines, especially in domains with limited data.", "conclusion": "MICRec enables robust and generalizable recommendation by capturing user contexts and latent preferences in heterogeneous and incomplete real-world data."}}
{"id": "2510.21958", "categories": ["cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.21958", "abs": "https://arxiv.org/abs/2510.21958", "authors": ["Harrison F. Stropkay", "Jiayi Chen", "Mohammad J. Latifi", "Daniel N. Rockmore", "Jeremy R. Manning"], "title": "A Stylometric Application of Large Language Models", "comment": "All code and data needed to reproduce the results in this paper are\n  available at https://github.com/ContextLab/llm-stylometry", "summary": "We show that large language models (LLMs) can be used to distinguish the\nwritings of different authors. Specifically, an individual GPT-2 model, trained\nfrom scratch on the works of one author, will predict held-out text from that\nauthor more accurately than held-out text from other authors. We suggest that,\nin this way, a model trained on one author's works embodies the unique writing\nstyle of that author. We first demonstrate our approach on books written by\neight different (known) authors. We also use this approach to confirm R. P.\nThompson's authorship of the well-studied 15th book of the Oz series,\noriginally attributed to F. L. Baum.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u4ee5\u533a\u5206\u4e0d\u540c\u4f5c\u8005\u7684\u5199\u4f5c\u98ce\u683c\u3002", "motivation": "\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u6355\u6349\u5e76\u533a\u5206\u4e0d\u540c\u4f5c\u8005\u7684\u5199\u4f5c\u98ce\u683c\u3002", "method": "\u8bad\u7ec3\u72ec\u7acb\u7684GPT-2\u6a21\u578b\uff0c\u6bcf\u4e2a\u6a21\u578b\u57fa\u4e8e\u4e00\u4f4d\u4f5c\u8005\u7684\u4f5c\u54c1\u8fdb\u884c\u8bad\u7ec3\uff0c\u7136\u540e\u6bd4\u8f83\u6a21\u578b\u9884\u6d4b\u8be5\u4f5c\u8005\u548c\u5176\u4ed6\u4f5c\u8005\u6587\u672c\u7684\u51c6\u786e\u7387\u3002", "result": "\u9488\u5bf9\u4e00\u4f4d\u4f5c\u8005\u8bad\u7ec3\u7684\u6a21\u578b\u80fd\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u8be5\u4f5c\u8005\u7684\u6587\u672c\u3002", "conclusion": "\u6a21\u578b\u80fd\u591f\u6355\u6349\u5230\u4f5c\u8005\u72ec\u7279\u7684\u5199\u4f5c\u98ce\u683c\u3002\u901a\u8fc7\u6b64\u65b9\u6cd5\uff0c\u8bc1\u5b9e\u4e86R. P. Thompson\u662fOz\u7cfb\u5217\u7b2c15\u672c\u4e66\u7684\u4f5c\u8005\u3002"}}
{"id": "2510.21783", "categories": ["cs.CV", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2510.21783", "abs": "https://arxiv.org/abs/2510.21783", "authors": ["Guo Li", "Yuyang Yu", "Xuemiao Xu"], "title": "Noise Aggregation Analysis Driven by Small-Noise Injection: Efficient Membership Inference for Diffusion Models", "comment": null, "summary": "Diffusion models have demonstrated powerful performance in generating\nhigh-quality images. A typical example is text-to-image generator like Stable\nDiffusion. However, their widespread use also poses potential privacy risks. A\nkey concern is membership inference attacks, which attempt to determine whether\na particular data sample was used in the model training process. We propose an\nefficient membership inference attack method against diffusion models. This\nmethod is based on the injection of slight noise and the evaluation of the\naggregation degree of the noise distribution. The intuition is that the noise\nprediction patterns of diffusion models for training set samples and\nnon-training set samples exhibit distinguishable differences.Specifically, we\nsuppose that member images exhibit higher aggregation of predicted noise around\na certain time step of the diffusion process. In contrast, the predicted noises\nof non-member images exhibit a more discrete characteristic around the certain\ntime step. Compared with other existing methods, our proposed method requires\nfewer visits to the target diffusion model. We inject slight noise into the\nimage under test and then determine its membership by analyzing the aggregation\ndegree of the noise distribution predicted by the model. Empirical findings\nindicate that our method achieves superior performance across multiple\ndatasets. At the same time, our method can also show better attack effects in\nASR and AUC when facing large-scale text-to-image diffusion models, proving the\nscalability of our method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6269\u6563\u6a21\u578b\u7684\u6709\u6548\u6210\u5458\u63a8\u7406\u653b\u51fb\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u6ce8\u5165\u8f7b\u5fae\u566a\u58f0\u5e76\u8bc4\u4f30\u566a\u58f0\u5206\u5e03\u7684\u805a\u5408\u7a0b\u5ea6\u6765\u5224\u65ad\u6837\u672c\u662f\u5426\u4e3a\u8bad\u7ec3\u96c6\u6210\u5458\u3002", "motivation": "\u6269\u6563\u6a21\u578b\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u6f5c\u5728\u7684\u9690\u79c1\u98ce\u9669\uff0c\u6210\u5458\u63a8\u7406\u653b\u51fb\u8bd5\u56fe\u786e\u5b9a\u7279\u5b9a\u6570\u636e\u6837\u672c\u662f\u5426\u88ab\u7528\u4e8e\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u6ce8\u5165\u8f7b\u5fae\u566a\u58f0\uff0c\u5e76\u8bc4\u4f30\u566a\u58f0\u5206\u5e03\u7684\u805a\u5408\u7a0b\u5ea6\u3002 \u0447\u043b\u0435\u043d \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f\u5728\u6269\u6563\u8fc7\u7a0b\u7684\u67d0\u4e2a\u65f6\u95f4\u6b65\u957f\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u9884\u6d4b\u566a\u58f0\u805a\u5408\uff0c\u800c\u975e\u6210\u5458\u56fe\u50cf\u7684\u9884\u6d4b\u566a\u58f0\u5219\u8868\u73b0\u51fa\u66f4\u79bb\u6563\u7684\u7279\u5f81\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u9762\u5bf9\u5927\u578b\u6587\u672c\u5230\u56fe\u50cf\u6269\u6563\u6a21\u578b\u65f6\uff0c\u5728ASR\u548cAUC\u65b9\u9762\u4e5f\u8868\u73b0\u51fa\u66f4\u597d\u7684\u653b\u51fb\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u5730\u653b\u51fb\u6269\u6563\u6a21\u578b\u3002"}}
{"id": "2510.22009", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22009", "abs": "https://arxiv.org/abs/2510.22009", "authors": ["Yangqin Jiang", "Chao Huang"], "title": "LightAgent: Mobile Agentic Foundation Models", "comment": null, "summary": "With the advancement of multimodal large language models (MLLMs), building\nGUI agent systems has become an increasingly promising direction-especially for\nmobile platforms, given their rich app ecosystems and intuitive touch\ninteractions. Yet mobile GUI agents face a critical dilemma: truly on-device\nmodels (4B or smaller) lack sufficient performance, while capable models\n(starting from 7B) are either too large for mobile deployment or prohibitively\ncostly (e.g., cloud-only closed-source MLLMs). To resolve this, we propose\nLightAgent, a mobile agentic foundation model solution that leverages\ndevice-cloud collaboration to tap the cost-efficiency of on-device models and\nthe high capability of cloud models, while avoiding their drawbacks.\nSpecifically, LightAgent enhances Qwen2.5-VL-3B via two-stage SFT->GRPO\ntraining on synthetic GUI data for strong decision-making, integrates an\nefficient long-reasoning mechanism to utilize historical interactions under\ntight resources, and defaults to on-device execution-only escalating\nchallenging subtasks to the cloud via real-time complexity assessment.\nExperiments on the online AndroidLab benchmark and diverse apps show LightAgent\nmatches or nears larger models, with a significant reduction in cloud costs.", "AI": {"tldr": "LightAgent\u662f\u4e00\u4e2a\u79fb\u52a8\u4ee3\u7406\u57fa\u7840\u6a21\u578b\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u5229\u7528\u8bbe\u5907-\u4e91\u534f\u4f5c\u6765\u5229\u7528\u8bbe\u5907\u4e0a\u6a21\u578b\u7684\u6210\u672c\u6548\u76ca\u548c\u4e91\u6a21\u578b\u7684\u9ad8\u80fd\u529b\uff0c\u540c\u65f6\u907f\u514d\u5b83\u4eec\u7684\u7f3a\u70b9\u3002", "motivation": "\u79fb\u52a8GUI\u4ee3\u7406\u9762\u4e34\u4e00\u4e2a\u5173\u952e\u56f0\u5883\uff1a\u771f\u6b63\u7684\u8bbe\u5907\u4e0a\u6a21\u578b\uff084B\u6216\u66f4\u5c0f\uff09\u7f3a\u4e4f\u8db3\u591f\u7684\u6027\u80fd\uff0c\u800c\u6709\u80fd\u529b\u7684\u6a21\u578b\uff08\u4ece7B\u5f00\u59cb\uff09\u8981\u4e48\u592a\u5927\u800c\u65e0\u6cd5\u8fdb\u884c\u79fb\u52a8\u90e8\u7f72\uff0c\u8981\u4e48\u6210\u672c\u8fc7\u9ad8\uff08\u4f8b\u5982\uff0c\u4ec5\u9650\u4e91\u7684\u95ed\u6e90MLLM\uff09\u3002", "method": "LightAgent\u901a\u8fc7\u5728\u5408\u6210GUI\u6570\u636e\u4e0a\u8fdb\u884c\u4e24\u9636\u6bb5SFT->GRPO\u8bad\u7ec3\u6765\u589e\u5f3aQwen2.5-VL-3B\uff0c\u4ee5\u5b9e\u73b0\u5f3a\u5927\u7684\u51b3\u7b56\uff0c\u96c6\u6210\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u957f\u63a8\u7406\u673a\u5236\uff0c\u4ee5\u5728\u8d44\u6e90\u7d27\u5f20\u7684\u60c5\u51b5\u4e0b\u5229\u7528\u5386\u53f2\u4ea4\u4e92\uff0c\u5e76\u9ed8\u8ba4\u4e3a\u8bbe\u5907\u4e0a\u6267\u884c-\u4ec5\u901a\u8fc7\u5b9e\u65f6\u590d\u6742\u6027\u8bc4\u4f30\u5c06\u5177\u6709\u6311\u6218\u6027\u7684\u5b50\u4efb\u52a1\u5347\u7ea7\u5230\u4e91\u3002", "result": "\u5728\u5728\u7ebfAndroidLab\u57fa\u51c6\u548c\u5404\u79cd\u5e94\u7528\u7a0b\u5e8f\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLightAgent\u4e0e\u66f4\u5927\u7684\u6a21\u578b\u76f8\u5339\u914d\u6216\u63a5\u8fd1\uff0c\u540c\u65f6\u663e\u7740\u964d\u4f4e\u4e86\u4e91\u6210\u672c\u3002", "conclusion": "LightAgent\u662f\u4e00\u4e2a\u5f88\u6709\u524d\u9014\u7684\u79fb\u52a8\u4ee3\u7406\u57fa\u7840\u6a21\u578b\u89e3\u51b3\u65b9\u6848\uff0c\u5b83\u53ef\u4ee5\u5728\u5177\u6709\u6210\u672c\u6548\u76ca\u7684\u65b9\u5f0f\u4e0b\u5b9e\u73b0\u4e0e\u5927\u578b\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\u3002"}}
{"id": "2510.21819", "categories": ["cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.21819", "abs": "https://arxiv.org/abs/2510.21819", "authors": ["Marcelo Cerda Castillo"], "title": "Geographic Transferability of Machine Learning Models for Short-Term Airport Fog Forecasting", "comment": "21 pages, 8 tables, 2 figures. Uses publicly available ERA5 and METAR\n  datasets", "summary": "Short-term forecasting of airport fog (visibility < 1.0 km) presents\nchallenges in geographic generalization because many machine learning models\nrely on location-specific features and fail to transfer across sites. This\nstudy investigates whether fundamental thermodynamic and radiative processes\ncan be encoded in a coordinate-free (location-independent) feature set to\nenable geographic transferability. A gradient boosting classifier (XGBoost)\ntrained on Santiago, Chile (SCEL, 33S) data from 2002-2009 was evaluated on a\n2010-2012 holdout set and under strict zero-shot tests at Puerto Montt (SCTE),\nSan Francisco (KSFO), and London (EGLL). The model achieved AUC values of\n0.923-0.947 across distances up to 11,650 km and different fog regimes\n(radiative, advective, marine). Consistent SHAP feature rankings show that\nvisibility persistence, solar angle, and thermal gradients dominate\npredictions, suggesting the model learned transferable physical relationships\nrather than site-specific patterns. Results suggest that physics-informed,\ncoordinate-free feature engineering can yield geographically transferable\natmospheric forecasting tools.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u65e0\u9700\u5730\u7406\u5750\u6807\u7684\u96fe\u9884\u62a5\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u591f\u5728\u4e0d\u540c\u5730\u70b9\u4e4b\u95f4\u8fc1\u79fb\u3002", "motivation": "\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u6a21\u578b\u4f9d\u8d56\u4e8e\u7279\u5b9a\u4f4d\u7f6e\u7684\u7279\u5f81\uff0c\u5bfc\u81f4\u65e0\u6cd5\u8de8\u5730\u70b9\u5e94\u7528\u3002\u672c\u6587\u7814\u7a76\u4e86\u662f\u5426\u53ef\u4ee5\u5c06\u57fa\u672c\u7684\u70ed\u529b\u5b66\u548c\u8f90\u5c04\u8fc7\u7a0b\u7f16\u7801\u5230\u4e0e\u5750\u6807\u65e0\u5173\u7684\u7279\u5f81\u96c6\u4e2d\uff0c\u4ee5\u5b9e\u73b0\u5730\u7406\u4e0a\u7684\u53ef\u8fc1\u79fb\u6027\u3002", "method": "\u4f7f\u7528\u667a\u5229\u5723\u5730\u4e9a\u54e5\uff08SCEL\uff092002-2009\u5e74\u7684\u6570\u636e\u8bad\u7ec3\u4e86\u4e00\u4e2a\u68af\u5ea6\u63d0\u5347\u5206\u7c7b\u5668\uff08XGBoost\uff09\uff0c\u5e76\u57282010-2012\u5e74\u7684\u9884\u7559\u6570\u636e\u96c6\u4ee5\u53ca\u8499\u7279\u6e2f\uff08SCTE\uff09\u3001\u65e7\u91d1\u5c71\uff08KSFO\uff09\u548c\u4f26\u6566\uff08EGLL\uff09\u8fdb\u884c\u4e86\u4e25\u683c\u7684\u96f6\u6837\u672c\u6d4b\u8bd5\u3002", "result": "\u8be5\u6a21\u578b\u5728\u9ad8\u8fbe11,650\u516c\u91cc\u7684\u8ddd\u79bb\u548c\u4e0d\u540c\u7684\u96fe\u7c7b\u578b\uff08\u8f90\u5c04\u96fe\u3001\u5e73\u6d41\u96fe\u3001\u6d77\u6d0b\u96fe\uff09\u4e0b\uff0c\u5b9e\u73b0\u4e860.923-0.947\u7684AUC\u503c\u3002\u4e00\u81f4\u7684SHAP\u7279\u5f81\u6392\u5e8f\u8868\u660e\uff0c\u80fd\u89c1\u5ea6\u6301\u7eed\u6027\u3001\u592a\u9633\u89d2\u5ea6\u548c\u70ed\u68af\u5ea6\u4e3b\u5bfc\u4e86\u9884\u6d4b\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u4e14\u4e0e\u5750\u6807\u65e0\u5173\u7684\u7279\u5f81\u5de5\u7a0b\u53ef\u4ee5\u4ea7\u751f\u5177\u6709\u5730\u7406\u8fc1\u79fb\u6027\u7684\u5929\u6c14\u9884\u62a5\u5de5\u5177\u3002"}}
{"id": "2510.21831", "categories": ["cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.21831", "abs": "https://arxiv.org/abs/2510.21831", "authors": ["Alok Dutta", "Nilanjana Roy", "Rhythm Sen", "Sougata Dutta", "Prabhat Das"], "title": "Development of an Automated Web Application for Efficient Web Scraping: Design and Implementation", "comment": null, "summary": "This paper presents the design and implementation of a user-friendly,\nautomated web application that simplifies and optimizes the web scraping\nprocess for non-technical users. The application breaks down the complex task\nof web scraping into three main stages: fetching, extraction, and execution. In\nthe fetching stage, the application accesses target websites using the HTTP\nprotocol, leveraging the requests library to retrieve HTML content. The\nextraction stage utilizes powerful parsing libraries like BeautifulSoup and\nregular expressions to extract relevant data from the HTML. Finally, the\nexecution stage structures the data into accessible formats, such as CSV,\nensuring the scraped content is organized for easy use. To provide personalized\nand secure experiences, the application includes user registration and login\nfunctionalities, supported by MongoDB, which stores user data and scraping\nhistory. Deployed using the Flask framework, the tool offers a scalable, robust\nenvironment for web scraping. Users can easily input website URLs, define data\nextraction parameters, and download the data in a simplified format, without\nneeding technical expertise. This automated tool not only enhances the\nefficiency of web scraping but also democratizes access to data extraction by\nempowering users of all technical levels to gather and manage data tailored to\ntheir needs. The methodology detailed in this paper represents a significant\nadvancement in making web scraping tools accessible, efficient, and easy to use\nfor a broader audience.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u7528\u6237\u53cb\u597d\u7684\u81ea\u52a8\u5316Web\u5e94\u7528\u7a0b\u5e8f\uff0c\u65e8\u5728\u7b80\u5316\u548c\u4f18\u5316\u975e\u6280\u672f\u7528\u6237\u7684\u7f51\u7edc\u6293\u53d6\u8fc7\u7a0b\u3002", "motivation": "\u4e3a\u4e86\u7b80\u5316\u975e\u6280\u672f\u7528\u6237\u7684\u7f51\u7edc\u6293\u53d6\u8fc7\u7a0b\uff0c\u5e76\u4f7f\u66f4\u591a\u4eba\u80fd\u591f\u8bbf\u95ee\u6570\u636e\u63d0\u53d6\u3002", "method": "\u8be5\u5e94\u7528\u5c06\u7f51\u7edc\u6293\u53d6\u5206\u89e3\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a\u6293\u53d6\uff08\u4f7f\u7528requests\u5e93\u83b7\u53d6HTML\u5185\u5bb9\uff09\u3001\u63d0\u53d6\uff08\u4f7f\u7528BeautifulSoup\u548c\u6b63\u5219\u8868\u8fbe\u5f0f\u4eceHTML\u4e2d\u63d0\u53d6\u76f8\u5173\u6570\u636e\uff09\u548c\u6267\u884c\uff08\u5c06\u6570\u636e\u7ed3\u6784\u5316\u4e3aCSV\u7b49\u683c\u5f0f\uff09\u3002\u4f7f\u7528Flask\u6846\u67b6\u90e8\u7f72\uff0c\u5e76\u4f7f\u7528MongoDB\u652f\u6301\u7528\u6237\u6ce8\u518c\u3001\u767b\u5f55\u548c\u6570\u636e\u5b58\u50a8\u3002", "result": "\u8be5\u5de5\u5177\u63d0\u9ad8\u4e86\u7f51\u7edc\u6293\u53d6\u7684\u6548\u7387\uff0c\u5e76\u4f7f\u7528\u6237\u80fd\u591f\u8f7b\u677e\u5730\u8f93\u5165\u7f51\u5740\u3001\u5b9a\u4e49\u6570\u636e\u63d0\u53d6\u53c2\u6570\u5e76\u4ee5\u7b80\u5316\u683c\u5f0f\u4e0b\u8f7d\u6570\u636e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4f7f\u7f51\u7edc\u6293\u53d6\u5de5\u5177\u66f4\u6613\u4e8e\u8bbf\u95ee\u3001\u9ad8\u6548\u4e14\u6613\u4e8e\u4f7f\u7528\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002"}}
{"id": "2510.21983", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21983", "abs": "https://arxiv.org/abs/2510.21983", "authors": ["Havva Alizadeh Noughabi", "Julien Serbanescu", "Fattane Zarrinkalam", "Ali Dehghantanha"], "title": "Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks", "comment": null, "summary": "Despite recent advances, Large Language Models remain vulnerable to jailbreak\nattacks that bypass alignment safeguards and elicit harmful outputs. While\nprior research has proposed various attack strategies differing in human\nreadability and transferability, little attention has been paid to the\nlinguistic and psychological mechanisms that may influence a model's\nsusceptibility to such attacks. In this paper, we examine an interdisciplinary\nline of research that leverages foundational theories of persuasion from the\nsocial sciences to craft adversarial prompts capable of circumventing alignment\nconstraints in LLMs. Drawing on well-established persuasive strategies, we\nhypothesize that LLMs, having been trained on large-scale human-generated text,\nmay respond more compliantly to prompts with persuasive structures.\nFurthermore, we investigate whether LLMs themselves exhibit distinct persuasive\nfingerprints that emerge in their jailbreak responses. Empirical evaluations\nacross multiple aligned LLMs reveal that persuasion-aware prompts significantly\nbypass safeguards, demonstrating their potential to induce jailbreak behaviors.\nThis work underscores the importance of cross-disciplinary insight in\naddressing the evolving challenges of LLM safety. The code and data are\navailable.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u7814\u7a76\u5229\u7528\u793e\u4f1a\u79d1\u5b66\u7684\u529d\u8bf4\u7406\u8bba\u6765\u6784\u5efa\u5bf9\u6297\u6027\u63d0\u793a\uff0c\u4ee5\u7ed5\u8fc7LLM\u4e2d\u7684\u5bf9\u9f50\u7ea6\u675f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u8d8a\u72f1\u653b\u51fb\uff0c\u4f46\u4e4b\u524d\u7814\u7a76\u5f88\u5c11\u5173\u6ce8\u5f71\u54cd\u6a21\u578b\u5bf9\u6b64\u7c7b\u653b\u51fb\u7684\u8bed\u8a00\u548c\u5fc3\u7406\u673a\u5236\u3002\u672c\u6587\u7740\u773c\u4e8e\u5229\u7528\u793e\u4f1a\u79d1\u5b66\u7684\u529d\u8bf4\u7406\u8bba\u6765\u5236\u4f5c\u5bf9\u6297\u6027\u63d0\u793a\u3002", "method": "\u5229\u7528\u793e\u4f1a\u79d1\u5b66\u4e2d\u5df2\u5efa\u7acb\u7684\u529d\u8bf4\u7b56\u7565\uff0c\u6784\u5efa\u5177\u6709\u529d\u8bf4\u7ed3\u6784\u7684\u63d0\u793a\u3002", "result": "\u57fa\u4e8e\u529d\u8bf4\u7684\u63d0\u793a\u663e\u8457\u7ed5\u8fc7\u4e86\u5b89\u5168\u63aa\u65bd\uff0c\u8bc1\u660e\u4e86\u5b83\u4eec\u8bf1\u5bfc\u8d8a\u72f1\u884c\u4e3a\u7684\u6f5c\u529b\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u5f3a\u8c03\u4e86\u8de8\u5b66\u79d1\u89c1\u89e3\u5728\u5e94\u5bf9LLM\u5b89\u5168\u6311\u6218\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2510.21785", "categories": ["cs.CV", "cs.GR", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2510.21785", "abs": "https://arxiv.org/abs/2510.21785", "authors": ["Arun Muthukkumar"], "title": "Multi-Agent Pose Uncertainty: A Differentiable Rendering Cram\u00e9r-Rao Bound", "comment": "5 pages, 3 figures, 1 table. Presented at IEEE/CVF International\n  Conference on Computer Vision (ICCV 2025) and IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS 2025)", "summary": "Pose estimation is essential for many applications within computer vision and\nrobotics. Despite its uses, few works provide rigorous uncertainty\nquantification for poses under dense or learned models. We derive a closed-form\nlower bound on the covariance of camera pose estimates by treating a\ndifferentiable renderer as a measurement function. Linearizing image formation\nwith respect to a small pose perturbation on the manifold yields a render-aware\nCram\\'er-Rao bound. Our approach reduces to classical bundle-adjustment\nuncertainty, ensuring continuity with vision theory. It also naturally extends\nto multi-agent settings by fusing Fisher information across cameras. Our\nstatistical formulation has downstream applications for tasks such as\ncooperative perception and novel view synthesis without requiring explicit\nkeypoint correspondences.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\u534f\u65b9\u5dee\u7684\u95ed\u5f0f\u4e0b\u754c\u7b97\u6cd5\uff0c\u5c06\u53ef\u5fae\u6e32\u67d3\u5668\u89c6\u4e3a\u6d4b\u91cf\u51fd\u6570\uff0c\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u673a\u5668\u4eba\u6280\u672f\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u4e25\u8c28\u7684\u59ff\u6001\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u673a\u5668\u4eba\u6280\u672f\u4e2d\uff0c\u59ff\u6001\u4f30\u8ba1\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5f88\u5c11\u6709\u7814\u7a76\u5bf9\u5bc6\u96c6\u6216\u5b66\u4e60\u6a21\u578b\u4e0b\u7684\u59ff\u6001\u8fdb\u884c\u4e25\u683c\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u53ef\u5fae\u6e32\u67d3\u5668\u89c6\u4e3a\u6d4b\u91cf\u51fd\u6570\uff0c\u63a8\u5bfc\u51fa\u76f8\u673a\u59ff\u6001\u4f30\u8ba1\u534f\u65b9\u5dee\u7684\u95ed\u5f0f\u4e0b\u754c\u3002\u901a\u8fc7\u5728\u6d41\u5f62\u4e0a\u5bf9\u4e00\u4e2a\u5c0f\u7684\u59ff\u6001\u6270\u52a8\u7ebf\u6027\u5316\u56fe\u50cf\u5f62\u6210\u8fc7\u7a0b\uff0c\u5f97\u5230\u4e00\u4e2a\u6e32\u67d3\u611f\u77e5\u7684Cram\u00e9r-Rao bound\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u4ee5\u7b80\u5316\u4e3a\u7ecf\u5178\u7684\u6346\u7ed1\u8c03\u6574\u4e0d\u786e\u5b9a\u6027\uff0c\u786e\u4fdd\u4e86\u4e0e\u89c6\u89c9\u7406\u8bba\u7684\u8fde\u7eed\u6027\u3002\u901a\u8fc7\u878d\u5408\u4e0d\u540c\u76f8\u673a\u7684Fisher\u4fe1\u606f\uff0c\u81ea\u7136\u5730\u6269\u5c55\u5230\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u3002", "conclusion": "\u8be5\u7edf\u8ba1\u516c\u5f0f\u53ef\u7528\u4e8e\u8bf8\u5982\u534f\u540c\u611f\u77e5\u548c\u65b0\u89c6\u89d2\u5408\u6210\u7b49\u4e0b\u6e38\u4efb\u52a1\uff0c\u800c\u65e0\u9700\u663e\u5f0f\u7684\u5173\u952e\u70b9\u5bf9\u5e94\u3002"}}
{"id": "2510.22034", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.22034", "abs": "https://arxiv.org/abs/2510.22034", "authors": ["Rick Chen", "Joseph Ternasky", "Aaron Ontoyin Yin", "Xianling Mu", "Fuat Alican", "Yigit Ihlamur"], "title": "LLM-AR: LLM-powered Automated Reasoning Framework", "comment": null, "summary": "Large language models (LLMs) can already identify patterns and reason\neffectively, yet their variable accuracy hampers adoption in high-stakes\ndecision-making applications. In this paper, we study this issue from a venture\ncapital perspective by predicting idea-stage startup success based on founder\ntraits. (i) To build a reliable prediction model, we introduce LLM-AR, a\npipeline inspired by neural-symbolic systems that distils LLM-generated\nheuristics into probabilistic rules executed by the ProbLog automated-reasoning\nengine. (ii) An iterative policy-evolution loop incorporates association-rule\nmining to progressively refine the prediction rules.\n  On unseen folds, LLM-AR achieves 59.5% precision and 8.7% recall, 5.9x the\nrandom baseline precision, while exposing every decision path for human\ninspection. The framework is interpretable and tunable via hyperparameters,\nshowing promise to extend into other domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a LLM-AR \u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u521d\u521b\u516c\u53f8\u7684\u6210\u529f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u6a21\u5f0f\u548c\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u963b\u788d\u4e86\u5176\u5728\u9ad8\u98ce\u9669\u51b3\u7b56\u5e94\u7528\u4e2d\u7684\u5e94\u7528\u3002\u672c\u6587\u4ece\u98ce\u9669\u6295\u8d44\u7684\u89d2\u5ea6\u7814\u7a76\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u901a\u8fc7\u9884\u6d4b\u65e9\u671f\u521d\u521b\u516c\u53f8\u7684\u521b\u59cb\u4eba\u7279\u5f81\u6765\u9884\u6d4b\u5176\u6210\u529f\u3002", "method": "\u8be5\u6846\u67b6\u9996\u5148\u5c06 LLM \u751f\u6210\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u63d0\u70bc\u6210\u6982\u7387\u89c4\u5219\uff0c\u7136\u540e\u901a\u8fc7\u8fed\u4ee3\u7b56\u7565\u6f14\u5316\u5faa\u73af\uff0c\u7ed3\u5408\u5173\u8054\u89c4\u5219\u6316\u6398\u6765\u9010\u6b65\u5b8c\u5584\u9884\u6d4b\u89c4\u5219\u3002", "result": "LLM-AR \u5728\u672a\u89c1\u8fc7\u7684\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u4e86 59.5% \u7684\u7cbe\u786e\u7387\u548c 8.7% \u7684\u53ec\u56de\u7387\uff0c\u7cbe\u786e\u7387\u662f\u968f\u673a\u57fa\u7ebf\u7684 5.9 \u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u8c03\u6027\uff0c\u5e76\u6709\u5e0c\u671b\u6269\u5c55\u5230\u5176\u4ed6\u9886\u57df\u3002"}}
{"id": "2510.21820", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.21820", "abs": "https://arxiv.org/abs/2510.21820", "authors": ["Rekha R Nair", "Tina Babu", "Alavikunhu Panthakkan", "Hussain Al-Ahmad", "Balamurugan Balusamy"], "title": "Unlocking Biomedical Insights: Hierarchical Attention Networks for High-Dimensional Data Interpretation", "comment": null, "summary": "The proliferation of high-dimensional datasets in fields such as genomics,\nhealthcare, and finance has created an urgent need for machine learning models\nthat are both highly accurate and inherently interpretable. While traditional\ndeep learning approaches deliver strong predictive performance, their lack of\ntransparency often impedes their deployment in critical, decision-sensitive\napplications. In this work, we introduce the Hierarchical Attention-based\nInterpretable Network (HAIN), a novel architecture that unifies multi-level\nattention mechanisms, dimensionality reduction, and explanation-driven loss\nfunctions to deliver interpretable and robust analysis of complex biomedical\ndata. HAIN provides feature-level interpretability via gradientweighted\nattention and offers global model explanations through prototype-based\nrepresentations. Comprehensive evaluation on The Cancer Genome Atlas (TCGA)\ndataset demonstrates that HAIN achieves a classification accuracy of 94.3%,\nsurpassing conventional post-hoc interpretability approaches such as SHAP and\nLIME in both transparency and explanatory power. Furthermore, HAIN effectively\nidentifies biologically relevant cancer biomarkers, supporting its utility for\nclinical and research applications. By harmonizing predictive accuracy with\ninterpretability, HAIN advances the development of transparent AI solutions for\nprecision medicine and regulatory compliance.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u89e3\u91ca\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bHAIN\uff0c\u7528\u4e8e\u5206\u6790\u9ad8\u7ef4\u751f\u7269\u533b\u5b66\u6570\u636e\u3002", "motivation": "\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7f3a\u4e4f\u900f\u660e\u5ea6\uff0c\u963b\u788d\u4e86\u5176\u5728\u5173\u952e\u51b3\u7b56\u5e94\u7528\u4e2d\u7684\u90e8\u7f72\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u3002", "method": "HAIN\u7edf\u4e00\u4e86\u591a\u5c42\u6b21\u6ce8\u610f\u529b\u673a\u5236\u3001\u964d\u7ef4\u548c\u89e3\u91ca\u9a71\u52a8\u7684\u635f\u5931\u51fd\u6570\u3002", "result": "\u5728TCGA\u6570\u636e\u96c6\u4e0a\uff0cHAIN\u7684\u5206\u7c7b\u7cbe\u5ea6\u8fbe\u523094.3%\uff0c\u8d85\u8fc7\u4e86\u4f20\u7edf\u7684\u4e8b\u540e\u53ef\u89e3\u91ca\u6027\u65b9\u6cd5\uff0c\u5e76\u4e14\u6709\u6548\u8bc6\u522b\u4e86\u751f\u7269\u76f8\u5173\u7684\u764c\u75c7\u751f\u7269\u6807\u5fd7\u7269\u3002", "conclusion": "HAIN\u901a\u8fc7\u534f\u8c03\u9884\u6d4b\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u63a8\u52a8\u4e86\u7528\u4e8e\u7cbe\u51c6\u533b\u7597\u548c\u6cd5\u89c4\u9075\u4ece\u7684\u900f\u660eAI\u89e3\u51b3\u65b9\u6848\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.21962", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2510.21962", "abs": "https://arxiv.org/abs/2510.21962", "authors": ["Yunsen Lei", "Kexin Bai", "Quan Li", "H. Howie Huang"], "title": "Temporal Graph Theoretic Analysis of Geopolitical Dynamics in the U.S. Entity List", "comment": "13 pages, 9 figures. Under review", "summary": "Export controls have become one of America's most prominent tools of economic\nstatecraft. They aim to block rival countries' access to sensitive\ntechnologies, safeguard U.S. supply chains, protect national security, and\nshape geopolitical competition. Among various instruments, the U.S. Entity List\nhas emerged as the most salient, yet its dynamics remain underexplored. This\npaper introduces a novel temporal graph framework that transforms the Entity\nList documents from a static registry of foreign entities of concern into a\ndynamic representation of geopolitical strategy. We construct the first\nevent-based dataset of U.S. government foreign entity designations and model\nthem as a temporal bipartite graph. Building on this representation, we develop\na multi-level analytical approach that reveals shifting roles, enforcement\nstrategy, and broader sanction ecosystems. Applied to 25 years of data, the\nframework uncovers dynamic patterns of escalation, persistence, and\ncoordination that static views cannot capture. More broadly, our study\ndemonstrates how temporal graph analysis offers systematic computational\ninsights into the geopolitical dynamics of export controls.", "AI": {"tldr": "\u7f8e\u56fd\u51fa\u53e3\u7ba1\u5236\u662f\u91cd\u8981\u7684\u7ecf\u6d4e\u624b\u6bb5\uff0c\u5b9e\u4f53\u6e05\u5355\u662f\u5176\u4e2d\u6700\u7a81\u51fa\u7684\u5de5\u5177\uff0c\u4f46\u5176\u52a8\u6001\u6027\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "motivation": "\u7814\u7a76\u5b9e\u4f53\u6e05\u5355\u7684\u52a8\u6001\u6027\uff0c\u63ed\u793a\u5176\u80cc\u540e\u7684\u5730\u7f18\u653f\u6cbb\u6218\u7565\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u65f6\u95f4\u56fe\u6846\u67b6\uff0c\u5c06\u5b9e\u4f53\u6e05\u5355\u6587\u4ef6\u4ece\u9759\u6001\u6ce8\u518c\u8868\u8f6c\u6362\u4e3a\u5730\u7f18\u653f\u6cbb\u6218\u7565\u7684\u52a8\u6001\u8868\u793a\u3002\u521b\u5efa\u4e86\u7f8e\u56fd\u653f\u5e9c\u5916\u56fd\u5b9e\u4f53\u6307\u5b9a\u4e8b\u4ef6\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5c06\u5176\u5efa\u6a21\u4e3a\u65f6\u95f4\u4e8c\u5206\u56fe\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u591a\u5c42\u6b21\u5206\u6790\u65b9\u6cd5\u3002", "result": "\u63ed\u793a\u4e86\u9759\u6001\u89c6\u89d2\u65e0\u6cd5\u6355\u6349\u7684\u5347\u7ea7\u3001\u6301\u4e45\u6027\u548c\u534f\u8c03\u7684\u52a8\u6001\u6a21\u5f0f\u3002", "conclusion": "\u65f6\u95f4\u56fe\u5206\u6790\u4e3a\u7cfb\u7edf\u8ba1\u7b97\u5730\u7f18\u653f\u6cbb\u51fa\u53e3\u7ba1\u5236\u52a8\u6001\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2510.22014", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.22014", "abs": "https://arxiv.org/abs/2510.22014", "authors": ["Sarah Ball", "Niki Hasrati", "Alexander Robey", "Avi Schwarzschild", "Frauke Kreuter", "Zico Kolter", "Andrej Risteski"], "title": "Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models", "comment": null, "summary": "Discrete optimization-based jailbreaking attacks on large language models aim\nto generate short, nonsensical suffixes that, when appended onto input prompts,\nelicit disallowed content. Notably, these suffixes are often transferable --\nsucceeding on prompts and models for which they were never optimized. And yet,\ndespite the fact that transferability is surprising and empirically\nwell-established, the field lacks a rigorous analysis of when and why transfer\noccurs. To fill this gap, we identify three statistical properties that\nstrongly correlate with transfer success across numerous experimental settings:\n(1) how much a prompt without a suffix activates a model's internal refusal\ndirection, (2) how strongly a suffix induces a push away from this direction,\nand (3) how large these shifts are in directions orthogonal to refusal. On the\nother hand, we find that prompt semantic similarity only weakly correlates with\ntransfer success. These findings lead to a more fine-grained understanding of\ntransferability, which we use in interventional experiments to showcase how our\nstatistical analysis can translate into practical improvements in attack\nsuccess.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u79bb\u6563\u4f18\u5316\u7684jailbreak\u653b\u51fb\uff0c\u8fd9\u79cd\u653b\u51fb\u901a\u8fc7\u5728\u8f93\u5165\u63d0\u793a\u540e\u6dfb\u52a0\u7b80\u77ed\u3001\u65e0\u610f\u4e49\u7684\u540e\u7f00\u6765\u5f15\u8bf1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e0d\u5141\u8bb8\u7684\u5185\u5bb9\u3002\u8fd9\u4e9b\u540e\u7f00\u901a\u5e38\u5177\u6709\u53ef\u8f6c\u79fb\u6027\uff0c\u5373\u5728\u672a\u4f18\u5316\u7684\u63d0\u793a\u548c\u6a21\u578b\u4e0a\u4e5f\u80fd\u6210\u529f\u3002\u8bba\u6587\u65e8\u5728\u5206\u6790\u53ef\u8f6c\u79fb\u6027\u53d1\u751f\u7684\u539f\u56e0\u548c\u6761\u4ef6\u3002", "motivation": "\u76ee\u524d\u5bf9jailbreak\u653b\u51fb\u7684\u53ef\u8f6c\u79fb\u6027\u7f3a\u4e4f\u4e25\u8c28\u7684\u5206\u6790\uff0c\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u6587\u65e8\u5728\u7814\u7a76jailbreak\u653b\u51fb\u53ef\u8f6c\u79fb\u6027\u53d1\u751f\u7684\u539f\u56e0\u548c\u6761\u4ef6\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u786e\u5b9a\u4e86\u4e09\u4e2a\u4e0e\u8de8\u591a\u4e2a\u5b9e\u9a8c\u8bbe\u7f6e\u7684\u8f6c\u79fb\u6210\u529f\u5bc6\u5207\u76f8\u5173\u7684\u7edf\u8ba1\u5c5e\u6027\uff1a(1) \u6ca1\u6709\u540e\u7f00\u7684\u63d0\u793a\u6fc0\u6d3b\u6a21\u578b\u5185\u90e8\u62d2\u7edd\u65b9\u5411\u7684\u7a0b\u5ea6\uff0c(2) \u540e\u7f00\u5f15\u8d77\u591a\u5927\u7a0b\u5ea6\u7684\u8fdc\u79bb\u8fd9\u4e2a\u65b9\u5411\u7684\u63a8\u52a8\uff0c(3) \u8fd9\u4e9b\u8f6c\u79fb\u5728\u6b63\u4ea4\u4e8e\u62d2\u7edd\u65b9\u5411\u7684\u65b9\u5411\u4e0a\u6709\u591a\u5927\u3002", "result": "\u63d0\u793a\u8bed\u4e49\u76f8\u4f3c\u6027\u4e0e\u8f6c\u79fb\u6210\u529f\u7684\u76f8\u5173\u6027\u8f83\u5f31\u3002\u8fd9\u4e9b\u53d1\u73b0\u4f7f\u5f97\u53ef\u4ee5\u66f4\u7ec6\u81f4\u5730\u7406\u89e3\u53ef\u8f6c\u79fb\u6027\u3002", "conclusion": "\u5bf9\u53ef\u8f6c\u79fb\u6027\u7684\u7ec6\u7c92\u5ea6\u7406\u89e3\u53ef\u4ee5\u8f6c\u5316\u4e3a\u653b\u51fb\u6210\u529f\u7684\u5b9e\u9645\u6539\u8fdb\uff0c\u5e76\u901a\u8fc7\u5e72\u9884\u5b9e\u9a8c\u5c55\u793a\u4e86\u8fd9\u4e00\u70b9\u3002"}}
{"id": "2510.21786", "categories": ["cs.CV", "cs.AI", "cs.MM", "I.2.10"], "pdf": "https://arxiv.org/pdf/2510.21786", "abs": "https://arxiv.org/abs/2510.21786", "authors": ["Qile Su", "Shoutai Zhu", "Shuai Zhang", "Baoyu Liang", "Chao Tong"], "title": "EventFormer: A Node-graph Hierarchical Attention Transformer for Action-centric Video Event Prediction", "comment": "15 pages, 7 figures, 6 tables", "summary": "Script event induction, which aims to predict the subsequent event based on\nthe context, is a challenging task in NLP, achieving remarkable success in\npractical applications. However, human events are mostly recorded and presented\nin the form of videos rather than scripts, yet there is a lack of related\nresearch in the realm of vision. To address this problem, we introduce AVEP\n(Action-centric Video Event Prediction), a task that distinguishes itself from\nexisting video prediction tasks through its incorporation of more complex logic\nand richer semantic information. We present a large structured dataset, which\nconsists of about $35K$ annotated videos and more than $178K$ video clips of\nevent, built upon existing video event datasets to support this task. The\ndataset offers more fine-grained annotations, where the atomic unit is\nrepresented as a multimodal event argument node, providing better structured\nrepresentations of video events. Due to the complexity of event structures,\ntraditional visual models that take patches or frames as input are not\nwell-suited for AVEP. We propose EventFormer, a node-graph hierarchical\nattention based video event prediction model, which can capture both the\nrelationships between events and their arguments and the coreferencial\nrelationships between arguments. We conducted experiments using several SOTA\nvideo prediction models as well as LVLMs on AVEP, demonstrating both the\ncomplexity of the task and the value of the dataset. Our approach outperforms\nall these video prediction models. We will release the dataset and code for\nreplicating the experiments and annotations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAVEP\uff08Action-centric Video Event Prediction\uff09\u7684\u65b0\u4efb\u52a1\uff0c\u65e8\u5728\u9884\u6d4b\u89c6\u9891\u4e2d\u540e\u7eed\u4e8b\u4ef6\uff0c\u5e76\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u578b\u7ed3\u6784\u5316\u6570\u636e\u96c6\u6765\u652f\u6301\u8be5\u4efb\u52a1\u3002\u540c\u65f6\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8282\u70b9\u56fe\u5206\u5c42\u6ce8\u610f\u529b\u7684\u89c6\u9891\u4e8b\u4ef6\u9884\u6d4b\u6a21\u578bEventFormer\uff0c\u5e76\u5728AVEP\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u8bc1\u660e\u4e86\u8be5\u4efb\u52a1\u7684\u590d\u6742\u6027\u548c\u6570\u636e\u96c6\u7684\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u7684\u4e8b\u4ef6\u9884\u6d4b\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u6587\u672c\u811a\u672c\u4e0a\uff0c\u800c\u5ffd\u7565\u4e86\u89c6\u9891\u4e2d\u4e8b\u4ef6\u9884\u6d4b\u7684\u91cd\u8981\u6027\u3002\u4e3a\u4e86\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u672c\u6587\u63d0\u51fa\u4e86AVEP\u4efb\u52a1\uff0c\u65e8\u5728\u7814\u7a76\u89c6\u9891\u4e2d\u7684\u4e8b\u4ef6\u9884\u6d4b\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u7ea63.5\u4e07\u4e2a\u5e26\u6ce8\u91ca\u89c6\u9891\u548c\u8d85\u8fc717.8\u4e07\u4e2a\u89c6\u9891\u7247\u6bb5\u7684\u5927\u578b\u7ed3\u6784\u5316\u6570\u636e\u96c6\u3002\u6b64\u5916\uff0c\u672c\u6587\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8282\u70b9\u56fe\u5206\u5c42\u6ce8\u610f\u529b\u7684\u89c6\u9891\u4e8b\u4ef6\u9884\u6d4b\u6a21\u578bEventFormer\uff0c\u8be5\u6a21\u578b\u80fd\u591f\u6355\u83b7\u4e8b\u4ef6\u53ca\u5176\u53c2\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4ee5\u53ca\u53c2\u6570\u4e4b\u95f4\u7684\u5171\u6307\u5173\u7cfb\u3002", "result": "\u5728AVEP\u6570\u636e\u96c6\u4e0a\uff0cEventFormer\u6a21\u578b\u4f18\u4e8e\u6240\u6709\u73b0\u6709\u7684\u89c6\u9891\u9884\u6d4b\u6a21\u578b\u548c\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684AVEP\u4efb\u52a1\u548cEventFormer\u6a21\u578b\u4e3a\u89c6\u9891\u4e8b\u4ef6\u9884\u6d4b\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u548c\u65b9\u6cd5\u3002"}}
{"id": "2510.22039", "categories": ["cs.AI", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.22039", "abs": "https://arxiv.org/abs/2510.22039", "authors": ["Po-Chen Kuo", "Han Hou", "Will Dabney", "Edgar Y. Walker"], "title": "Predictive Coding Enhances Meta-RL To Achieve Interpretable Bayes-Optimal Belief Representation Under Partial Observability", "comment": "Accepted to Annual Conference on Neural Information Processing\n  Systems (NeurIPS) 2025", "summary": "Learning a compact representation of history is critical for planning and\ngeneralization in partially observable environments. While meta-reinforcement\nlearning (RL) agents can attain near Bayes-optimal policies, they often fail to\nlearn the compact, interpretable Bayes-optimal belief states. This\nrepresentational inefficiency potentially limits the agent's adaptability and\ngeneralization capacity. Inspired by predictive coding in neuroscience--which\nsuggests that the brain predicts sensory inputs as a neural implementation of\nBayesian inference--and by auxiliary predictive objectives in deep RL, we\ninvestigate whether integrating self-supervised predictive coding modules into\nmeta-RL can facilitate learning of Bayes-optimal representations. Through state\nmachine simulation, we show that meta-RL with predictive modules consistently\ngenerates more interpretable representations that better approximate\nBayes-optimal belief states compared to conventional meta-RL across a wide\nvariety of tasks, even when both achieve optimal policies. In challenging tasks\nrequiring active information seeking, only meta-RL with predictive modules\nsuccessfully learns optimal representations and policies, whereas conventional\nmeta-RL struggles with inadequate representation learning. Finally, we\ndemonstrate that better representation learning leads to improved\ngeneralization. Our results strongly suggest the role of predictive learning as\na guiding principle for effective representation learning in agents navigating\npartial observability.", "AI": {"tldr": "\u5143\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u96be\u4ee5\u5b66\u4e60\u5230\u7d27\u51d1\u3001\u53ef\u89e3\u91ca\u7684\u8d1d\u53f6\u65af\u6700\u4f18\u7f6e\u4fe1\u72b6\u6001\uff0c\u8fd9\u9650\u5236\u4e86\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u53d7\u795e\u7ecf\u79d1\u5b66\u4e2d\u9884\u6d4b\u7f16\u7801\u7684\u542f\u53d1\uff0c\u7814\u7a76\u6574\u5408\u81ea\u76d1\u7763\u9884\u6d4b\u7f16\u7801\u6a21\u5757\u5230\u5143\u5f3a\u5316\u5b66\u4e60\u4e2d\u662f\u5426\u53ef\u4ee5\u4fc3\u8fdb\u5b66\u4e60\u8d1d\u53f6\u65af\u6700\u4f18\u8868\u793a\u3002", "method": "\u901a\u8fc7\u72b6\u6001\u673a\u6a21\u62df\uff0c\u5bf9\u6bd4\u4e86\u5e26\u6709\u9884\u6d4b\u6a21\u5757\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u548c\u4f20\u7edf\u5143\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5e26\u6709\u9884\u6d4b\u6a21\u5757\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u59cb\u7ec8\u751f\u6210\u66f4\u53ef\u89e3\u91ca\u7684\u8868\u793a\uff0c\u66f4\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u7f6e\u4fe1\u72b6\u6001\uff0c\u5e76\u4e14\u5728\u9700\u8981\u4e3b\u52a8\u4fe1\u606f\u5bfb\u6c42\u7684\u4efb\u52a1\u4e2d\uff0c\u53ea\u6709\u5e26\u6709\u9884\u6d4b\u6a21\u5757\u7684\u5143\u5f3a\u5316\u5b66\u4e60\u6210\u529f\u5b66\u4e60\u5230\u6700\u4f18\u8868\u793a\u548c\u7b56\u7565\u3002\u66f4\u597d\u7684\u8868\u793a\u5b66\u4e60\u5e26\u6765\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u9884\u6d4b\u5b66\u4e60\u53ef\u4ee5\u4f5c\u4e3a\u667a\u80fd\u4f53\u5728\u4e0d\u5b8c\u5168\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u8fdb\u884c\u6709\u6548\u8868\u793a\u5b66\u4e60\u7684\u6307\u5bfc\u539f\u5219\u3002"}}
