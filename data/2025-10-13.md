<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 17]
- [cs.CV](#cs.CV) [Total: 18]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IR](#cs.IR) [Total: 9]
- [cs.LG](#cs.LG) [Total: 20]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Biomedical Named Entity Recognition using GLiNER-BioMed with Targeted Dictionary-Based Post-processing for BioASQ 2025 task 6](https://arxiv.org/abs/2510.08588)
*Ritesh Mehta*

Main category: cs.CL

TL;DR: 本研究评估了GLiNER-BioMed模型在BioASQ数据集上的表现，并提出了一种基于字典的后处理策略来解决常见的错误分类问题。虽然该策略在开发集上有所改进，但在盲测集上效果不佳。


<details>
  <summary>Details</summary>
Motivation: 生物医学命名实体识别(BioNER)对于从科学文献中提取信息至关重要，但面临着区分基因和化学物质等相似实体类型的挑战。

Method: 本研究评估了GLiNER-BioMed模型，并引入了一种有针对性的、基于字典的后处理策略。

Result: 后处理方法在开发集上将micro F1-score从0.79提高到0.83，但在盲测集上，后处理模型的micro F1-score为0.77，低于基线的0.79。

Conclusion: 这项工作强调了基于字典的改进对预训练BioNER模型的潜力，但也强调了过度拟合开发数据的关键挑战，以及确保对现实世界适用性的稳健泛化的必要性。

Abstract: Biomedical Named Entity Recognition (BioNER), task6 in BioASQ (A challenge in
large-scale biomedical semantic indexing and question answering), is crucial
for extracting information from scientific literature but faces hurdles such as
distinguishing between similar entity types like genes and chemicals. This
study evaluates the GLiNER-BioMed model on a BioASQ dataset and introduces a
targeted dictionary-based post-processing strategy to address common
misclassifications. While this post-processing approach demonstrated notable
improvement on our development set, increasing the micro F1-score from a
baseline of 0.79 to 0.83, this enhancement did not generalize to the blind test
set, where the post-processed model achieved a micro F1-score of 0.77 compared
to the baselines 0.79. We also discuss insights gained from exploring
alternative methodologies, including Conditional Random Fields. This work
highlights the potential of dictionary-based refinement for pre-trained BioNER
models but underscores the critical challenge of overfitting to development
data and the necessity of ensuring robust generalization for real-world
applicability.

</details>


### [2] [Less Diverse, Less Safe: The Indirect But Pervasive Risk of Test-Time Scaling in Large Language Models](https://arxiv.org/abs/2510.08592)
*Shahriar Kabir Nahin,Hadi Askari,Muhao Chen,Anshuman Chhabra*

Main category: cs.CL

TL;DR: 论文揭示了测试时缩放(TTS)的一个新的失败模式：当候选答案的多样性降低时，TTS更容易产生不安全的结果。


<details>
  <summary>Details</summary>
Motivation: TTS依赖于候选答案的多样性来提高LLM推理的安全性，但论文指出多样性不足会导致不安全输出。

Method: 论文提出了一种参考引导的多样性降低协议(RefDiv)作为诊断攻击，用于压力测试TTS流程。

Result: 实验表明，降低多样性会显著提高TTS产生不安全结果的比率，且优于直接使用高对抗意图的prompt。现有的安全防护栏分类器无法有效识别RefDiv生成的对抗性输入。

Conclusion: 论文强调了TTS策略在多样性受限情况下的脆弱性，并呼吁未来研究设计更鲁棒的TTS策略，以应对多样性定向的压力测试。

Abstract: Test-Time Scaling (TTS) improves LLM reasoning by exploring multiple
candidate responses and then operating over this set to find the best output. A
tacit premise behind TTS is that sufficiently diverse candidate pools enhance
reliability. In this work, we show that this assumption in TTS introduces a
previously unrecognized failure mode. When candidate diversity is curtailed,
even by a modest amount, TTS becomes much more likely to produce unsafe
outputs. We present a reference-guided diversity reduction protocol (RefDiv)
that serves as a diagnostic attack to stress test TTS pipelines. Through
extensive experiments across four open-source models (Qwen3, Mistral, Llama3.1,
Gemma3) and two widely used TTS strategies (Monte Carlo Tree Search and
Best-of-N), constraining diversity consistently signifies the rate at which TTS
produces unsafe results. The effect is often stronger than that produced by
prompts directly with high adversarial intent scores. This observed phenomenon
also transfers across TTS strategies and to closed-source models (e.g. OpenAI
o3 and Gemini-2.5-Pro), thus indicating that this is a general and extant
property of TTS rather than a model-specific artifact. Additionally, we find
that numerous widely used safety guardrail classifiers (e.g. Llama-Guard and
OpenAI Moderation API), are unable to flag the adversarial input prompts
generated by RefDiv, demonstrating that existing defenses offer limited
protection against this diversity-driven failure mode. Through this work, we
hope to motivate future research on designing robust TTS strategies that are
both effective and secure against diversity-targeted stress tests as
illustrated by RefDiv.

</details>


### [3] [Hierarchical Self-Supervised Representation Learning for Depression Detection from Speech](https://arxiv.org/abs/2510.08593)
*Yuxin Li,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 本文提出了一种新的基于语音的抑郁症检测方法，该方法利用自监督学习模型的多层特征，并通过跨注意力机制和多任务学习框架进行整合，以捕捉稀疏和异构的抑郁线索。


<details>
  <summary>Details</summary>
Motivation: 现有的语音抑郁症检测方法难以提取有意义的特征，并且无法捕捉到随时间变化的稀疏和异构的抑郁线索。现有方法通常过度拟合特定数据集，并且无法利用检测细微和持续抑郁信号所需的完整分层结构。

Method: 提出了一种名为HAREN-CTC的新架构，该架构集成了多层SSL特征，使用多任务学习框架中的交叉注意力，并结合Connectionist Temporal Classification损失来处理稀疏时间监督。HAREN-CTC包括两个关键模块：一个分层自适应聚类模块，将SSL特征重组为互补嵌入；以及一个跨模态融合模块，通过交叉注意力对层间依赖关系进行建模。CTC目标实现了对齐感知训练，允许模型跟踪抑郁语音线索的不规则时间模式。

Result: 在标准数据分割的上界设置和使用五重交叉验证的泛化设置下评估HAREN-CTC。该模型在DAIC-WOZ上实现了0.81的state-of-the-art宏F1分数，在MODMA上实现了0.82的state-of-the-art宏F1分数，优于两种评估方案中的先前方法。

Conclusion: HAREN-CTC是一种有效的语音抑郁症检测方法，它能够利用自监督学习模型的多层特征，并通过跨注意力机制和多任务学习框架进行整合，以捕捉稀疏和异构的抑郁线索。

Abstract: Speech-based depression detection (SDD) is a promising, non-invasive
alternative to traditional clinical assessments. However, it remains limited by
the difficulty of extracting meaningful features and capturing sparse,
heterogeneous depressive cues over time. Pretrained self-supervised learning
(SSL) models such as WavLM provide rich, multi-layer speech representations,
yet most existing SDD methods rely only on the final layer or search for a
single best-performing one. These approaches often overfit to specific datasets
and fail to leverage the full hierarchical structure needed to detect subtle
and persistent depression signals.
  To address this challenge, we propose HAREN-CTC, a novel architecture that
integrates multi-layer SSL features using cross-attention within a multitask
learning framework, combined with Connectionist Temporal Classification loss to
handle sparse temporal supervision. HAREN-CTC comprises two key modules: a
Hierarchical Adaptive Clustering module that reorganizes SSL features into
complementary embeddings, and a Cross-Modal Fusion module that models
inter-layer dependencies through cross-attention. The CTC objective enables
alignment-aware training, allowing the model to track irregular temporal
patterns of depressive speech cues.
  We evaluate HAREN-CTC under both an upper-bound setting with standard data
splits and a generalization setting using five-fold cross-validation. The model
achieves state-of-the-art macro F1-scores of 0.81 on DAIC-WOZ and 0.82 on
MODMA, outperforming prior methods across both evaluation scenarios.

</details>


### [4] [Systematic Diagnosis of Brittle Reasoning in Large Language Models](https://arxiv.org/abs/2510.08595)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 提出了一种新的数学推理评估框架，通过分析模型在不同推理模式下的表现来诊断其弱点。


<details>
  <summary>Details</summary>
Motivation: 衡量机器学习模型对数学的理解程度。

Method: 利用 gpt-3.5-turbo 生成 GSM8K 数据集的逐步推理过程，并使用 gpt-4o-mini 对错误进行分类，对推理句子进行无监督聚类，识别“推理模式”。

Result: 模型在程序性模式（如顺序计算）上表现接近完美，但在需要组合推理的模式上表现不佳，揭示了一种非人类的脆弱性。

Conclusion: 该方法提供了一种更精细的数学理解评估方法，并为开发新能力和更可靠的未来应用提供了精确的路线图。

Abstract: A central question in artificial intelligence is the extent to which machine
learning models comprehend mathematics. To address this, we propose a novel
framework for measuring mathematical reasoning that moves beyond standard
benchmarks to diagnose specific failure points. Our method first generates
structured, step-by-step reasoning from gpt-3.5-turbo on the GSM8K dataset. We
then use a more capable analyst model, gpt-4o-mini, to categorize errors and,
crucially, perform an unsupervised clustering of every reasoning sentence to
identify emergent "reasoning modes." This analysis reveals a cognitive profile
with a stark, nonhuman-like brittleness: while the model achieves near-perfect
accuracy on procedural modes like sequential calculation, its performance on
modes requiring combinatorial reasoning with restrictions plummets. By
identifying and quantifying the reliability of these distinct reasoning skills,
our work provides a more granular method to evaluate mathematical comprehension
and offers a precise roadmap for developing new capabilities and more reliable
future applications.

</details>


### [5] [Confidence, Not Perplexity: A Better Metric for the Creative Era of LLMs](https://arxiv.org/abs/2510.08596)
*V. S. Raghu Parupudi*

Main category: cs.CL

TL;DR: 提出了置信度分数（CS），以解决现有无参考指标在评估创造性文本生成时存在的偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有的无参考指标（如自困惑度）在评估创造性文本生成时存在严重的偏差。

Method: 提出了置信度分数（CS），该分数源于模型的输出概率分布，作为一种偏差较小的替代方案。在 gpt-4o-mini 上进行了实验。

Result: 实验表明，基于流畅性的指标在 99 个创造性提示中，仅在 0% 的情况下偏爱新颖的响应，而 CS 在 19% 的情况下偏爱新颖的响应，差异具有统计学意义（95% CI 为 [11.1%, 27.3%]）。CS 还可以有效区分简单、中等和困难的任务。

Conclusion: 置信度分数缓解了传统指标的创造性偏差，同时保留了其核心评估优势，为现代大型语言模型提供了更平衡的评估。

Abstract: Reference-free metrics like self-perplexity are strongly biased against
creative text generation. We propose the Confidence Score (CS), derived from a
model's output probability distribution, as a less biased alternative.
Experiments on gpt-4o-mini show that while fluency-based metrics prefer novel
responses in 0\% of cases on 99 creative prompts, our CS does so 19% of the
time, a statistically significant difference (95% CI for difference: [11.1%,
27.3%]). We also show that CS effectively distinguishes between easy, medium,
and hard tasks, confirmed by non-overlapping confidence intervals. The
Confidence Score thus mitigates the creativity bias of traditional metrics
while retaining their core evaluative strengths, offering a more balanced
assessment for modern LLMs.

</details>


### [6] [Recover-LoRA: Data-Free Accuracy Recovery of Degraded Language Models via Low-Rank Adaptation](https://arxiv.org/abs/2510.08600)
*Devleena Das,Rajeev Patwari,Ashish Sirasao*

Main category: cs.CL

TL;DR: Recover-LoRA: A lightweight, dataset-agnostic method to recover accuracy in degraded language models using synthetic data and logit distillation to learn LoRA adapters.


<details>
  <summary>Details</summary>
Motivation: Model optimizations (quantization, pruning, etc.) and improper serialization can degrade language model performance.

Method: Recover-LoRA uses synthetic data and logit distillation to train LoRA adapters on selected layers, aligning the degraded model with the full-precision model.

Result: Recover-LoRA recovers model accuracies by 5-17% on multi-head attention (MHA) and group-query attention (GQA) small language models (SLMs).

Conclusion: Recover-LoRA effectively recovers accuracy in degraded SLMs with varying attention architectures.

Abstract: Inference optimizations such as quantization, pruning, format and datatype
conversion, model export, and serialization can lead to functional degradations
in language model task performance. While most efforts on performance recovery
for deployment focus on robust quantization techniques, we focus on recovering
model accuracies from any sources that degrade model weights, such as improper
model serialization. In this work, we propose Recover-LoRA, a lightweight and
dataset agnostic method to recover accuracy in degraded models. Recover-LoRA
uses synthetic data and logit distillation to learn LoRA adapters on selective
layers that facilitate aligning the degraded model to its full precision model.
We investigate the utility of Recover-LoRA across a diverse set of small
language models (SLMs), including models with varying attention architectures,
multi-head attention (MHA) and group-query attention (GQA), as well as several
evaluation datasets. Our results show that Recover-LoRA recovers model
accuracies by 5-17% on MHA and GQA SLMs.

</details>


### [7] [Mnemosyne: An Unsupervised, Human-Inspired Long-Term Memory Architecture for Edge-Based LLMs](https://arxiv.org/abs/2510.08601)
*Aneesh Jonelagadda,Christina Hahn,Haoze Zheng,Salvatore Penachio*

Main category: cs.CL

TL;DR: Mnemosyne is a human-inspired long-term memory architecture for edge-based LLMs, using graph storage, filters, and probabilistic recall.


<details>
  <summary>Details</summary>
Motivation: Current LLM memory systems are insufficient for realistic dialogue on edge devices due to reliance on context expansion or static retrieval.

Method: The paper introduces Mnemosyne, featuring graph-structured storage, modular filters, memory management, and probabilistic recall with temporal decay.

Result: Mnemosyne achieves a 65.8% win rate in human evaluations for realism and long-term memory, outperforms in LoCoMo benchmarks, and demonstrates improved factual recall and temporal reasoning.

Conclusion: Mnemosyne offers an edge-compatible, unsupervised memory architecture for enhanced dialogue and long-term memory capabilities in applications like healthcare assistants.

Abstract: Long-term memory is essential for natural, realistic dialogue. However,
current large language model (LLM) memory systems rely on either brute-force
context expansion or static retrieval pipelines that fail on edge-constrained
devices. We introduce Mnemosyne, an unsupervised, human-inspired long-term
memory architecture designed for edge-based LLMs. Our approach uses
graph-structured storage, modular substance and redundancy filters, memory
committing and pruning mechanisms, and probabilistic recall with temporal decay
and refresh processes modeled after human memory. Mnemosyne also introduces a
concentrated "core summary" efficiently derived from a fixed-length subset of
the memory graph to capture the user's personality and other domain-specific
long-term details such as, using healthcare application as an example,
post-recovery ambitions and attitude towards care. Unlike existing
retrieval-augmented methods, Mnemosyne is designed for use in longitudinal
healthcare assistants, where repetitive and semantically similar but temporally
distinct conversations are limited by naive retrieval. In experiments with
longitudinal healthcare dialogues, Mnemosyne demonstrates the highest win rate
of 65.8% in blind human evaluations of realism and long-term memory capability
compared to a baseline RAG win rate of 31.1%. Mnemosyne also achieves current
highest LoCoMo benchmark scores in temporal reasoning and single-hop retrieval
compared to other same-backboned techniques. Further, the average overall score
of 54.6% was second highest across all methods, beating commonly used Mem0 and
OpenAI baselines among others. This demonstrates that improved factual recall,
enhanced temporal reasoning, and much more natural user-facing responses can be
feasible with an edge-compatible and easily transferable unsupervised memory
architecture.

</details>


### [8] [Human Texts Are Outliers: Detecting LLM-generated Texts via Out-of-distribution Detection](https://arxiv.org/abs/2510.08602)
*Cong Zeng,Shengkun Tang,Yuanzhou Chen,Zhiqiang Shen,Wenchao Yu,Xujiang Zhao,Haifeng Chen,Wei Cheng,Zhiqiang Xu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的AI生成文本检测方法，将人类文本视为分布外的异常值，而机器生成的文本视为分布内的样本，从而提高检测的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成文本检测方法通常将该任务视为二元分类问题，导致跨领域和模型的泛化能力较差。这是因为人类文本不构成统一的分布，其多样性无法通过有限的抽样有效捕获。

Method: 该论文提出了一种基于单类学习（包括DeepSVDD和HRN）和基于分数的学习技术（如基于能量的方法）的检测框架，将人类文本视为分布外的异常值。

Result: 实验结果表明，该方法在多个数据集上都表现出良好的效果。例如，在DeepFake数据集上，该方法实现了98.3%的AUROC和AUPR，且FPR95仅为8.9%。

Conclusion: 该论文提出的基于OOD的检测框架具有鲁棒性和泛化能力，能够在多语言、攻击和未见模型和领域文本设置下有效检测AI生成的文本。

Abstract: The rapid advancement of large language models (LLMs) such as ChatGPT,
DeepSeek, and Claude has significantly increased the presence of AI-generated
text in digital communication. This trend has heightened the need for reliable
detection methods to distinguish between human-authored and machine-generated
content. Existing approaches both zero-shot methods and supervised classifiers
largely conceptualize this task as a binary classification problem, often
leading to poor generalization across domains and models. In this paper, we
argue that such a binary formulation fundamentally mischaracterizes the
detection task by assuming a coherent representation of human-written texts. In
reality, human texts do not constitute a unified distribution, and their
diversity cannot be effectively captured through limited sampling. This causes
previous classifiers to memorize observed OOD characteristics rather than learn
the essence of `non-ID' behavior, limiting generalization to unseen
human-authored inputs. Based on this observation, we propose reframing the
detection task as an out-of-distribution (OOD) detection problem, treating
human-written texts as distributional outliers while machine-generated texts
are in-distribution (ID) samples. To this end, we develop a detection framework
using one-class learning method including DeepSVDD and HRN, and score-based
learning techniques such as energy-based method, enabling robust and
generalizable performance. Extensive experiments across multiple datasets
validate the effectiveness of our OOD-based approach. Specifically, the
OOD-based method achieves 98.3% AUROC and AUPR with only 8.9% FPR95 on DeepFake
dataset. Moreover, we test our detection framework on multilingual, attacked,
and unseen-model and -domain text settings, demonstrating the robustness and
generalizability of our framework. Code, pretrained weights, and demo will be
released.

</details>


### [9] [YpathRAG:A Retrieval-Augmented Generation Framework and Benchmark for Pathology](https://arxiv.org/abs/2510.08603)
*Deshui Yu,Yizhi Wang,Saihui Jin,Taojie Zhu,Fanyi Zeng,Wen Qian,Zirui Huang,Jingli Ouyang,Jiameng Li,Zhen Song,Tian Guan,Yonghong He*

Main category: cs.CL

TL;DR: YpathRAG，一个病理学导向的RAG框架，具有双通道混合检索和基于LLM的支持证据判断模块，提高了检索质量和事实可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在病理学等高门槛领域存在幻觉问题，而先前的研究依赖于领域微调，既没有扩大知识边界，也没有强制执行基于证据的约束。

Method: 构建了一个包含28个子领域和153万个段落的病理学向量数据库，并提出了YpathRAG，它具有双通道混合检索（BGE-M3密集检索与词汇引导的稀疏检索相结合）和一个基于LLM的支持证据判断模块。

Result: 在YpathR上，YpathRAG的Recall@5达到了98.64%，比基线提高了23个百分点；在YpathQA-M上，对于300个最具挑战性的问题，它将通用和医学LLM的准确率平均提高了9.0%，最高提高了15.6%。

Conclusion: 这些结果表明，YpathRAG提高了检索质量和事实可靠性，为病理学导向的RAG提供了一个可扩展的构建范例和可解释的评估。

Abstract: Large language models (LLMs) excel on general tasks yet still hallucinate in
high-barrier domains such as pathology. Prior work often relies on domain
fine-tuning, which neither expands the knowledge boundary nor enforces
evidence-grounded constraints. We therefore build a pathology vector database
covering 28 subfields and 1.53 million paragraphs, and present YpathRAG, a
pathology-oriented RAG framework with dual-channel hybrid retrieval (BGE-M3
dense retrieval coupled with vocabulary-guided sparse retrieval) and an
LLM-based supportive-evidence judgment module that closes the
retrieval-judgment-generation loop. We also release two evaluation benchmarks,
YpathR and YpathQA-M. On YpathR, YpathRAG attains Recall@5 of 98.64%, a gain of
23 percentage points over the baseline; on YpathQA-M, a set of the 300 most
challenging questions, it increases the accuracies of both general and medical
LLMs by 9.0% on average and up to 15.6%. These results demonstrate improved
retrieval quality and factual reliability, providing a scalable construction
paradigm and interpretable evaluation for pathology-oriented RAG.

</details>


### [10] [FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs](https://arxiv.org/abs/2510.08886)
*Yan Wang,Keyi Wang,Shanshan Yang,Jaisal Patel,Jeff Zhao,Fengran Mo,Xueqing Peng,Lingfei Qian,Jimin Huang,Guojun Xiong,Xiao-Yang Liu,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 本文介绍了FinAuditing，这是一个用于评估LLM在财务审计任务中的性能的基准。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在理解结构化、相互依赖且由分类驱动的财务文档方面的能力仍有待探索，而GAAP的复杂性和XBRL的层级结构使得财务审计越来越难以自动化和验证。

Method: 构建了FinAuditing基准，它包含三个子任务：FinSM（语义一致性）、FinRE（关系一致性）和FinMR（数值一致性）。此外，还提出了一个统一的评估框架，整合了检索、分类和推理指标。

Result: 对13个最先进的LLM进行了零样本实验，结果表明，当前的模型在语义、关系和数学维度上的表现不一致，当对分层多文档结构进行推理时，准确率下降了60-90%。

Conclusion: 目前的大型语言模型在基于分类的财务推理方面存在局限性，FinAuditing可以作为开发值得信赖的、结构感知的和符合法规的财务智能系统的基础。

Abstract: The complexity of the Generally Accepted Accounting Principles (GAAP) and the
hierarchical structure of eXtensible Business Reporting Language (XBRL) filings
make financial auditing increasingly difficult to automate and verify. While
large language models (LLMs) have demonstrated strong capabilities in
unstructured text understanding, their ability to reason over structured,
interdependent, and taxonomy-driven financial documents remains largely
unexplored. To fill this gap, we introduce FinAuditing, the first
taxonomy-aligned, structure-aware, multi-document benchmark for evaluating LLMs
on financial auditing tasks. Built from real US-GAAP-compliant XBRL filings,
FinAuditing defines three complementary subtasks, FinSM for semantic
consistency, FinRE for relational consistency, and FinMR for numerical
consistency, each targeting a distinct aspect of structured auditing reasoning.
We further propose a unified evaluation framework integrating retrieval,
classification, and reasoning metrics across these subtasks. Extensive
zero-shot experiments on 13 state-of-the-art LLMs reveal that current models
perform inconsistently across semantic, relational, and mathematical
dimensions, with accuracy drops of up to 60-90% when reasoning over
hierarchical multi-document structures. Our findings expose the systematic
limitations of modern LLMs in taxonomy-grounded financial reasoning and
establish FinAuditing as a foundation for developing trustworthy,
structure-aware, and regulation-aligned financial intelligence systems. The
benchmark dataset is available at Hugging Face.

</details>


### [11] [LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback](https://arxiv.org/abs/2510.08604)
*Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio*

Main category: cs.CL

TL;DR: 提出了一种新的白盒攻击方法 LatentBreak，通过在潜在空间中替换词语生成自然对抗提示，以绕过基于困惑度的防御。


<details>
  <summary>Details</summary>
Motivation: 现有jailbreak攻击容易被基于困惑度的过滤检测到。

Method: 通过在输入提示中用语义等价的词语替换单词，并在潜在空间中最小化对抗提示和无害请求之间的距离来生成对抗提示。

Result: LatentBreak 能够生成更短、低困惑度的提示，并在多个安全对齐模型上优于其他jailbreak算法。

Conclusion: LatentBreak 是一种有效的对抗攻击方法，可以绕过基于困惑度的防御。

Abstract: Jailbreaks are adversarial attacks designed to bypass the built-in safety
mechanisms of large language models. Automated jailbreaks typically optimize an
adversarial suffix or adapt long prompt templates by forcing the model to
generate the initial part of a restricted or harmful response. In this work, we
show that existing jailbreak attacks that leverage such mechanisms to unlock
the model response can be detected by a straightforward perplexity-based
filtering on the input prompt. To overcome this issue, we propose LatentBreak,
a white-box jailbreak attack that generates natural adversarial prompts with
low perplexity capable of evading such defenses. LatentBreak substitutes words
in the input prompt with semantically-equivalent ones, preserving the initial
intent of the prompt, instead of adding high-perplexity adversarial suffixes or
long templates. These words are chosen by minimizing the distance in the latent
space between the representation of the adversarial prompt and that of harmless
requests. Our extensive evaluation shows that LatentBreak leads to shorter and
low-perplexity prompts, thus outperforming competing jailbreak algorithms
against perplexity-based filters on multiple safety-aligned models.

</details>


### [12] [Toward a Safer Web: Multilingual Multi-Agent LLMs for Mitigating Adversarial Misinformation Attacks](https://arxiv.org/abs/2510.08605)
*Nouar Aldahoul,Yasir Zaki*

Main category: cs.CL

TL;DR: 这篇论文提出了一种多语言、多代理的大型语言模型框架，用于检测在线平台上的虚假信息。


<details>
  <summary>Details</summary>
Motivation: 数字平台上虚假信息的迅速传播威胁着公众讨论、情绪稳定和决策。之前的研究没有系统地研究这篇论文中 исследованных 特定转换。

Method: 该研究调查了跨英语、法语、西班牙语、阿拉伯语、印地语和汉语的语言切换，然后进行翻译。他们还研究了在摘要之前查询长度膨胀以及结构重format成多项选择题。

Result: 该论文提出了一个多语言、多代理的大型语言模型框架，该框架具有检索增强生成功能，可以作为网络插件部署到在线平台中。

Conclusion: 这项工作强调了人工智能驱动的虚假信息检测在保护在线事实完整性免受各种攻击的重要性，同时展示了基于插件的部署在现实世界网络应用中的可行性。

Abstract: The rapid spread of misinformation on digital platforms threatens public
discourse, emotional stability, and decision-making. While prior work has
explored various adversarial attacks in misinformation detection, the specific
transformations examined in this paper have not been systematically studied. In
particular, we investigate language-switching across English, French, Spanish,
Arabic, Hindi, and Chinese, followed by translation. We also study query length
inflation preceding summarization and structural reformatting into
multiple-choice questions. In this paper, we present a multilingual,
multi-agent large language model framework with retrieval-augmented generation
that can be deployed as a web plugin into online platforms. Our work
underscores the importance of AI-driven misinformation detection in
safeguarding online factual integrity against diverse attacks, while showcasing
the feasibility of plugin-based deployment for real-world web applications.

</details>


### [13] [Centering Emotion Hotspots: Multimodal Local-Global Fusion and Cross-Modal Alignment for Emotion Recognition in Conversations](https://arxiv.org/abs/2510.08606)
*Yu Liu,Hanlei Shi,Haoxun Li,Yuqing Sun,Yuxuan Ding,Linlin Gong,Leyuan Qu,Taihao Li*

Main category: cs.CL

TL;DR: 本文提出了一种基于情感热点的对话情绪识别统一模型，该模型通过热点门控融合来融合文本、音频和视频中的热点与全局特征，并通过路由的对齐器混合来对齐模态。


<details>
  <summary>Details</summary>
Motivation: 对话情绪识别由于判别证据稀疏、局部化且跨模态异步而具有挑战性。本文旨在解决这些问题。

Method: 本文提出了一种统一的模型，该模型可以检测文本、音频和视频中的per-utterance热点，通过热点门控融合将它们与全局特征融合，并使用路由的对齐器混合来对齐模态；跨模态图编码对话结构。

Result: 在标准ERC基准上的实验表明，与强大的基线相比，本文提出的模型具有一致的优势，并且消融实验证实了HGF和MoA的贡献。

Conclusion: 本文的结果表明，以热点为中心的视角可以为未来的多模态学习提供信息，为ERC中的模态融合提供新的视角。

Abstract: Emotion Recognition in Conversations (ERC) is hard because discriminative
evidence is sparse, localized, and often asynchronous across modalities. We
center ERC on emotion hotspots and present a unified model that detects
per-utterance hotspots in text, audio, and video, fuses them with global
features via Hotspot-Gated Fusion, and aligns modalities using a routed
Mixture-of-Aligners; a cross-modal graph encodes conversational structure. This
design focuses modeling on salient spans, mitigates misalignment, and preserves
context. Experiments on standard ERC benchmarks show consistent gains over
strong baselines, with ablations confirming the contributions of HGF and MoA.
Our results point to a hotspot-centric view that can inform future multimodal
learning, offering a new perspective on modality fusion in ERC.

</details>


### [14] [MMA-ASIA: A Multilingual and Multimodal Alignment Framework for Culturally-Grounded Evaluation](https://arxiv.org/abs/2510.08608)
*Weihua Zheng,Zhengyuan Liu,Tanmoy Chakraborty,Weiwen Xu,Xiaoxue Gao,Bryan Chen Zhengyu Tan,Bowei Zou,Chang Liu,Yujia Hu,Xing Xie,Xiaoyuan Yi,Jing Yao,Chaojun Wang,Long Li,Rui Liu,Huiyao Liu,Koji Inoue,Ryuichi Sumida,Tatsuya Kawahara,Fan Xu,Lingyu Ye,Wei Tian,Dongjun Kim,Jimin Jung,Jaehyung Seo,Nadya Yuki Wangsajaya,Pham Minh Duc,Ojasva Saxena,Palash Nandi,Xiyan Tao,Wiwik Karlina,Tuan Luong,Keertana Arun Vasan,Roy Ka-Wei Lee,Nancy F. Chen*

Main category: cs.CL

TL;DR: MMA-ASIA是一个评估LLM在亚洲文化背景下文化意识的综合框架，包含一个多语言、多模态对齐的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在西方以外、高资源环境下的多模态理解和推理能力下降。

Method: 提出了一个五维评估协议，并使用文化意识基础验证模块来检测“捷径学习”。

Result: 构建了一个涵盖8个亚洲国家和10种语言，包含27,000个问题的基准数据集，其中超过79%的问题需要基于文化背景的多步骤推理。

Conclusion: 通过比较模型分析、注意力追踪和VPR方法，探究了模型在不同语言和模态上的差异原因，为构建文化上可靠的多模态LLM提供了可操作的见解。

Abstract: Large language models (LLMs) are now used worldwide, yet their multimodal
understanding and reasoning often degrade outside Western, high-resource
settings. We propose MMA-ASIA, a comprehensive framework to evaluate LLMs'
cultural awareness with a focus on Asian contexts. MMA-ASIA centers on a
human-curated, multilingual, and multimodally aligned multiple-choice benchmark
covering 8 Asian countries and 10 languages, comprising 27,000 questions; over
79 percent require multi-step reasoning grounded in cultural context, moving
beyond simple memorization. To our knowledge, this is the first dataset aligned
at the input level across three modalities: text, image (visual question
answering), and speech. This enables direct tests of cross-modal transfer.
Building on this benchmark, we propose a five-dimensional evaluation protocol
that measures: (i) cultural-awareness disparities across countries, (ii)
cross-lingual consistency, (iii) cross-modal consistency, (iv) cultural
knowledge generalization, and (v) grounding validity. To ensure rigorous
assessment, a Cultural Awareness Grounding Validation Module detects "shortcut
learning" by checking whether the requisite cultural knowledge supports correct
answers. Finally, through comparative model analysis, attention tracing, and an
innovative Vision-ablated Prefix Replay (VPR) method, we probe why models
diverge across languages and modalities, offering actionable insights for
building culturally reliable multimodal LLMs.

</details>


### [15] [GraphGhost: Tracing Structures Behind Large Language Models](https://arxiv.org/abs/2510.08613)
*Xinnan Dai,Kai Guo,Chung-Hsiang Lo,Shenglai Zeng,Jiayuan Ding,Dongsheng Luo,Subhabrata Mukherjee,Jiliang Tang*

Main category: cs.CL

TL;DR: 这篇论文提出了 GraphGhost 框架，用于分析大型语言模型 (LLM) 的结构化推理机制。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型 (LLM) 的推理能力的结构机制。

Method: 将神经元激活及其信号传播表示为图，并使用图算法（如 PageRank）来表征 LLM 的属性。

Result: 揭示了不同数据集上 LLM 的共享和模型特定的推理行为。对关键神经元节点进行编辑可以触发推理崩溃，改变逻辑流程和语义理解。

Conclusion: GraphGhost 是一个强大的工具，可用于分析、干预和最终理解 LLM 中推理的结构基础。

Abstract: Large Language Models (LLMs) demonstrate remarkable reasoning capabilities,
yet the structural mechanisms underlying these abilities remain under explored.
In this work, we introduce GraphGhost, a unified framework that represents
neuron activations and their signal propagation as graphs, explaining how LLMs
capture structural semantics from sequential inputs and generate outputs
through structurally consistent mechanisms. This graph-based perspective
enables us to employ graph algorithms such as PageRank to characterize the
properties of LLMs, revealing both shared and model-specific reasoning
behaviors across diverse datasets. We further identify the activated neurons
within GraphGhost and evaluate them through structural interventions, showing
that edits to key neuron nodes can trigger reasoning collapse, altering both
logical flow and semantic understanding. Together, these contributions position
GraphGhost as a powerful tool for analyzing, intervening in, and ultimately
understanding the structural foundations of reasoning in LLMs.

</details>


### [16] [Gender Bias in Large Language Models for Healthcare: Assignment Consistency and Clinical Implications](https://arxiv.org/abs/2510.08614)
*Mingxuan Liu,Yuhe Ke,Wentao Zhu,Mayli Mertens,Yilin Ning,Jingchi Liao,Chuan Hong,Daniel Shu Wei Ting,Yifan Peng,Danielle S. Bitterman,Marcus Eng Hock Ong,Nan Liu*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在医疗保健领域的应用前景广阔，但其偏见问题不容忽视。本研究探讨了LLMs在模拟临床医生或医学教育者角色时，是否会复制或放大与性别相关的偏见。通过使用新英格兰医学杂志挑战赛（NEJM）的案例研究，我们为多个开源和专有LLMs分配了性别（女性、男性或未指定），并评估了它们在LLM性别分配中的反应一致性，包括基于LLM的诊断以及模型对患者性别临床相关性或必要性的判断。研究发现，大多数模型的诊断在LLM性别之间相对一致。然而，关于患者性别在基于LLM的诊断中的相关性和必要性，所有模型在LLM性别之间都表现出显著的不一致性，尤其是在相关性判断方面。一些模型甚至在对患者性别的解释中表现出系统性的男女差异。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在医疗保健中的性别偏见问题，尤其是在模拟临床医生角色时可能复制或放大的偏见。

Method: 使用新英格兰医学杂志挑战赛（NEJM）的案例研究，为多个开源和专有LLMs分配性别（女性、男性或未指定），并评估它们在LLM性别分配中的反应一致性。

Result: 诊断在LLM性别之间相对一致，但患者性别相关性和必要性的判断上存在显著不一致性，尤其是在相关性判断方面。一些模型甚至在对患者性别的解释中表现出系统性的男女差异。

Conclusion: 研究揭示了一种未被充分重视的偏见，可能损害LLMs在临床实践中的可靠性。强调需要对身份分配一致性进行常规检查，以确保可靠和公平的AI支持的临床护理。

Abstract: The integration of large language models (LLMs) into healthcare holds promise
to enhance clinical decision-making, yet their susceptibility to biases remains
a critical concern. Gender has long influenced physician behaviors and patient
outcomes, raising concerns that LLMs assuming human-like roles, such as
clinicians or medical educators, may replicate or amplify gender-related
biases. Using case studies from the New England Journal of Medicine Challenge
(NEJM), we assigned genders (female, male, or unspecified) to multiple
open-source and proprietary LLMs. We evaluated their response consistency
across LLM-gender assignments regarding both LLM-based diagnosis and models'
judgments on the clinical relevance or necessity of patient gender. In our
findings, diagnoses were relatively consistent across LLM genders for most
models. However, for patient gender's relevance and necessity in LLM-based
diagnosis, all models demonstrated substantial inconsistency across LLM
genders, particularly for relevance judgements. Some models even displayed a
systematic female-male disparity in their interpretation of patient gender.
These findings present an underexplored bias that could undermine the
reliability of LLMs in clinical practice, underscoring the need for routine
checks of identity-assignment consistency when interacting with LLMs to ensure
reliable and equitable AI-supported clinical care.

</details>


### [17] [Iterative LLM-Based Generation and Refinement of Distracting Conditions in Math Word Problems](https://arxiv.org/abs/2510.08615)
*Kaiqi Yang,Hang Li,Yucheng Chu,Zitao Liu,Mi Tian,Hui Liu*

Main category: cs.CL

TL;DR: 本研究旨在解决现有数学应用题（MWP）数据集中缺乏干扰信息的问题，并提出了一种利用大型语言模型（LLM）自动生成干扰信息的迭代框架。


<details>
  <summary>Details</summary>
Motivation: 现有MWP数据集大多只包含必要信息，忽略了干扰条件。现有LLM在引入干扰条件时性能显著下降，但现有的带干扰条件的MWP数据集有限，且难度较低，缺乏实际意义。

Method: 设计了一个迭代框架，利用LLM自动生成干扰条件。通过一系列提示，从多个角度和认知层面修改MWP，生成有意义的干扰条件，并提出进一步改进的建议。该框架的关键优势在于保留了原始问题和修改后问题的共享解决方案。

Result: 该框架能够高效且易于部署，大大减少了生成带有干扰条件的MWP所需的工作量，同时保持了较高的数据质量。

Conclusion: 该研究提出了一种有效的自动生成数学应用题干扰信息的方法，为评估LLM在复杂条件下的推理能力提供了更有力的工具。

Abstract: Mathematical reasoning serves as a crucial testbed for evaluating the
intelligence of large language models (LLMs), and math word problems (MWPs)
represent one of the most widely used formats. Most existing MWP datasets
contain only the necessary information, while problems with distracting or
excessive conditions are often overlooked. Prior studies have shown that
popular LLMs experience a dramatic performance drop when such distracting
conditions are introduced. However, available datasets of MWPs with distracting
conditions remain limited, and most exhibit low difficulty and out-of-context
expressions. These shortcomings make the distracting conditions easy to detect
and disregard, thereby reducing the credibility of benchmarking on these
datasets. Moreover, when distracting conditions are added, the reasoning
process and answers may change, requiring intensive manual effort to check and
rewrite solutions.
  To address these issues, we design an iterative framework that leverages LLMs
to generate distracting conditions automatically. We develop a set of prompts
to revise MWPs from multiple perspectives and cognitive levels, encouraging the
creation of meaningful distracting conditions as well as suggestions for
further refinement. A key advantage of our framework is the preservation of
shared solutions between the original and revised problems: the LLMs are
explicitly guided to generate distractions that do not alter the original
solution, thus eliminating the need to produce new answers. This framework is
efficient and easy to deploy, substantially reducing the effort required to
generate MWPs with distracting conditions while maintaining high data quality.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [18] [Beyond CNNs: Efficient Fine-Tuning of Multi-Modal LLMs for Object Detection on Low-Data Regimes](https://arxiv.org/abs/2510.08589)
*Nirmal Elamon,Rouzbeh Davoudi*

Main category: cs.CV

TL;DR: 比较了微调的传统 CNN、zero-shot 预训练的多模态 LLM 和微调的多模态 LLM 在图像中人工文本叠加检测任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用语言引导模型以最少的监督来实现精确的视觉理解，从而弥合视觉和语言之间的差距。

Method: 对少量数据（少于 1,000 张图像）上微调 LLM，以提高准确率。

Result: LLM 经过微调后，准确率提高了 36%，与通常需要更多数据的基于 CNN 的基线相匹配或超过。

Conclusion: LLM 方法具有适应性和数据效率，适用于实际对象检测任务，并为在低资源视觉环境中应用多模态 Transformer 提供可操作的指导。

Abstract: The field of object detection and understanding is rapidly evolving, driven
by advances in both traditional CNN-based models and emerging multi-modal large
language models (LLMs). While CNNs like ResNet and YOLO remain highly effective
for image-based tasks, recent transformer-based LLMs introduce new capabilities
such as dynamic context reasoning, language-guided prompts, and holistic scene
understanding. However, when used out-of-the-box, the full potential of LLMs
remains underexploited, often resulting in suboptimal performance on
specialized visual tasks. In this work, we conduct a comprehensive comparison
of fine-tuned traditional CNNs, zero-shot pre-trained multi-modal LLMs, and
fine-tuned multi-modal LLMs on the challenging task of artificial text overlay
detection in images. A key contribution of our study is demonstrating that LLMs
can be effectively fine-tuned on very limited data (fewer than 1,000 images) to
achieve up to 36% accuracy improvement, matching or surpassing CNN-based
baselines that typically require orders of magnitude more data. By exploring
how language-guided models can be adapted for precise visual understanding with
minimal supervision, our work contributes to the broader effort of bridging
vision and language, offering novel insights into efficient cross-modal
learning strategies. These findings highlight the adaptability and data
efficiency of LLM-based approaches for real-world object detection tasks and
provide actionable guidance for applying multi-modal transformers in
low-resource visual environments. To support continued progress in this area,
we have made the code used to fine-tune the models available in our GitHub,
enabling future improvements and reuse in related applications.

</details>


### [19] [Reproducible Evaluation of Data Augmentation and Loss Functions for Brain Tumor Segmentation](https://arxiv.org/abs/2510.08617)
*Saumya B*

Main category: cs.CV

TL;DR: 本文提出了一种基于U-Net的脑肿瘤分割方法，使用focal loss和数据增强策略，并在公开数据集上进行了评估，达到了与最先进方法相当的精度。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤分割对于诊断和治疗计划至关重要，但类别不平衡和模型泛化能力有限等挑战仍然阻碍进展。

Method: 使用focal loss和基本数据增强策略（水平翻转、旋转和缩放）在公开的MRI数据集上评估U-Net分割性能。

Result: U-Net与focal loss的结合达到了90%的精度，与目前最先进的结果相当。

Conclusion: 该研究建立了一个透明、可重复的基线，以指导未来关于脑肿瘤分割中增强策略和损失函数设计的研究。

Abstract: Brain tumor segmentation is crucial for diagnosis and treatment planning, yet
challenges such as class imbalance and limited model generalization continue to
hinder progress. This work presents a reproducible evaluation of U-Net
segmentation performance on brain tumor MRI using focal loss and basic data
augmentation strategies. Experiments were conducted on a publicly available MRI
dataset, focusing on focal loss parameter tuning and assessing the impact of
three data augmentation techniques: horizontal flip, rotation, and scaling. The
U-Net with focal loss achieved a precision of 90%, comparable to
state-of-the-art results. By making all code and results publicly available,
this study establishes a transparent, reproducible baseline to guide future
research on augmentation strategies and loss function design in brain tumor
segmentation.

</details>


### [20] [Adjusting Initial Noise to Mitigate Memorization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2510.08625)
*Hyeonggeun Han,Sehwan Kim,Hyungjun Joo,Sangwoo Hong,Jungwoo Lee*

Main category: cs.CV

TL;DR: 文本到图像扩散模型容易记忆和复制训练数据，引发隐私和版权问题。通过调整初始噪声样本，可以减少记忆并保持图像-文本对齐。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型会记忆和复制训练数据，引发隐私和版权问题。现有方法通过延迟应用无分类器指导(CFG)来避免记忆，但导致图像与提示词对齐不良，因此需要尽早逃离记忆库。

Method: 通过调整初始噪声样本（集体或单独）来寻找并利用鼓励更早逃离记忆库的初始样本。

Result: 该方法显著减少了记忆，同时保持了图像-文本对齐。

Conclusion: 初始噪声样本在决定何时逃离记忆库方面起着关键作用，所提出的两种缓解策略可以调整初始噪声以鼓励更早地逃离记忆库。

Abstract: Despite their impressive generative capabilities, text-to-image diffusion
models often memorize and replicate training data, prompting serious concerns
over privacy and copyright. Recent work has attributed this memorization to an
attraction basin-a region where applying classifier-free guidance (CFG) steers
the denoising trajectory toward memorized outputs-and has proposed deferring
CFG application until the denoising trajectory escapes this basin. However,
such delays often result in non-memorized images that are poorly aligned with
the input prompts, highlighting the need to promote earlier escape so that CFG
can be applied sooner in the denoising process. In this work, we show that the
initial noise sample plays a crucial role in determining when this escape
occurs. We empirically observe that different initial samples lead to varying
escape times. Building on this insight, we propose two mitigation strategies
that adjust the initial noise-either collectively or individually-to find and
utilize initial samples that encourage earlier basin escape. These approaches
significantly reduce memorization while preserving image-text alignment.

</details>


### [21] [The Digital Mirror: Gender Bias and Occupational Stereotypes in AI-Generated Images](https://arxiv.org/abs/2510.08628)
*Siiri Leppälampi,Sonja M. Hyrynsalmi,Erno Vanhala*

Main category: cs.CV

TL;DR: 本研究调查了AI生成的图像中存在的表征偏差，特别是在职业场景中。


<details>
  <summary>Details</summary>
Motivation: 现有的AI生成可视化研究主要关注生成过程和图像质量，忽略了表征偏差。为了弥补这一差距，本研究旨在测试AI生成图像中的表征偏差。

Method: 本研究使用了DALL-E 3和Ideogram两个AI图像生成工具，生成了超过750张职业相关的图像，并进行了主题分析。

Result: 研究结果表明，DALL-E 3和Ideogram都在不同程度上强化了AI生成图像中传统的性别刻板印象。

Conclusion: AI可视化工具存在强化狭隘表征的风险。研究为从业者、个人和研究人员提出了增加图像表征的建议。

Abstract: Generative AI offers vast opportunities for creating visualisations, such as
graphics, videos, and images. However, recent studies around AI-generated
visualisations have primarily focused on the creation process and image
quality, overlooking representational biases. This study addresses this gap by
testing representation biases in AI-generated pictures in an occupational
setting and evaluating how two AI image generator tools, DALL-E 3 and Ideogram,
compare. Additionally, the study discusses topics such as ageing and emotions
in AI-generated images. As AI image tools are becoming more widely used,
addressing and mitigating harmful gender biases becomes essential to ensure
diverse representation in media and professional settings. In this study, over
750 AI-generated images of occupations were prompted. The thematic analysis
results revealed that both DALL-E 3 and Ideogram reinforce traditional gender
stereotypes in AI-generated images, although to varying degrees. These findings
emphasise that AI visualisation tools risk reinforcing narrow representations.
In our discussion section, we propose suggestions for practitioners,
individuals and researchers to increase representation when generating images
with visible genders.

</details>


### [22] [Dynamic Mixture-of-Experts for Visual Autoregressive Model](https://arxiv.org/abs/2510.08629)
*Jort Vincenti,Metod Jazbec,Guoxuan Xia*

Main category: cs.CV

TL;DR: 本研究提出了一种动态混合专家路由器，集成到视觉自回归模型（VAR）中，以在计算效率和图像质量之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: 视觉自回归模型（VAR）虽然能高效生成高质量图像，但由于在不断提高的分辨率下重复调用 Transformer，存在计算冗余。

Method: 引入动态混合专家路由器，通过感知尺度的阈值策略，根据 token 复杂度和分辨率平衡专家选择，无需额外训练。

Result: 实现了 20% 的 FLOPs 减少和 11% 的推理加速，同时保持了与密集基线相当的图像质量。

Conclusion: 该方法在不损失图像质量的前提下，显著提高了视觉自回归模型的计算效率。

Abstract: Visual Autoregressive Models (VAR) offer efficient and high-quality image
generation but suffer from computational redundancy due to repeated Transformer
calls at increasing resolutions. We introduce a dynamic Mixture-of-Experts
router integrated into VAR. The new architecture allows to trade compute for
quality through scale-aware thresholding. This thresholding strategy balances
expert selection based on token complexity and resolution, without requiring
additional training. As a result, we achieve 20% fewer FLOPs, 11% faster
inference and match the image quality achieved by the dense baseline.

</details>


### [23] [Out-of-Distribution Detection in LiDAR Semantic Segmentation Using Epistemic Uncertainty from Hierarchical GMMs](https://arxiv.org/abs/2510.08631)
*Hanieh Shojaei Miandashti,Claus Brenner*

Main category: cs.CV

TL;DR: 提出了一种新的基于分层贝叶斯建模高斯混合模型（GMM）参数的无人监督OOD检测方法，该方法在SemanticKITTI数据集上优于现有的基于不确定性的方法。


<details>
  <summary>Details</summary>
Motivation: 精确的语义分割对于准确的场景理解至关重要，检测训练期间未遇到的分布外（OOD）对象对于防止将未知对象错误分配给已知类至关重要。现有的方法或者依赖于辅助OOD数据集，或者将认知不确定性和偶然不确定性混淆。

Method: 采用从深度神经网络特征空间中高斯混合模型（GMM）参数的分层贝叶斯建模中获得的认知不确定性。

Result: 在SemanticKITTI数据集上，AUROC提高了18%，AUPRC提高了22%，FPR95降低了36%。

Conclusion: 该方法不需要辅助数据或额外的训练阶段，并且优于先前工作中使用过的预测熵方法。

Abstract: In addition to accurate scene understanding through precise semantic
segmentation of LiDAR point clouds, detecting out-of-distribution (OOD)
objects, instances not encountered during training, is essential to prevent the
incorrect assignment of unknown objects to known classes. While supervised OOD
detection methods depend on auxiliary OOD datasets, unsupervised methods avoid
this requirement but typically rely on predictive entropy, the entropy of the
predictive distribution obtained by averaging over an ensemble or multiple
posterior weight samples. However, these methods often conflate epistemic
(model) and aleatoric (data) uncertainties, misclassifying ambiguous in
distribution regions as OOD. To address this issue, we present an unsupervised
OOD detection approach that employs epistemic uncertainty derived from
hierarchical Bayesian modeling of Gaussian Mixture Model (GMM) parameters in
the feature space of a deep neural network. Without requiring auxiliary data or
additional training stages, our approach outperforms existing uncertainty-based
methods on the SemanticKITTI dataset, achieving an 18\% improvement in AUROC,
22\% increase in AUPRC, and 36\% reduction in FPR95 (from 76\% to 40\%),
compared to the predictive entropy approach used in prior works.

</details>


### [24] [Hi-OSCAR: Hierarchical Open-set Classifier for Human Activity Recognition](https://arxiv.org/abs/2510.08635)
*Conor McCarthy,Loes Quirijnen,Jan Peter van Zandwijk,Zeno Geradts,Marcel Worring*

Main category: cs.CV

TL;DR: 论文提出了Hi-OSCAR，一种用于活动识别的分层开放集分类器，可以识别已知活动并拒绝未知活动，同时提供关于未知活动的信息。


<details>
  <summary>Details</summary>
Motivation: 现有的HAR分类器无法处理未见过的活动，并且活动类别之间存在重叠或包含关系，这影响了分类器的可靠性。

Method: 论文将活动类别组织成一个结构化的层次结构，并提出了Hi-OSCAR分类器，该分类器可以将未知类别定位到最近的内部节点。

Result: Hi-OSCAR分类器在识别已知活动方面达到了最先进的精度，同时可以拒绝未知活动。

Conclusion: 论文收集了一个新的数据集NFI_FARED，用于促进开放集HAR的研究。

Abstract: Within Human Activity Recognition (HAR), there is an insurmountable gap
between the range of activities performed in life and those that can be
captured in an annotated sensor dataset used in training. Failure to properly
handle unseen activities seriously undermines any HAR classifier's reliability.
Additionally within HAR, not all classes are equally dissimilar, some
significantly overlap or encompass other sub-activities. Based on these
observations, we arrange activity classes into a structured hierarchy. From
there, we propose Hi-OSCAR: a Hierarchical Open-set Classifier for Activity
Recognition, that can identify known activities at state-of-the-art accuracy
while simultaneously rejecting unknown activities. This not only enables
open-set classification, but also allows for unknown classes to be localized to
the nearest internal node, providing insight beyond a binary "known/unknown"
classification. To facilitate this and future open-set HAR research, we
collected a new dataset: NFI_FARED. NFI_FARED contains data from multiple
subjects performing nineteen activities from a range of contexts, including
daily living, commuting, and rapid movements, which is fully public and
available for download.

</details>


### [25] [Detection of high-frequency oscillations using time-frequency analysis](https://arxiv.org/abs/2510.08637)
*Mostafa Mohammadpour,Mehdi Zekriyapanah Gashti,Yusif S. Gasimov*

Main category: cs.CV

TL;DR: 本文提出了一种新的高频振荡（HFO）检测方法，旨在提高难治性癫痫患者手术切除部位的精确性。


<details>
  <summary>Details</summary>
Motivation: 高频振荡(HFOs)是识别致痫区的新生物标志物。绘制产生HFO的区域可以提高难治性癫痫患者切除部位的精确性。然而，检测HFO仍然具有挑战性，并且它们的临床特征尚未完全确定。视觉识别HFOs非常耗时、费力且主观。因此，开发自动检测HFOs的方法对于研究和临床应用至关重要。

Method: 该方法采用一种无监督聚类技术，对使用S变换从时频域中提取的事件进行分类，以区分HFO事件与尖峰、背景活动和伪影。

Result: 在对照数据集上，该方法实现了97.67%的灵敏度、98.57%的精确度和97.78%的F-score。在癫痫患者中，切除与未切除接触点中HFOs比率为0.73，结果与手术结果显示出更强的相关性。

Conclusion: 该研究证实了先前的发现，即HFOs是癫痫患者致痫性的有希望的生物标志物。去除HFOs，尤其是快速波纹，可导致无癫痫发作，而剩余的HFOs会导致癫痫复发。

Abstract: High-frequency oscillations (HFOs) are a new biomarker for identifying the
epileptogenic zone. Mapping HFO-generating regions can improve the precision of
resection sites in patients with refractory epilepsy. However, detecting HFOs
remains challenging, and their clinical features are not yet fully defined.
Visual identification of HFOs is time-consuming, labor-intensive, and
subjective. As a result, developing automated methods to detect HFOs is
critical for research and clinical use. In this study, we developed a novel
method for detecting HFOs in the ripple and fast ripple frequency bands (80-500
Hz). We validated it using both controlled datasets and data from epilepsy
patients. Our method employs an unsupervised clustering technique to categorize
events extracted from the time-frequency domain using the S-transform. The
proposed detector differentiates HFOs events from spikes, background activity,
and artifacts. Compared to existing detectors, our method achieved a
sensitivity of 97.67%, a precision of 98.57%, and an F-score of 97.78% on the
controlled dataset. In epilepsy patients, our results showed a stronger
correlation with surgical outcomes, with a ratio of 0.73 between HFOs rates in
resected versus non-resected contacts. The study confirmed previous findings
that HFOs are promising biomarkers of epileptogenicity in epileptic patients.
Removing HFOs, especially fast ripple, leads to seizure freedom, while
remaining HFOs lead to seizure recurrence.

</details>


### [26] [Into the Rabbit Hull: From Task-Relevant Concepts in DINO to Minkowski Geometry](https://arxiv.org/abs/2510.08638)
*Thomas Fel,Binxu Wang,Michael A. Lepori,Matthew Kowal,Andrew Lee,Randall Balestriero,Sonia Joseph,Ekdeep S. Lubana,Talia Konkle,Demba Ba,Martin Wattenberg*

Main category: cs.CV

TL;DR: DINOv2的感知机制尚不清楚，本文通过SAEs构建了一个32,000单元的字典作为研究基础，并从下游任务、几何与统计、以及综合观察三个方面展开研究。


<details>
  <summary>Details</summary>
Motivation: 探究DINOv2究竟感知到了什么。

Method: 使用SAEs构建一个32,000单元的字典，并以此为基础进行分析。

Result: 分类利用“Elsewhere”概念，分割依赖于边界检测器，深度估计利用三种单眼深度线索。表示是部分密集的，字典向更大的连贯性演变。Token占据低维局部连接的集合。

Conclusion: Token由原型（如动物中的兔子、颜色中的棕色、纹理中的蓬松）的凸混合组合形成。

Abstract: DINOv2 is routinely deployed to recognize objects, scenes, and actions; yet
the nature of what it perceives remains unknown. As a working baseline, we
adopt the Linear Representation Hypothesis (LRH) and operationalize it using
SAEs, producing a 32,000-unit dictionary that serves as the interpretability
backbone of our study, which unfolds in three parts.
  In the first part, we analyze how different downstream tasks recruit concepts
from our learned dictionary, revealing functional specialization:
classification exploits "Elsewhere" concepts that fire everywhere except on
target objects, implementing learned negations; segmentation relies on boundary
detectors forming coherent subspaces; depth estimation draws on three distinct
monocular depth cues matching visual neuroscience principles.
  Following these functional results, we analyze the geometry and statistics of
the concepts learned by the SAE. We found that representations are partly dense
rather than strictly sparse. The dictionary evolves toward greater coherence
and departs from maximally orthogonal ideals (Grassmannian frames). Within an
image, tokens occupy a low dimensional, locally connected set persisting after
removing position. These signs suggest representations are organized beyond
linear sparsity alone.
  Synthesizing these observations, we propose a refined view: tokens are formed
by combining convex mixtures of archetypes (e.g., a rabbit among animals, brown
among colors, fluffy among textures). This structure is grounded in Gardenfors'
conceptual spaces and in the model's mechanism as multi-head attention produces
sums of convex mixtures, defining regions bounded by archetypes. We introduce
the Minkowski Representation Hypothesis (MRH) and examine its empirical
signatures and implications for interpreting vision-transformer
representations.

</details>


### [27] [PhyDAE: Physics-Guided Degradation-Adaptive Experts for All-in-One Remote Sensing Image Restoration](https://arxiv.org/abs/2510.08653)
*Zhe Dong,Yuzhe Sun,Haochen Jiang,Tianzhu Liu,Yanfeng Gu*

Main category: cs.CV

TL;DR: 本文提出了一种名为Physics-Guided Degradation-Adaptive Experts (PhyDAE) 的遥感图像修复方法，该方法通过显式建模退化物理过程，实现了对多种异构退化的精确识别和差异化处理，并在性能和效率之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 遥感图像在获取过程中会受到多种退化因素的影响，现有的修复方法过度依赖隐式特征表示，缺乏对退化物理过程的显式建模。

Method: 该方法采用两阶段级联架构，将退化信息从隐式特征转化为显式决策信号，并结合残差流形投影器 (RMP) 和频率感知退化分解器 (FADD) 从流形几何和频率角度分析退化特征。同时，引入了物理感知专家模块和温度控制的稀疏激活策略。

Result: 在三个基准数据集上的实验结果表明，PhyDAE 在所有四个修复任务上均优于现有技术，并在参数数量和计算复杂度上实现了显著降低。

Conclusion: PhyDAE 能够显著提高修复质量，同时降低参数数量和计算复杂度，在性能和效率之间取得了最佳平衡。

Abstract: Remote sensing images inevitably suffer from various degradation factors
during acquisition, including atmospheric interference, sensor limitations, and
imaging conditions. These complex and heterogeneous degradations pose severe
challenges to image quality and downstream interpretation tasks. Addressing
limitations of existing all-in-one restoration methods that overly rely on
implicit feature representations and lack explicit modeling of degradation
physics, this paper proposes Physics-Guided Degradation-Adaptive Experts
(PhyDAE). The method employs a two-stage cascaded architecture transforming
degradation information from implicit features into explicit decision signals,
enabling precise identification and differentiated processing of multiple
heterogeneous degradations including haze, noise, blur, and low-light
conditions. The model incorporates progressive degradation mining and
exploitation mechanisms, where the Residual Manifold Projector (RMP) and
Frequency-Aware Degradation Decomposer (FADD) comprehensively analyze
degradation characteristics from manifold geometry and frequency perspectives.
Physics-aware expert modules and temperature-controlled sparse activation
strategies are introduced to enhance computational efficiency while ensuring
imaging physics consistency. Extensive experiments on three benchmark datasets
(MD-RSID, MD-RRSHID, and MDRS-Landsat) demonstrate that PhyDAE achieves
superior performance across all four restoration tasks, comprehensively
outperforming state-of-the-art methods. Notably, PhyDAE substantially improves
restoration quality while achieving significant reductions in parameter count
and computational complexity, resulting in remarkable efficiency gains compared
to mainstream approaches and achieving optimal balance between performance and
efficiency. Code is available at https://github.com/HIT-SIRS/PhyDAE.

</details>


### [28] [Hulu-Med: A Transparent Generalist Model towards Holistic Medical Vision-Language Understanding](https://arxiv.org/abs/2510.08668)
*Songtao Jiang,Yuan Wang,Sibo Song,Tianxiang Hu,Chenyi Zhou,Bin Pu,Yan Zhang,Zhibo Yang,Yang Feng,Joey Tianyi Zhou,Jin Hao,Zijian Chen,Ruijia Wu,Tao Tang,Junhui Lv,Hongxia Xu,Hongwei Wang,Jun Xiao,Bin Feng,Fudong Zhu,Kenli Li,Weidi Xie,Jimeng Sun,Jian Wu,Zuozhu Liu*

Main category: cs.CV

TL;DR: Hulu-Med是一个透明的医学视觉语言模型，它统一了对医学文本、2D/3D图像和视频的理解。


<details>
  <summary>Details</summary>
Motivation: 现实世界的临床决策需要在整合来自不同数据模式的信息，包括医学文本、2D/3D图像和视频，这导致效率低下和潜在的诊断疏忽。通用视觉语言模型(vlm)很有前景，但它们的医学发展面临着管道不透明、数据稀缺和架构不灵活的挑战。

Method: Hulu-Med建立在一个统一的基于patch的视觉编码器和一个LLM解码器的基础上，经过1670万(M)样本的逐步训练，从2D扩展到3D和视频理解。医学感知令牌减少实现了高效的训练，7B到32B参数变体只需要4000到40000个GPU小时。

Result: 在30个基准上的广泛评估显示了最先进的性能，超过了领先的开源模型，并在跨越视觉问答、医学报告生成以及多语言和罕见疾病场景中的复杂推理任务中与专有系统竞争。

Conclusion: 通过开源我们完整的管道，我们确定高性能的医学VLM可以透明地实现，为可访问和有影响力的临床AI提供了一个基础工具。

Abstract: Real-world clinical decision-making grapples with integrating information
from diverse data modalities, including medical text, 2D/3D images, and video,
leading to inefficiencies and potential diagnostic oversights. While generalist
vision-language models (VLMs) offer promise, their medical development faces
challenges of opaque pipelines, data scarcity, and architectural inflexibility.
Here we present Hulu-Med, a transparent medical VLM that unifies understanding
across all these modalities. Built upon a unified patch-based vision encoder
and an LLM decoder, Hulu-Med was progressively trained on 16.7 million (M)
samples to scale from 2D to 3D and video comprehension. The medical-aware token
reduction enables efficient training, requiring only 4,000 to 40,000 GPU hours
for 7B to 32B parameter variants. Extensive evaluation across 30 benchmarks
exhibits state-of-the-art performance, surpassing leading open-source models
and competing with proprietary systems in tasks spanning visual
question-answering, medical report generation, and complex reasoning in
multilingual and rare disease scenarios. By open-sourcing our complete
pipeline, we establish that high-performance medical VLM can be achieved
transparently, providing a foundational tool for accessible and impactful
clinical AI. Code is released on
\href{https://github.com/ZJUI-AI4H/Hulu-Med}{https://github.com/ZJUI-AI4H/Hulu-Med}.

</details>


### [29] [Thinking with Camera: A Unified Multimodal Model for Camera-Centric Understanding and Generation](https://arxiv.org/abs/2510.08673)
*Kang Liao,Size Wu,Zhonghua Wu,Linyi Jin,Chao Wang,Yikai Wang,Fei Wang,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: Puffin是一个统一的、以相机为中心的 multimodal 模型，它扩展了相机维度的空间感知能力，可以从任意视点解释和创建场景。


<details>
  <summary>Details</summary>
Motivation: 目前，以相机为中心的理解和生成是空间智能的两个基石，但它们通常是孤立研究的。Puffin 旨在弥合相机和视觉语言之间的模态差距。

Method: Puffin 结合了语言回归和基于扩散的生成，将相机视为语言，并引入了一种新的范例，从而能够利用相机进行思考。该模型在包含 400 万个视觉-语言-相机三元组的大规模数据集 Puffin-4M 上进行训练。

Result: 实验表明，Puffin 在以相机为中心的生成和理解方面优于专用模型。通过指令调整，Puffin 可以推广到各种跨视图任务，例如空间想象、世界探索和摄影指导。

Conclusion: Puffin 通过统一的 multimodal 模型，提升了相机维度的空间感知能力，并在多个任务上表现出卓越的性能。

Abstract: Camera-centric understanding and generation are two cornerstones of spatial
intelligence, yet they are typically studied in isolation. We present Puffin, a
unified camera-centric multimodal model that extends spatial awareness along
the camera dimension. Puffin integrates language regression and diffusion-based
generation to interpret and create scenes from arbitrary viewpoints. To bridge
the modality gap between cameras and vision-language, we introduce a novel
paradigm that treats camera as language, enabling thinking with camera. This
guides the model to align spatially grounded visual cues with photographic
terminology while reasoning across geometric context. Puffin is trained on
Puffin-4M, a large-scale dataset of 4 million vision-language-camera triplets.
We incorporate both global camera parameters and pixel-wise camera maps,
yielding flexible and reliable spatial generation. Experiments demonstrate
Puffin superior performance over specialized models for camera-centric
generation and understanding. With instruction tuning, Puffin generalizes to
diverse cross-view tasks such as spatial imagination, world exploration, and
photography guidance. We will release the code, models, dataset pipeline, and
benchmark to advance multimodal spatial intelligence research.

</details>


### [30] [Hierarchical Scheduling for Multi-Vector Image Retrieval](https://arxiv.org/abs/2510.08976)
*Maoliang Li,Ke Li,Yaoyang Liu,Jiayu Chen,Zihao Zheng,Yinjun Wu,Xiang Chen*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为HiMIR的高效图像检索调度框架，用于提高多模态大型语言模型应用中检索增强生成(RAG)的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统检索方法精度有限，多向量检索(MVR)虽然有所改进，但仍存在精度和效率问题，忽略了查询和图像对象之间的对齐以及冗余的细粒度图像分割。

Method: 该方法采用分层范式，利用多个中间粒度来对不同的图像对象进行对齐，并通过交叉层次相似性一致性和层次稀疏性来减少检索中的冗余。

Result: 实验结果表明，HiMIR在显著提高准确率的同时，与现有的MVR系统相比，计算量减少了3.5倍。

Conclusion: HiMIR框架在图像检索方面取得了显著的准确率提升和计算效率的降低，为多模态大型语言模型应用中的RAG提供了更优的解决方案。

Abstract: To effectively leverage user-specific data, retrieval augmented generation
(RAG) is employed in multimodal large language model (MLLM) applications.
However, conventional retrieval approaches often suffer from limited retrieval
accuracy. Recent advances in multi-vector retrieval (MVR) improve accuracy by
decomposing queries and matching against segmented images. They still suffer
from sub-optimal accuracy and efficiency, overlooking alignment between the
query and varying image objects and redundant fine-grained image segments. In
this work, we present an efficient scheduling framework for image retrieval -
HiMIR. First, we introduce a novel hierarchical paradigm, employing multiple
intermediate granularities for varying image objects to enhance alignment.
Second, we minimize redundancy in retrieval by leveraging cross-hierarchy
similarity consistency and hierarchy sparsity to minimize unnecessary matching
computation. Furthermore, we configure parameters for each dataset
automatically for practicality across diverse scenarios. Our empirical study
shows that, HiMIR not only achieves substantial accuracy improvements but also
reduces computation by up to 3.5 times over the existing MVR system.

</details>


### [31] [Structured Output Regularization: a framework for few-shot transfer learning](https://arxiv.org/abs/2510.08728)
*Nicolas Ewen,Jairo Diaz-Rodriguez,Kelly Ramsay*

Main category: cs.CV

TL;DR: 提出了一种名为结构化输出正则化 (SOR) 的迁移学习框架，该框架冻结内部网络结构，同时使用 group lasso 和 L1 惩罚的组合，用最少的额外参数定制模型到特定数据。


<details>
  <summary>Details</summary>
Motivation: 传统的迁移学习通常通过冻结一些权重并添加特定于任务的层来重用大型预训练网络。虽然这种方法在计算上很有效，但它限制了模型适应特定领域特征的能力，并且仍然可能导致数据非常有限的过拟合。

Method: 冻结内部网络结构（例如，卷积滤波器），同时使用 group lasso 和 L1 惩罚的组合。

Result: 在三个小样本医学图像分类任务中评估了 SOR，并且与已建立的基准相比，使用 DenseNet121 和 EfficientNetB4 基础实现了有竞争力的结果。

Conclusion: SOR 框架可以用最少的额外参数将模型定制到特定数据，并且易于应用于各种网络组件，例如卷积滤波器或神经网络中的各种块，从而能够广泛应用于迁移学习任务。

Abstract: Traditional transfer learning typically reuses large pre-trained networks by
freezing some of their weights and adding task-specific layers. While this
approach is computationally efficient, it limits the model's ability to adapt
to domain-specific features and can still lead to overfitting with very limited
data. To address these limitations, we propose Structured Output Regularization
(SOR), a simple yet effective framework that freezes the internal network
structures (e.g., convolutional filters) while using a combination of group
lasso and $L_1$ penalties. This framework tailors the model to specific data
with minimal additional parameters and is easily applicable to various network
components, such as convolutional filters or various blocks in neural networks
enabling broad applicability for transfer learning tasks. We evaluate SOR on
three few shot medical imaging classification tasks and we achieve competitive
results using DenseNet121, and EfficientNetB4 bases compared to established
benchmarks.

</details>


### [32] [BEAR: Benchmarking and Enhancing Multimodal Language Models for Atomic Embodied Capabilities](https://arxiv.org/abs/2510.08759)
*Yu Qi,Haibo Zhao,Ziyu Guo,Siyuan Ma,Ziyan Chen,Yaokun Han,Renrui Zhang,Zitiantao Lin,Shiji Xin,Yijian Huang,Kai Cheng,Peiheng Wang,Jiazheng Liu,Jiayi Zhang,Yizhe Zhu,Wenqing Wang,Yiran Qin,Xupeng Zhu,Haojie Huang,Lawson L. S. Wong*

Main category: cs.CV

TL;DR: 这篇论文介绍了一个名为BEAR的综合性benchmark，用于评估多模态大型语言模型（MLLM）在具身能力方面的表现。实验表明，现有的MLLM在各项具身能力上存在局限性。因此，作者提出了BEAR-Agent，通过整合预训练的视觉模型来提升MLLM的感知、3D理解和规划能力，从而在BEAR benchmark上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的benchmark主要集中在特定领域，对MLLM的具身能力缺乏全面系统的评估。

Method: 提出了BEAR benchmark，包含4,469个图像-视频-文本条目，涵盖14个领域和6个类别，从低级指向、轨迹理解、空间推理到高级规划。同时，提出了BEAR-Agent，一个多模态可对话的agent，集成了预训练视觉模型。

Result: 对20个MLLM的广泛评估表明，它们在具身能力的各个领域都存在持续的局限性。BEAR-Agent在BEAR benchmark上显著提高了MLLM的性能，获得了9.12%的绝对收益和17.5%的相对提升（与GPT-5相比）。

Conclusion: 提高MLLM的具身能力可以改善模拟环境中的具身任务表现。

Abstract: Embodied capabilities refer to a suite of fundamental abilities for an agent
to perceive, comprehend, and interact with the physical world. While multimodal
large language models (MLLMs) show promise as embodied agents, a thorough and
systematic evaluation of their embodied capabilities remains underexplored, as
existing benchmarks primarily focus on specific domains such as planning or
spatial understanding. To bridge this gap, we introduce BEAR, a comprehensive
and fine-grained benchmark that evaluates MLLMs on atomic embodied
capabilities. BEAR comprises 4,469 interleaved image-video-text entries across
14 domains in 6 categories, including tasks from low-level pointing, trajectory
understanding, spatial reasoning, to high-level planning. Extensive evaluation
results of 20 representative MLLMs reveal their persistent limitations across
all domains of embodied capabilities. To tackle the shortfall, we propose
BEAR-Agent, a multimodal conversable agent that integrates pretrained vision
models to strengthen MLLM perception, 3D understanding, and planning
capabilities. It substantially enhances MLLM performance across diverse
embodied capabilities on BEAR, yielding a 9.12% absolute gain and a relative
improvement of 17.5% on GPT-5. Furthermore, our experiments indicate that
improving MLLM embodied capabilities can benefit embodied tasks in simulated
environments. Project website: https://bear-official66.github.io/

</details>


### [33] [SAFER-AiD: Saccade-Assisted Foveal-peripheral vision Enhanced Reconstruction for Adversarial Defense](https://arxiv.org/abs/2510.08761)
*Jiayang Liu,Daniel Tso,Yiming Bu,Qinru Qiu*

Main category: cs.CV

TL;DR: 提出了一种新的防御框架，该框架结合了三种关键的生物机制：中央凹-周边处理、扫视眼动和皮质填充。


<details>
  <summary>Details</summary>
Motivation: 对抗性攻击对深度学习模型的安全部署提出了重大挑战，尤其是在现实世界的应用中。传统的防御方法通常依赖于计算密集型优化（例如，对抗性训练或数据增强）来提高鲁棒性，而人类视觉系统通过进化的生物机制实现了对对抗性扰动的内在鲁棒性。

Method: 该方法采用强化学习引导的扫视来选择性地捕获多个中央凹-周边一瞥，然后将其集成到重建图像中，然后再进行分类。

Result: 在 ImageNet 数据集上的实验表明，该方法提高了系统在不同分类器和攻击类型中的鲁棒性，同时与生物和非生物启发式防御技术相比，显着降低了训练开销。

Conclusion: 该方法有效地减轻了对抗性噪声，保留了语义完整性，并且值得注意的是，无需对下游分类器进行重新训练或微调，从而可以与现有系统无缝集成。

Abstract: Adversarial attacks significantly challenge the safe deployment of deep
learning models, particularly in real-world applications. Traditional defenses
often rely on computationally intensive optimization (e.g., adversarial
training or data augmentation) to improve robustness, whereas the human visual
system achieves inherent robustness to adversarial perturbations through
evolved biological mechanisms. We hypothesize that attention guided
non-homogeneous sparse sampling and predictive coding plays a key role in this
robustness. To test this hypothesis, we propose a novel defense framework
incorporating three key biological mechanisms: foveal-peripheral processing,
saccadic eye movements, and cortical filling-in. Our approach employs
reinforcement learning-guided saccades to selectively capture multiple
foveal-peripheral glimpses, which are integrated into a reconstructed image
before classification. This biologically inspired preprocessing effectively
mitigates adversarial noise, preserves semantic integrity, and notably requires
no retraining or fine-tuning of downstream classifiers, enabling seamless
integration with existing systems. Experiments on the ImageNet dataset
demonstrate that our method improves system robustness across diverse
classifiers and attack types, while significantly reducing training overhead
compared to both biologically and non-biologically inspired defense techniques.

</details>


### [34] [Detecting spills using thermal imaging, pretrained deep learning models, and a robotic platform](https://arxiv.org/abs/2510.08770)
*Gregory Yeghiyan,Jurius Azar,Devson Butani,Chan-Jin Chung*

Main category: cs.CV

TL;DR: 提出一个使用预训练深度学习模型和RGB和热成像的实时溢出检测系统，用于在各种环境中对溢出与非溢出情况进行分类。


<details>
  <summary>Details</summary>
Motivation: 在各种环境中准确、快速地检测溢出情况。

Method: 使用包含4000张图像的平衡二元数据集，利用VGG19和NasNetMobile等轻量级模型，结合RGB和热成像进行实验。

Result: 使用VGG19和NasNetMobile等轻量级模型，最高可达100%的准确率，热成像模型在不同光照条件下表现更快、更稳健。在消费级硬件（RTX 4080）上运行，推理时间低至44毫秒，模型大小低于350MB。VGG19模型在热成像上训练的效果最佳。

Conclusion: 该系统在安全关键环境中具有部署潜力，VGG19模型在热成像上训练效果最佳。

Abstract: This paper presents a real-time spill detection system that utilizes
pretrained deep learning models with RGB and thermal imaging to classify spill
vs. no-spill scenarios across varied environments. Using a balanced binary
dataset (4,000 images), our experiments demonstrate the advantages of thermal
imaging in inference speed, accuracy, and model size. We achieve up to 100%
accuracy using lightweight models like VGG19 and NasNetMobile, with thermal
models performing faster and more robustly across different lighting
conditions. Our system runs on consumer-grade hardware (RTX 4080) and achieves
inference times as low as 44 ms with model sizes under 350 MB, highlighting its
deployability in safety-critical contexts. Results from experiments with a real
robot and test datasets indicate that a VGG19 model trained on thermal imaging
performs best.

</details>


### [35] [LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution](https://arxiv.org/abs/2510.08771)
*Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu*

Main category: cs.CV

TL;DR: 本文提出了一种名为 LinearSR 的整体框架，首次系统地克服了线性注意力在图像超分辨率 (SR) 中的关键障碍，实现了最先进的感知质量和卓越的效率。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的二次复杂度 (O(N^2)) 造成了计算瓶颈。线性注意力提供了一种 O(N) 的解决方案，但其在照片级真实感 SR 中的潜力尚未开发。

Method: 1. 提出了一种基于“膝点”的早停引导微调 (ESGF) 策略，解决了根本性的训练不稳定性问题。2. 采用基于 SNR 的专家混合 (MoE) 架构，缓解了经典的感知-失真权衡。3. 建立了一种有效的轻量级指导范式 TAG，源自“精度高于数量”原则。

Result: LinearSR 模型同时提供了最先进的感知质量和卓越的效率。其核心扩散前向传递 (1-NFE) 实现了 SOTA 级别的速度，而其整体多步推理时间仍然具有很强的竞争力。

Conclusion: 这项工作为在线性注意力在照片级真实感 SR 领域的应用提供了第一个稳健的方法，为未来高效生成超分辨率的研究奠定了基础。

Abstract: Generative models for Image Super-Resolution (SR) are increasingly powerful,
yet their reliance on self-attention's quadratic complexity (O(N^2)) creates a
major computational bottleneck. Linear Attention offers an O(N) solution, but
its promise for photorealistic SR has remained largely untapped, historically
hindered by a cascade of interrelated and previously unsolved challenges. This
paper introduces LinearSR, a holistic framework that, for the first time,
systematically overcomes these critical hurdles. Specifically, we resolve a
fundamental, training instability that causes catastrophic model divergence
using our novel "knee point"-based Early-Stopping Guided Fine-tuning (ESGF)
strategy. Furthermore, we mitigate the classic perception-distortion trade-off
with a dedicated SNR-based Mixture of Experts (MoE) architecture. Finally, we
establish an effective and lightweight guidance paradigm, TAG, derived from our
"precision-over-volume" principle. Our resulting LinearSR model simultaneously
delivers state-of-the-art perceptual quality with exceptional efficiency. Its
core diffusion forward pass (1-NFE) achieves SOTA-level speed, while its
overall multi-step inference time remains highly competitive. This work
provides the first robust methodology for applying Linear Attention in the
photorealistic SR domain, establishing a foundational paradigm for future
research in efficient generative super-resolution.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [36] [Hypothesis Hunting with Evolving Networks of Autonomous Scientific Agents](https://arxiv.org/abs/2510.08619)
*Tennison Liu,Silas Ruhrberg Estévez,David L. Bentley,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文介绍了一种名为AScience的框架，用于支持大规模科学数据集中的探索性发现（假设搜索）。


<details>
  <summary>Details</summary>
Motivation: 当前大型科学数据集为探索性发现提供了机会，但缺乏有效的方法来支持这种探索。

Method: 本文提出了AScience框架，该框架将发现建模为智能体、网络和评估规范的交互。该框架被实现为ASCollab，一个基于LLM的研究智能体分布式系统，具有不同的行为。这些智能体自组织成不断发展的网络，在共享的评估标准下持续生成和同行评审研究结果。

Result: 实验表明，这种社会动态能够积累专家评估的结果，包括重新发现已建立的生物标志物、扩展已知的通路以及提出新的治疗靶点。

Conclusion: 本文证明了在癌症队列中，社会结构化的智能体网络可以大规模地支持探索性假设搜索。

Abstract: Large-scale scientific datasets -- spanning health biobanks, cell atlases,
Earth reanalyses, and more -- create opportunities for exploratory discovery
unconstrained by specific research questions. We term this process hypothesis
hunting: the cumulative search for insight through sustained exploration across
vast and complex hypothesis spaces. To support it, we introduce AScience, a
framework modeling discovery as the interaction of agents, networks, and
evaluation norms, and implement it as ASCollab, a distributed system of
LLM-based research agents with heterogeneous behaviors. These agents
self-organize into evolving networks, continually producing and peer-reviewing
findings under shared standards of evaluation. Experiments show that such
social dynamics enable the accumulation of expert-rated results along the
diversity-quality-novelty frontier, including rediscoveries of established
biomarkers, extensions of known pathways, and proposals of new therapeutic
targets. While wet-lab validation remains indispensable, our experiments on
cancer cohorts demonstrate that socially structured, agentic networks can
sustain exploratory hypothesis hunting at scale.

</details>


### [37] [Safe, Untrusted, "Proof-Carrying" AI Agents: toward the agentic lakehouse](https://arxiv.org/abs/2510.09567)
*Jacopo Tagliabue,Ciro Greco*

Main category: cs.AI

TL;DR: API优先的可编程Lakehouse为安全、自主的工作流程提供了正确的抽象。


<details>
  <summary>Details</summary>
Motivation: 在数据湖中，AI驱动的自动化引起了对信任、正确性和治理的担忧。

Method: 以Bauplan为例，展示了数据分支和声明式环境如何自然地扩展到代理，从而实现可重复性和可观察性，同时减少攻击面。

Result: 一个概念验证，其中代理使用受携带代码证明启发的正确性检查来修复数据管道。原型表明，不受信任的AI代理可以在生产数据上安全运行。

Conclusion: 不受信任的AI代理可以在生产数据上安全运行，并概述了通往完全代理化的lakehouse的路径。

Abstract: Data lakehouses run sensitive workloads, where AI-driven automation raises
concerns about trust, correctness, and governance. We argue that API-first,
programmable lakehouses provide the right abstractions for safe-by-design,
agentic workflows. Using Bauplan as a case study, we show how data branching
and declarative environments extend naturally to agents, enabling
reproducibility and observability while reducing the attack surface. We present
a proof-of-concept in which agents repair data pipelines using correctness
checks inspired by proof-carrying code. Our prototype demonstrates that
untrusted AI agents can operate safely on production data and outlines a path
toward a fully agentic lakehouse.

</details>


### [38] [Optimizing delivery for quick commerce factoring qualitative assessment of generated routes](https://arxiv.org/abs/2510.08671)
*Milon Bhattacharya,Milan Kumar*

Main category: cs.AI

TL;DR: 印度电商市场增长迅速，但最后一公里配送成本高昂且面临现实问题。本研究提出利用大型语言模型（LLM）评估车辆路径问题（VRP）生成的路线，以提升配送效率。


<details>
  <summary>Details</summary>
Motivation: 在印度，最后一公里配送占电商运营成本近一半。传统的VRP求解器在实际应用中受限于不规范的地址、不完整的地图以及距离估算的计算约束，效果不佳。

Method: 该研究提出一个框架，利用大型语言模型（LLM）根据策略标准评估VRP生成的路线。

Result: 研究结果表明，开源LLM能以79%的准确率识别路线问题，而专有推理模型则高达86%。

Conclusion: 基于LLM的VRP路线评估是一种有效且可扩展的评估手段，超越了传统的距离和时间指标，有助于提高最后一公里物流的成本效率、交付可靠性和可持续性，尤其是在像印度这样的发展中国家。

Abstract: Indias e-commerce market is projected to grow rapidly, with last-mile
delivery accounting for nearly half of operational expenses. Although vehicle
routing problem (VRP) based solvers are widely used for delivery planning,
their effectiveness in real-world scenarios is limited due to unstructured
addresses, incomplete maps, and computational constraints in distance
estimation. This study proposes a framework that employs large language models
(LLMs) to critique VRP-generated routes against policy-based criteria, allowing
logistics operators to evaluate and prioritise more efficient delivery plans.
As a illustration of our approach we generate, annotate and evaluated 400 cases
using large language models. Our study found that open-source LLMs identified
routing issues with 79% accuracy, while proprietary reasoning models achieved
reach upto 86%. The results demonstrate that LLM-based evaluation of
VRP-generated routes can be an effective and scalable layer of evaluation which
goes beyond beyond conventional distance and time based metrics. This has
implications for improving cost efficiency, delivery reliability, and
sustainability in last-mile logistics, especially for developing countries like
India.

</details>


### [39] [Unified World Models: Memory-Augmented Planning and Foresight for Visual Navigation](https://arxiv.org/abs/2510.08713)
*Yifei Dong,Fengyi Wu,Guangyu Chen,Zhi-Qi Cheng,Qiyu Hu,Yuxuan Zhou,Jingdong Sun,Jun-Yan He,Qi Dai,Alexander G Hauptmann*

Main category: cs.AI

TL;DR: 提出了一种名为UniWM的统一的、记忆增强的世界模型，用于具身智能体的视觉导航。


<details>
  <summary>Details</summary>
Motivation: 现有的方法采用模块化架构，将导航规划与视觉世界建模分离，导致状态-动作不对齐，并且在新场景或动态场景中的适应性有限。

Method: UniWM 在单个多模态自回归骨干网络中集成了以自我为中心的视觉预测和规划。分层记忆机制进一步整合了详细的短期感知线索和长期轨迹上下文。

Result: 在四个具有挑战性的基准测试中，UniWM 显著提高了导航成功率（高达 30%），与强大的基线相比，显著减少了轨迹误差，并且在未见过的 TartanDrive 数据集上表现出令人印象深刻的零样本泛化能力。

Conclusion: UniWM 是朝着统一的、想象驱动的具身导航迈出的重要一步。

Abstract: Enabling embodied agents to effectively imagine future states is critical for
robust and generalizable visual navigation. Current state-of-the-art
approaches, however, adopt modular architectures that separate navigation
planning from visual world modeling, leading to state-action misalignment and
limited adaptability in novel or dynamic scenarios. To overcome this
fundamental limitation, we propose UniWM, a unified, memory-augmented world
model integrating egocentric visual foresight and planning within a single
multimodal autoregressive backbone. Unlike modular frameworks, UniWM explicitly
grounds action decisions in visually imagined outcomes, ensuring tight
alignment between prediction and control. A hierarchical memory mechanism
further integrates detailed short-term perceptual cues with longer-term
trajectory context, enabling stable, coherent reasoning over extended horizons.
Extensive experiments across four challenging benchmarks (Go Stanford, ReCon,
SCAND, HuRoN) demonstrate that UniWM substantially improves navigation success
rates by up to 30%, significantly reduces trajectory errors compared to strong
baselines, and exhibits impressive zero-shot generalization on the unseen
TartanDrive dataset. These results highlight UniWM as a principled step toward
unified, imagination-driven embodied navigation.

</details>


### [40] [Robust Heuristic Algorithm Design with LLMs](https://arxiv.org/abs/2510.08755)
*Pantea Karimi,Dany Rouhana,Pooria Namyar,Siva Kesava Reddy Kakarla,Venkat Arun,Behnaz Arzani*

Main category: cs.AI

TL;DR: 使用LLM通过解释为什么启发式方法表现不佳以及关于如何修复它们的建议来增强启发式设计方法，可以生成更稳健和高性能的启发式方法。


<details>
  <summary>Details</summary>
Motivation: 利用LLM设计启发式方法。

Method: 1. 将LLM暴露于启发式方法表现不佳的实例；2. 解释它们发生的原因；3. 专门针对输入空间中的区域进行设计。

Result: 与现有技术相比，所产生的启发式算法具有更好的鲁棒性。与FunSearch相比，最坏情况下的性能提高了约28倍，提高了平均性能，并保持了运行时间。

Conclusion: 通过使用LLM增强启发式设计方法，可以生成更稳健和高性能的启发式方法。

Abstract: We posit that we can generate more robust and performant heuristics if we
augment approaches using LLMs for heuristic design with tools that explain why
heuristics underperform and suggestions about how to fix them. We find even
simple ideas that (1) expose the LLM to instances where the heuristic
underperforms; (2) explain why they occur; and (3) specialize design to regions
in the input space, can produce more robust algorithms compared to existing
techniques~ -- ~the heuristics we produce have a $\sim28\times$ better
worst-case performance compared to FunSearch, improve average performance, and
maintain the runtime.

</details>


### [41] [COMPASS: Enhancing Agent Long-Horizon Reasoning with Evolving Context](https://arxiv.org/abs/2510.08790)
*Guangya Wan,Mingyang Ling,Xiaoqi Ren,Rujun Han,Sheng Li,Zizhao Zhang*

Main category: cs.AI

TL;DR: LLM agents struggle with long-horizon tasks due to context management issues.


<details>
  <summary>Details</summary>
Motivation: Long-horizon tasks requiring reasoning and tool interactions are challenging for LLM agents due to error compounding and incoherence. Context management is identified as the bottleneck.

Method: The paper proposes COMPASS, a hierarchical framework with a Main Agent, Meta-Thinker, and Context Manager to address context management issues.

Result: COMPASS improves accuracy by up to 20% on GAIA, BrowseComp, and Humanity's Last Exam benchmarks. A scaling extension matches DeepResearch agents, and a post-training pipeline enhances efficiency.

Conclusion: COMPASS, a lightweight hierarchical framework, effectively addresses context management issues in LLM agents for long-horizon tasks.

Abstract: Long-horizon tasks that require sustained reasoning and multiple tool
interactions remain challenging for LLM agents: small errors compound across
steps, and even state-of-the-art models often hallucinate or lose coherence. We
identify context management as the central bottleneck -- extended histories
cause agents to overlook critical evidence or become distracted by irrelevant
information, thus failing to replan or reflect from previous mistakes. To
address this, we propose COMPASS (Context-Organized Multi-Agent Planning and
Strategy System), a lightweight hierarchical framework that separates tactical
execution, strategic oversight, and context organization into three specialized
components: (1) a Main Agent that performs reasoning and tool use, (2) a
Meta-Thinker that monitors progress and issues strategic interventions, and (3)
a Context Manager that maintains concise, relevant progress briefs for
different reasoning stages. Across three challenging benchmarks -- GAIA,
BrowseComp, and Humanity's Last Exam -- COMPASS improves accuracy by up to 20%
relative to both single- and multi-agent baselines. We further introduce a
test-time scaling extension that elevates performance to match established
DeepResearch agents, and a post-training pipeline that delegates context
management to smaller models for enhanced efficiency.

</details>


### [42] [Everyone prefers human writers, including AI](https://arxiv.org/abs/2510.08831)
*Wouter Haverals,Meredith Martin*

Main category: cs.AI

TL;DR: 研究发现，在评估文学风格时，人类和AI都存在偏见，AI的偏见程度甚至是人类的2.5倍。当内容被标记为“AI生成”时，AI系统会系统性地贬低其价值，无论由哪个AI创建。


<details>
  <summary>Details</summary>
Motivation: 随着AI写作工具的普及，我们需要了解人类和机器如何评估文学风格，因为这个领域缺乏客观标准，判断具有主观性。

Method: 通过对照实验，使用雷蒙德·基诺的《风格练习》(1947)来测量评估者中的归因偏差。研究1比较了人类参与者(N=556)和AI模型(N=13)在三种条件下评估来自基诺与GPT-4生成的文学段落：盲测、准确标记和反事实标记。研究2测试了AI评估者和创造者在14x14矩阵中的偏差泛化。

Result: 两项研究都揭示了系统性的亲人类归因偏差。人类表现出+13.7个百分点的偏差，而AI模型表现出+34.3个百分点的偏差，是人类的2.5倍。研究2证实，这种偏差在AI架构中普遍存在(+25.8pp)，表明当内容被标记为“AI生成”时，AI系统会系统性地贬低其价值，无论由哪个AI创建。归因标签导致评估者颠倒评估标准，相同的特征会因为感知的作者身份而得到相反的评估。

Conclusion: AI系统不仅复制而且放大了人类的这种倾向。这项研究首次对人类和人工智能评估者在审美判断中的归因偏差进行了对照比较，揭示了AI系统不仅复制而且放大了人类的这种倾向。

Abstract: As AI writing tools become widespread, we need to understand how both humans
and machines evaluate literary style, a domain where objective standards are
elusive and judgments are inherently subjective. We conducted controlled
experiments using Raymond Queneau's Exercises in Style (1947) to measure
attribution bias across evaluators. Study 1 compared human participants (N=556)
and AI models (N=13) evaluating literary passages from Queneau versus
GPT-4-generated versions under three conditions: blind, accurately labeled, and
counterfactually labeled. Study 2 tested bias generalization across a
14$\times$14 matrix of AI evaluators and creators. Both studies revealed
systematic pro-human attribution bias. Humans showed +13.7 percentage point
(pp) bias (Cohen's h = 0.28, 95% CI: 0.21-0.34), while AI models showed +34.3
percentage point bias (h = 0.70, 95% CI: 0.65-0.76), a 2.5-fold stronger effect
(P$<$0.001). Study 2 confirmed this bias operates across AI architectures
(+25.8pp, 95% CI: 24.1-27.6%), demonstrating that AI systems systematically
devalue creative content when labeled as "AI-generated" regardless of which AI
created it. We also find that attribution labels cause evaluators to invert
assessment criteria, with identical features receiving opposing evaluations
based solely on perceived authorship. This suggests AI models have absorbed
human cultural biases against artificial creativity during training. Our study
represents the first controlled comparison of attribution bias between human
and artificial evaluators in aesthetic judgment, revealing that AI systems not
only replicate but amplify this human tendency.

</details>


### [43] [What Is Your Agent's GPA? A Framework for Evaluating Agent Goal-Plan-Action Alignment](https://arxiv.org/abs/2510.08847)
*Allison Sihan Jia,Daniel Huang,Nikhil Vytla,Nirvika Choudhury,John C Mitchell,Anupam Datta*

Main category: cs.AI

TL;DR: 提出了Agent GPA (Goal-Plan-Action) 框架，用于评估智能体的目标设定、计划制定和行动执行的循环过程。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个系统化的方法来覆盖各种智能体失败案例，并支持LLM裁判对智能体性能进行评估和错误定位。

Method: 该框架包含五个评估指标：目标完成度、逻辑一致性、执行效率、计划质量和计划坚持度。通过这些指标来评估智能体的行为。

Result: 在两个基准数据集上的实验结果表明，该框架能够系统地覆盖各种智能体失败案例，LLM裁判与人工标注高度一致，并且能够以高准确率定位错误。

Conclusion: Agent GPA框架为智能体评估提供了一个全面、有效的方法，可以用于识别和改进智能体的性能。

Abstract: We introduce the Agent GPA (Goal-Plan-Action) framework: an evaluation
paradigm based on an agent's operational loop of setting goals, devising plans,
and executing actions. The framework includes five evaluation metrics: Goal
Fulfillment, Logical Consistency, Execution Efficiency, Plan Quality, and Plan
Adherence. Logical Consistency checks that an agent's actions are consistent
with its prior actions. Execution Efficiency checks whether the agent executes
in the most efficient way to achieve its goal. Plan Quality checks whether an
agent's plans are aligned with its goals; Plan Adherence checks if an agent's
actions are aligned with its plan; and Goal Fulfillment checks that agent's
final outcomes match the stated goals. Our experimental results on two
benchmark datasets - the public TRAIL/GAIA dataset and an internal dataset for
a production-grade data agent - show that this framework (a) provides a
systematic way to cover a broad range of agent failures, including all agent
errors on the TRAIL/GAIA benchmark dataset; (b) supports LLM-judges that
exhibit strong agreement with human annotation, covering 80% to over 95%
errors; and (c) localizes errors with 86% agreement to enable targeted
improvement of agent performance.

</details>


### [44] [ReviewerToo: Should AI Join The Program Committee? A Look At The Future of Peer Review](https://arxiv.org/abs/2510.08867)
*Gaurav Sahu,Hugo Larochelle,Laurent Charlin,Christopher Pal*

Main category: cs.AI

TL;DR: 本文介绍了一个名为ReviewerToo的模块化框架，用于研究和部署AI辅助的同行评审，以补充人类的判断，从而实现系统和一致的评估。


<details>
  <summary>Details</summary>
Motivation: 同行评审是科学出版的基石，但它存在不一致、审稿人主观性和可扩展性挑战。

Method: 本文提出了ReviewerToo框架，该框架支持使用专门的审稿人角色和结构化的评估标准进行系统实验，并且可以部分或完全集成到实际的会议工作流程中。

Result: 在ICLR 2025的1,963篇论文提交数据集上验证了ReviewerToo，其中gpt-oss-120b模型在将论文分类为接受/拒绝的任务中实现了81.8%的准确率，而普通人类审稿人的准确率为83.9%。此外，由LLM判断，ReviewerToo生成的评论的质量高于人类平均水平，但仍落后于最强的专家贡献。

Conclusion: 本文的研究结果表明，AI审稿人在事实核查、文献覆盖等方面表现出色，但在评估方法创新和理论贡献方面存在不足，这 подчеркивает 人类专业知识的持续需求。基于这些发现，本文提出了将AI集成到同行评审流程中的指南，展示了AI如何在提高一致性、覆盖范围和公平性的同时，将复杂的评估判断留给领域专家。

Abstract: Peer review is the cornerstone of scientific publishing, yet it suffers from
inconsistencies, reviewer subjectivity, and scalability challenges. We
introduce ReviewerToo, a modular framework for studying and deploying
AI-assisted peer review to complement human judgment with systematic and
consistent assessments. ReviewerToo supports systematic experiments with
specialized reviewer personas and structured evaluation criteria, and can be
partially or fully integrated into real conference workflows. We validate
ReviewerToo on a carefully curated dataset of 1,963 paper submissions from ICLR
2025, where our experiments with the gpt-oss-120b model achieves 81.8% accuracy
for the task of categorizing a paper as accept/reject compared to 83.9% for the
average human reviewer. Additionally, ReviewerToo-generated reviews are rated
as higher quality than the human average by an LLM judge, though still trailing
the strongest expert contributions. Our analysis highlights domains where AI
reviewers excel (e.g., fact-checking, literature coverage) and where they
struggle (e.g., assessing methodological novelty and theoretical
contributions), underscoring the continued need for human expertise. Based on
these findings, we propose guidelines for integrating AI into peer-review
pipelines, showing how AI can enhance consistency, coverage, and fairness while
leaving complex evaluative judgments to domain experts. Our work provides a
foundation for systematic, hybrid peer-review systems that scale with the
growth of scientific publishing.

</details>


### [45] [GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare](https://arxiv.org/abs/2510.08872)
*Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You*

Main category: cs.AI

TL;DR: 提出了博弈论对齐（GTAlign）框架，通过将博弈论决策融入推理和训练中，优化LLM与用户之间的互动。


<details>
  <summary>Details</summary>
Motivation: 传统对齐方法假设最大化模型奖励也能最大化用户福利，但实际并非如此，模型可能过度解释或产生冗长的推理。根本挑战是缺乏互利互惠的决策机制。

Method: 在推理过程中，模型将用户-LLM互动视为策略博弈，构建收益矩阵来评估双方福利，并选择互利的行动。在训练过程中，引入互惠福利奖励来强化合作响应。

Result: 实验表明，GTAlign在推理效率、答案质量和互惠福利方面均优于基线模型。

Conclusion: GTAlign通过博弈论方法显著提升了LLM与用户之间的互动效果，实现了更高效、高质量和互利的交流。

Abstract: Large Language Models (LLMs) have achieved remarkable progress in reasoning,
yet sometimes produce responses that are suboptimal for users in tasks such as
writing, information seeking, or providing practical guidance. Conventional
alignment practices typically assume that maximizing model reward also
maximizes user welfare, but this assumption frequently fails in practice:
models may over-clarify or generate overly verbose reasoning when users prefer
concise answers. Such behaviors resemble the prisoner's dilemma, where
individually rational choices lead to socially suboptimal outcomes. The
fundamental challenge is the lack of a principled decision making mechanism
that mutually benefits both the LLM and the user. We propose Game-Theoretic
Alignment (GTAlign), an alignment framework that integrates game-theoretic
decision making into both reasoning and training. During reasoning, the model
explicitly treats user-LLM interaction as a strategic game: it constructs
payoff matrices within its reasoning chain to estimate welfare for both itself
and the user, and then selects actions that are mutually beneficial. During
training, we introduce a mutual welfare reward that reinforces cooperative
responses, aligning model behavior with socially efficient outcomes. In
addition, we introduce an inference technique that leverages game-theoretic
reasoning to dynamically adapt LLM's response when pricing policies of LLM
service change. Extensive experiments demonstrate that GTAlign substantially
improves reasoning efficiency, answer quality, and mutual welfare compared to
baselines across diverse tasks. The code is available at
https://github.com/ulab-uiuc/GTAlign .

</details>


### [46] [LM Fight Arena: Benchmarking Large Multimodal Models via Game Competition](https://arxiv.org/abs/2510.08928)
*Yushuo Zheng,Zicheng Zhang,Xiongkuo Min,Huiyu Duan,Guangtao Zhai*

Main category: cs.AI

TL;DR: 提出了一个名为 LM Fight Arena 的新框架，用于评估大型多模态模型 (LMM) 在实时对抗环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 LMM 基准测试通常无法捕捉它们在实时对抗环境中的性能。

Method: 该框架通过让 LMM 在真人快打 II 中相互对抗来评估 LMM，这需要快速的视觉理解和战术性的顺序决策。

Result: 在一个受控的比赛中，我们测试了六个领先的开源和闭源模型，每个 agent 操作控制相同的角色以确保公平的比较。模型被提示解释游戏帧和状态数据以选择他们的下一个动作。

Conclusion: LM Fight Arena 提供了一个完全自动化、可重复和客观的 LMM 在动态环境中战略推理能力评估。

Abstract: Existing benchmarks for large multimodal models (LMMs) often fail to capture
their performance in real-time, adversarial environments. We introduce LM Fight
Arena (Large Model Fight Arena), a novel framework that evaluates LMMs by
pitting them against each other in the classic fighting game Mortal Kombat II,
a task requiring rapid visual understanding and tactical, sequential
decision-making. In a controlled tournament, we test six leading open- and
closed-source models, where each agent operates controlling the same character
to ensure a fair comparison. The models are prompted to interpret game frames
and state data to select their next actions. Unlike static evaluations, LM
Fight Arena provides a fully automated, reproducible, and objective assessment
of an LMM's strategic reasoning capabilities in a dynamic setting. This work
introduces a challenging and engaging benchmark that bridges the gap between AI
evaluation and interactive entertainment.

</details>


### [47] [RADAR: Mechanistic Pathways for Detecting Data Contamination in LLM Evaluation](https://arxiv.org/abs/2510.08931)
*Ashish Kattamuri,Harshwardhan Fartale,Arpita Vats,Rahul Raja,Ishita Prasad*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个名为RADAR的新框架，它利用机制可解释性来检测大型语言模型（LLM）评估中的数据污染。


<details>
  <summary>Details</summary>
Motivation: 可靠的LLM评估面临数据污染的重大挑战，模型可能通过记忆训练数据而非展示真正的推理能力来实现高性能。

Method: RADAR提取了37个特征，涵盖表面置信度轨迹和深度机制属性，包括注意力专业化、电路动力学和激活流模式。使用在这些特征上训练的分类器集成。

Result: RADAR在多样化的评估集上实现了93%的准确率，在明确的案例中表现完美，在具有挑战性的模糊示例中实现了76.7%的准确率。

Conclusion: 这项工作证明了机制可解释性在推进LLM评估方面超越传统表面水平指标的潜力。

Abstract: Data contamination poses a significant challenge to reliable LLM evaluation,
where models may achieve high performance by memorizing training data rather
than demonstrating genuine reasoning capabilities. We introduce RADAR (Recall
vs. Reasoning Detection through Activation Representation), a novel framework
that leverages mechanistic interpretability to detect contamination by
distinguishing recall-based from reasoning-based model responses. RADAR
extracts 37 features spanning surface-level confidence trajectories and deep
mechanistic properties including attention specialization, circuit dynamics,
and activation flow patterns. Using an ensemble of classifiers trained on these
features, RADAR achieves 93\% accuracy on a diverse evaluation set, with
perfect performance on clear cases and 76.7\% accuracy on challenging ambiguous
examples. This work demonstrates the potential of mechanistic interpretability
for advancing LLM evaluation beyond traditional surface-level metrics.

</details>


### [48] [EcphoryRAG: Re-Imagining Knowledge-Graph RAG via Human Associative Memory](https://arxiv.org/abs/2510.08958)
*Zirui Liao*

Main category: cs.AI

TL;DR: EcphoryRAG是一个实体中心的知识图谱RAG框架，它通过提取和存储核心实体及其元数据来减少token消耗，并通过多跳关联搜索和动态推断实体间关系来进行检索，从而在复杂问答任务中达到新的state-of-the-art。


<details>
  <summary>Details</summary>
Motivation: 受认知神经科学研究的启发，该研究表明人类利用线索激活以实体为中心的记忆痕迹来进行复杂的回忆。

Method: EcphoryRAG首先提取查询中的线索实体，然后跨知识图谱执行可扩展的多跳关联搜索，并动态推断实体之间的隐式关系来填充上下文。

Result: 在2WikiMultiHop、HotpotQA和MuSiQue基准测试中，EcphoryRAG将平均Exact Match (EM)得分从0.392提高到0.474，超越了像HippoRAG这样的强大KG-RAG方法。

Conclusion: 结果验证了实体线索多跳检索范式对于复杂问答的有效性。

Abstract: Cognitive neuroscience research indicates that humans leverage cues to
activate entity-centered memory traces (engrams) for complex, multi-hop
recollection. Inspired by this mechanism, we introduce EcphoryRAG, an
entity-centric knowledge graph RAG framework. During indexing, EcphoryRAG
extracts and stores only core entities with corresponding metadata, a
lightweight approach that reduces token consumption by up to 94\% compared to
other structured RAG systems. For retrieval, the system first extracts cue
entities from queries, then performs a scalable multi-hop associative search
across the knowledge graph. Crucially, EcphoryRAG dynamically infers implicit
relations between entities to populate context, enabling deep reasoning without
exhaustive pre-enumeration of relationships. Extensive evaluations on the
2WikiMultiHop, HotpotQA, and MuSiQue benchmarks demonstrate that EcphoryRAG
sets a new state-of-the-art, improving the average Exact Match (EM) score from
0.392 to 0.474 over strong KG-RAG methods like HippoRAG. These results validate
the efficacy of the entity-cue-multi-hop retrieval paradigm for complex
question answering.

</details>


### [49] [FATHOMS-RAG: A Framework for the Assessment of Thinking and Observation in Multimodal Systems that use Retrieval Augmented Generation](https://arxiv.org/abs/2510.08945)
*Samuel Hildebrand,Curtis Taylor,Sean Oesch,James M Ghawaly Jr,Amir Sadovnik,Ryan Shivers,Brandon Schreiber,Kevin Kurian*

Main category: cs.AI

TL;DR: 这篇论文介绍了一个用于评估检索增强生成（RAG）管道的基准，该基准旨在评估管道摄取、检索和推理多种信息的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准侧重于检索等特定方面，为了弥补这一缺陷，本研究旨在评估RAG管道的整体性能，特别是其处理多模态信息的能力。

Method: 该研究提出：（1）一个包含93个问题的小型人工数据集，用于评估管道摄取文本、表格、图像以及跨文档数据等能力；（2）一个用于评估正确性的短语级别召回指标；（3）一个用于识别潜在管道幻觉的最近邻嵌入分类器；（4）对使用开源检索机制构建的2个管道和4个闭源基础模型的比较评估；（5）对正确性和幻觉指标一致性的第三方人工评估。

Result: 闭源管道在正确性和幻觉指标上明显优于开源管道，尤其是在依赖多模态和跨文档信息的问题上。人工评估表明，对于正确性和幻觉检测，指标的平均一致性分别为4.62和4.53（Likert量表1-5，5表示“非常同意”）。

Conclusion: 该研究提出的基准和评估结果为RAG管道的性能评估提供了有价值的参考，并揭示了闭源管道在处理复杂信息方面的优势。

Abstract: Retrieval-augmented generation (RAG) has emerged as a promising paradigm for
improving factual accuracy in large language models (LLMs). We introduce a
benchmark designed to evaluate RAG pipelines as a whole, evaluating a
pipeline's ability to ingest, retrieve, and reason about several modalities of
information, differentiating it from existing benchmarks that focus on
particular aspects such as retrieval. We present (1) a small, human-created
dataset of 93 questions designed to evaluate a pipeline's ability to ingest
textual data, tables, images, and data spread across these modalities in one or
more documents; (2) a phrase-level recall metric for correctness; (3) a
nearest-neighbor embedding classifier to identify potential pipeline
hallucinations; (4) a comparative evaluation of 2 pipelines built with
open-source retrieval mechanisms and 4 closed-source foundation models; and (5)
a third-party human evaluation of the alignment of our correctness and
hallucination metrics. We find that closed-source pipelines significantly
outperform open-source pipelines in both correctness and hallucination metrics,
with wider performance gaps in questions relying on multimodal and
cross-document information. Human evaluation of our metrics showed average
agreement of 4.62 for correctness and 4.53 for hallucination detection on a 1-5
Likert scale (5 indicating "strongly agree").

</details>


### [50] [DualResearch: Entropy-Gated Dual-Graph Retrieval for Answer Reconstruction](https://arxiv.org/abs/2510.08959)
*Jinxin Shi,Zongsheng Cao,Runmin Ma,Yusong Hu,Jie Zhou,Xin Li,Lei Bai,Liang He,Bo Zhang*

Main category: cs.AI

TL;DR: 提出 DualResearch，一个检索和融合框架，通过联合建模广度语义图和深度因果图来匹配工具密集型推理的认知结构，以解决深层研究框架中的问题。


<details>
  <summary>Details</summary>
Motivation: 深层研究框架存在上下文污染、证据支持不足和执行路径脆弱的问题。

Method: DualResearch 框架联合建模广度语义图（编码背景知识）和深度因果图（捕获执行过程），并使用层原生相关性函数、种子锚定的语义扩散和因果语义路径匹配。

Result: 在 HLE 和 GPQA 科学推理基准测试中，DualResearch 取得了有竞争力的性能。在使用 InternAgent 的日志文件时，其在 HLE 上的准确率提高了 7.7%，在 GPQA 上的准确率提高了 6.06%。

Conclusion: DualResearch 可以将冗长的多工具执行日志压缩成简洁的推理图，并能稳定有效地重建答案，作为深层研究系统的补充。

Abstract: The deep-research framework orchestrates external tools to perform complex,
multi-step scientific reasoning that exceeds the native limits of a single
large language model. However, it still suffers from context pollution, weak
evidentiary support, and brittle execution paths. To address these issues, we
propose DualResearch, a retrieval and fusion framework that matches the
epistemic structure of tool-intensive reasoning by jointly modeling two
complementary graphs: a breadth semantic graph that encodes stable background
knowledge, and a depth causal graph that captures execution provenance. Each
graph has a layer-native relevance function, seed-anchored semantic diffusion
for breadth, and causal-semantic path matching with reliability weighting for
depth. To reconcile their heterogeneity and query-dependent uncertainty,
DualResearch converts per-layer path evidence into answer distributions and
fuses them in log space via an entropy-gated rule with global calibration. The
fusion up-weights the more certain channel and amplifies agreement. As a
complement to deep-research systems, DualResearch compresses lengthy multi-tool
execution logs into a concise reasoning graph, and we show that it can
reconstruct answers stably and effectively. On the scientific reasoning
benchmarks HLE and GPQA, DualResearch achieves competitive performance. Using
log files from the open-source system InternAgent, its accuracy improves by
7.7% on HLE and 6.06% on GPQA.

</details>


### [51] [Semantic-Condition Tuning: Fusing Graph Context with Large Language Models for Knowledge Graph Completion](https://arxiv.org/abs/2510.08966)
*Ruitong Liu,Yan Wen,Te Sun,Yunjia Wu,Pingyang Huang,Zihang Yu,Siyuan Li*

Main category: cs.AI

TL;DR: 提出了一种新的知识注入范式，通过语义图模块和条件自适应融合模块，将知识图谱的语义信息融入到LLM中，以提升知识图谱补全等知识密集型任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的prefix-tuning方法忽略了知识图谱中丰富的关系语义，并对LLM提出了隐式的推理负担，影响了知识图谱补全的效果。

Method: 提出了语义条件调整(SCT)方法，包含语义图模块和条件自适应融合模块。语义图模块利用图神经网络提取上下文感知的语义条件，条件自适应融合模块自适应地调整文本嵌入。

Result: 在知识图谱基准测试中，SCT显著优于prefix-tuning和其他基线方法。

Conclusion: 通过在LLM推理之前用语义图上下文调制输入表示，SCT提供了一种更直接和有效的信号，从而实现更准确和鲁棒的知识推理。

Abstract: Fusing Knowledge Graphs with Large Language Models is crucial for
knowledge-intensive tasks like knowledge graph completion. The prevailing
paradigm, prefix-tuning, simply concatenates knowledge embeddings with text
inputs. However, this shallow fusion overlooks the rich relational semantics
within KGs and imposes a significant implicit reasoning burden on the LLM to
correlate the prefix with the text. To address these, we propose
Semantic-condition Tuning (SCT), a new knowledge injection paradigm comprising
two key modules. First, a Semantic Graph Module employs a Graph Neural Network
to extract a context-aware semantic condition from the local graph
neighborhood, guided by knowledge-enhanced relations. Subsequently, this
condition is passed to a Condition-Adaptive Fusion Module, which, in turn,
adaptively modulates the textual embedding via two parameterized projectors,
enabling a deep, feature-wise, and knowledge-aware interaction. The resulting
pre-fused embedding is then fed into the LLM for fine-tuning. Extensive
experiments on knowledge graph benchmarks demonstrate that SCT significantly
outperforms prefix-tuning and other strong baselines. Our analysis confirms
that by modulating the input representation with semantic graph context before
LLM inference, SCT provides a more direct and potent signal, enabling more
accurate and robust knowledge reasoning.

</details>


### [52] [Tiny-R1V: Lightweight Multimodal Unified Reasoning Model via Model Merging](https://arxiv.org/abs/2510.08987)
*Qixiang Yin,Huanjin Yao,Jianghao Chen,Jiaxing Huang,Zhicheng Zhao,Fei Su*

Main category: cs.AI

TL;DR: Tiny-R1V: A lightweight 3B model for faster and more accurate multimodal reasoning.


<details>
  <summary>Details</summary>
Motivation: Reasoning efficiency challenges (large model size, overthinking, accuracy compromise) in existing Multimodal Large Language Models (MLLMs), especially in lightweight scenarios.

Method: Two-stage optimization: 1) Length-Informed Relative Policy Optimization (LIPO) for concise and accurate responses. 2) Adaptive Model Merging (AMM) to merge specialist models into a unified architecture.

Result: Superior performance of Tiny-R1V on ten reasoning benchmarks (mathematics, structured data, OCR, general capabilities).

Conclusion: Tiny-R1V enables lightweight models to excel in diverse multimodal reasoning tasks.

Abstract: Although Multimodal Large Language Models (MLLMs) have demonstrated
remarkable capabilities across diverse tasks, they encounter numerous
challenges in terms of reasoning efficiency, such as large model size,
overthinking, and compromised accuracy in lightweight scenarios. However,
research on the reasoning capabilities of lightweight MLLMs is quite lacking.
To this end, we propose Tiny-R1V, a novel lightweight 3B model that achieves
faster inference and higher accuracy via a two-stage optimization, while
unifying multimodal reasoning across multiple tasks and using fewer tokens. In
the first stage, Tiny-R1V introduces Length-Informed Relative Policy
Optimization (LIPO), a novel reinforcement learning method, to train each
reasoning model. The LIPO is designed to dynamically adjusts advantages of
responses within groups, that is, by prioritizing concise yet high-quality
responses to encourage the generation of shorter and more accurate response. In
the second stage, we propose Adaptive Model Merging (AMM), a training-free
model merging method that merges multiple specialist models into a unified
architecture. Specifically, AMM adaptively adjusts the weights of task vectors
and robustly optimizes the merged vectors via a novel gradient projection
regularization loss function, thus mitigating redundant conflicts between them.
Extensive evaluations on ten widely-used reasoning benchmarks covering
mathematics, structured data (charts, tables, documents), OCR, and general
capabilities showcase the superior performance of Tiny-R1V, enabling
lightweight models to excel in diverse multimodal reasoning tasks.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [53] [Comparative Performance Analysis of Modern NoSQL Data Technologies: Redis, Aerospike, and Dragonfly](https://arxiv.org/abs/2510.08863)
*Deep Bodra,Sushil Khairnar*

Main category: cs.DB

TL;DR: 本文对三种NoSQL键值存储系统（Redis、Aerospike和Dragonfly）进行了性能评估。


<details>
  <summary>Details</summary>
Motivation: 随着分布式应用和云计算的兴起，对可扩展、高性能的键值存储系统的需求不断增长。

Method: 使用Yahoo! Cloud Serving Benchmark (YCSB) 框架，在三种不同的工作负载模式（读密集型、写密集型和平衡型）下，系统地改变客户端并发数（从 1 到 32 个客户端）进行了大量实验。

Result: 评估方法在实际操作条件下捕获了延迟、吞吐量和内存特性，从而深入了解了每个系统的性能权衡和可扩展性行为。

Conclusion: 根据摘要，论文对三种NoSQL数据库做了基准测试，并分析了不同场景下的性能表现。

Abstract: The rise of distributed applications and cloud computing has created a demand
for scalable, high-performance key-value storage systems. This paper presents a
performance evaluation of three prominent NoSQL key-value stores: Redis,
Aerospike, and Dragonfly, using the Yahoo! Cloud Serving Benchmark (YCSB)
framework. We conducted extensive experiments across three distinct workload
patterns (read-heavy, write-heavy), and balanced while systematically varying
client concurrency from 1 to 32 clients. Our evaluation methodology captures
both latency, throughput, and memory characteristics under realistic
operational conditions, providing insights into the performance trade-offs and
scalability behaviour of each system

</details>


### [54] [HES-SQL: Hybrid Reasoning for Efficient Text-to-SQL with Structural Skeleton Guidance](https://arxiv.org/abs/2510.08896)
*Suming Qiu,Jing Li,Zhicheng Zhou,Junjie Huang,Linyuan Qiu,Zhijie Sun*

Main category: cs.DB

TL;DR: HES-SQL: A hybrid training framework combining supervised fine-tuning and reinforcement learning for Text-to-SQL generation.


<details>
  <summary>Details</summary>
Motivation: To improve SQL query accuracy and efficiency by balancing semantic accuracy with computational efficiency.

Method: Integrating thinking-mode-fused supervised fine-tuning with Group Relative Policy Optimization, featuring skeleton-completeness scoring, query-latency-aware rewards, and self-distillation for thinking-mode completion.

Result: Achieves competitive performance on BIRD and KaggleDBQA benchmarks with execution accuracies of 79.14% and 54.9%, respectively, and efficiency gains of 11% to 20% relative to supervised baselines.

Conclusion: HES-SQL establishes a new paradigm for Text-to-SQL systems, balancing semantic accuracy and computational efficiency, with implications for natural language interfaces to databases and broader structured generation tasks.

Abstract: We present HES-SQL, a novel hybrid training framework that advances
Text-to-SQL generation through the integration of thinking-mode-fused
supervised fine-tuning (SFT) with Group Relative Policy Optimization (GRPO).
Our approach introduces three key innovations: (1) a skeleton-completeness
scoring mechanism that enhances preference alignment between generated queries
and optimal SQL structures; (2) a query-latency-aware reward system that
incentivizes the generation of computationally efficient SQL queries; (3) a
self-distillation process for thinking-mode completion that prevents
degradation of the model's reasoning capabilities. This framework enables
hybrid thinking models to switch between reasoning and non-reasoning modes
while improving SQL query accuracy and execution efficiency.
  Experimental evaluation, conducted on MySQL 8.0 and SQLite 3.42 under
controlled single-user conditions, demonstrates that HES-SQL achieves
competitive performance with execution accuracies of 79.14\% and 54.9\% on the
BIRD and KaggleDBQA benchmarks, respectively. Query latency is measured as the
end-to-end execution time of generated queries on the DBMS, averaged over
multiple runs to mitigate variance. Efficiency gains range from 11\% to 20\%
relative to supervised baselines. Our results establish a new paradigm for
Text-to-SQL systems that effectively balances semantic accuracy with
computational efficiency through execution-informed reinforcement learning
(RL). The proposed methodology has significant implications for developing
robust natural language interfaces to databases and can be extended to broader
structured generation tasks requiring both correctness and efficiency
optimization.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [55] [Personalize Before Retrieve: LLM-based Personalized Query Expansion for User-Centric Retrieval](https://arxiv.org/abs/2510.08935)
*Yingyi Zhang,Pengyue Jia,Derong Xu,Yi Wen,Xianneng Li,Yichao Wang,Wenlin Zhang,Xiaopeng Li,Weinan Gan,Huifeng Guo,Yong Liu,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 这篇论文提出了一种名为Personalize Before Retrieve (PBR) 的框架，用于解决检索增强生成 (RAG) 中 query expansion 的个性化问题。PBR 在检索前将用户特定信号融入到 query expansion 中，以解决用户表达方式多样性和用户语料库异构语义结构带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的 query expansion 方法采用统一策略，忽略了用户特定的语义，限制了 RAG 系统在个性化设置中的泛化能力。具体来说，用户表达方式多样，且用户语料库诱导出异构的语义结构。

Method: 该论文提出了 Personalize Before Retrieve (PBR) 框架，包含两个组成部分：P-PRF，它使用用户历史生成风格对齐的伪反馈，用于模拟用户表达风格；以及 P-Anchor，它对用户语料库执行基于图的结构对齐，以捕获其结构。

Result: 在两个个性化基准测试上的实验表明，PBR 始终优于强大的基线，在 PersonaBench 上，检索器的性能提升高达 10%。

Conclusion: 研究结果表明，在检索前对个性化进行建模对于缩小用户自适应 RAG 系统中的语义差距具有重要价值。

Abstract: Retrieval-Augmented Generation (RAG) critically depends on effective query
expansion to retrieve relevant information. However, existing expansion methods
adopt uniform strategies that overlook user-specific semantics, ignoring
individual expression styles, preferences, and historical context. In practice,
identical queries in text can express vastly different intentions across users.
This representational rigidity limits the ability of current RAG systems to
generalize effectively in personalized settings. Specifically, we identify two
core challenges for personalization: 1) user expression styles are inherently
diverse, making it difficult for standard expansions to preserve personalized
intent. 2) user corpora induce heterogeneous semantic structures-varying in
topical focus and lexical organization-which hinders the effective anchoring of
expanded queries within the user's corpora space. To address these challenges,
we propose Personalize Before Retrieve (PBR), a framework that incorporates
user-specific signals into query expansion prior to retrieval. PBR consists of
two components: P-PRF, which generates stylistically aligned pseudo feedback
using user history for simulating user expression style, and P-Anchor, which
performs graph-based structure alignment over user corpora to capture its
structure. Together, they produce personalized query representations tailored
for retrieval. Experiments on two personalized benchmarks show that PBR
consistently outperforms strong baselines, with up to 10% gains on PersonaBench
across retrievers. Our findings demonstrate the value of modeling
personalization before retrieval to close the semantic gap in user-adaptive RAG
systems. Our code is available at https://github.com/Zhang-Yingyi/PBR-code.

</details>


### [56] [SHERLOCK: Towards Dynamic Knowledge Adaptation in LLM-enhanced E-commerce Risk Management](https://arxiv.org/abs/2510.08948)
*Nan Lu,Yurong Hu,Jiaquan Fang,Yan Liu,Rui Dong,Yiming Wang,Rui Lin,Shaoyi Xu*

Main category: cs.IR

TL;DR: 提出 SHERLOCK 框架，利用大型语言模型 (LLM) 协助风险调查，提高效率。


<details>
  <summary>Details</summary>
Motivation: 电商发展加剧了影子经济行为者与风险管理团队之间的对抗，案件分析工作量大，分析师之间存在个体差异，难以建立统一的高标准工作流程。

Method: 该框架包含三个主要组成部分：(1) 从多模态数据中提取风险管理知识并构建领域知识库 (KB)，(2) 构建由数据飞轮范式指导的智能平台，整合日常运营、专家注释和模型评估，并通过迭代微调以进行偏好对齐，(3) 引入 Reflect & Refine (R&R) 模块，该模块与领域知识库 (KB) 协作，为不断变化的风险模式建立快速响应机制。

Result: 在 JD.com 的真实交易数据集上进行的实验表明，该方法显着提高了 LLM 分析结果中事实对齐和风险定位的准确性。

Conclusion: 在 JD.com 上部署基于 SHERLOCK 的 LLM 系统大大提高了风险管理人员的案件调查工作流程效率。

Abstract: The growth of the e-commerce industry has intensified the adversarial
dynamics between shadow economy actors and risk management teams. Companies
often conduct risk investigations into suspicious cases to identify emerging
fraud patterns, thereby enhancing both preemptive risk prevention and post-hoc
governance. However, the sheer volume of case analyses imposes a substantial
workload on risk management analysts, as each case requires the integration of
long-term expert experience and meticulous scrutiny across multiple risk
dimensions. Additionally, individual disparities among analysts hinder the
establishment of uniform and high-standard workflows. To address these
challenges, we propose the SHERLOCK framework, which leverages the reasoning
capabilities of large language models (LLMs) to assist analysts in risk
investigations. Our approach consists of three primary components: (1)
extracting risk management knowledge from multi-modal data and constructing a
domain knowledge base (KB), (2) building an intelligent platform guided by the
data flywheel paradigm that integrates daily operations, expert annotations,
and model evaluations, with iteratively fine-tuning for preference alignment,
and (3) introducing a Reflect & Refine (R&R) module that collaborates with the
domain KB to establish a rapid response mechanism for evolving risk patterns.
Experiments conducted on the real-world transaction dataset from JD.com
demonstrate that our method significantly improves the precision of both
factual alignment and risk localization within the LLM analysis results.
Deployment of the SHERLOCK-based LLM system on JD.com has substantially
enhanced the efficiency of case investigation workflows for risk managers.

</details>


### [57] [Rethinking Reasoning in Document Ranking: Why Chain-of-Thought Falls Short](https://arxiv.org/abs/2510.08985)
*Xuan Lu,Haohang Huang,Rui Meng,Yaohui Jin,Wenjun Zeng,Xiaoyu Shen*

Main category: cs.IR

TL;DR: 本文研究了在文档重排序任务中，将显式思维链（CoT）推理融入基于大型语言模型（LLM）的重排序器中的有效性。实验表明，尽管推理增强的重排序器具有更高的推理成本，但其性能始终不如直接预测排序的同类模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究开始将显式思维链推理融入基于LLM的重排序器中，但这种推理对于排序任务的有效性仍未得到充分探索。

Method: 本文在监督微调和强化学习下，对点式和列表式设置中的重排序推理进行了首次系统研究。使用了包括推理密集型数据集（BRIGHT）和标准IR基准（BEIR）在内的各种基准。

Result: 推理增强的重排序器始终不如没有CoT的直接对应模型，并且推理会打破校准，使模型偏向正类，从而增加假阳性并降低排序质量。此外，推理提高了域内拟合度，但增加了方差，并且无法推广到域外。

Conclusion: 显式推理并非普遍适用于重排序，直接微调的重排序器更稳定、有效和鲁棒。未来的方向包括点式重排序器的校准感知评分，以及简洁、有针对性的推理策略，以减轻列表式重排序器中的过度拟合和过度思考。

Abstract: Document reranking is a key component in information retrieval (IR), aimed at
refining initial retrieval results to improve ranking quality for downstream
tasks. Recent studies--motivated by large reasoning models (LRMs)--have begun
incorporating explicit chain-of-thought (CoT) reasoning into LLM-based
rerankers. However, the effectiveness of such reasoning for ranking tasks
remains underexplored. In this work, we present the first systematic study of
reasoning in reranking across both pointwise and listwise settings, under both
supervised fine-tuning and reinforcement learning. Using diverse benchmarks,
including reasoning-intensive datasets (BRIGHT) and standard IR benchmarks
(BEIR), we find that reasoning-augmented rerankers consistently underperform
their direct counterparts that predict rankings without CoT, despite
substantially higher inference costs. Our analysis reveals three core
limitations: (i) in pointwise rerankers, reasoning breaks calibration and
biases models toward the positive class, raising TPR but lowering TNR, which
inflates false positives and degrades ranking in negative-dominant pools; (ii)
in listwise rerankers, reasoning improves in-domain fit but increases variance
and fails to generalize out-of-domain, even when reinforcement learning
shortens rationales; and (iii) overall, directly fine-tuned rerankers remain
more stable, effective, and robust. These findings challenge the assumption
that explicit reasoning is universally beneficial for reranking. We conclude by
highlighting future directions, including calibration-aware scoring for
pointwise rerankers and the design of concise, targeted reasoning strategies to
mitigate overfitting and overthinking in listwise rerankers.

</details>


### [58] [Generative Data Augmentation in Graph Contrastive Learning for Recommendation](https://arxiv.org/abs/2510.09129)
*Yansong Wang,Qihui Lin,Junjie Huang,Tao Jia*

Main category: cs.IR

TL;DR: GDA4Rec: uses generative models for data augmentation in graph contrastive learning to improve recommendation systems.


<details>
  <summary>Details</summary>
Motivation: Learning effective embeddings from sparse user-item interactions is challenging in recommendation systems.

Method: A noise generation module leverages deep generative models to approximate the distribution of original data for data augmentation. An item complement matrix is extracted to characterize latent correlations between items. A joint objective integrates recommendation, data augmentation, and contrastive learning.

Result: Experiments on three public datasets demonstrate the model's superiority.

Conclusion: GDA4Rec generates high-quality augmented views and provides robust self-supervised signals for recommendation systems.

Abstract: Recommendation systems have become indispensable in various online platforms,
from e-commerce to streaming services. A fundamental challenge in this domain
is learning effective embeddings from sparse user-item interactions. While
contrastive learning has recently emerged as a promising solution to this
issue, generating augmented views for contrastive learning through most
existing random data augmentation methods often leads to the alteration of
original semantic information. In this paper, we propose a novel framework,
GDA4Rec (Generative Data Augmentation in graph contrastive learning for
Recommendation) to generate high-quality augmented views and provide robust
self-supervised signals. Specifically, we employ a noise generation module that
leverages deep generative models to approximate the distribution of original
data for data augmentation. Additionally, GDA4Rec further extracts an item
complement matrix to characterize the latent correlations between items and
provide additional self-supervised signals. Lastly, a joint objective that
integrates recommendation, data augmentation and contrastive learning is used
to enforce the model to learn more effective and informative embeddings.
Extensive experiments are conducted on three public datasets to demonstrate the
superiority of the model. The code is available at:
https://github.com/MrYansong/GDA4Rec.

</details>


### [59] [Controlled Personalization in Legacy Media Online Services: A Case Study in News Recommendation](https://arxiv.org/abs/2510.09136)
*Marlene Holzleitner,Stephan Leitner,Hanna Lind Jorgensen,Christoph Schmitz,Jacob Welander,Dietmar Jannach*

Main category: cs.IR

TL;DR: 传统新闻媒体在优化用户参与度的同时，谨慎地采用个性化新闻推荐，并将编辑策划内容与算法选择的文章相结合，我们称之为“受控个性化”。


<details>
  <summary>Details</summary>
Motivation: 传统新闻媒体希望在技术创新与核心编辑价值之间取得平衡，因此在个性化新闻推荐方面持谨慎态度。

Method: 通过在挪威一家大型传统新闻机构的网站上进行的 A/B 测试，评估受控个性化的有效性。

Result: 即使是适度的个性化也能带来显著的好处，点击率更高，导航工作量更少，内容多样性更大，受欢迎程度偏差更小。

Conclusion: 受控个性化可以成功地将用户需求与编辑目标结合起来，为传统媒体采用个性化技术同时坚持新闻价值提供了一条可行的途径。

Abstract: Personalized news recommendations have become a standard feature of large
news aggregation services, optimizing user engagement through automated content
selection. In contrast, legacy news media often approach personalization
cautiously, striving to balance technological innovation with core editorial
values. As a result, online platforms of traditional news outlets typically
combine editorially curated content with algorithmically selected articles - a
strategy we term controlled personalization. In this industry paper, we
evaluate the effectiveness of controlled personalization through an A/B test
conducted on the website of a major Norwegian legacy news organization. Our
findings indicate that even a modest level of personalization yields
substantial benefits. Specifically, we observe that users exposed to
personalized content demonstrate higher click-through rates and reduced
navigation effort, suggesting improved discovery of relevant content. Moreover,
our analysis reveals that controlled personalization contributes to greater
content diversity and catalog coverage and in addition reduces popularity bias.
Overall, our results suggest that controlled personalization can successfully
align user needs with editorial goals, offering a viable path for legacy media
to adopt personalization technologies while upholding journalistic values.

</details>


### [60] [Hierarchical Semantic RL: Tackling the Problem of Dynamic Action Space for RL-based Recommendations](https://arxiv.org/abs/2510.09167)
*Minmao Wang,Xingchen Liu,Shijie Yi,Likang Wu,Hongke Zhao,Fei Pan,Qingpeng Cai,Peng Jiang*

Main category: cs.IR

TL;DR: 提出了一种新的基于强化学习的推荐系统方法，称为分层语义强化学习 (HSRL)，该方法在固定的语义动作空间 (SAS) 上进行强化学习，以解决传统强化学习方法在推荐中面临的巨大动态动作空间的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统方法主要优化短期用户参与度，而基于强化学习的方法由于推荐中固有的巨大动态动作空间而面临挑战，这阻碍了稳定的策略学习。

Method: HSRL 将物品编码为语义 ID (SID) 以进行策略学习，并通过固定的可逆查找将 SID 映射回其原始物品。分层策略网络 (HPN) 以粗到精的方式运行，采用分层残差状态建模来细化每个级别的上下文。多级评论家 (MLC) 提供 token 级别的价值估计，从而实现细粒度的信用分配。

Result: 在公共基准和一个来自中国领先的短视频广告平台的大规模生产数据集上，HSRL 始终优于最先进的基线。在为期七天的 A/B 测试的在线部署中，它实现了 18.421% 的 CVR 提升，而成本仅增加了 1.251%。

Conclusion: HSRL 是一种可扩展的基于强化学习的推荐范例。

Abstract: Recommender Systems (RS) are fundamental to modern online services. While
most existing approaches optimize for short-term engagement, recent work has
begun to explore reinforcement learning (RL) to model long-term user value.
However, these efforts face significant challenges due to the vast, dynamic
action spaces inherent in recommendation, which hinder stable policy learning.
To resolve this bottleneck, we introduce Hierarchical Semantic RL (HSRL), which
reframes RL-based recommendation over a fixed Semantic Action Space (SAS). HSRL
encodes items as Semantic IDs (SIDs) for policy learning, and maps SIDs back to
their original items via a fixed, invertible lookup during execution. To align
decision-making with SID generation, the Hierarchical Policy Network (HPN)
operates in a coarse-to-fine manner, employing hierarchical residual state
modeling to refine each level's context from the previous level's residual,
thereby stabilizing training and reducing representation-decision mismatch. In
parallel, a Multi-level Critic (MLC) provides token-level value estimates,
enabling fine-grained credit assignment. Across public benchmarks and a
large-scale production dataset from a leading Chinese short-video advertising
platform, HSRL consistently surpasses state-of-the-art baselines. In online
deployment over a seven-day A/B testing, it delivers an 18.421% CVR lift with
only a 1.251% increase in cost, supporting HSRL as a scalable paradigm for
RL-based recommendation. Our code is released at
https://github.com/MinmaoWang/HSRL.

</details>


### [61] [ChoirRec: Semantic User Grouping via LLMs for Conversion Rate Prediction of Low-Activity Users](https://arxiv.org/abs/2510.09393)
*Dakai Zhai,Jiong Gao,Boya Du,Junwei Xu,Qijie Shen,Jialin Zhu,Yuning Jiang*

Main category: cs.IR

TL;DR: ChoirRec利用大型语言模型(LLM)构建语义用户组，以提高低活跃用户的转化率(CVR)预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于嘈杂且不可靠的行为信号；由于缺乏多样化的交互数据，用户级别的信息不足；以及对高活跃用户的系统性训练偏差掩盖了低活跃用户的需求。

Method: ChoirRec包含三个组件：(i)利用LLM形成可靠的跨活动用户集群的语义组生成模块，从而过滤掉噪声信号；(ii)使用信息丰富的组级别先验来丰富稀疏用户嵌入的组感知分层表示模块，以缓解数据不足；(iii)采用双通道架构和自适应融合机制的组感知多粒度模块，以确保有效学习和利用组知识。

Result: 离线评估中，ChoirRec将GAUC提高了1.16％，而在线A/B测试显示订单量增加了7.24％。

Conclusion: ChoirRec在实际应用中具有巨大的实用价值。

Abstract: Accurately predicting conversion rates (CVR) for low-activity users remains a
fundamental challenge in large-scale e-commerce recommender systems.Existing
approaches face three critical limitations: (i) reliance on noisy and
unreliable behavioral signals; (ii) insufficient user-level information due to
the lack of diverse interaction data; and (iii) a systemic training bias toward
high-activity users that overshadows the needs of low-activity users.To address
these challenges, we propose ChoirRec, a novel framework that leverages the
semantic capabilities of Large Language Models (LLMs) to construct semantic
user groups and enhance CVR prediction for low-activity users.With a
dual-channel architecture designed for robust cross-user knowledge transfer,
ChoirRec comprises three components: (i) a Semantic Group Generation module
that utilizes LLMs to form reliable, cross-activity user clusters, thereby
filtering out noisy signals; (ii) a Group-aware Hierarchical Representation
module that enriches sparse user embeddings with informative group-level priors
to mitigate data insufficiency; and (iii) a Group-aware Multi-granularity
Modual that employs a dual-channel architecture and adaptive fusion mechanism
to ensure effective learning and utilization of group knowledge. We conduct
extensive offline and online experiments on Taobao, a leading industrial-scale
e-commerce platform.ChoirRec improves GAUC by 1.16\% in offline evaluations,
while online A/B testing reveals a 7.24\% increase in order volume,
highlighting its substantial practical value in real-world applications.

</details>


### [62] [MRMR: A Realistic and Expert-Level Multidisciplinary Benchmark for Reasoning-Intensive Multimodal Retrieval](https://arxiv.org/abs/2510.09510)
*Siyue Zhang,Yuan Gao,Xiao Zhou,Yilun Zhao,Tingyu Song,Arman Cohan,Anh Tuan Luu,Chen Zhao*

Main category: cs.IR

TL;DR: 提出了一个新的多模态检索基准MRMR，它比以前的基准更具挑战性，需要更深入的推理。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态检索基准存在局限性，无法满足对专业领域和推理能力的需求。

Method: 构建了一个包含1502个查询的基准数据集，涵盖23个领域，并引入了矛盾检索任务。

Result: 对多种模型在MRMR上进行了评估，发现Qwen3-Embedding模型表现最佳，但所有模型在推理密集型任务上仍有提升空间。

Conclusion: MRMR为多模态检索的未来发展奠定了基础，尤其是在更真实和具有挑战性的场景中。

Abstract: We introduce MRMR, the first expert-level multidisciplinary multimodal
retrieval benchmark requiring intensive reasoning. MRMR contains 1,502 queries
spanning 23 domains, with positive documents carefully verified by human
experts. Compared to prior benchmarks, MRMR introduces three key advancements.
First, it challenges retrieval systems across diverse areas of expertise,
enabling fine-grained model comparison across domains. Second, queries are
reasoning-intensive, with images requiring deeper interpretation such as
diagnosing microscopic slides. We further introduce Contradiction Retrieval, a
novel task requiring models to identify conflicting concepts. Finally, queries
and documents are constructed as image-text interleaved sequences. Unlike
earlier benchmarks restricted to single images or unimodal documents, MRMR
offers a realistic setting with multi-image queries and mixed-modality corpus
documents. We conduct an extensive evaluation of 4 categories of multimodal
retrieval systems and 14 frontier models on MRMR. The text embedding model
Qwen3-Embedding with LLM-generated image captions achieves the highest
performance, highlighting substantial room for improving multimodal retrieval
models. Although latest multimodal models such as Ops-MM-Embedding perform
competitively on expert-domain queries, they fall short on reasoning-intensive
tasks. We believe that MRMR paves the way for advancing multimodal retrieval in
more realistic and challenging scenarios.

</details>


### [63] [Doc2Query++: Topic-Coverage based Document Expansion and its Application to Dense Retrieval via Dual-Index Fusion](https://arxiv.org/abs/2510.09557)
*Tzu-Lin Kuo,Wei-Ning Chiu,Wei-Yun Ma,Pu-Jen Cheng*

Main category: cs.IR

TL;DR: Doc2Query++ overcomes limitations of document expansion (DE) in retrieval by structuring query generation with latent topics and keyword selection, enhancing diversity and relevance, and introducing Dual-Index Fusion for improved dense retrieval performance.


<details>
  <summary>Details</summary>
Motivation: Document expansion via query generation suffers from uncontrolled generation, poor generalization, and noise, hindering sparse and dense retrieval performance.

Method: Doc2Query++ infers latent document topics, uses hybrid keyword selection for diverse and relevant keywords, and guides LLMs to generate queries based on these keywords. It also employs Dual-Index Fusion to isolate text and query signals in dense retrieval.

Result: Doc2Query++ significantly outperforms state-of-the-art baselines in MAP, nDCG@10, and Recall@100 across diverse datasets for both sparse and dense retrieval.

Conclusion: Doc2Query++ addresses the challenges of document expansion by structuring query generation, leading to substantial performance gains in both sparse and dense retrieval scenarios.

Abstract: Document expansion (DE) via query generation tackles vocabulary mismatch in
sparse retrieval, yet faces limitations: uncontrolled generation producing
hallucinated or redundant queries with low diversity; poor generalization from
in-domain training (e.g., MS MARCO) to out-of-domain data like BEIR; and noise
from concatenation harming dense retrieval. While Large Language Models (LLMs)
enable cross-domain query generation, basic prompting lacks control, and
taxonomy-based methods rely on domain-specific structures, limiting
applicability. To address these challenges, we introduce Doc2Query++, a DE
framework that structures query generation by first inferring a document's
latent topics via unsupervised topic modeling for cross-domain applicability,
then using hybrid keyword selection to create a diverse and relevant keyword
set per document. This guides LLM not only to leverage keywords, which ensure
comprehensive topic representation, but also to reduce redundancy through
diverse, relevant terms. To prevent noise from query appending in dense
retrieval, we propose Dual-Index Fusion strategy that isolates text and query
signals, boosting performance in dense settings. Extensive experiments show
Doc2Query++ significantly outperforms state-of-the-art baselines, achieving
substantial gains in MAP, nDCG@10 and Recall@100 across diverse datasets on
both sparse and dense retrieval.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [64] [RFOD: Random Forest-based Outlier Detection for Tabular Data](https://arxiv.org/abs/2510.08747)
*Yihao Ang,Peicheng Yao,Yifan Bao,Yushuo Feng,Qiang Huang,Anthony K. H. Tung,Zhiyong Huang*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的基于随机森林的异常检测框架，专门用于表格数据。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在处理混合类型表格数据时存在困难，并且缺乏可解释性。

Method: 该方法将异常检测重新定义为特征条件重建问题，并为每个特征训练专门的随机森林。它结合了调整后的Gower距离（AGD）用于单元级别的评分，以及不确定性加权平均（UWA）来聚合单元级别的分数。

Result: 在15个真实世界数据集上的大量实验表明，RFOD在检测精度方面始终优于最先进的基线，同时为混合类型表格数据提供卓越的鲁棒性、可扩展性和可解释性。

Conclusion: RFOD是一种有效的异常检测方法，特别适用于混合类型表格数据。

Abstract: Outlier detection in tabular data is crucial for safeguarding data integrity
in high-stakes domains such as cybersecurity, financial fraud detection, and
healthcare, where anomalies can cause serious operational and economic impacts.
Despite advances in both data mining and deep learning, many existing methods
struggle with mixed-type tabular data, often relying on encoding schemes that
lose important semantic information. Moreover, they frequently lack
interpretability, offering little insight into which specific values cause
anomalies. To overcome these challenges, we introduce \textsf{\textbf{RFOD}}, a
novel \textsf{\textbf{R}}andom \textsf{\textbf{F}}orest-based
\textsf{\textbf{O}}utlier \textsf{\textbf{D}}etection framework tailored for
tabular data. Rather than modeling a global joint distribution, \textsf{RFOD}
reframes anomaly detection as a feature-wise conditional reconstruction
problem, training dedicated random forests for each feature conditioned on the
others. This design robustly handles heterogeneous data types while preserving
the semantic integrity of categorical features. To further enable precise and
interpretable detection, \textsf{RFOD} combines Adjusted Gower's Distance (AGD)
for cell-level scoring, which adapts to skewed numerical data and accounts for
categorical confidence, with Uncertainty-Weighted Averaging (UWA) to aggregate
cell-level scores into robust row-level anomaly scores. Extensive experiments
on 15 real-world datasets demonstrate that \textsf{RFOD} consistently
outperforms state-of-the-art baselines in detection accuracy while offering
superior robustness, scalability, and interpretability for mixed-type tabular
data.

</details>


### [65] [Cross-Representation Benchmarking in Time-Series Electronic Health Records for Clinical Outcome Prediction](https://arxiv.org/abs/2510.09159)
*Tianyi Chen,Mingcheng Zhu,Zhiyao Luo,Tingting Zhu*

Main category: cs.LG

TL;DR: 系统地比较了电子病历（EHR）表示方法，包括多元时间序列、事件流和LLM的文本事件流，并提供在不同临床环境中选择EHR表示的实践指导。


<details>
  <summary>Details</summary>
Motivation: 由于不一致的评估实践，用于临床预测的最佳患者数据表示方法仍不清楚。

Method: 通过统一和可重复的pipeline，在两个不同的临床环境中标准化数据管理和评估：用于ICU任务的MIMIC-IV数据集和用于纵向护理的EHRSHOT数据集。针对每种范例，评估合适的建模家族，并分析基于数据缺失的特征修剪的影响。

Result: 事件流模型始终提供最强大的性能。像CLMBR这样的预训练模型在少样本设置中具有很高的样本效率，但如果给定足够的数据，则更简单的基于计数的模型可能具有竞争力。特征选择策略必须适应临床环境：修剪稀疏特征可改善ICU预测，而保留它们对于纵向任务至关重要。

Conclusion: 根据临床背景和数据方案，为选择EHR表示提供实用指导。

Abstract: Electronic Health Records (EHRs) enable deep learning for clinical
predictions, but the optimal method for representing patient data remains
unclear due to inconsistent evaluation practices. We present the first
systematic benchmark to compare EHR representation methods, including
multivariate time-series, event streams, and textual event streams for LLMs.
This benchmark standardises data curation and evaluation across two distinct
clinical settings: the MIMIC-IV dataset for ICU tasks (mortality, phenotyping)
and the EHRSHOT dataset for longitudinal care (30-day readmission, 1-year
pancreatic cancer). For each paradigm, we evaluate appropriate modelling
families--including Transformers, MLP, LSTMs and Retain for time-series, CLMBR
and count-based models for event streams, 8-20B LLMs for textual streams--and
analyse the impact of feature pruning based on data missingness. Our
experiments reveal that event stream models consistently deliver the strongest
performance. Pre-trained models like CLMBR are highly sample-efficient in
few-shot settings, though simpler count-based models can be competitive given
sufficient data. Furthermore, we find that feature selection strategies must be
adapted to the clinical setting: pruning sparse features improves ICU
predictions, while retaining them is critical for longitudinal tasks. Our
results, enabled by a unified and reproducible pipeline, provide practical
guidance for selecting EHR representations based on the clinical context and
data regime.

</details>


### [66] [Energy-Driven Steering: Reducing False Refusals in Large Language Models](https://arxiv.org/abs/2510.08646)
*Eric Hanchen Jiang,Weixuan Ou,Run Liu,Shengyuan Pang,Guancheng Wan,Ranjie Duan,Wei Dong,Kai-Wei Chang,XiaoFeng Wang,Ying Nian Wu,Xinfeng Li*

Main category: cs.LG

TL;DR: 提出了一种名为能量驱动控制（EDS）的框架，旨在提高大型语言模型的安全性，同时减少错误拒绝率。


<details>
  <summary>Details</summary>
Motivation: 当前的安全对齐技术通常只关注提高模型对有害提示的安全性，导致LLM变得过度谨慎，拒绝响应良性提示。因此，安全对齐的一个关键目标是增强安全性的同时减少错误拒绝。

Method: 训练一个轻量级的、外部的基于能量的模型（EBM），EBM将LLM的内部激活映射到一个“能量 landscape”，并使用能量函数的梯度来动态地将LLM的隐藏状态引导到低能量区域，从而实时纠正模型以生成期望的响应，而无需修改其权重。

Result: 在广泛的模型上进行的大量实验表明，该方法成功地实现了这一目标：它大大降低了错误拒绝率。例如，在ORB-H基准测试中，合规性从57.3%提高到82.6%，同时保持了基线安全性能。

Conclusion: 这项工作为构建既具有低错误拒绝率又具有高安全性的LLM提供了一个有效的范例。

Abstract: Safety alignment of large language models (LLMs) faces a key challenge:
current alignment techniques often only focus on improving safety against
harmful prompts, causing LLMs to become over-cautious and refuse to respond to
benign prompts. Therefore, a key objective of safe alignment is to enhance
safety while simultaneously reducing false refusals. In this paper, we
introduce Energy-Driven Steering (EDS), a novel, fine-tuning free framework
designed to resolve this challenge through dynamic, inference-time
intervention. We trained a lightweight, external Energy-Based Model (EBM) to
assign high energy to undesirable (false refusal or jailbreak) states and low
energy to desirable (helpful response or safe reject) ones. During inference,
EBM maps the LLM's internal activations to an "energy landscape". We use the
gradient of the energy function to dynamically steer the LLM's hidden states to
low energy regions, correcting the model to generate a desirable response in
real-time without modifying its weights. This method decouples behavioral
control from the model's core knowledge, offering a flexible solution with
minimal computational overhead. Extensive experiments across a wide range of
models show our method successfully achieves this objective: it substantially
lowers false refusal rates. For example, raising compliance on the ORB-H
benchmark from 57.3% to 82.6% while maintaining the baseline safety
performance. Our work presents an effective paradigm for building LLMs that
achieve both low false refusal rates and high safety.

</details>


### [67] [Inverse-Free Wilson Loops for Transformers: A Practical Diagnostic for Invariance and Order Sensitivity](https://arxiv.org/abs/2510.08648)
*Edward Y. Chang,Ethan Y. Chang*

Main category: cs.LG

TL;DR: 大型语言模型在实际应用中，会在无害的编辑下改变答案。我们提出了WILSON，一个最小的事后诊断套件，它可以将内部表征的简单循环和重新排序检查转换为系统信号。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型未能保持预期不变性，打破了持续集成，并迫使团队在安全性和速度之间进行权衡。

Method: 我们提出了WILSON，它结合了使用JVPs和Hutchinson probes计算的位置和层上的无逆曲率图，以及标记重新排序风险的激活水平换向器。

Result: WILSON的信号计算成本低廉，对标准Transformer具有模型无关性，并导出为编排器的阈值和CSV工件。

Conclusion: WILSON有助于预测故障并批准安全优化，从而可以在不更改模型架构或训练的情况下，同时提高可靠性和吞吐量。

Abstract: Large language models can change answers under harmless edits that matter in
practice: RAG outputs flip when passages are reordered, fine-tuning erodes
invariances learned at pretraining, debate or chain-of-thought prompts take
path-dependent routes, and compiler fusion or reordering perturbs logits near
decision boundaries. These failures violate intended invariances, break
continuous integration, and force teams to trade safety for speed. The effects
are small yet distributed across layers and positions, sensitive to context
length and evaluation order, and costly to repair with retraining or formal
verification. We present WILSON, a minimal post-hoc diagnostic suite that
converts simple loop and reordering checks on internal representations into
system signals. WILSON combines an inverse-free curvature map over positions
and layers, computed with JVPs and Hutchinson probes, with activation-level
commutators that flag reorder risk. Signals are cheap to compute,
model-agnostic for standard Transformers, and exported as thresholds and CSV
artifacts for orchestrators. This enables concrete actions: guard RAG against
order effects, catch fine-tuning regressions, stabilize debate pathways and
long multi-turn contexts, and gate fusions or reorders in deployment. In short,
WILSON helps anticipate failures and approve safe optimizations so reliability
and throughput can improve together without changing model architecture or
training.

</details>


### [68] [Knowledge Graph Sparsification for GNN-based Rare Disease Diagnosis](https://arxiv.org/abs/2510.08655)
*Premt Cara,Kamilia Zaripova,David Bani-Harouni,Nassir Navab,Azade Farshad*

Main category: cs.LG

TL;DR: RareNet is a subgraph-based GNN that uses patient phenotypes to predict causal genes for rare genetic diseases, addressing limitations of data scarcity and inaccessible sequencing.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome challenges in rare genetic disease diagnosis due to insufficient patient data, inaccessible full genome sequencing, and a large number of possible causative genes, which leads to delays and inappropriate treatments, especially in resource-limited settings.

Method: RareNet, a subgraph-based Graph Neural Network, uses only patient phenotypes to identify the most likely causal gene and retrieve focused patient subgraphs.

Result: RareNet demonstrates competitive and robust causal gene prediction and significant performance gains when integrated with other frameworks on two biomedical datasets.

Conclusion: RareNet democratizes access to sophisticated genetic analysis by requiring only phenotypic data, offering particular value for underserved populations.

Abstract: Rare genetic disease diagnosis faces critical challenges: insufficient
patient data, inaccessible full genome sequencing, and the immense number of
possible causative genes. These limitations cause prolonged diagnostic
journeys, inappropriate treatments, and critical delays, disproportionately
affecting patients in resource-limited settings where diagnostic tools are
scarce. We propose RareNet, a subgraph-based Graph Neural Network that requires
only patient phenotypes to identify the most likely causal gene and retrieve
focused patient subgraphs for targeted clinical investigation. RareNet can
function as a standalone method or serve as a pre-processing or post-processing
filter for other candidate gene prioritization methods, consistently enhancing
their performance while potentially enabling explainable insights. Through
comprehensive evaluation on two biomedical datasets, we demonstrate competitive
and robust causal gene prediction and significant performance gains when
integrated with other frameworks. By requiring only phenotypic data, which is
readily available in any clinical setting, RareNet democratizes access to
sophisticated genetic analysis, offering particular value for underserved
populations lacking advanced genomic infrastructure.

</details>


### [69] [Inner-Instance Normalization for Time Series Forecasting](https://arxiv.org/abs/2510.08657)
*Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen*

Main category: cs.LG

TL;DR: 提出了一种新的时间序列预测方法，通过解决实例内部的分布偏移来提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的时间序列受多种因素影响，表现出复杂的非平稳特性，导致分布偏移，从而对模型性能产生负面影响。现有方法未能考虑单个实例内部的偏移。

Method: 提出了两种新的点级方法：学习分布（LD）和学习条件分布（LCD）。LD通过在不同时间步长使用不同的参数拟合输入和输出的内部分布来消除内部差异，而LCD利用神经网络来预测输出的缩放系数。

Result: 在公共基准数据集上，使用各种骨干模型评估了这两种方法的性能，并通过比较实验证明了点级范式的有效性。

Conclusion: 提出的点级方法可以有效解决时间序列预测中的实例内部分布偏移问题，提高模型性能。

Abstract: Real-world time series are influenced by numerous factors and exhibit complex
non-stationary characteristics. Non-stationarity can lead to distribution
shifts, where the statistical properties of time series change over time,
negatively impacting model performance. Several instance normalization
techniques have been proposed to address distribution shifts in time series
forecasting. However, existing methods fail to account for shifts within
individual instances, leading to suboptimal performance. To tackle
inner-instance distribution shifts, we propose two novel point-level methods:
Learning Distribution (LD) and Learning Conditional Distribution (LCD). LD
eliminates internal discrepancies by fitting the internal distribution of input
and output with different parameters at different time steps, while LCD
utilizes neural networks to predict scaling coefficients of the output. We
evaluate the performance of the two methods with various backbone models across
public benchmarks and demonstrate the effectiveness of the point-level paradigm
through comparative experiments.

</details>


### [70] [Provably Robust Adaptation for Language-Empowered Foundation Models](https://arxiv.org/abs/2510.08659)
*Yuni Lai,Xiaoyu Xue,Linghui Shen,Yulun Wu,Gaolei Li,Song Guo,Kai Zhou,Bin Xiao*

Main category: cs.LG

TL;DR: This paper introduces LeFCert, a provably robust few-shot classifier for language-empowered foundation models (LeFMs), which addresses vulnerability to poisoning attacks. It also introduces two variants LeFCert-L and LeFCert-C to enhance performance under different attack scenarios.


<details>
  <summary>Details</summary>
Motivation: Existing LeFMs are vulnerable to poisoning attacks due to their reliance on small, task-specific support datasets. Current defenses lack formal guarantees. Certified robustness is largely unexplored for few-shot classifiers based on LeFMs.

Method: The paper proposes LeFCert, which integrates textual and feature embeddings with an adaptive blending mechanism. It uses a twofold trimmed mean prototype and derives provable upper and lower bounds for classification scores. LeFCert-L incorporates randomized smoothing, and LeFCert-C provides collective certification.

Result: LeFCert achieves state-of-the-art performance, significantly improving both clean and certified accuracy compared to existing baselines. It is also computationally efficient.

Conclusion: LeFCert provides a practical and robust solution for few-shot classification with LeFMs, addressing the vulnerability to poisoning attacks with provable guarantees and computational efficiency.

Abstract: Language-empowered foundation models (LeFMs), such as CLIP and GraphCLIP,
have transformed multimodal learning by aligning visual (or graph) features
with textual representations, enabling powerful downstream capabilities like
few-shot learning. However, the reliance on small, task-specific support
datasets collected in open environments exposes these models to poisoning
attacks, where adversaries manipulate the support samples to degrade
performance. Existing defenses rely on empirical strategies, which lack formal
guarantees and remain vulnerable to unseen and adaptive attacks. Certified
robustness offers provable guarantees but has been largely unexplored for
few-shot classifiers based on LeFMs. This study seeks to fill these critical
gaps by proposing the first provably robust few-shot classifier that is
tailored for LeFMs. We term our model Language-empowered Few-shot Certification
(\textbf{LeFCert}). It integrates both textual and feature embeddings with an
adaptive blending mechanism. To achieve provable robustness, we propose a
twofold trimmed mean prototype and derive provable upper and lower bounds for
classification scores, enabling certification under worst-case poisoning
scenarios. To further enhance the performance, we extend LeFCert with two
variants by considering a more realistic and tighter attack budget: LeFCert-L
incorporates randomized smoothing to provide Lipschitz continuity and derive
robustness under dual budget constraints, and LeFCert-C provides collective
certification for scenarios where attackers distribute a shared poisoning
budget across multiple samples. Experiments demonstrate that LeFCert achieves
state-of-the-art performance, significantly improving both clean and certified
accuracy compared to existing baselines. Despite its advanced robustness
mechanisms, LeFCert is computationally efficient, making it practical for
real-world applications.

</details>


### [71] [How Scale Breaks "Normalized Stress" and KL Divergence: Rethinking Quality Metrics](https://arxiv.org/abs/2510.08660)
*Kiran Smelser,Kaviru Gunaratne,Jacob Miller,Stephen Kobourov*

Main category: cs.LG

TL;DR: 本文研究了高维数据降维后散点图的质量评估问题，发现常用指标（如 normalized stress 和 KL 散度）对投影的均匀缩放敏感。本文分析了缩放对这些指标的影响，并提出了一种使它们尺度不变的简单技术。


<details>
  <summary>Details</summary>
Motivation: 研究动机是现有的降维散点图质量评估指标对投影的缩放敏感，影响评估的准确性。

Method: 通过分析和实验，研究缩放对 normalized stress 和 KL 散度的影响，并提出一种使这两个指标尺度不变的技术。

Result: 结果表明，提出的尺度不变技术能够准确捕捉到小规模基准测试中的预期行为。

Conclusion: 结论是现有的质量评估指标对尺度敏感，本文提出的方法可以解决这个问题，提高评估的准确性。

Abstract: Complex, high-dimensional data is ubiquitous across many scientific
disciplines, including machine learning, biology, and the social sciences. One
of the primary methods of visualizing these datasets is with two-dimensional
scatter plots that visually capture some properties of the data. Because
visually determining the accuracy of these plots is challenging, researchers
often use quality metrics to measure the projection's accuracy and faithfulness
to the original data. One of the most commonly employed metrics, normalized
stress, is sensitive to uniform scaling (stretching, shrinking) of the
projection, despite this act not meaningfully changing anything about the
projection. Another quality metric, the Kullback--Leibler (KL) divergence used
in the popular t-Distributed Stochastic Neighbor Embedding (t-SNE) technique,
is also susceptible to this scale sensitivity. We investigate the effect of
scaling on stress and KL divergence analytically and empirically by showing
just how much the values change and how this affects dimension reduction
technique evaluations. We introduce a simple technique to make both metrics
scale-invariant and show that it accurately captures expected behavior on a
small benchmark.

</details>


### [72] [CATS-Linear: Classification Auxiliary Linear Model for Time Series Forecasting](https://arxiv.org/abs/2510.08661)
*Zipo Jibao,Yingyi Fu,Xinyang Chen,Guoting Chen*

Main category: cs.LG

TL;DR: 本文提出了一种名为CATS-Linear的线性模型，该模型通过分类将不同的时间序列实例动态路由到专用预测器，从而实现监督通道设计。


<details>
  <summary>Details</summary>
Motivation: 线性模型在预测方面表现出色，但增强线性模型的方法仍有待探索。本文的动机是不同的时间序列实例可能遵循不同的线性映射。

Method: 该模型采用分类辅助通道独立性(CACI)，通过分类将实例动态路由到专用预测器。此外，还重新设计了趋势季节分解架构，为趋势分量添加了解耦-线性映射-重耦框架，为季节分量添加了复域线性投影。

Result: 大量实验表明，CATS-Linear在固定超参数的情况下，实现了与超参数调整基线相当的最新准确率，同时提供了针对固定超参数同行的SOTA准确率。

Conclusion: CATS-Linear模型在固定超参数下实现了最先进的精度，与经过超参数调整的基线相当。

Abstract: Recent research demonstrates that linear models achieve forecasting
performance competitive with complex architectures, yet methodologies for
enhancing linear models remain underexplored. Motivated by the hypothesis that
distinct time series instances may follow heterogeneous linear mappings, we
propose the Classification Auxiliary Trend-Seasonal Decoupling Linear Model
CATS-Linear, employing Classification Auxiliary Channel-Independence (CACI).
CACI dynamically routes instances to dedicated predictors via classification,
enabling supervised channel design. We further analyze the theoretical expected
risks of different channel settings. Additionally, we redesign the
trend-seasonal decomposition architecture by adding a decoupling -- linear
mapping -- recoupling framework for trend components and complex-domain linear
projections for seasonal components. Extensive experiments validate that
CATS-Linear with fixed hyperparameters achieves state-of-the-art accuracy
comparable to hyperparameter-tuned baselines while delivering SOTA accuracy
against fixed-hyperparameter counterparts.

</details>


### [73] [DPCformer: An Interpretable Deep Learning Model for Genomic Prediction in Crops](https://arxiv.org/abs/2510.08662)
*Pengcheng Deng,Kening Liu,Mengxi Zhou,Mingxi Li,Rui Yang,Chuzhe Cao,Maojun Wang,Zeyu Zhang*

Main category: cs.LG

TL;DR: DPCformer, a deep learning model, enhances genomic selection accuracy for complex traits across multiple crops.


<details>
  <summary>Details</summary>
Motivation: Traditional genomic selection methods struggle with prediction accuracy for complex traits and large datasets.

Method: A deep learning model integrating convolutional neural networks with a self-attention mechanism is used to model complex genotype-phenotype relationships. An 8-dimensional one-hot encoding for SNP data, ordered by chromosome, and the PMF algorithm for feature selection are employed.

Result: DPCformer outperforms existing methods, with accuracy improvements up to 2.92% in maize, 8.37% in cotton, 57.35% in tomato, and 16.62% in chickpea.

Conclusion: DPCformer demonstrates superior accuracy, robustness in small-sample scenarios, and enhanced interpretability, providing a powerful tool for precision breeding and addressing global food security challenges.

Abstract: Genomic Selection (GS) uses whole-genome information to predict crop
phenotypes and accelerate breeding. Traditional GS methods, however, struggle
with prediction accuracy for complex traits and large datasets. We propose
DPCformer, a deep learning model integrating convolutional neural networks with
a self-attention mechanism to model complex genotype-phenotype relationships.
We applied DPCformer to 13 traits across five crops (maize, cotton, tomato,
rice, chickpea). Our approach uses an 8-dimensional one-hot encoding for SNP
data, ordered by chromosome, and employs the PMF algorithm for feature
selection. Evaluations show DPCformer outperforms existing methods. In maize
datasets, accuracy for traits like days to tasseling and plant height improved
by up to 2.92%. For cotton, accuracy gains for fiber traits reached 8.37%. On
small-sample tomato data, the Pearson Correlation Coefficient for a key trait
increased by up to 57.35%. In chickpea, the yield correlation was boosted by
16.62%. DPCformer demonstrates superior accuracy, robustness in small-sample
scenarios, and enhanced interpretability, providing a powerful tool for
precision breeding and addressing global food security challenges.

</details>


### [74] [FreqCa: Accelerating Diffusion Models via Frequency-Aware Caching](https://arxiv.org/abs/2510.08669)
*Jiacheng Liu,Peiliang Cai,Qinming Zhou,Yuqi Lin,Deyang Kong,Benhao Huang,Yupei Pan,Haowen Xu,Chang Zou,Junshu Tang,Shikang Zheng,Linfeng Zhang*

Main category: cs.LG

TL;DR: 提出了一种新的频率感知缓存（FreqCa）方法，以解决扩散Transformer中的推理成本问题。该方法通过重用低频分量的特征并使用Hermite插值器预测高频分量，同时缓存累积残差特征（CRF）以减少内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有的特征缓存方法假设相邻时间步的特征相似或连续，但这在所有情况下并不成立。本文通过频域分析发现，扩散模型中特征的不同频段在时间步上表现出不同的动态特性。低频分量相似度高但连续性差，而高频分量连续性好但相似度差。

Method: 提出了频率感知缓存（FreqCa），它基于相似性直接重用低频分量的特征，并使用二阶Hermite插值器基于连续性预测高频分量。此外，还提出了缓存累积残差特征（CRF）以减少内存占用。

Result: 在FLUX.1-dev, FLUX.1-Kontext-dev, Qwen-Image, 和Qwen-Image-Edit上的大量实验表明了该方法在生成和编辑方面的有效性。

Conclusion: 通过频率分析，提出了FreqCa方法，有效降低了推理成本并减少了内存占用，同时在图像生成和编辑任务中表现出色。

Abstract: The application of diffusion transformers is suffering from their significant
inference costs. Recently, feature caching has been proposed to solve this
problem by reusing features from previous timesteps, thereby skipping
computation in future timesteps. However, previous feature caching assumes that
features in adjacent timesteps are similar or continuous, which does not always
hold in all settings. To investigate this, this paper begins with an analysis
from the frequency domain, which reveal that different frequency bands in the
features of diffusion models exhibit different dynamics across timesteps.
Concretely, low-frequency components, which decide the structure of images,
exhibit higher similarity but poor continuity. In contrast, the high-frequency
bands, which decode the details of images, show significant continuity but poor
similarity. These interesting observations motivate us to propose
Frequency-aware Caching (FreqCa)
  which directly reuses features of low-frequency components based on their
similarity, while using a second-order Hermite interpolator to predict the
volatile high-frequency ones based on its continuity.
  Besides, we further propose to cache Cumulative Residual Feature (CRF)
instead of the features in all the layers, which reduces the memory footprint
of feature caching by 99%.
  Extensive experiments on FLUX.1-dev, FLUX.1-Kontext-dev, Qwen-Image, and
Qwen-Image-Edit demonstrate its effectiveness in both generation and editing.
Codes are available in the supplementary materials and will be released on
GitHub.

</details>


### [75] [Don't Waste Mistakes: Leveraging Negative RL-Groups via Confidence Reweighting](https://arxiv.org/abs/2510.08696)
*Yunzhen Feng,Parag Jain,Anthony Hartshorn,Yaqi Duan,Julia Kempe*

Main category: cs.LG

TL;DR: 提出了 LENS 方法，通过置信度加权惩罚错误答案，使负样本组也能提供有用的梯度更新，从而提升 RLVR 的效率和性能。


<details>
  <summary>Details</summary>
Motivation: GRPO 在负样本组上浪费了大量计算资源，因为负样本组中没有正确的回复，不会产生梯度。

Method: 从奖励建模中的最大似然估计 (MLE) 目标出发，推导出 MLE 梯度等价于一个修正价值函数的策略梯度。该价值函数对不正确的回复增加了一个置信度加权惩罚。

Result: 在 MATH 基准测试中，LENS 始终优于 GRPO 基线，并且在更难的项目上获得了显著的收益。

Conclusion: LENS 提供了一种有效且实用的方法来“拯救”负样本组，从而提高 RLVR 的效率和性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has become a standard
recipe for improving large language models (LLMs) on reasoning tasks, with
Group Relative Policy Optimization (GRPO) widely used in practice. Yet GRPO
wastes substantial compute on negative groups: groups in which no sampled
response is correct yield zero advantage and thus no gradient. We ask whether
negative groups can be leveraged without extra supervision. Starting from a
maximum-likelihood (MLE) objective in reward modeling, we show that the MLE
gradient is equivalent to a policy gradient for a modified value function. This
value function adds a confidence-weighted penalty on incorrect responses,
imposing larger penalties on more confident mistakes. We refer to this as
\textbf{L}ikelihood \textbf{E}stimation with \textbf{N}egative \textbf{S}amples
(\textbf{LENS}). LENS modifies GRPO to assign non-zero, confidence-dependent
rewards to incorrect generations, making negative groups informative and
converting previously wasted samples into useful gradient updates. On the MATH
benchmark with Llama-3.1-8B and Qwen-2.5-3B, the proposed variant consistently
outperforms GRPO baseline, with significant gains on harder items. These
results demonstrate a principled and practical way to "rescue" negative groups,
improving efficiency and performance in RLVR.

</details>


### [76] [MATT-CTR: Unleashing a Model-Agnostic Test-Time Paradigm for CTR Prediction with Confidence-Guided Inference Paths](https://arxiv.org/abs/2510.08932)
*Moyu Zhang,Yun Chen,Yujun Jin,Jinxin Hu,Yu Zhang,Xiaoyi Zeng*

Main category: cs.LG

TL;DR: 提出了一种与模型无关的测试时间范式 (MATT)，通过置信度分数引导生成多个推理路径，从而减轻低置信度特征对最终预测的影响。


<details>
  <summary>Details</summary>
Motivation: 以往的研究主要集中在训练阶段的优化，而忽略了推理阶段的优化机会。不常出现的特征组合会降低预测性能，导致不可靠或低置信度的输出。

Method: 利用分层概率哈希方法来估计各种阶数的特征组合的出现频率，以此作为置信度分数。然后，使用置信度分数作为抽样概率，通过迭代抽样生成多个特定于实例的推理路径，并聚合来自多个路径的预测分数以进行稳健的预测。

Result: 大量的离线实验和在线 A/B 测试强烈验证了 MATT 在现有 CTR 模型中的兼容性和有效性。

Conclusion: MATT 能够解锁已训练的 CTR 模型的预测潜力。

Abstract: Recently, a growing body of research has focused on either optimizing CTR
model architectures to better model feature interactions or refining training
objectives to aid parameter learning, thereby achieving better predictive
performance. However, previous efforts have primarily focused on the training
phase, largely neglecting opportunities for optimization during the inference
phase. Infrequently occurring feature combinations, in particular, can degrade
prediction performance, leading to unreliable or low-confidence outputs. To
unlock the predictive potential of trained CTR models, we propose a
Model-Agnostic Test-Time paradigm (MATT), which leverages the confidence scores
of feature combinations to guide the generation of multiple inference paths,
thereby mitigating the influence of low-confidence features on the final
prediction. Specifically, to quantify the confidence of feature combinations,
we introduce a hierarchical probabilistic hashing method to estimate the
occurrence frequencies of feature combinations at various orders, which serve
as their corresponding confidence scores. Then, using the confidence scores as
sampling probabilities, we generate multiple instance-specific inference paths
through iterative sampling and subsequently aggregate the prediction scores
from multiple paths to conduct robust predictions. Finally, extensive offline
experiments and online A/B tests strongly validate the compatibility and
effectiveness of MATT across existing CTR models.

</details>


### [77] [In-Context Learning for Non-Stationary MIMO Equalization](https://arxiv.org/abs/2510.08711)
*Jiachen Jiang,Zhen Qin,Zhihui Zhu*

Main category: cs.LG

TL;DR: 本文研究了上下文学习（ICL）在非静态信道均衡中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有的ICL均衡器主要针对静态信道，且缺乏对非静态问题的理论分析。

Method: 利用自适应信号处理算法设计高效的注意力机制，以提高在非静态任务中的适应性。

Result: 实验结果表明，ICL在非静态MIMO均衡中具有潜力，受经典自适应算法启发的注意力机制可以显著提高动态环境中的适应性和性能。

Conclusion: 研究结果为开发具有更强适应性和鲁棒性的下一代无线基础模型提供了关键见解。

Abstract: Channel equalization is fundamental for mitigating distortions such as
frequency-selective fading and inter-symbol interference. Unlike standard
supervised learning approaches that require costly retraining or fine-tuning
for each new task, in-context learning (ICL) adapts to new channels at
inference time with only a few examples. However, existing ICL-based equalizers
are primarily developed for and evaluated on static channels within the context
window. Indeed, to our knowledge, prior principled analyses and theoretical
studies of ICL focus exclusively on the stationary setting, where the function
remains fixed within the context. In this paper, we investigate the ability of
ICL to address non-stationary problems through the lens of time-varying channel
equalization. We employ a principled framework for designing efficient
attention mechanisms with improved adaptivity in non-stationary tasks,
leveraging algorithms from adaptive signal processing to guide better designs.
For example, new attention variants can be derived from the Least Mean Square
(LMS) adaptive algorithm, a Least Root Mean Square (LRMS) formulation for
enhanced robustness, or multi-step gradient updates for improved long-term
tracking. Experimental results demonstrate that ICL holds strong promise for
non-stationary MIMO equalization, and that attention mechanisms inspired by
classical adaptive algorithms can substantially enhance adaptability and
performance in dynamic environments. Our findings may provide critical insights
for developing next-generation wireless foundation models with stronger
adaptability and robustness.

</details>


### [78] [Enhancing Self-Supervised Learning with Semantic Pairs A New Dataset and Empirical Study](https://arxiv.org/abs/2510.08722)
*Mohammad Alkhalefi,Georgios Leontidis,Mingjun Zhong*

Main category: cs.LG

TL;DR: 这篇论文介绍了实例判别，一种自监督表征学习范式。


<details>
  <summary>Details</summary>
Motivation: 动机是学习对常见底层对象不变的表征。

Method: 通过应用随机变换为每个实例生成两个不同的视图。

Result: 模型学习了对这些视图中常见底层对象不变的表征。

Conclusion: 实例判别是一种有效的自监督学习方法。

Abstract: Instance discrimination is a self-supervised representation learning paradigm
wherein individual instances within a dataset are treated as distinct classes.
This is typically achieved by generating two disparate views of each instance
by applying stochastic transformations, which encourages the model to learn
representations that are invariant to the common underlying object across these
views.

</details>


### [79] [Counterfactually Fair Conformal Prediction](https://arxiv.org/abs/2510.08724)
*Ozgur Guldogan,Neeraj Sarna,Yuanyuan Li,Michael Berger*

Main category: cs.LG

TL;DR: 本文提出了一种名为“反事实公平共形预测 (CF-CP)” 的新方法，用于生成反事实公平的预测集。


<details>
  <summary>Details</summary>
Motivation: 虽然点预测的反事实公平性已被充分研究，但将其扩展到预测集仍未被充分探索。共形预测 (CP) 提供了高效、无分布、有限样本有效的预测集，但不能确保反事实公平性。

Method: 通过对受保护属性干预的一致性分数进行对称化，实现了反事实公平。

Result: 在合成数据集和真实数据集上，CF-CP 实现了预期的反事实公平性，并以最小的预测集大小增加满足了目标覆盖率。

Conclusion: CF-CP 提供了一种简单、无需训练的途径来实现反事实公平的不确定性量化。

Abstract: While counterfactual fairness of point predictors is well studied, its
extension to prediction sets--central to fair decision-making under
uncertainty--remains underexplored. On the other hand, conformal prediction
(CP) provides efficient, distribution-free, finite-sample valid prediction
sets, yet does not ensure counterfactual fairness. We close this gap by
developing Counterfactually Fair Conformal Prediction (CF-CP) that produces
counterfactually fair prediction sets. Through symmetrization of conformity
scores across protected-attribute interventions, we prove that CF-CP results in
counterfactually fair prediction sets while maintaining the marginal coverage
property. Furthermore, we empirically demonstrate that on both synthetic and
real datasets, across regression and classification tasks, CF-CP achieves the
desired counterfactual fairness and meets the target coverage rate with minimal
increase in prediction set size. CF-CP offers a simple, training-free route to
counterfactually fair uncertainty quantification.

</details>


### [80] [Cross-attention Secretly Performs Orthogonal Alignment in Recommendation Models](https://arxiv.org/abs/2510.09435)
*Hyunin Lee,Yong Zhang,Hoang Vu Nguyen,Xiaoyi Liu,Namyong Park,Christopher Jung,Rong Jin,Yang Wang,Zhigang Wang,Somayeh Sojoudi,Xue Feng*

Main category: cs.LG

TL;DR: 本文研究了跨域序列推荐（CDSR）中交叉注意力的机制，发现除了去除冗余信息的残差对齐外，还存在一种正交对齐现象，即交叉注意力可以发现查询输入中不存在的新信息。


<details>
  <summary>Details</summary>
Motivation: 目前对交叉注意力的机制理解不充分，多数研究将其解释为残差对齐。

Method: 通过大量实验（超过300次）观察交叉注意力的行为，并分析其与模型性能的关系。

Result: 发现当交叉注意力的查询输入和输出正交时，模型性能提升。正交对齐的出现是因为它可以改进缩放定律。引入交叉注意力模块的基线模型优于参数匹配的基线模型。

Conclusion: 正交对齐现象为多模态研究中的参数高效缩放提供了新的方向。

Abstract: Cross-domain sequential recommendation (CDSR) aims to align heterogeneous
user behavior sequences collected from different domains. While cross-attention
is widely used to enhance alignment and improve recommendation performance, its
underlying mechanism is not fully understood. Most researchers interpret
cross-attention as residual alignment, where the output is generated by
removing redundant and preserving non-redundant information from the query
input by referencing another domain data which is input key and value. Beyond
the prevailing view, we introduce Orthogonal Alignment, a phenomenon in which
cross-attention discovers novel information that is not present in the query
input, and further argue that those two contrasting alignment mechanisms can
co-exist in recommendation models We find that when the query input and output
of cross-attention are orthogonal, model performance improves over 300
experiments. Notably, Orthogonal Alignment emerges naturally, without any
explicit orthogonality constraints. Our key insight is that Orthogonal
Alignment emerges naturally because it improves scaling law. We show that
baselines additionally incorporating cross-attention module outperform
parameter-matched baselines, achieving a superior accuracy-per-model parameter.
We hope these findings offer new directions for parameter-efficient scaling in
multi-modal research.

</details>


### [81] [Transmuting prompts into weights](https://arxiv.org/abs/2510.08734)
*Hanna Mazzawi,Benoit Dherin,Michael Munn,Michael Wunder,Javier Gonzalvo*

Main category: cs.LG

TL;DR: 大型语言模型的行为可以通过在推理时直接修改其内部状态来有效控制。本文为这些干预提供了一个理论基础，解释了它们是如何从 Transformer 架构的基本计算中产生的。


<details>
  <summary>Details</summary>
Motivation: 现有的通过修改大型语言模型的内部状态来控制其行为的技术，通常依赖于经验启发式方法。本文旨在为这些干预提供理论基础。

Method: 通过将 prompt 的影响映射到隐式权重更新，并将该理论推广到深层、多块 Transformer。推导出一种原则性方法，将信息浓缩成独立于 token 的思想向量和思想矩阵。

Result: 解释了现有的基于向量和矩阵的模型编辑技术，并提供了一种直接的、基于计算的方法，用于将文本输入转换为可重用的权重更新。

Conclusion: 为大型语言模型内部状态干预提供了理论解释和计算方法。

Abstract: A growing body of research has demonstrated that the behavior of large
language models can be effectively controlled at inference time by directly
modifying their internal states, either through vector additions to their
activations or through updates to their weight matrices. These techniques,
while powerful, are often guided by empirical heuristics, such as deriving
steering vectors from the average activations of contrastive prompts. This work
provides a theoretical foundation for these interventions, explaining how they
emerge from the fundamental computations of the transformer architecture.
Building on the recent finding that a prompt's influence can be mathematically
mapped to implicit weight updates (Dherin et al., 2025), we generalize this
theory to deep, multi-block transformers. We show how the information contained
in any chunk of a user prompt is represented and composed internally through
weight vectors and weight matrices. We then derive a principled method for
condensing this information into token-independent thought vectors and thought
matrices. These constructs provide a theoretical explanation for existing
vector- and matrix-based model editing techniques and offer a direct,
computationally-grounded method for transmuting textual input into reusable
weight updates.

</details>


### [82] [SHAP-Based Supervised Clustering for Sample Classification and the Generalized Waterfall Plot](https://arxiv.org/abs/2510.08737)
*Justin Lin,Julia Fukuyama*

Main category: cs.LG

TL;DR: 本文提出了一种使用SHAP值聚类来理解模型预测的方法，并通过模拟实验和阿尔茨海默病案例研究展示了该方法。


<details>
  <summary>Details</summary>
Motivation: 大型黑盒模型缺乏可解释性，这使其在关键情况下难以信任。SHAP分析是一种流行的可解释AI方法，但需要进一步探索其潜力。

Method: 使用SHAP值聚类来揭示数据集中具有相似预测原因的样本组，从而绘制出不同样本获得相同预测的路径。

Result: 通过模拟实验和ADNI数据库中的阿尔茨海默病案例研究展示了该方法，并提出了一种新的多分类瀑布图。

Conclusion: SHAP值聚类可以提供对数据的洞察力，并帮助理解模型的预测过程。

Abstract: In this growing age of data and technology, large black-box models are
becoming the norm due to their ability to handle vast amounts of data and learn
incredibly complex input-output relationships. The deficiency of these methods,
however, is their inability to explain the prediction process, making them
untrustworthy and their use precarious in high-stakes situations. SHapley
Additive exPlanations (SHAP) analysis is an explainable AI method growing in
popularity for its ability to explain model predictions in terms of the
original features. For each sample and feature in the data set, we associate a
SHAP value that quantifies the contribution of that feature to the prediction
of that sample. Clustering these SHAP values can provide insight into the data
by grouping samples that not only received the same prediction, but received
the same prediction for similar reasons. In doing so, we map the various
pathways through which distinct samples arrive at the same prediction. To
showcase this methodology, we present a simulated experiment in addition to a
case study in Alzheimer's disease using data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database. We also present a novel generalization
of the waterfall plot for multi-classification.

</details>


### [83] [Faithful and Interpretable Explanations for Complex Ensemble Time Series Forecasts using Surrogate Models and Forecastability Analysis](https://arxiv.org/abs/2510.08739)
*Yikai Zhao,Jiekai Ma*

Main category: cs.LG

TL;DR: 本文提出了一种双重框架，旨在解决复杂时间序列集成模型的可解释性和可预测性问题。


<details>
  <summary>Details</summary>
Motivation: 现代时间序列预测越来越依赖于像AutoGluon这样的AutoML系统生成的复杂集成模型，虽然提高了准确性，但也牺牲了透明性和可解释性。

Method: 该框架首先开发了一种基于代理模型的解释方法，通过训练LightGBM模型来模仿AutoGluon的时间序列预测，从而实现稳定的SHAP特征归因。其次，集成了频谱可预测性分析来量化每个序列的固有可预测性。

Result: 在M5数据集上的经验评估表明，较高的频谱可预测性不仅与提高的预测准确性密切相关，而且与代理模型和原始预测模型之间更高的保真度密切相关。此外，逐项归一化对于跨具有不同尺度的异构时间序列生成有意义的SHAP解释至关重要。

Conclusion: 该框架为最先进的集成预测提供可解释的、实例级别的解释，同时为用户提供可预测性指标，作为预测及其解释的可靠性指标。

Abstract: Modern time series forecasting increasingly relies on complex ensemble models
generated by AutoML systems like AutoGluon, delivering superior accuracy but
with significant costs to transparency and interpretability. This paper
introduces a comprehensive, dual-approach framework that addresses both the
explainability and forecastability challenges in complex time series ensembles.
First, we develop a surrogate-based explanation methodology that bridges the
accuracy-interpretability gap by training a LightGBM model to faithfully mimic
AutoGluon's time series forecasts, enabling stable SHAP-based feature
attributions. We rigorously validated this approach through feature injection
experiments, demonstrating remarkably high faithfulness between extracted SHAP
values and known ground truth effects. Second, we integrated spectral
predictability analysis to quantify each series' inherent forecastability. By
comparing each time series' spectral predictability to its pure noise
benchmarks, we established an objective mechanism to gauge confidence in
forecasts and their explanations. Our empirical evaluation on the M5 dataset
found that higher spectral predictability strongly correlates not only with
improved forecast accuracy but also with higher fidelity between the surrogate
and the original forecasting model. These forecastability metrics serve as
effective filtering mechanisms and confidence scores, enabling users to
calibrate their trust in both the forecasts and their explanations. We further
demonstrated that per-item normalization is essential for generating meaningful
SHAP explanations across heterogeneous time series with varying scales. The
resulting framework delivers interpretable, instance-level explanations for
state-of-the-art ensemble forecasts, while equipping users with forecastability
metrics that serve as reliability indicators for both predictions and their
explanations.

</details>
