<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]
- [cs.CV](#cs.CV) [Total: 5]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.IR](#cs.IR) [Total: 6]
- [cs.LG](#cs.LG) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions](https://arxiv.org/abs/2507.10577)
*Logé Cécile,Ghori Rehan*

Main category: cs.CL

TL;DR: 开发了一个AI系统，通过事实核查和用户互动来打击YouTube上的虚假信息。


<details>
  <summary>Details</summary>
Motivation: 虚假信息在当今的数字世界中构成重大威胁，经常通过YouTube等平台迅速传播。

Method: 开发了一个AI驱动的系统，该系统不仅可以核实YouTube视频中的声明，还可以主动让用户参与评论部分并挑战误导性叙述。该系统包含两个主要代理：Truth Sleuth和Trend Bender。

Result: 通过在已建立的基准数据集和YouTube上的实际部署中进行的实验，展示了该系统的功能，展示了其吸引用户并可能影响观点的潜力。调查结果强调了事实核查代理的高准确性，并证实了AI驱动的干预措施在打击虚假信息和营造更明智的在线空间方面的潜力。

Conclusion: AI驱动的干预措施有潜力打击虚假信息，营造更明智的在线空间。

Abstract: Misinformation poses a significant threat in today's digital world, often
spreading rapidly through platforms like YouTube. This paper introduces a novel
approach to combating misinformation by developing an AI-powered system that
not only fact-checks claims made in YouTube videos but also actively engages
users in the comment section and challenge misleading narratives. Our system
comprises two main agents: Truth Sleuth and Trend Bender.
  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented
Generation (RAG) approach - drawing on sources like Wikipedia, Google Search,
Google FactCheck - to accurately assess their veracity and generates a nuanced
and comprehensive report. Through rigorous prompt engineering, Trend Bender
leverages this report along with a curated corpus of relevant articles to
generate insightful and persuasive comments designed to stimulate a productive
debate. With a carefully set up self-evaluation loop, this agent is able to
iteratively improve its style and refine its output.
  We demonstrate the system's capabilities through experiments on established
benchmark datasets and a real-world deployment on YouTube, showcasing its
potential to engage users and potentially influence perspectives. Our findings
highlight the high accuracy of our fact-checking agent, and confirm the
potential of AI-driven interventions in combating misinformation and fostering
a more informed online space.

</details>


### [2] [An Offline Mobile Conversational Agent for Mental Health Support: Learning from Emotional Dialogues and Psychological Texts with Student-Centered Evaluation](https://arxiv.org/abs/2507.10580)
*Vimaleswar A,Prabhu Nandan Sahu,Nilesh Kumar Sahu,Haroon R Lone*

Main category: cs.CL

TL;DR: EmoSApp: an offline, smartphone-based conversational app for mental health, leveraging fine-tuned LLMs.


<details>
  <summary>Details</summary>
Motivation: Persistent challenges related to limited user accessibility, internet connectivity, and data privacy highlight the need for an offline, smartphone-based solution.

Method: fine-tuned, quantized and deployed LLMs (LLaMA-3.2-1B-Instruct model) using Torchtune and Executorch

Result: EmoSApp can respond coherently and empathetically, maintain interactive dialogue, and provide relevant suggestions. Quantitative evaluations demonstrate the efficacy of the model in low-resource settings.

Conclusion: EmoSApp serves as a blueprint for future innovations in portable, secure, and highly tailored AI-driven mental health solutions.

Abstract: Mental health plays a crucial role in the overall well-being of an
individual. In recent years, digital platforms have been increasingly used to
expand mental health and emotional support. However, there are persistent
challenges related to limited user accessibility, internet connectivity, and
data privacy, which highlight the need for an offline, smartphone-based
solution. To address these challenges, we propose EmoSApp (Emotional Support
App): an entirely offline, smartphone-based conversational app designed for
mental health and emotional support. The system leverages Large Language Models
(LLMs), specifically fine-tuned, quantized and deployed using Torchtune and
Executorch for resource-constrained devices, allowing all inferences to occur
on the smartphone. To equip EmoSApp with robust domain expertise, we fine-tuned
the LLaMA-3.2-1B-Instruct model on our custom curated ``Knowledge dataset'' of
14,582 mental-health QA pairs, along with the multi-turn conversational data.
  Through qualitative human evaluation with the student population, we
demonstrate that EmoSApp has the ability to respond coherently, empathetically,
maintain interactive dialogue, and provide relevant suggestions to user's
mental health problems. Additionally, quantitative evaluations on nine standard
commonsense and reasoning benchmarks demonstrate the efficacy of our
fine-tuned, quantized model in low-resource settings. By prioritizing on-device
deployment and specialized domain adaptation, EmoSApp serves as a blueprint for
future innovations in portable, secure, and highly tailored AI-driven mental
health solutions.

</details>


### [3] [Transforming Sensitive Documents into Quantitative Data: An AI-Based Preprocessing Toolchain for Structured and Privacy-Conscious Analysis](https://arxiv.org/abs/2507.10582)
*Anders Ledberg,Anna Thalén*

Main category: cs.CL

TL;DR: 该工具链使用LLM来匿名化和标准化法律、医疗和管理文本，以便进行大规模分析。


<details>
  <summary>Details</summary>
Motivation: 来自法律、医疗和行政来源的非结构化文本为公共卫生和社会科学研究提供了丰富但未被充分利用的资源。然而，大规模分析受到两个主要挑战的阻碍：敏感的个人身份信息的存在，以及结构和语言的显着异质性。

Method: 该工具链采用大型语言模型（LLM）提示来标准化、总结文本，并在需要时将文本翻译成英语以提高可比性。通过基于LLM的编辑实现匿名化，并辅以命名实体识别和基于规则的方法，以最大限度地降低泄露风险。

Result: 我们在一个包含10,842份瑞典法院判决的语料库上演示了该工具链，这些判决属于《虐待者照顾法案》（LVM），包含超过56,000页。每个文档都被处理成匿名、标准化的摘要，并转换为文档级嵌入。验证，包括手动审查、自动扫描和预测评估，表明该工具链有效地删除了识别信息，同时保留了语义内容。

Conclusion: 该工具链通过对敏感文档进行结构化和保护隐私的分析，为大规模研究开辟了新的可能性，这些研究领域以前由于隐私和异构性限制而无法访问文本数据。

Abstract: Unstructured text from legal, medical, and administrative sources offers a
rich but underutilized resource for research in public health and the social
sciences. However, large-scale analysis is hampered by two key challenges: the
presence of sensitive, personally identifiable information, and significant
heterogeneity in structure and language. We present a modular toolchain that
prepares such text data for embedding-based analysis, relying entirely on
open-weight models that run on local hardware, requiring only a
workstation-level GPU and supporting privacy-sensitive research.
  The toolchain employs large language model (LLM) prompting to standardize,
summarize, and, when needed, translate texts to English for greater
comparability. Anonymization is achieved via LLM-based redaction, supplemented
with named entity recognition and rule-based methods to minimize the risk of
disclosure. We demonstrate the toolchain on a corpus of 10,842 Swedish court
decisions under the Care of Abusers Act (LVM), comprising over 56,000 pages.
Each document is processed into an anonymized, standardized summary and
transformed into a document-level embedding. Validation, including manual
review, automated scanning, and predictive evaluation shows the toolchain
effectively removes identifying information while retaining semantic content.
As an illustrative application, we train a predictive model using embedding
vectors derived from a small set of manually labeled summaries, demonstrating
the toolchain's capacity for semi-automated content analysis at scale.
  By enabling structured, privacy-conscious analysis of sensitive documents,
our toolchain opens new possibilities for large-scale research in domains where
textual data was previously inaccessible due to privacy and heterogeneity
constraints.

</details>


### [4] [Applying Text Embedding Models for Efficient Analysis in Labeled Property Graphs](https://arxiv.org/abs/2507.10772)
*Michal Podstawski*

Main category: cs.CL

TL;DR: 利用预训练文本嵌入模型，在不改变图结构的情况下，增强属性图的语义分析，提高节点分类和关系预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 标记属性图通常包含丰富的文本属性，如果 правильно 利用，可以增强分析任务。

Method: 将语言模型嵌入集成到图管道中，而不改变其结构。

Result: 通过嵌入文本节点和边属性，我们支持下游任务，包括节点分类和关系预测，并具有改进的上下文理解。

Conclusion: 文本语义可以显著提高属性图分析的准确性和可解释性。

Abstract: Labeled property graphs often contain rich textual attributes that can
enhance analytical tasks when properly leveraged. This work explores the use of
pretrained text embedding models to enable efficient semantic analysis in such
graphs. By embedding textual node and edge properties, we support downstream
tasks including node classification and relation prediction with improved
contextual understanding. Our approach integrates language model embeddings
into the graph pipeline without altering its structure, demonstrating that
textual semantics can significantly enhance the accuracy and interpretability
of property graph analysis.

</details>


### [5] [A Taxonomy for Design and Evaluation of Prompt-Based Natural Language Explanations](https://arxiv.org/abs/2507.10585)
*Isar Nejadgholi,Mona Omidyeganeh,Marc-Antoine Drouin,Jonathan Boisvert*

Main category: cs.CL

TL;DR: This paper presents an updated XAI taxonomy for prompt-based NLEs to improve AI governance and transparency.


<details>
  <summary>Details</summary>
Motivation: Effective AI governance requires structured approaches for stakeholders to access and verify AI system behavior. With the rise of large language models, Natural Language Explanations (NLEs) are now key to articulating model behavior, which necessitates a focused examination of their characteristics and governance implications.

Method: We draw on Explainable AI (XAI) literature to create an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, including task, data, audience, and goals; (2) Generation and Presentation, covering generation methods, inputs, interactivity, outputs, and forms; and (3) Evaluation, focusing on content, presentation, and user-centered properties, as well as the setting of the evaluation.

Result: An updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions: (1) Context, (2) Generation and Presentation, and (3) Evaluation.

Conclusion: This taxonomy provides a framework for researchers, auditors, and policymakers to characterize, design, and enhance NLEs for transparent AI systems.

Abstract: Effective AI governance requires structured approaches for stakeholders to
access and verify AI system behavior. With the rise of large language models,
Natural Language Explanations (NLEs) are now key to articulating model
behavior, which necessitates a focused examination of their characteristics and
governance implications. We draw on Explainable AI (XAI) literature to create
an updated XAI taxonomy, adapted to prompt-based NLEs, across three dimensions:
(1) Context, including task, data, audience, and goals; (2) Generation and
Presentation, covering generation methods, inputs, interactivity, outputs, and
forms; and (3) Evaluation, focusing on content, presentation, and user-centered
properties, as well as the setting of the evaluation. This taxonomy provides a
framework for researchers, auditors, and policymakers to characterize, design,
and enhance NLEs for transparent AI systems.

</details>


### [6] [AutoRAG-LoRA: Hallucination-Triggered Knowledge Retuning via Lightweight Adapters](https://arxiv.org/abs/2507.10586)
*Kaushik Dwivedi,Padmanabh Patanjali Mishra*

Main category: cs.CL

TL;DR: AutoRAG-LoRA是一个RAG框架，它使用LoRA适配器和KL正则化训练来减少大型语言模型中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在一系列自然语言任务中表现出了卓越的流畅性，但仍然容易出现幻觉——事实性不准确，这破坏了对现实世界部署的信任。

Method: AutoRAG-LoRA，一个模块化的检索增强生成（RAG）框架，通过轻量级的基于LoRA的适配器和KL正则化训练来解决大型语言模型中的幻觉问题。

Result: 幻觉检测模块，使用基于分类器和自我评估技术，为生成的输出分配置信度分数，触发可选的反馈校正循环。该循环通过对比KL损失和适配器微调来加强事实对齐。

Conclusion: AutoRAG-LoRA显著减少了事实性漂移，同时保持了模型的效率和模块化。

Abstract: Large Language Models (LLMs) have demonstrated remarkable fluency across a
range of natural language tasks, yet remain vulnerable to hallucinations -
factual inaccuracies that undermine trust in real world deployment. We present
AutoRAG-LoRA, a modular framework for Retrieval-Augmented Generation (RAG) that
tackles hallucination in large language models through lightweight LoRA-based
adapters and KL-regularized training. Our pipeline integrates automated prompt
rewriting, hybrid retrieval, and low-rank adapter tuning to ground responses in
retrieved evidence. A hallucination detection module, using both
classifier-based and self-evaluation techniques, assigns confidence scores to
generated outputs, triggering an optional feedback correction loop. This loop
enforces factual alignment via contrastive KL loss and adapter fine tuning. We
demonstrate that AutoRAG-LoRA significantly reduces the factual drift while
preserving the efficiency and modularity of the model.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [7] [CWNet: Causal Wavelet Network for Low-Light Image Enhancement](https://arxiv.org/abs/2507.10689)
*Tongshun Zhang,Pingping Liu,Yubing Lu,Mengen Cai,Zijian Zhang,Zhe Zhang,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: CWNet, a Causal Wavelet Network, leverages wavelet transforms and causal reasoning to enhance low-light images, outperforming existing methods by considering instance-level semantic information and feature characteristics.


<details>
  <summary>Details</summary>
Motivation: Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on uniform brightness adjustment, often neglecting instance-level semantic information and the inherent characteristics of different features. To address these limitations

Method: a novel architecture that leverages wavelet transforms for causal reasoning. Specifically, our approach comprises two key components: 1) Inspired by the concept of intervention in causality, we adopt a causal reasoning perspective to reveal the underlying causal relationships in low-light enhancement. From a global perspective, we employ a metric learning strategy to ensure causal embeddings adhere to causal principles, separating them from non-causal confounding factors while focusing on the invariance of causal factors. At the local level, we introduce an instance-level CLIP semantic loss to precisely maintain causal factor consistency. 2) Based on our causal analysis, we present a wavelet transform-based backbone network that effectively optimizes the recovery of frequency information, ensuring precise enhancement tailored to the specific attributes of wavelet transforms.

Result: CWNet significantly outperforms current state-of-the-art methods across multiple datasets, showcasing its robust performance across diverse scenes.

Conclusion: CWNet significantly outperforms current state-of-the-art methods across multiple datasets, showcasing its robust performance across diverse scenes.

Abstract: Traditional Low-Light Image Enhancement (LLIE) methods primarily focus on
uniform brightness adjustment, often neglecting instance-level semantic
information and the inherent characteristics of different features. To address
these limitations, we propose CWNet (Causal Wavelet Network), a novel
architecture that leverages wavelet transforms for causal reasoning.
Specifically, our approach comprises two key components: 1) Inspired by the
concept of intervention in causality, we adopt a causal reasoning perspective
to reveal the underlying causal relationships in low-light enhancement. From a
global perspective, we employ a metric learning strategy to ensure causal
embeddings adhere to causal principles, separating them from non-causal
confounding factors while focusing on the invariance of causal factors. At the
local level, we introduce an instance-level CLIP semantic loss to precisely
maintain causal factor consistency. 2) Based on our causal analysis, we present
a wavelet transform-based backbone network that effectively optimizes the
recovery of frequency information, ensuring precise enhancement tailored to the
specific attributes of wavelet transforms. Extensive experiments demonstrate
that CWNet significantly outperforms current state-of-the-art methods across
multiple datasets, showcasing its robust performance across diverse scenes.
Code is available at https://github.com/bywlzts/CWNet-Causal-Wavelet-Network.

</details>


### [8] [Integrating Biological Knowledge for Robust Microscopy Image Profiling on De Novo Cell Lines](https://arxiv.org/abs/2507.10737)
*Jiayuan Chen,Thai-Hoang Pham,Yuanlong Wang,Ping Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的框架，通过整合外部生物学知识来提高显微镜图像分析模型对新细胞系的泛化能力，从而改善基于表型的药物发现应用。


<details>
  <summary>Details</summary>
Motivation: 由于细胞系之间存在显著的形态和生物学异质性，因此对新细胞系进行稳健的扰动筛选仍然具有挑战性。

Method: 该方法整合了外部生物学知识到现有的预训练策略中，以增强显微镜图像分析模型。具体来说，它利用蛋白质互作数据构建知识图谱，并结合来自单细胞基础模型的转录组特征，来分别引导模型学习扰动特异性和细胞系特异性的表征。

Result: 实验结果表明，该方法增强了新细胞系的显微镜图像分析能力。

Conclusion: 该方法通过学习解耦的特征，提高了图像模型对新细胞系的泛化能力，并通过在 RxRx 数据库上的实验验证了其有效性。

Abstract: High-throughput screening techniques, such as microscopy imaging of cellular
responses to genetic and chemical perturbations, play a crucial role in drug
discovery and biomedical research. However, robust perturbation screening for
\textit{de novo} cell lines remains challenging due to the significant
morphological and biological heterogeneity across cell lines. To address this,
we propose a novel framework that integrates external biological knowledge into
existing pretraining strategies to enhance microscopy image profiling models.
Our approach explicitly disentangles perturbation-specific and cell
line-specific representations using external biological information.
Specifically, we construct a knowledge graph leveraging protein interaction
data from STRING and Hetionet databases to guide models toward
perturbation-specific features during pretraining. Additionally, we incorporate
transcriptomic features from single-cell foundation models to capture cell
line-specific representations. By learning these disentangled features, our
method improves the generalization of imaging models to \textit{de novo} cell
lines. We evaluate our framework on the RxRx database through one-shot
fine-tuning on an RxRx1 cell line and few-shot fine-tuning on cell lines from
the RxRx19a dataset. Experimental results demonstrate that our method enhances
microscopy image profiling for \textit{de novo} cell lines, highlighting its
effectiveness in real-world phenotype-based drug discovery applications.

</details>


### [9] [Auditing Facial Emotion Recognition Datasets for Posed Expressions and Racial Bias](https://arxiv.org/abs/2507.10755)
*Rina Khan,Catherine Stinson*

Main category: cs.CV

TL;DR: FER 算法在自发表情和不同种族的人脸上表现不佳，因为数据集存在偏差。


<details>
  <summary>Details</summary>
Motivation: 与摆拍表情相比，FER 算法在检测自发表情时性能下降。FER 算法面临的伦理（和评估）挑战是，它们对于某些种族和肤色的人来说，往往表现不佳。这些挑战与 FER 数据集创建过程中采用的数据收集实践有关。

Method: 我们从每个数据集中抽取随机样本，并检查图像是自发的还是摆拍的。在这样做时，我们提出了一种识别自发或摆拍图像的方法。

Result: 我们发现大量图像是在声称由野外图像组成的数据集中摆拍的。由于 FER 模型在自发图像和摆拍图像之间的性能各不相同，因此如果将此类模型部署在野外应用中，则在这些数据集上训练的模型的性能将无法代表真实性能。

Conclusion: FER 模型在预测非白人或深色皮肤的人的面部表情时，更有可能将其预测为负面情绪，即使他们在微笑。这种偏见使得这些模型容易在现实生活中造成伤害。

Abstract: Facial expression recognition (FER) algorithms classify facial expressions
into emotions such as happy, sad, or angry. An evaluative challenge facing FER
algorithms is the fall in performance when detecting spontaneous expressions
compared to posed expressions. An ethical (and evaluative) challenge facing FER
algorithms is that they tend to perform poorly for people of some races and
skin colors. These challenges are linked to the data collection practices
employed in the creation of FER datasets. In this study, we audit two
state-of-the-art FER datasets. We take random samples from each dataset and
examine whether images are spontaneous or posed. In doing so, we propose a
methodology for identifying spontaneous or posed images. We discover a
significant number of images that were posed in the datasets purporting to
consist of in-the-wild images. Since performance of FER models vary between
spontaneous and posed images, the performance of models trained on these
datasets will not represent the true performance if such models were to be
deployed in in-the-wild applications. We also observe the skin color of
individuals in the samples, and test three models trained on each of the
datasets to predict facial expressions of people from various races and skin
tones. We find that the FER models audited were more likely to predict people
labeled as not white or determined to have dark skin as showing a negative
emotion such as anger or sadness even when they were smiling. This bias makes
such models prone to perpetuate harm in real life applications.

</details>


### [10] [FPC-Net: Revisiting SuperPoint with Descriptor-Free Keypoint Detection via Feature Pyramids and Consistency-Based Implicit Matching](https://arxiv.org/abs/2507.10770)
*Ionuţ Grigore,Călin-Adrian Popa,Claudiu Leoveanu-Condrei*

Main category: cs.CV

TL;DR: This paper introduces a descriptor-free interest point matching technique that reduces memory usage but sacrifices some accuracy.


<details>
  <summary>Details</summary>
Motivation: The extraction and matching of interest points are fundamental to many geometric computer vision tasks. Traditionally, matching is performed by assigning descriptors to interest points and identifying correspondences based on descriptor similarity.

Method: A technique where interest points are inherently associated during detection, eliminating the need for computing, storing, transmitting, or matching descriptors.

Result: The matching accuracy is marginally lower than that of conventional approaches, and it drastically reduces memory usage.

Conclusion: This method reduces memory usage for localization systems by eliminating the need for descriptors, but with marginally lower matching accuracy compared to conventional approaches.

Abstract: The extraction and matching of interest points are fundamental to many
geometric computer vision tasks. Traditionally, matching is performed by
assigning descriptors to interest points and identifying correspondences based
on descriptor similarity. This work introduces a technique where interest
points are inherently associated during detection, eliminating the need for
computing, storing, transmitting, or matching descriptors. Although the
matching accuracy is marginally lower than that of conventional approaches, our
method completely eliminates the need for descriptors, leading to a drastic
reduction in memory usage for localization systems. We assess its effectiveness
by comparing it against both classical handcrafted methods and modern learned
approaches.

</details>


### [11] [A New Dataset and Performance Benchmark for Real-time Spacecraft Segmentation in Onboard Flight Computers](https://arxiv.org/abs/2507.10775)
*Jeffrey Joan Sam,Janhavi Sathe,Nikhil Chigali,Naman Gupta,Radhey Ruparel,Yicheng Jiang,Janmajay Singh,James W. Berck,Arko Barman*

Main category: cs.CV

TL;DR: A new dataset of 64k annotated spacecraft images was created and used to finetune YOLO models for autonomous inspection systems, achieving a Dice score of 0.92 and Hausdorff distance of 0.69 with an inference time of about 0.5 second.


<details>
  <summary>Details</summary>
Motivation: Spacecraft in outer space are subjected to damage, and in-space repairs are costly. Image segmentation can enable cost-effective autonomous inspection systems, but annotated spacecraft segmentation data are scarce.

Method: Finetuned YOLOv8 and YOLOv11 segmentation models

Result: A new dataset of nearly 64k annotated spacecraft images was created using real spacecraft models, superimposed on a mixture of real and synthetic backgrounds. The dataset and models for performance benchmark are available at https://github.com/RiceD2KLab/SWiM.

Conclusion: The finetuned YOLOv8 and YOLOv11 segmentation models achieved a Dice score of 0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second under defined hardware and inference time constraints.

Abstract: Spacecraft deployed in outer space are routinely subjected to various forms
of damage due to exposure to hazardous environments. In addition, there are
significant risks to the subsequent process of in-space repairs through human
extravehicular activity or robotic manipulation, incurring substantial
operational costs. Recent developments in image segmentation could enable the
development of reliable and cost-effective autonomous inspection systems. While
these models often require large amounts of training data to achieve
satisfactory results, publicly available annotated spacecraft segmentation data
are very scarce. Here, we present a new dataset of nearly 64k annotated
spacecraft images that was created using real spacecraft models, superimposed
on a mixture of real and synthetic backgrounds generated using NASA's TTALOS
pipeline. To mimic camera distortions and noise in real-world image
acquisition, we also added different types of noise and distortion to the
images. Finally, we finetuned YOLOv8 and YOLOv11 segmentation models to
generate performance benchmarks for the dataset under well-defined hardware and
inference time constraints to mimic real-world image segmentation challenges
for real-time onboard applications in space on NASA's inspector spacecraft. The
resulting models, when tested under these constraints, achieved a Dice score of
0.92, Hausdorff distance of 0.69, and an inference time of about 0.5 second.
The dataset and models for performance benchmark are available at
https://github.com/RiceD2KLab/SWiM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [12] [SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents](https://arxiv.org/abs/2507.10562)
*Hari Masoor*

Main category: cs.AI

TL;DR: SAMEP是一种新的框架，它支持AI代理之间持久、安全和语义可搜索的内存共享。


<details>
  <summary>Details</summary>
Motivation: 目前的AI代理架构存在短暂的内存限制，阻碍了跨会话和代理边界的有效协作和知识共享。

Method: SAMEP实现了具有基于向量的语义搜索、加密访问控制（AES-256-GCM）和与现有代理通信协议（MCP、A2A）兼容的标准化API的分布式存储库。

Result: 实验结果表明，冗余计算减少了73%，上下文相关性评分提高了89%，并且完全符合包括审计跟踪生成在内的监管要求。

Conclusion: SAMEP实现了持久、协作的AI代理生态系统，同时保持安全和隐私保证。

Abstract: Current AI agent architectures suffer from ephemeral memory limitations,
preventing effective collaboration and knowledge sharing across sessions and
agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a
novel framework that enables persistent, secure, and semantically searchable
memory sharing among AI agents. Our protocol addresses three critical
challenges: (1) persistent context preservation across agent sessions, (2)
secure multi-agent collaboration with fine-grained access control, and (3)
efficient semantic discovery of relevant historical context. SAMEP implements a
distributed memory repository with vector-based semantic search, cryptographic
access controls (AES-256-GCM), and standardized APIs compatible with existing
agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness
across diverse domains including multi-agent software development, healthcare
AI with HIPAA compliance, and multi-modal processing pipelines. Experimental
results show 73% reduction in redundant computations, 89% improvement in
context relevance scores, and complete compliance with regulatory requirements
including audit trail generation. SAMEP enables a new paradigm of persistent,
collaborative AI agent ecosystems while maintaining security and privacy
guarantees.

</details>


### [13] [AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems](https://arxiv.org/abs/2507.10566)
*Hung Ming Liu*

Main category: cs.AI

TL;DR: The paper explores emergent communication in MARL using the AIM framework, showing that agents with an endogenous symbol system can achieve effective communication without external inductive biases, suggesting new directions for bridging symbolism and connectionism.


<details>
  <summary>Details</summary>
Motivation: The development of Emergent Communication in Decentralized Multi-Agent Reinforcement Learning (MARL) has been constrained by the Joint Exploration Dilemma, leading to a Communication Vacuum Equilibrium. The study questions whether artificial inductive biases are over-engineering.

Method: The study uses the AIM framework, based on a Vector Quantized Variational Autoencoder (VQ-VAE), to enable agents to possess an endogenous symbol system.

Result: Agents' neural representations naturally exhibit spontaneous semantic compression and Nash equilibrium-driven semantic convergence, achieving effective symbolic communication without external inductive biases. Symbol usage exhibits a significant power-law distribution, leading to three major theoretical insights: the Neural Communication Hypothesis, the Tool-First Principle, and the Semantic Interpretability Paradigm.

Conclusion: AIM demonstrates stronger generality and efficiency compared to traditional explicit communication methods, offering new avenues for bridging symbolism and connectionism.

Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development
of Emergent Communication has long been constrained by the ``Joint Exploration
Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' .
Traditional methods address this by introducing inductive biases to facilitate
communication emergence . This study fundamentally questions whether such
artificial inductive biases are, in fact, over-engineering. Through experiments
with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized
Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an
endogenous symbol system, their neural representations naturally exhibit
spontaneous semantic compression and Nash equilibrium-driven semantic
convergence, achieving effective symbolic communication without external
inductive biases. This aligns with recent neuroscience findings suggesting that
the human brain does not directly use human language for internal thought , and
resonates with research on ``soft thinking'' capabilities in Large Language
Models (LLMs) . Compared to traditional explicit communication methods, AIM
demonstrates stronger generality and efficiency. The interpretable analysis
toolkit developed in this study confirms that symbol usage exhibits a
significant power-law distribution, leading to three major theoretical
insights: the ``Neural Communication Hypothesis'', the ``Tool-First
Principle'', and the ``Semantic Interpretability Paradigm''. Future research
will explore the integration of Hierarchical Quantized Variational Autoencoders
(HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the
potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This
discovery offers new avenues for bridging symbolism and connectionism.

</details>


### [14] [Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning](https://arxiv.org/abs/2507.10571)
*Konstantinos I. Roumeliotis,Ranjan Sapkota,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.AI

TL;DR: This paper presents a new AI framework for visual classification that uses multiple agents, a reasoning orchestrator, and RAG to improve accuracy and trust, especially in zero-shot scenarios, with significant improvements demonstrated in apple leaf disease diagnosis.


<details>
  <summary>Details</summary>
Motivation: Trusting multi-agent AI systems in zero-shot settings is challenging. This paper addresses this by introducing a novel framework to improve trust and accuracy in such systems.

Method: The study introduces a modular Agentic AI visual classification framework that combines multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. It benchmarks zero-shot, fine-tuned, and trust-calibrated configurations, using confidence calibration metrics (ECE, OCR, CCC) to modulate trust across agents and CLIP-based image retrieval for re-evaluation.

Result: The framework achieves a 77.94% accuracy improvement in the zero-shot setting with trust-aware orchestration and RAG, reaching 85.63% overall. Image-RAG helps correct agent overconfidence through iterative re-evaluation. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence.

Conclusion: The proposed modular Agentic AI framework, featuring trust-aware orchestration and RAG, significantly improves zero-shot accuracy in apple leaf disease diagnosis. The system's design, separating perception from meta-reasoning, offers scalability and interpretability for trust-critical domains.

Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent
architectures that blend visual and language understanding. Yet, a pressing
challenge remains: How can we trust these agents especially in zero-shot
settings with no fine-tuning? We introduce a novel modular Agentic AI visual
classification framework that integrates generalist multimodal agents with a
non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG)
module. Applied to apple leaf disease diagnosis, we benchmark three
configurations: (I) zero-shot with confidence-based orchestration, (II)
fine-tuned agents with improved performance, and (III) trust-calibrated
orchestration enhanced by CLIP-based image retrieval and re-evaluation loops.
Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator
modulates trust across agents. Our results demonstrate a 77.94\% accuracy
improvement in the zero-shot setting using trust-aware orchestration and RAG,
achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL
displayed overconfidence. Furthermore, image-RAG grounded predictions with
visually similar cases, enabling correction of agent overconfidence via
iterative re-evaluation. The proposed system separates perception (vision
agents) from meta-reasoning (orchestrator), enabling scalable and interpretable
multi-agent AI. This blueprint is extensible to diagnostics, biology, and other
trust-critical domains. All models, prompts, results, and system components
including the complete software source code are openly released to support
reproducibility, transparency, and community benchmarking at Github:
https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust

</details>


### [15] [Comprehension Without Competence: Architectural Limits of LLMs in Symbolic Computation and Reasoning](https://arxiv.org/abs/2507.10624)
*Zheng Zhang*

Main category: cs.AI

TL;DR: LLM在需要推理的任务中失败，因为它们理解概念但不能可靠地应用它们，这是由于指令和执行路径分离造成的。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在表面上表现出惊人的流畅性，但在需要符号推理、算术精度和逻辑一致性的任务中却系统性地失败。

Method: 通过对照实验和架构分析

Result: LLM通常可以表达正确的原则，但不能可靠地应用它们。指令和执行路径在几何和功能上分离。

Conclusion: 当前的大型语言模型（LLM）在需要符号推理、算术精度和逻辑一致性的任务中表现出明显的不足，这源于理解和能力之间的差距。LLM可以表达正确的原则，但不能可靠地应用它们。这种现象被称为计算“裂脑综合症”，是由于指令和执行路径在几何和功能上分离。这种核心限制在数学运算和关系推理等领域反复出现。LLM作为强大的模式完成引擎运行，但缺乏原则性和组合推理的架构支撑。这些发现界定了当前LLM能力的边界，并促使未来的模型具有元认知控制、原则提升和结构化执行。

Abstract: Large Language Models (LLMs) display striking surface fluency yet
systematically fail at tasks requiring symbolic reasoning, arithmetic accuracy,
and logical consistency. This paper offers a structural diagnosis of such
failures, revealing a persistent gap between \textit{comprehension} and
\textit{competence}. Through controlled experiments and architectural analysis,
we demonstrate that LLMs often articulate correct principles without reliably
applying them--a failure rooted not in knowledge access, but in computational
execution. We term this phenomenon the computational \textit{split-brain
syndrome}, where instruction and action pathways are geometrically and
functionally dissociated. This core limitation recurs across domains, from
mathematical operations to relational inferences, and explains why model
behavior remains brittle even under idealized prompting. We argue that LLMs
function as powerful pattern completion engines, but lack the architectural
scaffolding for principled, compositional reasoning. Our findings delineate the
boundary of current LLM capabilities and motivate future models with
metacognitive control, principle lifting, and structurally grounded execution.
This diagnosis also clarifies why mechanistic interpretability findings may
reflect training-specific pattern coordination rather than universal
computational principles, and why the geometric separation between instruction
and execution pathways suggests limitations in neural introspection and
mechanistic analysis.

</details>


### [16] [Automated Thematic Analyses Using LLMs: Xylazine Wound Management Social Media Chatter Use Case](https://arxiv.org/abs/2507.10803)
*JaMor Hairston,Ritvik Ranjan,Sahithi Lakamana,Anthony Spadaro,Selen Bozkurt,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.AI

TL;DR: LLMs, especially GPT-4o with few-shot prompting, can automate thematic analysis of social media data with high accuracy, providing a scalable tool for qualitative research.


<details>
  <summary>Details</summary>
Motivation: LLMs face challenges in inductive thematic analysis, a task requiring deep interpretive and domain-specific expertise. The study evaluates the feasibility of using LLMs to replicate expert-driven thematic analysis of social media data.

Method: Evaluated five LLMs against expert coding using two Reddit datasets on xylazine, modeling the task as binary classifications with zero-, single-, and few-shot prompting.

Result: GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score: 0.71). Model-derived thematic distributions closely mirrored expert classifications for high-prevalence themes.

Conclusion: Few-shot LLM-based approaches can automate thematic analyses, offering a scalable supplement for qualitative research.

Abstract: Background Large language models (LLMs) face challenges in inductive thematic
analysis, a task requiring deep interpretive and domain-specific expertise. We
evaluated the feasibility of using LLMs to replicate expert-driven thematic
analysis of social media data. Methods Using two temporally non-intersecting
Reddit datasets on xylazine (n=286 and n=686, for model optimization and
validation, respectively) with twelve expert-derived themes, we evaluated five
LLMs against expert coding. We modeled the task as a series of binary
classifications, rather than a single, multi-label classification, employing
zero-, single-, and few-shot prompting strategies and measuring performance via
accuracy, precision, recall, and F1-score. Results On the validation set,
GPT-4o with two-shot prompting performed best (accuracy: 90.9%; F1-score:
0.71). For high-prevalence themes, model-derived thematic distributions closely
mirrored expert classifications (e.g., xylazine use: 13.6% vs. 17.8%; MOUD use:
16.5% vs. 17.8%). Conclusions Our findings suggest that few-shot LLM-based
approaches can automate thematic analyses, offering a scalable supplement for
qualitative research. Keywords: thematic analysis, large language models,
natural language processing, qualitative analysis, social media, prompt
engineering, public health

</details>


### [17] [Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs](https://arxiv.org/abs/2507.10630)
*Ye Yang,Xue Xiao,Ping Yin,Taotao Xie*

Main category: cs.AI

TL;DR: KG2data 是一种利用知识图谱增强大型语言模型在气象领域数据分析能力的系统，它通过提高内容检索、复杂查询处理和领域推理能力，并在 API 调用准确性方面优于其他系统，从而为知识密集型领域提供了一种有效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 的 API 调用为数据分析提供了一种前沿方法。然而，它们通过 API 调用有效利用工具的能力在气象等知识密集型领域仍未得到充分探索。

Method: 该论文介绍了一种名为 KG2data 的系统，该系统集成了知识图谱、大型语言模型 (LLM)、ReAct 代理和工具使用技术，以实现在气象领域中的智能数据采集和查询处理。

Result: KG2data 在名称识别失败率（1.43%）、幻觉失败率 (0%) 和调用正确率 (88.57%) 三个指标上优于 RAG2data (16%, 10%, 72.14%) 和 chat2data (7.14%, 8.57%, 71.43%)。

Conclusion: KG2data 为高知识需求的领域中的智能、基于知识的问答和数据分析提供了一种新颖的解决方案。

Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for
data analysis. However, their ability to effectively utilize tools via API
calls remains underexplored in knowledge-intensive domains like meteorology.
This paper introduces KG2data, a system that integrates knowledge graphs, LLMs,
ReAct agents, and tool-use technologies to enable intelligent data acquisition
and query handling in the meteorological field. Using a virtual API, we
evaluate API call accuracy across three metrics: name recognition failure,
hallucination failure, and call correctness. KG2data achieves superior
performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and
chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based
systems by addressing their limited access to domain-specific knowledge, which
hampers performance on complex or terminology-rich queries. By using a
knowledge graph as persistent memory, our system enhances content retrieval,
complex query handling, domain-specific reasoning, semantic relationship
resolution, and heterogeneous data integration. It also mitigates the high cost
of fine-tuning LLMs, making the system more adaptable to evolving domain
knowledge and API structures. In summary, KG2data provides a novel solution for
intelligent, knowledge-based question answering and data analysis in domains
with high knowledge demands.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [18] [SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition](https://arxiv.org/abs/2507.10629)
*Song Cheng,Qiannan Cheng,Linbo Jin,Lei Yi,Guannan Zhang*

Main category: cs.DB

TL;DR: SQLord是一个企业级NL2SQL框架，它引入了一种数据反向生成方法，将原始SQL语句转换为带注释的数据，用于监督微调 (SFT)。


<details>
  <summary>Details</summary>
Motivation: 现有的框架在复杂业务逻辑方面存在不足，并且缺乏用于微调的领域特定数据。此外，评估方法通常需要带注释的数据和可执行的数据库环境，这在现实场景中很少见。

Method: SQLord 引入了一种数据反向生成方法，将原始 SQL 语句转换为带注释的数据，用于监督微调 (SFT)。其次，它提出了一种使用自动化工作流生成器分解复杂查询的方法。此外，SQLord 还具有一个全面的 GPT-Judge 评估框架，包括执行评估 (EXE)、查询-SQL 评估 (QSE) 和 SQL-SQL 评估 (SSE)，专为各种场景量身定制。

Result: 离线测试明显优于最先进的基线，在线准确率始终超过 90。

Conclusion: SQLord在复杂现实场景中具有优势和有效性，已成功应用于全球最大的B2B电子商务平台的多个场景。

Abstract: Transforming natural language into SQL queries (NL2SQL) is crucial for
data-driven business applications. Existing frameworks, trained on open-source
datasets, struggle with complex business logic and lack domain-specific data
for fine-tuning. Additionally, evaluation methods often require annotated data
and executable database environments, which are scarce in real-world scenarios.
To address these challenges, we propose SQLord, an enterprise-level NL2SQL
framework. First, SQLord introduces a data reverse generation approach to
convert raw SQL statements into annotated data for supervised fine-tuning
(SFT). Second, it proposes a decomposition method for complex queries using an
automated workflow generator. Additionally, SQLord features a comprehensive
GPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL
Evaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios.
Offline tests significantly outperform state of the art baselines, and online
accuracy consistently exceeds 90, highlighting SQLord's advantages and
effectiveness in complex real world scenarios. SQLord has been successfully
applied across multiple scenarios on the world's largest B2B e-commerce
platform.

</details>


### [19] [LLMATCH: A Unified Schema Matching Framework with Large Language Models](https://arxiv.org/abs/2507.10897)
*Sha Wang,Yuchen Li,Hanhua Xiao,Bing Tian Dai,Roy Ka-Wei Lee,Yanfei Dong,Lambert Deng*

Main category: cs.DB

TL;DR: LLMatch 是一个统一且模块化的模式匹配框架，它将模式匹配分解为三个不同的阶段，并包含一个新颖的两阶段优化策略。为了解决复杂语义匹配基准的稀缺问题，我们引入了 SchemaNet，这是一个来自三个企业域的真实模式对的基准。


<details>
  <summary>Details</summary>
Motivation: 传统方法可以处理简单的一对一表格映射，但它们通常难以应对实际应用中复杂的多表格模式匹配。

Method: LLMatch 将模式匹配分解为三个不同的阶段：模式准备、表候选选择和列级对齐，从而实现组件级评估和面向未来的兼容性。它包括一种新颖的两阶段优化策略：一个 Rollup 模块，将语义相关的列整合到更高阶的概念中，然后是一个 Drilldown 模块，重新扩展这些概念以进行细粒度的列映射。

Result: LLMatch 显著提高了复杂模式匹配设置中的匹配精度，并大大提高了现实世界数据集成中的工程师生产力。我们引入了 SchemaNet，这是一个来自三个企业域的真实模式对的基准，旨在捕捉实际设置中多表模式对齐的挑战。

Conclusion: LLMatch 显著提高了复杂模式匹配设置中的匹配精度，并大大提高了现实世界数据集成中的工程师生产力。

Abstract: Schema matching is a foundational task in enterprise data integration, aiming
to align disparate data sources. While traditional methods handle simple
one-to-one table mappings, they often struggle with complex multi-table schema
matching in real-world applications. We present LLMatch, a unified and modular
schema matching framework. LLMatch decomposes schema matching into three
distinct stages: schema preparation, table-candidate selection, and
column-level alignment, enabling component-level evaluation and future-proof
compatibility. It includes a novel two-stage optimization strategy: a Rollup
module that consolidates semantically related columns into higher-order
concepts, followed by a Drilldown module that re-expands these concepts for
fine-grained column mapping. To address the scarcity of complex semantic
matching benchmarks, we introduce SchemaNet, a benchmark derived from
real-world schema pairs across three enterprise domains, designed to capture
the challenges of multi-table schema alignment in practical settings.
Experiments demonstrate that LLMatch significantly improves matching accuracy
in complex schema matching settings and substantially boosts engineer
productivity in real-world data integration.

</details>


### [20] [Towards Practical Benchmarking of Data Cleaning Techniques: On Generating Authentic Errors via Large Language Models](https://arxiv.org/abs/2507.10934)
*Xinyuan Liu,Jiahui Chen,Bocheng Hu,Yu Sun,Xinyang Chen,Shaoxu Song*

Main category: cs.DB

TL;DR: TableEG是一个利用大型语言模型生成真实错误的框架，可以弥合合成错误和真实错误之间的差距，并为后续错误检测和纠正任务建立了可靠的基准。


<details>
  <summary>Details</summary>
Motivation: 表格数据中的错误会严重影响下游分析和机器学习性能。缺乏多样化的真实世界错误数据集限制了综合评估。手动错误注释既耗时又不一致，促使人们探索合成错误生成作为替代方案。

Method: 利用大型语言模型 (LLM) 生成真实错误的框架

Result: TableEG生成的错误与基于规则的方法和未经微调的LLM生成的错误相比，表现出卓越的模式和分布相似性。此外，在TableEG生成的错误上的性能指标与几乎所有数据集和检测算法（特别是基于机器学习的检测技术）上的真实世界错误上的性能指标非常吻合。

Conclusion: TableEG弥合了合成错误和真实错误之间的差距，并为后续错误检测和纠正任务建立了可靠的基准。

Abstract: Data quality remains an important challenge in data-driven systems, as errors
in tabular data can severely compromise downstream analytics and machine
learning performance. Although numerous error detection algorithms have been
proposed, the lack of diverse, real-world error datasets limits comprehensive
evaluation. Manual error annotation is both time-consuming and inconsistent,
motivating the exploration of synthetic error generation as an alternative. In
this work, we introduce TableEG, a framework that leverages large language
models (LLMs) to generate authentic errors. By employing a table fine-tuning
strategy and a triplet representation $(I, T, O)$ to model error generation,
detection, and correction tasks, TableEG captures the complex dependencies
inherent in two-dimensional tables. Trained on 12 real-world datasets spanning
10 diverse domains, TableEG ensures that the synthesized errors faithfully
reflect authentic error distributions. Experimental results indicate that
errors generated by TableEG exhibit superior pattern and distribution
similarity compared to both rule-based methods and LLM-generated errors without
fine-tuning. Furthermore, performance metrics on TableEG-generated errors
closely align with those on real-world errors across nearly all datasets and
detection algorithms, particularly for machine learning based detection
techniques. Overall, TableEG not only bridges the gap between synthetic and
real-world errors but also establishes a robust benchmark for subsequent error
detection and correction tasks.

</details>


### [21] [TOPJoin: A Context-Aware Multi-Criteria Approach for Joinable Column Search](https://arxiv.org/abs/2507.11505)
*Harsha Kokel,Aamod Khatiwada,Tejaswini Pedapati,Haritha Ananthakrishnan,Oktie Hassanzadeh,Horst Samulowitz,Kavitha Srinivas*

Main category: cs.DB

TL;DR: 提出了一种上下文感知列连接性的多标准方法TOPJoin，并在学术界和现实世界中都优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在企业数据分析中，发现概念相关且提供有意义见解的可连接表是一项重大挑战。对于企业数据湖，列相似性不足以识别可连接的列和表。查询列的上下文非常重要。

Method: 提出了一种名为TOPJoin的多标准方法，用于可连接的列搜索。

Result: 通过实验，我们发现TOPJoin在两个基准测试中均优于基线。

Conclusion: TOPJoin在两个基准测试中均优于基线。

Abstract: One of the major challenges in enterprise data analysis is the task of
finding joinable tables that are conceptually related and provide meaningful
insights. Traditionally, joinable tables have been discovered through a search
for similar columns, where two columns are considered similar syntactically if
there is a set overlap or they are considered similar semantically if either
the column embeddings or value embeddings are closer in the embedding space.
However, for enterprise data lakes, column similarity is not sufficient to
identify joinable columns and tables. The context of the query column is
important. Hence, in this work, we first define context-aware column
joinability. Then we propose a multi-criteria approach, called TOPJoin, for
joinable column search. We evaluate TOPJoin against existing join search
baselines over one academic and one real-world join search benchmark. Through
experiments, we find that TOPJoin performs better on both benchmarks than the
baselines.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [22] [Extracting Document Relations from Search Corpus by Marginalizing over User Queries](https://arxiv.org/abs/2507.10726)
*Yuki Iwamoto,Kaoru Tsunoda,Ken Kaneiwa*

Main category: cs.IR

TL;DR: EDR-MQ 通过边缘化用户查询发现文档关系，无需标记训练数据或预定义的分类，从而能够识别有意义的文档关系。


<details>
  <summary>Details</summary>
Motivation: 理解大规模语料库中文档之间的关系对于知识发现和信息组织至关重要。然而，现有的方法严重依赖于手动注释或预定义的关系分类。

Method: EDR-MQ (通过边缘化用户查询提取文档关系) 框架，该框架通过查询边缘化发现文档关系。为了实现这种查询边缘化方法，我们开发了多重条件检索增强生成 (MC-RAG)，它采用条件检索，其中后续文档检索取决于先前检索的内容。

Result: 我们的查询边缘化方法成功地识别了有意义的文档关系，揭示了主题集群、证据链和跨域连接，这些都是传统的基于相似性的方法无法实现的。

Conclusion: query-driven 框架为文档组织提供了一种实用的方法，可以适应不同的用户视角和信息需求。

Abstract: Understanding relationships between documents in large-scale corpora is
essential for knowledge discovery and information organization. However,
existing approaches rely heavily on manual annotation or predefined
relationship taxonomies. We propose EDR-MQ (Extracting Document Relations by
Marginalizing over User Queries), a novel framework that discovers document
relationships through query marginalization. EDR-MQ is based on the insight
that strongly related documents often co-occur in results across diverse user
queries, enabling us to estimate joint probabilities between document pairs by
marginalizing over a collection of queries. To enable this query
marginalization approach, we develop Multiply Conditioned Retrieval-Augmented
Generation (MC-RAG), which employs conditional retrieval where subsequent
document retrievals depend on previously retrieved content. By observing
co-occurrence patterns across diverse queries, EDR-MQ estimates joint
probabilities between document pairs without requiring labeled training data or
predefined taxonomies. Experimental results show that our query marginalization
approach successfully identifies meaningful document relationships, revealing
topical clusters, evidence chains, and cross-domain connections that are not
apparent through traditional similarity-based methods. Our query-driven
framework offers a practical approach to document organization that adapts to
different user perspectives and information needs.

</details>


### [23] [Overview of the TREC 2022 deep learning track](https://arxiv.org/abs/2507.10865)
*Nick Craswell,Bhaskar Mitra,Emine Yilmaz,Daniel Campos,Jimmy Lin,Ellen M. Voorhees,Ian Soboroff*

Main category: cs.IR

TL;DR: TREC Deep Learning track 第四年，主要关注构建更完整的 passage 检索测试集。深度神经排序模型继续优于传统方法，但密集检索的表现令人意外。


<details>
  <summary>Details</summary>
Motivation: 构建一个更完整的 passage 检索任务的测试集合，这一直是该 track 的主要重点。文档排序任务被保留为辅助任务，其中文档级别的标签是从 passage 级别的标签推断出来的。

Method: 利用 MS MARCO 数据集，该数据集为 passage 和文档排序任务提供了数十万个人工标注的训练标签。此外，今年我们还利用了去年发布的刷新的 passage 和文档集合，导致 passage 集合的大小增加了近 16 倍，文档集合的大小增加了近 4 倍。

Result: 与往年类似，采用大规模预训练的深度神经排序模型继续优于传统检索方法。由于我们将 judging 资源集中在 passage judging 上，因此我们更有信心区分 runs 并在未来重用数据集。我们还看到了一些令人惊讶的总体结果。一些表现最佳的 runs 没有做密集检索。单阶段密集检索的 runs 不如去年有竞争力。

Conclusion: 深度神经排序模型继续优于传统检索方法。专注于 passage judging 使得我们更有信心区分 runs 并在未来重用数据集。一些表现最佳的 runs 没有做密集检索。单阶段密集检索的 runs 不如去年有竞争力。

Abstract: This is the fourth year of the TREC Deep Learning track. As in previous
years, we leverage the MS MARCO datasets that made hundreds of thousands of
human annotated training labels available for both passage and document ranking
tasks. In addition, this year we also leverage both the refreshed passage and
document collections that were released last year leading to a nearly $16$
times increase in the size of the passage collection and nearly four times
increase in the document collection size. Unlike previous years, in 2022 we
mainly focused on constructing a more complete test collection for the passage
retrieval task, which has been the primary focus of the track. The document
ranking task was kept as a secondary task, where document-level labels were
inferred from the passage-level labels. Our analysis shows that similar to
previous years, deep neural ranking models that employ large scale pretraining
continued to outperform traditional retrieval methods. Due to the focusing our
judging resources on passage judging, we are more confident in the quality of
this year's queries and judgments, with respect to our ability to distinguish
between runs and reuse the dataset in future. We also see some surprises in
overall outcomes. Some top-performing runs did not do dense retrieval. Runs
that did single-stage dense retrieval were not as competitive this year as they
were last year.

</details>


### [24] [LLM-Driven Dual-Level Multi-Interest Modeling for Recommendation](https://arxiv.org/abs/2507.10917)
*Ziyan Wang,Yingpeng Du,Zhu Sun,Jieyi Bi,Haoyan Chua,Tianjun Wei,Jie Zhang*

Main category: cs.IR

TL;DR: This paper introduces an LLM-driven dual-level multi-interest modeling framework to enhance recommendation systems by addressing the limitations of existing methods in capturing user multi-interests. It leverages LLMs at both individual and crowd levels, using semantic clusters and synthesized users to improve interest analysis and item representation.


<details>
  <summary>Details</summary>
Motivation: Existing methods often rely on heuristic assumptions, e.g., co-occurring items indicate the same interest of users, failing to capture user multi-interests aligning with real-world scenarios. While large language models (LLMs) show significant potential for multi-interest analysis due to their extensive knowledge and powerful reasoning capabilities, two key challenges remain. First, the granularity of LLM-driven multi-interests is agnostic, possibly leading to overly fine or coarse interest grouping. Second, individual user analysis provides limited insights due to the data sparsity issue.

Method: We propose an LLM-driven dual-level multi-interest modeling framework for more effective recommendation. At the user-individual level, we exploit LLMs to flexibly allocate items engaged by users into different semantic clusters, indicating their diverse and distinct interests. To alleviate the agnostic generation of LLMs, we adaptively assign these semantic clusters to users' collaborative multi-interests learned from global user-item interactions, allowing the granularity to be automatically adjusted according to the user's behaviors using an alignment module. To alleviate the limited insights derived from individual users' behaviors, at the user-crowd level, we propose aggregating user cliques into synthesized users with rich behaviors for more comprehensive LLM-driven multi-interest analysis. We formulate a max covering problem to ensure the compactness and representativeness of synthesized users' behaviors, and then conduct contrastive learning based on their LLM-driven multi-interests to disentangle item representations among different interests.

Result: superiority of our approach against state-of-the-art methods

Conclusion: Experiments on real-world datasets show the superiority of our approach against state-of-the-art methods.

Abstract: Recently, much effort has been devoted to modeling users' multi-interests
based on their behaviors or auxiliary signals. However, existing methods often
rely on heuristic assumptions, e.g., co-occurring items indicate the same
interest of users, failing to capture user multi-interests aligning with
real-world scenarios. While large language models (LLMs) show significant
potential for multi-interest analysis due to their extensive knowledge and
powerful reasoning capabilities, two key challenges remain. First, the
granularity of LLM-driven multi-interests is agnostic, possibly leading to
overly fine or coarse interest grouping. Second, individual user analysis
provides limited insights due to the data sparsity issue. In this paper, we
propose an LLM-driven dual-level multi-interest modeling framework for more
effective recommendation. At the user-individual level, we exploit LLMs to
flexibly allocate items engaged by users into different semantic clusters,
indicating their diverse and distinct interests. To alleviate the agnostic
generation of LLMs, we adaptively assign these semantic clusters to users'
collaborative multi-interests learned from global user-item interactions,
allowing the granularity to be automatically adjusted according to the user's
behaviors using an alignment module. To alleviate the limited insights derived
from individual users' behaviors, at the user-crowd level, we propose
aggregating user cliques into synthesized users with rich behaviors for more
comprehensive LLM-driven multi-interest analysis. We formulate a max covering
problem to ensure the compactness and representativeness of synthesized users'
behaviors, and then conduct contrastive learning based on their LLM-driven
multi-interests to disentangle item representations among different interests.
Experiments on real-world datasets show the superiority of our approach against
state-of-the-art methods.

</details>


### [25] [Unraveling the Biomarker Prospects of High-Altitude Diseases: Insights from Biomolecular Event Network Constructed using Text Mining](https://arxiv.org/abs/2507.10953)
*Balu Bhasuran,Sabenabanu Abdulkadhar,Jeyakumar Natarajan*

Main category: cs.IR

TL;DR: This study uses text mining and graph analysis to identify key biomolecules and pathways involved in high-altitude diseases.


<details>
  <summary>Details</summary>
Motivation: High-altitude diseases (HAD) pose significant health risks, yet the molecular mechanisms remain insufficiently understood.

Method: The authors developed a biomolecular event extraction pipeline integrating supervised machine learning with feature-based and multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related abstracts from PubMed. They constructed a weighted, undirected biomolecular event network and used the PageRank algorithm to prioritize key biomolecules.

Result: The study extracted over 150 unique biomolecular events and identified key proteins including Erythropoietin (EPO), Vascular endothelial growth factor (VEGF), and Hypoxia-inducible factor 1 (HIF-1) alpha. Subnetwork analysis revealed three major functional clusters centered on hypoxia response, inflammation, and stress adaptation pathways.

Conclusion: This study demonstrates the utility of large-scale text mining and graph-based analysis to uncover mechanistic insights and prioritize potential biomarkers for high-altitude disease.

Abstract: High-altitude diseases (HAD), encompassing acute mountain sickness (AMS),
high-altitude cerebral edema (HACE), and high-altitude pulmonary edema (HAPE),
are triggered by hypobaric hypoxia at elevations above 2,500 meters. These
conditions pose significant health risks, yet the molecular mechanisms remain
insufficiently understood. In this study, we developed a biomolecular event
extraction pipeline integrating supervised machine learning with feature-based
and multiscale Laplacian graph kernels to analyze 7,847 curated HAD-related
abstracts from PubMed. We extracted over 150 unique biomolecular events
including gene expression, regulation, binding, and localization and
constructed a weighted, undirected biomolecular event network comprising 97
nodes and 153 edges. Using the PageRank algorithm, we prioritized key
biomolecules based on their centrality within the event network. The top-ranked
proteins included Erythropoietin (EPO) (0.0163), Vascular endothelial growth
factor (VEGF) (0.0148), Hypoxia-inducible factor 1 (HIF-1) alpha (0.0136),
Endothelial PAS Domain Protein 1 (EPAS1) and Angiotensin-Converting Enzyme
(ACE) (0.0119), Egl nine homolog 1 (EGLN1), Endothelin 1 (ET-1), and 70
kilodalton heat shock protein (Hsp70)(0.0118), all of which play crucial roles
in oxygen sensing, vascular remodeling, erythropoiesis, and blood pressure
regulation. Subnetwork analysis revealed three major functional clusters
centered on hypoxia response, inflammation, and stress adaptation pathways. Our
integrative approach demonstrates the utility of large-scale text mining and
graph-based analysis to uncover mechanistic insights and prioritize potential
biomarkers for high-altitude disease.

</details>


### [26] [Aligned Query Expansion: Efficient Query Expansion for Information Retrieval through LLM Alignment](https://arxiv.org/abs/2507.11042)
*Adam Yang,Gustavo Penha,Enrico Palumbo,Hugues Bouchard*

Main category: cs.IR

TL;DR: AQE是一种新的查询扩展方法，它通过对齐LLM来优化检索任务的有效性，无需额外的过滤步骤。


<details>
  <summary>Details</summary>
Motivation: 克服生成式查询扩展的局限性，例如幻觉和计算成本。

Method: Aligned Query Expansion (AQE)

Result: AQE提高了检索有效性，同时降低了计算成本。

Conclusion: AQE在同域和异域设置中优于查询扩展的基线模型，证明了检索有效性的显着提高。

Abstract: With the breakthroughs in large language models (LLMs), query generation
techniques that expand documents and queries with related terms are becoming
increasingly popular in the information retrieval field. Such techniques have
been shown to improve the effectiveness of traditional lexical retrieval
methods by dealing with the vocabulary mismatch problem. Recent work has found
that generating queries with a greedy decoding strategy can produce sub-optimal
queries, including hallucinations, and proposed to filter out queries before
expansion. This `generate-then-filter' approach is costly, as it requires
generating multiple queries and applying a relevance model to all of them and
does not teach the LLM which of the generated queries is more effective for
expansion. To overcome such limitations, we propose Aligned Query Expansion
(AQE), a novel approach to enhance query expansion for passage retrieval in
open-domain question answering. AQE leverages recent techniques in LLM
alignment to fine-tune models for generating query expansions that directly
optimize the effectiveness of the retrieval task, eliminating the need for
additional filtering steps. This alignment ensures that queries are more
relevant, reducing computational costs while improving retrieval effectiveness.
Empirical evaluations show that AQE outperforms baseline models for query
expansion in both in-domain and out-of-domain settings, demonstrating
significant improvements in retrieval effectiveness.

</details>


### [27] [From Chaos to Automation: Enabling the Use of Unstructured Data for Robotic Process Automation](https://arxiv.org/abs/2507.11364)
*Kelly Kurowski,Xixi Lu,Hajo A. Reijers*

Main category: cs.IR

TL;DR: 本研究开发了一个名为UNDRESS的系统，利用模糊正则表达式、自然语言处理和大型语言模型，使RPA平台能够有效地从非结构化文档中检索信息，从而提升业务流程效率。


<details>
  <summary>Details</summary>
Motivation: 组织内不断增长的非结构化数据给数据分析和流程自动化带来了重大挑战。传统RPA依赖于结构化数据，限制了其在涉及非结构化文档的流程中的应用。

Method: 开发了一个名为UNDRESS的系统，该系统结合了模糊正则表达式、自然语言处理技术和大型语言模型。

Result: UNDRESS系统在增强RPA处理非结构化数据的能力方面表现出有效性。

Conclusion: UNDRESS系统通过增强RPA平台处理非结构化数据的能力，显著提升了业务流程效率，并促进了RPA在传统上受非结构化数据限制的流程中的应用。

Abstract: The growing volume of unstructured data within organizations poses
significant challenges for data analysis and process automation. Unstructured
data, which lacks a predefined format, encompasses various forms such as
emails, reports, and scans. It is estimated to constitute approximately 80% of
enterprise data. Despite the valuable insights it can offer, extracting
meaningful information from unstructured data is more complex compared to
structured data. Robotic Process Automation (RPA) has gained popularity for
automating repetitive tasks, improving efficiency, and reducing errors.
However, RPA is traditionally reliant on structured data, limiting its
application to processes involving unstructured documents. This study addresses
this limitation by developing the UNstructured Document REtrieval SyStem
(UNDRESS), a system that uses fuzzy regular expressions, techniques for natural
language processing, and large language models to enable RPA platforms to
effectively retrieve information from unstructured documents. The research
involved the design and development of a prototype system, and its subsequent
evaluation based on text extraction and information retrieval performance. The
results demonstrate the effectiveness of UNDRESS in enhancing RPA capabilities
for unstructured data, providing a significant advancement in the field. The
findings suggest that this system could facilitate broader RPA adoption across
processes traditionally hindered by unstructured data, thereby improving
overall business process efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [28] [Tool-to-Tool Matching Analysis Based Difference Score Computation Methods for Semiconductor Manufacturing](https://arxiv.org/abs/2507.10564)
*Sameera Bharadwaja H.,Siddhrath Jandial,Shashank S. Agashe,Rajesh Kumar Reddy Moore,Youngkwan Kim*

Main category: cs.LG

TL;DR: 本文提出了一种新的工具匹配 (TTTM) 分析管道，用于解决传统 TTTM 方法在异构环境中难以应用的问题。实验结果表明，该方法是有效的。


<details>
  <summary>Details</summary>
Motivation: 传统的 TTTM 方法利用静态配置数据或依赖于难以在商业生产线中获得的黄金参考。此外，现有方法不能很好地扩展到异构环境，即设备来自不同的制造商和型号，来自不同的设备供应商。

Method: 提出了新的 TTTM 分析管道。

Result: 最佳单变量方法与方差和模态数的相关系数分别大于 0.95 和 0.5，最佳多变量方法与表现最佳的单变量方法的相关系数大于 0.75。

Conclusion: 所提出的方法是有效的，最佳单变量方法与方差和模态数的相关系数分别大于 0.95 和 0.5，最佳多变量方法与表现最佳的单变量方法的相关系数大于 0.75。分析了多元算法对算法超参数的敏感性。

Abstract: We consider the problem of tool-to-tool matching (TTTM), also called, chamber
matching in the context of a semiconductor manufacturing equipment. Traditional
TTTM approaches utilize static configuration data or depend on a golden
reference which are difficult to obtain in a commercial manufacturing line.
Further, existing methods do not extend very well to a heterogeneous setting,
where equipment are of different make-and-model, sourced from different
equipment vendors. We propose novel TTTM analysis pipelines to overcome these
issues. We hypothesize that a mismatched equipment would have higher variance
and/or higher number of modes in the data. Our best univariate method achieves
a correlation coefficient >0.95 and >0.5 with the variance and number of modes,
respectively showing that the proposed methods are effective. Also, the best
multivariate method achieves a correlation coefficient >0.75 with the
top-performing univariate methods, showing its effectiveness. Finally, we
analyze the sensitivity of the multivariate algorithms to the algorithm
hyper-parameters.

</details>


### [29] [Enhancing Cross Entropy with a Linearly Adaptive Loss Function for Optimized Classification Performance](https://arxiv.org/abs/2507.10574)
*Jae Wan Shim*

Main category: cs.LG

TL;DR: A new loss function, Linearly Adaptive Cross Entropy, improves classification accuracy compared to standard cross entropy without sacrificing efficiency.


<details>
  <summary>Details</summary>
Motivation: Enhance the optimization process in classification tasks with one-hot encoded class labels.

Method: A linearly adaptive cross entropy loss function is proposed, which includes an additional term based on the predicted probability of the true class.

Result: The proposed loss function consistently outperforms the standard cross entropy loss in classification accuracy on CIFAR-100 using a ResNet-based model and maintains similar efficiency.

Conclusion: The proposed linearly adaptive cross entropy loss function outperforms the standard cross entropy loss in classification accuracy on CIFAR-100 with ResNet, while maintaining similar efficiency. This suggests potential for future research in loss function design.

Abstract: We propose the Linearly Adaptive Cross Entropy Loss function. This is a novel
measure derived from the information theory. In comparison to the standard
cross entropy loss function, the proposed one has an additional term that
depends on the predicted probability of the true class. This feature serves to
enhance the optimization process in classification tasks involving one-hot
encoded class labels. The proposed one has been evaluated on a ResNet-based
model using the CIFAR-100 dataset. Preliminary results show that the proposed
one consistently outperforms the standard cross entropy loss function in terms
of classification accuracy. Moreover, the proposed one maintains simplicity,
achieving practically the same efficiency to the traditional cross entropy
loss. These findings suggest that our approach could broaden the scope for
future research into loss function design.

</details>


### [30] [An Adaptive Volatility-based Learning Rate Scheduler](https://arxiv.org/abs/2507.10575)
*Kieran Chai Kai Ren*

Main category: cs.LG

TL;DR: VolSched, a volatility-inspired LR scheduler, enhances generalization by dynamically adjusting the learning rate, leading to performance gains on CIFAR-100.


<details>
  <summary>Details</summary>
Motivation: Popular LR schedulers can lead to suboptimal generalization.

Method: A novel adaptive LR scheduler inspired by volatility in stochastic processes.

Result: VolSched improves top-1 accuracy by 1.4 and 1.3 percentage points on CIFAR-100 with ResNet-18 and ResNet-34, respectively.

Conclusion: VolSched finds flatter solutions leading to better generalization.

Abstract: Effective learning rate (LR) scheduling is crucial for training deep neural
networks. However, popular pre-defined and adaptive schedulers can still lead
to suboptimal generalization. This paper introduces VolSched, a novel adaptive
LR scheduler inspired by the concept of volatility in stochastic processes like
Geometric Brownian Motion to dynamically adjust the learning rate. By
calculating the ratio between long-term and short-term accuracy volatility,
VolSched increases the LR to escape plateaus and decreases it to stabilize
training, allowing the model to explore the loss landscape more effectively. We
evaluate VolSched on the CIFAR-100 dataset against a strong baseline using a
standard augmentation pipeline. When paired with ResNet-18 and ResNet-34, our
scheduler delivers consistent performance gains, improving top-1 accuracy by
1.4 and 1.3 percentage points respectively. Analysis of the loss curves reveals
that VolSched promotes a longer exploration phase. A quantitative analysis of
the Hessian shows that VolSched finds a final solution that is 38% flatter than
the next-best baseline, allowing the model to obtain wider minima and hence
better generalization performance.

</details>


### [31] [Universal Approximation Theorem for a Single-Layer Transformer](https://arxiv.org/abs/2507.10581)
*Esmail Gumaan*

Main category: cs.LG

TL;DR: 本文证明了单层Transformer可以逼近任何连续序列到序列的映射。


<details>
  <summary>Details</summary>
Motivation: 目前对深度学习和Transformer的理论理解仍然有限。

Method: 本文深入分析了多头自注意力机制和反向传播算法，并结合线性代数、概率和优化等关键概念，为深度学习和Transformer的数学基础提供了理论支撑。

Result: 本文的主要贡献是Transformer的通用逼近定理。

Conclusion: 本文提出了Transformer的通用逼近定理，证明了单层Transformer可以以任意精度逼近紧域上的任何连续序列到序列的映射，并通过案例研究展示了该结果的实际意义。

Abstract: Deep learning employs multi-layer neural networks trained via the
backpropagation algorithm. This approach has achieved success across many
domains and relies on adaptive gradient methods such as the Adam optimizer.
Sequence modeling evolved from recurrent neural networks to attention-based
models, culminating in the Transformer architecture. Transformers have achieved
state-of-the-art performance in natural language processing (for example, BERT
and GPT-3) and have been applied in computer vision and computational biology.
However, theoretical understanding of these models remains limited. In this
paper, we examine the mathematical foundations of deep learning and
Transformers and present a novel theoretical result. We review key concepts
from linear algebra, probability, and optimization that underpin deep learning,
and we analyze the multi-head self-attention mechanism and the backpropagation
algorithm in detail. Our main contribution is a universal approximation theorem
for Transformers: we prove that a single-layer Transformer, comprising one
self-attention layer followed by a position-wise feed-forward network with ReLU
activation, can approximate any continuous sequence-to-sequence mapping on a
compact domain to arbitrary precision. We provide a formal statement and a
complete proof. Finally, we present case studies that demonstrate the practical
implications of this result. Our findings advance the theoretical understanding
of Transformer models and help bridge the gap between theory and practice.

</details>


### [32] [MH-FSF: A Unified Framework for Overcoming Benchmarking and Reproducibility Limitations in Feature Selection Evaluation](https://arxiv.org/abs/2507.10591)
*Vanderson Rocha,Diego Kreutz,Gabriel Canto,Hendrio Bragança,Eduardo Feitosa*

Main category: cs.LG

TL;DR: MH-FSF是一个特征选择框架，解决了可重复性问题，并在Android恶意软件数据集上实现了17种方法，结果强调了数据预处理的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前的研究通常受到有限的基准测试和对专有数据集的依赖的困扰，这严重阻碍了可重复性，并可能对整体性能产生负面影响。

Method: MH-FSF框架，一个综合的、模块化的和可扩展的平台，旨在促进特征选择方法的重现和实施。

Result: 结果揭示了平衡和不平衡数据集的性能变化，突出了数据预处理和选择标准的关键需求，这些标准考虑了这些不对称性。

Conclusion: MH-FSF平台能够比较不同的特征选择技术，促进方法学的一致性和严谨性。该框架旨在拓展现有文献，并为特征选择的新研究方向铺平道路，特别是在Android恶意软件检测的背景下。

Abstract: Feature selection is vital for building effective predictive models, as it
reduces dimensionality and emphasizes key features. However, current research
often suffers from limited benchmarking and reliance on proprietary datasets.
This severely hinders reproducibility and can negatively impact overall
performance. To address these limitations, we introduce the MH-FSF framework, a
comprehensive, modular, and extensible platform designed to facilitate the
reproduction and implementation of feature selection methods. Developed through
collaborative research, MH-FSF provides implementations of 17 methods (11
classical, 6 domain-specific) and enables systematic evaluation on 10 publicly
available Android malware datasets. Our results reveal performance variations
across both balanced and imbalanced datasets, highlighting the critical need
for data preprocessing and selection criteria that account for these
asymmetries. We demonstrate the importance of a unified platform for comparing
diverse feature selection techniques, fostering methodological consistency and
rigor. By providing this framework, we aim to significantly broaden the
existing literature and pave the way for new research directions in feature
selection, particularly within the context of Android malware detection.

</details>
