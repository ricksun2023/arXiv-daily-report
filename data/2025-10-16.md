<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 56]
- [cs.CV](#cs.CV) [Total: 55]
- [cs.AI](#cs.AI) [Total: 22]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IR](#cs.IR) [Total: 11]
- [cs.LG](#cs.LG) [Total: 55]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Benchmarking Open-Source Large Language Models for Persian in Zero-Shot and Few-Shot Learning](https://arxiv.org/abs/2510.12807)
*Mahdi Cherakhloo,Arash Abbasi,Mohammad Saeid Sarafraz,Bijan Vosoughi Vahdat*

Main category: cs.CL

TL;DR: 评估了开源LLM在波斯语NLP任务上的表现，发现Gemma 2在大多数任务中表现优于其他模型，但在命名实体识别等token级别理解任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在波斯语等低资源语言中的有效性。

Method: 在情感分析、命名实体识别、阅读理解和问答等任务上，利用zero-shot和few-shot学习范式，使用ParsiNLU和ArmanEmo等波斯语数据集，采用准确率、F1-score、BLEU和ROUGE等指标进行评估。

Result: Gemma 2在几乎所有任务中都优于其他模型，尤其是在复杂的推理任务中。但在命名实体识别等token级别理解任务中，大多数模型表现不佳。

Conclusion: 该研究为多语言LLM的研究做出了贡献，提供了关于其在波斯语中的表现的宝贵见解，并为未来的模型开发提供了基准。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
numerous languages; however, their effectiveness in low-resource languages like
Persian requires thorough investigation. This paper presents a comprehensive
benchmark of several open-source LLMs for Persian Natural Language Processing
(NLP) tasks, utilizing both zero-shot and few-shot learning paradigms. We
evaluate models across a range of tasks including sentiment analysis, named
entity recognition, reading comprehension, and question answering, using
established Persian datasets such as ParsiNLU and ArmanEmo. Our methodology
encompasses rigorous experimental setups for both zero-shot and few-shot
scenarios, employing metrics such as Accuracy, F1-score, BLEU, and ROUGE for
performance evaluation. The results reveal that Gemma 2 consistently
outperforms other models across nearly all tasks in both learning paradigms,
with particularly strong performance in complex reasoning tasks. However, most
models struggle with token-level understanding tasks like Named Entity
Recognition, highlighting specific challenges in Persian language processing.
This study contributes to the growing body of research on multilingual LLMs,
providing valuable insights into their performance in Persian and offering a
benchmark for future model development.

</details>


### [2] [Cancer Diagnosis Categorization in Electronic Health Records Using Large Language Models and BioBERT: Model Performance Evaluation Study](https://arxiv.org/abs/2510.12813)
*Soheil Hashtarkhani,Rezaur Rashid,Christopher L Brett,Lokesh Chinthala,Fekede Asefa Kumsa,Janet A Zink,Robert L Davis,David L Schwartz,Arash Shaban-Nejad*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型和BioBERT在对癌症诊断进行分类时的性能，发现GPT-4o和BioBERT在不同数据格式上表现最佳，但临床应用仍需人工监督。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录数据结构不一致，需要有效的预处理以支持预测性医疗模型。人工智能驱动的自然语言处理工具在自动化诊断分类方面显示出潜力，但其性能和可靠性需要系统评估。

Method: 研究分析了3456名癌症患者的762个独特诊断（包括ICD代码描述和自由文本条目），使用GPT-3.5、GPT-4o、Llama 3.2、Gemini 1.5和BioBERT模型对诊断进行分类，并由两位肿瘤学专家验证分类结果。

Result: BioBERT在ICD代码分类中取得了最高的加权宏F1得分（84.2），与GPT-4o在ICD代码准确率上相匹配（90.8）。对于自由文本诊断，GPT-4o在加权宏F1得分（71.8 vs 61.5）和准确率（81.9 vs 81.6）上优于BioBERT。

Conclusion: 当前性能水平对于行政和研究用途来说似乎足够，但可靠的临床应用需要标准化文档实践以及强大的人工监督，以进行高风险决策。

Abstract: Electronic health records contain inconsistently structured or free-text
data, requiring efficient preprocessing to enable predictive health care
models. Although artificial intelligence-driven natural language processing
tools show promise for automating diagnosis classification, their comparative
performance and clinical reliability require systematic evaluation. The aim of
this study is to evaluate the performance of 4 large language models (GPT-3.5,
GPT-4o, Llama 3.2, and Gemini 1.5) and BioBERT in classifying cancer diagnoses
from structured and unstructured electronic health records data. We analyzed
762 unique diagnoses (326 International Classification of Diseases (ICD) code
descriptions, 436free-text entries) from 3456 records of patients with cancer.
Models were tested on their ability to categorize diagnoses into 14predefined
categories. Two oncology experts validated classifications. BioBERT achieved
the highest weighted macro F1-score for ICD codes (84.2) and matched GPT-4o in
ICD code accuracy (90.8). For free-text diagnoses, GPT-4o outperformed BioBERT
in weighted macro F1-score (71.8 vs 61.5) and achieved slightly higher accuracy
(81.9 vs 81.6). GPT-3.5, Gemini, and Llama showed lower overall performance on
both formats. Common misclassification patterns included confusion between
metastasis and central nervous system tumors, as well as errors involving
ambiguous or overlapping clinical terminology. Although current performance
levels appear sufficient for administrative and research use, reliable clinical
applications will require standardized documentation practices alongside robust
human oversight for high-stakes decision-making.

</details>


### [3] [Classifier-Augmented Generation for Structured Workflow Prediction](https://arxiv.org/abs/2510.12825)
*Thomas Gschwind,Shramona Chakraborty,Nitin Gupta,Sameep Mehta*

Main category: cs.CL

TL;DR: 该论文提出了一种将自然语言描述转换为可执行工作流的系统，用于自动化ETL流程。


<details>
  <summary>Details</summary>
Motivation: 配置ETL工具（如IBM DataStage）中的stages和属性非常耗时，需要深入的工具知识。

Method: 该系统采用了一种分类器增强生成（CAG）方法，结合了语句分解、分类器和特定stage的少量样本提示，以生成准确的stage预测。然后，使用边缘预测将这些stages连接成非线性工作流，并从子语句上下文中推断stage属性。

Result: CAG方法在准确性和效率方面优于强大的单提示和代理基线，同时显著减少了token使用量。

Conclusion: 该架构是模块化的、可解释的，并且能够进行端到端的工作流生成，包括强大的验证步骤。这是第一个对自然语言驱动的ETL创作进行详细评估的系统，评估范围包括stage预测、边缘布局和属性生成。

Abstract: ETL (Extract, Transform, Load) tools such as IBM DataStage allow users to
visually assemble complex data workflows, but configuring stages and their
properties remains time consuming and requires deep tool knowledge. We propose
a system that translates natural language descriptions into executable
workflows, automatically predicting both the structure and detailed
configuration of the flow. At its core lies a Classifier-Augmented Generation
(CAG) approach that combines utterance decomposition with a classifier and
stage-specific few-shot prompting to produce accurate stage predictions. These
stages are then connected into non-linear workflows using edge prediction, and
stage properties are inferred from sub-utterance context. We compare CAG
against strong single-prompt and agentic baselines, showing improved accuracy
and efficiency, while substantially reducing token usage. Our architecture is
modular, interpretable, and capable of end-to-end workflow generation,
including robust validation steps. To our knowledge, this is the first system
with a detailed evaluation across stage prediction, edge layout, and property
generation for natural-language-driven ETL authoring.

</details>


### [4] [From Noise to Signal to Selbstzweck: Reframing Human Label Variation in the Era of Post-training in NLP](https://arxiv.org/abs/2510.12817)
*Shanshan Xu,Santosh T. Y. S. S,Barbara Plank*

Main category: cs.CL

TL;DR: 人类标签变异（HLV）反映了注释中人类视角的真正多样性，而不是单纯的错误。本文认为，在设计人工智能系统时，应将保留HLV作为人类多元化的一种体现。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的兴起，HLV的作用变得越来越重要。当前偏好学习数据集通常将多个注释聚合为单个标签，从而将不同的观点扁平化为虚假的普遍一致，并抹杀了对齐旨在保留的人类价值观的多元化。

Method: 提倡将HLV主动纳入偏好数据集。

Result: 讨论了HLV在NLP中逐渐被重构为提高模型鲁棒性的信号，并强调了其在大型语言模型对齐中的重要性。

Conclusion: 在设计人工智能系统时，应将保留HLV作为人类多元化的一种体现，并概述了实现这一目标的可行步骤。

Abstract: Human Label Variation (HLV) refers to legitimate disagreement in annotation
that reflects the genuine diversity of human perspectives rather than mere
error. For decades, HLV in NLP was dismissed as noise to be discarded, and only
slowly over the last decade has it been reframed as a signal for improving
model robustness. With the rise of large language models (LLMs), where
post-training on human feedback has become central to model alignment, the role
of HLV has become increasingly consequential. Yet current preference-learning
datasets routinely aggregate multiple annotations into a single label, thereby
flattening diverse perspectives into a false universal agreement and erasing
precisely the pluralism of human values that alignment aims to preserve. In
this position paper, we argue that preserving HLV as an embodiment of human
pluralism must be treated as a Selbstzweck - a goal it self when designing AI
systems. We call for proactively incorporating HLV into preference datasets and
outline actionable steps towards it.

</details>


### [5] [MTSQL-R1: Towards Long-Horizon Multi-Turn Text-to-SQL via Agentic Training](https://arxiv.org/abs/2510.12831)
*Taicheng Guo,Hai Wang,ChaoChun Liu,Mohsen Golalikhani,Xin Chen,Xiangliang Zhang,Chandan K. Reddy*

Main category: cs.CL

TL;DR: MTSQL-R1是一个用于长程多轮Text-to-SQL的agentic训练框架，通过与数据库和对话记忆互动，进行迭代式的提议-执行-验证-改进循环，直到所有检查通过。


<details>
  <summary>Details</summary>
Motivation: 现有系统将多轮Text-to-SQL视为简单的文本翻译任务，缺乏执行、显式验证和改进，导致输出不可执行或不连贯。

Method: 将任务建模为马尔可夫决策过程（MDP），agent与数据库和持久对话记忆互动，执行迭代式的提议-执行-验证-改进循环。

Result: 在COSQL和SPARC数据集上的实验表明，MTSQL-R1始终优于强大的基线。

Conclusion: 环境驱动的验证和记忆引导的改进对于会话语义解析至关重要。

Abstract: Multi-turn Text-to-SQL aims to translate a user's conversational utterances
into executable SQL while preserving dialogue coherence and grounding to the
target schema. However, most existing systems only regard this task as a simple
text translation task and follow a short-horizon paradigm, generating a query
per turn without execution, explicit verification, and refinement, which leads
to non-executable or incoherent outputs. We present MTSQL-R1, an agentic
training framework for long-horizon multi-turn Text-to-SQL. We cast the task as
a Markov Decision Process (MDP) in which an agent interacts with (i) a database
for execution feedback and (ii) a persistent dialogue memory for coherence
verification, performing an iterative propose to execute -> verify -> refine
cycle until all checks pass. Experiments on COSQL and SPARC demonstrate that
MTSQL-R1 consistently outperforms strong baselines, highlighting the importance
of environment-driven verification and memory-guided refinement for
conversational semantic parsing. Full recipes (including code, trained models,
logs, reasoning trajectories, etc.) will be released after the internal review
to contribute to community research.

</details>


### [6] [MEDEQUALQA: Evaluating Biases in LLMs with Counterfactual Reasoning](https://arxiv.org/abs/2510.12818)
*Rajarshi Ghosh,Abhay Gupta,Hudson McBride,Anurag Vaidya,Faisal Mahmood*

Main category: cs.CL

TL;DR: 该研究调查了大型语言模型在临床决策支持中，人口统计线索对其推理的影响。通过构建一个反事实基准MEDEQUALQA，该基准仅改变患者代词，同时保持关键症状和条件不变，来评估GPT-4.1模型在不同代词变体下的推理稳定性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型越来越多地应用于临床决策支持，但微妙的人口统计学线索会影响它们的推理。之前的研究已经记录了不同患者群体在输出方面的差异，但对于在受控人口统计学变化下内部推理如何变化知之甚少。

Method: 构建MEDEQUALQA基准，该基准通过改变患者代词（他/她/他们）来扰动，同时保持关键症状和条件（CSC）不变。每个临床案例被扩展为单一CSC消融，产生三个平行的，每个约23,000个项目的数据集（总共69,000个）。评估GPT-4.1模型，并计算推理轨迹之间的语义文本相似性（STS），以衡量不同代词变体之间的稳定性。

Result: 结果显示总体相似度较高（平均STS>0.80），但揭示了在引用的风险因素、指南锚定和差异排序中持续存在的局部差异，即使最终诊断结果保持不变。误差分析突出了推理发生变化的某些情况，强调了可能导致不公平护理的临床相关偏差。

Conclusion: MEDEQUALQA为审核医疗AI中的推理稳定性提供了一个受控的诊断环境。

Abstract: Large language models (LLMs) are increasingly deployed in clinical decision
support, yet subtle demographic cues can influence their reasoning. Prior work
has documented disparities in outputs across patient groups, but little is
known about how internal reasoning shifts under controlled demographic changes.
We introduce MEDEQUALQA, a counterfactual benchmark that perturbs only patient
pronouns (he/him, she/her, they/them) while holding critical symptoms and
conditions (CSCs) constant. Each clinical vignette is expanded into single-CSC
ablations, producing three parallel datasets of approximately 23,000 items each
(69,000 total). We evaluate a GPT-4.1 model and compute Semantic Textual
Similarity (STS) between reasoning traces to measure stability across pronoun
variants. Our results show overall high similarity (mean STS >0.80), but reveal
consistent localized divergences in cited risk factors, guideline anchors, and
differential ordering, even when final diagnoses remain unchanged. Our error
analysis highlights certain cases in which the reasoning shifts, underscoring
clinically relevant bias loci that may cascade into inequitable care.
MEDEQUALQA offers a controlled diagnostic setting for auditing reasoning
stability in medical AI.

</details>


### [7] [Scheming Ability in LLM-to-LLM Strategic Interactions](https://arxiv.org/abs/2510.12826)
*Thao Pham*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）智能体在不同环境中自主部署，评估其战略欺骗能力至关重要。本研究通过博弈论框架，探讨了前沿LLM智能体的欺骗能力和倾向。


<details>
  <summary>Details</summary>
Motivation: 研究动机是现有研究较少关注LLM之间的欺骗行为，而LLM智能体在自主部署时可能出现欺骗行为。

Method: 通过两个博弈论框架（廉价信号博弈和同行评估对抗博弈）测试了四种模型（GPT-4o、Gemini-2.5-pro、Claude-3.7-Sonnet和Llama-3.3-70b）的欺骗能力，并分析了其推理过程。

Result: 在提示下，大多数模型，尤其是Gemini-2.5-pro和Claude-3.7-Sonnet，几乎达到了完美的欺骗性能。即使没有提示，所有模型在同行评估中都选择了欺骗而非坦白（100%），在廉价信号博弈中选择欺骗的模型成功率也达到了95-100%。

Conclusion: 研究结果表明，需要在多智能体环境中使用高风险的博弈论场景进行稳健的评估，以应对LLM的欺骗行为。

Abstract: As large language model (LLM) agents are deployed autonomously in diverse
contexts, evaluating their capacity for strategic deception becomes crucial.
While recent research has examined how AI systems scheme against human
developers, LLM-to-LLM scheming remains underexplored. We investigate the
scheming ability and propensity of frontier LLM agents through two
game-theoretic frameworks: a Cheap Talk signaling game and a Peer Evaluation
adversarial game. Testing four models (GPT-4o, Gemini-2.5-pro,
Claude-3.7-Sonnet, and Llama-3.3-70b), we measure scheming performance with and
without explicit prompting while analyzing scheming tactics through
chain-of-thought reasoning. When prompted, most models, especially
Gemini-2.5-pro and Claude-3.7-Sonnet, achieved near-perfect performance.
Critically, models exhibited significant scheming propensity without prompting:
all models chose deception over confession in Peer Evaluation (100% rate),
while models choosing to scheme in Cheap Talk succeeded at 95-100% rates. These
findings highlight the need for robust evaluations using high-stakes
game-theoretic scenarios in multi-agent settings.

</details>


### [8] [Mathematics with large language models as provers and verifiers](https://arxiv.org/abs/2510.12829)
*Hieu Le Duc,Leo Liberti*

Main category: cs.CL

TL;DR: ChatGPT使用协作的GPT-5模型，结合Lean证明助手和人工验证，成功解决了一部分IMO问题和数论猜想。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在定理证明方面的能力，验证其是否能证明难题和猜想。

Method: 使用不同的GPT-5模型实例作为证明者和验证者进行协作，并通过Lean证明助手进行形式化验证，最后由人工验证Lean代码的前提和结论是否一致。

Result: 成功解决了六分之五的2025年IMO问题，并解决了[Cohen, Journal of Integer Sequences, 2025]中三分之一的66个数论猜想。

Conclusion: 该方法在定理证明方面取得了显著成果，表明大型语言模型在数学领域具有潜力。

Abstract: During 2024 and 2025 the discussion about the theorem-proving capabilities of
large language models started reporting interesting success stories, mostly to
do with difficult exercises (such as problems from the International
Mathematical Olympiad), but also with conjectures [Feldman & Karbasi,
arXiv:2509.18383v1] formulated for the purpose of verifying whether the
artificial intelligence could prove it. In this paper we report a theorem
proving feat achieved by ChatGPT by using a protocol involving different prover
and verifier instances of the gpt-5 model working collaboratively. To make sure
that the produced proofs do not suffer from hallucinations, the final proof is
formally verified by the lean proof assistant, and the conformance of premises
and conclusion of the lean code is verified by a human. Our methodology was
able to solve five out of six 2025 IMO problems, and close a third of the
sixty-six number theory conjectures in [Cohen, Journal of Integer Sequences,
2025].

</details>


### [9] [Repurposing Annotation Guidelines to Instruct LLM Annotators: A Case Study](https://arxiv.org/abs/2510.12835)
*Kon Woo Kim,Rezarta Islamaj,Jin-Dong Kim,Florian Boudin,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本研究探讨了如何调整现有的标注指南，以指导大型语言模型（LLM）进行文本标注任务。


<details>
  <summary>Details</summary>
Motivation: 传统的指南是为经过训练的人工标注者编写的，他们可以内化培训内容，而LLM则需要明确的、结构化的指令。

Method: 我们提出了一种面向审核的指南改造方法，通过LLM审核过程将指南转化为清晰的指令，以指导LLM。

Result: 以NCBI疾病语料库为例，我们的实验表明，经过改造的指南可以有效地指导LLM标注者，同时也揭示了一些实际的挑战。

Conclusion: 结果强调了该工作流程在支持可扩展且具有成本效益的标注指南改进和自动标注方面的潜力。

Abstract: This study investigates how existing annotation guidelines can be repurposed
to instruct large language model (LLM) annotators for text annotation tasks.
Traditional guidelines are written for human annotators who internalize
training, while LLMs require explicit, structured instructions. We propose a
moderation-oriented guideline repurposing method that transforms guidelines
into clear directives for LLMs through an LLM moderation process. Using the
NCBI Disease Corpus as a case study, our experiments show that repurposed
guidelines can effectively guide LLM annotators, while revealing several
practical challenges. The results highlight the potential of this workflow to
support scalable and cost-effective refinement of annotation guidelines and
automated annotation.

</details>


### [10] [ChatR1: Reinforcement Learning for Conversational Reasoning and Retrieval Augmented Question Answering](https://arxiv.org/abs/2510.13312)
*Simon Lupart,Mohammad Aliannejadi,Evangelos Kanoulas*

Main category: cs.CL

TL;DR: ChatR1: 基于强化学习的对话问答框架，通过交错搜索和推理，实现探索性和自适应行为。


<details>
  <summary>Details</summary>
Motivation: 解决对话问答中用户意图演变、表达不明确等问题，现有静态流水线方法不足。

Method: 提出基于强化学习的ChatR1框架，并设计了一种意图感知奖励，以应对强化学习中的稀疏和延迟奖励问题。

Result: 在五个对话问答数据集上，ChatR1优于现有模型，并在不同指标上表现出色。消融实验验证了意图感知奖励的有效性。

Conclusion: 基于强化学习的推理能够实现比静态流水线更灵活和上下文敏感的行为，ChatR1具有良好的泛化能力。

Abstract: We present ChatR1, a reasoning framework based on reinforcement learning (RL)
for conversational question answering (CQA). Reasoning plays an important role
in CQA, where user intent evolves across dialogue turns, and utterances are
often underspecified, requiring contextual interpretation, query reformulation,
and dynamic coordination between retrieval and generation. Unlike static
`rewrite, retrieve, and generate' pipelines, ChatR1 interleaves search and
reasoning across turns, enabling exploratory and adaptive behaviors learned
through RL. To address the challenge of sparse and delayed rewards in RL, we
propose an intent-aware reward that provides turn-level feedback by aligning
retrieval and reasoning with evolving user goals. Our proposed ChatR1
demonstrates strong performance on both 3B and 7B model backbones,
outperforming competitive models on five CQA datasets, measured by different
metrics (F1, BERTScore, and LLM-as-judge). We include a diverse set of CQA
datasets to cover topic shifts, evolving intents, mixed-initiative dialogues,
and multi-document grounding, testing ChatR1's performance from various
aspects. Ablation studies confirm the effectiveness of the intent-aware reward.
Our analyses further reveal diverse reasoning trajectories and effective use of
the search tool. ChatR1 also generalizes robustly across domains, demonstrating
that RL-based reasoning enables more flexible and context-sensitive behavior
than static CQA pipelines.

</details>


### [11] [A\textsuperscript{2}FM: An Adaptive Agent Foundation Model for Tool-Aware Hybrid Reasoning](https://arxiv.org/abs/2510.12838)
*Qianben Chen,Jingyi Cao,Jiayu Zhang,Tianrui Qin,Xiaowan Li,King Zhu,Dingfeng Shi,He Zhu,Minghao Liu,Xiaobo Liang,Ge Zhang,Jian Yang,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 提出了一个统一的框架，名为自适应代理基础模型（A²FM），它遵循先路由后对齐的原则，以解决推理和工具调用之间的差距，并通过引入即时模式来处理简单查询，从而避免不必要的推理或工具调用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型分为两类：以推理为中心的LLM和代理LLM，它们在深层推理和工具使用方面存在差距，并且在简单查询中效率低下。

Method: 该模型首先学习任务感知的路由，然后在共享主干下对齐特定模式的轨迹。引入第三种模式——即时模式，以直接处理简单查询。提出了自适应策略优化（APO），它强制跨模式进行自适应采样，并应用成本正则化的奖励。

Result: A²FM在BrowseComp上达到13.4％，在AIME25上达到70.4％，在HLE上达到16.7％，与其他可比模型相比，设定了新的SOTA，并且在代理、推理和通用基准测试中与前沿LLM竞争。

Conclusion: 自适应执行实现了每次正确答案仅0.00487美元的成本，相对于推理降低了45.2％的成本，相对于代理降低了33.5％的成本，从而在保持相当的准确性的同时，提供了更高的成本效率。

Abstract: Large language models split into two families: reasoning-centric LLMs, which
strengthen internal chain-of-thought reasoning but cannot invoke external
tools, and agentic LLMs, which learn to interact with environments and leverage
tools but often lag in deep reasoning. This divide arises from fundamentally
different training objectives, leading to mismatched strengths and inefficiency
on simple queries, where both families tend to overthink or over-call tools. In
this work, we present Adaptive Agent Foundation Model (A\textsuperscript{2}FM),
a unified framework that follows a route-then-align principle: the model first
learns task-aware routing and then aligns mode-specific trajectories under a
shared backbone. To address the inefficiency gap, we introduce a third
mode-instant-that handles simple queries directly, preventing unnecessary
reasoning or tool calls while complementing the agentic and reasoning modes. To
jointly enhance accuracy and efficiency, we propose Adaptive Policy
Optimization (APO), which enforces adaptive sampling across modes and applies a
cost-regularized reward. On the 32B scale, A\textsuperscript{2}FM achieves
13.4\% on BrowseComp, 70.4\% on AIME25, and 16.7\% on HLE, setting new SOTA
among comparable models and performing competitively with frontier LLMs across
agentic, reasoning, and general benchmarks. Notably, the adaptive execution
achieves a cost of pass of only \$0.00487 per correct answer-cutting cost by
45.2\% relative to reasoning and 33.5\% relative to agentic, thus delivering
substantially higher cost efficiency while maintaining comparable accuracy.

</details>


### [12] [FaStFACT: Faster, Stronger Long-Form Factuality Evaluations in LLMs](https://arxiv.org/abs/2510.12839)
*Yingjia Wan,Haochen Tan,Xiao Zhu,Xinyu Zhou,Zhiwei Li,Qingsong Lv,Changxuan Sun,Jiaqi Zeng,Yi Xu,Jianqiao Lu,Yinhong Liu,Zhijiang Guo*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为 \name 的快速且强大的评估框架，用于评估大型语言模型生成长文本的事实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在评估大型语言模型生成长文本的事实性时，存在效率低和效果差的问题，因为它们依赖于复杂的流水线组件，并且 claim 集合不准确，证据收集不足。

Method: 该方法首先采用 chunk 级别的 claim 提取，并结合基于置信度的预验证，以降低网络搜索和推理调用的成本。然后，它从爬取的网页中收集文档级别的证据，并在验证过程中选择性地检索这些证据。

Result: 在聚合和手动注释的基准测试中，该方法在评估长文本生成的事实性方面表现出高效和可靠性。

Conclusion: 该方法能够有效地评估大型语言模型生成长文本的事实性，并在效率和效果上优于现有基线。

Abstract: Evaluating the factuality of long-form generations from Large Language Models
(LLMs) remains challenging due to accuracy issues and costly human assessment.
Prior efforts attempt this by decomposing text into claims, searching for
evidence, and verifying claims, but suffer from critical drawbacks: (1)
inefficiency due to complex pipeline components unsuitable for long LLM
outputs, and (2) ineffectiveness stemming from inaccurate claim sets and
insufficient evidence collection of one-line snippets.
  To address these limitations, we propose \name, a fast and strong evaluation
framework that achieves the highest alignment with human evaluation and
efficiency among existing baselines. \name first employs chunk-level claim
extraction integrated with confidence-based pre-verification, significantly
reducing the cost of web searching and inference calling while ensuring
reliability. For searching and verification, it collects document-level
evidence from crawled webpages and selectively retrieves it during
verification, addressing the evidence insufficiency problem in previous
pipelines.
  Extensive experiments based on an aggregated and manually annotated benchmark
demonstrate the reliability of \name in both efficiently and effectively
evaluating the factuality of long-form LLM generations. Code and benchmark data
is available at https://github.com/Yingjia-Wan/FastFact.

</details>


### [13] [VLURes: Benchmarking VLM Visual and Linguistic Understanding in Low-Resource Languages](https://arxiv.org/abs/2510.12845)
*Jesse Atuhurra,Iqra Ali,Tomoya Iwakura,Hidetaka Kamigaito,Tatsuya Hiraoka*

Main category: cs.CL

TL;DR: 提出了一个新的多语言视觉语言基准 VLURes，用于评估 VLM 在长文本设置下的细粒度能力。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLM 评估主要集中在以英语为中心的基准上，图像-文本对包含短文本，无法全面评估 VLM 的细粒度能力。

Method: 构建了一个包含八个视觉语言任务和开创性的不相关性任务的 VLURes 基准，涵盖英语、日语、斯瓦希里语和乌尔都语四种语言，并从网络资源中整理数据集，包含十个不同的图像类别和丰富的文本内容。

Result: 评估了十个 VLM 在 VLURes 上的表现，发现不同语言和任务之间存在性能差异。GPT-4o 表现最佳，但仍与人类水平存在差距，开源模型的差距更大。

Conclusion: VLURes 在开发用于处理多模态视觉推理的智能代理方面发挥着关键作用。

Abstract: Vision Language Models (VLMs) are pivotal for advancing perception in
intelligent agents. Yet, evaluation of VLMs remains limited to predominantly
English-centric benchmarks in which the image-text pairs comprise short texts.
To evaluate VLM fine-grained abilities, in four languages under long-text
settings, we introduce a novel multilingual benchmark VLURes featuring eight
vision-and-language tasks, and a pioneering unrelatedness task, to probe the
fine-grained Visual and Linguistic Understanding capabilities of VLMs across
English, Japanese, and low-resource languages, Swahili, and Urdu. Our datasets,
curated from web resources in the target language, encompass ten diverse image
categories and rich textual context, introducing valuable vision-language
resources for Swahili and Urdu. By prompting VLMs to generate responses and
rationales, evaluated automatically and by native speakers, we uncover
performance disparities across languages and tasks critical to intelligent
agents, such as object recognition, scene understanding, and relationship
understanding. We conducted evaluations of ten VLMs with VLURes. The best
performing model, GPT-4o, achieves an overall accuracy of 90.8% and lags human
performance by 6.7%, though the gap is larger for open-source models. The gap
highlights VLURes' critical role in developing intelligent agents to tackle
multi-modal visual reasoning.

</details>


### [14] [Efficient Adaptive Transformer: An Empirical Study and Reproducible Framework](https://arxiv.org/abs/2510.12856)
*Jan Miller*

Main category: cs.CL

TL;DR: EAT框架整合了三种自适应效率技术，用于输入自适应推理。


<details>
  <summary>Details</summary>
Motivation: 为延迟敏感的NLP提供动态计算的潜力

Method: 将渐进式token剪枝、稀疏注意力和动态提前退出统一到一个可重现的架构中

Result: 在SST-2上实现了比DistilBERT基线略高的准确率

Conclusion: EAT提供了一个开放的、端到端的可重现框架，旨在为自适应transformer的进一步研究提供社区工具。

Abstract: The Efficient Adaptive Transformer (EAT) framework unifies three adaptive
efficiency techniques - progressive token pruning, sparse attention, and
dynamic early exiting - into a single, reproducible architecture for
input-adaptive inference. EAT provides an open-source benchmarking pipeline
that automates data processing, timing, and ablation across GLUE tasks (SST-2,
QQP, MNLI). Although this empirical study finds that combining these mechanisms
can increase latency in shallow six-layer models, it demonstrates that EAT
achieves slightly higher accuracy than the optimized DistilBERT baseline on
SST-2, illustrating the potential of dynamic computation for latency-sensitive
NLP. The main contribution is the open, end-to-end reproducible framework -
complete with scripts, CSV logging, and analysis utilities - intended to serve
as a community tool for further research on adaptive transformers.

</details>


### [15] [A Critical Review of the Need for Knowledge-Centric Evaluation of Quranic Recitation](https://arxiv.org/abs/2510.12858)
*Mohammed Hilal Al-Kharusi,Khizar Hayat,Khalil Bader Al Ruqeishi,Haroon Rashid Lone*

Main category: cs.CL

TL;DR: 现有古兰经背诵评估工具效果不佳，未被广泛采用。


<details>
  <summary>Details</summary>
Motivation: 现代古兰经背诵教学面临挑战，数字化工具应用不足。

Method: 对过去二十年的学术研究、网络平台和商业应用进行了综合分析。

Result: 现有方法存在根本性偏差，过度依赖自动语音识别 (ASR) 架构，导致语音评估质量不高，且受数据依赖性、人口偏见和诊断反馈不足等问题的影响。

Conclusion: 未来的古兰经自动评估应采用混合系统，将语言知识与音频分析相结合，为全球学习者提供支持。

Abstract: The sacred practice of Quranic recitation (Tajweed), governed by precise
phonetic, prosodic, and theological rules, faces significant pedagogical
challenges in the modern era. While digital technologies promise unprecedented
access to education, automated tools for recitation evaluation have failed to
achieve widespread adoption or pedagogical efficacy. This literature review
investigates this critical gap, conducting a comprehensive analysis of academic
research, web platforms, and commercial applications developed over the past
two decades. Our synthesis reveals a fundamental misalignment in prevailing
approaches that repurpose Automatic Speech Recognition (ASR) architectures,
which prioritize lexical recognition over qualitative acoustic assessment and
are plagued by data dependency, demographic biases, and an inability to provide
diagnostically useful feedback. Critiquing these data--driven paradigms, we
argue for a foundational paradigm shift towards a knowledge-centric
computational framework. Capitalizing on the immutable nature of the Quranic
text and the precisely defined rules of Tajweed, we propose that a robust
evaluator must be architected around anticipatory acoustic modeling based on
canonical rules and articulation points (Makhraj), rather than relying on
statistical patterns learned from imperfect and biased datasets. This review
concludes that the future of automated Quranic evaluation lies in hybrid
systems that integrate deep linguistic knowledge with advanced audio analysis,
offering a path toward robust, equitable, and pedagogically sound tools that
can faithfully support learners worldwide.

</details>


### [16] [EduDial: Constructing a Large-scale Multi-turn Teacher-Student Dialogue Corpus](https://arxiv.org/abs/2510.12899)
*Shouang Wei,Min Zhang,Xin Lin,Bo Jiang,Zhongxiang Dai,Kun Kuang*

Main category: cs.CL

TL;DR: 提出了一个多轮师生对话数据集EduDial，并训练了EduDial-LLM模型，该模型在教学能力方面优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在智能教育中具有重要作用，因此构建专门的师生对话基准非常重要。

Method: 构建了一个包含345个核心知识点和34,250个对话的EduDial数据集，并设计了差异化的教学策略。通过训练，进一步开发了EduDial-LLM 32B。

Result: EduDial-LLM在学生中心教学场景中表现出色，并在所有指标上优于所有基线模型。

Conclusion: EduDial-LLM在教学能力方面取得了显著进展。

Abstract: Recently, several multi-turn dialogue benchmarks have been proposed to
evaluate the conversational abilities of large language models (LLMs). As LLMs
are increasingly recognized as a key technology for advancing intelligent
education, owing to their ability to deeply understand instructional contexts
and provide personalized guidance, the construction of dedicated
teacher-student dialogue benchmarks has become particularly important. To this
end, we present EduDial, a comprehensive multi-turn teacher-student dialogue
dataset. EduDial covers 345 core knowledge points and consists of 34,250
dialogue sessions generated through interactions between teacher and student
agents. Its design is guided by Bloom's taxonomy of educational objectives and
incorporates ten questioning strategies, including situational questioning,
zone of proximal development (ZPD) questioning, and metacognitive
questioning-thus better capturing authentic classroom interactions.
Furthermore, we design differentiated teaching strategies for students at
different cognitive levels, thereby providing more targeted teaching guidance.
Building on EduDial, we further develop EduDial-LLM 32B via training and
propose an 11-dimensional evaluation framework that systematically measures the
teaching abilities of LLMs, encompassing both overall teaching quality and
content quality. Experiments on 17 mainstream LLMs reveal that most models
struggle in student-centered teaching scenarios, whereas our EduDial-LLM
achieves significant gains, consistently outperforming all baselines across all
metrics. The code is available at
https://github.com/Mind-Lab-ECNU/EduDial/tree/main.

</details>


### [17] [Who's Asking? Evaluating LLM Robustness to Inquiry Personas in Factual Question Answering](https://arxiv.org/abs/2510.12925)
*Nil-Jana Akpinar,Chia-Jung Lee,Vanessa Murdock,Pietro Perona*

Main category: cs.CL

TL;DR: 评估大型语言模型（LLM）在面对带有身份、专业知识或信仰等属性的用户画像时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型应基于客观知识如实回答事实性问题，而不受用户背景信息的影响。本文旨在系统性评估大型语言模型对用户画像的鲁棒性。

Method: 通过构建包含身份、专业知识或信仰等属性的用户画像，评估这些画像线索对问答准确性的影响。

Result: 用户画像线索会显著改变问答准确性，并引发拒绝回答、幻觉限制和角色混淆等问题。

Conclusion: 模型对用户框架的敏感性会损害事实可靠性，用户画像测试是鲁棒性评估的有效工具。

Abstract: Large Language Models (LLMs) should answer factual questions truthfully,
grounded in objective knowledge, regardless of user context such as
self-disclosed personal information, or system personalization. In this paper,
we present the first systematic evaluation of LLM robustness to inquiry
personas, i.e. user profiles that convey attributes like identity, expertise,
or belief. While prior work has primarily focused on adversarial inputs or
distractors for robustness testing, we evaluate plausible, human-centered
inquiry persona cues that users disclose in real-world interactions. We find
that such cues can meaningfully alter QA accuracy and trigger failure modes
such as refusals, hallucinated limitations, and role confusion. These effects
highlight how model sensitivity to user framing can compromise factual
reliability, and position inquiry persona testing as an effective tool for
robustness evaluation.

</details>


### [18] [The Curious Case of Curiosity across Human Cultures and LLMs](https://arxiv.org/abs/2510.12943)
*Angana Borah,Rada Mihalcea*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型(llm)在跨文化背景下的好奇心表现，发现llm倾向于模仿西方文化的好奇心表达方式，并通过微调方法缩小了这种差距。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在不同文化背景下的好奇心表现，填补了该领域的研究空白。

Method: 提出了CUEST框架，通过语言风格、主题偏好分析等方法评估llm的好奇心，并结合社会科学理论进行分析。

Result: 发现llm在跨文化好奇心表达方面存在扁平化现象，更接近西方文化的好奇心表达方式；通过微调策略，human-model alignment gap缩小了50%。

Conclusion: 好奇心对于llm在不同文化中的适应性至关重要，未来的自然语言处理研究应重视好奇心。

Abstract: Recent advances in Large Language Models (LLMs) have expanded their role in
human interaction, yet curiosity -- a central driver of inquiry -- remains
underexplored in these systems, particularly across cultural contexts. In this
work, we investigate cultural variation in curiosity using Yahoo! Answers, a
real-world multi-country dataset spanning diverse topics. We introduce CUEST
(CUriosity Evaluation across SocieTies), an evaluation framework that measures
human-model alignment in curiosity through linguistic (style), topic preference
(content) analysis and grounding insights in social science constructs. Across
open- and closed-source models, we find that LLMs flatten cross-cultural
diversity, aligning more closely with how curiosity is expressed in Western
countries. We then explore fine-tuning strategies to induce curiosity in LLMs,
narrowing the human-model alignment gap by up to 50\%. Finally, we demonstrate
the practical value of curiosity for LLM adaptability across cultures, showing
its importance for future NLP research.

</details>


### [19] [3-Model Speculative Decoding](https://arxiv.org/abs/2510.12966)
*Sanghyun Byun,Mohanad Odema,Jung Ick Guack,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CL

TL;DR: Pyramid Speculative Decoding (PyramidSD) improves speculative decoding by adding an intermediate qualifier model between the draft and target models, leading to higher acceptance rates and faster generation speeds.


<details>
  <summary>Details</summary>
Motivation: Speculative Decoding's speed is limited by the trade-off between draft model size and token acceptance rate.

Method: PyramidSD uses a qualifier model to bridge the gap between the draft and target models, along with fuzzy acceptance criteria.

Result: PyramidSD achieves up to 1.91x speedup over standard SD, reaching 124 tokens/second on an RTX 4090. It also performs well in small-memory settings.

Conclusion: PyramidSD enhances speculative decoding efficiency and is easily applicable to existing pipelines.

Abstract: Speculative Decoding (SD) accelerates inference in large language models by
using a smaller draft model to propose tokens, which are then verified by a
larger target model. However, the throughput gains of SD are fundamentally
limited by a trade-off between draft model size and token acceptance: smaller
draft models generate tokens more quickly but exhibit greater divergence from
the target model, resulting in lower acceptance rates and reduced speedups. We
introduce Pyramid Speculative Decoding (PyramidSD), an extension of SD that
inserts an intermediate qualifier model between the draft and target to bridge
the distributional gap in output predictions, allowing smaller model to be used
for drafting. This hierarchical decoding strategy improves alignment across
models, enabling higher acceptance rates and allowing the use of significantly
smaller draft models without sacrificing overall performance. PyramidSD builds
on fuzzy acceptance criteria to support relaxed divergence thresholds at each
stage, improving throughput. In experiments, PyramidSD achieves up to 1.91x
generation speed over standard SD, reaching 124 tokens per second on a consumer
GPU (RTX 4090). In small-memory settings with a 1B-parameter draft model and an
8B target model, PyramidSD minimally trades target model quality for improved
throughput. Overall, PyramidSD offers a practical approach to enhancing
speculative decoding efficiency and can be readily applied to existing
inference pipelines.

</details>


### [20] [A Multilingual, Large-Scale Study of the Interplay between LLM Safeguards, Personalisation, and Disinformation](https://arxiv.org/abs/2510.12993)
*João A. Leite,Arnav Arora,Silvia Gargova,João Luz,Gustavo Sampaio,Ian Roberts,Carolina Scarton,Kalina Bontcheva*

Main category: cs.CL

TL;DR: 大型语言模型(llm)生成有说服力和个性化的虚假信息的能力引起了人们的担忧。本文对llm针对特定人群生成虚假信息进行了大规模、多语种的实证研究，并评估了llm安全机制对人群定向提示的鲁棒性。本研究创建了一个包含160万条文本的新数据集AI-TRAITS，这些文本由8个最先进的llm生成。研究结果表明，在提示中使用简单的个性化策略会显著增加所有研究llm的越狱可能性。此外，个性化的提示会导致语言和修辞模式的改变，并增强llm生成的虚假叙述的说服力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(llm)在生成有说服力和个性化的虚假信息方面存在潜在的误用。

Method: 采用红队方法，系统地评估llm安全机制对人群定向提示的鲁棒性。创建了一个包含160万条文本的新数据集AI-TRAITS，这些文本由8个最先进的llm生成，并结合了324个虚假信息叙述和150个不同的人群画像，涵盖四种主要语言(英语、俄语、葡萄牙语、印地语)和关键的人口维度(国家、世代、政治倾向)。

Result: 即使在提示中使用简单的个性化策略也会显著增加所有研究llm的越狱可能性。个性化的提示会导致语言和修辞模式的改变，并增强llm生成的虚假叙述的说服力。

Conclusion: 目前最先进的llm存在严重漏洞，本研究为改进多语种和跨人口背景下的安全对齐和检测策略奠定了基础。

Abstract: The human-like proficiency of Large Language Models (LLMs) has brought
concerns about their potential misuse for generating persuasive and
personalised disinformation at scale. While prior work has demonstrated that
LLMs can generate disinformation, specific questions around persuasiveness and
personalisation (generation of disinformation tailored to specific demographic
attributes) remain largely unstudied. This paper presents the first
large-scale, multilingual empirical study on persona-targeted disinformation
generation by LLMs. Employing a red teaming methodology, we systematically
evaluate the robustness of LLM safety mechanisms to persona-targeted prompts. A
key novel result is AI-TRAITS (AI-generaTed peRsonAlIsed disinformaTion
dataSet), a new dataset of around 1.6 million texts generated by eight
state-of-the-art LLMs. AI-TRAITS is seeded by prompts that combine 324
disinformation narratives and 150 distinct persona profiles, covering four
major languages (English, Russian, Portuguese, Hindi) and key demographic
dimensions (country, generation, political orientation). The resulting
personalised narratives are then assessed quantitatively and compared along the
dimensions of models, languages, jailbreaking rate, and personalisation
attributes. Our findings demonstrate that the use of even simple
personalisation strategies in the prompts significantly increases the
likelihood of jailbreaks for all studied LLMs. Furthermore, personalised
prompts result in altered linguistic and rhetorical patterns and amplify the
persuasiveness of the LLM-generated false narratives. These insights expose
critical vulnerabilities in current state-of-the-art LLMs and offer a
foundation for improving safety alignment and detection strategies in
multilingual and cross-demographic contexts.

</details>


### [21] [OPLoRA: Orthogonal Projection LoRA Prevents Catastrophic Forgetting during Parameter-Efficient Fine-Tuning](https://arxiv.org/abs/2510.13003)
*Yifeng Xiong,Xiaohui Xie*

Main category: cs.CL

TL;DR: OPLoRA通过正交投影防止LoRA更新干扰预训练知识，从而减少灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: LoRA在微调大型语言模型时会发生灾难性遗忘，因为它干扰了编码重要预训练知识的主导奇异方向。

Method: OPLoRA使用双边正交投影，将LoRA更新限制在顶部奇异子空间的垂直补集中。通过SVD分解冻结权重，并使用投影 $P_L = I - U_k U_k^	$ 和 $P_R = I - V_k V_k^	$。

Result: OPLoRA显著减少了遗忘，同时在LLaMA-2 7B和Qwen2.5 7B上保持了有竞争力的特定任务性能。$\rho_k$指标用于量化子空间干扰。

Conclusion: 正交投影是参数高效微调中知识保留的有效机制。

Abstract: Low-Rank Adaptation (LoRA) enables efficient fine-tuning of large language
models but suffers from catastrophic forgetting when learned updates interfere
with the dominant singular directions that encode essential pre-trained
knowledge. We propose Orthogonal Projection LoRA (OPLoRA), a theoretically
grounded approach that prevents this interference through double-sided
orthogonal projections. By decomposing frozen weights via SVD, OPLoRA
constrains LoRA updates to lie entirely within the orthogonal complement of the
top-$k$ singular subspace using projections $P_L = I - U_k U_k^\top$ and $P_R =
I - V_k V_k^\top$. We prove that this construction exactly preserves the
top-$k$ singular triples, providing mathematical guarantees for knowledge
retention. To quantify subspace interference, we introduce $\rho_k$, a metric
measuring update alignment with dominant directions. Extensive experiments
across commonsense reasoning, mathematics, and code generation demonstrate that
OPLoRA significantly reduces forgetting while maintaining competitive
task-specific performance on LLaMA-2 7B and Qwen2.5 7B, establishing orthogonal
projection as an effective mechanism for knowledge preservation in
parameter-efficient fine-tuning.

</details>


### [22] [CurLL: A Developmental Framework to Evaluate Continual Learning in Language Models](https://arxiv.org/abs/2510.13008)
*Pavan Kalyan,Shubhra Mishra,Satya Lokam,Navin Goyal*

Main category: cs.CL

TL;DR: 提出了一个全面的持续学习数据集和基准（CurlL），模仿人类5-10岁的发育轨迹，用于评估模型逐步获取新技能的能力。


<details>
  <summary>Details</summary>
Motivation: 旨在系统地、细粒度地评估模型逐步获取新技能的能力。

Method: 构建了一个包含五个发育阶段（0-4）的数据集，这些阶段覆盖5-10岁，并由一个技能图支持，该技能图将广泛的技能分解为更小的能力、具体目标和可衡量的指标。生成了一个包含234亿个token的合成数据集，该数据集具有受控的技能进展、词汇复杂性和格式多样性，包括段落、基于理解的问答（CQA）、技能测试问答（CSQA）和指令-响应（IR）对。

Result: 使用一个1.35亿参数的transformer，在独立、联合和顺序（持续）设置下进行训练，展示了技能保留和迁移效率之间的权衡。

Conclusion: 通过镜像人类学习模式并提供对技能依赖性的细粒度控制，这项工作推进了语言模型的持续学习评估。

Abstract: We introduce a comprehensive continual learning dataset and benchmark (CurlL)
grounded in human developmental trajectories from ages 5-10, enabling
systematic and fine-grained assessment of models' ability to progressively
acquire new skills. CurlL spans five developmental stages (0-4) covering ages
5-10, supported by a skill graph that breaks down broad skills into smaller
abilities, concrete goals, and measurable indicators, while also capturing
which abilities build on others. We generate a 23.4B-token synthetic dataset
with controlled skill progression, vocabulary complexity, and format diversity,
comprising paragraphs, comprehension-based QA (CQA), skill-testing QA (CSQA),
and instruction-response (IR) pairs. Stage-wise token counts range from 2.12B
to 6.78B tokens, supporting precise analysis of forgetting, forward transfer,
and backward transfer. Using a 135M-parameter transformer trained under
independent, joint, and sequential (continual) setups, we show trade-offs in
skill retention and transfer efficiency. By mirroring human learning patterns
and providing fine-grained control over skill dependencies, this work advances
continual learning evaluations for language models.

</details>


### [23] [On the Role of Preference Variance in Preference Optimization](https://arxiv.org/abs/2510.13022)
*Jiacheng Guo,Zihao Li,Jiahao Qiu,Yue Wu,Mengdi Wang*

Main category: cs.CL

TL;DR: 本文研究了直接偏好优化（DPO）中偏好方差（PVar）对模型对齐效果的影响，发现高PVar的prompt对学习更有价值。


<details>
  <summary>Details</summary>
Motivation: 人工标注偏好数据成本高效率低，需要减少标注的方法。

Method: 理论上，建立了DPO梯度范数的上界，表明它受prompt的PVar控制。通过reward模型生成偏好，并在AlpacaEval 2.0和Arena-Hard上进行实验验证。

Result: 实验结果表明，较高PVar的prompt优于随机选择的prompt或较低PVar的prompt。即使使用较小的reward模型进行选择，基于PVar的选择方法也很稳健。使用UltraFeedback数据集的原始人工标注，仅使用前10％最高PVar的prompt进行训练，比在完整数据集上训练产生更好的评估性能。

Conclusion: 偏好方差在识别用于有效LLM对齐的信息性示例中非常重要。

Abstract: Direct Preference Optimization (DPO) has emerged as an important approach for
learning from human preferences in aligning large language models (LLMs).
However, collecting human preference data is costly and inefficient, motivating
methods to reduce the required annotations. In this work, we investigate the
impact of \emph{preference variance} (PVar), which measures the variance in
model preferences when comparing pairs of responses, on the effectiveness of
DPO training. We provide a theoretical insight by establishing an upper bound
on the DPO gradient norm for any given prompt, showing it is controlled by the
PVar of that prompt. This implies that prompts with low PVar can only produce
small gradient updates, making them less valuable for learning. We validate
this finding by fine-tuning LLMs with preferences generated by a reward model,
evaluating on two benchmarks (AlpacaEval 2.0 and Arena-Hard). Experimental
results demonstrate that prompts with higher PVar outperform randomly selected
prompts or those with lower PVar. We also show that our PVar-based selection
method is robust, when using smaller reward models (1B, 3B) for selection.
Notably, in a separate experiment using the original human annotations from the
UltraFeedback dataset, we found that training on only the top 10\% of prompts
with the highest PVar yields better evaluation performance than training on the
full dataset, highlighting the importance of preference variance in identifying
informative examples for efficient LLM alignment.

</details>


### [24] [GatePro: Parameter-Free Expert Selection Optimization for Mixture-of-Experts Models](https://arxiv.org/abs/2510.13079)
*Chen Zheng,Yuhang Cai,Deyi Liu,Jin Ma,Yiyuan Ma,Yuan Yang,Jing Liu,Yutao Zeng,Xun Zhou,Siyuan Qiao*

Main category: cs.CL

TL;DR: GatePro is a parameter-free method that promotes expert selection diversity by introducing localized competition mechanisms, preventing redundant expert co-activation while maintaining natural expert specialization.


<details>
  <summary>Details</summary>
Motivation: Functionally similar experts are often selected simultaneously, creating redundant computation and limiting effective model capacity. Existing auxiliary balance loss methods improve token distribution but fail to address the underlying expert diversity problem.

Method: GatePro identifies the most similar expert pairs and introduces localized competition mechanisms.

Result: GatePro's effectiveness is demonstrated across model scales and benchmarks. It achieves enhanced expert diversity, where experts develop more distinct and complementary capabilities, avoiding functional redundancy.

Conclusion: GatePro can be deployed hot-swappable during any training phase without additional learnable parameters, offering a practical solution for improving MoE effectiveness.

Abstract: Modern large language models leverage Mixture-of-Experts (MoE) architectures
for efficient scaling, but face a critical challenge: functionally similar
experts are often selected simultaneously, creating redundant computation and
limiting effective model capacity. Existing auxiliary balance loss methods
improve token distribution but fail to address the underlying expert diversity
problem. We introduce GatePro, a novel parameter-free method that directly
promotes expert selection diversity. GatePro identifies the most similar expert
pairs and introduces localized competition mechanisms, preventing redundant
expert co-activation while maintaining natural expert specialization. Our
comprehensive evaluation demonstrates GatePro's effectiveness across model
scales and benchmarks. Analysis demonstrates GatePro's ability to achieve
enhanced expert diversity, where experts develop more distinct and
complementary capabilities, avoiding functional redundancy. This approach can
be deployed hot-swappable during any training phase without additional
learnable parameters, offering a practical solution for improving MoE
effectiveness.

</details>


### [25] [ESI: Epistemic Uncertainty Quantification via Semantic-preserving Intervention for Large Language Models](https://arxiv.org/abs/2510.13103)
*Mingda Li,Xinyu Li,Weinan Zhang,Longxuan Ma*

Main category: cs.CL

TL;DR: 提出了一种新的LLM不确定性量化方法，该方法通过语义保留干预来衡量模型输出的变化。


<details>
  <summary>Details</summary>
Motivation: 量化大型语言模型（LLM）的不确定性非常重要，但并非易事。

Method: 提出了一种新颖的灰盒不确定性量化方法，该方法在语义保留干预前后测量模型输出的变化。

Result: 通过理论验证和大量实验，证明了该方法在有效性和计算效率方面都表现出色。

Conclusion: 该方法为认知不确定性提供了有效的估计。

Abstract: Uncertainty Quantification (UQ) is a promising approach to improve model
reliability, yet quantifying the uncertainty of Large Language Models (LLMs) is
non-trivial. In this work, we establish a connection between the uncertainty of
LLMs and their invariance under semantic-preserving intervention from a causal
perspective. Building on this foundation, we propose a novel grey-box
uncertainty quantification method that measures the variation in model outputs
before and after the semantic-preserving intervention. Through theoretical
justification, we show that our method provides an effective estimate of
epistemic uncertainty. Our extensive experiments, conducted across various LLMs
and a variety of question-answering (QA) datasets, demonstrate that our method
excels not only in terms of effectiveness but also in computational efficiency.

</details>


### [26] [Multi-Label Clinical Text Eligibility Classification and Summarization System](https://arxiv.org/abs/2510.13115)
*Surya Tejaswi Yerramsetty,Almas Fathimah*

Main category: cs.CL

TL;DR: 本研究提出了一种利用自然语言处理（NLP）和大型语言模型（LLM）来自动进行多标签临床文本资格分类和总结的系统。


<details>
  <summary>Details</summary>
Motivation: 临床试验对于医学进步至关重要，它们有助于提高对人类健康和医疗保健系统的理解。临床试验在发现检测、预防或治疗疾病的新方法方面起着关键作用，临床试验必须包括具有适当和多样医学背景的参与者。

Method: 该系统结合了词嵌入（Word2Vec）和命名实体识别等特征提取方法来识别相关的医学概念，以及传统的向量化技术，如计数向量化和TF-IDF（词频-逆文档频率）。此外，还探索了加权TF-IDF词嵌入，它整合了基于计数和基于嵌入的优势，以有效地捕捉术语的重要性。使用随机森林和SVM模型的多标签分类被应用于根据资格标准对文档进行分类。评估了包括TextRank、Luhn和GPT-3在内的摘要技术，以简洁地总结资格要求。

Result: 使用ROUGE分数的评估证明了所提出方法的有效性。

Conclusion: 该系统显示了使用数据驱动方法自动进行临床试验资格评估的潜力，从而提高研究效率。

Abstract: Clinical trials are central to medical progress because they help improve
understanding of human health and the healthcare system. They play a key role
in discovering new ways to detect, prevent, or treat diseases, and it is
essential that clinical trials include participants with appropriate and
diverse medical backgrounds. In this paper, we propose a system that leverages
Natural Language Processing (NLP) and Large Language Models (LLMs) to automate
multi-label clinical text eligibility classification and summarization. The
system combines feature extraction methods such as word embeddings (Word2Vec)
and named entity recognition to identify relevant medical concepts, along with
traditional vectorization techniques such as count vectorization and TF-IDF
(Term Frequency-Inverse Document Frequency). We further explore weighted TF-IDF
word embeddings that integrate both count-based and embedding-based strengths
to capture term importance effectively. Multi-label classification using Random
Forest and SVM models is applied to categorize documents based on eligibility
criteria. Summarization techniques including TextRank, Luhn, and GPT-3 are
evaluated to concisely summarize eligibility requirements. Evaluation with
ROUGE scores demonstrates the effectiveness of the proposed methods. This
system shows potential for automating clinical trial eligibility assessment
using data-driven approaches, thereby improving research efficiency.

</details>


### [27] [Stable LLM Ensemble: Interaction between Example Representativeness and Diversity](https://arxiv.org/abs/2510.13143)
*Junichiro Niimi*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型（LLM）中，示例代表性和输出多样性对LLM集成性能的影响，发现结合代表性示例选择和提高温度可以显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 提高one-shot LLM预测的准确性和鲁棒性，并研究示例代表性和集成成员的多样性对性能的影响。

Method: 比较基于中心点的代表性示例（提出的方法）和随机抽样示例（基线），并改变抽样温度。

Result: 提出的方法在高温度设置下，显著优于随机选择（macro-F1提高7.6%，RMSE降低10.5%），甚至超过了5-shot prompting（macro-F1提高21.1%，RMSE降低24.0%）。

Conclusion: 结合代表性示例选择和提高温度，可以为集成提供适当的多样性水平，这对于设计有效的one-shot LLM集成至关重要。

Abstract: Large language models (LLMs) have achieved remarkable results in wide range
of domains. However, the accuracy and robustness of one-shot LLM predictions
remain highly sensitive to the examples and the diversity among ensemble
members. This study systematically investigates the effects of example
representativeness (one-shot strategy) and output diversity (sampling
temperature) on LLM ensemble performance. Two one-shot strategies are compared:
centroid-based representative examples (proposed) and randomly sampled examples
(baseline) and sampling temperature also is varied. The proposed approach with
higher temperature setting significantly outperforms random selection by +7.6%
(macro-F1) and -10.5% (RMSE). Furthermore, the proposed model exceeds 5-shot
prompting by +21.1% (macro-F1) and -24.0% (RMSE). Our findings demonstrate that
combining representative example selection with increased temperature provides
the appropriate level of diversity to the ensemble. This work highlights the
practical importance of both example selection and controlled diversity in
designing effective one-shot LLM ensembles.

</details>


### [28] [I Am Aligned, But With Whom? MENA Values Benchmark for Evaluating Cultural Alignment and Multilingual Bias in LLMs](https://arxiv.org/abs/2510.13154)
*Pardis Sadat Zahraei,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: MENAValues是一个新的基准，旨在评估大型语言模型（LLM）在文化上与中东和北非（MENA）地区的价值观的对齐情况，该地区在当前的人工智能评估工作中代表性不足。


<details>
  <summary>Details</summary>
Motivation: 旨在衡量大型语言模型与中东和北非地区文化价值观的偏差，该地区在人工智能评估中代表性不足。

Method: 从大规模、权威的人工调查中，我们整理了一个结构化的数据集，该数据集通过来自16个国家的人口水平的反应分布来捕捉MENA的社会文化景观。为了探测LLM的行为，我们评估了跨多个条件的不同模型，这些条件由三个视角框架（中立、个性化和第三人/文化观察者）与两种语言模式（英语和本地化母语：阿拉伯语、波斯语、土耳其语）交叉形成。

Result: 我们的分析揭示了三种关键现象：相同的用不同语言提问会产生截然不同的回答；提示模型解释他们的理由会恶化文化契合度；模型拒绝回答敏感问题，而内部概率揭示了强烈的隐藏偏好。我们进一步证明，当模型以母语运行时，会将不同的国家视为铁板一块。

Conclusion: MENAValues提供了一个可扩展的框架，用于诊断文化错位，为开发更具文化包容性的人工智能提供实证见解和方法工具。

Abstract: We introduce MENAValues, a novel benchmark designed to evaluate the cultural
alignment and multilingual biases of large language models (LLMs) with respect
to the beliefs and values of the Middle East and North Africa (MENA) region, an
underrepresented area in current AI evaluation efforts. Drawing from
large-scale, authoritative human surveys, we curate a structured dataset that
captures the sociocultural landscape of MENA with population-level response
distributions from 16 countries. To probe LLM behavior, we evaluate diverse
models across multiple conditions formed by crossing three perspective framings
(neutral, personalized, and third-person/cultural observer) with two language
modes (English and localized native languages: Arabic, Persian, Turkish). Our
analysis reveals three critical phenomena: "Cross-Lingual Value Shifts" where
identical questions yield drastically different responses based on language,
"Reasoning-Induced Degradation" where prompting models to explain their
reasoning worsens cultural alignment, and "Logit Leakage" where models refuse
sensitive questions while internal probabilities reveal strong hidden
preferences. We further demonstrate that models collapse into simplistic
linguistic categories when operating in native languages, treating diverse
nations as monolithic entities. MENAValues offers a scalable framework for
diagnosing cultural misalignment, providing both empirical insights and
methodological tools for developing more culturally inclusive AI.

</details>


### [29] [Mirror Speculative Decoding: Breaking the Serial Barrier in LLM Inference](https://arxiv.org/abs/2510.13161)
*Nikhil Bhendawade,Kumari Nishu,Arnav Kundu,Chris Bartels,Minsik Cho,Irina Belousova*

Main category: cs.CL

TL;DR: Mirror Speculative Decoding (Mirror-SD) accelerates LLM inference by using a draft model to look ahead and introducing two complementary execution pipelines.


<details>
  <summary>Details</summary>
Motivation: Gains are capped by the cost of autoregressive draft generation: increasing draft size elevates acceptance rates but introduces additional latency overhead exacerbating the speed-accuracy tradeoff.

Method: launches branch-complete rollouts from early-exit signals in parallel with the target model's suffix and explicitly maps computation across heterogeneous accelerators (GPU and NPU) to exploit cross-device parallelism. To further cut draft latency without weakening acceptance semantics, we add speculative streaming so the draft emits multiple tokens per step.

Result: delivers consistent end-to-end gains, achieving 2.8x-5.8x wall-time speedups across diverse tasks and a 30% average relative improvement over the strongest baseline, EAGLE3.

Conclusion: Mirror-SD pushes speculative decoding toward its ideal regime of high acceptance with low overhead.

Abstract: Speculative decoding accelerates LLM inference by using a draft model to look
ahead, but gains are capped by the cost of autoregressive draft generation:
increasing draft size elevates acceptance rates but introduces additional
latency overhead exacerbating the speed-accuracy tradeoff. Prior methods
(Medusa, Hydra, EAGLE) partially reduce draft cost but either degrade
acceptance or introduce overheads that limit scaling. We present Mirror
Speculative Decoding (Mirror-SD), an inference algorithm that breaks the
latency-acceptance tradeoff. Mirror-SD launches branch-complete rollouts from
early-exit signals in parallel with the target model's suffix and explicitly
maps computation across heterogeneous accelerators (GPU and NPU) to exploit
cross-device parallelism. The draft speculates forward continuations for the
target to verify, while the target simultaneously speculates correction paths
for the draft, converting speculation into two complementary execution
pipelines. To further cut draft latency without weakening acceptance semantics,
we add speculative streaming so the draft emits multiple tokens per step. This
dual strategy of parallel heterogeneous execution plus multi-token speculative
streaming pushes speculative decoding toward its ideal regime of high
acceptance with low overhead. On SpecBench with server-scale models from 14B to
66B parameters, Mirror-SD delivers consistent end-to-end gains, achieving
2.8x-5.8x wall-time speedups across diverse tasks and a 30% average relative
improvement over the strongest baseline, EAGLE3.

</details>


### [30] [A Matter of Representation: Towards Graph-Based Abstract Code Generation](https://arxiv.org/abs/2510.13163)
*Nyx Iskandar,Hisham Bedri,Andy Tsen*

Main category: cs.CL

TL;DR: 本文提出了一种基于图的抽象代码生成方法，并使用JSON格式表示图结构，以提高LLM在此任务上的准确性。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在生成原始代码方面表现出色，但对于基于图的抽象代码生成的研究较少。这种生成方法在可视化编程语言和源代码不可访问的情况下非常重要。

Method: 本文提出并评估了用于图的JSON表示，以实现高精度的基于图的抽象代码生成。使用ScratchTest评估这些表示。

Result: 实验结果表明，在给定正确的图表示的情况下，LLM可以在单个pass中执行代码生成任务，并且不同的表示会显著影响准确性。

Conclusion: 本文为基于图的抽象代码生成表示学习奠定了基础。

Abstract: Most large language models (LLMs) today excel at generating raw, sequential
code with minimal abstractions and custom structures. However, there has been
little work on graph-based abstract code generation, where significant logic is
encapsulated in predefined nodes and execution flow is determined by edges.
This is relevant for visual programming languages, and in cases where raw
source code is inaccessible to users and LLM training sets. In this work, we
propose and evaluate JSON representations for graphs to enable high accuracy
graph-based abstract code generation. We evaluate these representations on
ScratchTest, a mini-benchmark based on our custom Python re-implementation of
Scratch, which tests the LLM in code graph space. Our findings demonstrate that
LLMs can indeed perform the aforementioned generation task in a single pass
without relying on specialized or complex pipelines, given the correct graph
representations. We also show that different representations induce
significantly different accuracies, highlighting the instrumental role of
representations in this generation task. All in all, this work establishes the
first steps towards representation learning for graph-based abstract code
generation.

</details>


### [31] [CoT-Evo: Evolutionary Distillation of Chain-of-Thought for Scientific Reasoning](https://arxiv.org/abs/2510.13166)
*Kehua Feng,Keyan Ding,Zhihui Zhu,Lei Liang,Qiang Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 提出了一种名为 CoT-Evo 的进化 CoT 蒸馏框架，用于解决大型语言模型 (LLM) 在科学领域的推理难题。


<details>
  <summary>Details</summary>
Motivation: 现有 CoT 蒸馏方法在科学领域表现不佳，因为大型语言模型在该领域经常产生不正确或肤浅的推理。

Method: CoT-Evo 框架首先构建来自多个 LLM 的推理轨迹池，然后通过检索到的领域知识丰富这些轨迹，并使用新颖性驱动的选择、反思性重组和变异迭代地细化轨迹。细化过程由评估答案正确性、连贯性和有效知识利用的适应度函数指导。

Result: 使用 CoT-Evo 框架生成的科学推理数据集对紧凑模型进行微调，在科学推理基准测试中实现了最先进的性能。

Conclusion: CoT-Evo 建立了一种可扩展的方法，可以从不同的且容易出错的 LLM 合成高保真科学推理数据。

Abstract: While chain-of-thought (CoT) distillation from advanced large language models
(LLMs) has proven effective in general reasoning tasks, it struggles in
scientific domains where even advanced models often produce incorrect or
superficial reasoning due to high complexity and specialized knowledge
requirements. Directly distilling from such flawed outputs results in
low-quality training data and limits the performance of smaller student models.
To overcome this, we propose CoT-Evo, an evolutionary CoT distillation
framework. It begins by constructing a diverse pool of reasoning trajectories
from multiple LLM thinkers, enriches them with automatically retrieved domain
knowledge, and iteratively refines the trajectories using novelty-driven
selection, reflective recombination and mutation. The refinement is guided by a
fitness function that evaluates answer correctness, coherence, and effective
knowledge utilization. This results in a high-quality CoT dataset tailored for
scientific reasoning. We employ this evolved dataset to fine-tune a compact
model, which achieves state-of-the-art performance on scientific reasoning
benchmarks. Our work establishes a scalable approach to synthesizing
high-fidelity scientific reasoning data from diverse and fallible LLMs.

</details>


### [32] [Putting on the Thinking Hats: A Survey on Chain of Thought Fine-tuning from the Perspective of Human Reasoning Mechanism](https://arxiv.org/abs/2510.13170)
*Xiaoshu Chen,Sihang Zhou,Ke Liang,Duanyang Yuan,Haoyuan Chen,Xiaoyu Sun,Linyuan Meng,Xinwang Liu*

Main category: cs.CL

TL;DR: 本文对思维链 (CoT) 微调进行了综述，旨在通过在精选的推理轨迹上训练大型语言模型 (LLM) 来赋予它们推理能力。从人类推理机制的角度对 CoT 微调进行了系统的分析，并根据著名的六顶思考帽框架对 CoT 微调方法进行了分类和检查。最后，概述了未来研究的潜在方向，并整理了现有数据集和模型性能的全面概述。


<details>
  <summary>Details</summary>
Motivation: 现有的关于 CoT 微调的调查主要侧重于技术方面，而忽略了从人类推理机制角度进行的系统分析。鉴于 CoT 微调的最终目标是使 LLM 像人类一样进行推理，因此通过人类认知的视角研究这项技术至关重要。

Method: 本文基于人类推理理论，对 CoT 微调进行了首次全面调查。受著名的六顶思考帽框架的启发，该框架使用六个隐喻帽子系统地描述了常见的人类思维模式，我们通过这个视角对 CoT 微调方法进行了分类和检查。

Result: 本文从人类推理的角度对 CoT 微调进行了分析，并为未来的研究方向提供了指导。此外，本文还整理了现有数据集和模型性能的全面概述，并维护了一个 GitHub 存储库，用于跟踪该领域的最新进展。

Conclusion: 本文旨在为 CoT 微调领域的研究提供有价值的资源，以激发创新和促进进步。

Abstract: Chain of thought (CoT) fine-tuning aims to endow large language models (LLMs)
with reasoning capabilities by training them on curated reasoning traces. It
leverages both supervised and reinforced fine-tuning to cultivate human-like
reasoning skills in LLMs, including detailed planning, divergent thinking,
intuitive judgment, timely reflection, internal thinking, and fact perception,
etc. As CoT fine-tuning has advanced, LLMs have demonstrated substantial
improvements in tasks such as mathematical reasoning and code generation.
However, existing surveys about CoT fine-tuning primarily focus on technical
aspects and overlook a systematic analysis from the perspective of human
reasoning mechanisms. Given that the ultimate goal of CoT fine-tuning is to
enable LLMs to reason like humans, it is crucial to investigate this technique
through the lens of human cognition. To fill this gap, we present the first
comprehensive survey of CoT fine-tuning grounded in human reasoning theory.
Specifically, inspired by the well-known Six Thinking Hats framework, which
systematically characterizes common human thinking modes using six metaphorical
hats, we classify and examine CoT fine-tuning methods through this lens.
Furthermore, building upon this theory, we outline potential directions for
future research in CoT fine-tuning. In addition, we compile a comprehensive
overview of existing datasets and model performances, and a real-time GitHub
repository \footnote{https://github.com/AI-Chen/Awesome-CoT-Finetuning} that
continuously tracks recent advances in this area is maintained. We hope this
survey will serve as a valuable resource to inspire innovation and foster
progress in this rapidly evolving field.

</details>


### [33] [DSCD: Large Language Model Detoxification with Self-Constrained Decoding](https://arxiv.org/abs/2510.13183)
*Ming Dong,Jinkui Zhang,Bolong Zheng,Xinhui Tu,Po Hu,Tingting He*

Main category: cs.CL

TL;DR: 提出了一种新的LLM解毒方法，无需参数微调，即可在输出生成过程中增强安全层，减弱幻觉和毒性层，从而有效降低毒性并提高输出安全性。


<details>
  <summary>Details</summary>
Motivation: 现有解码解毒方法均基于外部约束，需要额外的资源开销并损失生成流畅性。

Method: 提出了一种自约束解码（DSCD）的解毒方法。

Result: 在代表性的开源LLM和公共数据集上进行了大量实验，验证了DSCD的有效性，在解毒和生成流畅性方面均表现出最先进（SOTA）的性能，并且与现有方法相比具有更高的效率。

Conclusion: DSCD作为一种实用且可扩展的解决方案，在更安全的LLM部署方面具有潜力。

Abstract: Detoxification in large language models (LLMs) remains a significant research
challenge. Existing decoding detoxification methods are all based on external
constraints, which require additional resource overhead and lose generation
fluency. This work proposes Detoxification with Self-Constrained Decoding
(DSCD), a novel method for LLM detoxification without parameter fine-tuning.
DSCD strengthens the inner next-token distribution of the safety layer while
weakening that of hallucination and toxic layers during output generation. This
effectively diminishes toxicity and enhances output safety. DSCD offers
lightweight, high compatibility, and plug-and-play capabilities, readily
integrating with existing detoxification methods for further performance
improvement. Extensive experiments on representative open-source LLMs and
public datasets validate DSCD's effectiveness, demonstrating state-of-the-art
(SOTA) performance in both detoxification and generation fluency, with superior
efficiency compared to existing methods. These results highlight DSCD's
potential as a practical and scalable solution for safer LLM deployments.

</details>


### [34] [SHIELD: Classifier-Guided Prompting for Robust and Safer LVLMs](https://arxiv.org/abs/2510.13190)
*Juan Ren,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: SHIELD是一个轻量级的、与模型无关的预处理框架，旨在提高大型视觉语言模型的安全性，防止对抗性攻击。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型存在被对抗性输入攻击的风险，这些输入会将有害目标隐藏在看似良性的提示中。

Method: SHIELD通过细粒度的安全分类与特定类别的指导和显式操作（Block、Reframe、Forward）相结合来实现。

Result: 在五个基准测试和五个代表性的大型视觉语言模型上，SHIELD能够持续降低越狱和不遵循指令的比率，同时保持模型的实用性。

Conclusion: SHIELD是一种即插即用、开销可忽略不计且易于扩展到新型攻击的实用安全补丁，适用于弱对齐和强对齐的大型视觉语言模型。

Abstract: Large Vision-Language Models (LVLMs) unlock powerful multimodal reasoning but
also expand the attack surface, particularly through adversarial inputs that
conceal harmful goals in benign prompts. We propose SHIELD, a lightweight,
model-agnostic preprocessing framework that couples fine-grained safety
classification with category-specific guidance and explicit actions (Block,
Reframe, Forward). Unlike binary moderators, SHIELD composes tailored safety
prompts that enforce nuanced refusals or safe redirection without retraining.
Across five benchmarks and five representative LVLMs, SHIELD consistently
lowers jailbreak and non-following rates while preserving utility. Our method
is plug-and-play, incurs negligible overhead, and is easily extendable to new
attack types -- serving as a practical safety patch for both weakly and
strongly aligned LVLMs.

</details>


### [35] [Grounding Long-Context Reasoning with Contextual Normalization for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.13191)
*Jiamin Chen,Yuchen Li,Xinyu Ma,Xinran Chen,Xiaokun Zhang,Shuaiqiang Wang,Chen Ma,Dawei Yin*

Main category: cs.CL

TL;DR: 论文研究了检索增强生成（RAG）中上下文格式的影响，发现即使语义内容相同，分隔符等表面选择也会显著影响准确性和稳定性。提出了上下文归一化方法，以提高RAG的鲁棒性和长上下文利用率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在检索质量和提示策略上，忽略了检索文档的呈现方式（即上下文格式）的影响。

Method: 通过设计受控实验，改变上下文密度、分隔符样式和位置排列，研究影响性能差异的根本因素。提出了上下文归一化方法，自适应地标准化生成前的上下文表示。

Result: 在受控和真实RAG基准测试中的大量实验表明，所提出的策略能够持续提高对顺序变化的鲁棒性，并加强长上下文利用率。

Conclusion: 可靠的RAG不仅取决于检索正确的内容，还取决于内容的呈现方式。

Abstract: Retrieval-Augmented Generation (RAG) has become an essential approach for
extending the reasoning and knowledge capacity of large language models (LLMs).
While prior research has primarily focused on retrieval quality and prompting
strategies, the influence of how the retrieved documents are framed, i.e.,
context format, remains underexplored. We show that seemingly superficial
choices, such as delimiters or structural markers in key-value extraction, can
induce substantial shifts in accuracy and stability, even when semantic content
is identical. To systematically investigate this effect, we design controlled
experiments that vary context density, delimiter styles, and positional
placement, revealing the underlying factors that govern performance
differences. Building on these insights, we introduce Contextual Normalization,
a lightweight strategy that adaptively standardizes context representations
before generation. Extensive experiments on both controlled and real-world RAG
benchmarks across diverse settings demonstrate that the proposed strategy
consistently improves robustness to order variation and strengthens
long-context utilization. These findings underscore that reliable RAG depends
not only on retrieving the right content, but also on how that content is
presented, offering both new empirical evidence and a practical technique for
better long-context reasoning.

</details>


### [36] [StressTransfer: Stress-Aware Speech-to-Speech Translation with Emphasis Preservation](https://arxiv.org/abs/2510.13194)
*Xi Chen,Yuchen Song,Satoshi Nakamura*

Main category: cs.CL

TL;DR: 提出了一种强调感知的语音到语音翻译 (S2ST) 系统，该系统利用大型语言模型 (LLM) 进行跨语言强调转换，从而保留词语层面的强调。


<details>
  <summary>Details</summary>
Motivation: 强调语音翻译中韵律的重要性，并解决数据稀缺问题。

Method: 将源语言的强调翻译成目标语言的标签，以指导可控的TTS模型。开发了一个pipeline来自动生成对齐的训练数据，并引入 “LLM-as-Judge” 进行评估。

Result: 在保留强调的同时，在翻译质量、说话人意图和自然度方面，该方法明显优于基线。

Conclusion: 强调了韵律在翻译中的重要性，并为在S2ST中保留副语言线索提供了一种有效且数据高效的解决方案。

Abstract: We propose a stress-aware speech-to-speech translation (S2ST) system that
preserves word-level emphasis by leveraging LLMs for cross-lingual emphasis
conversion. Our method translates source-language stress into target-language
tags that guide a controllable TTS model. To overcome data scarcity, we
developed a pipeline to automatically generate aligned training data and
introduce the "LLM-as-Judge" for evaluation. Experiments show our approach
substantially outperforms baselines in preserving emphasis while maintaining
comparable translation quality, speaker intent, and naturalness. Our work
highlights the importance of prosody in translation and provides an effective,
data-efficient solution for preserving paralinguistic cues in S2ST.

</details>


### [37] [Text Anomaly Detection with Simplified Isolation Kernel](https://arxiv.org/abs/2510.13197)
*Yang Cao,Sikun Yang,Yujiu Yang,Lianyong Qi,Ming Liu*

Main category: cs.CL

TL;DR: 提出了一种名为 Simplified Isolation Kernel (SIK) 的新方法，用于文本异常检测，该方法通过将高维密集嵌入映射到低维稀疏表示来降低内存需求和计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于预训练的大型语言模型嵌入和异常检测器，但在处理高维密集嵌入时面临内存和计算挑战。

Method: 引入 Simplified Isolation Kernel (SIK)，它通过创新的边界聚焦特征映射，将高维密集嵌入映射到低维稀疏表示，同时保留关键的异常特征。

Result: 在 7 个数据集上的实验表明，SIK 在保持计算效率和低内存成本的同时，比 11 种最先进的 (SOTA) 异常检测算法实现了更好的检测性能。

Conclusion: SIK 是一种有效的文本异常检测方法，它在性能、效率和内存使用方面优于现有技术。

Abstract: Two-step approaches combining pre-trained large language model embeddings and
anomaly detectors demonstrate strong performance in text anomaly detection by
leveraging rich semantic representations. However, high-dimensional dense
embeddings extracted by large language models pose challenges due to
substantial memory requirements and high computation time. To address this
challenge, we introduce the Simplified Isolation Kernel (SIK), which maps
high-dimensional dense embeddings to lower-dimensional sparse representations
while preserving crucial anomaly characteristics. SIK has linear time
complexity and significantly reduces space complexity through its innovative
boundary-focused feature mapping. Experiments across 7 datasets demonstrate
that SIK achieves better detection performance than 11 state-of-the-art (SOTA)
anomaly detection algorithms while maintaining computational efficiency and low
memory cost. All code and demonstrations are available at
https://github.com/charles-cao/SIK.

</details>


### [38] [LLM-Guided Synthetic Augmentation (LGSA) for Mitigating Bias in AI Systems](https://arxiv.org/abs/2510.13202)
*Sai Suhruth Reddy Karri,Yashwanth Sai Nallapuneni,Laxmi Narasimha Reddy Mallireddy,Gopichand G*

Main category: cs.CL

TL;DR: 提出了一种新的数据增强方法 (LGSA) 来减少 AI 系统中的偏见，该方法使用大型语言模型生成反事实样本，从而在不牺牲准确性的前提下提高性能。


<details>
  <summary>Details</summary>
Motivation: AI 系统中的偏见，特别是依赖自然语言数据的系统，引起了伦理和实践问题。某些群体的代表性不足通常导致跨人口统计的性能不平衡。传统公平方法依赖于受保护的属性标签，涉及准确性与公平性之间的权衡，并且可能无法跨数据集推广。

Method: 提出了 LLM 引导的合成增强 (LGSA)，它使用大型语言模型为代表性不足的群体生成反事实示例，同时保持标签的完整性。使用结构化提示来生成性别交换的释义，然后进行包括语义相似性检查、属性验证、毒性筛选和人工抽查在内的质量控制。

Result: LGSA 减少了性能差异，同时没有影响准确性。基线模型的准确率为 96.7%，性别偏见差距为 7.2%。简单的交换增强将差距缩小到 0.7%，但将准确率降低到 95.6%。LGSA 实现了 99.1% 的准确率，偏见差距为 1.9%，提高了女性标记示例的性能。

Conclusion: LGSA 是一种有效的偏见缓解策略，可在保持高任务准确性和标签保真度的同时增强亚组平衡。

Abstract: Bias in AI systems, especially those relying on natural language data, raises
ethical and practical concerns. Underrepresentation of certain groups often
leads to uneven performance across demographics. Traditional fairness methods,
such as pre-processing, in-processing, and post-processing, depend on
protected-attribute labels, involve accuracy-fairness trade-offs, and may not
generalize across datasets. To address these challenges, we propose LLM-Guided
Synthetic Augmentation (LGSA), which uses large language models to generate
counterfactual examples for underrepresented groups while preserving label
integrity. We evaluated LGSA on a controlled dataset of short English sentences
with gendered pronouns, professions, and binary classification labels.
Structured prompts were used to produce gender-swapped paraphrases, followed by
quality control including semantic similarity checks, attribute verification,
toxicity screening, and human spot checks. The augmented dataset expanded
training coverage and was used to train a classifier under consistent
conditions. Results show that LGSA reduces performance disparities without
compromising accuracy. The baseline model achieved 96.7 percent accuracy with a
7.2 percent gender bias gap. Simple swap augmentation reduced the gap to 0.7
percent but lowered accuracy to 95.6 percent. LGSA achieved 99.1 percent
accuracy with a 1.9 percent bias gap, improving performance on female-labeled
examples. These findings demonstrate that LGSA is an effective strategy for
bias mitigation, enhancing subgroup balance while maintaining high task
accuracy and label fidelity.

</details>


### [39] [A fully automated and scalable Parallel Data Augmentation for Low Resource Languages using Image and Text Analytics](https://arxiv.org/abs/2510.13211)
*Prawaal Sharma,Navneet Goyal,Poonam Goyal,Vishnupriyan R*

Main category: cs.CL

TL;DR: 本文提出了一种从报纸文章中提取双语平行语料库的新方法，该方法可扩展且全自动，利用图像和文本分析技术。


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量的数字语言资源限制了技术对大多数人的益处，低资源语言尤其缺乏数据资源，难以执行自然语言处理任务。

Method: 提出了一种新的可扩展且全自动的方法，利用图像和文本分析从报纸文章中提取双语平行语料库。

Result: 通过构建两个不同语言组合的平行语料库验证了该方法，并通过机器翻译的下游任务证明了该数据集的价值，相比目前的基线提高了近3个BLEU点。

Conclusion: 本文提出了一种有效的方法，可以为低资源语言构建平行语料库，并在机器翻译任务中取得了显著的改进。

Abstract: Linguistic diversity across the world creates a disparity with the
availability of good quality digital language resources thereby restricting the
technological benefits to majority of human population. The lack or absence of
data resources makes it difficult to perform NLP tasks for low-resource
languages. This paper presents a novel scalable and fully automated methodology
to extract bilingual parallel corpora from newspaper articles using image and
text analytics. We validate our approach by building parallel data corpus for
two different language combinations and demonstrate the value of this dataset
through a downstream task of machine translation and improve over the current
baseline by close to 3 BLEU points.

</details>


### [40] [Hierarchical Frequency Tagging Probe (HFTP): A Unified Approach to Investigate Syntactic Structure Representations in Large Language Models and the Human Brain](https://arxiv.org/abs/2510.13255)
*Jingmin An,Yilong Song,Ruolin Yang,Nai Ding,Lingxi Lu,Yuxuan Wang,Wei Wang,Chu Zhuang,Qian Wang,Fang Fang*

Main category: cs.CL

TL;DR: 大型语言模型(llm)在建模句法结构方面表现出人类水平甚至更高级的语言能力，但负责的具体计算模块仍不清楚。本文介绍了分层频率标记探针(HFTP)，该工具利用频域分析来识别llm的神经元组件(例如，单个多层感知器(MLP)神经元)和皮质区域(通过颅内记录)编码句法结构。


<details>
  <summary>Details</summary>
Motivation: 研究LLM的行为能力是否源于类似于人脑的机制, 并探究LLM中负责句法结构建模的具体计算模块。

Method: 使用分层频率标记探针(HFTP)，一种利用频域分析来识别LLM神经元组件和大脑皮层区域编码句法结构的工具。

Result: GPT-2、Gemma、Gemma 2、Llama 2、Llama 3.1和GLM-4等模型在类似的层中处理语法，而人脑依赖于不同的皮质区域来处理不同的句法层次。LLM表示与大脑左半球(在语言处理中占主导地位)之间具有更强的对齐。升级后的模型表现出不同的趋势：Gemma 2显示出比Gemma更大的大脑相似性，而Llama 3.1与Llama 2相比，与大脑的对齐程度较低。

Conclusion: 这些发现为LLM行为改进的可解释性提供了新的见解，提出了这些改进是由类人机制还是非类人机制驱动的问题，并将HFTP确立为连接计算语言学和认知神经科学的有价值的工具。

Abstract: Large Language Models (LLMs) demonstrate human-level or even superior
language abilities, effectively modeling syntactic structures, yet the specific
computational modules responsible remain unclear. A key question is whether LLM
behavioral capabilities stem from mechanisms akin to those in the human brain.
To address these questions, we introduce the Hierarchical Frequency Tagging
Probe (HFTP), a tool that utilizes frequency-domain analysis to identify
neuron-wise components of LLMs (e.g., individual Multilayer Perceptron (MLP)
neurons) and cortical regions (via intracranial recordings) encoding syntactic
structures. Our results show that models such as GPT-2, Gemma, Gemma 2, Llama
2, Llama 3.1, and GLM-4 process syntax in analogous layers, while the human
brain relies on distinct cortical regions for different syntactic levels.
Representational similarity analysis reveals a stronger alignment between LLM
representations and the left hemisphere of the brain (dominant in language
processing). Notably, upgraded models exhibit divergent trends: Gemma 2 shows
greater brain similarity than Gemma, while Llama 3.1 shows less alignment with
the brain compared to Llama 2. These findings offer new insights into the
interpretability of LLM behavioral improvements, raising questions about
whether these advancements are driven by human-like or non-human-like
mechanisms, and establish HFTP as a valuable tool bridging computational
linguistics and cognitive neuroscience. This project is available at
https://github.com/LilTiger/HFTP.

</details>


### [41] [Do You Get the Hint? Benchmarking LLMs on the Board Game Concept](https://arxiv.org/abs/2510.13271)
*Ine Gevers,Walter Daelemans*

Main category: cs.CL

TL;DR: 大型语言模型在许多基准测试中取得了显著成功，但最近的研究不断揭示其根本弱点。特别是，需要抽象推理的任务仍然具有挑战性，通常是因为它们使用的表示形式（如网格、符号或视觉模式）与大型语言模型训练的自然语言数据不同。


<details>
  <summary>Details</summary>
Motivation: 本文介绍了一种简单的猜词 बोर्ड 游戏 Concept，它是一种用于探究与 LLM 预训练数据更接近的表示形式（自然语言）中的溯因推理的基准。

Method: 通过 Concept 游戏来测试语言模型的抽象推理能力。

Result: 结果表明，对于人类来说很容易解决的这个游戏，对于最先进的语言模型来说仍然非常具有挑战性（没有模型的成功率超过 40%）。

Conclusion: 我们观察到，语言模型难以解释其他玩家的战略意图，并且难以根据顺序信息更新来纠正初始假设。此外，我们将评估扩展到多种语言，并且发现与英语相比，语言模型在较低资源语言（荷兰语、法语和西班牙语）中的性能进一步下降。

Abstract: Large language models (LLMs) have achieved striking successes on many
benchmarks, yet recent studies continue to expose fundamental weaknesses. In
particular, tasks that require abstract reasoning remain challenging, often
because they use representations such as grids, symbols, or visual patterns
that differ from the natural language data LLMs are trained on. In this paper,
we introduce Concept, a simple word-guessing board game, as a benchmark for
probing abductive reasoning in a representation that is much closer to LLM
pre-training data: natural language. Our results show that this game, easily
solved by humans (with a success rate of over 90\%), is still very challenging
for state-of-the-art LLMs (no model exceeds 40\% success rate). Specifically,
we observe that LLMs struggle with interpreting other players' strategic
intents, and with correcting initial hypotheses given sequential information
updates. In addition, we extend the evaluation across multiple languages, and
find that the LLM performance drops further in lower-resource languages (Dutch,
French, and Spanish) compared to English.

</details>


### [42] [Beyond Correctness: Rewarding Faithful Reasoning in Retrieval-Augmented Generation](https://arxiv.org/abs/2510.13272)
*Zhichao Xu,Zongyu Wu,Yun Zhou,Aosong Feng,Kang Zhou,Sangmin Woo,Kiran Ramnath,Yijun Tian,Xuan Qi,Weikang Qiu,Lin Lee Cheong,Haibo Ding*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的框架，通过在强化学习过程中整合细粒度的忠实度奖励，来提高基于强化学习的搜索代理的推理忠实度，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练大型语言模型使用搜索引擎时，往往忽略中间推理步骤的质量，导致思维链不忠实。

Method: 该论文首先提出了一个全面的评估框架，用于评估基于强化学习的搜索代理，涵盖三个不同的忠实度指标。然后，引入了一个名为VERITAS的框架，该框架将细粒度的忠实度奖励整合到强化学习过程中。

Result: 实验结果表明，使用VERITAS训练的模型不仅显著提高了推理忠实度，而且在七个QA基准测试中取得了可比较的任务性能。

Conclusion: VERITAS框架能够有效地提高基于强化学习的搜索代理的推理忠实度，同时保持任务性能。

Abstract: Inspired by the success of reinforcement learning (RL) in Large Language
Model (LLM) training for domains like math and code, recent works have begun
exploring how to train LLMs to use search engines more effectively as tools for
retrieval-augmented generation. Although these methods achieve performance
improvement across QA benchmarks, many prioritize final answer correctness
while overlooking the quality of intermediate reasoning steps, which may lead
to chain-of-thought unfaithfulness. In this paper, we first introduce a
comprehensive evaluation framework for evaluating RL-based search agents,
covering three distinct faithfulness metrics: information-think faithfulness,
think-answer faithfulness, and think-search faithfulness. Our evaluations
reveal that a prototypical RL-based search agent, Search-R1, has significant
room for improvement in this regard. To foster faithful reasoning, we introduce
VERITAS (Verifying Entailed Reasoning through Intermediate Traceability in
Agentic Search), a novel framework that integrates fine-grained faithfulness
rewards into the reinforcement learning process. Our experiments show that
models trained with VERITAS not only significantly improve reasoning
faithfulness, but also achieve comparable task performance across seven QA
benchmarks.

</details>


### [43] [In-Distribution Steering: Balancing Control and Coherence in Language Model Generation](https://arxiv.org/abs/2510.13285)
*Arthur Vogels,Benjamin Wong,Yann Choho,Annabelle Blangero,Milan Bhan*

Main category: cs.CL

TL;DR: 提出了一种新的激活控制方法，可以根据输入数据分布动态调整steering strength，在保证分类准确率的同时，生成连贯的文本。


<details>
  <summary>Details</summary>
Motivation: 现有的激活控制方法依赖于固定的steering strength，导致控制不足或过度干预，从而降低了文本的合理性和连贯性。

Method: 提出了一种名为In-Distribution Steering (IDS) 的方法，该方法基于表征空间中的输入数据分布来调整steering strength。

Result: 实验表明，IDS在分类任务上实现了很高的准确率，同时生成了连贯的文本，没有出现崩溃。

Conclusion: IDS特别适合实际应用。

Abstract: Activation steering methods control large language model (LLM) behavior by
modifying internal activations at inference time. However, most existing
activation steering methods rely on a fixed steering strength, leading to
either insufficient control or unadapted intervention that degrades text
plausibility and coherence. We introduce In-Distribution Steering (IDS), a
novel method that adapts steering strength based on the input data distribution
in representation space. IDS dynamically adjusts interventions according to how
far a given input lies within the distribution, enabling adaptive intervention
and generation stability during text generation. Experiments demonstrate that
IDS achieves strong accuracy on classification tasks while producing coherent
text without collapse, making IDS particularly well suited for real-world
applications.

</details>


### [44] [Higher Satisfaction, Lower Cost: A Technical Report on How LLMs Revolutionize Meituan's Intelligent Interaction Systems](https://arxiv.org/abs/2510.13291)
*Xuxin Cheng,Ke Zeng,Zhiquan Cao,Linyi Dai,Wenxuan Gao,Fei Han,Ai Jian,Feng Hong,Wenxing Hu,Zihe Huang,Dejian Kong,Jia Leng,Zhuoyuan Liao,Pei Liu,Jiaye Lin,Xing Ma,Jingqing Ruan,Jiaxing Song,Xiaoyu Tan,Ruixuan Xiao,Wenhui Yu,Wenyu Zhan,Haoxing Zhang,Chao Zhou,Hao Zhou,Shaodong Zheng,Ruinian Chen,Siyuan Chen,Ziyang Chen,Yiwen Dong,Yaoyou Fan,Yangyi Fang,Yang Gan,Shiguang Guo,Qi He,Chaowen Hu,Binghui Li,Dailin Li,Xiangyu Li,Yan Li,Chengjian Liu,Xiangfeng Liu,Jiahui Lv,Qiao Ma,Jiang Pan,Cong Qin,Chenxing Sun,Wen Sun,Zhonghui Wang,Abudukelimu Wuerkaixi,Xin Yang,Fangyi Yuan,Yawen Zhu,Tianyi Zhai,Jie Zhang,Runlai Zhang,Yao Xu,Yiran Zhao,Yifan Wang,Xunliang Cai,Yangen Hu,Cao Liu,Lu Pan,Xiaoli Wang,Bo Xiao,Wenyuan Yao,Qianlin Zhou,Benchang Zhu*

Main category: cs.CL

TL;DR: This paper introduces WOWService, an intelligent interaction system for industrial applications that uses LLMs and multi-agent architectures to improve customer service.


<details>
  <summary>Details</summary>
Motivation: Current intelligent interaction systems struggle with data construction, multi-turn dialogue performance, business rule evolution, single LLM reliance, and evaluation.

Method: WOWService integrates LLMs and multi-agent architectures, focusing on data construction, capability enhancement, business scenario adaptation, multi-agent coordination, and automated evaluation.

Result: WOWService is deployed on the Meituan App and has improved user satisfaction metrics (USM 1: -27.53%, USM 2: +25.51%).

Conclusion: WOWService effectively captures user needs and advances personalized service.

Abstract: Enhancing customer experience is essential for business success, particularly
as service demands grow in scale and complexity. Generative artificial
intelligence and Large Language Models (LLMs) have empowered intelligent
interaction systems to deliver efficient, personalized, and 24/7 support. In
practice, intelligent interaction systems encounter several challenges: (1)
Constructing high-quality data for cold-start training is difficult, hindering
self-evolution and raising labor costs. (2) Multi-turn dialogue performance
remains suboptimal due to inadequate intent understanding, rule compliance, and
solution extraction. (3) Frequent evolution of business rules affects system
operability and transferability, constraining low-cost expansion and
adaptability. (4) Reliance on a single LLM is insufficient in complex
scenarios, where the absence of multi-agent frameworks and effective
collaboration undermines process completeness and service quality. (5) The
open-domain nature of multi-turn dialogues, lacking unified golden answers,
hampers quantitative evaluation and continuous optimization. To address these
challenges, we introduce WOWService, an intelligent interaction system tailored
for industrial applications. With the integration of LLMs and multi-agent
architectures, WOWService enables autonomous task management and collaborative
problem-solving. Specifically, WOWService focuses on core modules including
data construction, general capability enhancement, business scenario
adaptation, multi-agent coordination, and automated evaluation. Currently,
WOWService is deployed on the Meituan App, achieving significant gains in key
metrics, e.g., User Satisfaction Metric 1 (USM 1) -27.53% and User Satisfaction
Metric 2 (USM 2) +25.51%, demonstrating its effectiveness in capturing user
needs and advancing personalized service.

</details>


### [45] [Mismatch Aware Guidance for Robust Emotion Control in Auto-Regressive TTS Models](https://arxiv.org/abs/2510.13293)
*Yizhou Peng,Yukun Ma,Chong Zhang,Yi-Wen Chao,Chongjia Ni,Bin Ma*

Main category: cs.CL

TL;DR: 本文提出了一种自适应的无分类器引导（CFG）方案，以解决自回归（AR）TTS模型中风格与内容不匹配的问题，该方案可根据检测到的不匹配程度进行调整。


<details>
  <summary>Details</summary>
Motivation: 当期望的情感（风格提示）与文本的语义内容冲突时，TTS系统的情感表达会受到影响，导致语音听起来不自然。无分类器引导（CFG）是增强提示对齐的关键技术，但其在自回归（AR）TTS模型中的应用仍未得到充分探索，这可能会降低音频质量。

Method: 通过使用大型语言模型或自然语言推理模型来测量不匹配程度，提出了一种自适应CFG方案，该方案可以调整到不同程度的检测到的不匹配。

Result: 所提出的自适应CFG方案提高了AR TTS模型的情感表达能力，同时保持了音频质量和可理解性。

Conclusion: 本文直接解决了AR TTS模型中风格内容不匹配的挑战，并通过自适应CFG方案提高了情感表达能力，同时保持了音频质量。

Abstract: While Text-to-Speech (TTS) systems can achieve fine-grained control over
emotional expression via natural language prompts, a significant challenge
emerges when the desired emotion (style prompt) conflicts with the semantic
content of the text. This mismatch often results in unnatural-sounding speech,
undermining the goal of achieving fine-grained emotional control.
Classifier-Free Guidance (CFG) is a key technique for enhancing prompt
alignment; however, its application to auto-regressive (AR) TTS models remains
underexplored, which can lead to degraded audio quality. This paper directly
addresses the challenge of style-content mismatch in AR TTS models by proposing
an adaptive CFG scheme that adjusts to different levels of the detected
mismatch, as measured using large language models or natural language inference
models. This solution is based on a comprehensive analysis of CFG's impact on
emotional expressiveness in state-of-the-art AR TTS models. Our results
demonstrate that the proposed adaptive CFG scheme improves the emotional
expressiveness of the AR TTS model while maintaining audio quality and
intelligibility.

</details>


### [46] [LLM one-shot style transfer for Authorship Attribution and Verification](https://arxiv.org/abs/2510.13302)
*Pablo Miralles-González,Javier Huertas-Tato,Alejandro Martín,David Camacho*

Main category: cs.CL

TL;DR: 提出了一种新的无监督方法，该方法利用大型语言模型的预训练和上下文学习能力来衡量文本之间的风格可转移性。


<details>
  <summary>Details</summary>
Motivation: 现有的计算文体学方法依赖于带有虚假相关性的数据，并且经常混淆风格和主题。

Method: 利用大型语言模型的对数概率来衡量文本之间的风格可转移性。

Result: 该方法显著优于同等规模的LLM提示方法，并且在控制主题相关性时，比对比训练的基线方法实现了更高的准确率。性能随着基础模型的大小而相当一致地扩展，并且在作者身份验证的情况下，随着增加测试时间计算的额外机制而扩展；从而实现了计算成本和准确性之间的灵活权衡。

Conclusion: 该方法在计算风格学方面具有优势，可以通过调整模型大小和计算资源来实现性能的提升。

Abstract: Computational stylometry analyzes writing style through quantitative patterns
in text, supporting applications from forensic tasks such as identity linking
and plagiarism detection to literary attribution in the humanities. Supervised
and contrastive approaches rely on data with spurious correlations and often
confuse style with topic. Despite their natural use in AI-generated text
detection, the CLM pre-training of modern LLMs has been scarcely leveraged for
general authorship problems. We propose a novel unsupervised approach based on
this extensive pre-training and the in-context learning capabilities of LLMs,
employing the log-probabilities of an LLM to measure style transferability from
one text to another. Our method significantly outperforms LLM prompting
approaches of comparable scale and achieves higher accuracy than contrastively
trained baselines when controlling for topical correlations. Moreover,
performance scales fairly consistently with the size of the base model and, in
the case of authorship verification, with an additional mechanism that
increases test-time computation; enabling flexible trade-offs between
computational cost and accuracy.

</details>


### [47] [Embedding-Based Context-Aware Reranker](https://arxiv.org/abs/2510.13329)
*Ye Yuan,Mohammad Amin Shabani,Siqi Liu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的轻量级重排序框架EBCAR，用于解决RAG系统中跨段落推理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成系统在处理需要跨段落推理的信息检索任务时存在不足，而现有的重排序方法忽略了这些挑战。

Method: 该方法通过 passages 的结构信息和混合注意力机制，直接在检索到的 passages 的嵌入上进行操作，增强跨段落理解。

Result: 在ConTEB基准测试中，EBCAR 相对于 SOTA 重排序器展示了其有效性，尤其是在需要跨段落推理的信息检索方面。

Conclusion: EBCAR 在准确性和效率方面都具有优势。

Abstract: Retrieval-Augmented Generation (RAG) systems rely on retrieving relevant
evidence from a corpus to support downstream generation. The common practice of
splitting a long document into multiple shorter passages enables finer-grained
and targeted information retrieval. However, it also introduces challenges when
a correct retrieval would require inference across passages, such as resolving
coreference, disambiguating entities, and aggregating evidence scattered across
multiple sources. Many state-of-the-art (SOTA) reranking methods, despite
utilizing powerful large pretrained language models with potentially high
inference costs, still neglect the aforementioned challenges. Therefore, we
propose Embedding-Based Context-Aware Reranker (EBCAR), a lightweight reranking
framework operating directly on embeddings of retrieved passages with enhanced
cross-passage understandings through the structural information of the passages
and a hybrid attention mechanism, which captures both high-level interactions
across documents and low-level relationships within each document. We evaluate
EBCAR against SOTA rerankers on the ConTEB benchmark, demonstrating its
effectiveness for information retrieval requiring cross-passage inference and
its advantages in both accuracy and efficiency.

</details>


### [48] [Taming the Fragility of KV Cache Eviction in LLM Inference](https://arxiv.org/abs/2510.13334)
*Yuan Feng,Haoyu Guo,JunLin Lv,S. Kevin Zhou,Xike Xie*

Main category: cs.CL

TL;DR: 本文提出了一种新的缓存淘汰方法，旨在解决大型语言模型部署中Transformer的Key-Value缓存带来的内存和运行时间开销问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于稳定性假设，即一小部分缓存条目在生成过程中始终保持重要，但这种假设本身是脆弱的，导致均值聚合在极端情况下容易出错。

Method: 提出了一种简单的两步线性时间防御性聚合策略，以控制最坏情况风险，并提出了新的缓存淘汰方法DefensiveKV及其扩展Layer-DefensiveKV，后者结合了分层预算分配。

Result: 在七个任务领域（18个数据集）中，与最强的基线相比，在20%缓存大小下，该方法分别将生成质量损失降低了2.3倍和4.3倍。

Conclusion: 研究结果确立了新的性能基准，并为通过最坏情况风险管理优化缓存淘汰开辟了一个有希望的方向。

Abstract: Large language models have revolutionized natural language processing, yet
their deployment remains hampered by the substantial memory and runtime
overhead of the transformer's Key-Value cache. To mitigate this, recent methods
employ a scoring-aggregation framework to evict unimportant cache entries,
based on the stability assumption-that a fixed subset of entries remains
consistently important during generation. However, prior work has largely
focused on refining importance indicators for scoring, while defaulting to mean
aggregation due to a faithful trust in the stability assumption. In this work,
we argue that this underlying assumption is inherently fragile, making mean
aggregation highly vulnerable in extreme cases. To counter this, we propose a
simple yet elegant defensive aggregation strategy: a two-step, linear-time
approach that controls worst-case risk, thereby defending against extreme cases
with negligible computational overhead. Embodying this strategy, we propose a
novel cache eviction method, DefensiveKV and its extension, Layer-DefensiveKV,
which incorporates layer-wise budget allocation. Across seven task domains (18
datasets), our methods reduce generation quality loss by 2.3x and 4.3x
respectively, versus the strongest baseline under a 20% cache size. These
results set new performance benchmarks and pioneer a promising direction for
optimizing cache eviction against underlying fragility through worst-case risk
management. Our code is available at https://github.com/FFY0/DefensiveKV.

</details>


### [49] [Are Proverbs the New Pythian Oracles? Exploring Sentiment in Greek Sayings](https://arxiv.org/abs/2510.13341)
*Katerina Korre,John Pavlopoulos*

Main category: cs.CL

TL;DR: 本研究利用自然语言处理技术分析希腊谚语的情感。


<details>
  <summary>Details</summary>
Motivation: 探索谚语的全球景观，许多文化将其传统智慧保存在自己的社区内。

Method: 利用大型语言模型对希腊谚语进行情感分类，并将其扩展到包括当地方言，有效地绘制了注释的情感。

Result: 大型语言模型可以为我们提供足够准确的谚语情感图，尤其是在作为非传统情感极性任务处理时。此外，在希腊的大部分地区，负面情绪更为普遍。

Conclusion: 大型语言模型可以有效地用于分析谚语的情感，并揭示特定文化中的情感分布。

Abstract: Proverbs are among the most fascinating linguistic phenomena that transcend
cultural and linguistic boundaries. Yet, much of the global landscape of
proverbs remains underexplored, as many cultures preserve their traditional
wisdom within their own communities due to the oral tradition of the
phenomenon. Taking advantage of the current advances in Natural Language
Processing (NLP), we focus on Greek proverbs, analyzing their sentiment.
Departing from an annotated dataset of Greek proverbs, we expand it to include
local dialects, effectively mapping the annotated sentiment. We present (1) a
way to exploit LLMs in order to perform sentiment classification of proverbs,
(2) a map of Greece that provides an overview of the distribution of sentiment,
(3) a combinatory analysis in terms of the geographic position, dialect, and
topic of proverbs. Our findings show that LLMs can provide us with an accurate
enough picture of the sentiment of proverbs, especially when approached as a
non-conventional sentiment polarity task. Moreover, in most areas of Greece
negative sentiment is more prevalent.

</details>


### [50] [Protect: Towards Robust Guardrailing Stack for Trustworthy Enterprise LLM Systems](https://arxiv.org/abs/2510.13351)
*Karthik Avinash,Nikhil Pareek,Rishav Hada*

Main category: cs.CL

TL;DR: 提出了一种名为Protect的多模态安全防护模型，旨在解决现有方案在实时监督、多模态数据处理和可解释性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型安全防护系统在企业和关键任务领域面临挑战，尤其是在处理多模态数据时。

Method: 通过低秩适应（LoRA）在包含毒性、性别歧视、数据隐私和提示注入四个安全维度的大型多模态数据集上训练特定类别的适配器。使用教师辅助标注管道生成高质量、上下文相关的标签。

Result: 在所有安全维度上都表现出最先进的性能，超过了现有的开放和专有模型，如WildGuard、LlamaGuard-4和GPT-4.1。

Conclusion: Protect为可信、可审计且可用于生产的安全系统奠定了坚实的基础，该系统能够在文本、图像和音频模态上运行。

Abstract: The increasing deployment of Large Language Models (LLMs) across enterprise
and mission-critical domains has underscored the urgent need for robust
guardrailing systems that ensure safety, reliability, and compliance. Existing
solutions often struggle with real-time oversight, multi-modal data handling,
and explainability -- limitations that hinder their adoption in regulated
environments. Existing guardrails largely operate in isolation, focused on text
alone making them inadequate for multi-modal, production-scale environments. We
introduce Protect, natively multi-modal guardrailing model designed to operate
seamlessly across text, image, and audio inputs, designed for enterprise-grade
deployment. Protect integrates fine-tuned, category-specific adapters trained
via Low-Rank Adaptation (LoRA) on an extensive, multi-modal dataset covering
four safety dimensions: toxicity, sexism, data privacy, and prompt injection.
Our teacher-assisted annotation pipeline leverages reasoning and explanation
traces to generate high-fidelity, context-aware labels across modalities.
Experimental results demonstrate state-of-the-art performance across all safety
dimensions, surpassing existing open and proprietary models such as WildGuard,
LlamaGuard-4, and GPT-4.1. Protect establishes a strong foundation for
trustworthy, auditable, and production-ready safety systems capable of
operating across text, image, and audio modalities.

</details>


### [51] [Personal Attribute Leakage in Federated Speech Models](https://arxiv.org/abs/2510.13357)
*Hamdan Al-Ali,Ali Reza Ghavamipour,Tommaso Caselli,Fatih Turkmen,Zeerak Talat,Hanan Aldarmaki*

Main category: cs.CL

TL;DR: 分析了联邦学习中ASR模型在属性推断攻击下的漏洞


<details>
  <summary>Details</summary>
Motivation: 在联邦学习环境中，分析ASR模型对属性推断攻击的脆弱性

Method: 在被动威胁模型下，测试了一种非参数白盒攻击方法，攻击对象为Wav2Vec2, HuBERT, 和 Whisper三种ASR模型。该攻击仅利用权重差异，无需访问目标说话者的原始语音。

Result: 证明了攻击在敏感的人口统计和临床属性上的可行性，包括性别、年龄、口音、情感和构音障碍。预训练数据中代表性不足或缺失的属性更容易受到此类推断攻击。口音的信息可以从所有模型中可靠地推断出来。

Conclusion: 揭示了联邦ASR模型中以前未记录的漏洞，并为改进安全性提供了见解。

Abstract: Federated learning is a common method for privacy-preserving training of
machine learning models. In this paper, we analyze the vulnerability of ASR
models to attribute inference attacks in the federated setting. We test a
non-parametric white-box attack method under a passive threat model on three
ASR models: Wav2Vec2, HuBERT, and Whisper. The attack operates solely on weight
differentials without access to raw speech from target speakers. We demonstrate
attack feasibility on sensitive demographic and clinical attributes: gender,
age, accent, emotion, and dysarthria. Our findings indicate that attributes
that are underrepresented or absent in the pre-training data are more
vulnerable to such inference attacks. In particular, information about accents
can be reliably inferred from all models. Our findings expose previously
undocumented vulnerabilities in federated ASR models and offer insights towards
improved security.

</details>


### [52] [D-SMART: Enhancing LLM Dialogue Consistency via Dynamic Structured Memory And Reasoning Tree](https://arxiv.org/abs/2510.13363)
*Xiang Lei,Qin Li,Min Zhang,Min Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为D-SMART的框架，用于保持多轮对话的一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多轮对话中存在事实不一致和逻辑衰退的问题，这是因为它们依赖于静态的预训练知识，并且无法在对话历史中进行自适应推理。

Method: D-SMART框架通过构建和推理对话上下文的动态、结构化表示来实现这一点，它包含两个协同组件：动态结构化记忆（DSM）和推理树（RT）。

Result: 在MT-Bench-101基准测试上的综合实验表明，D-SMART显著优于最先进的基线，使专有模型和开源模型的对话一致性得分提高了48％以上，并显着提高了后者的质量得分高达10.1％。

Conclusion: D-SMART框架能够有效地提高多轮对话中语言模型的事实和逻辑一致性。

Abstract: Large Language Models (LLMs) often exhibit factual inconsistencies and
logical decay in extended, multi-turn dialogues, a challenge stemming from
their reliance on static, pre-trained knowledge and an inability to reason
adaptively over the dialogue history. Prevailing mitigation strategies, such as
Retrieval-Augmented Generation (RAG) and agentic working memories, improve
information recall but still engage with fundamentally static knowledge sources
and follow pre-defined single reasoning path. This hinders their ability to
preserve factual and logical consistency of their responses in multi-turn
dialogues while the context evolves over time. To address this issue, we
propose D-SMART, a model-agnostic framework designed to maintain multi-turn
dialogue consistency by enabling LLMs to build and reason over a dynamic,
structured representation of the conversational context. This is achieved via
two synergistic components: (1) a Dynamic Structured Memory (DSM), which
incrementally constructs and maintains an authoritative, OWL-compliant
knowledge graph of the conversation; and (2) a Reasoning Tree (RT), which
executes inferences as an explicit and traceable multi-step search over the
graph. As the popular-used quality score (judged by GPT-4) can overlook logical
flaws, we introduce new NLI-based metrics to better measure multi-turn dialogue
consistency. Comprehensive experiments on the MT-Bench-101 benchmark show that
D-SMART significantly outperforms state-of-the-art baselines, elevating the
dialogue consistency score by over 48\% for both proprietary and open-source
models, and notably improves the quality score of the latter by up to 10.1\%.

</details>


### [53] [Document Intelligence in the Era of Large Language Models: A Survey](https://arxiv.org/abs/2510.13366)
*Weishi Wang,Hengchang Hu,Zhijie Zhang,Zhaochen Li,Hongxin Shao,Daniel Dahlmeier*

Main category: cs.CL

TL;DR: 本文概述了文档人工智能（DAI）的演变，强调了当前的研究尝试以及LLM在该领域的未来前景。


<details>
  <summary>Details</summary>
Motivation: 探讨多模态、多语言和检索增强的DAI的关键进展和挑战。

Method: 对DAI的现状进行结构化分析。

Result: 强调了decoder-only LLM给DAI带来的巨大进步。

Conclusion: 为DAI的学术和实际应用提供了指导，并为未来的研究方向提出了建议，包括基于代理的方法和文档特定的基础模型。

Abstract: Document AI (DAI) has emerged as a vital application area, and is
significantly transformed by the advent of large language models (LLMs). While
earlier approaches relied on encoder-decoder architectures, decoder-only LLMs
have revolutionized DAI, bringing remarkable advancements in understanding and
generation. This survey provides a comprehensive overview of DAI's evolution,
highlighting current research attempts and future prospects of LLMs in this
field. We explore key advancements and challenges in multimodal, multilingual,
and retrieval-augmented DAI, while also suggesting future research directions,
including agent-based approaches and document-specific foundation models. This
paper aims to provide a structured analysis of the state-of-the-art in DAI and
its implications for both academic and practical applications.

</details>


### [54] [Make an Offer They Can't Refuse: Grounding Bayesian Persuasion in Real-World Dialogues without Pre-Commitment](https://arxiv.org/abs/2510.13387)
*Buwei He,Yang Liu,Zhaowei Zhang,Zixia Jia,Huijia Wu,Zhaofeng He,Zilong Zheng,Yipeng Kang*

Main category: cs.CL

TL;DR: 本文探讨了在自然语言单轮对话中应用贝叶斯劝导（BP）来提高大型语言模型（LLM）的策略性劝导能力。


<details>
  <summary>Details</summary>
Motivation: 当前研究通常忽略了信息不对称在消息设计中的策略性使用，或者依赖于关于预先承诺的强假设。本文旨在解决这些问题。

Method: 本文提出了一个框架，该框架包含一个承诺-沟通机制，劝说者通过叙述他们的潜在类型（例如，诚实或不诚实）来明确概述信息模式，从而指导被劝说者执行预期的贝叶斯信念更新。本文评估了两种变体：半形式自然语言（SFNL）BP 和完全自然语言（FNL）BP，并针对朴素和强大的非 BP（NBP）基线进行了基准测试。

Result: 在基于 LLM 的代理上的实验结果表明：(1) 在 BP 策略指导下的 LLM 比 NBP 基线始终获得更高的劝说成功率；(2) SFNL 表现出更高的可信度和逻辑连贯性，而 FNL 在自然对话中表现出更强的情感共鸣和鲁棒性；(3) 通过监督微调，较小的模型可以达到与较大模型相当的 BP 性能。

Conclusion: 本文表明，贝叶斯劝导可以有效地提高 LLM 的策略性劝导能力，并且通过微调可以使较小的模型达到与较大模型相当的性能。

Abstract: Persuasion, a fundamental social capability for humans, remains a challenge
for AI systems such as large language models (LLMs). Current studies often
overlook the strategic use of information asymmetry in message design or rely
on strong assumptions regarding pre-commitment. In this work, we explore the
application of Bayesian Persuasion (BP) in natural language within single-turn
dialogue settings, to enhance the strategic persuasion capabilities of LLMs.
Our framework incorporates a commitment-communication mechanism, where the
persuader explicitly outlines an information schema by narrating their
potential types (e.g., honest or dishonest), thereby guiding the persuadee in
performing the intended Bayesian belief update. We evaluate two variants of our
approach: Semi-Formal-Natural-Language (SFNL) BP and Fully-Natural-Language
(FNL) BP, benchmarking them against both naive and strong non-BP (NBP)
baselines within a comprehensive evaluation framework. This framework covers a
diverse set of persuadees -- including LLM instances with varying prompts and
fine-tuning and human participants -- across tasks ranging from specially
designed persuasion scenarios to general everyday situations. Experimental
results on LLM-based agents reveal three main findings: (1) LLMs guided by BP
strategies consistently achieve higher persuasion success rates than NBP
baselines; (2) SFNL exhibits greater credibility and logical coherence, while
FNL shows stronger emotional resonance and robustness in naturalistic
conversations; (3) with supervised fine-tuning, smaller models can attain BP
performance comparable to that of larger models.

</details>


### [55] [Doing Things with Words: Rethinking Theory of Mind Simulation in Large Language Models](https://arxiv.org/abs/2510.13395)
*Agnese Lombardi,Alessandro Lenci*

Main category: cs.CL

TL;DR: 探讨了大型语言模型（LLM）在模拟真实世界环境中的心理理论（ToM）能力，发现GPT-4在基于信念归因选择行动方面存在不足，暗示先前研究中观察到的类似ToM的能力可能源于肤浅的统计关联，而非真正的推理。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能在模拟现实世界环境中有效建模心理理论（ToM），并评估GPT-4是否能通过从社会背景中进行真实的推断来执行任务，而不是依赖于语言记忆。

Method: 使用基于生成代理的模型（GABM）Concordia来评估GPT-4在模拟环境中的心理理论能力，并分析其在行动选择和因果关系生成方面的表现。

Result: GPT-4在基于信念归因选择行动方面表现不佳，表明其类似ToM的能力可能源于肤浅的统计关联。此外，该模型难以从代理行为中产生连贯的因果效应，表明其在处理复杂的社会互动方面存在困难。

Conclusion: 研究结果对当前关于LLM中涌现的类似ToM的能力提出了挑战，并强调需要更严格的、基于行动的评估框架。

Abstract: Language is fundamental to human cooperation, facilitating not only the
exchange of information but also the coordination of actions through shared
interpretations of situational contexts. This study explores whether the
Generative Agent-Based Model (GABM) Concordia can effectively model Theory of
Mind (ToM) within simulated real-world environments. Specifically, we assess
whether this framework successfully simulates ToM abilities and whether GPT-4
can perform tasks by making genuine inferences from social context, rather than
relying on linguistic memorization. Our findings reveal a critical limitation:
GPT-4 frequently fails to select actions based on belief attribution,
suggesting that apparent ToM-like abilities observed in previous studies may
stem from shallow statistical associations rather than true reasoning.
Additionally, the model struggles to generate coherent causal effects from
agent actions, exposing difficulties in processing complex social interactions.
These results challenge current statements about emergent ToM-like capabilities
in LLMs and highlight the need for more rigorous, action-based evaluation
frameworks.

</details>


### [56] [Investigating Lexical Change through Cross-Linguistic Colexification Patterns](https://arxiv.org/abs/2510.13407)
*Kim Gfeller,Sabine Stoll,Chundra Cathcart,Paul Widmer*

Main category: cs.CL

TL;DR: 本研究利用系统发育比较模型，研究了三种语言语系（南岛语系、印欧语系和乌拉尔语系）中概念对共同词汇化的演变动态。


<details>
  <summary>Details</summary>
Motivation: 理解意义演变的决定因素仍然是一个挑战。共同词汇化现象为研究跨语言的意义变化动态提供了一个窗口。

Method: 使用系统发育比较模型分析三种语言语系的词典数据，评估关联性、借用性和使用频率三个预测因素对概念对共同词汇化的影响。

Result: 结果表明，关系更密切的概念对在更大的语系树范围内被共同词汇化，变化速度较慢。更频繁和更易于借用的概念对变化更快，共同词汇化程度较低。不同语系之间存在显著差异。

Conclusion: 区域和文化因素可能在概念对的共同词汇化中起作用。

Abstract: One of the most intriguing features of language is its constant change, with
ongoing shifts in how meaning is expressed. Despite decades of research, the
factors that determine how and why meanings evolve remain only partly
understood. Colexification -- the phenomenon of expressing multiple distinct
concepts using the same word form -- serves as a valuable window onto the
dynamics of meaning change across languages. Here, we apply phylogenetic
comparative models to dictionary data from three language families,
Austronesian, Indo-European, and Uralic, in order to shed light on the
evolutionary dynamics underlying the colexification of concept pairs. We assess
the effects of three predictors: associativity, borrowability, and usage
frequency. Our results show that more closely related concept pairs are
colexified across a larger portion of the family tree and exhibit slower rates
of change. In contrast, concept pairs that are more frequent and more prone to
borrowing tend to change more rapidly and are less often colexified. We also
find considerable differences between the language families under study,
suggesting that areal and cultural factors may play a role.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [57] [SimULi: Real-Time LiDAR and Camera Simulation with Unscented Transforms](https://arxiv.org/abs/2510.12901)
*Haithem Turki,Qi Wu,Xin Kang,Janick Martinez Esturo,Shengyu Huang,Ruilong Li,Zan Gojcic,Riccardo de Lutio*

Main category: cs.CV

TL;DR: SimULi: a novel method capable of rendering arbitrary camera models and LiDAR data in real-time.


<details>
  <summary>Details</summary>
Motivation: Existing neural rendering methods suffer from low rendering speeds or can only render pinhole camera models, hindering their suitability to applications that commonly require high-distortion lenses and LiDAR data. Multi-sensor simulation poses additional challenges as existing methods handle cross-sensor inconsistencies by favoring the quality of one modality at the expense of others.

Method: The method extends 3DGUT with LiDAR support, via an automated tiling strategy for arbitrary spinning LiDAR models and ray-based culling. To address cross-sensor inconsistencies, the method design a factorized 3D Gaussian representation and anchoring strategy.

Result: SimULi renders 10-20x faster than ray tracing approaches and 1.5-10x faster than prior rasterization-based work. When evaluated on two widely benchmarked autonomous driving datasets, SimULi matches or exceeds the fidelity of existing state-of-the-art methods across numerous camera and LiDAR metrics.

Conclusion: SimULi is the first method capable of rendering arbitrary camera models and LiDAR data in real-time with high fidelity.

Abstract: Rigorous testing of autonomous robots, such as self-driving vehicles, is
essential to ensure their safety in real-world deployments. This requires
building high-fidelity simulators to test scenarios beyond those that can be
safely or exhaustively collected in the real-world. Existing neural rendering
methods based on NeRF and 3DGS hold promise but suffer from low rendering
speeds or can only render pinhole camera models, hindering their suitability to
applications that commonly require high-distortion lenses and LiDAR data.
Multi-sensor simulation poses additional challenges as existing methods handle
cross-sensor inconsistencies by favoring the quality of one modality at the
expense of others. To overcome these limitations, we propose SimULi, the first
method capable of rendering arbitrary camera models and LiDAR data in
real-time. Our method extends 3DGUT, which natively supports complex camera
models, with LiDAR support, via an automated tiling strategy for arbitrary
spinning LiDAR models and ray-based culling. To address cross-sensor
inconsistencies, we design a factorized 3D Gaussian representation and
anchoring strategy that reduces mean camera and depth error by up to 40%
compared to existing methods. SimULi renders 10-20x faster than ray tracing
approaches and 1.5-10x faster than prior rasterization-based work (and handles
a wider range of camera models). When evaluated on two widely benchmarked
autonomous driving datasets, SimULi matches or exceeds the fidelity of existing
state-of-the-art methods across numerous camera and LiDAR metrics.

</details>


### [58] [State-Change Learning for Prediction of Future Events in Endoscopic Videos](https://arxiv.org/abs/2510.12904)
*Saurav Sharma,Chinedu Innocent Nwoye,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 本文提出了一种新的手术未来预测方法，通过将预测问题转化为状态变化学习，并引入SurgFUTR模型，实现了在短时和长时预测任务上的提升，并在跨手术流程的泛化性方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前手术AI研究主要集中于理解正在发生的事情，缺乏预测未来事件的统一方法，且现有方法泛化性不足。

Method: 本文将手术未来预测重新定义为状态变化学习，提出SurgFUTR模型，采用teacher-student架构，利用Sinkhorn-Knopp聚类压缩视频片段为状态表示，并通过Action Dynamics (ActDyn)模块引导学生网络预测未来状态。

Result: 在四个数据集和三个手术流程的实验中，SurgFUTR模型在五个预测任务上均表现出一致的改进，并且在跨流程迁移中验证了其泛化性。

Conclusion: SurgFUTR模型通过状态变化学习和teacher-student架构，有效提升了手术未来预测的准确性和泛化性，为手术室安全和效率提供了有价值的见解。

Abstract: Surgical future prediction, driven by real-time AI analysis of surgical
video, is critical for operating room safety and efficiency. It provides
actionable insights into upcoming events, their timing, and risks-enabling
better resource allocation, timely instrument readiness, and early warnings for
complications (e.g., bleeding, bile duct injury). Despite this need, current
surgical AI research focuses on understanding what is happening rather than
predicting future events. Existing methods target specific tasks in isolation,
lacking unified approaches that span both short-term (action triplets, events)
and long-term horizons (remaining surgery duration, phase transitions). These
methods rely on coarse-grained supervision while fine-grained surgical action
triplets and steps remain underexplored. Furthermore, methods based only on
future feature prediction struggle to generalize across different surgical
contexts and procedures. We address these limits by reframing surgical future
prediction as state-change learning. Rather than forecasting raw observations,
our approach classifies state transitions between current and future timesteps.
We introduce SurgFUTR, implementing this through a teacher-student
architecture. Video clips are compressed into state representations via
Sinkhorn-Knopp clustering; the teacher network learns from both current and
future clips, while the student network predicts future states from current
videos alone, guided by our Action Dynamics (ActDyn) module. We establish
SFPBench with five prediction tasks spanning short-term (triplets, events) and
long-term (remaining surgery duration, phase and step transitions) horizons.
Experiments across four datasets and three procedures show consistent
improvements. Cross-procedure transfer validates generalizability.

</details>


### [59] [Robust Plant Disease Diagnosis with Few Target-Domain Samples](https://arxiv.org/abs/2510.12909)
*Takafumi Nogami,Satoshi Kagiwada,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: 提出了一个名为 Target-Aware Metric Learning with Prioritized Sampling (TMPS) 的学习框架，以提高植物疾病诊断的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的植物病害诊断系统在不同条件下拍摄的图像上难以保持诊断准确性，原因是训练数据多样性有限，导致模型在新领域中脆弱。

Method: 提出了一种基于度量学习的 Target-Aware Metric Learning with Prioritized Sampling (TMPS) 框架，该框架利用来自目标域的少量标记样本来提高诊断的鲁棒性。

Result: 在包含来自 23 个农业田地的 223,073 张叶片图像的大规模植物病害诊断任务中，TMPS 仅通过将每个疾病的 10 个目标域样本纳入训练，就超过了使用相同组合的源和目标样本训练的模型，以及在源数据上预训练后使用这些目标样本进行微调的模型。

Conclusion: TMPS 实现了平均 macro F1 分数分别提高了 7.3 和 3.6 个百分点，并且比基线和传统度量学习分别提高了 18.7 和 17.1 个百分点。

Abstract: Various deep learning-based systems have been proposed for accurate and
convenient plant disease diagnosis, achieving impressive performance. However,
recent studies show that these systems often fail to maintain diagnostic
accuracy on images captured under different conditions from the training
environment -- an essential criterion for model robustness. Many deep learning
methods have shown high accuracy in plant disease diagnosis. However, they
often struggle to generalize to images taken in conditions that differ from the
training setting. This drop in performance stems from the subtle variability of
disease symptoms and domain gaps -- differences in image context and
environment. The root cause is the limited diversity of training data relative
to task complexity, making even advanced models vulnerable in unseen domains.
To tackle this challenge, we propose a simple yet highly adaptable learning
framework called Target-Aware Metric Learning with Prioritized Sampling (TMPS),
grounded in metric learning. TMPS operates under the assumption of access to a
limited number of labeled samples from the target (deployment) domain and
leverages these samples effectively to improve diagnostic robustness. We assess
TMPS on a large-scale automated plant disease diagnostic task using a dataset
comprising 223,073 leaf images sourced from 23 agricultural fields, spanning 21
diseases and healthy instances across three crop species. By incorporating just
10 target domain samples per disease into training, TMPS surpasses models
trained using the same combined source and target samples, and those fine-tuned
with these target samples after pre-training on source data. It achieves
average macro F1 score improvements of 7.3 and 3.6 points, respectively, and a
remarkable 18.7 and 17.1 point improvement over the baseline and conventional
metric learning.

</details>


### [60] [Unifying Vision-Language Latents for Zero-label Image Caption Enhancement](https://arxiv.org/abs/2510.12931)
*Sanghyun Byun,Jung Ick Guack,Mohanad Odema,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CV

TL;DR: 提出了一种名为 ViZer 的零标签增强训练框架，用于改进图像字幕生成，无需文本标签或完全重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型依赖于带标签的图像数据集，限制了可扩展性，且大量未标记图像数据未被充分利用。

Method: ViZer 在训练期间主动对齐视觉和语言表示特征，使现有 VLM 能够生成改进的字幕，而无需文本标签。

Result: 在 SmolVLM-Base 和 Qwen2-VL 上应用 ViZer 观察到持续的定性改进，生成的字幕比基线更 grounded 和更具描述性。

Conclusion: ViZer 实现了图像字幕中的零标签学习，为视觉-语言任务中更广泛的零标签适应提供了实践起点。

Abstract: Vision-language models (VLMs) achieve remarkable performance through
large-scale image-text pretraining. However, their reliance on labeled image
datasets limits scalability and leaves vast amounts of unlabeled image data
underutilized. To address this, we propose Unified Vision-Language Alignment
for Zero-Label Enhancement (ViZer), an enhancement training framework that
enables zero-label learning in image captioning, providing a practical starting
point for broader zero-label adaptation in vision-language tasks. Unlike prior
approaches that rely on human or synthetically annotated datasets, ViZer
actively aligns vision and language representation features during training,
enabling existing VLMs to generate improved captions without requiring text
labels or full retraining. We demonstrate ViZer's advantage in qualitative
evaluation, as automated caption metrics such as CIDEr and BERTScore often
penalize details that are absent in reference captions. Applying ViZer on
SmolVLM-Base and Qwen2-VL, we observe consistent qualitative improvements,
producing captions that are more grounded and descriptive than their baseline.

</details>


### [61] [Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation](https://arxiv.org/abs/2510.12953)
*Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: FetalMind是一个专为胎儿超声设计的医学AI系统，用于报告生成和诊断，它通过引入 Salient Epistemic Disentanglement (SED) 来解耦视图-疾病关联，并通过强化学习引导偏好选择，从而缓解疾病变异性和视图异质性。为了训练 FetalMind，我们创建了 FetalSigma-1M 数据集，这是一个大规模的胎儿超声报告语料库。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉-语言模型在胎儿超声方面表现不佳，因为胎儿超声具有多视图图像推理、多种疾病和图像多样性等挑战。

Method: 提出了 Salient Epistemic Disentanglement (SED)，它将专家策划的二分图注入到模型中，以解耦视图-疾病关联，并通过强化学习引导偏好选择。

Result: FetalMind 在所有妊娠阶段都优于开源和闭源基线，平均增益 +14%，在关键条件下准确率提高 +61.2%，同时保持高效、稳定和可扩展。

Conclusion: FetalMind 是一个专为胎儿超声设计的有效医学AI系统，它通过 SED 和大规模数据集的训练，在报告生成和诊断方面取得了显著的成果。

Abstract: Recent medical vision-language models have shown promise on tasks such as
VQA, report generation, and anomaly detection. However, most are adapted to
structured adult imaging and underperform in fetal ultrasound, which poses
challenges of multi-view image reasoning, numerous diseases, and image
diversity. To bridge this gap, we introduce FetalMind, a medical AI system
tailored to fetal ultrasound for both report generation and diagnosis. Guided
by clinical workflow, we propose Salient Epistemic Disentanglement (SED), which
injects an expert-curated bipartite graph into the model to decouple
view-disease associations and to steer preference selection along clinically
faithful steps via reinforcement learning. This design mitigates variability
across diseases and heterogeneity across views, reducing learning bottlenecks
while aligning the model's inference with obstetric practice. To train
FetalMind at scale, we curate FetalSigma-1M dataset, the first large-scale
fetal ultrasound report corpus, comprising 20K reports from twelve medical
centers, addressing the scarcity of domain data. Extensive experiments show
that FetalMind outperforms open- and closed-source baselines across all
gestational stages, achieving +14% average gains and +61.2% higher accuracy on
critical conditions while remaining efficient, stable, and scalable. Project
Page: https://hexiao0275.github.io/FetalMind.

</details>


### [62] [CADE 2.5 - ZeResFDG: Frequency-Decoupled, Rescaled and Zero-Projected Guidance for SD/SDXL Latent Diffusion Models](https://arxiv.org/abs/2510.12954)
*Denis Rychkovskiy,GPT-5*

Main category: cs.CV

TL;DR: CADE 2.5 (Comfy Adaptive Detail Enhancer) is introduced, a sampler-level guidance stack for SD/SDXL latent diffusion models.


<details>
  <summary>Details</summary>
Motivation: To improve sharpness, prompt adherence, and artifact control at moderate guidance scales without any retraining.

Method: It unifies frequency-decoupled guidance, energy rescaling, and zero-projection in ZeResFDG. Also, it employs a training-free inference-time stabilizer, QSilk Micrograin Stabilizer.

Result: ZeResFDG improves sharpness, prompt adherence, and artifact control. QSilk Micrograin Stabilizer improves robustness and yields natural high-frequency micro-texture at high resolutions with negligible overhead.

Conclusion: CADE 2.5 improves image generation quality without retraining by using ZeResFDG and QSilk Micrograin Stabilizer.

Abstract: We introduce CADE 2.5 (Comfy Adaptive Detail Enhancer), a sampler-level
guidance stack for SD/SDXL latent diffusion models. The central module,
ZeResFDG, unifies (i) frequency-decoupled guidance that reweights low- and
high-frequency components of the guidance signal, (ii) energy rescaling that
matches the per-sample magnitude of the guided prediction to the positive
branch, and (iii) zero-projection that removes the component parallel to the
unconditional direction. A lightweight spectral EMA with hysteresis switches
between a conservative and a detail-seeking mode as structure crystallizes
during sampling. Across SD/SDXL samplers, ZeResFDG improves sharpness, prompt
adherence, and artifact control at moderate guidance scales without any
retraining. In addition, we employ a training-free inference-time stabilizer,
QSilk Micrograin Stabilizer (quantile clamp + depth/edge-gated micro-detail
injection), which improves robustness and yields natural high-frequency
micro-texture at high resolutions with negligible overhead. For completeness we
note that the same rule is compatible with alternative parameterizations (e.g.,
velocity), which we briefly discuss in the Appendix; however, this paper
focuses on SD/SDXL latent diffusion models.

</details>


### [63] [Scope: Selective Cross-modal Orchestration of Visual Perception Experts](https://arxiv.org/abs/2510.12974)
*Tianyu Zhang,Suyuchen Wang,Chao Wang,Juan Rodriguez,Ahmed Masry,Xiangru Jian,Yoshua Bengio,Perouz Taslakian*

Main category: cs.CV

TL;DR: 提出了一种新的视觉语言模型框架，称为SCOPE，它使用混合编码器（MoEnc）结构，通过实例级别的路由动态选择每个图像-文本对的专用编码器。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型受益于多个视觉编码器，但简单地堆叠它们会降低收益并增加推理成本。

Method: SCOPE框架包含一个共享编码器和一个路由编码器池。一个轻量级路由器使用文本提示和共享视觉特征之间的交叉注意力，从路由编码器中选择最佳编码器。为了训练这个路由器，引入了双熵正则化和辅助损失，以平衡数据集级别的负载分配和实例级别的路由置信度。

Result: SCOPE使用一个共享编码器和一个路由编码器，性能优于同时使用所有四个额外编码器的模型，同时计算量减少了24-49%。

Conclusion: 智能编码器选择优于蛮力聚合，挑战了多编码器视觉语言模型中普遍存在的范例。

Abstract: Vision-language models (VLMs) benefit from multiple vision encoders, but
naively stacking them yields diminishing returns while multiplying inference
costs. We propose SCOPE, a Mixture-of-Encoders (MoEnc) framework that
dynamically selects one specialized encoder per image-text pair via
instance-level routing, unlike token-level routing in traditional MoE. SCOPE
maintains a shared encoder and a pool of routed encoders. A lightweight router
uses cross-attention between text prompts and shared visual features to select
the optimal encoder from the routed encoders. To train this router, we
introduce dual entropy regularization with auxiliary losses to balance
dataset-level load distribution with instance-level routing confidence.
Remarkably, SCOPE with one shared plus one routed encoder outperforms models
using all four extra encoders simultaneously, while reducing compute by
24-49\%. This demonstrates that intelligent encoder selection beats brute-force
aggregation, challenging the prevailing paradigm in multi-encoder VLMs.

</details>


### [64] [SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding](https://arxiv.org/abs/2510.13016)
*Tanveer Hannan,Shuaicong Wu,Mark Weber,Suprosanna Shit,Jindong Gu,Rajat Koner,Aljoša Ošep,Laura Leal-Taixé,Thomas Seidl*

Main category: cs.CV

TL;DR: 提出了时空视频动作定位 (SVAG) 任务，以根据动作的自然语言描述，同时检测、跟踪和时间定位视频中的所有参考对象。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要解决粗粒度动作识别或通用对象跟踪问题，忽略了根据对象的动作联合检测和跟踪多个对象并在时间上定位它们的挑战。

Method: 构建了包含 688 个视频、19,590 个带注释的记录和 903 个独特动词的大规模基准 SVAG-Bench。提出了 SVAGFormer，这是一个用于联合空间和时间定位的基线框架，并引入了用于公平和可重复基准测试的标准化评估工具包 SVAGEval。

Result: 现有模型在 SVAG 上表现不佳，尤其是在密集或复杂的场景中。

Conclusion: 需要在长视频中对细粒度的对象-动作交互进行更高级的推理。

Abstract: Understanding fine-grained actions and accurately localizing their
corresponding actors in space and time are fundamental capabilities for
advancing next-generation AI systems, including embodied agents, autonomous
platforms, and human-AI interaction frameworks. Despite recent progress in
video understanding, existing methods predominantly address either
coarse-grained action recognition or generic object tracking, thereby
overlooking the challenge of jointly detecting and tracking multiple objects
according to their actions while grounding them temporally. To address this
gap, we introduce Spatio-temporal Video Action Grounding (SVAG), a novel task
that requires models to simultaneously detect, track, and temporally localize
all referent objects in videos based on natural language descriptions of their
actions. To support this task, we construct SVAG-Bench, a large-scale benchmark
comprising 688 videos, 19,590 annotated records, and 903 unique verbs, covering
a diverse range of objects, actions, and real-world scenes. We further propose
SVAGFormer, a baseline framework that adapts state of the art vision language
models for joint spatial and temporal grounding, and introduce SVAGEval, a
standardized evaluation toolkit for fair and reproducible benchmarking.
Empirical results show that existing models perform poorly on SVAG,
particularly in dense or complex scenes, underscoring the need for more
advanced reasoning over fine-grained object-action interactions in long videos.

</details>


### [65] [SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models](https://arxiv.org/abs/2510.13042)
*Zhengxu Tang,Zizheng Wang,Luning Wang,Zitao Shuai,Chenhao Zhang,Siyu Qian,Yirui Wu,Bohao Wang,Haosong Rao,Zhenyu Yang,Chenwei Wu*

Main category: cs.CV

TL;DR: SeqBench是一个用于评估文本到视频生成模型中叙事连贯性的综合基准，包含数据集和评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频基准主要关注视觉质量，而忽略了对扩展序列中叙事连贯性的评估。

Method: 该论文提出了SeqBench，一个包含320个提示和2560个人工标注视频的数据集，以及一个基于动态时间图（DTG）的自动评估指标。

Result: 通过SeqBench的系统评估，揭示了当前文本到视频模型在保持对象状态一致性、物理合理性和时序关系方面的局限性。

Conclusion: SeqBench提供了一个评估文本到视频生成中叙事连贯性的系统框架，并为改进未来模型的序列推理能力提供了具体见解。

Abstract: Text-to-video (T2V) generation models have made significant progress in
creating visually appealing videos. However, they struggle with generating
coherent sequential narratives that require logical progression through
multiple events. Existing T2V benchmarks primarily focus on visual quality
metrics but fail to evaluate narrative coherence over extended sequences. To
bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating
sequential narrative coherence in T2V generation. SeqBench includes a carefully
designed dataset of 320 prompts spanning various narrative complexities, with
2,560 human-annotated videos generated from 8 state-of-the-art T2V models.
Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic
evaluation metric, which can efficiently capture long-range dependencies and
temporal ordering while maintaining computational efficiency. Our DTG-based
metric demonstrates a strong correlation with human annotations. Through
systematic evaluation using SeqBench, we reveal critical limitations in current
T2V models: failure to maintain consistent object states across multi-action
sequences, physically implausible results in multi-object scenarios, and
difficulties in preserving realistic timing and ordering relationships between
sequential actions. SeqBench provides the first systematic framework for
evaluating narrative coherence in T2V generation and offers concrete insights
for improving sequential reasoning capabilities in future models. Please refer
to https://videobench.github.io/SeqBench.github.io/ for more details.

</details>


### [66] [SceneAdapt: Scene-aware Adaptation of Human Motion Diffusion](https://arxiv.org/abs/2510.13044)
*Jungbin Cho,Minsu Kim,Jisoo Kim,Ce Zheng,Laszlo A. Jeni,Ming-Hsuan Yang,Youngjae Yu,Seonjoo Kim*

Main category: cs.CV

TL;DR: SceneAdapt框架通过两个阶段的适应，将场景感知注入到文本条件运动模型中：帧间和场景感知帧间。


<details>
  <summary>Details</summary>
Motivation: 现有运动生成方法孤立地处理运动语义或场景感知，因为构建具有丰富的文本-运动覆盖和精确的场景交互的大规模数据集极具挑战性。

Method: 利用不相交的场景-运动和文本-运动数据集，通过两个适应阶段：帧间和场景感知帧间，将场景感知注入到文本条件运动模型中。关键思想是使用运动帧间（无需文本即可学习）作为代理任务，以桥接两个不同的数据集，从而将场景感知注入到文本到运动模型。

Result: 实验结果表明，SceneAdapt有效地将场景感知注入到文本到运动模型中，并且我们进一步分析了这种感知出现的机制。

Conclusion: SceneAdapt有效地将场景感知注入到文本到运动模型中。

Abstract: Human motion is inherently diverse and semantically rich, while also shaped
by the surrounding scene. However, existing motion generation approaches
address either motion semantics or scene-awareness in isolation, since
constructing large-scale datasets with both rich text--motion coverage and
precise scene interactions is extremely challenging. In this work, we introduce
SceneAdapt, a framework that injects scene awareness into text-conditioned
motion models by leveraging disjoint scene--motion and text--motion datasets
through two adaptation stages: inbetweening and scene-aware inbetweening. The
key idea is to use motion inbetweening, learnable without text, as a proxy task
to bridge two distinct datasets and thereby inject scene-awareness to
text-to-motion models. In the first stage, we introduce keyframing layers that
modulate motion latents for inbetweening while preserving the latent manifold.
In the second stage, we add a scene-conditioning layer that injects scene
geometry by adaptively querying local context through cross-attention.
Experimental results show that SceneAdapt effectively injects scene awareness
into text-to-motion models, and we further analyze the mechanisms through which
this awareness emerges. Code and models will be released.

</details>


### [67] [One Dimensional CNN ECG Mamba for Multilabel Abnormality Classification in 12 Lead ECG](https://arxiv.org/abs/2510.13046)
*Huawei Jiang,Husna Mutahira,Gan Huang,Mannan Saeed Muhammad*

Main category: cs.CV

TL;DR: 提出了一种新的心电图分类框架，该框架结合了卷积特征提取和 Mamba，一种选择性状态空间模型，用于有效的序列建模。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在处理长序列信号时性能有限。

Method: 结合卷积特征提取和 Mamba，一种选择性状态空间模型，用于有效的序列建模。该模型建立在 Vision Mamba 之上，Vision Mamba 是一种双向变体，通过它可以增强心电图数据中时间依赖性的表示。

Result: 在 2020 年和 2021 年 PhysioNet 心脏病学计算挑战赛中进行的综合实验表明，与现有方法相比，该模型取得了优异的性能。具体而言，所提出的模型获得了比以前发表的十二导联心电图最佳算法更高的 AUPRC 和 AUROC 分数。

Conclusion: 基于 Mamba 的架构具有推进可靠 ECG 分类的潜力。这种能力支持早期诊断和个性化治疗，同时提高远程医疗和资源受限的医疗保健系统的可及性。

Abstract: Accurate detection of cardiac abnormalities from electrocardiogram recordings
is regarded as essential for clinical diagnostics and decision support.
Traditional deep learning models such as residual networks and transformer
architectures have been applied successfully to this task, but their
performance has been limited when long sequential signals are processed.
Recently, state space models have been introduced as an efficient alternative.
In this study, a hybrid framework named One Dimensional Convolutional Neural
Network Electrocardiogram Mamba is introduced, in which convolutional feature
extraction is combined with Mamba, a selective state space model designed for
effective sequence modeling. The model is built upon Vision Mamba, a
bidirectional variant through which the representation of temporal dependencies
in electrocardiogram data is enhanced. Comprehensive experiments on the
PhysioNet Computing in Cardiology Challenges of 2020 and 2021 were conducted,
and superior performance compared with existing methods was achieved.
Specifically, the proposed model achieved substantially higher AUPRC and AUROC
scores than those reported by the best previously published algorithms on
twelve lead electrocardiograms. These results demonstrate the potential of
Mamba-based architectures to advance reliable ECG classification. This
capability supports early diagnosis and personalized treatment, while enhancing
accessibility in telemedicine and resource-constrained healthcare systems.

</details>


### [68] [True Self-Supervised Novel View Synthesis is Transferable](https://arxiv.org/abs/2510.13063)
*Thomas W. Mitchel,Hyunwoo Ryu,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 本文介绍了一种名为XFactor的无几何自监督模型，该模型能够进行真正的新视角合成(NVS)。


<details>
  <summary>Details</summary>
Motivation: 以往的自监督NVS模型预测的姿势不具备可转移性，即同一组姿势在不同的3D场景中会导致不同的相机轨迹。

Method: XFactor结合了成对姿势估计和简单的输入输出增强方案，从而能够解耦相机姿势和场景内容，并促进几何推理。

Result: XFactor在可转移性方面优于以往的无姿势NVS转换器，并且潜在姿势与真实姿势高度相关。

Conclusion: XFactor是第一个能够实现真正NVS的无几何自监督模型，它在没有3D归纳偏差或多视图几何概念的情况下实现了可转移性。

Abstract: In this paper, we identify that the key criterion for determining whether a
model is truly capable of novel view synthesis (NVS) is transferability:
Whether any pose representation extracted from one video sequence can be used
to re-render the same camera trajectory in another. We analyze prior work on
self-supervised NVS and find that their predicted poses do not transfer: The
same set of poses lead to different camera trajectories in different 3D scenes.
Here, we present XFactor, the first geometry-free self-supervised model capable
of true NVS. XFactor combines pair-wise pose estimation with a simple
augmentation scheme of the inputs and outputs that jointly enables
disentangling camera pose from scene content and facilitates geometric
reasoning. Remarkably, we show that XFactor achieves transferability with
unconstrained latent pose variables, without any 3D inductive biases or
concepts from multi-view geometry -- such as an explicit parameterization of
poses as elements of SE(3). We introduce a new metric to quantify
transferability, and through large-scale experiments, we demonstrate that
XFactor significantly outperforms prior pose-free NVS transformers, and show
that latent poses are highly correlated with real-world poses through probing
experiments.

</details>


### [69] [Direction-aware multi-scale gradient loss for infrared and visible image fusion](https://arxiv.org/abs/2510.13067)
*Kaixuan Yang,Wei Xiang,Zhenshuai Chen,Tong Jin,Yunpeng Liu*

Main category: cs.CV

TL;DR: 提出了一种方向感知的多尺度梯度损失函数，用于红外和可见光图像融合，以提高边缘保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法在训练时结合了结构相似性损失、强度重建损失和梯度幅度项，但梯度幅度会移除方向信息，导致监督模糊和边缘保真度欠佳。

Method: 引入方向感知的多尺度梯度损失，分别监督水平和垂直分量，并在不同尺度上保持其符号。

Result: 在开源模型和多个公共基准测试上的实验表明了该方法的有效性。

Conclusion: 该轴向、保号目标在精细和粗略分辨率下提供清晰的方向指导，从而在不改变模型架构或训练协议的情况下，促进更清晰、更好对齐的边缘和更丰富的纹理保留。

Abstract: Infrared and visible image fusion aims to integrate complementary information
from co-registered source images to produce a single, informative result. Most
learning-based approaches train with a combination of structural similarity
loss, intensity reconstruction loss, and a gradient-magnitude term. However,
collapsing gradients to their magnitude removes directional information,
yielding ambiguous supervision and suboptimal edge fidelity. We introduce a
direction-aware, multi-scale gradient loss that supervises horizontal and
vertical components separately and preserves their sign across scales. This
axis-wise, sign-preserving objective provides clear directional guidance at
both fine and coarse resolutions, promoting sharper, better-aligned edges and
richer texture preservation without changing model architectures or training
protocols. Experiments on open-source model and multiple public benchmarks
demonstrate effectiveness of our approach.

</details>


### [70] [Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation](https://arxiv.org/abs/2510.13075)
*Hoda Kalabizadeh,Ludovica Griffanti,Pak-Hei Yeung,Ana I. L. Namburete,Nicola K. Dinsdale,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 本文提出了一种新的无监督域适应框架，用于解决医学图像分割中由于域偏移导致的问题，特别关注内容变化。该方法结合了通过 z-norm 实现的风格协调和双向可变形图像配准 (DIR) 策略。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割的深度学习模型在不同数据集上部署时，由于域偏移（图像外观和 population-dependent 的解剖学特征的变化）而面临挑战。

Method: 该方法结合了通过 z-norm 实现的风格协调和双向可变形图像配准 (DIR) 策略。DIR 网络与分割和判别器网络联合训练，以根据感兴趣区域指导配准，并生成在解剖学上合理的变换，从而将源图像与目标域对齐。

Result: 在所有实验中，该方法都优于现有基线。对于海马分割，当从年轻、健康人群转移到临床痴呆患者时，与标准增强方法相比，该框架在 Dice 评分方面实现了高达 15% 的相对改进，并且在内容偏移较大的情况下观察到最大的收益。

Conclusion: 这些结果突出了该方法在不同人群中进行准确海马分割的有效性。

Abstract: Deep learning models for medical image segmentation often struggle when
deployed across different datasets due to domain shifts - variations in both
image appearance, known as style, and population-dependent anatomical
characteristics, referred to as content. This paper presents a novel
unsupervised domain adaptation framework that directly addresses domain shifts
encountered in cross-domain hippocampus segmentation from MRI, with specific
emphasis on content variations. Our approach combines efficient style
harmonisation through z-normalisation with a bidirectional deformable image
registration (DIR) strategy. The DIR network is jointly trained with
segmentation and discriminator networks to guide the registration with respect
to a region of interest and generate anatomically plausible transformations
that align source images to the target domain. We validate our approach through
comprehensive evaluations on both a synthetic dataset using Morpho-MNIST (for
controlled validation of core principles) and three MRI hippocampus datasets
representing populations with varying degrees of atrophy. Across all
experiments, our method outperforms existing baselines. For hippocampus
segmentation, when transferring from young, healthy populations to clinical
dementia patients, our framework achieves up to 15% relative improvement in
Dice score compared to standard augmentation methods, with the largest gains
observed in scenarios with substantial content shift. These results highlight
the efficacy of our approach for accurate hippocampus segmentation across
diverse populations.

</details>


### [71] [Counting Hallucinations in Diffusion Models](https://arxiv.org/abs/2510.13080)
*Shuai Fu,Jian Zhou,Qi Chen,Huang Jing,Huy Anh Nguyen,Xiaohan Liu,Zhixiong Zeng,Lin Ma,Quanshi Zhang,Qi Wu*

Main category: cs.CV

TL;DR: 这篇论文研究了扩散概率模型(DPMs)中常见的幻觉问题，特别是计数幻觉，即生成错误数量的物体。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型会产生与现实世界知识冲突的幻觉样本，缺乏量化这些幻觉的方法阻碍了相关研究。

Method: 构建了一个名为CountHalluSet的数据集套件，并设计了一个标准化的评估协议来量化计数幻觉。通过该数据集，系统地研究了DPMs中不同采样条件（如求解器类型、ODE求解器阶数、采样步数和初始噪声）如何影响计数幻觉的水平。

Result: 发现常用的图像质量指标FID不能始终如一地捕捉到计数幻觉。

Conclusion: 这项工作旨在朝着系统地量化扩散模型中的幻觉现象迈出第一步，并为研究图像生成中的幻觉现象提供新的见解。

Abstract: Diffusion probabilistic models (DPMs) have demonstrated remarkable progress
in generative tasks, such as image and video synthesis. However, they still
often produce hallucinated samples (hallucinations) that conflict with
real-world knowledge, such as generating an implausible duplicate cup floating
beside another cup. Despite their prevalence, the lack of feasible
methodologies for systematically quantifying such hallucinations hinders
progress in addressing this challenge and obscures potential pathways for
designing next-generation generative models under factual constraints. In this
work, we bridge this gap by focusing on a specific form of hallucination, which
we term counting hallucination, referring to the generation of an incorrect
number of instances or structured objects, such as a hand image with six
fingers, despite such patterns being absent from the training data. To this
end, we construct a dataset suite CountHalluSet, with well-defined counting
criteria, comprising ToyShape, SimObject, and RealHand. Using these datasets,
we develop a standardized evaluation protocol for quantifying counting
hallucinations, and systematically examine how different sampling conditions in
DPMs, including solver type, ODE solver order, sampling steps, and initial
noise, affect counting hallucination levels. Furthermore, we analyze their
correlation with common evaluation metrics such as FID, revealing that this
widely used image quality metric fails to capture counting hallucinations
consistently. This work aims to take the first step toward systematically
quantifying hallucinations in diffusion models and offer new insights into the
investigation of hallucination phenomena in image generation.

</details>


### [72] [Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation](https://arxiv.org/abs/2510.13084)
*Yi Zuo,Zitao Wang,Lingling Li,Xu Liu,Fang Liu,Licheng Jiao*

Main category: cs.CV

TL;DR: Edit-Your-Interest是一种轻量级的文本驱动的零样本视频编辑方法，它通过引入时空特征记忆来缓存前一帧的特征，显著降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编辑方法受到高计算开销和内存消耗的严重限制，并且常常牺牲视觉保真度，导致不良的时间不一致和伪影。

Method: 该方法引入了时空特征记忆库（SFM）来缓存和保留空间注意力处理的关键图像token；提出了特征最相似传播（FMP）方法，将最相关的token从前一帧传播到后一帧，保持时间一致性；引入了SFM更新算法，不断刷新缓存的特征；利用交叉注意力图自动提取感兴趣实例的掩码。

Result: 大量实验表明，Edit-Your-Interest在效率和视觉保真度方面均优于最先进的方法。

Conclusion: Edit-Your-Interest具有卓越的有效性和实用性。

Abstract: Text-to-image (T2I) diffusion models have recently demonstrated significant
progress in video editing.
  However, existing video editing methods are severely limited by their high
computational overhead and memory consumption.
  Furthermore, these approaches often sacrifice visual fidelity, leading to
undesirable temporal inconsistencies and artifacts such as blurring and
pronounced mosaic-like patterns.
  We propose Edit-Your-Interest, a lightweight, text-driven, zero-shot video
editing method.
  Edit-Your-Interest introduces a spatio-temporal feature memory to cache
features from previous frames, significantly reducing computational overhead
compared to full-sequence spatio-temporal modeling approaches.
  Specifically, we first introduce a Spatio-Temporal Feature Memory bank (SFM),
which is designed to efficiently cache and retain the crucial image tokens
processed by spatial attention.
  Second, we propose the Feature Most-Similar Propagation (FMP) method. FMP
propagates the most relevant tokens from previous frames to subsequent ones,
preserving temporal consistency.
  Finally, we introduce an SFM update algorithm that continuously refreshes the
cached features, ensuring their long-term relevance and effectiveness
throughout the video sequence.
  Furthermore, we leverage cross-attention maps to automatically extract masks
for the instances of interest.
  These masks are seamlessly integrated into the diffusion denoising process,
enabling fine-grained control over target objects and allowing
Edit-Your-Interest to perform highly accurate edits while robustly preserving
the background integrity.
  Extensive experiments decisively demonstrate that the proposed
Edit-Your-Interest outperforms state-of-the-art methods in both efficiency and
visual fidelity, validating its superior effectiveness and practicality.

</details>


### [73] [EgoSocial: Benchmarking Proactive Intervention Ability of Omnimodal LLMs via Egocentric Social Interaction Perception](https://arxiv.org/abs/2510.13105)
*Xijun Wang,Tanay Sharma,Achin Kulshrestha,Abhimitra Meka,Aveek Purohit,Dinesh Manocha*

Main category: cs.CV

TL;DR: 论文提出了EgoSocial数据集和EgoSoD方法，用于提升AI在社交互动中从自我中心视角进行干预时机的判断能力。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM缺乏社交感知能力，无法判断何时作为AI助手进行干预，导致不自然的对话和用户注意力分散。

Method: 1. 构建大规模的自我中心数据集EgoSocial，包含13,500个社交视频-问题对。
2. 深入分析当前的多模态LLM (OLLM) 在检测不同社交情境线索方面的有效性。
3. 提出EgoSoD方法，该方法将多模态情境线索整合到社交思维图中，动态建模参与者和互动，从而主动检测干预时机和社交互动。

Result: EgoSoD在干预时机判断方面，相较于Phi-4提升了45.6%，相较于Gemini 2.5 Pro提升了9.9%；在整体社交互动表现方面，相较于Phi-4提升了20.4%，相较于Gemini 2.5 Pro提升了6.9%。

Conclusion: 论文提出的EgoSocial数据集和EgoSoD方法显著提升了AI在社交互动中判断干预时机的能力。

Abstract: As AR/VR technologies become integral to daily life, there's a growing need
for AI that understands human social dynamics from an egocentric perspective.
However, current LLMs often lack the social awareness to discern when to
intervene as AI assistant. This leads to constant, socially unaware responses
that may disrupt natural conversation and negatively impact user focus. To
address these limitations, we introduce EgoSocial, a large-scale egocentric
dataset with 13,500 social video-question pairs, specifically designed to
benchmark intervention in social interaction perception. We also present an
in-depth analysis of current omnimodal LLMs (OLLMs) to assess their
effectiveness in detecting diverse social contextual cues. Experiments show
that OLLMs still struggle to detect the intervention timing (14.4% for Gemini
2.5 Pro). We also propose EgoSoD (EgoSocial Detection), an end-to-end method
for robustly discerning social dynamics. Informed by our OLLM analysis, EgoSoD
integrates multimodal contextual cues (e.g., audio and visual cues) into a
social thinking graph, dynamically modeling participants and interactions. Our
method proactively detects intervention timing and social interactions,
precisely determining when to intervene. Our EgoSoD improves Phi-4 by 45.6% and
Gemini 2.5 Pro by 9.9% on Intervention Timing performance, and improves Phi-4
by 20.4% and Gemini 2.5 Pro by 6.9% on overall Social Interaction performance.
We will release the dataset and code soon.

</details>


### [74] [DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models](https://arxiv.org/abs/2510.13108)
*Jingyu Song,Zhenxin Li,Shiyi Lan,Xinglong Sun,Nadine Chang,Maying Shen,Joshua Chen,Katherine A. Skinner,Jose M. Alvarez*

Main category: cs.CV

TL;DR: 提出 DriveCritic，一个用于评估自动驾驶规划器的新框架，更符合人类判断。


<details>
  <summary>Details</summary>
Motivation: 现有评估指标（如 EPDMS）在复杂场景中缺乏上下文感知能力。

Method: 1) 构建 DriveCritic 数据集，包含需要上下文判断的挑战性场景，并标注人类偏好；2) 提出 DriveCritic 模型，一个基于视觉-语言模型 (VLM) 的评估器；3) 使用两阶段监督和强化学习流程微调 DriveCritic 模型。

Result: DriveCritic 在匹配人类偏好方面显著优于现有指标和基线，并表现出强大的上下文感知能力。

Conclusion: DriveCritic 为评估自动驾驶系统提供了一个更可靠、更符合人类判断的基础。

Abstract: Benchmarking autonomous driving planners to align with human judgment remains
a critical challenge, as state-of-the-art metrics like the Extended Predictive
Driver Model Score (EPDMS) lack context awareness in nuanced scenarios. To
address this, we introduce DriveCritic, a novel framework featuring two key
contributions: the DriveCritic dataset, a curated collection of challenging
scenarios where context is critical for correct judgment and annotated with
pairwise human preferences, and the DriveCritic model, a Vision-Language Model
(VLM) based evaluator. Fine-tuned using a two-stage supervised and
reinforcement learning pipeline, the DriveCritic model learns to adjudicate
between trajectory pairs by integrating visual and symbolic context.
Experiments show DriveCritic significantly outperforms existing metrics and
baselines in matching human preferences and demonstrates strong context
awareness. Overall, our work provides a more reliable, human-aligned foundation
to evaluating autonomous driving systems.

</details>


### [75] [VPREG: An Optimal Control Formulation for Diffeomorphic Image Registration Based on the Variational Principle Grid Generation Method](https://arxiv.org/abs/2510.13109)
*Zicong Zhou,Baihan Zhao,Andreas Mang,Guojun Liao*

Main category: cs.CV

TL;DR: VPreg是一种新的diffeomorphic图像配准方法，旨在提高配准精度并控制配准变换的质量。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法在diffeomorphism群内生成逆变换，并且在计算解剖学和形态学中，需要保证diffeomorphic空间变换。

Method: VPreg的核心是网格生成方法，称为变分原理（VP），它构建具有规定雅可比行列式和旋度的非折叠网格。

Result: VPreg在Dice分数、计算变换的规律性以及提供的逆映射的准确性和一致性方面优于最先进的方法。

Conclusion: VPreg优于ANTs-SyN、Freesurfer-Easyreg和FSL-Fnirt。

Abstract: This paper introduces VPreg, a novel diffeomorphic image registration method.
This work provides several improvements to our past work on mesh generation and
diffeomorphic image registration. VPreg aims to achieve excellent registration
accuracy while controlling the quality of the registration transformations. It
ensures a positive Jacobian determinant of the spatial transformation and
provides an accurate approximation of the inverse of the registration, a
crucial property for many neuroimaging workflows. Unlike conventional methods,
VPreg generates this inverse transformation within the group of diffeomorphisms
rather than operating on the image space. The core of VPreg is a grid
generation approach, referred to as \emph{Variational Principle} (VP), which
constructs non-folding grids with prescribed Jacobian determinant and curl.
These VP-generated grids guarantee diffeomorphic spatial transformations
essential for computational anatomy and morphometry, and provide a more
accurate inverse than existing methods. To assess the potential of the proposed
approach, we conduct a performance analysis for 150 registrations of brain
scans from the OASIS-1 dataset. Performance evaluation based on Dice scores for
35 regions of interest, along with an empirical analysis of the properties of
the computed spatial transformations, demonstrates that VPreg outperforms
state-of-the-art methods in terms of Dice scores, regularity properties of the
computed transformation, and accuracy and consistency of the provided inverse
map. We compare our results to ANTs-SyN, Freesurfer-Easyreg, and FSL-Fnirt.

</details>


### [76] [OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment](https://arxiv.org/abs/2510.13131)
*Rongjun Chen,Chengsi Yao,Jinchang Ren,Xianxian Zeng,Peixian Wang,Jun Yuan,Jiawen Li,Huimin Zhao,Xu Lu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的跨模态文本图像对齐方法，通过利用大型语言模型（LLM）的开放语义知识来弥补文本和图像之间信息熵的差距，从而提高检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在文本和图像的互检索中存在不平衡，因为文本和图像的信息熵存在差异。

Method: 该方法通过两个步骤实现：1) 设计新的prompt模版，利用LLM增强文本模态的语义描述，增加文本模态的信息熵；2) 使用超图适配器构建文本和图像模态之间的多边连接，纠正同义语义的匹配错误，并通过降维映射减少开放语义熵带来的噪声。

Result: 在Flickr30K和MS-COCO基准测试中，该方法在跨模态检索方面取得了显著提升，text-to-image提升了16.8%，image-to-text提升了40.1%，并在语义对齐任务中达到了新的state-of-the-art。

Conclusion: 该方法有效地利用了LLM的开放语义知识，弥补了文本和图像之间信息熵的差距，提高了跨模态检索的性能。

Abstract: Text-image alignment constitutes a foundational challenge in multimedia
content understanding, where effective modeling of cross-modal semantic
correspondences critically enhances retrieval system performance through joint
embedding space optimization. Given the inherent difference in information
entropy between texts and images, conventional approaches often show an
imbalance in the mutual retrieval of these two modalities. To address this
particular challenge, we propose to use the open semantic knowledge of Large
Language Model (LLM) to fill for the entropy gap and reproduce the alignment
ability of humans in these tasks. Our entropy-enhancing alignment is achieved
through a two-step process: 1) a new prompt template that does not rely on
explicit knowledge in the task domain is designed to use LLM to enhance the
polysemy description of the text modality. By analogy, the information entropy
of the text modality relative to the visual modality is increased; 2) A
hypergraph adapter is used to construct multilateral connections between the
text and image modalities, which can correct the positive and negative matching
errors for synonymous semantics in the same fixed embedding space, whilst
reducing the noise caused by open semantic entropy by mapping the reduced
dimensions back to the original dimensions. Comprehensive evaluations on the
Flickr30K and MS-COCO benchmarks validate the superiority of our Open Semantic
Hypergraph Adapter (OS-HGAdapter), showcasing 16.8\% (text-to-image) and 40.1\%
(image-to-text) cross-modal retrieval gains over existing methods while
establishing new state-of-the-art performance in semantic alignment tasks.

</details>


### [77] [Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN](https://arxiv.org/abs/2510.13137)
*Madhumati Pol,Anvay Anturkar,Anushka Khot,Ayush Andure,Aniruddha Ghosh,Anvit Magadum,Anvay Bahadur*

Main category: cs.CV

TL;DR: 研究了3D CNN和LSTM在实时美国手语(ASL)识别中的性能。


<details>
  <summary>Details</summary>
Motivation: 3D CNN擅长从视频序列中提取时空特征，而LSTM针对顺序数据中的时间依赖性建模进行了优化。

Method: 在包含50个类别1200个ASL符号的数据集上评估了两种架构，比较了它们的准确性、计算效率和延迟。

Result: 3D CNN的识别准确率达到92.4%，但与LSTM相比，每帧需要多3.2%的处理时间，LSTM保持86.7%的准确率，资源消耗明显更低。

Conclusion: 混合3D CNNLSTM模型显示出不错的性能，这表明上下文相关的架构选择对于实际实现至关重要。

Abstract: This study investigates the performance of 3D Convolutional Neural Networks
(3D CNNs) and Long Short-Term Memory (LSTM) networks for real-time American
Sign Language (ASL) recognition. Though 3D CNNs are good at spatiotemporal
feature extraction from video sequences, LSTMs are optimized for modeling
temporal dependencies in sequential data. We evaluate both architectures on a
dataset containing 1,200 ASL signs across 50 classes, comparing their accuracy,
computational efficiency, and latency under similar training conditions.
Experimental results demonstrate that 3D CNNs achieve 92.4% recognition
accuracy but require 3.2% more processing time per frame compared to LSTMs,
which maintain 86.7% accuracy with significantly lower resource consumption.
The hybrid 3D CNNLSTM model shows decent performance, which suggests that
context-dependent architecture selection is crucial for practical
implementation.This project provides professional benchmarks for developing
assistive technologies, highlighting trade-offs between recognition precision
and real-time operational requirements in edge computing environments.

</details>


### [78] [Foveation Improves Payload Capacity in Steganography](https://arxiv.org/abs/2510.13151)
*Lifeng Qiu Lin,Henry Kam,Qi Sun,Kaan Akşit*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的隐写术方法，该方法在提高容量的同时，实现了更好的准确性和可比的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 隐写术在视觉媒体中有应用，例如提供元数据和水印。

Method: 利用高效的潜在表示和中心凹渲染训练模型。

Result: 容量限制从 100 位提高到 500 位，在 20 万个测试位中，实现了高达 2000 个位中 1 个失败位的更好准确率。PSNR 为 31.47 dB，LPIPS 为 0.13，实现了可比的视觉质量。

Conclusion: 该论文表明了在隐写术中创建多模式潜在表示的新型感知设计的有效性。

Abstract: Steganography finds its use in visual medium such as providing metadata and
watermarking. With support of efficient latent representations and foveated
rendering, we trained models that improve existing capacity limits from 100 to
500 bits, while achieving better accuracy of up to 1 failure bit out of 2000,
at 200K test bits. Finally, we achieve a comparable visual quality of 31.47 dB
PSNR and 0.13 LPIPS, showing the effectiveness of novel perceptual design in
creating multi-modal latent representations in steganography.

</details>


### [79] [DP-TTA: Test-time Adaptation for Transient Electromagnetic Signal Denoising via Dictionary-driven Prior Regularization](https://arxiv.org/abs/2510.13160)
*Meng Yang,Kecheng Chen,Wei Luo,Xianjie Chen,Yong Jia,Mingyue Wang,Fanqiang Lin*

Main category: cs.CV

TL;DR: 提出了一种名为字典驱动的先验正则化测试时自适应(DP-TTA)方法，用于提高瞬态电磁(TEM)信号的去噪性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的去噪模型大多在模拟或单一真实场景数据上训练，忽略了不同地理区域噪声特征的显著差异，导致在新环境中性能下降。

Method: 利用TEM信号固有的物理特性(如指数衰减和平滑性)作为先验知识，指导测试时自适应策略，并设计了一个名为DTEMDNet的网络，该网络使用字典学习将这些固有特征编码为字典驱动的先验，并在测试阶段通过最小化自监督损失来动态适应新环境。

Result: 实验结果表明，该方法比现有的TEM去噪方法和TTA方法具有更好的性能。

Conclusion: 该方法能够有效提高TEM信号在不同地理区域的去噪性能。

Abstract: Transient Electromagnetic (TEM) method is widely used in various geophysical
applications, providing valuable insights into subsurface properties. However,
time-domain TEM signals are often submerged in various types of noise. While
recent deep learning-based denoising models have shown strong performance,
these models are mostly trained on simulated or single real-world scenario
data, overlooking the significant differences in noise characteristics from
different geographical regions. Intuitively, models trained in one environment
often struggle to perform well in new settings due to differences in geological
conditions, equipment, and external interference, leading to reduced denoising
performance. To this end, we propose the Dictionary-driven Prior Regularization
Test-time Adaptation (DP-TTA). Our key insight is that TEM signals possess
intrinsic physical characteristics, such as exponential decay and smoothness,
which remain consistent across different regions regardless of external
conditions. These intrinsic characteristics serve as ideal prior knowledge for
guiding the TTA strategy, which helps the pre-trained model dynamically adjust
parameters by utilizing self-supervised losses, improving denoising performance
in new scenarios. To implement this, we customized a network, named DTEMDNet.
Specifically, we first use dictionary learning to encode these intrinsic
characteristics as a dictionary-driven prior, which is integrated into the
model during training. At the testing stage, this prior guides the model to
adapt dynamically to new environments by minimizing self-supervised losses
derived from the dictionary-driven consistency and the signal one-order
variation. Extensive experimental results demonstrate that the proposed method
achieves much better performance than existing TEM denoising methods and TTA
methods.

</details>


### [80] [STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control](https://arxiv.org/abs/2510.13186)
*Zhen Li,Xibin Jin,Guoliang Li,Shuai Wang,Miaowen Wen,Huseyin Arslan,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.CV

TL;DR: 提出了一种新的边缘高斯溅射（EGS）框架，用于在边缘服务器上聚合来自分布式客户端的数据并训练全局GS模型，以最大限度地提高GS质量。


<details>
  <summary>Details</summary>
Motivation: 现有的边缘资源管理方法不适用于最大化GS质量，因为它们强调通信吞吐量或通用学习性能。

Method: 提出了一个面向GS的目标函数，区分不同客户端的异构视图贡献，并提出了一个sample-then-transmit EGS (STT-GS)策略，该策略首先从每个客户端采样一个图像子集作为pilot数据进行损失预测。此外，还开发了一个联合客户端选择和功率控制（JCSPC）框架，以在通信资源约束下最大化面向GS的函数。

Result: 实验表明，该方案在真实数据集上明显优于现有基准。

Conclusion: 该方法可以在视图贡献和通信成本之间实现出色的权衡。

Abstract: Edge Gaussian splatting (EGS), which aggregates data from distributed clients
and trains a global GS model at the edge server, is an emerging paradigm for
scene reconstruction. Unlike traditional edge resource management methods that
emphasize communication throughput or general-purpose learning performance, EGS
explicitly aims to maximize the GS qualities, rendering existing approaches
inapplicable. To address this problem, this paper formulates a novel
GS-oriented objective function that distinguishes the heterogeneous view
contributions of different clients. However, evaluating this function in turn
requires clients' images, leading to a causality dilemma. To this end, this
paper further proposes a sample-then-transmit EGS (or STT-GS for short)
strategy, which first samples a subset of images as pilot data from each client
for loss prediction. Based on the first-stage evaluation, communication
resources are then prioritized towards more valuable clients. To achieve
efficient sampling, a feature-domain clustering (FDC) scheme is proposed to
select the most representative data and pilot transmission time minimization
(PTTM) is adopted to reduce the pilot overhead.Subsequently, we develop a joint
client selection and power control (JCSPC) framework to maximize the
GS-oriented function under communication resource constraints. Despite the
nonconvexity of the problem, we propose a low-complexity efficient solution
based on the penalty alternating majorization minimization (PAMM) algorithm.
Experiments unveil that the proposed scheme significantly outperforms existing
benchmarks on real-world datasets. It is found that the GS-oriented objective
can be accurately predicted with low sampling ratios (e.g.,10%), and our method
achieves an excellent tradeoff between view contributions and communication
costs.

</details>


### [81] [Complementary Information Guided Occupancy Prediction via Multi-Level Representation Fusion](https://arxiv.org/abs/2510.13198)
*Rongtao Xu,Jinzhou Lin,Jialei Zhou,Jiahua Dong,Changwei Wang,Ruisheng Wang,Li Guo,Shibiao Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: CIGOcc：一个基于多层次表示融合的两阶段 occupancy 预测框架，通过提取分割、图形和深度特征，并引入可变形多层次融合机制来融合这些多层次特征，并结合 SAM 的知识蒸馏来提高预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要集中在通过结构修改来提高性能，而忽略了从表示融合的角度来利用 2D 图像中丰富的特征多样性。

Method: CIGOcc 框架，基于多层次表示融合，提取分割、图形和深度特征，并引入可变形多层次融合机制，结合 SAM 的知识蒸馏。

Result: 在 SemanticKITTI 基准测试中取得了 state-of-the-art 的性能，且没有增加训练成本。

Conclusion: CIGOcc 是一种有效的 occupancy 预测方法，它通过多层次表示融合和知识蒸馏，在 SemanticKITTI 基准测试中取得了优异的性能。

Abstract: Camera-based occupancy prediction is a mainstream approach for 3D perception
in autonomous driving, aiming to infer complete 3D scene geometry and semantics
from 2D images. Almost existing methods focus on improving performance through
structural modifications, such as lightweight backbones and complex cascaded
frameworks, with good yet limited performance. Few studies explore from the
perspective of representation fusion, leaving the rich diversity of features in
2D images underutilized. Motivated by this, we propose \textbf{CIGOcc, a
two-stage occupancy prediction framework based on multi-level representation
fusion. \textbf{CIGOcc extracts segmentation, graphics, and depth features from
an input image and introduces a deformable multi-level fusion mechanism to fuse
these three multi-level features. Additionally, CIGOcc incorporates knowledge
distilled from SAM to further enhance prediction accuracy. Without increasing
training costs, CIGOcc achieves state-of-the-art performance on the
SemanticKITTI benchmark. The code is provided in the supplementary material and
will be released https://github.com/VitaLemonTea1/CIGOcc

</details>


### [82] [Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences](https://arxiv.org/abs/2510.13201)
*Jing Yang,Qiyao Wei,Jiaxin Pei*

Main category: cs.CV

TL;DR: 论文介绍了Paper Copilot，一个用于创建同行评审的持久数字档案的系统，以及一个用于大规模研究同行评审的开放数据集。


<details>
  <summary>Details</summary>
Motivation: AI会议的快速增长给脆弱的同行评审系统带来压力，导致评审员工作量过重、专业知识不匹配、评估标准不一致等问题。

Method: 创建Paper Copilot系统，收集计算机科学场所的同行评审数据，并对ICLR的多年评审进行大规模实证分析。

Result: 发布Paper Copilot的基础设施和数据集，支持对同行评审演变的重复性研究。

Conclusion: 希望这些资源能够帮助社区跟踪变化、诊断失败模式，并为改进同行评审系统提供循证依据。

Abstract: The rapid growth of AI conferences is straining an already fragile
peer-review system, leading to heavy reviewer workloads, expertise mismatches,
inconsistent evaluation standards, superficial or templated reviews, and
limited accountability under compressed timelines. In response, conference
organizers have introduced new policies and interventions to preserve review
standards. Yet these ad-hoc changes often create further concerns and confusion
about the review process, leaving how papers are ultimately accepted - and how
practices evolve across years - largely opaque. We present Paper Copilot, a
system that creates durable digital archives of peer reviews across a wide
range of computer-science venues, an open dataset that enables researchers to
study peer review at scale, and a large-scale empirical analysis of ICLR
reviews spanning multiple years. By releasing both the infrastructure and the
dataset, Paper Copilot supports reproducible research on the evolution of peer
review. We hope these resources help the community track changes, diagnose
failure modes, and inform evidence-based improvements toward a more robust,
transparent, and reliable peer-review system.

</details>


### [83] [MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation](https://arxiv.org/abs/2510.13208)
*Lianlian Liu,YongKang He,Zhaojie Chu,Xiaofen Xing,Xiangmin Xu*

Main category: cs.CV

TL;DR: 提出MimicParts，一个新颖的框架，旨在通过部分感知风格注入和部分感知去噪网络来增强风格化运动生成。


<details>
  <summary>Details</summary>
Motivation: 从语音信号生成风格化3D人体运动存在巨大的挑战，主要是由于语音信号、个体风格和相应的身体运动之间复杂而精细的关系。目前的风格编码方法要么过度简化风格多样性，要么忽略区域运动风格差异（例如，上半身与下半身），限制了运动的真实感。此外，运动风格应动态适应语音节奏和情感的变化，但现有方法通常忽略了这一点。

Method: 将身体划分为不同的区域以编码局部运动风格，使模型能够捕获细粒度的区域差异。此外，我们的部分感知注意力块允许节奏和情感线索精确地引导每个身体区域，确保生成的运动与语音节奏和情感状态的变化相一致。

Result: 实验结果表明，我们的方法优于现有方法，展示了自然和富有表现力的3D人体运动序列。

Conclusion: 为了解决这些问题，我们提出了MimicParts。

Abstract: Generating stylized 3D human motion from speech signals presents substantial
challenges, primarily due to the intricate and fine-grained relationships among
speech signals, individual styles, and the corresponding body movements.
Current style encoding approaches either oversimplify stylistic diversity or
ignore regional motion style differences (e.g., upper vs. lower body), limiting
motion realism. Additionally, motion style should dynamically adapt to changes
in speech rhythm and emotion, but existing methods often overlook this. To
address these issues, we propose MimicParts, a novel framework designed to
enhance stylized motion generation based on part-aware style injection and
part-aware denoising network. It divides the body into different regions to
encode localized motion styles, enabling the model to capture fine-grained
regional differences. Furthermore, our part-aware attention block allows rhythm
and emotion cues to guide each body region precisely, ensuring that the
generated motion aligns with variations in speech rhythm and emotional state.
Experimental results show that our method outperforming existing methods
showcasing naturalness and expressive 3D human motion sequences.

</details>


### [84] [Prompt-based Adaptation in Large-scale Vision Models: A Survey](https://arxiv.org/abs/2510.13219)
*Xi Xiao,Yunbei Zhang,Lin Zhao,Yiyang Liu,Xiaoying Liao,Zheda Mai,Xingjian Li,Xiao Wang,Hao Xu,Jihun Hamm,Xue Lin,Min Xu,Qifan Wang,Tianyang Wang,Cheng Han*

Main category: cs.CV

TL;DR: 本文对视觉提示 (VP) 和视觉提示调整 (VPT) 进行了综述，将它们统一在提示调整 (PA) 框架下。


<details>
  <summary>Details</summary>
Motivation: 当前研究中，VP 和 VPT 的概念边界模糊，缺乏系统性的区分。

Method: 本文从第一性原理重新审视 VP 和 VPT 的设计，并在统一的框架下对它们进行概念化。提出了一个分类法，将现有方法分为可学习、生成和非学习提示，并按注入粒度（像素级和令牌级）进行组织。

Result: 本文总结了当前基准，并确定了关键挑战和未来方向。

Conclusion: 本文旨在为研究人员和从业人员提供一个清晰的路线图，以理解和探索 PA 相关研究的发展前景。

Abstract: In computer vision, Visual Prompting (VP) and Visual Prompt Tuning (VPT) have
recently emerged as lightweight and effective alternatives to full fine-tuning
for adapting large-scale vision models within the ``pretrain-then-finetune''
paradigm. However, despite rapid progress, their conceptual boundaries remain
blurred, as VP and VPT are frequently used interchangeably in current research,
reflecting a lack of systematic distinction between these techniques and their
respective applications. In this survey, we revisit the designs of VP and VPT
from first principles, and conceptualize them within a unified framework termed
Prompt-based Adaptation (PA). We provide a taxonomy that categorizes existing
methods into learnable, generative, and non-learnable prompts, and further
organizes them by injection granularity -- pixel-level and token-level. Beyond
the core methodologies, we examine PA's integrations across diverse domains,
including medical imaging, 3D point clouds, and vision-language tasks, as well
as its role in test-time adaptation and trustworthy AI. We also summarize
current benchmarks and identify key challenges and future directions. To the
best of our knowledge, we are the first comprehensive survey dedicated to PA's
methodologies and applications in light of their distinct characteristics. Our
survey aims to provide a clear roadmap for researchers and practitioners in all
area to understand and explore the evolving landscape of PA-related research.

</details>


### [85] [Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects](https://arxiv.org/abs/2510.13226)
*Hang-Cheng Dong,Yibo Jiao,Fupeng Wei,Guodong Liu,Dong Ye,Bingguo Liu*

Main category: cs.CV

TL;DR: 本文提出了一种用于工业表面缺陷检测的样本中心多任务学习框架，以解决前景-背景不平衡、缺陷稀疏和小缺陷对比度低等问题，提高了样本层面决策的可靠性和缺陷定位的完整性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在像素重叠指标上表现良好，但在样本层面稳定性不足，尤其是在稀疏或细长缺陷方面。根本原因是优化目标与质量控制决策的粒度不匹配。

Method: 该方法构建在共享编码器架构上，联合学习样本级缺陷分类和像素级掩码定位。样本级监督调节特征分布，并在梯度水平上不断提高对小缺陷和低对比度缺陷的召回率，而分割分支保留边界和形状细节，以增强每个样本的决策稳定性并减少遗漏。

Result: 在两个基准数据集上的实验表明，该方法大大提高了样本层面决策的可靠性和缺陷定位的完整性。

Conclusion: 本文提出的样本中心多任务学习框架和评估套件，可以有效解决工业表面缺陷检测中的挑战，提高样本层面决策的可靠性和缺陷定位的完整性。

Abstract: Industrial surface defect inspection for sample-wise quality control (QC)
must simultaneously decide whether a given sample contains defects and localize
those defects spatially. In real production lines, extreme
foreground-background imbalance, defect sparsity with a long-tailed scale
distribution, and low contrast are common. As a result, pixel-centric training
and evaluation are easily dominated by large homogeneous regions, making it
difficult to drive models to attend to small or low-contrast defects-one of the
main bottlenecks for deployment. Empirically, existing models achieve strong
pixel-overlap metrics (e.g., mIoU) but exhibit insufficient stability at the
sample level, especially for sparse or slender defects. The root cause is a
mismatch between the optimization objective and the granularity of QC
decisions. To address this, we propose a sample-centric multi-task learning
framework and evaluation suite. Built on a shared-encoder architecture, the
method jointly learns sample-level defect classification and pixel-level mask
localization. Sample-level supervision modulates the feature distribution and,
at the gradient level, continually boosts recall for small and low-contrast
defects, while the segmentation branch preserves boundary and shape details to
enhance per-sample decision stability and reduce misses. For evaluation, we
propose decision-linked metrics, Seg_mIoU and Seg_Recall, which remove the bias
of classical mIoU caused by empty or true-negative samples and tightly couple
localization quality with sample-level decisions. Experiments on two benchmark
datasets demonstrate that our approach substantially improves the reliability
of sample-level decisions and the completeness of defect localization.

</details>


### [86] [What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](https://arxiv.org/abs/2510.13232)
*Inha Kang,Youngsun Lim,Seonho Lee,Jiho Choi,Junsuk Choe,Hyunjung Shim*

Main category: cs.CV

TL;DR: 本文介绍了一种解决视觉语言模型在理解否定方面的缺陷的方法，特别是在描述对象检测（DOD）任务中。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在理解否定方面存在严重不足，尤其是在描述对象检测（DOD）任务中，这是一个关键的失败。

Method: 1.  提出了一个新的数据集构建流程CoVAND，该流程使用系统性的思维链（CoT）和基于VQA的方法来生成高质量的、实例级别的否定数据。2.  提出了NegToMe，一个新的文本token合并模块，该模块直接解决了肯定偏见的结构性原因。NegToMe将否定线索与属性组合成连贯的语义短语，从而在输入层面保持正确的极性。

Result: 该方法显著提高了在具有挑战性的否定基准测试中的性能，降低了假阳性率，并在OVDEval上将NMS-AP提高了高达+10.8个点，并证明了对SoTA VLM的泛化能力。

Conclusion: 这项工作标志着在解决现实世界检测应用中的否定理解方面迈出了关键一步。

Abstract: State-of-the-art vision-language models (VLMs) suffer from a critical failure
in understanding negation, often referred to as affirmative bias. This
limitation is particularly severe in described object detection (DOD) tasks. To
address this, we propose two primary contributions: (1) a new dataset pipeline
and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a
dataset constructed with a systematic chain-of-thought (CoT) and VQA-based
pipeline to generate high-quality, instance-grounded negation data. Second, we
propose NegToMe, a novel text token merging module that directly tackles the
architectural cause of affirmative bias. NegToMe fundamentally addresses the
structural loss of negation cues in tokenization, grouping them with attributes
into coherent semantic phrases. It maintains correct polarity at the input
level, enabling robust negation understanding even with limited data. For
instance, to prevent a model from treating the fragmented tokens "not" and
"girl" as simply "girl", NegToMe binds them into a single token whose meaning
is correctly distinguished from that of "girl" alone. This module is integrated
with a parameter-efficient and strategic LoRA fine-tuning approach. Our method
significantly improves performance on challenging negation benchmarks with a
lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval
and demonstrating generalization to SoTA VLMs. This work marks a crucial step
forward in addressing negation understanding for real-world detection
applications.

</details>


### [87] [UniVector: Unified Vector Extraction via Instance-Geometry Interaction](https://arxiv.org/abs/2510.13234)
*Yinglong Yan,Jun Yue,Shaobo Xia,Hanmeng Sun,Tianxu Ying,Chengcheng Wu,Sifan Lan,Min He,Pedram Ghamisi,Leyuan Fang*

Main category: cs.CV

TL;DR: 提出了一种名为 UniVector 的统一矢量提取框架，它能够从栅格图像中提取多种矢量类型（多边形、折线、线段），并在单结构和多结构矢量提取任务上都达到了新的state-of-the-art。


<details>
  <summary>Details</summary>
Motivation: 现有的矢量提取方法通常只针对单一矢量类型，并且独立处理实例属性和几何属性，这限制了其捕获复杂结构的能力。UniVector 的动机在于模仿人脑同时使用语义和空间交互进行视觉感知的方式，从而能够在一个模型中提取多种矢量类型。

Method: UniVector 将矢量编码为包含实例和几何级别信息的结构化查询，并通过交互模块迭代更新这些查询以进行跨级别上下文交换。此外，动态形状约束进一步细化了全局结构和关键点。

Result: UniVector 在单结构和多结构矢量提取任务上都达到了新的 state-of-the-art。

Conclusion: UniVector 是一种有效的统一矢量提取框架，它能够处理多种矢量类型，并在多个任务上表现出色。

Abstract: Vector extraction retrieves structured vector geometry from raster images,
offering high-fidelity representation and broad applicability. Existing
methods, however, are usually tailored to a single vector type (e.g., polygons,
polylines, line segments), requiring separate models for different structures.
This stems from treating instance attributes (category, structure) and
geometric attributes (point coordinates, connections) independently, limiting
the ability to capture complex structures. Inspired by the human brain's
simultaneous use of semantic and spatial interactions in visual perception, we
propose UniVector, a unified VE framework that leverages instance-geometry
interaction to extract multiple vector types within a single model. UniVector
encodes vectors as structured queries containing both instance- and
geometry-level information, and iteratively updates them through an interaction
module for cross-level context exchange. A dynamic shape constraint further
refines global structures and key points. To benchmark multi-structure
scenarios, we introduce the Multi-Vector dataset with diverse polygons,
polylines, and line segments. Experiments show UniVector sets a new state of
the art on both single- and multi-structure VE tasks. Code and dataset will be
released at https://github.com/yyyyll0ss/UniVector.

</details>


### [88] [EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking](https://arxiv.org/abs/2510.13235)
*Yukuan Zhang,Jiarui Zhao,Shangqing Nie,Jin Kuang,Shengsheng Wang*

Main category: cs.CV

TL;DR: EPIPTrack: A unified multimodal vision-language tracking framework using explicit and implicit prompts for dynamic target modeling and semantic alignment.


<details>
  <summary>Details</summary>
Motivation: Existing methods rely on static textual descriptions from large language models, which lack adaptability to real-time target state changes and are prone to hallucinations.

Method: Explicit prompts transform spatial motion information into natural language; implicit prompts combine pseudo-words with learnable descriptors; dynamic adjustment via CLIP text encoder; Discriminative Feature Augmentor to enhance representations.

Result: Outperforms existing trackers on MOT17, MOT20, and DanceTrack.

Conclusion: EPIPTrack exhibits robust adaptability and superior performance in diverse scenarios.

Abstract: Multimodal semantic cues, such as textual descriptions, have shown strong
potential in enhancing target perception for tracking. However, existing
methods rely on static textual descriptions from large language models, which
lack adaptability to real-time target state changes and prone to
hallucinations. To address these challenges, we propose a unified multimodal
vision-language tracking framework, named EPIPTrack, which leverages explicit
and implicit prompts for dynamic target modeling and semantic alignment.
Specifically, explicit prompts transform spatial motion information into
natural language descriptions to provide spatiotemporal guidance. Implicit
prompts combine pseudo-words with learnable descriptors to construct
individualized knowledge representations capturing appearance attributes. Both
prompts undergo dynamic adjustment via the CLIP text encoder to respond to
changes in target state. Furthermore, we design a Discriminative Feature
Augmentor to enhance visual and cross-modal representations. Extensive
experiments on MOT17, MOT20, and DanceTrack demonstrate that EPIPTrack
outperforms existing trackers in diverse scenarios, exhibiting robust
adaptability and superior performance.

</details>


### [89] [Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models](https://arxiv.org/abs/2510.13237)
*Haochuan Xu,Yun Sing Koh,Shuhuai Huang,Zirun Zhou,Di Wang,Jun Sakuma,Jingfeng Zhang*

Main category: cs.CV

TL;DR: 本文研究了视觉-语言-动作(VLA)模型在机器人学习中的对抗鲁棒性问题，提出了嵌入扰动补丁攻击(EDPA)方法，并通过对抗微调进行防御。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人学习中取得了进展，但其对抗鲁棒性有待研究。

Method: 提出了嵌入扰动补丁攻击(EDPA)，通过扰乱视觉和文本潜在表示之间的语义对齐，并最大化对抗和干净视觉输入之间的潜在表示差异来生成补丁。同时，提出了针对视觉编码器的对抗微调方案，以提高模型对对抗扰动的鲁棒性。

Result: 在LIBERO机器人仿真基准上的实验表明，EDPA显著提高了VLA模型的任务失败率，而提出的防御方法有效地缓解了这种退化。

Conclusion: 本文提出的EDPA攻击能够有效攻击VLA模型，而对抗微调防御能够有效缓解攻击。

Abstract: Vision-Language-Action (VLA) models have achieved revolutionary progress in
robot learning, enabling robots to execute complex physical robot tasks from
natural language instructions. Despite this progress, their adversarial
robustness remains underexplored. In this work, we propose both adversarial
patch attack and corresponding defense strategies for VLA models. We first
introduce the Embedding Disruption Patch Attack (EDPA), a model-agnostic
adversarial attack that generates patches directly placeable within the
camera's view. In comparison to prior methods, EDPA can be readily applied to
different VLA models without requiring prior knowledge of the model
architecture, or the controlled robotic manipulator. EDPA constructs these
patches by (i) disrupting the semantic alignment between visual and textual
latent representations, and (ii) maximizing the discrepancy of latent
representations between adversarial and corresponding clean visual inputs.
Through the optimization of these objectives, EDPA distorts the VLA's
interpretation of visual information, causing the model to repeatedly generate
incorrect actions and ultimately result in failure to complete the given
robotic task. To counter this, we propose an adversarial fine-tuning scheme for
the visual encoder, in which the encoder is optimized to produce similar latent
representations for both clean and adversarially perturbed visual inputs.
Extensive evaluations on the widely recognized LIBERO robotic simulation
benchmark demonstrate that EDPA substantially increases the task failure rate
of cutting-edge VLA models, while our proposed defense effectively mitigates
this degradation. The codebase is accessible via the homepage at
https://edpa-attack.github.io/.

</details>


### [90] [FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding](https://arxiv.org/abs/2510.13243)
*Francesco Barbato,Matteo Caligiuri,Pietro Zanuttigh*

Main category: cs.CV

TL;DR: FlyAwareV2是一个用于城市环境理解的多模态无人机数据集，包含真实和合成图像。


<details>
  <summary>Details</summary>
Motivation: 真实无人机数据的收集和标注成本高昂。

Method: 构建包含RGB、深度和语义标签的多模态数据集，并使用单目深度估计计算真实样本的深度图。

Result: 提供了RGB和多模态语义分割的标准架构的基准，并研究了synthetic-to-real的领域适应性。

Conclusion: FlyAwareV2为基于无人机的3D城市场景理解研究提供了有价值的资源。

Abstract: The development of computer vision algorithms for Unmanned Aerial Vehicle
(UAV) applications in urban environments heavily relies on the availability of
large-scale datasets with accurate annotations. However, collecting and
annotating real-world UAV data is extremely challenging and costly. To address
this limitation, we present FlyAwareV2, a novel multimodal dataset encompassing
both real and synthetic UAV imagery tailored for urban scene understanding
tasks. Building upon the recently introduced SynDrone and FlyAware datasets,
FlyAwareV2 introduces several new key contributions: 1) Multimodal data (RGB,
depth, semantic labels) across diverse environmental conditions including
varying weather and daytime; 2) Depth maps for real samples computed via
state-of-the-art monocular depth estimation; 3) Benchmarks for RGB and
multimodal semantic segmentation on standard architectures; 4) Studies on
synthetic-to-real domain adaptation to assess the generalization capabilities
of models trained on the synthetic data. With its rich set of annotations and
environmental diversity, FlyAwareV2 provides a valuable resource for research
on UAV-based 3D urban scene understanding.

</details>


### [91] [CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation](https://arxiv.org/abs/2510.13245)
*Li Liang,Bo Miao,Xinyu Wang,Naveed Akhtar,Jordan Vice,Ajmal Mian*

Main category: cs.CV

TL;DR: 提出了SketchSem3D，一个用于从草图生成3D户外语义场景的大规模基准数据集，并提出了Cylinder Mamba Diffusion (CymbaDiff) 模型。


<details>
  <summary>Details</summary>
Motivation: 缺乏公开可用的、良好注释的数据集限制了户外3D语义场景生成的发展。

Method: 提出了Cylinder Mamba Diffusion (CymbaDiff) 模型，该模型通过引入结构化的空间排序，显式地捕获圆柱连续性和垂直层级结构，从而增强了户外3D场景生成的空间连贯性。

Result: CymbaDiff 在 SketchSem3D 数据集上实现了卓越的语义一致性、空间真实性和跨数据集泛化能力。

Conclusion: CymbaDiff 模型在户外3D语义场景生成方面表现出色，并且提出的 SketchSem3D 数据集为该领域的研究提供了有价值的资源。

Abstract: Outdoor 3D semantic scene generation produces realistic and semantically rich
environments for applications such as urban simulation and autonomous driving.
However, advances in this direction are constrained by the absence of publicly
available, well-annotated datasets. We introduce SketchSem3D, the first
large-scale benchmark for generating 3D outdoor semantic scenes from abstract
freehand sketches and pseudo-labeled annotations of satellite images.
SketchSem3D includes two subsets, Sketch-based SemanticKITTI and Sketch-based
KITTI-360 (containing LiDAR voxels along with their corresponding sketches and
annotated satellite images), to enable standardized, rigorous, and diverse
evaluations. We also propose Cylinder Mamba Diffusion (CymbaDiff) that
significantly enhances spatial coherence in outdoor 3D scene generation.
CymbaDiff imposes structured spatial ordering, explicitly captures cylindrical
continuity and vertical hierarchy, and preserves both physical neighborhood
relationships and global context within the generated scenes. Extensive
experiments on SketchSem3D demonstrate that CymbaDiff achieves superior
semantic consistency, spatial realism, and cross-dataset generalization. The
code and dataset will be available at
https://github.com/Lillian-research-hub/CymbaDiff

</details>


### [92] [Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture](https://arxiv.org/abs/2510.13250)
*Zhiyuan Zhao,Yubin Wen,Siyu Yang,Lichen Ning,Yuandong Liu,Junyu Gao*

Main category: cs.CV

TL;DR: 本文提出了一种超实时人群计数模型，适用于嵌入式系统。


<details>
  <summary>Details</summary>
Motivation: 现有的人群计数方法在嵌入式系统上的实际应用中存在模型参数过多、计算复杂等问题，无法满足实时性要求。

Method: 该模型采用stem-encoder-decoder结构，利用大卷积核提取头部信息，并使用条件通道加权和多分支局部融合块融合多尺度特征，最后添加特征金字塔网络。

Result: 该网络在三个基准测试中表现出具有竞争力的准确率，并在NVIDIA GTX 1080Ti上达到381.7 FPS，在NVIDIA Jetson TX1上达到71.9 FPS。

Conclusion: 该网络适用于嵌入式系统上的超实时人群计数。

Abstract: Crowd counting is a task of estimating the number of the crowd through
images, which is extremely valuable in the fields of intelligent security,
urban planning, public safety management, and so on. However, the existing
counting methods have some problems in practical application on embedded
systems for these fields, such as excessive model parameters, abundant complex
calculations, etc. The practical application of embedded systems requires the
model to be real-time, which means that the model is fast enough. Considering
the aforementioned problems, we design a super real-time model with a
stem-encoder-decoder structure for crowd counting tasks, which achieves the
fastest inference compared with state-of-the-arts. Firstly, large convolution
kernels in the stem network are used to enlarge the receptive field, which
effectively extracts detailed head information. Then, in the encoder part, we
use conditional channel weighting and multi-branch local fusion block to merge
multi-scale features with low computational consumption. This part is crucial
to the super real-time performance of the model. Finally, the feature pyramid
networks are added to the top of the encoder to alleviate its incomplete fusion
problems. Experiments on three benchmarks show that our network is suitable for
super real-time crowd counting on embedded systems, ensuring competitive
accuracy. At the same time, the proposed network reasoning speed is the
fastest. Specifically, the proposed network achieves 381.7 FPS on NVIDIA GTX
1080Ti and 71.9 FPS on NVIDIA Jetson TX1.

</details>


### [93] [Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs](https://arxiv.org/abs/2510.13251)
*Minji Kim,Taekyung Kim,Bohyung Han*

Main category: cs.CV

TL;DR: 本文研究了VideoLLM的内部信息流，发现其时间推理始于早期到中期层的跨帧交互，然后是中期层的视频-语言集成，最后模型准备好在中期到后期层生成正确的答案。


<details>
  <summary>Details</summary>
Motivation: 尽管VideoLLM最近取得了进展，但它们在何处以及如何提取和传播视频和文本信息的内部机制仍有待探索。

Method: 使用机械可解释性技术研究VideoLLM的内部信息流。

Result: 揭示了跨不同VideoQA任务的一致模式：(1) VideoLLM中的时间推理始于早期到中期层的活跃跨帧交互，(2) 随后是中期层的渐进式视频-语言集成。这是通过视频表示和包含时间概念的语言嵌入之间的对齐来实现的。(3) 完成此集成后，模型就可以在中期到后期层生成正确的答案。(4) 基于我们的分析，我们表明VideoLLM可以通过选择这些有效的信息路径，同时抑制大量的注意力边缘来保持其VideoQA性能，例如，在LLaVA-NeXT-7B-Video-FT中抑制58%的注意力边缘。

Conclusion: 这些发现为VideoLLM如何执行时间推理提供了蓝图，并为提高模型的可解释性和下游泛化提供了实践见解。

Abstract: Video Large Language Models (VideoLLMs) extend the capabilities of
vision-language models to spatiotemporal inputs, enabling tasks such as video
question answering (VideoQA). Despite recent advances in VideoLLMs, their
internal mechanisms on where and how they extract and propagate video and
textual information remain less explored. In this study, we investigate the
internal information flow of VideoLLMs using mechanistic interpretability
techniques. Our analysis reveals consistent patterns across diverse VideoQA
tasks: (1) temporal reasoning in VideoLLMs initiates with active cross-frame
interactions in early-to-middle layers, (2) followed by progressive
video-language integration in middle layers. This is facilitated by alignment
between video representations and linguistic embeddings containing temporal
concepts. (3) Upon completion of this integration, the model is ready to
generate correct answers in middle-to-late layers. (4) Based on our analysis,
we show that VideoLLMs can retain their VideoQA performance by selecting these
effective information pathways while suppressing a substantial amount of
attention edges, e.g., 58% in LLaVA-NeXT-7B-Video-FT. These findings provide a
blueprint on how VideoLLMs perform temporal reasoning and offer practical
insights for improving model interpretability and downstream generalization.
Our project page with the source code is available at
https://map-the-flow.github.io

</details>


### [94] [End-to-End Multi-Modal Diffusion Mamba](https://arxiv.org/abs/2510.13253)
*Chunhao Lu,Qiang Lu,Meichen Dong,Jake Luo*

Main category: cs.CV

TL;DR: 提出了一个名为MDM的新型多模态架构，该架构使用基于Mamba的多步选择扩散模型来统一多模态处理。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端多模态模型使用不同的编码器和解码器来处理输入和输出信息，阻碍了各种模态的联合表示学习。

Method: MDM利用基于Mamba的多步选择扩散模型，通过统一的变分自动编码器逐步生成和细化模态特定信息，用于编码和解码。

Result: MDM 在处理高维数据方面表现出色，尤其是在同时生成高分辨率图像和扩展文本序列方面。在图像生成、图像字幕、视觉问答、文本理解和推理任务等领域的评估表明，MDM 显着优于现有的端到端模型，并且可以与 GPT-4V、Gemini Pro 和 Mistral 等 SOTA 模型有效竞争。

Conclusion: MDM 在统一多模态流程同时保持计算效率方面的有效性，为端到端多模态架构建立了一个新方向。

Abstract: Current end-to-end multi-modal models utilize different encoders and decoders
to process input and output information. This separation hinders the joint
representation learning of various modalities. To unify multi-modal processing,
we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM
utilizes a Mamba-based multi-step selection diffusion model to progressively
generate and refine modality-specific information through a unified variational
autoencoder for both encoding and decoding. This innovative approach allows MDM
to achieve superior performance when processing high-dimensional data,
particularly in generating high-resolution images and extended text sequences
simultaneously. Our evaluations in areas such as image generation, image
captioning, visual question answering, text comprehension, and reasoning tasks
demonstrate that MDM significantly outperforms existing end-to-end models
(MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA
models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's
effectiveness in unifying multi-modal processes while maintaining computational
efficiency, establishing a new direction for end-to-end multi-modal
architectures.

</details>


### [95] [MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models](https://arxiv.org/abs/2510.13276)
*Keyan Zhou,Zecheng Tang,Lingfeng Ming,Guanghao Zhou,Qiguang Chen,Dan Qiao,Zheming Yang,Libo Qin,Minghui Qiu,Juntao Li,Min Zhang*

Main category: cs.CV

TL;DR: 大型视觉语言模型(LVLMs)的上下文窗口迅速扩展，但扩展的上下文窗口并不保证上下文的有效利用。


<details>
  <summary>Details</summary>
Motivation: 现有的长上下文忠实度评估主要集中在纯文本领域，而多模态评估仍然局限于短上下文。为了弥合这一差距，我们引入了MMLongCite，这是一个综合基准，旨在评估LVLMs在长上下文场景中的保真度。

Method: MMLongCite包含8个不同的任务，跨越6个上下文长度间隔，并包含不同的模态，包括文本、图像和视频。

Result: 对最先进的lvlm的评估表明，它们在处理长多模态上下文方面的忠实度有限。

Conclusion: 我们深入分析了上下文长度和关键内容的位置如何影响这些模型的忠实度。

Abstract: The rapid advancement of large vision language models (LVLMs) has led to a
significant expansion of their context windows. However, an extended context
window does not guarantee the effective utilization of the context, posing a
critical challenge for real-world applications. Current evaluations of such
long-context faithfulness are predominantly focused on the text-only domain,
while multimodal assessments remain limited to short contexts. To bridge this
gap, we introduce MMLongCite, a comprehensive benchmark designed to evaluate
the fidelity of LVLMs in long-context scenarios. MMLongCite comprises 8
distinct tasks spanning 6 context length intervals and incorporates diverse
modalities, including text, images, and videos. Our evaluation of
state-of-the-art LVLMs reveals their limited faithfulness in handling long
multimodal contexts. Furthermore, we provide an in-depth analysis of how
context length and the position of crucial content affect the faithfulness of
these models.

</details>


### [96] [Universal Image Restoration Pre-training via Masked Degradation Classification](https://arxiv.org/abs/2510.13282)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Yinghao Chen,Yanye Lu*

Main category: cs.CV

TL;DR: 提出了一种MaskDCPT预训练方法，用于图像退化类型分类，从而实现全面的图像恢复预训练。


<details>
  <summary>Details</summary>
Motivation: 传统的预训练方法在图像恢复任务中的泛化能力有限，尤其是在处理未见过的退化类型和程度时。

Method: 该方法包括一个编码器和两个解码器：编码器从掩码的低质量输入图像中提取特征。分类解码器使用这些特征来识别退化类型，而重建解码器旨在重建相应的高质量图像。

Result: MaskDCPT显著提高了CNN和Transformer的性能，在5D一体化恢复任务中，PSNR至少提高了3.77 dB，与真实场景中的基线相比，PIQE降低了34.8%。

Conclusion: MaskDCPT 能够有效地提高图像恢复任务的性能，并且具有很强的泛化能力，可以处理以前未见过的退化类型和程度。

Abstract: This study introduces a Masked Degradation Classification Pre-Training method
(MaskDCPT), designed to facilitate the classification of degradation types in
input images, leading to comprehensive image restoration pre-training. Unlike
conventional pre-training methods, MaskDCPT uses the degradation type of the
image as an extremely weak supervision, while simultaneously leveraging the
image reconstruction to enhance performance and robustness. MaskDCPT includes
an encoder and two decoders: the encoder extracts features from the masked
low-quality input image. The classification decoder uses these features to
identify the degradation type, whereas the reconstruction decoder aims to
reconstruct a corresponding high-quality image. This design allows the
pre-training to benefit from both masked image modeling and contrastive
learning, resulting in a generalized representation suited for restoration
tasks. Benefit from the straightforward yet potent MaskDCPT, the pre-trained
encoder can be used to address universal image restoration and achieve
outstanding performance. Implementing MaskDCPT significantly improves
performance for both convolution neural networks (CNNs) and Transformers, with
a minimum increase in PSNR of 3.77 dB in the 5D all-in-one restoration task and
a 34.8% reduction in PIQE compared to baseline in real-world degradation
scenarios. It also emergences strong generalization to previously unseen
degradation types and levels. In addition, we curate and release the UIR-2.5M
dataset, which includes 2.5 million paired restoration samples across 19
degradation types and over 200 degradation levels, incorporating both synthetic
and real-world data. The dataset, source code, and models are available at
https://github.com/MILab-PKU/MaskDCPT.

</details>


### [97] [Automated document processing system for government agencies using DBNET++ and BART models](https://arxiv.org/abs/2510.13303)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 本文介绍了一种自动文档分类系统，该系统可以检测图像中的文本内容，并将文档分为四个预定义类别（发票、报告、信件和表格）。


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中光照变化、任意方向、弯曲或部分遮挡文本、低分辨率和远距离文本等挑战。

Method: 使用DBNet++检测器进行文本检测，使用BART分类器进行文本分类，所有这些都集成在Python和PyQt5实现的用户界面中。

Result: 在Total-Text数据集上进行了10小时的测试，文本检测的准确率达到了92.88%。

Conclusion: 该方法对于非约束成像场景中的实际混合源文档分类是有效的。

Abstract: An automatic document classification system is presented that detects textual
content in images and classifies documents into four predefined categories
(Invoice, Report, Letter, and Form). The system supports both offline images
(e.g., files on flash drives, HDDs, microSD) and real-time capture via
connected cameras, and is designed to mitigate practical challenges such as
variable illumination, arbitrary orientation, curved or partially occluded
text, low resolution, and distant text. The pipeline comprises four stages:
image capture and preprocessing, text detection [1] using a DBNet++
(Differentiable Binarization Network Plus) detector, and text classification
[2] using a BART (Bidirectional and Auto-Regressive Transformers) classifier,
all integrated within a user interface implemented in Python with PyQt5. The
achieved results by the system for text detection in images were good at about
92.88% through 10 hours on Total-Text dataset that involve high resolution
images simulate a various and very difficult challenges. The results indicate
the proposed approach is effective for practical, mixed-source document
categorization in unconstrained imaging scenarios.

</details>


### [98] [Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning](https://arxiv.org/abs/2510.13307)
*Yang Li,Aming Wu,Zihao Zhang,Yahong Han*

Main category: cs.CV

TL;DR: 本文研究了点云分割的新类发现 (3D-NCD) 问题，旨在仅使用带标签的（基础）3D 类的监督来学习分割未标记的（新）3D 类的模型。


<details>
  <summary>Details</summary>
Motivation: 该任务的关键是建立点表示及其基础类标签之间的精确相关性，以及来自基础类和新类的点之间的表示相关性。粗略或统计相关性学习可能导致新类推理的混淆。如果我们施加因果关系作为学习过程中的强相关约束，那么准确对应于类别的基本点云表示应该被发现。

Method: 我们引入了一个结构因果模型 (SCM) 来重新形式化 3D-NCD 问题，并提出了一种新方法，即因果表示和推理的联合学习。具体来说，我们首先分析基础类表示中的隐藏混杂因素以及通过 SCM 基础类和新类之间的因果关系。我们设计了一种因果表示原型，消除混杂因素以捕获基础类的因果表示。然后使用图结构来建模基础类的因果表示原型和新类原型之间的因果关系，从而实现从基础类到新类的因果推理。

Result: 在 3D 和 2D NCD 语义分割上的大量实验和可视化结果证明了我们方法的优越性。

Conclusion: 本文提出了一种新的点云分割新类发现方法，通过结构因果模型和因果表示学习，有效地提高了新类分割的准确性。

Abstract: In this paper, we focus on Novel Class Discovery for Point Cloud Segmentation
(3D-NCD), aiming to learn a model that can segment unlabeled (novel) 3D classes
using only the supervision from labeled (base) 3D classes. The key to this task
is to setup the exact correlations between the point representations and their
base class labels, as well as the representation correlations between the
points from base and novel classes. A coarse or statistical correlation
learning may lead to the confusion in novel class inference. lf we impose a
causal relationship as a strong correlated constraint upon the learning
process, the essential point cloud representations that accurately correspond
to the classes should be uncovered. To this end, we introduce a structural
causal model (SCM) to re-formalize the 3D-NCD problem and propose a new method,
i.e., Joint Learning of Causal Representation and Reasoning. Specifically, we
first analyze hidden confounders in the base class representations and the
causal relationships between the base and novel classes through SCM. We devise
a causal representation prototype that eliminates confounders to capture the
causal representations of base classes. A graph structure is then used to model
the causal relationships between the base classes' causal representation
prototypes and the novel class prototypes, enabling causal reasoning from base
to novel classes. Extensive experiments and visualization results on 3D and 2D
NCD semantic segmentation demonstrate the superiorities of our method.

</details>


### [99] [InstantSfM: Fully Sparse and Parallel Structure-from-Motion](https://arxiv.org/abs/2510.13310)
*Jiankun Zhong,Zitong Zhan,Quankai Gao,Ziyu Chen,Haozhe Lou,Jiageng Mao,Ulrich Neumann,Yue Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于GPU加速的SfM框架，旨在解决传统SfM方法在大规模场景下的计算瓶颈和深度学习方法在处理大量视图时的内存限制。


<details>
  <summary>Details</summary>
Motivation: 传统SfM方法在大规模场景下计算开销大，且缺乏灵活性，深度学习方法则存在内存限制，无法处理大量视图。

Method: 该方法利用GPU并行计算加速标准SfM流程的关键步骤，扩展了稀疏感知BA优化技术，统一了BA和GP。

Result: 在不同规模的数据集上，该方法比COLMAP加速约40倍，并实现了相当甚至更高的重建精度。

Conclusion: 该方法充分利用了GPU的潜力，提高了SfM的效率和准确性。

Abstract: Structure-from-Motion (SfM), a method that recovers camera poses and scene
geometry from uncalibrated images, is a central component in robotic
reconstruction and simulation. Despite the state-of-the-art performance of
traditional SfM methods such as COLMAP and its follow-up work, GLOMAP, naive
CPU-specialized implementations of bundle adjustment (BA) or global positioning
(GP) introduce significant computational overhead when handling large-scale
scenarios, leading to a trade-off between accuracy and speed in SfM. Moreover,
the blessing of efficient C++-based implementations in COLMAP and GLOMAP comes
with the curse of limited flexibility, as they lack support for various
external optimization options. On the other hand, while deep learning based SfM
pipelines like VGGSfM and VGGT enable feed-forward 3D reconstruction, they are
unable to scale to thousands of input views at once as GPU memory consumption
increases sharply as the number of input views grows. In this paper, we unleash
the full potential of GPU parallel computation to accelerate each critical
stage of the standard SfM pipeline. Building upon recent advances in
sparse-aware bundle adjustment optimization, our design extends these
techniques to accelerate both BA and GP within a unified global SfM framework.
Through extensive experiments on datasets of varying scales (e.g. 5000 images
where VGGSfM and VGGT run out of memory), our method demonstrates up to about
40 times speedup over COLMAP while achieving consistently comparable or even
improved reconstruction accuracy. Our project page can be found at
https://cre185.github.io/InstantSfM/.

</details>


### [100] [Self-Augmented Visual Contrastive Decoding](https://arxiv.org/abs/2510.13315)
*Eun Woo Im,Muhammad Kashif Ali,Vivek Gupta*

Main category: cs.CV

TL;DR: 本文提出了一种新的、无需训练的解码策略，以解决大型视觉语言模型 (LVLM) 中存在的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常应用通用的视觉增强，而忽略了文本查询提供的特定上下文，从而限制了它们的有效性。

Method: 该方法包括：1) 自增强提示策略，利用模型的内在知识来动态对齐查询和视觉增强之间的语义；2) 自适应阈值算法，基于输出稀疏性自适应调整下一个token候选大小，利用logit分布的完整信息。

Result: 在四个 LVLM 和七个基准测试中进行的大量实验表明，所提出的解码方法显着提高了事实一致性，优于最先进的解码方法。

Conclusion: 这项工作强调了整合查询相关的增强和熵感知解码对于改进 LVLM 的有效生成的重要性。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal
capabilities, but they inherit the tendency to hallucinate from their
underlying language models. While visual contrastive decoding has been proposed
to mitigate this issue, existing methods often apply generic visual
augmentations that disregard the specific context provided by the text query,
limiting their effectiveness. This study introduces a novel training-free
decoding strategy that addresses these limitations, featuring two key
contributions. First, a self-augmentation prompting strategy that leverages the
intrinsic knowledge of the model to dynamically align semantics between the
query and the visual augmentation. Second, an adaptive thresholding algorithm
that adaptively adjusts next token candidate size based on the output sparsity,
utilizing full information from the logit distribution. Extensive experiments
across four LVLMs and seven benchmarks demonstrate that the proposed decoding
significantly enhances factual consistency compared to state-of-the-art
decoding methods. This work highlights the importance of integrating
query-dependent augmentation and entropy-aware decoding for improving effective
generation of LVLMs.

</details>


### [101] [Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests](https://arxiv.org/abs/2510.13316)
*Fitim Abdullahu,Helmut Grabner*

Main category: cs.CV

TL;DR: 探讨大型多模态模型(LMM)在理解视觉趣味性方面的潜力，并将其与人类评估进行比较。


<details>
  <summary>Details</summary>
Motivation: 吸引和保持人们的注意力至关重要，而视觉趣味性是关键。大型多模态模型在视觉和文本数据方面表现出令人印象深刻的能力，因此有必要研究它们是否能理解视觉趣味性的概念。

Method: 通过比较分析，检验人类评估与GPT-4o（一种领先的LMM）的预测之间的一致性。

Result: 研究表明，人类与GPT-4o之间存在部分一致性，GPT-4o已经尽可能地捕捉到了这个概念。

Conclusion: 该研究为更深入地理解人类兴趣铺平了道路，并允许根据图像对的趣味性对其进行有效标记，从而将知识提炼到学习排序模型中。

Abstract: Our daily life is highly influenced by what we consume and see. Attracting
and holding one's attention -- the definition of (visual) interestingness -- is
essential. The rise of Large Multimodal Models (LMMs) trained on large-scale
visual and textual data has demonstrated impressive capabilities. We explore
these models' potential to understand to what extent the concepts of visual
interestingness are captured and examine the alignment between human
assessments and GPT-4o's, a leading LMM, predictions through comparative
analysis. Our studies reveal partial alignment between humans and GPT-4o. It
already captures the concept as best compared to state-of-the-art methods.
Hence, this allows for the effective labeling of image pairs according to their
(commonly) interestingness, which are used as training data to distill the
knowledge into a learning-to-rank model. The insights pave the way for a deeper
understanding of human interest.

</details>


### [102] [Removing Cost Volumes from Optical Flow Estimators](https://arxiv.org/abs/2510.13317)
*Simon Kiefhaber,Stefan Roth,Simone Schaub-Meyer*

Main category: cs.CV

TL;DR: 提出了一种训练策略，可以在训练过程中从光流估计器中移除代价体，从而显著提高推理速度并降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 代价体在现代光流估计器中被广泛使用，但其计算和空间复杂度限制了处理速度和输入帧的分辨率。观察到一旦基于RAFT的pipeline的所有其他网络部分都经过充分训练，代价体的重要性就会降低。

Method: 引入了一种训练策略，允许在训练过程中从光流估计器中移除代价体。

Result: 创建了三个不同的模型，涵盖不同的计算预算。最精确的模型达到了最先进的精度，同时速度提高了1.2倍，内存占用降低了6倍；最快的模型能够以20 FPS的速度处理全高清帧，仅使用500 MB的GPU内存。

Conclusion: 提出的训练策略可以有效地提高光流估计器的性能，并降低其资源消耗。

Abstract: Cost volumes are used in every modern optical flow estimator, but due to
their computational and space complexity, they are often a limiting factor
regarding both processing speed and the resolution of input frames. Motivated
by our empirical observation that cost volumes lose their importance once all
other network parts of, e.g., a RAFT-based pipeline have been sufficiently
trained, we introduce a training strategy that allows removing the cost volume
from optical flow estimators throughout training. This leads to significantly
improved inference speed and reduced memory requirements. Using our training
strategy, we create three different models covering different compute budgets.
Our most accurate model reaches state-of-the-art accuracy while being
$1.2\times$ faster and having a $6\times$ lower memory footprint than
comparable models; our fastest model is capable of processing Full HD frames at
$20\,\mathrm{FPS}$ using only $500\,\mathrm{MB}$ of GPU memory.

</details>


### [103] [DEF-YOLO: Leveraging YOLO for Concealed Weapon Detection in Thermal Imagin](https://arxiv.org/abs/2510.13326)
*Divya Bhardwaj,Arnav Ramamoorthy,Poonam Goyal*

Main category: cs.CV

TL;DR: 本文提出了一种基于热成像的隐藏武器检测方法和数据集，旨在提供一种实时、低成本、保护隐私的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有成像方式在隐藏武器检测中存在分辨率低、隐私问题等局限性。为了提供一种全天候、低成本且保护隐私的解决方案，本文选择使用热成像技术。

Method: 本文提出了一种基于YOLOv8的改进架构DEF-YOLO，并采用了可变形卷积和焦点损失。

Result: 本文构建了一个新的大规模热成像隐藏武器数据集TICW，并通过实验验证了所提方法的有效性，为热成像隐藏武器检测建立了一个新的基准。

Conclusion: 本文提出的方法和数据集为热成像隐藏武器检测提供了一种新的有效途径。

Abstract: Concealed weapon detection aims at detecting weapons hidden beneath a
person's clothing or luggage. Various imaging modalities like Millimeter Wave,
Microwave, Terahertz, Infrared, etc., are exploited for the concealed weapon
detection task. These imaging modalities have their own limitations, such as
poor resolution in microwave imaging, privacy concerns in millimeter wave
imaging, etc. To provide a real-time, 24 x 7 surveillance, low-cost, and
privacy-preserved solution, we opted for thermal imaging in spite of the lack
of availability of a benchmark dataset. We propose a novel approach and a
dataset for concealed weapon detection in thermal imagery. Our YOLO-based
architecture, DEF-YOLO, is built with key enhancements in YOLOv8 tailored to
the unique challenges of concealed weapon detection in thermal vision. We adopt
deformable convolutions at the SPPF layer to exploit multi-scale features;
backbone and neck layers to extract low, mid, and high-level features, enabling
DEF-YOLO to adaptively focus on localization around the objects in thermal
homogeneous regions, without sacrificing much of the speed and throughput. In
addition to these simple yet effective key architectural changes, we introduce
a new, large-scale Thermal Imaging Concealed Weapon dataset, TICW, featuring a
diverse set of concealed weapons and capturing a wide range of scenarios. To
the best of our knowledge, this is the first large-scale contributed dataset
for this task. We also incorporate focal loss to address the significant class
imbalance inherent in the concealed weapon detection task. The efficacy of the
proposed work establishes a new benchmark through extensive experimentation for
concealed weapon detection in thermal imagery.

</details>


### [104] [Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models](https://arxiv.org/abs/2510.13331)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CV

TL;DR: Group-VQ: A novel approach to enhance VQ-VAE by group-wise codebook optimization and a training-free resampling method for improved reconstruction and flexible codebook size adjustment.


<details>
  <summary>Details</summary>
Motivation: Existing VQ-VAE methods suffer from codebook collapse and limited learning capability, leading to reduced reconstruction quality.

Method: The paper proposes Group-VQ, which performs group-wise optimization on the codebook, optimizing each group independently while jointly optimizing within groups. A training-free codebook resampling method is also introduced.

Result: Group-VQ demonstrates improved performance on reconstruction metrics in image reconstruction experiments. The post-training codebook sampling method achieves flexibility in adjusting the codebook size.

Conclusion: Group-VQ improves the trade-off between codebook utilization and reconstruction performance and allows post-training adjustment of the codebook size.

Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) leverage self-supervised
learning through reconstruction tasks to represent continuous vectors using the
closest vectors in a codebook. However, issues such as codebook collapse
persist in the VQ model. To address these issues, existing approaches employ
implicit static codebooks or jointly optimize the entire codebook, but these
methods constrain the codebook's learning capability, leading to reduced
reconstruction quality. In this paper, we propose Group-VQ, which performs
group-wise optimization on the codebook. Each group is optimized independently,
with joint optimization performed within groups. This approach improves the
trade-off between codebook utilization and reconstruction performance.
Additionally, we introduce a training-free codebook resampling method, allowing
post-training adjustment of the codebook size. In image reconstruction
experiments under various settings, Group-VQ demonstrates improved performance
on reconstruction metrics. And the post-training codebook sampling method
achieves the desired flexibility in adjusting the codebook size.

</details>


### [105] [No-Reference Rendered Video Quality Assessment: Dataset and Metrics](https://arxiv.org/abs/2510.13349)
*Sipeng Yang,Jiayu Ji,Qingchuan Zhu,Zhiyao Yang,Xiaogang Jin*

Main category: cs.CV

TL;DR: 本文提出了一个针对渲染视频的无参考视频质量评估(NR-VQA)数据集和指标。


<details>
  <summary>Details</summary>
Motivation: 现有的NR-VQA数据集和指标主要针对相机拍摄的视频，直接应用于渲染视频会导致偏差，因为渲染视频更容易出现时间伪影。

Method: 构建了一个大型渲染视频数据集，包含各种3D场景和渲染设置，并针对不同显示类型标注了质量分数。在此基础上，校准了NR-VQA指标，通过考察图像质量和时间稳定性来评估渲染视频质量。

Result: 提出的指标在渲染视频上表现优于现有的NR-VQA指标。

Conclusion: 该指标可用于评估超采样方法和实时渲染中的帧生成策略。

Abstract: Quality assessment of videos is crucial for many computer graphics
applications, including video games, virtual reality, and augmented reality,
where visual performance has a significant impact on user experience. When test
videos cannot be perfectly aligned with references or when references are
unavailable, the significance of no-reference video quality assessment (NR-VQA)
methods is undeniable. However, existing NR-VQA datasets and metrics are
primarily focused on camera-captured videos; applying them directly to rendered
videos would result in biased predictions, as rendered videos are more prone to
temporal artifacts. To address this, we present a large rendering-oriented
video dataset with subjective quality annotations, as well as a designed NR-VQA
metric specific to rendered videos. The proposed dataset includes a wide range
of 3D scenes and rendering settings, with quality scores annotated for various
display types to better reflect real-world application scenarios. Building on
this dataset, we calibrate our NR-VQA metric to assess rendered video quality
by looking at both image quality and temporal stability. We compare our metric
to existing NR-VQA metrics, demonstrating its superior performance on rendered
videos. Finally, we demonstrate that our metric can be used to benchmark
supersampling methods and assess frame generation strategies in real-time
rendering.

</details>


### [106] [Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity](https://arxiv.org/abs/2510.13364)
*MingZe Tang,Jubal Chandy Jacob*

Main category: cs.CV

TL;DR: 研究了提示语设计对零样本图像分类的影响，特别是在视觉上相似的类别中，发现简单提示语通常效果最好。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型(VLMs)可以通过在共享空间中对齐图像和文本来实现零样本分类，这是一种很有前景的方法，但在数据稀缺的情况下，提示语设计对识别视觉上相似的类别的影响尚不清楚。

Method: 使用一个包含285张图像的小型COCO衍生数据集，评估了一套现代VLMs（包括OpenCLIP、MetaCLIP 2和SigLip），采用了一个三层提示语设计，系统地增加了语言细节。

Result: 对于性能最高的模型（MetaCLIP 2和OpenCLIP），最简单、最基本的提示语始终能获得最佳结果。添加描述性细节会显著降低性能。相反，性能较低的SigLip模型在获得更多描述性的、基于身体线索的提示时，对模糊类的分类效果有所提高。

Conclusion: 对于高性能的视觉-语言模型，简单的提示语通常比复杂的提示语效果更好，而对于低性能的模型，更详细的提示语可能会有所帮助。

Abstract: Recent Vision-Language Models (VLMs) enable zero-shot classification by
aligning images and text in a shared space, a promising approach for
data-scarce conditions. However, the influence of prompt design on recognizing
visually similar categories, such as human postures, is not well understood.
This study investigates how prompt specificity affects the zero-shot
classification of sitting, standing, and walking/running on a small, 285-image
COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2,
and SigLip, were evaluated using a three-tiered prompt design that
systematically increases linguistic detail. Our findings reveal a compelling,
counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and
OpenCLIP), the simplest, most basic prompts consistently achieve the best
results. Adding descriptive detail significantly degrades performance for
instance, MetaCLIP 2's multi-class accuracy drops from 68.8\% to 55.1\% a
phenomenon we term "prompt overfitting". Conversely, the lower-performing
SigLip model shows improved classification on ambiguous classes when given more
descriptive, body-cue-based prompts.

</details>


### [107] [DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning](https://arxiv.org/abs/2510.13375)
*Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Zhuoguang Chen,Tao Jiang,Hang Zhao*

Main category: cs.CV

TL;DR: DepthVLA模型通过结合预训练的深度预测模块，显式地提高了VLA模型的空间感知能力，从而在需要精确空间推理的任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在需要精确空间推理的任务中表现不佳，并且依赖于大量的动作数据预训练，效率低且空间理解不准确。

Method: DepthVLA采用混合transformer设计，整合了VLM、深度transformer和动作专家，并通过完全共享的注意力机制形成端到端模型。

Result: 在真实和模拟环境中的大量评估表明，DepthVLA优于现有技术，在真实世界任务、LIBERO模拟器和Simpler模拟器中分别实现了78.5% vs. 65.0%、94.9% vs. 93.6%和74.8% vs. 58.8%的进展。

Conclusion: DepthVLA通过显式地结合空间感知，显著提升了VLA模型在需要精确空间推理任务中的性能。

Abstract: Vision-Language-Action (VLA) models have recently shown impressive
generalization and language-guided manipulation capabilities. However, their
performance degrades on tasks requiring precise spatial reasoning due to
limited spatial reasoning inherited from Vision-Language Models (VLMs).
Existing VLAs rely on extensive action-data pretraining to ground VLMs in 3D
space, which reduces training efficiency and is still insufficient for accurate
spatial understanding. In this work, we present DepthVLA, a simple yet
effective VLA architecture that explicitly incorporates spatial awareness
through a pretrained depth prediction module. DepthVLA adopts a
mixture-of-transformers design that unifies a VLM, a depth transformer, and an
action expert with fully shared attentions, forming an end-to-end model with
enhanced spatial reasoning. Extensive evaluations in both real-world and
simulated environments show that DepthVLA outperforms state-of-the-art
approaches, achieving 78.5% vs. 65.0% progress in real-world tasks, 94.9% vs.
93.6% in the LIBERO simulator, and 74.8% vs. 58.8% in the Simpler simulator.
Our code will be made publicly available.

</details>


### [108] [Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering](https://arxiv.org/abs/2510.13381)
*Siddharth Tourani,Jayaram Reddy,Akash Kumbar,Satyajit Tourani,Nishant Goyal,Madhava Krishna,N. Dinesh Reddy,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 本文提出了一种新的动态场景渲染和重建方法，该方法结合了 signed distance function (SDF) 和 3D Gaussian Splatting (3DGS)，可以在没有 LiDAR 数据和 3D 运动注释的情况下，实现最先进的渲染性能，并支持各种场景编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 3DGS 的动态城市场景建模方法需要相机和 LiDAR 数据、ground-truth 3D 分割以及 tracklets 或 SMPL 等预定义对象模板形式的运动数据，成本较高。

Method: 本文将 SDF 与 3DGS 相结合，利用两者的优势来创建更强大的对象表示。该方法通过统一的优化框架，增强了 3DGS 的几何精度，并改进了 SDF 中的变形建模。

Result: 该方法在没有 LiDAR 数据的情况下，在城市场景中实现了最先进的渲染指标。当结合 LiDAR 时，该方法在重建和生成跨不同对象类别的新颖视图方面得到了进一步的改进，且无需 ground-truth 3D 运动注释。

Conclusion: 本文提出的方法可以有效地进行动态场景渲染和重建，并支持各种场景编辑任务，例如场景分解和场景合成。

Abstract: Dynamic scene rendering and reconstruction play a crucial role in computer
vision and augmented reality. Recent methods based on 3D Gaussian Splatting
(3DGS), have enabled accurate modeling of dynamic urban scenes, but for urban
scenes they require both camera and LiDAR data, ground-truth 3D segmentations
and motion data in the form of tracklets or pre-defined object templates such
as SMPL. In this work, we explore whether a combination of 2D object agnostic
priors in the form of depth and point tracking coupled with a signed distance
function (SDF) representation for dynamic objects can be used to relax some of
these requirements. We present a novel approach that integrates Signed Distance
Functions (SDFs) with 3D Gaussian Splatting (3DGS) to create a more robust
object representation by harnessing the strengths of both methods. Our unified
optimization framework enhances the geometric accuracy of 3D Gaussian splatting
and improves deformation modeling within the SDF, resulting in a more adaptable
and precise representation. We demonstrate that our method achieves
state-of-the-art performance in rendering metrics even without LiDAR data on
urban scenes. When incorporating LiDAR, our approach improved further in
reconstructing and generating novel views across diverse object categories,
without ground-truth 3D motion annotation. Additionally, our method enables
various scene editing tasks, including scene decomposition, and scene
composition.

</details>


### [109] [Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment](https://arxiv.org/abs/2510.13390)
*Feng-Qi Cui,Yu-Tong Guo,Tianyue Zheng,Jinyang Huang*

Main category: cs.CV

TL;DR: 本文提出了一种名为GLSDA的新框架，用于增强基于WiFi的手势识别，提高泛化能力和语义表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于WiFi的手势识别方法由于信道状态信息的域敏感性和缺乏高级手势抽象，泛化能力和语义表达能力有限。

Method: 该方法利用预训练的大型基础模型的语义先验，设计了一个双路径CSI编码管道，通过CSI-Ratio相位序列和多普勒频谱图捕获几何和动态手势模式，并使用多尺度语义编码器学习鲁棒的时间嵌入，并通过跨模态注意力机制将其与手势语义对齐。此外，还引入了语义感知软监督方案，以编码类间相关性并减少标签模糊。最后，开发了一种鲁棒的双重蒸馏策略，将对齐的模型压缩为轻量级的学生网络。

Result: 在Widar3.0基准测试上的大量实验表明，GLSDA在域内和跨域手势识别任务中始终优于最先进的方法，同时显着减小了模型大小和推理延迟。

Conclusion: 该方法为实际AIoT应用中基于RF的通用手势界面提供了一种可扩展且可部署的解决方案。

Abstract: WiFi-based gesture recognition has emerged as a promising RF sensing paradigm
for enabling non-contact and privacy-preserving human-computer interaction in
AIoT environments. However, existing methods often suffer from limited
generalization and semantic expressiveness due to the domain-sensitive nature
of Channel State Information and the lack of high-level gesture abstraction. To
address these challenges, we propose a novel generalization framework, termed
Large-Model-Aware Semantic Distillation and Alignment (GLSDA), which leverages
the semantic prior of pre-trained large foundation models to enhance gesture
representation learning in both in-domain and cross-domain scenarios.
Specifically, we first design a dual-path CSI encoding pipeline that captures
geometric and dynamic gesture patterns via CSI-Ratio phase sequences and
Doppler spectrograms. These representations are then fed into a Multiscale
Semantic Encoder, which learns robust temporal embeddings and aligns them with
gesture semantics through cross-modal attention mechanisms. To further enhance
category discrimination, we introduce a Semantic-Aware Soft Supervision scheme
that encodes inter-class correlations and reduces label ambiguity, especially
for semantically similar gestures. Finally, we develop a Robust
Dual-Distillation strategy to compress the aligned model into a lightweight
student network, jointly distilling intermediate features and semantic-informed
soft labels from the teacher model. Extensive experiments on the Widar3.0
benchmark show that GLSDA consistently outperforms state-of-the-art methods in
both in-domain and cross-domain gesture recognition tasks, while significantly
reducing model size and inference latency. Our method offers a scalable and
deployable solution for generalized RF-based gesture interfaces in real-world
AIoT applications.

</details>


### [110] [Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.13394)
*Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang*

Main category: cs.CV

TL;DR: 论文提出了一个新的空间推理基准Spatial-DISE，用于评估视觉语言模型在内在-动态空间推理方面的能力，并提供了一个自动生成大规模数据集的pipeline。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试在评估空间推理能力方面不足，尤其是在内在-动态空间推理方面。

Method: 论文提出了一个统一的基准Spatial-DISE，该基准基于认知分类法，将任务分为四个基本象限：内在-静态、内在-动态、外在-静态和外在-动态空间推理。此外，论文还开发了一个可扩展的自动化pipeline，以生成多样且可验证的空间推理问题。

Result: 对28个最先进的视觉语言模型进行的综合评估表明，当前的视觉语言模型与人类能力之间存在巨大且持续的差距，尤其是在多步骤多视图空间推理方面。

Conclusion: Spatial-DISE为未来的研究提供了一个稳健的框架、有价值的数据集和明确的方向，朝着类人空间智能发展。

Abstract: Spatial reasoning ability is crucial for Vision Language Models (VLMs) to
support real-world applications in diverse domains including robotics,
augmented reality, and autonomous navigation. Unfortunately, existing
benchmarks are inadequate in assessing spatial reasoning ability, especially
the \emph{intrinsic-dynamic} spatial reasoning which is a fundamental aspect of
human spatial cognition. In this paper, we propose a unified benchmark,
\textbf{Spatial-DISE}, based on a cognitively grounded taxonomy that
categorizes tasks into four fundamental quadrants:
\textbf{I}ntrinsic-\textbf{S}tatic, Intrinsic-\textbf{D}ynamic,
\textbf{E}xtrinsic-Static, and Extrinsic-Dynamic spatial reasoning. Moreover,
to address the issue of data scarcity, we develop a scalable and automated
pipeline to generate diverse and verifiable spatial reasoning questions,
resulting in a new \textbf{Spatial-DISE} dataset that includes Spatial-DISE
Bench (559 evaluation VQA pairs) and Spatial-DISE-12K (12K+ training VQA
pairs). Our comprehensive evaluation across 28 state-of-the-art VLMs reveals
that, current VLMs have a large and consistent gap to human competence,
especially on multi-step multi-view spatial reasoning. Spatial-DISE offers a
robust framework, valuable dataset, and clear direction for future research
toward human-like spatial intelligence. Benchmark, dataset, and code will be
publicly released.

</details>


### [111] [Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation](https://arxiv.org/abs/2510.13418)
*Yifu Luo,Xinhao Hu,Keyu Fan,Haoyuan Sun,Zeyu Chen,Bo Xia,Tiantian Zhang,Yongzhe Chang,Xueqian Wang*

Main category: cs.CV

TL;DR: 提出了一种新的基于强化学习的文本到图像生成方法 Mask-GRPO，该方法适用于掩码生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要集中在扩散模型或自回归模型，忽略了掩码生成模型这一重要替代方案。

Method: 将基于 Group Relative Policy Optimization (GRPO) 的强化学习融入掩码生成模型，并重新定义了转移概率，将 unmasking 过程建模为多步决策问题。同时，探索了移除 KL 约束、应用归约策略和过滤低质量样本等优化策略。

Result: 在标准 T2I 基准测试和偏好对齐方面，Mask-GRPO 显著优于现有最佳方法。

Conclusion: Mask-GRPO 成功地将强化学习应用于掩码生成模型，并在文本到图像生成任务中取得了显著的性能提升。

Abstract: Reinforcement learning (RL) has garnered increasing attention in
text-to-image (T2I) generation. However, most existing RL approaches are
tailored to either diffusion models or autoregressive models, overlooking an
important alternative: masked generative models. In this work, we propose
Mask-GRPO, the first method to incorporate Group Relative Policy Optimization
(GRPO)-based RL into this overlooked paradigm. Our core insight is to redefine
the transition probability, which is different from current approaches, and
formulate the unmasking process as a multi-step decision-making problem. To
further enhance our method, we explore several useful strategies, including
removing the KL constraint, applying the reduction strategy, and filtering out
low-quality samples. Using Mask-GRPO, we improve a base model, Show-o, with
substantial improvements on standard T2I benchmarks and preference alignment,
outperforming existing state-of-the-art approaches. The code is available on
https://github.com/xingzhejun/Mask-GRPO

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [112] [From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models](https://arxiv.org/abs/2510.12864)
*Imran Khan*

Main category: cs.AI

TL;DR: 大型语言模型在作为代理 AI 系统的推理引擎时，会严格遵守显式规则，导致决策与人类常识和意图不符。本文提出了规则-意图区分 (RID) 框架，这是一种低计算的元提示技术，旨在以零样本方式引出 LLM 中与人类对齐的异常处理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 作为代理 AI 系统的推理引擎被越来越多地部署，但它们表现出一个关键缺陷： rigid adherence to explicit rules，这导致决策与人类常识和意图不符。这种“规则刚性”是构建可信赖的自主代理的一个重大障碍。虽然之前的工作表明，使用人类解释进行监督微调 (SFT) 可以缓解这个问题，但 SFT 的计算成本很高，而且许多从业者无法获得。

Method: 本文介绍了一种新颖的低计算元提示技术，即规则-意图区分 (RID) 框架，旨在以零样本方式引出 LLM 中与人类对齐的异常处理。RID 框架为模型提供了一个结构化的认知模式，用于解构任务、分类规则、权衡冲突结果以及证明其最终决策的合理性。

Result: 在需要跨不同领域进行细致判断的 20 个场景的自定义基准上，评估了 RID 框架与基线和思维链 (CoT) 提示的效果。经验证的结果表明，RID 框架显著提高了性能，实现了 95% 的人类对齐分数 (HAS)，而基线为 80%，CoT 为 75%。

Conclusion: 这项工作提出了一种实用、可访问且有效的方法，用于引导 LLM 从字面指令遵循转向自由的、以目标为导向的推理，从而为更可靠和实用的 AI 代理铺平道路。

Abstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning
engines for agentic AI systems, yet they exhibit a critical flaw: a rigid
adherence to explicit rules that leads to decisions misaligned with human
common sense and intent. This "rule-rigidity" is a significant barrier to
building trustworthy autonomous agents. While prior work has shown that
supervised fine-tuning (SFT) with human explanations can mitigate this issue,
SFT is computationally expensive and inaccessible to many practitioners. To
address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a
novel, low-compute meta-prompting technique designed to elicit human-aligned
exception handling in LLMs in a zero-shot manner. The RID framework provides
the model with a structured cognitive schema for deconstructing tasks,
classifying rules, weighing conflicting outcomes, and justifying its final
decision. We evaluated the RID framework against baseline and Chain-of-Thought
(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced
judgment across diverse domains. Our human-verified results demonstrate that
the RID framework significantly improves performance, achieving a 95% Human
Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT.
Furthermore, it consistently produces higher-quality, intent-driven reasoning.
This work presents a practical, accessible, and effective method for steering
LLMs from literal instruction-following to liberal, goal-oriented reasoning,
paving the way for more reliable and pragmatic AI agents.

</details>


### [113] [DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping](https://arxiv.org/abs/2510.12979)
*Wei Fan,Wenlin Yao,Zheng Li,Feng Yao,Xin Liu,Liang Qiu,Qingyu Yin,Yangqiu Song,Bing Yin*

Main category: cs.AI

TL;DR: 本文提出了一种名为 DeepPlanner 的端到端强化学习框架，旨在提升深度研究代理的规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法要么依赖于推理阶段的隐式规划，要么引入显式规划器，但没有系统地解决如何优化规划阶段的问题。我们观察到，在 vanilla 强化学习 (RL) 下，规划 tokens 比其他 action tokens 表现出明显更高的熵，揭示了仍然未被充分优化的不确定决策点。

Method: 我们的方法通过基于熵的项来塑造 token 级别的优势，以将更大的更新分配给高熵 tokens，并选择性地增加规划密集型 rollouts 的样本级别优势。

Result: 在七个深度研究基准上的大量实验表明，DeepPlanner 提高了规划质量，并在大大降低的训练预算下实现了最先进的结果。

Conclusion: DeepPlanner 有效地提升了深度研究代理的规划能力，并在实验中取得了优异的结果。

Abstract: Large language models (LLMs) augmented with multi-step reasoning and action
generation abilities have shown promise in leveraging external tools to tackle
complex tasks that require long-horizon planning. However, existing approaches
either rely on implicit planning in the reasoning stage or introduce explicit
planners without systematically addressing how to optimize the planning stage.
As evidence, we observe that under vanilla reinforcement learning (RL),
planning tokens exhibit significantly higher entropy than other action tokens,
revealing uncertain decision points that remain under-optimized. To address
this, we propose DeepPlanner, an end-to-end RL framework that effectively
enhances the planning capabilities of deep research agents. Our approach shapes
token-level advantage with an entropy-based term to allocate larger updates to
high entropy tokens, and selectively upweights sample-level advantages for
planning-intensive rollouts. Extensive experiments across seven deep research
benchmarks demonstrate that DeepPlanner improves planning quality and achieves
state-of-the-art results under a substantially lower training budget.

</details>


### [114] [SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents](https://arxiv.org/abs/2510.12985)
*Simon Sinong Zhan,Yao Liu,Philip Wang,Zinan Wang,Qineng Wang,Zhian Ruan,Xiangyu Shi,Xinyu Cao,Frank Yang,Kangrui Wang,Huajie Shao,Manling Li,Qi Zhu*

Main category: cs.AI

TL;DR: Sentinel是一个用于评估大型语言模型(LLM)具身智能体物理安全性的框架，它在语义、计划和轨迹层面进行评估。


<details>
  <summary>Details</summary>
Motivation: 以往方法依赖于启发式规则或主观的LLM判断，而Sentinel将实际安全需求置于形式时序逻辑(TL)语义中，可以精确地指定状态不变性、时间依赖性和时序约束。

Method: Sentinel采用多层次验证管道，(i)在语义层，将直观的自然语言安全需求形式化为TL公式，并探究LLM智能体对这些需求的理解是否与TL公式一致；(ii)在计划层，针对TL公式验证LLM智能体生成的高级行动计划和子目标，以在执行前检测不安全的计划；(iii)在轨迹层，将多个执行轨迹合并成一个计算树，并针对物理细节化的TL规范进行有效验证，以进行最终安全检查。

Result: 在VirtualHome和ALFRED中应用Sentinel，并针对各种安全需求对多个基于LLM的具身智能体进行正式评估。实验表明，通过将物理安全置于时序逻辑中，并在多个层面上应用验证方法，Sentinel为系统地评估物理环境中的LLM具身智能体提供了一个严谨的基础，暴露了先前方法忽略的安全违规行为，并提供了对其失效模式的见解。

Conclusion: Sentinel通过在多个层面上应用验证方法，为系统评估LLM具身智能体的物理安全性提供了一个严谨的基础。

Abstract: We present Sentinel, the first framework for formally evaluating the physical
safety of Large Language Model(LLM-based) embodied agents across the semantic,
plan, and trajectory levels. Unlike prior methods that rely on heuristic rules
or subjective LLM judgments, Sentinel grounds practical safety requirements in
formal temporal logic (TL) semantics that can precisely specify state
invariants, temporal dependencies, and timing constraints. It then employs a
multi-level verification pipeline where (i) at the semantic level, intuitive
natural language safety requirements are formalized into TL formulas and the
LLM agent's understanding of these requirements is probed for alignment with
the TL formulas; (ii) at the plan level, high-level action plans and subgoals
generated by the LLM agent are verified against the TL formulas to detect
unsafe plans before execution; and (iii) at the trajectory level, multiple
execution trajectories are merged into a computation tree and efficiently
verified against physically-detailed TL specifications for a final safety
check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate
multiple LLM-based embodied agents against diverse safety requirements. Our
experiments show that by grounding physical safety in temporal logic and
applying verification methods across multiple levels, Sentinel provides a
rigorous foundation for systematically evaluating LLM-based embodied agents in
physical environments, exposing safety violations overlooked by previous
methods and offering insights into their failure modes.

</details>


### [115] [From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model](https://arxiv.org/abs/2510.13002)
*Boyou Chen,Gerui Xu,Zifei Wang,Huizhong Guo,Ananna Ahmed,Zhaonan Sun,Zhen Hu,Kaihan Zhang,Shan Bao*

Main category: cs.AI

TL;DR: This paper introduces a framework using a fine-tuned large language model to automatically infer Driver Hazardous Actions (DHAs) from textual crash narratives.


<details>
  <summary>Details</summary>
Motivation: Identifying Driver Hazardous Action (DHA) is essential for understanding crash causation, but the reliability of DHA data in large-scale databases is limited.

Method: The Llama 3.2 1B model was fine-tuned on five years of two-vehicle crash data and benchmarked against conventional machine learning classifiers.

Result: The fine-tuned LLM achieved an overall accuracy of 80%, surpassing all baseline models. Probabilistic reasoning approach was developed, analyzing model output shifts across original test sets and three targeted counterfactual scenarios: variations in driver distraction and age.

Conclusion: The framework and analytical methods provide a robust and interpretable solution for large-scale automated DHA detection, offering new opportunities for traffic safety analysis and intervention.

Abstract: Vehicle crashes involve complex interactions between road users, split-second
decisions, and challenging environmental conditions. Among these, two-vehicle
crashes are the most prevalent, accounting for approximately 70% of roadway
crashes and posing a significant challenge to traffic safety. Identifying
Driver Hazardous Action (DHA) is essential for understanding crash causation,
yet the reliability of DHA data in large-scale databases is limited by
inconsistent and labor-intensive manual coding practices. Here, we present an
innovative framework that leverages a fine-tuned large language model to
automatically infer DHAs from textual crash narratives, thereby improving the
validity and interpretability of DHA classifications. Using five years of
two-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on
detailed crash narratives and benchmarked its performance against conventional
machine learning classifiers, including Random Forest, XGBoost, CatBoost, and a
neural network. The fine-tuned LLM achieved an overall accuracy of 80%,
surpassing all baseline models and demonstrating pronounced improvements in
scenarios with imbalanced data. To increase interpretability, we developed a
probabilistic reasoning approach, analyzing model output shifts across original
test sets and three targeted counterfactual scenarios: variations in driver
distraction and age. Our analysis revealed that introducing distraction for one
driver substantially increased the likelihood of "General Unsafe Driving";
distraction for both drivers maximized the probability of "Both Drivers Took
Hazardous Actions"; and assigning a teen driver markedly elevated the
probability of "Speed and Stopping Violations." Our framework and analytical
methods provide a robust and interpretable solution for large-scale automated
DHA detection, offering new opportunities for traffic safety analysis and
intervention.

</details>


### [116] [Toward Reasoning-Centric Time-Series Analysis](https://arxiv.org/abs/2510.13029)
*Xinlei Wang,Mingtian Tan,Jing Qiu,Junhua Zhao,Jinjin Gu*

Main category: cs.AI

TL;DR: 传统时间序列分析依赖于模式识别，但在实际环境中需要超越表面趋势，揭示驱动因素。大型语言模型（LLM）的兴起为重新思考时间序列分析带来了机会，但需要谨慎使用，充分利用其推理潜力。本文认为应将时间序列分析视为一个推理任务，强调因果结构和可解释性，以实现更透明和符合人类理解的洞察。


<details>
  <summary>Details</summary>
Motivation: 在政策变化、人类行为适应和意外事件发生的实际环境中，有效的时间序列分析必须超越表面层面的趋势，揭示驱动它们的实际力量。现有基于LLM的方法大多只利用其数值回归能力，忽略了其更深层次的推理潜力。

Method: 将时间序列分析重新定义为一个推理任务，优先考虑因果结构和可解释性。

Result: 使时间序列分析更接近于符合人类的理解，从而在复杂的实际环境中实现透明的、上下文感知的洞察。

Conclusion: 利用大型语言模型（LLM）的推理能力，重新思考时间序列分析，强调因果结构和可解释性，可以提升分析的透明度和符合人类理解的程度。

Abstract: Traditional time series analysis has long relied on pattern recognition,
trained on static and well-established benchmarks. However, in real-world
settings -- where policies shift, human behavior adapts, and unexpected events
unfold -- effective analysis must go beyond surface-level trends to uncover the
actual forces driving them. The recent rise of Large Language Models (LLMs)
presents new opportunities for rethinking time series analysis by integrating
multimodal inputs. However, as the use of LLMs becomes popular, we must remain
cautious, asking why we use LLMs and how to exploit them effectively. Most
existing LLM-based methods still employ their numerical regression ability and
ignore their deeper reasoning potential. This paper argues for rethinking time
series with LLMs as a reasoning task that prioritizes causal structure and
explainability. This shift brings time series analysis closer to human-aligned
understanding, enabling transparent and context-aware insights in complex
real-world environments.

</details>


### [117] [Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking](https://arxiv.org/abs/2510.13036)
*Stephane Hatgis-Kessell,Logan Mondal Bhamidipaty,Emma Brunskill*

Main category: cs.AI

TL;DR: 提出了一种基于偏好的奖励修复 (PBRR) 框架，通过学习附加的、依赖于转移的校正项来修复人工指定的代理奖励函数。


<details>
  <summary>Details</summary>
Motivation: 人工设计的强化学习 (RL) 智能体的奖励函数经常与人类的真实、不可观察的目标不一致，因此只能作为代理。优化错误指定的代理奖励函数通常会导致奖励入侵，从而导致策略与人类的真实目标不一致。构建人类反馈数据集的成本很高。

Method: PBRR 使用目标探索策略和新的偏好学习目标来识别和纠正这些转移。

Result: 在表格域中，PBRR 具有累积遗憾，在奖励入侵基准测试中，PBRR 始终优于从偏好中从头开始学习奖励函数或使用其他方法修改代理奖励函数的基线方法，只需要更少的偏好即可学习高性能策略。

Conclusion: PBRR 是一种有效的框架，可以通过从人类偏好中学习来修复人工指定的代理奖励函数，并且优于其他方法。

Abstract: Human-designed reward functions for reinforcement learning (RL) agents are
frequently misaligned with the humans' true, unobservable objectives, and thus
act only as proxies. Optimizing for a misspecified proxy reward function often
induces reward hacking, resulting in a policy misaligned with the human's true
objectives. An alternative is to perform RL from human feedback, which involves
learning a reward function from scratch by collecting human preferences over
pairs of trajectories. However, building such datasets is costly. To address
the limitations of both approaches, we propose Preference-Based Reward Repair
(PBRR): an automated iterative framework that repairs a human-specified proxy
reward function by learning an additive, transition-dependent correction term
from preferences. A manually specified reward function can yield policies that
are highly suboptimal under the ground-truth objective, yet corrections on only
a few transitions may suffice to recover optimal performance. To identify and
correct for those transitions, PBRR uses a targeted exploration strategy and a
new preference-learning objective. We prove in tabular domains PBRR has a
cumulative regret that matches, up to constants, that of prior preference-based
RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR
consistently outperforms baselines that learn a reward function from scratch
from preferences or modify the proxy reward function using other approaches,
requiring substantially fewer preferences to learn high performing policies.

</details>


### [118] [Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation](https://arxiv.org/abs/2510.13195)
*Qun Ma,Xiao Xue,Xuwen Zhang,Zihan Zhao,Yuwei Guo,Ming Zhang*

Main category: cs.AI

TL;DR: 本文构建了一个情感认知框架，旨在实现基于LLM的智能体与人类之间的情感对齐，模拟智能体的完整决策过程。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体在情感认知方面存在严重局限性，无法模拟虚拟和现实世界服务之间的有限理性，并且缺乏经过验证的集成机制将情感嵌入到智能体决策架构中。

Method: 构建了一个包含欲望生成和目标管理的情感认知框架，对基于LLM的智能体的完整决策过程进行建模，包括状态演化、欲望生成、目标优化、决策生成和行动执行。

Result: 实验结果表明，在该框架下，智能体不仅表现出与其情感状态相符的行为，而且与其他智能体类型相比，表现出卓越的生态有效性，并生成更接近人类行为模式的决策结果。

Conclusion: 该框架能够有效提升LLM智能体的情感认知能力，使其行为更贴近人类。

Abstract: The advent of large language models (LLMs) has enabled agents to represent
virtual humans in societal simulations, facilitating diverse interactions
within complex social systems. However, existing LLM-based agents exhibit
severe limitations in affective cognition: They fail to simulate the bounded
rationality essential for bridging virtual and real-world services; They lack
empirically validated integration mechanisms embedding emotions within agent
decision architectures. This paper constructs an emotional cognition framework
incorporating desire generation and objective management, designed to achieve
emotion alignment between LLM-based agents and humans, modeling the complete
decision-making process of LLM-based agents, encompassing state evolution,
desire generation, objective optimization, decision generation, and action
execution. This study implements the proposed framework within our proprietary
multi-agent interaction environment. Experimental results demonstrate that
agents governed by our framework not only exhibit behaviors congruent with
their emotional states but also, in comparative assessments against other agent
types, demonstrate superior ecological validity and generate decision outcomes
that significantly more closely approximate human behavioral patterns.

</details>


### [119] [Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning](https://arxiv.org/abs/2510.13214)
*Zehui Ling,Deshu Chen,Yichi Zhang,Yuchen Liu,Xigui Li,Xin Guo,Yuan Cheng*

Main category: cs.AI

TL;DR: 提出了一种大小LLM集成的互补代理系统，以降低计算成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）中的思维链提示和深度推理可以显著提高复杂任务的性能，多代理系统可以通过模型辩论进一步提高准确性。然而，对所有问题应用深度推理的计算成本很高。

Method: 小LLM首先生成一个初始答案，然后由大LLM验证。如果正确，则直接采用答案；否则，大LLM执行深入推理。

Result: 对于简单的问题，该方法将大型LLM的计算成本降低了50%以上，而精度损失可忽略不计，同时始终保持了复杂任务的强大性能。

Conclusion: 通过集成大小LLM，该方法能够在降低计算成本的同时，保持甚至提高模型在复杂任务上的性能。

Abstract: Recent advances in Large Language Models (LLMs) demonstrate that
chain-of-thought prompting and deep reasoning substantially enhance performance
on complex tasks, and multi-agent systems can further improve accuracy by
enabling model debates. However, applying deep reasoning to all problems is
computationally expensive. To mitigate these costs, we propose a complementary
agent system integrating small and large LLMs. The small LLM first generates an
initial answer, which is then verified by the large LLM. If correct, the answer
is adopted directly; otherwise, the large LLM performs in-depth reasoning.
Experimental results show that, for simple problems, our approach reduces the
computational cost of the large LLM by more than 50% with negligible accuracy
loss, while consistently maintaining robust performance on complex tasks.

</details>


### [120] [Personalized Learning Path Planning with Goal-Driven Learner State Modeling](https://arxiv.org/abs/2510.13215)
*Joy Jia Yin Lim,Ye He,Jifan Yu,Xin Cong,Daniel Zhang-Li,Zhiyuan Liu,Huiqin Liu,Lei Hou,Juanzi Li,Bin Xu*

Main category: cs.AI

TL;DR: Pxplore是一个用于PLPP的新框架，它整合了基于强化的训练范式和LLM驱动的教育架构。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常缺乏与目标对齐的机制来实现PLPP中自适应学习路径的设计，而大型语言模型（LLM）在个性化学习体验方面显示出潜力。

Method: 我们设计了一个结构化的学习者状态模型和一个自动奖励函数，该函数将抽象目标转换为可计算信号。我们结合了监督微调（SFT）和群体相对策略优化（GRPO）来训练策略，并将其部署在真实世界的学习平台中。

Result: 大量实验验证了Pxplore在生成连贯的、个性化的和目标驱动的学习路径方面的有效性。

Conclusion: 我们发布了我们的代码和数据集，以促进未来的研究。

Abstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning
paths that align with individual goals. While large language models (LLMs) show
potential in personalizing learning experiences, existing approaches often lack
mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework
for PLPP that integrates a reinforcement-based training paradigm and an
LLM-driven educational architecture. We design a structured learner state model
and an automated reward function that transforms abstract objectives into
computable signals. We train the policy combining supervised fine-tuning (SFT)
and Group Relative Policy Optimization (GRPO), and deploy it within a
real-world learning platform. Extensive experiments validate Pxplore's
effectiveness in producing coherent, personalized, and goal-driven learning
paths. We release our code and dataset to facilitate future research.

</details>


### [121] [EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems](https://arxiv.org/abs/2510.13220)
*Yufei He,Juncheng Liu,Yue Liu,Yibo Li,Tri Cao,Zhiyuan Hu,Xinxing Xu,Bryan Hooi*

Main category: cs.AI

TL;DR: 当前AI智能体无法在测试时快速学习复杂技能，限制了它们的实用性。本文提出了Jericho Test-Time Learning (J-TTL) 基准来评估和推动这一领域的进展，并提出了EvoTest框架，通过进化整个智能体系统来改进智能体，无需微调或梯度。


<details>
  <summary>Details</summary>
Motivation: 现有AI智能体在新的环境中无法快速学习复杂技能，限制了它们的实际应用。

Method: 提出了EvoTest框架，包含Actor Agent和Evolver Agent。Evolver Agent分析 эпизоды记录，并为下一次运行提出修改后的配置，包括重写提示、更新记忆、调整超参数和学习工具使用程序。

Result: EvoTest在J-TTL基准测试中持续提高性能，优于其他基线方法，并且是唯一能够赢得两个游戏的智能体。

Conclusion: EvoTest框架有效解决了AI智能体在测试时学习复杂技能的难题，并在J-TTL基准测试中取得了显著成果。

Abstract: A fundamental limitation of current AI agents is their inability to learn
complex skills on the fly at test time, often behaving like "clever but
clueless interns" in novel environments. This severely limits their practical
utility. To systematically measure and drive progress on this challenge, we
first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a
new evaluation setup where an agent must play the same game for several
consecutive episodes, attempting to improve its performance from one episode to
the next. On J-TTL, we find that existing adaptation methods like reflection,
memory, or reinforcement learning struggle. To address the challenges posed by
our benchmark, we present EvoTest, an evolutionary test-time learning framework
that improves an agent without any fine-tuning or gradients-by evolving the
entire agentic system after every episode. EvoTest has two roles: the Actor
Agent, which plays the game, and the Evolver Agent, which analyzes the episode
transcript to propose a revised configuration for the next run. This
configuration rewrites the prompt, updates memory by logging effective
state-action choices, tunes hyperparameters, and learns the tool-use routines.
On our J-TTL benchmark, EvoTest consistently increases performance,
outperforming not only reflection and memory-only baselines but also more
complex online fine-tuning methods. Notably, our method is the only one capable
of winning two games (Detective and Library), while all baselines fail to win
any.

</details>


### [122] [An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities](https://arxiv.org/abs/2510.13230)
*Jalal Khan,Manzoor Khan,Sherzod Turaev,Sumbal Malik,Hesham El-Sayed,Farman Ullah*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于效用的分析模型，使自动驾驶汽车的感知系统能够理解驾驶环境。


<details>
  <summary>Details</summary>
Motivation: 开发能够准确感知道路上多个物体并预测驾驶员感知的模型，以控制汽车的运动。

Method: 获取包含独特物体的自定义数据集；一个基于深度学习的模型（YOLOv8s）用于物体检测；以及一个从训练模型实例的性能值中衡量感知服务效用的模块。

Result: 实验结果显示了三个基于 mAP@0.5 值表现最佳的 YOLOv8s 实例，即基于 SGD 的（0.832）、基于 Adam 的（0.810）和基于 AdamW 的（0.822）。

Conclusion: 验证了所提出的功能能够为自动驾驶汽车找到正确的感知。

Abstract: The driving environment perception has a vital role for autonomous driving
and nowadays has been actively explored for its realization. The research
community and relevant stakeholders necessitate the development of Deep
Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles
(AVs) for smart mobility. There is a need to develop a model that accurately
perceives multiple objects on the road and predicts the driver's perception to
control the car's movements. This article proposes a novel utility-based
analytical model that enables perception systems of AVs to understand the
driving environment. The article consists of modules: acquiring a custom
dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a
DL-based model (YOLOv8s) for object detection; and a module to measure the
utility of perception service from the performance values of trained model
instances. The perception model is validated based on the object detection
task, and its process is benchmarked by state-of-the-art deep learning models'
performance metrics from the nuScense dataset. The experimental results show
three best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,
SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the
AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)
still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,
truck: 0.781, etc.) because it has better class-level performance values,
confirmed by the proposed perception model. We validate that the proposed
function is capable of finding the right perception for AVs. The results above
encourage using the proposed perception model to evaluate the utility of
learning models and determine the appropriate perception for AVs.

</details>


### [123] [SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2510.13262)
*Weiqi Guo,Guanjun Liu,Ziyuan Zhou*

Main category: cs.AI

TL;DR: 提出了一种新的状态-动作联合攻击（SAJA）框架，用于评估多智能体深度强化学习（MADRL）模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在仅状态攻击或仅动作攻击，但没有考虑到如何有效地结合它们。

Method: SAJA框架包含两个阶段：(1) 状态攻击阶段，利用actor网络和critic网络计算对抗状态；(2) 在动作攻击阶段，基于扰动状态，使用critic网络来生成最终的对抗动作。此外，还添加了一个启发式正则化器，用于衡量扰动动作和原始动作之间的距离。

Result: 在多智能体粒子环境（MPE）中评估SAJA，证明了它优于并且比仅状态或仅动作攻击更隐蔽，并且现有的状态或动作防御方法无法防御其攻击。

Conclusion: SAJA框架能够有效地攻击多智能体深度强化学习模型，并且比现有的攻击方法更有效。

Abstract: Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for
cooperative and competitive tasks such as autonomous driving and strategic
gaming. However, models trained by MADRL are vulnerable to adversarial
perturbations on states and actions. Therefore, it is essential to investigate
the robustness of MADRL models from an attack perspective. Existing studies
focus on either state-only attacks or action-only attacks, but do not consider
how to effectively joint them. Simply combining state and action perturbations
such as randomly perturbing states and actions does not exploit their potential
synergistic effects. In this paper, we propose the State-Action Joint Attack
(SAJA) framework that has a good synergistic effects. SAJA consists of two
important phases: (1) In the state attack phase, a multi-step gradient ascent
method utilizes both the actor network and the critic network to compute an
adversarial state, and (2) in the action attack phase, based on the perturbed
state, a second gradient ascent uses the critic network to craft the final
adversarial action. Additionally, a heuristic regularizer measuring the
distance between the perturbed actions and the original clean ones is added
into the loss function to enhance the effectiveness of the critic's guidance.
We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating
that (1) it outperforms and is more stealthy than state-only or action-only
attacks, and (2) existing state or action defense methods cannot defend its
attacks.

</details>


### [124] [Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization](https://arxiv.org/abs/2510.13393)
*Yunxiao Zhao,Zhiqiang Wang,Xingtong Yu,Xiaoli Li,Jiye Liang,Ru Li*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于博弈论策略优化的方法 (PORAT) 来解决传统 rationalization 方法中的 mode collapse 问题，该方法通过逐步引入策略干预来引导模型达到更优的博弈均衡状态。


<details>
  <summary>Details</summary>
Motivation: 传统 rationalization 方法存在 mode collapse 问题，即预测器产生正确预测但生成器持续输出具有 collapsed patterns 的 rationales。现有的研究通常是为特定的 collapsed patterns 单独设计的，缺乏统一的考虑。

Method: 本文从博弈论的角度重新审视了 cooperative rationalization，并提出了 Game-theoretic Policy Optimization oriented RATionalization (PORAT) 方法，该方法通过逐步引入策略干预来解决博弈均衡问题。

Result: 在九个广泛使用的真实世界数据集和两个合成数据集上验证了 PORAT 方法，结果表明 PORAT 相比现有 state-of-the-art 方法取得了高达 8.1% 的性能提升。

Conclusion: 本文通过博弈论分析了 suboptimal equilibrium 的原因，并证明了所提出方法的可行性，实验结果验证了 PORAT 方法的有效性。

Abstract: Rationalization, a data-centric framework, aims to build self-explanatory
models to explain the prediction outcome by generating a subset of
human-intelligible pieces of the input data. It involves a cooperative game
model where a generator generates the most human-intelligible parts of the
input (i.e., rationales), followed by a predictor that makes predictions based
on these generated rationales. Conventional rationalization methods typically
impose constraints via regularization terms to calibrate or penalize undesired
generation. However, these methods are suffering from a problem called mode
collapse, in which the predictor produces correct predictions yet the generator
consistently outputs rationales with collapsed patterns. Moreover, existing
studies are typically designed separately for specific collapsed patterns,
lacking a unified consideration. In this paper, we systematically revisit
cooperative rationalization from a novel game-theoretic perspective and
identify the fundamental cause of this problem: the generator no longer tends
to explore new strategies to uncover informative rationales, ultimately leading
the system to converge to a suboptimal game equilibrium (correct predictions
v.s collapsed rationales). To solve this problem, we then propose a novel
approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),
which progressively introduces policy interventions to address the game
equilibrium in the cooperative game process, thereby guiding the model toward a
more optimal solution state. We theoretically analyse the cause of such a
suboptimal equilibrium and prove the feasibility of the proposed method.
Furthermore, we validate our method on nine widely used real-world datasets and
two synthetic settings, where PORAT achieves up to 8.1% performance
improvements over existing state-of-the-art methods.

</details>


### [125] [Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse](https://arxiv.org/abs/2510.13417)
*Liesbeth Allein,Nataly Pineda-Castañeda,Andrea Rocci,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 大型语言模型在因果链发现任务中表现出一定的能力，但其判断主要基于关联模式匹配而非真正的因果推理。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLM）在解释因果关系中的机制因果推理能力，通过隐式因果链发现任务来考察。

Method: 使用诊断评估框架，指示九个LLM生成连接气候变化讨论中给定的因果对的所有可能的中间因果步骤。

Result: LLM在生成的因果步骤的数量和粒度上有所不同，虽然它们通常对生成的链中的中间因果关系具有自我一致性和信心，但它们的判断主要由联想模式匹配驱动，而不是真正的因果推理。

Conclusion: 该研究为推进论证环境中隐式、机械的因果推理的未来工作奠定了坚实的基础。

Abstract: How does a cause lead to an effect, and which intermediate causal steps
explain their connection? This work scrutinizes the mechanistic causal
reasoning capabilities of large language models (LLMs) to answer these
questions through the task of implicit causal chain discovery. In a diagnostic
evaluation framework, we instruct nine LLMs to generate all possible
intermediate causal steps linking given cause-effect pairs in causal chain
structures. These pairs are drawn from recent resources in argumentation
studies featuring polarized discussion on climate change. Our analysis reveals
that LLMs vary in the number and granularity of causal steps they produce.
Although they are generally self-consistent and confident about the
intermediate causal connections in the generated chains, their judgments are
mainly driven by associative pattern matching rather than genuine causal
reasoning. Nonetheless, human evaluations confirmed the logical coherence and
integrity of the generated chains. Our baseline causal chain discovery
approach, insights from our diagnostic evaluation, and benchmark dataset with
causal chains lay a solid foundation for advancing future work in implicit,
mechanistic causal reasoning in argumentation settings.

</details>


### [126] [Mobile Coverage Analysis using Crowdsourced Data](https://arxiv.org/abs/2510.13459)
*Timothy Wong,Tom Freeman,Joseph Feehily*

Main category: cs.AI

TL;DR: 本文利用众包 QoE 数据，提出了一种移动网络覆盖和弱点分析的新框架。


<details>
  <summary>Details</summary>
Motivation: 为了提升用户体验，移动网络运营商需要有效地评估移动网络覆盖和精确识别服务弱点。

Method: 该方法的核心是在小区（天线）层面进行覆盖分析，然后使用经验地理位置数据汇总到站点层面。使用 One-Class Support Vector Machine (OC-SVM) 算法来计算移动网络覆盖。

Result: 研究结果表明，该框架能够准确地绘制移动覆盖地图，并突出显示信号不足的区域，尤其是在复杂的城市环境中。

Conclusion: 本文提出的框架能够有效地映射移动覆盖，并突出显示信号弱点区域。

Abstract: Effective assessment of mobile network coverage and the precise
identification of service weak spots are paramount for network operators
striving to enhance user Quality of Experience (QoE). This paper presents a
novel framework for mobile coverage and weak spot analysis utilising
crowdsourced QoE data. The core of our methodology involves coverage analysis
at the individual cell (antenna) level, subsequently aggregated to the site
level, using empirical geolocation data. A key contribution of this research is
the application of One-Class Support Vector Machine (OC-SVM) algorithm for
calculating mobile network coverage. This approach models the decision
hyperplane as the effective coverage contour, facilitating robust calculation
of coverage areas for individual cells and entire sites. The same methodology
is extended to analyse crowdsourced service loss reports, thereby identifying
and quantifying geographically localised weak spots. Our findings demonstrate
the efficacy of this novel framework in accurately mapping mobile coverage and,
crucially, in highlighting granular areas of signal deficiency, particularly
within complex urban environments.

</details>


### [127] [Confidence as a Reward: Transforming LLMs into Reward Models](https://arxiv.org/abs/2510.13501)
*He Du,Bowen Li,Chengxing Xie,Chang Gao,Kai Chen,Dacheng Tao*

Main category: cs.AI

TL;DR: 提出了一种名为 Confidence-as-a-Reward (CRew) 的免训练方法，利用模型在最终答案中的 token 级别置信度作为奖励代理，尤其适用于封闭式任务。


<details>
  <summary>Details</summary>
Motivation: 奖励模型可以显著增强大型语言模型 (LLM) 的推理能力，但它们通常需要大量的精选数据和昂贵的训练。为了缓解这些挑战，像 LLM-as-a-Judge 这样的免训练方法利用 LLM 的内在推理能力来评估响应，取得了可喜的成果。最近的研究也表明，模型置信度可以有效地作为奖励指标，区分思维链 (CoT) 和非 CoT 路径。然而，使用置信度作为奖励的概念尚未得到全面研究。

Method: 系统地研究 Confidence-as-a-Reward (CRew)，这是一种简单而强大的免训练方法，它利用模型最终答案中的 token 级别置信度作为奖励代理，尤其适用于封闭式任务。此外，提出了 CRew-DPO，一种训练策略，它构建来自置信度分数和正确性信号的偏好数据。

Result: 在数学推理任务上进行了广泛的实验，证明 CRew 在 MATH500 和 RewardMATH 基准测试中优于现有的免训练奖励方法，甚至超过了大多数经过训练的奖励模型。CRew 分数与模型的实际推理性能之间存在很强的相关性。CRew 可以有效地过滤高质量的训练数据。使用 CRew-DPO 进行微调进一步增强了模型的判断能力，并且始终优于现有的自我训练方法。

Conclusion: CRew 是一种有前景的免训练奖励方法，可以提高大型语言模型在封闭式任务中的推理能力。

Abstract: Reward models can significantly enhance the reasoning capabilities of large
language models (LLMs), but they typically require extensive curated data and
costly training. To mitigate these challenges, training-free approaches such as
LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate
responses, achieving promising results. Recent works have also indicated that
model confidence can serve effectively as a reward metric, distinguishing
between chain-of-thought (CoT) and non-CoT paths. However, the concept of using
confidence as a reward has not been comprehensively studied. In this work, we
systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful
training-free method that utilizes token-level confidence in the model's final
answers as a proxy for reward, especially suitable for close-ended tasks.
Through extensive experiments on mathematical reasoning tasks, we demonstrate
that CRew outperforms existing training-free reward approaches on the MATH500
and RewardMATH benchmarks, and even surpasses most trained reward models. We
further identify a strong correlation between CRew scores and the actual
reasoning performance of the model. Additionally, we find that CRew can
effectively filter high-quality training data. Building upon these insights, we
propose CRew-DPO, a training strategy that constructs preference data from
confidence scores combined with correctness signals. Finetuning with CRew-DPO
further enhances the model's judging capabilities and consistently outperforms
existing self-training methods.

</details>


### [128] [A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain](https://arxiv.org/abs/2510.13524)
*William Flanagan,Mukunda Das,Rajitha Ramanyake,Swaunja Maslekar,Meghana Manipuri,Joong Ho Choi,Shruti Nair,Shambhavi Bhusan,Sanjana Dulam,Mouni Pendharkar,Nidhi Singh,Vashisth Doshi,Sachi Shah Paresh*

Main category: cs.AI

TL;DR: 传统机器学习指标不适用于通用人工智能工作负载，需要专家评估。许多项目未能考虑到选择特定指标时存在的各种独特风险。此外，基础研究实验室和教育机构创建的许多广泛使用的基准未能推广到工业用途。本文解释了这些挑战，并提供了一个风险评估框架，以便更好地应用中小企业和机器学习指标。


<details>
  <summary>Details</summary>
Motivation: 在金融服务行业采用通用人工智能之际，衡量模型性能是一个重要的应用和使用障碍。

Method: 提供风险评估框架

Result: 允许更好地应用中小企业和机器学习指标

Conclusion: 解释了传统机器学习指标不适用于通用人工智能工作负载的挑战，并提供了一个风险评估框架。

Abstract: As Generative Artificial Intelligence is adopted across the financial
services industry, a significant barrier to adoption and usage is measuring
model performance. Historical machine learning metrics can oftentimes fail to
generalize to GenAI workloads and are often supplemented using Subject Matter
Expert (SME) Evaluation. Even in this combination, many projects fail to
account for various unique risks present in choosing specific metrics.
Additionally, many widespread benchmarks created by foundational research labs
and educational institutions fail to generalize to industrial use. This paper
explains these challenges and provides a Risk Assessment Framework to allow for
better application of SME and machine learning Metrics

</details>


### [129] [Tandem Training for Language Models](https://arxiv.org/abs/2510.13551)
*Robert West,Ashton Anderson,Ece Kamar,Eric Horvitz*

Main category: cs.AI

TL;DR: 本文提出了一种使语言模型更易于理解的方法，即使对于能力较弱的智能体或人类也是如此。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型的快速发展，其行为和推理变得难以理解，从而削弱了可解释性和监督。

Method: 本文提出了串联训练，这是一种强化学习范式，其中 rollout tokens 间歇且随机地从一个冻结的弱模型中采样，而不是从被训练的强模型中采样。

Result: 在 GSM8K 数学推理任务中，串联训练可靠地教会模型放弃术语并调整其语言以适应较弱的伙伴，同时保持较高的任务准确性。

Conclusion: 串联训练是构建可被较弱智能体审核的 AI 系统的一条有希望的途径，对人机协作和多智能体通信具有影响。

Abstract: As language models continue to rapidly improve, we can expect their actions
and reasoning to become difficult or impossible for weaker agents and humans to
follow, undermining interpretability and oversight. With an eye on long-term
futures, we pursue methods that encourage models to produce solutions that
remain intelligible to weaker collaborators. We formalize intelligibility as
handoff robustness: a strong model's solution is intelligible to a weaker model
if randomly handing off control to the weaker model along the solution path
does not cause failure. Building on this criterion, we introduce tandem
training for language models, a reinforcement learning (RL) paradigm in which
rollout tokens are intermittently and randomly sampled from a frozen weak model
rather than the strong model being trained. Because rollouts succeed only when
the strong model's actions and reasoning process can be continued by the weak
model -- when the two can co-construct a successful solution -- optimizing
standard RL objectives with tandem training implicitly incentivizes both
correctness and intelligibility. In the GSM8K math reasoning task, tandem
training reliably teaches models to abandon jargon and adapt their language to
weaker partners while keeping task accuracy high. Our results demonstrate a
promising route to building AI systems that remain auditable by weaker agents,
with implications for human--AI collaboration and multi-agent communication.

</details>


### [130] [A Modal Logic for Temporal and Jurisdictional Classifier Models](https://arxiv.org/abs/2510.13691)
*Cecilia Di Florio,Huimin Dong,Antonino Rotolo*

Main category: cs.AI

TL;DR: 本文提出了一种用于捕获法律领域基于案例的推理 (CBR) 的模态逻辑。


<details>
  <summary>Details</summary>
Motivation: 在法律领域，机器学习 (ML) 分类器可以根据先前的案例预测新案例的结果，从而执行一种基于案例的推理 (CBR)。

Method: 引入案例的时间维度和法律系统内的法院层级，将解决先例之间冲突的原则纳入逻辑中。

Result: 形式化地捕捉法律 CBR。

Conclusion: 逻辑模型可用于为法律领域中使用的机器学习分类器构建验证工具。

Abstract: Logic-based models can be used to build verification tools for machine
learning classifiers employed in the legal field. ML classifiers predict the
outcomes of new cases based on previous ones, thereby performing a form of
case-based reasoning (CBR). In this paper, we introduce a modal logic of
classifiers designed to formally capture legal CBR. We incorporate principles
for resolving conflicts between precedents, by introducing into the logic the
temporal dimension of cases and the hierarchy of courts within the legal
system.

</details>


### [131] [Training LLM Agents to Empower Humans](https://arxiv.org/abs/2510.13709)
*Evan Ellis,Vivek Myers,Jens Tuyls,Sergey Levine,Anca Dragan,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: 提出了一种新的方法来调整辅助语言模型，基于最大化人类的自主能力，只需要离线文本数据，为微调语言模型以更好地帮助人类提供了一种自监督方法。


<details>
  <summary>Details</summary>
Motivation: 当前的辅助智能体构建方法，无论是通过模仿人类专家还是通过强化学习对推断的奖励进行微调，通常鼓励智能体自主完成任务，而不是真正帮助人类实现他们的目标。此外，这些方法通常需要昂贵的显式人工反馈来提供训练信号。

Method: 提出了一种新的方法，即Empower，基于最大化人类的自主能力来调整辅助语言模型，只需要离线文本数据，提供了一种自监督方法来微调语言模型以更好地帮助人类。

Result: 在18人的用户研究中，参与者在78%的时间里更喜欢我们的助手(p=0.015)，接受率高出31%，建议少38%。此外，我们引入了一个新的环境，用于评估使用模拟人类进行多轮代码辅助。在这个环境中，我们表明，使用Empower训练的智能体，在具有挑战性的编码问题上，模拟人类程序员的成功率比SFT基线平均提高了192%。

Conclusion: 通过这种自主能力目标，我们提供了一个框架，可以使用仅离线数据，而无需任何额外的人工反馈或可验证的奖励，来实现有用的对齐AI智能体。

Abstract: Assistive agents should not only take actions on behalf of a human, but also
step out of the way and cede control when there are important decisions to be
made. However, current methods for building assistive agents, whether via
mimicking expert humans or via RL finetuning on an inferred reward, often
encourage agents to complete tasks on their own rather than truly assisting the
human attain their objectives. Additionally, these methods often require costly
explicit human feedback to provide a training signal. We propose a new approach
to tuning assistive language models based on maximizing the human's
empowerment, their ability to effect desired changes in the environment. Our
empowerment-maximizing method, Empower, only requires offline text data,
providing a self-supervised method for fine-tuning language models to better
assist humans. To study the efficacy of our approach, we conducted an 18-person
user study comparing our empowerment assistant with a strong baseline.
Participants preferred our assistant 78% of the time (p=0.015), with a 31%
higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a
new environment for evaluating multi-turn code assistance using simulated
humans. Using this environment, we show that agents trained with Empower
increase the success rate of a simulated human programmer on challenging coding
questions by an average of 192% over an SFT baseline. With this empowerment
objective, we provide a framework for useful aligned AI agents at scale using
only offline data without the need for any additional human feedback or
verifiable rewards.

</details>


### [132] [From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails](https://arxiv.org/abs/2510.13727)
*Ravi Pandya,Madison Bland,Duy P. Nguyen,Changliu Liu,Jaime Fernández Fisac,Andrea Bajcsy*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的AI安全防护方法，通过控制理论来预测和纠正AI系统的风险行为，以防止造成财务或人身伤害等严重后果，从而取代了目前常用的基于标签数据和人工规则的静态防护方法。


<details>
  <summary>Details</summary>
Motivation: 现有的AI安全防护系统依赖于输出分类，容易在新出现的危险情况下失效，且缺乏补救措施。因此，需要一种能够主动预测和纠正风险行为的动态安全防护方法。

Method: 该论文从安全关键控制理论的角度，将AI安全问题形式化为一个序列决策问题，并在AI模型的潜在表征中构建预测性防护栏。通过安全关键强化学习，可以大规模地训练这种防护栏。

Result: 在模拟驾驶和电子商务环境中的实验表明，基于控制理论的防护栏可以有效地避免灾难性后果，同时保持任务性能。

Conclusion: 基于控制理论的防护栏为目前的AI安全防护提供了一种动态的、有原则的替代方案，能够可靠地引导LLM智能体避开灾难性后果，同时保持任务性能。

Abstract: Generative AI systems are increasingly assisting and acting on behalf of end
users in practical settings, from digital shopping assistants to
next-generation autonomous cars. In this context, safety is no longer about
blocking harmful content, but about preempting downstream hazards like
financial or physical harm. Yet, most AI guardrails continue to rely on output
classification based on labeled datasets and human-specified criteria,making
them brittle to new hazardous situations. Even when unsafe conditions are
flagged, this detection offers no path to recovery: typically, the AI system
simply refuses to act--which is not always a safe choice. In this work, we
argue that agentic AI safety is fundamentally a sequential decision problem:
harmful outcomes arise from the AI system's continually evolving interactions
and their downstream consequences on the world. We formalize this through the
lens of safety-critical control theory, but within the AI model's latent
representation of the world. This enables us to build predictive guardrails
that (i) monitor an AI system's outputs (actions) in real time and (ii)
proactively correct risky outputs to safe ones, all in a model-agnostic manner
so the same guardrail can be wrapped around any AI model. We also offer a
practical training recipe for computing such guardrails at scale via
safety-critical reinforcement learning. Our experiments in simulated driving
and e-commerce settings demonstrate that control-theoretic guardrails can
reliably steer LLM agents clear of catastrophic outcomes (from collisions to
bankruptcy) while preserving task performance, offering a principled dynamic
alternative to today's flag-and-block guardrails.

</details>


### [133] [Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math](https://arxiv.org/abs/2510.13744)
*Shrey Pandit,Austin Xu,Xuan-Phi Nguyen,Yifei Ming,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: 本研究介绍了一个名为 Hard2Verify 的人工标注、步骤级验证基准，用于评估大型语言模型在复杂数学问题上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了训练能够进行复杂、开放式推理的大型语言模型，需要强大的验证器来捕捉步骤级的错误。

Method: 通过 500 多个小时的人工标注，构建了一个步骤级验证基准 Hard2Verify，并评估了 29 个生成式评论员和过程奖励模型。

Result: 结果表明，除了少数表现突出的模型外，开源验证器的性能落后于闭源模型。

Conclusion: 分析了步骤级验证性能不佳的原因，验证器计算规模的影响，以及自我验证和验证-生成动态等基本问题。

Abstract: Large language model (LLM)-based reasoning systems have recently achieved
gold medal-level performance in the IMO 2025 competition, writing mathematical
proofs where, to receive full credit, each step must be not only correct but
also sufficiently supported. To train LLM-based reasoners in such challenging,
open-ended settings, strong verifiers capable of catching step-level mistakes
are necessary prerequisites. We introduce Hard2Verify, a human-annotated,
step-level verification benchmark produced with over 500 hours of human labor.
Hard2Verify is designed to rigorously assess step-level verifiers at the
frontier: Verifiers must provide step-level annotations or identify the first
error in responses generated by frontier LLMs for very recent, challenging, and
open-ended math questions. We evaluate 29 generative critics and process reward
models, demonstrating that, beyond a few standouts, open-source verifiers lag
closed source models. We subsequently analyze what drives poor performance in
step-level verification, the impacts of scaling verifier compute, as well as
fundamental questions such as self-verification and verification-generation
dynamics.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [134] [Experiments \& Analysis of Privacy-Preserving SQL Query Sanitization Systems](https://arxiv.org/abs/2510.13528)
*Loïs Ecoffet,Veronika Rehn-Sonigo,Jean-François Couchot,Catuscia Palamidessi*

Main category: cs.DB

TL;DR: 本文对现有的SQL查询脱敏系统进行了系统性的分类，并从数据效用、查询执行开销和隐私保证等方面对领先的系统进行了定量分析。


<details>
  <summary>Details</summary>
Motivation: 分析型SQL查询在从关系数据库中提取信息时至关重要，但同时也带来了潜在的隐私风险。为了缓解这些风险，人们开发了许多查询脱敏系统，但这些系统的方法各不相同，这使得研究人员和从业人员很难理解。

Method: 本文基于定性标准（如隐私模型、受保护的隐私单元和软件架构）和查询范围对现有的SQL脱敏系统进行了系统分类。此外，我们还对领先的系统进行了定量分析，通过一系列分析查询来衡量数据效用、查询执行开销和隐私保证之间的权衡。

Result: 本文对领先的系统进行了定量分析，通过一系列分析查询来衡量数据效用、查询执行开销和隐私保证之间的权衡。

Conclusion: 这项工作提供了一个结构化的概述和性能评估，旨在阐明当前保护隐私的数据库技术的能力和局限性。

Abstract: Analytical SQL queries are essential for extracting insights from relational
databases but concurrently introduce significant privacy risks by potentially
exposing sensitive information. To mitigate these risks, numerous query
sanitization systems have been developed, employing diverse approaches that
create a complex landscape for both researchers and practitioners. These
systems vary fundamentally in their design, including the underlying privacy
model, such as k-anonymity or Differential Privacy; the protected privacy unit,
whether at the tuple- or user-level; and the software architecture, which can
be proxy-based or integrated. This paper provides a systematic classification
of state-of-the-art SQL sanitization systems based on these qualitative
criteria and the scope of queries they support. Furthermore, we present a
quantitative analysis of leading systems, empirically measuring the trade-offs
between data utility, query execution overhead, and privacy guarantees across a
range of analytical queries. This work offers a structured overview and
performance assessment intended to clarify the capabilities and limitations of
current privacy-preserving database technologies.

</details>


### [135] [The Past Still Matters: A Temporally-Valid Data Discovery System](https://arxiv.org/abs/2510.13662)
*Mahdi Esmailoghli,Matthias Weidlich*

Main category: cs.DB

TL;DR: 现有的数据发现方法忽略了时间维度，尤其是在缺少显式的日期/时间元数据时。本文提出了一个包含数据时间维度的数据发现系统。


<details>
  <summary>Details</summary>
Motivation: 在过去十年中，公共和企业数据湖的激增推动了对数据发现的深入研究，旨在从庞大而复杂的数据集中识别出最相关的数据，以支持各种用户任务。尽管在创新索引结构、相似性度量和查询基础设施的开发方面取得了显著进展，但一个关键方面仍被忽视：相关性是随时间变化的。

Method: 定义了时间有效的数据发现问题，并提出解决该问题需要版本发现、时间沿袭推理、变更日志合成和时间感知数据发现等技术。然后，提出了一个系统架构来提供这些技术。

Result: 概述了一个数据发现系统，该系统结合了数据的时间维度。

Conclusion: 为新型数据发现系统奠定了基础，改变了我们与不断发展的数据湖互动的方式。

Abstract: Over the past decade, the proliferation of public and enterprise data lakes
has fueled intensive research into data discovery, aiming to identify the most
relevant data from vast and complex corpora to support diverse user tasks.
Significant progress has been made through the development of innovative index
structures, similarity measures, and querying infrastructures. Despite these
advances, a critical aspect remains overlooked: relevance is time-varying.
Existing discovery methods largely ignore this temporal dimension, especially
when explicit date/time metadata is missing. To fill this gap, we outline a
vision for a data discovery system that incorporates the temporal dimension of
data. Specifically, we define the problem of temporally-valid data discovery
and argue that addressing it requires techniques for version discovery,
temporal lineage inference, change log synthesis, and time-aware data
discovery. We then present a system architecture to deliver these techniques,
before we summarize research challenges and opportunities. As such, we lay the
foundation for a new class of data discovery systems, transforming how we
interact with evolving data lakes.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [136] [Energy-Guided Diffusion Sampling for Long-Term User Behavior Prediction in Reinforcement Learning-based Recommendation](https://arxiv.org/abs/2510.12815)
*Xiaocong Chen,Siyu Wang,Lina Yao*

Main category: cs.IR

TL;DR: 提出了一种名为DAC4Rec的离线强化学习推荐系统框架，该框架集成了扩散过程与强化学习，以更有效地模拟复杂的用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有的RL4RS系统在离线环境中面临数据效率低下和依赖预收集轨迹的挑战，且难以捕捉长期用户偏好，导致推荐策略欠优。

Method: 结合扩散模型的去噪能力来增强离线RL算法的鲁棒性，并结合Q值引导的策略优化策略来更好地处理次优轨迹。此外，引入了一种基于能量的采样策略，以减少推荐生成过程中的随机性。

Result: 在六个真实世界的离线数据集和在线模拟环境中进行了大量实验，验证了DAC4Rec优化长期用户偏好的能力。

Conclusion: 所提出的扩散策略可以无缝集成到RL4RS中其他常用的RL算法中，突出了其通用性和广泛的适用性。

Abstract: Reinforcement learning-based recommender systems (RL4RS) have gained
attention for their ability to adapt to dynamic user preferences. However,
these systems face challenges, particularly in offline settings, where data
inefficiency and reliance on pre-collected trajectories limit their broader
applicability. While offline reinforcement learning methods leverage extensive
datasets to address these issues, they often struggle with noisy data and fail
to capture long-term user preferences, resulting in suboptimal recommendation
policies. To overcome these limitations, we propose Diffusion-enhanced
Actor-Critic for Offline RL4RS (DAC4Rec), a novel framework that integrates
diffusion processes with reinforcement learning to model complex user
preferences more effectively. DAC4Rec leverages the denoising capabilities of
diffusion models to enhance the robustness of offline RL algorithms and
incorporates a Q-value-guided policy optimization strategy to better handle
suboptimal trajectories. Additionally, we introduce an energy-based sampling
strategy to reduce randomness during recommendation generation, ensuring more
targeted and reliable outcomes. We validate the effectiveness of DAC4Rec
through extensive experiments on six real-world offline datasets and in an
online simulation environment, demonstrating its ability to optimize long-term
user preferences. Furthermore, we show that the proposed diffusion policy can
be seamlessly integrated into other commonly used RL algorithms in RL4RS,
highlighting its versatility and wide applicability.

</details>


### [137] [Maximum In-Support Return Modeling for Dynamic Recommendation with Language Model Prior](https://arxiv.org/abs/2510.12816)
*Xiaocong Chen,Siyu Wang,Lina Yao*

Main category: cs.IR

TL;DR: MDT4Rec: An offline RLRS framework using Decision Transformer to handle sub-optimal data and complex interactions.


<details>
  <summary>Details</summary>
Motivation: RLRS struggles with sub-optimal/sparse user feedback in real-world settings.

Method: Shifts trajectory stitching to action inference, uses pre-trained LLM for initialization, replaces linear layers with MLPs, and employs LoRA for efficient fine-tuning.

Result: Outperforms existing methods on five public datasets and in online simulations.

Conclusion: MDT4Rec effectively addresses challenges in real-world RLRS by learning from sub-optimal histories and representing complex user-item interactions.

Abstract: Reinforcement Learning-based recommender systems (RLRS) offer an effective
way to handle sequential recommendation tasks but often face difficulties in
real-world settings, where user feedback data can be sub-optimal or sparse. In
this paper, we introduce MDT4Rec, an offline RLRS framework that builds on the
Decision Transformer (DT) to address two major challenges: learning from
sub-optimal histories and representing complex user-item interactions. First,
MDT4Rec shifts the trajectory stitching procedure from the training phase to
action inference, allowing the system to shorten its historical context when
necessary and thereby ignore negative or unsuccessful past experiences. Second,
MDT4Rec initializes DT with a pre-trained large language model (LLM) for
knowledge transfer, replaces linear embedding layers with Multi-Layer
Perceptrons (MLPs) for more flexible representations, and employs Low-Rank
Adaptation (LoRA) to efficiently fine-tune only a small subset of parameters.
We evaluate MDT4Rec on five public datasets and in an online simulation
environment, demonstrating that it outperforms existing methods.

</details>


### [138] [Post-hoc Popularity Bias Correction in GNN-based Collaborative Filtering](https://arxiv.org/abs/2510.12959)
*Md Aminul Islam,Elena Zheleva,Ren Wang*

Main category: cs.IR

TL;DR: 这篇论文提出了一种名为Post-hoc Popularity Debiasing (PPD)的方法，用于修正基于GNN的CF中的流行度偏差，且无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 协同过滤(CF)中的用户历史交互数据是学习用户偏好的主要信号。然而，训练数据通常呈现长尾分布，导致流行度偏差，降低了个性化推荐质量。GNN虽然有效，但也可能通过聚合过程传播和放大流行度偏差。

Method: 该方法通过估计交互级别的流行度，并利用流行度方向向量从节点表示中移除流行度成分，从而减少偏差，同时保留用户偏好。

Result: 实验结果表明，该方法优于GNN-based CF中用于流行度偏差校正的state-of-the-art方法。

Conclusion: 该论文提出了一种有效的后处理方法，可以在不重新训练的情况下，有效地减少GNN-based CF中的流行度偏差。

Abstract: User historical interaction data is the primary signal for learning user
preferences in collaborative filtering (CF). However, the training data often
exhibits a long-tailed distribution, where only a few items have the majority
of interactions. CF models trained directly on such imbalanced data are prone
to learning popularity bias, which reduces personalization and leads to
suboptimal recommendation quality. Graph Neural Networks (GNNs), while
effective for CF due to their message passing mechanism, can further propagate
and amplify popularity bias through their aggregation process. Existing
approaches typically address popularity bias by modifying training objectives
but fail to directly counteract the bias propagated during GNN's neighborhood
aggregation. Applying weights to interactions during aggregation can help
alleviate this problem, yet it risks distorting model learning due to unstable
node representations in the early stages of training. In this paper, we propose
a Post-hoc Popularity Debiasing (PPD) method that corrects for popularity bias
in GNN-based CF and operates directly on pre-trained embeddings without
requiring retraining. By estimating interaction-level popularity and removing
popularity components from node representations via a popularity direction
vector, PPD reduces bias while preserving user preferences. Experimental
results show that our method outperforms state-of-the-art approaches for
popularity bias correction in GNN-based CF.

</details>


### [139] [Retrieval-in-the-Chain: Bootstrapping Large Language Models for Generative Retrieval](https://arxiv.org/abs/2510.13095)
*Yingchen zhang,Ruqing zhang,Jiafeng Guo,Wenjun Peng,Sen Li,Fuyu Lv*

Main category: cs.IR

TL;DR: 这篇论文提出了一种名为Reason-for-Retrieval (R4R)的框架，用于增强生成式检索(GR)。R4R利用大型语言模型(LLM)的推理能力，将自由形式的CoT推理转化为紧凑的结构化格式，并在检索过程中迭代地改进推理。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式检索(GR)研究主要集中于利用大型语言模型(LLM)的生成能力来改进GR，而忽略了它们的推理能力可能同样有帮助。因此，研究人员提出了一个关键问题：显式推理是否可以使GR受益？

Method: 该论文提出Reason-for-Retrieval (R4R)，它将自由形式的CoT推理转换为紧凑的结构化格式，并在检索过程中迭代地改进推理。R4R通过利用一个已经过指令调整的、具有推理能力的LLM来增强现有的GR方法。在推理时，R4R首先使用LLM生成一个初始的结构化推理；然后，同一个LLM在(i)使用所选的GR方法进行约束解码以生成候选docid和(ii)基于检索结果更新推理以改进下一轮之间交替进行。

Result: 在Natural Questions、MS MARCO和一个真实世界的物品搜索基准上的大量实验验证了R4R的有效性。

Conclusion: R4R不需要额外的模型或训练，而是由单个LLM同时作为推理生成器和检索器。

Abstract: Generative retrieval (GR) is an emerging paradigm that leverages large
language models (LLMs) to autoregressively generate document identifiers
(docids) relevant to a given query. Prior works have focused on leveraging the
generative capabilities of LLMs to improve GR, while overlooking that their
reasoning capabilities could likewise help. This raises a key question: Can
explicit reasoning benefit GR? To investigate, we first conduct a preliminary
study where an LLM is prompted to generate free-form chain-of-thought (CoT)
reasoning before performing constrained docid decoding. Although this method
outperforms standard GR, the generated reasoning tends to be verbose and poorly
aligned with the docid space. These limitations motivate the development of a
reasoning mechanism better tailored to GR.
  Therefore, we propose Reason-for-Retrieval (R4R), a reasoning-augmented
framework for GR that converts free-form CoT reasoning into a compact,
structured format, and iteratively refines the reasoning during the retrieval
process. R4R augments an existing GR method by leveraging a reasoning-capable
LLM that has been instruction-tuned for GR. At inference time, R4R first uses
the LLM to generate an initial structured reasoning; then the same LLM
alternates between (i) constrained decoding with the chosen GR method to
produce candidate docids and (ii) updating the reasoning based on retrieval
results to improve the next round. R4R does not require additional models or
training, and instead a single LLM serves as both the reasoning generator and
the retriever. Extensive experiments on Natural Questions, MS MARCO, and a
real-world item-search benchmark validate the effectiveness of R4R.

</details>


### [140] [ReMindRAG: Low-Cost LLM-Guided Knowledge Graph Traversal for Efficient RAG](https://arxiv.org/abs/2510.13193)
*Yikuan Hu,Jifeng Zhu,Lanrui Tang,Chen Huang*

Main category: cs.IR

TL;DR: 提出了一种新的知识图谱增强检索增强生成 (KG-RAG) 系统，名为 REMINDRAG，旨在提高系统有效性和成本效率。


<details>
  <summary>Details</summary>
Motivation: 现有的 KG-RAG 系统在系统有效性和成本效率之间难以达到有效的协同。

Method: REMINDRAG 采用 LLM 指导的图遍历，具有节点探索、节点利用以及记忆重放功能。它在 KG 边缘嵌入中记忆遍历经验。

Result: 理论和实验结果表明，REMINDRAG 优于现有基线。

Conclusion: REMINDRAG 能够有效地提高 KG-RAG 系统的性能和成本效率。

Abstract: Knowledge graphs (KGs), with their structured representation capabilities,
offer promising avenue for enhancing Retrieval Augmented Generation (RAG)
systems, leading to the development of KG-RAG systems. Nevertheless, existing
methods often struggle to achieve effective synergy between system
effectiveness and cost efficiency, leading to neither unsatisfying performance
nor excessive LLM prompt tokens and inference time. To this end, this paper
proposes REMINDRAG, which employs an LLM-guided graph traversal featuring node
exploration, node exploitation, and, most notably, memory replay, to improve
both system effectiveness and cost efficiency. Specifically, REMINDRAG
memorizes traversal experience within KG edge embeddings, mirroring the way
LLMs "memorize" world knowledge within their parameters, but in a train-free
manner. We theoretically and experimentally confirm the effectiveness of
REMINDRAG, demonstrating its superiority over existing baselines across various
benchmark datasets and LLM backbones. Our code is available at
https://github.com/kilgrims/ReMindRAG.

</details>


### [141] [LLM-guided Hierarchical Retrieval](https://arxiv.org/abs/2510.13217)
*Nilesh Gupta,Wei-Cheng Chang,Ngot Bui,Cho-Jui Hsieh,Inderjit S. Dhillon*

Main category: cs.IR

TL;DR: LATTICE is a hierarchical retrieval framework using LLMs to navigate large corpora with logarithmic search complexity.


<details>
  <summary>Details</summary>
Motivation: Current LLM-based IR systems struggle with complex queries, limitations of embedding-based retrieval, difficulty in updating parametric generative approaches, and computational infeasibility of long-context methods.

Method: It organizes the corpus into a semantic hierarchy and uses a search LLM to navigate this tree, estimating calibrated latent relevance scores from local LLM outputs and aggregates them into a global path relevance metric.

Result: Achieves state-of-the-art zero-shot performance on the reasoning-intensive BRIGHT benchmark, with improvements in Recall@100 and nDCG@5 over baselines. Comparable results to fine-tuned SOTA method DIVER-v2 on BRIGHT subsets.

Conclusion: LATTICE, a hierarchical retrieval framework, addresses the challenges of complex IR tasks by enabling LLMs to efficiently reason over large corpora. It achieves strong zero-shot performance and demonstrates the effectiveness of its hierarchical search approach.

Abstract: Modern IR systems are increasingly tasked with answering complex,
multi-faceted queries that require deep reasoning rather than simple keyword or
semantic matching. While LLM-based IR has shown great promise, the prevailing
retrieve-then-rerank paradigm inherits the limitations of embedding-based
retrieval; parametric generative approaches are difficult to update with new
information; and long-context methods that place the entire corpus in context
are computationally infeasible for large document collections. To address these
challenges, we introduce LATTICE, a hierarchical retrieval framework that
enables an LLM to reason over and navigate large corpora with logarithmic
search complexity by imposing a semantic tree structure on the corpus. Our
approach consists of two stages: (1) an offline phase that organizes the corpus
into a semantic hierarchy via either a bottom-up agglomerative strategy or a
top-down divisive strategy using multi-level summaries and (2) an online
traversal phase where a search LLM navigates this tree. A central challenge in
such LLM-guided search is that the model's relevance judgments are noisy,
context-dependent, and unaware of the hierarchy, making cross-branch and
cross-level comparisons difficult. To overcome this, we propose a traversal
algorithm that estimates calibrated latent relevance scores from local LLM
outputs and aggregates them into a global path relevance metric. Our
training-free framework achieves state-of-the-art zero-shot performance on the
reasoning-intensive BRIGHT benchmark, demonstrating up to 9% improvement in
Recall@100 and 5% in nDCG@10 over the next best zero-shot baseline.
Furthermore, compared to the fine-tuned SOTA method DIVER-v2, LATTICE attains
comparable results on BRIGHT subsets that use a static corpus for evaluation.

</details>


### [142] [Beyond Static LLM Policies: Imitation-Enhanced Reinforcement Learning for Recommendation](https://arxiv.org/abs/2510.13229)
*Yi Zhang,Lili Xie,Ruihong Qiu,Jiajun Liu,Sen Wang*

Main category: cs.IR

TL;DR: 这篇论文提出了一种新颖的离线强化学习框架，该框架利用模仿学习从大型语言模型（LLM）生成的轨迹中学习，以解决直接部署LLM作为推荐策略时遇到的延迟和模型局限性问题。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型（LLM）改进推荐系统（RecSys）具有巨大潜力，但直接部署LLM作为主要推荐策略存在延迟和模型局限性问题。

Method: 该方法采用逆强化学习从LLM演示中提取稳健的奖励模型，避免了LLM微调，并利用累积奖励引导强化学习策略。

Result: 在两个基准数据集上进行的综合实验验证了该方法的有效性，与最先进的基于强化学习和上下文学习的基线相比，表现出卓越的性能。

Conclusion: 该研究提出了一种有效的离线强化学习框架，通过模仿学习LLM的轨迹，成功地将LLM的语义信息转移到强化学习策略中，解决了直接部署LLM作为推荐策略时遇到的问题。

Abstract: Recommender systems (RecSys) have become critical tools for enhancing user
engagement by delivering personalized content across diverse digital platforms.
Recent advancements in large language models (LLMs) demonstrate significant
potential for improving RecSys, primarily due to their exceptional
generalization capabilities and sophisticated contextual understanding, which
facilitate the generation of flexible and interpretable recommendations.
However, the direct deployment of LLMs as primary recommendation policies
presents notable challenges, including persistent latency issues stemming from
frequent API calls and inherent model limitations such as hallucinations and
biases. To address these issues, this paper proposes a novel offline
reinforcement learning (RL) framework that leverages imitation learning from
LLM-generated trajectories. Specifically, inverse reinforcement learning is
employed to extract robust reward models from LLM demonstrations. This approach
negates the need for LLM fine-tuning, thereby substantially reducing
computational overhead. Simultaneously, the RL policy is guided by the
cumulative rewards derived from these demonstrations, effectively transferring
the semantic insights captured by the LLM. Comprehensive experiments conducted
on two benchmark datasets validate the effectiveness of the proposed method,
demonstrating superior performance when compared against state-of-the-art
RL-based and in-context learning baselines. The code can be found at
https://github.com/ArronDZhang/IL-Rec.

</details>


### [143] [Improving Visual Recommendation on E-commerce Platforms Using Vision-Language Models](https://arxiv.org/abs/2510.13359)
*Yuki Yada,Sho Akiyama,Ryo Watanabe,Yuta Ueno,Yusuke Shido,Andre Rusli*

Main category: cs.IR

TL;DR: 本研究将视觉语言模型 (VLM) 应用于 Mercari 上的产品推荐，Mercari 是日本一个拥有超过 2000 万月活跃用户的 C2C 市场。


<details>
  <summary>Details</summary>
Motivation: 在拥有数千万月活跃用户的大型电子商务平台上，推荐视觉上相似的产品对于使用户能够高效地发现符合其偏好的商品至关重要。

Method: 使用从 Mercari 收集的一百万个产品图像-标题对，对采用基于 sigmoid 的对比损失的 VLM SigLIP 进行了微调，并开发了一个图像编码器，用于生成推荐系统中使用的项目嵌入。

Result: 离线分析表明，与基线相比，nDCG@5 提高了 9.1%。在线 A/B 测试表明，与现有模型相比，点击率提高了 50%，转化率提高了 14%。

Conclusion: 结果表明，基于 VLM 的编码器对于电子商务产品推荐非常有效，并为开发基于视觉相似性的推荐系统提供了实践见解。

Abstract: On large-scale e-commerce platforms with tens of millions of active monthly
users, recommending visually similar products is essential for enabling users
to efficiently discover items that align with their preferences. This study
presents the application of a vision-language model (VLM) -- which has
demonstrated strong performance in image recognition and image-text retrieval
tasks -- to product recommendations on Mercari, a major consumer-to-consumer
marketplace used by more than 20 million monthly users in Japan. Specifically,
we fine-tuned SigLIP, a VLM employing a sigmoid-based contrastive loss, using
one million product image-title pairs from Mercari collected over a three-month
period, and developed an image encoder for generating item embeddings used in
the recommendation system. Our evaluation comprised an offline analysis of
historical interaction logs and an online A/B test in a production environment.
In offline analysis, the model achieved a 9.1% improvement in nDCG@5 compared
with the baseline. In the online A/B test, the click-through rate improved by
50% whereas the conversion rate improved by 14% compared with the existing
model. These results demonstrate the effectiveness of VLM-based encoders for
e-commerce product recommendations and provide practical insights into the
development of visual similarity-based recommendation systems.

</details>


### [144] [MADREC: A Multi-Aspect Driven LLM Agent for Explainable and Adaptive Recommendation](https://arxiv.org/abs/2510.13371)
*Jiin Park,Misuk Kim*

Main category: cs.IR

TL;DR: 提出了一种名为MADRec的自主LLM推荐系统，它通过非监督方式提取用户和项目的多方面信息来构建用户和项目画像，并能进行直接推荐、序列推荐和生成解释。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在推荐系统中的应用未能充分捕捉用户偏好和真实世界互动的复杂性，多数仅限于简单的文本生成或静态的基于提示的推理。

Method: 该研究提出MADRec，一个多方面驱动的LLM Agent，通过基于方面类别的摘要生成结构化画像，并应用重排序构建高密度输入。当输出中缺少真实项目时，自反馈机制会动态调整推理标准。

Result: 在多个领域进行的实验表明，MADRec在精度和可解释性方面均优于传统和基于LLM的基线模型，人工评估也进一步证实了生成的解释具有说服力。

Conclusion: MADRec模型在推荐系统的精度、可解释性和说服力方面表现出色

Abstract: Recent attempts to integrate large language models (LLMs) into recommender
systems have gained momentum, but most remain limited to simple text generation
or static prompt-based inference, failing to capture the complexity of user
preferences and real-world interactions. This study proposes the Multi-Aspect
Driven LLM Agent MADRec, an autonomous LLM-based recommender that constructs
user and item profiles by unsupervised extraction of multi-aspect information
from reviews and performs direct recommendation, sequential recommendation, and
explanation generation. MADRec generates structured profiles via
aspect-category-based summarization and applies Re-Ranking to construct
high-density inputs. When the ground-truth item is missing from the output, the
Self-Feedback mechanism dynamically adjusts the inference criteria. Experiments
across multiple domains show that MADRec outperforms traditional and LLM-based
baselines in both precision and explainability, with human evaluation further
confirming the persuasiveness of the generated explanations.

</details>


### [145] [RAG Meets Temporal Graphs: Time-Sensitive Modeling and Retrieval for Evolving Knowledge](https://arxiv.org/abs/2510.13590)
*Jiale Han,Austin Cheung,Yubai Wei,Zheng Yu,Xusheng Wang,Bing Zhu,Yi Yang*

Main category: cs.IR

TL;DR: 提出了一种时间感知的RAG系统，名为TG-RAG，它使用双层时间图来模拟外部语料库，并支持增量更新。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG系统大多忽略了知识的时间敏感性，缺乏有效的时间感知表示，并且评估时假设静态语料库，忽略了更新成本和检索稳定性。

Method: 构建了一个双层时间图，包括时间知识图谱和分层时间图，为每个时间节点生成多粒度的时间摘要，并支持增量更新。

Result: TG-RAG 在处理时间知识和增量更新方面显著优于现有基线。

Conclusion: TG-RAG 是一种有效的时间感知 RAG 系统，能够处理时间知识和增量更新。

Abstract: Knowledge is inherently time-sensitive and continuously evolves over time.
Although current Retrieval-Augmented Generation (RAG) systems enrich LLMs with
external knowledge, they largely ignore this temporal nature. This raises two
challenges for RAG. First, current RAG methods lack effective time-aware
representations. Same facts of different time are difficult to distinguish with
vector embeddings or conventional knowledge graphs. Second, most RAG
evaluations assume a static corpus, leaving a blind spot regarding update costs
and retrieval stability as knowledge evolves. To make RAG time-aware, we
propose Temporal GraphRAG (TG-RAG), which models external corpora as a bi-level
temporal graph consisting of a temporal knowledge graph with timestamped
relations and a hierarchical time graph. Multi-granularity temporal summaries
are generated for each time node to capture both key events and broader trends
at that time. The design supports incremental updates by extracting new
temporal facts from the incoming corpus and merging them into the existing
graph. The temporal graph explicitly represents identical facts at different
times as distinct edges to avoid ambiguity, and the time hierarchy graph allows
only generating reports for new leaf time nodes and their ancestors, ensuring
effective and efficient updates. During inference, TG-RAG dynamically retrieves
a subgraph within the temporal and semantic scope of the query, enabling
precise evidence gathering. Moreover, we introduce ECT-QA, a time-sensitive
question-answering dataset featuring both specific and abstract queries, along
with a comprehensive evaluation protocol designed to assess incremental update
capabilities of RAG systems. Extensive experiments show that TG-RAG
significantly outperforms existing baselines, demonstrating the effectiveness
of our method in handling temporal knowledge and incremental updates.

</details>


### [146] [HyMiRec: A Hybrid Multi-interest Learning Framework for LLM-based Sequential Recommendation](https://arxiv.org/abs/2510.13738)
*Jingyi Zhou,Cheng Chen,Kai Zuo,Manjie Xu,Zhendong Fu,Yibo Chen,Xu Tang,Yao Hu*

Main category: cs.IR

TL;DR: 提出了一种混合多兴趣序列推荐框架 (HyMiRec)，该框架利用轻量级推荐器从长用户序列中提取粗略兴趣嵌入，并利用基于 LLM 的推荐器捕获精细兴趣嵌入。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常会截断用户行为序列，仅包含最近的交互，从而导致有价值的远程偏好信号丢失。大多数当前方法依赖于具有单个预测嵌入的下一项预测，忽略了用户兴趣的多方面性并限制了推荐多样性。

Method: 利用轻量级推荐器从长用户序列中提取粗略兴趣嵌入，并利用基于 LLM 的推荐器捕获精细兴趣嵌入。为了减轻获取特征的开销，我们引入了一种基于余弦相似度的残差码本，从而能够高效地压缩和重用用户历史嵌入。为了对用户多样化的偏好进行建模，我们设计了一个解耦的多兴趣学习模块，该模块利用多个兴趣查询来学习自适应地解耦多个兴趣信号，从而使模型能够捕获用户意图的不同方面。

Result: 在基准数据集和收集的工业数据集上进行了大量实验，证明了我们的方法优于现有的最先进方法。此外，在线 A/B 测试表明 HyMiRec 在实际推荐系统中带来了一致的改进。

Conclusion: HyMiRec 是一种有效的序列推荐框架，它能够捕获用户的长期和多样化兴趣，并在实际推荐系统中带来显著的改进。

Abstract: Large language models (LLMs) have recently demonstrated strong potential for
sequential recommendation. However, current LLM-based approaches face critical
limitations in modeling users' long-term and diverse interests. First, due to
inference latency and feature fetching bandwidth constraints, existing methods
typically truncate user behavior sequences to include only the most recent
interactions, resulting in the loss of valuable long-range preference signals.
Second, most current methods rely on next-item prediction with a single
predicted embedding, overlooking the multifaceted nature of user interests and
limiting recommendation diversity. To address these challenges, we propose
HyMiRec, a hybrid multi-interest sequential recommendation framework, which
leverages a lightweight recommender to extracts coarse interest embeddings from
long user sequences and an LLM-based recommender to captures refined interest
embeddings. To alleviate the overhead of fetching features, we introduce a
residual codebook based on cosine similarity, enabling efficient compression
and reuse of user history embeddings. To model the diverse preferences of
users, we design a disentangled multi-interest learning module, which leverages
multiple interest queries to learn disentangles multiple interest signals
adaptively, allowing the model to capture different facets of user intent.
Extensive experiments are conducted on both benchmark datasets and a collected
industrial dataset, demonstrating our effectiveness over existing
state-of-the-art methods. Furthermore, online A/B testing shows that HyMiRec
brings consistent improvements in real-world recommendation systems.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [147] [Local Timescale Gates for Timescale-Robust Continual Spiking Neural Networks](https://arxiv.org/abs/2510.12843)
*Ansh Tiwari,Ayush Chauhan*

Main category: cs.LG

TL;DR: 提出了一种名为局部时间尺度门控（LT-Gate）的神经元模型，用于解决脉冲神经网络（SNN）在持续学习中快速适应和长期记忆之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络在神经形态硬件上具有节能潜力，但在需要快速适应和长期记忆的任务中表现不佳，尤其是在持续学习中。

Method: 该模型结合了双时间常数动态和一个自适应门控机制，每个脉冲神经元并行跟踪快速和慢速时间尺度上的信息，并通过学习的门控局部调整它们的影响。此外，还引入了一种方差跟踪正则化来稳定放电活动。

Result: LT-Gate在序列学习任务中显著提高了准确性和保留率，在具有挑战性的时间分类基准测试中，最终准确率达到约51%，而最近的Hebbian持续学习基线约为46%，之前的SNN方法则更低。

Conclusion: 多时间尺度门控可以显著增强SNN中的持续学习，缩小脉冲神经网络和传统深度网络在终身学习任务中的差距。

Abstract: Spiking neural networks (SNNs) promise energy-efficient artificial
intelligence on neuromorphic hardware but struggle with tasks requiring both
fast adaptation and long-term memory, especially in continual learning. We
propose Local Timescale Gating (LT-Gate), a neuron model that combines dual
time-constant dynamics with an adaptive gating mechanism. Each spiking neuron
tracks information on a fast and a slow timescale in parallel, and a learned
gate locally adjusts their influence. This design enables individual neurons to
preserve slow contextual information while responding to fast signals,
addressing the stability-plasticity dilemma. We further introduce a
variance-tracking regularization that stabilizes firing activity, inspired by
biological homeostasis. Empirically, LT-Gate yields significantly improved
accuracy and retention in sequential learning tasks: on a challenging temporal
classification benchmark it achieves about 51 percent final accuracy, compared
to about 46 percent for a recent Hebbian continual-learning baseline and lower
for prior SNN methods. Unlike approaches that require external replay or
expensive orthogonalizations, LT-Gate operates with local updates and is fully
compatible with neuromorphic hardware. In particular, it leverages features of
Intel's Loihi chip (multiple synaptic traces with different decay rates) for
on-chip learning. Our results demonstrate that multi-timescale gating can
substantially enhance continual learning in SNNs, narrowing the gap between
spiking and conventional deep networks on lifelong-learning tasks.

</details>


### [148] [Lifting Manifolds to Mitigate Pseudo-Alignment in LLM4TS](https://arxiv.org/abs/2510.12847)
*Liangwei Nathan Zheng,Wenhao Liang,Wei Emma Zhang,Miao Xu,Olaf Maennel,Weitong Chen*

Main category: cs.LG

TL;DR: 这篇论文研究了大型语言模型在时间序列预测中表现不佳的问题（伪对齐），发现其根源在于预训练语言模型的“锥形效应”与时间序列数据的低维特性之间的相互作用。为了解决这个问题，作者提出了一种名为 TimeSUP 的新技术，通过增加时间序列流形的维度来匹配语言嵌入的维度，从而提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在时间序列预测中表现不佳的根本原因，即伪对齐问题。

Method: 通过研究伪对齐与大型语言模型中的锥形效应之间的联系，揭示其内在机制。并提出一种名为 TimeSUP 的新技术，旨在缓解伪对齐问题。

Result: TimeSUP 在长期预测性能上优于现有先进方法，并且可以无缝集成到现有的大型语言模型时间序列预测流程中，显著提高预测性能。

Conclusion: 伪对齐源于预训练语言模型的锥形效应与时间序列数据的低维特性之间的相互作用。TimeSUP 通过增加时间序列流形的维度，使模型能够更好地区分时间信号，同时捕捉跨模态的共享结构，从而提高预测性能。

Abstract: Pseudo-Alignment is a pervasive challenge in many large language models for
time series (LLM4TS) models, often causing them to underperform compared to
linear models or randomly initialised backbones. However, there is limited
discussion in the community for the reasons that pseudo-alignment occurs. In
this work, we conduct a thorough investigation into the root causes of
pseudo-alignment in LLM4TS and build a connection of pseudo-alignment to the
cone effect in LLM. We demonstrate that pseudo-alignment arises from the
interplay of cone effect within pretrained LLM components and the intrinsically
low-dimensional manifold of time-series data. In addition, we also introduce
\textit{\textbf{TimeSUP}}, a novel technique designed to mitigate this issue
and improve forecast performance in existing LLM4TS approaches. TimeSUP
addresses this by increasing the time series manifold to more closely match the
intrinsic dimension of language embeddings, allowing the model to distinguish
temporal signals clearly while still capturing shared structures across
modalities. As a result, representations for time and language tokens remain
distinct yet exhibit high cosine similarity, signifying that the model
preserves each modality unique features while learning their commonalities in a
unified embedding space. Empirically, TimeSUP consistently outperforms
state-of-the-art LLM4TS methods and other lightweight baselines on long-term
forecasting performance. Furthermore, it can be seamlessly integrated into four
existing LLM4TS pipelines and delivers significant improvements in forecasting
performance.

</details>


### [149] [FedGTEA: Federated Class-Incremental Learning with Gaussian Task Embedding and Alignment](https://arxiv.org/abs/2510.12927)
*Haolin Li,Hoda Bidkhori*

Main category: cs.LG

TL;DR: 提出了一个名为 FedGTEA 的联邦类增量学习的新框架，旨在以可扩展且通信高效的方式捕获特定于任务的知识并模拟不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中的任务异构性和数据不确定性问题。

Method: 在客户端，使用 Cardinality-Agnostic Task Encoder (CATE) 生成高斯分布的任务嵌入，对任务知识进行编码并量化数据不确定性。在服务器端，FedGTEA 利用 2-Wasserstein 距离来测量高斯嵌入之间的任务间差距，并制定 Wasserstein 损失以加强任务间分离。

Result: 在流行数据集上的大量实证评估表明，FedGTEA 实现了卓越的分类性能，并显着减轻了遗忘，始终优于现有的强大基线。

Conclusion: FedGTEA 不仅增强了表示学习，还通过避免直接传输潜在嵌入来保护任务级别的隐私，符合联邦学习中的隐私约束。

Abstract: We introduce a novel framework for Federated Class Incremental Learning,
called Federated Gaussian Task Embedding and Alignment (FedGTEA). FedGTEA is
designed to capture task-specific knowledge and model uncertainty in a scalable
and communication-efficient manner. At the client side, the
Cardinality-Agnostic Task Encoder (CATE) produces Gaussian-distributed task
embeddings that encode task knowledge, address statistical heterogeneity, and
quantify data uncertainty. Importantly, CATE maintains a fixed parameter size
regardless of the number of tasks, which ensures scalability across long task
sequences. On the server side, FedGTEA utilizes the 2-Wasserstein distance to
measure inter-task gaps between Gaussian embeddings. We formulate the
Wasserstein loss to enforce inter-task separation. This probabilistic
formulation not only enhances representation learning but also preserves
task-level privacy by avoiding the direct transmission of latent embeddings,
aligning with the privacy constraints in federated learning. Extensive
empirical evaluations on popular datasets demonstrate that FedGTEA achieves
superior classification performance and significantly mitigates forgetting,
consistently outperforming strong existing baselines.

</details>


### [150] [Learning at the Speed of Physics: Equilibrium Propagation on Oscillator Ising Machines](https://arxiv.org/abs/2510.12934)
*Alex Gower*

Main category: cs.LG

TL;DR: 振荡器 Ising 机 (OIM) 是一种用于神经形态学习的快速、节能的基板，它通过利用物理系统自然执行能量下降的特性，为能量模型 (EBM) 的优化和损失情况下的梯度下降提供了一种直接途径。


<details>
  <summary>Details</summary>
Motivation: 探索使用物理系统加速机器学习的方法，特别是利用振荡器 Ising 机 (OIM) 的能量下降特性。

Method: 在 OIM 上实现平衡传播 (EP)，并评估其在 MNIST 和 Fashion-MNIST 数据集上的准确性和鲁棒性。

Result: 在 MNIST 上实现了约 97.2% 的准确率，在 Fashion-MNIST 上实现了约 88.0% 的准确率，同时在参数量化和相位噪声等实际硬件约束下保持了鲁棒性。

Conclusion: OIM 是一种有前景的神经形态学习基板，它可以通过物理硬件直接执行优化，从而实现 EBM 的实际应用。

Abstract: Physical systems that naturally perform energy descent offer a direct route
to accelerating machine learning. Oscillator Ising Machines (OIMs) exemplify
this idea: their GHz-frequency dynamics mirror both the optimization of
energy-based models (EBMs) and gradient descent on loss landscapes, while
intrinsic noise corresponds to Langevin dynamics - supporting sampling as well
as optimization. Equilibrium Propagation (EP) unifies these processes into
descent on a single total energy landscape, enabling local learning rules
without global backpropagation. We show that EP on OIMs achieves competitive
accuracy ($\sim 97.2 \pm 0.1 \%$ on MNIST, $\sim 88.0 \pm 0.1 \%$ on
Fashion-MNIST), while maintaining robustness under realistic hardware
constraints such as parameter quantization and phase noise. These results
establish OIMs as a fast, energy-efficient substrate for neuromorphic learning,
and suggest that EBMs - often bottlenecked by conventional processors - may
find practical realization on physical hardware whose dynamics directly perform
their optimization.

</details>


### [151] [Pruning Cannot Hurt Robustness: Certified Trade-offs in Reinforcement Learning](https://arxiv.org/abs/2510.12939)
*James Pedley,Benjamin Etheridge,Stephen J. Roberts,Francesco Quinzan*

Main category: cs.LG

TL;DR: 研究剪枝在强化学习中对抗扰动下的鲁棒性作用，发现适当的剪枝可以在不损害甚至提高原始性能的情况下，显著提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实环境中部署的强化学习策略必须在对抗扰动下保持可靠性；现代深度强化学习智能体过度参数化，导致成本和脆弱性问题。

Method: 针对状态对抗马尔可夫决策过程（SA-MDPs），开发了首个关于剪枝下认证鲁棒性的理论框架。对于具有 Lipschitz 网络的 Gaussian 和 categorical 策略，证明了逐元素剪枝只能收紧认证鲁棒性边界；剪枝永远不会降低策略的鲁棒性。基于此，推导出一个新的三项遗憾分解，解开了clean-task性能、剪枝引起的性能损失和鲁棒性增益，揭示了一个基本的性能-鲁棒性前沿。

Result: 在具有强策略感知对抗的连续控制基准上，评估了幅度和微剪枝计划。在各项任务中，剪枝持续发现中等稀疏度下的可重复“最佳点”，在这些点上，鲁棒性显着提高，而不会损害——有时甚至会增强——原始性能。

Conclusion: 剪枝不仅仅是一种压缩工具，而且是一种用于鲁棒强化学习的结构性干预手段。

Abstract: Reinforcement learning (RL) policies deployed in real-world environments must
remain reliable under adversarial perturbations. At the same time, modern deep
RL agents are heavily over-parameterized, raising costs and fragility concerns.
While pruning has been shown to improve robustness in supervised learning, its
role in adversarial RL remains poorly understood. We develop the first
theoretical framework for certified robustness under pruning in
state-adversarial Markov decision processes (SA-MDPs). For Gaussian and
categorical policies with Lipschitz networks, we prove that element-wise
pruning can only tighten certified robustness bounds; pruning never makes the
policy less robust. Building on this, we derive a novel three-term regret
decomposition that disentangles clean-task performance, pruning-induced
performance loss, and robustness gains, exposing a fundamental
performance--robustness frontier. Empirically, we evaluate magnitude and
micro-pruning schedules on continuous-control benchmarks with strong
policy-aware adversaries. Across tasks, pruning consistently uncovers
reproducible ``sweet spots'' at moderate sparsity levels, where robustness
improves substantially without harming - and sometimes even enhancing - clean
performance. These results position pruning not merely as a compression tool
but as a structural intervention for robust RL.

</details>


### [152] [An Investigation of Memorization Risk in Healthcare Foundation Models](https://arxiv.org/abs/2510.12950)
*Sana Tonekaboni,Lena Stempfle,Adibvafa Fallahpour,Walter Gerych,Marzyeh Ghassemi*

Main category: cs.LG

TL;DR: 评估在电子健康记录（EHR）上训练的foundation model的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 大型电子健康记录（EHR）上训练的foundation model在临床应用中很有前景，但会 memorization 病人信息， 引起隐私问题。

Method: 引入一套黑盒评估测试，以评估在结构化EHR数据上训练的foundation model中与隐私相关的memorization风险。该框架包括在嵌入和生成级别探测memorization的方法，旨在区分模型泛化和临床相关环境中有害的memorization。

Result: 在一个公开的EHR foundation model上验证了该方法。

Conclusion: 发布了一个开源工具包，以促进医疗保健AI中可重复和协作的隐私评估。

Abstract: Foundation models trained on large-scale de-identified electronic health
records (EHRs) hold promise for clinical applications. However, their capacity
to memorize patient information raises important privacy concerns. In this
work, we introduce a suite of black-box evaluation tests to assess
privacy-related memorization risks in foundation models trained on structured
EHR data. Our framework includes methods for probing memorization at both the
embedding and generative levels, and aims to distinguish between model
generalization and harmful memorization in clinically relevant settings. We
contextualize memorization in terms of its potential to compromise patient
privacy, particularly for vulnerable subgroups. We validate our approach on a
publicly available EHR foundation model and release an open-source toolkit to
facilitate reproducible and collaborative privacy assessments in healthcare AI.

</details>


### [153] [A Multimodal XAI Framework for Trustworthy CNNs and Bias Detection in Deep Representation Learning](https://arxiv.org/abs/2510.12957)
*Noor Islam S. Mohammad*

Main category: cs.LG

TL;DR: 本文提出了一个新的多模态可解释AI (XAI) 框架，用于偏差检测和缓解。


<details>
  <summary>Details</summary>
Motivation: 标准benchmark数据集通常不能暴露潜在的偏差和多模态特征的复杂性，限制了深度神经网络在高风险应用中的可信度。

Method: 该框架统一了注意力增强特征融合、基于Grad-CAM++的局部解释和Reveal-to-Revise反馈循环。

Result: 在MNIST的多模态扩展数据集上，该方法达到了93.2%的分类准确率，91.6%的F1分数和78.1%的解释保真度(IoU-XAI)，优于单模态和不可解释的基线。

Conclusion: 将可解释性与偏差感知学习相结合，可以增强鲁棒性和人类一致性，为敏感领域中值得信赖的AI提供了一条实用途径。

Abstract: Standard benchmark datasets, such as MNIST, often fail to expose latent
biases and multimodal feature complexities, limiting the trustworthiness of
deep neural networks in high-stakes applications. We propose a novel multimodal
Explainable AI (XAI) framework that unifies attention-augmented feature fusion,
Grad-CAM++-based local explanations, and a Reveal-to-Revise feedback loop for
bias detection and mitigation. Evaluated on multimodal extensions of MNIST, our
approach achieves 93.2% classification accuracy, 91.6% F1-score, and 78.1%
explanation fidelity (IoU-XAI), outperforming unimodal and non-explainable
baselines. Ablation studies demonstrate that integrating interpretability with
bias-aware learning enhances robustness and human alignment. Our work bridges
the gap between performance, transparency, and fairness, highlighting a
practical pathway for trustworthy AI in sensitive domains.

</details>


### [154] [Balancing Performance and Reject Inclusion: A Novel Confident Inlier Extrapolation Framework for Credit Scoring](https://arxiv.org/abs/2510.12967)
*Athyrson Machado Ribeiro,Marcos Medeiros Raimundo*

Main category: cs.LG

TL;DR: 提出了一种新的置信内点外推框架（CI-EX）来解决拒绝推断（RI）中的样本偏差问题，该框架通过识别拒绝客户样本的分布并基于概率分配标签来迭代地进行推断。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常假设被拒绝客户的行为可以从被接受客户的行为中推断出来，但两者之间可能存在分布差异，为了缓解这种盲目外推。

Method: 使用异常值检测模型识别拒绝客户样本的分布，并基于监督分类模型得出的概率，将被拒绝个体分配标签到最接近接受人群分布的个体。

Result: 在两个大型真实信用数据集上的实验表明，RI 方法通常涉及 AUC 和 RI-specific 指标之间的权衡。CI-EX 框架在 RI-specific 指标方面始终优于现有 RI 模型，并在大多数实验中保持了 AUC 的竞争性能。

Conclusion: 提出的 CI-EX 框架在 RI-specific 指标方面优于现有模型，并在 AUC 方面保持竞争力，从而有效地解决了拒绝推断中的样本偏差问题。

Abstract: Reject Inference (RI) methods aim to address sample bias by inferring missing
repayment data for rejected credit applicants. Traditional approaches often
assume that the behavior of rejected clients can be extrapolated from accepted
clients, despite potential distributional differences between the two
populations. To mitigate this blind extrapolation, we propose a novel Confident
Inlier Extrapolation framework (CI-EX). CI-EX iteratively identifies the
distribution of rejected client samples using an outlier detection model and
assigns labels to rejected individuals closest to the distribution of the
accepted population based on probabilities derived from a supervised
classification model. The effectiveness of our proposed framework is validated
through experiments on two large real-world credit datasets. Performance is
evaluated using the Area Under the Curve (AUC) as well as RI-specific metrics
such as Kickout and a novel metric introduced in this work, denoted as Area
under the Kickout. Our findings reveal that RI methods, including the proposed
framework, generally involve a trade-off between AUC and RI-specific metrics.
However, the proposed CI-EX framework consistently outperforms existing RI
models from the credit literature in terms of RI-specific metrics while
maintaining competitive performance in AUC across most experiments.

</details>


### [155] [A Connection Between Score Matching and Local Intrinsic Dimension](https://arxiv.org/abs/2510.12975)
*Eric Yeats,Aaron Jacobson,Darryl Hannan,Yiran Jia,Timothy Doster,Henry Kvinge,Scott Mahan*

Main category: cs.LG

TL;DR: 提出了一种新的LID估计方法，该方法计算效率高，内存占用小。


<details>
  <summary>Details</summary>
Motivation: 量化高维复杂数据的局部固有维数(LID)是一个具有挑战性的任务。现有的基于扩散模型的方法需要大量的计算或梯度计算，限制了它们在计算和内存受限场景中的应用。

Method: 利用去噪得分匹配损失作为LID估计器，并证明了等价的隐式得分匹配损失也近似于LID。

Result: 在流形基准测试和Stable Diffusion 3.5上的实验表明，去噪得分匹配损失是一种具有竞争力和可扩展性的LID估计器，在问题规模和量化级别增加的情况下，实现了卓越的准确性和内存占用。

Conclusion: 去噪得分匹配损失是一种有效的LID估计方法，可以在计算和内存受限的场景中使用。

Abstract: The local intrinsic dimension (LID) of data is a fundamental quantity in
signal processing and learning theory, but quantifying the LID of
high-dimensional, complex data has been a historically challenging task. Recent
works have discovered that diffusion models capture the LID of data through the
spectra of their score estimates and through the rate of change of their
density estimates under various noise perturbations. While these methods can
accurately quantify LID, they require either many forward passes of the
diffusion model or use of gradient computation, limiting their applicability in
compute- and memory-constrained scenarios.
  We show that the LID is a lower bound on the denoising score matching loss,
motivating use of the denoising score matching loss as a LID estimator.
Moreover, we show that the equivalent implicit score matching loss also
approximates LID via the normal dimension and is closely related to a recent
LID estimator, FLIPD. Our experiments on a manifold benchmark and with Stable
Diffusion 3.5 indicate that the denoising score matching loss is a highly
competitive and scalable LID estimator, achieving superior accuracy and memory
footprint under increasing problem size and quantization level.

</details>


### [156] [Reference-Specific Unlearning Metrics Can Hide the Truth: A Reality Check](https://arxiv.org/abs/2510.12981)
*Sungjun Cho,Dasol Hwang,Frederic Sala,Sangheum Hwang,Kyunghyun Cho,Sungmin Cha*

Main category: cs.LG

TL;DR: 现有的生成模型非学习指标依赖于参考响应或分类器输出，而不是评估核心目标：非学习模型的行为是否与从未见过不需要的数据的模型无法区分。这种参考特定的方法会造成盲点，使模型在保持不需要的知识的同时，通过其他提示或攻击看起来是成功的。我们提出了功能对齐分布等价（FADE），这是一种新的度量标准，通过比较生成样本的双向可能性分配来衡量非学习模型和参考模型之间的分布相似性。与依赖于预定参考的现有方法不同，FADE 捕获整个输出分布中的功能对齐，从而对真正的非学习进行评估。


<details>
  <summary>Details</summary>
Motivation: 当前用于生成模型的非学习指标存在盲点，无法真正评估模型是否忘记了不需要的数据。

Method: 提出了一种新的指标 FADE，通过比较生成样本的双向可能性分配来衡量非学习模型和参考模型之间的分布相似性。

Result: 在 LLM 非学习的 TOFU 基准和文本到图像扩散模型非学习的 UnlearnCanvas 基准上的实验表明，在传统指标上获得接近最优分数的模型未能实现分布等价，许多模型变得比非学习之前更远离黄金标准。

Conclusion: 现有的评估方法存在根本差距，FADE 为开发和评估真正有效的非学习方法提供了更强大的基础。

Abstract: Current unlearning metrics for generative models evaluate success based on
reference responses or classifier outputs rather than assessing the core
objective: whether the unlearned model behaves indistinguishably from a model
that never saw the unwanted data. This reference-specific approach creates
systematic blind spots, allowing models to appear successful while retaining
unwanted knowledge accessible through alternative prompts or attacks. We
address these limitations by proposing Functional Alignment for Distributional
Equivalence (FADE), a novel metric that measures distributional similarity
between unlearned and reference models by comparing bidirectional likelihood
assignments over generated samples. Unlike existing approaches that rely on
predetermined references, FADE captures functional alignment across the entire
output distribution, providing a principled assessment of genuine unlearning.
Our experiments on the TOFU benchmark for LLM unlearning and the UnlearnCanvas
benchmark for text-to-image diffusion model unlearning reveal that methods
achieving near-optimal scores on traditional metrics fail to achieve
distributional equivalence, with many becoming more distant from the gold
standard than before unlearning. These findings expose fundamental gaps in
current evaluation practices and demonstrate that FADE provides a more robust
foundation for developing and assessing truly effective unlearning methods.

</details>


### [157] [CSI-4CAST: A Hybrid Deep Learning Model for CSI Prediction with Comprehensive Robustness and Generalization Testing](https://arxiv.org/abs/2510.12996)
*Sikai Cheng,Reza Zandehshahvar,Haoruo Zhao,Daniel A. Garcia-Ulloa,Alejandro Villena-Rodriguez,Carles Navarro Manchón,Pascal Van Hentenryck*

Main category: cs.LG

TL;DR: 提出了一种名为CSI-4CAST的混合深度学习架构，用于信道状态信息（CSI）预测，并在CSI-RRG基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的CSI预测方法在非高斯噪声的鲁棒性、跨信道条件的泛化能力和计算效率方面存在局限性。

Method: CSI-4CAST集成了卷积神经网络残差、自适应校正层、ShuffleNet块和Transformer，以有效捕获CSI预测中的局部和长程依赖关系。同时，构建了包含超过30万个样本的CSI-RRG基准测试，用于全面评估。

Result: 实验结果表明，CSI-4CAST在预测精度上优于其他模型，同时显著降低了计算成本。在TDD场景中，CSI-4CAST在88.9%的场景中优于基线，在FDD场景中，CSI-4CAST在43.8%的场景中优于基线，并且与最强的基线LLM4CP相比，FLOPs分别降低了5倍和3倍。

Conclusion: CSI-4CAST在CSI预测方面表现出色，并且发布了数据集和评估协议，以促进该领域的研究。

Abstract: Channel state information (CSI) prediction is a promising strategy for
ensuring reliable and efficient operation of massive multiple-input
multiple-output (mMIMO) systems by providing timely downlink (DL) CSI. While
deep learning-based methods have advanced beyond conventional model-driven and
statistical approaches, they remain limited in robustness to practical
non-Gaussian noise, generalization across diverse channel conditions, and
computational efficiency. This paper introduces CSI-4CAST, a hybrid deep
learning architecture that integrates 4 key components, i.e., Convolutional
neural network residuals, Adaptive correction layers, ShuffleNet blocks, and
Transformers, to efficiently capture both local and long-range dependencies in
CSI prediction. To enable rigorous evaluation, this work further presents a
comprehensive benchmark, CSI-RRG for Regular, Robustness and Generalization
testing, which includes more than 300,000 samples across 3,060 realistic
scenarios for both TDD and FDD systems. The dataset spans multiple channel
models, a wide range of delay spreads and user velocities, and diverse noise
types and intensity degrees. Experimental results show that CSI-4CAST achieves
superior prediction accuracy with substantially lower computational cost,
outperforming baselines in 88.9% of TDD scenarios and 43.8% of FDD scenario,
the best performance among all evaluated models, while reducing FLOPs by 5x and
3x compared to LLM4CP, the strongest baseline. In addition, evaluation over
CSI-RRG provides valuable insights into how different channel factors affect
the performance and generalization capability of deep learning models. Both the
dataset (https://huggingface.co/CSI-4CAST) and evaluation protocols
(https://github.com/AI4OPT/CSI-4CAST) are publicly released to establish a
standardized benchmark and to encourage further research on robust and
efficient CSI prediction.

</details>


### [158] [Max It or Miss It: Benchmarking LLM On Solving Extremal Problems](https://arxiv.org/abs/2510.12997)
*Binxin Gao,Jingjun Han*

Main category: cs.LG

TL;DR: 论文研究了大型语言模型在解决数学极值问题方面的能力，发现现有数学基准测试可能无法全面评估模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型推理能力的来源和机制了解不足，尤其是在优化推理方面。优化推理是规划、控制和资源分配等应用的基础。

Method: 提出了ExtremBench，一个用于解决数学极值问题的基准数据集，该数据集来自中国数学奥林匹克不等式练习题，并转化为93个标准化极值问题。

Result: 实验结果表明，大型语言模型在解决极值问题方面的能力与现有数学基准测试（如AIME25和MATH-500）的结果并不总是一致。一些模型在通用数学推理方面表现出色，但在解决极值问题方面的能力较差，反之亦然。

Conclusion: 现有基准测试可能无法全面捕捉数学推理能力的全部范围，需要改进评估方法。

Abstract: Test-time scaling has enabled Large Language Models (LLMs) with remarkable
reasoning capabilities, particularly in mathematical domains, through
intermediate chain-of-thought (CoT) reasoning before generating final answers.
However, the specific sources and mechanisms underlying these reasoning
capabilities remain insufficiently understood. Optimization reasoning, i.e.
finding extrema under constraints, represents a fundamental abstraction that
underpins critical applications in planning, control, resource allocation, and
prompt search. To systematically evaluate this capability, we introduce
ExtremBench, a benchmark dataset for solving mathematical extremal problems,
curated from inequality exercises used for Chinese Mathematical Olympiad and
transformed into $93$ standardized extrema-finding problems. We conduct
extensive evaluations across various state-of-the-art open-source model
families, including the Qwen3, GPT-OSS, and DeepSeek. Our results reveal that
LLMs' extremal-solving reasoning capabilities do not always align with those of
current mathematical benchmarks such as AIME25 and MATH-500, with some models
showing strong general mathematical reasoning but poor extremal-solving skills,
and vice versa. This discrepancy highlights a critical gap in current
evaluation practices and suggests that existing benchmarks may not
comprehensively capture the full spectrum of mathematical reasoning abilities.

</details>


### [159] [AMORE: Adaptive Multi-Output Operator Network for Stiff Chemical Kinetics](https://arxiv.org/abs/2510.12999)
*Kamaljyoti Nath,Additi Pandey,Bryan T. Susi,Hessam Babaee,George Em Karniadakis*

Main category: cs.LG

TL;DR: This paper introduces AMORE, a framework using neural operators (DeepONets) to act as surrogates for stiff kinetics in reactive transport systems. It uses adaptive loss functions and a unique approach to handle mass-fraction constraints.


<details>
  <summary>Details</summary>
Motivation: Stiffness in time integration of reactive transport systems (e.g., combustion) leads to high computational costs due to very small time steps required by explicit schemes or intensive computation required by implicit methods.

Method: The paper develops AMORE, an Adaptive Multi-Output Operator Network, with adaptive loss functions and a trunk designed to satisfy Partition of Unity. It uses an invertible analytical map to handle mass-fraction constraints and two-step training for DeepONet.

Result: The efficacy of AMORE is demonstrated through syngas (12 states) and GRI-Mech 3.0 (24 active states out of 54) examples.

Conclusion: The proposed DeepONet can accelerate turbulent combustion simulations and AMORE is a general framework applicable to other operator types like FNO.

Abstract: Time integration of stiff systems is a primary source of computational cost
in combustion, hypersonics, and other reactive transport systems. This
stiffness can introduce time scales significantly smaller than those associated
with other physical processes, requiring extremely small time steps in explicit
schemes or computationally intensive implicit methods. Consequently, strategies
to alleviate challenges posed by stiffness are important. While neural
operators (DeepONets) can act as surrogates for stiff kinetics, a reliable
operator learning strategy is required to appropriately account for differences
in the error between output variables and samples. Here, we develop AMORE,
Adaptive Multi-Output Operator Network, a framework comprising an operator
capable of predicting multiple outputs and adaptive loss functions ensuring
reliable operator learning. The operator predicts all thermochemical states
from given initial conditions. We propose two adaptive loss functions within
the framework, considering each state variable's and sample's error to penalize
the loss function. We designed the trunk to automatically satisfy Partition of
Unity. To enforce unity mass-fraction constraint exactly, we propose an
invertible analytical map that transforms the $n$-dimensional species
mass-fraction vector into an ($n-1$)-dimensional space, where DeepONet training
is performed. We consider two-step training for DeepONet for multiple outputs
and extend adaptive loss functions for trunk and branch training. We
demonstrate the efficacy and applicability of our models through two examples:
the syngas (12 states) and GRI-Mech 3.0 (24 active states out of 54). The
proposed DeepONet will be a backbone for future CFD studies to accelerate
turbulent combustion simulations. AMORE is a general framework, and here, in
addition to DeepONet, we also demonstrate it for FNO.

</details>


### [160] [Escaping Local Optima in the Waddington Landscape: A Multi-Stage TRPO-PPO Approach for Single-Cell Perturbation Analysis](https://arxiv.org/abs/2510.13018)
*Francis Boabang,Samuel Asante Gyamerah*

Main category: cs.LG

TL;DR: 本研究提出了一种多阶段强化学习算法，用于单细胞扰动建模，通过预处理参数和近端策略优化，提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动模型在细胞命运决定的非凸Waddington景观中容易陷入局部最优，导致轨迹陷入虚假谱系或难以置信的分化结果。因此，需要一种完全数据驱动且具有良好设计的初始化方法来避免局部最优。

Method: 该方法首先使用Fisher向量积和共轭梯度求解器计算显式自然梯度更新，并使用KL信任区域约束进行缩放，为策略提供安全的曲率感知第一步。然后，应用第二阶段的近端策略优化（PPO），利用小批量效率来改进策略。

Result: 该初始化方法在单细胞RNA测序（scRNA-seq）和单细胞ATAC测序（scATAC-seq）扰动分析中显著提高了泛化能力。

Conclusion: 多阶段强化学习算法可以有效提高单细胞扰动建模的泛化能力。

Abstract: Modeling cellular responses to genetic and chemical perturbations remains a
central challenge in single-cell biology. Existing data-driven framework have
advanced perturbation prediction through variational autoencoders, chemically
conditioned autoencoders, and large-scale transformer pretraining. However,
these models are prone to local optima in the nonconvex Waddington landscape of
cell fate decisions, where poor initialization can trap trajectories in
spurious lineages or implausible differentiation outcomes. While executable
gene regulatory networks complement these approaches, automated design
frameworks incorporate biological priors through multi-agent optimization. Yet,
an approach that is completely data-driven with well-designed initialization to
escape local optima and converge to a proper lineage remains elusive. In this
work, we introduce a multistage reinforcement learning algorithm tailored for
single-cell perturbation modeling. We first compute an explicit natural
gradient update using Fisher-vector products and a conjugate gradient solver,
scaled by a KL trust-region constraint to provide a safe, curvature-aware the
first step for the policy. Starting with these preconditioned parameters, we
then apply a second phase of proximal policy optimization (PPO) with clipped
surrogates, exploiting minibatch efficiency to refine the policy. We
demonstrate that this initialization substantially improves generalization on
Single-cell RNA sequencing (scRNA-seq) and Single-cell ATAC sequencing
(scATAC-seq) pertubation analysis.

</details>


### [161] [Machine Learning-Based Ultrasonic Weld Characterization Using Hierarchical Wave Modeling and Diffusion-Driven Distribution Alignment](https://arxiv.org/abs/2510.13023)
*Joshua R. Tempelman,Adam J. Wachtor,Eric B. Flynn*

Main category: cs.LG

TL;DR: 本研究提出了一种用于自动焊缝检测的端到端机器学习工作流程，该流程集成了降阶建模、基于扩散的分布对齐和基于U-Net的分割与反演。


<details>
  <summary>Details</summary>
Motivation: 在无损评估(NDE)领域，由于训练数据有限以及工业环境的不稳定性，自动超声波焊缝检测仍然是一个重大挑战。因此，在实际工业环境中实现声波焊缝检测的端到端机器学习工作流程仍然是一个难以实现的目标。

Method: 该工作流程包括降阶建模方案、基于扩散的分布对齐以及基于U-Net的分割和反演。基于Lamb波理论的降阶Helmholtz模型用于生成包含不同焊接异质性和裂纹缺陷的综合数据集。然后，通过使用有限的全3D弹性动力学模拟的迁移学习阶段来改进反演模型。为了处理具有不同和不可预测噪声分布的实测数据，即激光多普勒测振仪扫描，引导扩散生成OOD实验LDV扫描的分布内表示，然后由反演模型处理。

Result: 该集成框架为真实数据上的自动焊缝检测提供了一个端到端解决方案。

Conclusion: 通过降阶建模生成训练数据，使用扩散模型处理噪声，并结合U-Net进行分割和反演，实现了在实际工业环境中的自动焊缝检测。

Abstract: Automated ultrasonic weld inspection remains a significant challenge in the
nondestructive evaluation (NDE) community to factors such as limited training
data (due to the complexity of curating experimental specimens or high-fidelity
simulations) and environmental volatility of many industrial settings
(resulting in the corruption of on-the-fly measurements). Thus, an end-to-end
machine learning (ML) workflow for acoustic weld inspection in realistic (i.e.,
industrial) settings has remained an elusive goal. This work addresses the
challenges of data curation and signal corruption by proposing workflow
consisting of a reduced-order modeling scheme, diffusion based distribution
alignment, and U-Net-based segmentation and inversion. A reduced-order
Helmholtz model based on Lamb wave theory is used to generate a comprehensive
dataset over varying weld heterogeneity and crack defects. The relatively
inexpensive low-order solutions provide a robust training dateset for inversion
models which are refined through a transfer learning stage using a limited set
of full 3D elastodynamic simulations. To handle out-of-distribution (OOD)
real-world measurements with varying and unpredictable noise distributions,
i.e., Laser Doppler Vibrometry scans, guided diffusion produces in-distribution
representations of OOD experimental LDV scans which are subsequently processed
by the inversion models. This integrated framework provides an end-to-end
solution for automated weld inspection on real data.

</details>


### [162] [Information Shapes Koopman Representation](https://arxiv.org/abs/2510.13025)
*Xiaoyuan Cheng,Wenxuan Yuan,Yiming Yang,Yuanzhao Zhang,Sibo Cheng,Yi He,Zhuo Sun*

Main category: cs.LG

TL;DR: 本文提出了一种新的基于信息论的 Koopman 算子学习框架，该框架通过平衡潜在变量的互信息和冯·诺依曼熵来解决表示学习中的表达性和简单性之间的权衡问题，从而获得更稳定和可解释的 Koopman 表示。


<details>
  <summary>Details</summary>
Motivation: 现有的 Koopman 算子学习方法在识别合适的有限维子空间方面面临挑战，尤其是在深度架构中，这主要是由于次优的表示学习，其中潜在变量未能平衡表达性和简单性。

Method: 本文提出了一种新的信息论拉格朗日公式，该公式显式地平衡了简单性和表达性，并基于此提出了一种新的算法，该算法鼓励简单性和表达性。

Result: 通过在各种动态系统上的验证，本文提出的方法比现有的 Koopman 学习方法表现更好，并且通过可视化学习到的流形，观察到与理论预测一致的经验结果。

Conclusion: 本文提出的基于信息论的 Koopman 算子学习框架能够获得更稳定和可解释的 Koopman 表示，并在各种动态系统上表现出更好的性能。

Abstract: The Koopman operator provides a powerful framework for modeling dynamical
systems and has attracted growing interest from the machine learning community.
However, its infinite-dimensional nature makes identifying suitable
finite-dimensional subspaces challenging, especially for deep architectures. We
argue that these difficulties come from suboptimal representation learning,
where latent variables fail to balance expressivity and simplicity. This
tension is closely related to the information bottleneck (IB) dilemma:
constructing compressed representations that are both compact and predictive.
Rethinking Koopman learning through this lens, we demonstrate that latent
mutual information promotes simplicity, yet an overemphasis on simplicity may
cause latent space to collapse onto a few dominant modes. In contrast,
expressiveness is sustained by the von Neumann entropy, which prevents such
collapse and encourages mode diversity. This insight leads us to propose an
information-theoretic Lagrangian formulation that explicitly balances this
tradeoff. Furthermore, we propose a new algorithm based on the Lagrangian
formulation that encourages both simplicity and expressiveness, leading to a
stable and interpretable Koopman representation. Beyond quantitative
evaluations, we further visualize the learned manifolds under our
representations, observing empirical results consistent with our theoretical
predictions. Finally, we validate our approach across a diverse range of
dynamical systems, demonstrating improved performance over existing Koopman
learning methods. The implementation is publicly available at
https://github.com/Wenxuan52/InformationKoopman.

</details>


### [163] [Bridging Idealized and Operational Models: An Explainable AI Framework for Earth System Emulators](https://arxiv.org/abs/2510.13030)
*Pouria Behnoudfar,Charlotte Moser,Marc Bocquet,Sibo Cheng,Nan Chen*

Main category: cs.LG

TL;DR: 提出了一种可解释的AI框架，用于地球系统模拟器，通过重新配置的潜在数据同化技术桥接模型层次结构，利用理想化模型的稀疏输出来提高全局精度。


<details>
  <summary>Details</summary>
Motivation: 高分辨率业务模型在模拟极端事件和统计分布方面存在偏差，而粗粒度理想化模型可以精确校准以表征特定动态和统计特征。不同模型因学科界限而相互隔离。

Method: 利用不同复杂性模型的互补优势，开发了一种可解释的AI框架，通过重新配置的潜在数据同化技术桥接模型层次结构，利用理想化模型的稀疏输出。

Result: 该桥接模型继承了业务模型的高分辨率和综合变量，同时通过理想化模型的有针对性的改进，实现了全局精度增强。在CMIP6 El Ni
o模拟中显著纠正了偏差。

Conclusion: 这项工作强调了推进理想化模型开发和加强建模社区之间沟通的重要性。

Abstract: Computer models are indispensable tools for understanding the Earth system.
While high-resolution operational models have achieved many successes, they
exhibit persistent biases, particularly in simulating extreme events and
statistical distributions. In contrast, coarse-grained idealized models isolate
fundamental processes and can be precisely calibrated to excel in
characterizing specific dynamical and statistical features. However, different
models remain siloed by disciplinary boundaries. By leveraging the
complementary strengths of models of varying complexity, we develop an
explainable AI framework for Earth system emulators. It bridges the model
hierarchy through a reconfigured latent data assimilation technique, uniquely
suited to exploit the sparse output from the idealized models. The resulting
bridging model inherits the high resolution and comprehensive variables of
operational models while achieving global accuracy enhancements through
targeted improvements from idealized models. Crucially, the mechanism of AI
provides a clear rationale for these advancements, moving beyond black-box
correction to physically insightful understanding in a computationally
efficient framework that enables effective physics-assisted digital twins and
uncertainty quantification. We demonstrate its power by significantly
correcting biases in CMIP6 simulations of El Ni\~no spatiotemporal patterns,
leveraging statistically accurate idealized models. This work also highlights
the importance of pushing idealized model development and advancing
communication between modeling communities.

</details>


### [164] [Randomness and Interpolation Improve Gradient Descent](https://arxiv.org/abs/2510.13040)
*Jiawen Li,Pascal Lefevre,Anwar Pp Abdul Majeed*

Main category: cs.LG

TL;DR: 本文介绍 IAGD 和 NRSGD 两种优化器，它们分别是基于 SGD 的改进。


<details>
  <summary>Details</summary>
Motivation: 为了加速收敛和避免过拟合。

Method: IAGD 利用牛顿插值加速收敛，NRSGD 引入噪声正则化。

Result: 在 CIFAR-10 和 CIFAR-100 数据集上，IAGD 和 NRSGD 在 CNN 上的表现优于 Keras 中的经典优化器。

Conclusion: IAGD 和 NRSGD 是 SGD 的有效改进方法。

Abstract: Based on Stochastic Gradient Descent (SGD), the paper introduces two
optimizers, named Interpolational Accelerating Gradient Descent (IAGD) as well
as Noise-Regularized Stochastic Gradient Descent (NRSGD). IAGD leverages
second-order Newton Interpolation to expedite the convergence process during
training, assuming relevancy in gradients between iterations. To avoid
over-fitting, NRSGD incorporates a noise regularization technique that
introduces controlled noise to the gradients during the optimization process.
Comparative experiments of this research are conducted on the CIFAR-10, and
CIFAR-100 datasets, benchmarking different CNNs(Convolutional Neural Networks)
with IAGD and NRSGD against classical optimizers in Keras Package. Results
demonstrate the potential of those two viable improvement methods in SGD,
implicating the effectiveness of the advancements.

</details>


### [165] [An Operational Deep Learning System for Satellite-Based High-Resolution Global Nowcasting](https://arxiv.org/abs/2510.13050)
*Shreya Agrawal,Mohammed Alewi Hassen,Emmanuel Asiedu Brempong,Boris Babenko,Fred Zyda,Olivia Graham,Di Li,Samier Merchant,Santiago Hincapie Potes,Tyler Russell,Danny Cheresnick,Aditya Prakash Kakkirala,Stephan Rasp,Avinatan Hassidim,Yossi Matias,Nal Kalchbrenner,Pramod Gupta,Jason Hickey,Aaron Bell*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种名为Global MetNet的全球机器学习临近预报模型，该模型利用多种数据源预测未来12小时的降水，并在数据稀疏地区表现出比传统方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统数值天气预报方法存在延迟高、分辨率低以及全球范围内准确性差距大的问题。现有的机器学习临近预报方法由于雷达覆盖不足，无法扩展到全球南方。

Method: 该模型利用全球降水 मिशन的CORRA数据集、地球静止卫星数据和全球数值天气预报数据，以约0.05度（约5公里）的空间分辨率和15分钟的时间分辨率运行。

Result: Global MetNet显著优于行业标准的每小时预报，并实现了显著更高的技能，使预报在比以前可用更大的世界区域更有用。在数据稀疏区域，该模型比美国最好的高分辨率数值天气预报模型表现出更好的技能。经过地面雷达和卫星数据的验证，该模型在关键指标（如临界成功指数和所有降水率和提前期的分数技能评分）方面显示出显着改进。

Conclusion: 该模型在一分钟内生成预测，使其易于部署到实时应用程序。它已经为Google搜索上的数百万用户部署。这项工作代表了减少全球预报质量差距以及将稀疏的高分辨率卫星观测结果整合到天气预报中的关键一步。

Abstract: Precipitation nowcasting, which predicts rainfall up to a few hours ahead, is
a critical tool for vulnerable communities in the Global South frequently
exposed to intense, rapidly developing storms. Timely forecasts provide a
crucial window to protect lives and livelihoods. Traditional numerical weather
prediction (NWP) methods suffer from high latency, low spatial and temporal
resolution, and significant gaps in accuracy across the world. Recent machine
learning-based nowcasting methods, common in the Global North, cannot be
extended to the Global South due to extremely sparse radar coverage. We present
Global MetNet, an operational global machine learning nowcasting model. It
leverages the Global Precipitation Mission's CORRA dataset, geostationary
satellite data, and global NWP data to predict precipitation for the next 12
hours. The model operates at a high resolution of approximately 0.05{\deg}
(~5km) spatially and 15 minutes temporally. Global MetNet significantly
outperforms industry-standard hourly forecasts and achieves significantly
higher skill, making forecasts useful over a much larger area of the world than
previously available. Our model demonstrates better skill in data-sparse
regions than even the best high-resolution NWP models achieve in the US.
Validated using ground radar and satellite data, it shows significant
improvements across key metrics like the critical success index and fractions
skill score for all precipitation rates and lead times. Crucially, our model
generates forecasts in under a minute, making it readily deployable for
real-time applications. It is already deployed for millions of users on Google
Search. This work represents a key step in reducing global disparities in
forecast quality and integrating sparse, high-resolution satellite observations
into weather forecasting.

</details>


### [166] [Time-Varying Optimization for Streaming Data Via Temporal Weighting](https://arxiv.org/abs/2510.13052)
*Muhammad Faraz Ul Abrar,Nicolò Michelusi,Erik G. Larsson*

Main category: cs.LG

TL;DR: 本文研究了通过时变优化视角从流数据中学习的问题，针对两种加权策略（均匀加权和折扣加权）下的梯度下降更新，推导了跟踪误差的界限。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中，时变优化已成为决策的重要课题。本文研究从流数据中学习的问题。

Method: 提出了一个结构化的、基于权重的公式，显式地捕捉了时变目标的流数据来源，其中在每个时间步，代理的目标是最小化所有过去数据样本上的加权平均损失。重点研究了两种特定的加权策略：(1) 均匀权重，平等对待所有样本；(2) 折扣权重，以几何方式衰减旧数据的影响。对于这两种方案，我们推导了梯度下降 (GD) 更新下“跟踪误差” (TE) 的严格界限。

Result: 在均匀加权下，TE 以 $\mathcal{O}(1/t)$ 的衰减率渐近消失，而折扣加权会产生一个非零误差下限，该下限由折扣因子和每个时间步执行的梯度更新次数控制。

Conclusion: 通过数值模拟验证了理论结果。

Abstract: Classical optimization theory deals with fixed, time-invariant objective
functions. However, time-varying optimization has emerged as an important
subject for decision-making in dynamic environments. In this work, we study the
problem of learning from streaming data through a time-varying optimization
lens. Unlike prior works that focus on generic formulations, we introduce a
structured, \emph{weight-based} formulation that explicitly captures the
streaming-data origin of the time-varying objective, where at each time step,
an agent aims to minimize a weighted average loss over all the past data
samples. We focus on two specific weighting strategies: (1) uniform weights,
which treat all samples equally, and (2) discounted weights, which
geometrically decay the influence of older data. For both schemes, we derive
tight bounds on the ``tracking error'' (TE), defined as the deviation between
the model parameter and the time-varying optimum at a given time step, under
gradient descent (GD) updates. We show that under uniform weighting, the TE
vanishes asymptotically with a $\mathcal{O}(1/t)$ decay rate, whereas
discounted weighting incurs a nonzero error floor controlled by the discount
factor and the number of gradient updates performed at each time step. Our
theoretical findings are validated through numerical simulations.

</details>


### [167] [Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games](https://arxiv.org/abs/2510.13060)
*Anupam Nayak,Tong Yang,Osman Yagan,Gauri Joshi,Yuejie Chi*

Main category: cs.LG

TL;DR: 这篇论文研究了强化学习中基于反向KL散度的正则化方法，并分析了其在博弈论环境下的理论优势。


<details>
  <summary>Details</summary>
Motivation: 研究KL正则化在博弈论环境下的理论收益，因为现有方法对此理解不足。

Method: 提出了OMG和SOMG算法，分别用于矩阵博弈和马尔可夫博弈，都基于最佳响应抽样和乐观奖励。

Result: OMG和SOMG算法在T步内实现了对数遗憾，其与KL正则化强度β成反比，并且具有与β无关的标准遗憾。

Conclusion: 所提出的算法在KL正则化下实现了改进的样本效率。

Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to
a fixed reference policy is widely used in modern reinforcement learning to
preserve the desired traits of the reference policy and sometimes to promote
exploration (using uniform reference policy, known as entropy regularization).
Beyond serving as a mere anchor, the reference policy can also be interpreted
as encoding prior knowledge about good actions in the environment. In the
context of alignment, recent game-theoretic approaches have leveraged KL
regularization with pretrained language models as reference policies, achieving
notable empirical success in self-play methods. Despite these advances, the
theoretical benefits of KL regularization in game-theoretic settings remain
poorly understood. In this work, we develop and analyze algorithms that
provably achieve improved sample efficiency under KL regularization. We study
both two-player zero-sum Matrix games and Markov games: for Matrix games, we
propose OMG, an algorithm based on best response sampling with optimistic
bonuses, and extend this idea to Markov games through the algorithm SOMG, which
also uses best response sampling and a novel concept of superoptimistic
bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales
inversely with the KL regularization strength $\beta$ in addition to the
standard $\widetilde{\mathcal{O}}(\sqrt{T})$ regret independent of $\beta$
which is attained in both regularized and unregularized settings

</details>


### [168] [Absolute indices for determining compactness, separability and number of clusters](https://arxiv.org/abs/2510.13065)
*Adil M. Bagirov,Ramiz M. Aliguliyev,Nargiz Sultanova,Sona Taheri*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的绝对聚类指数，用于确定聚类的紧凑性和可分离性。


<details>
  <summary>Details</summary>
Motivation: 在数据集中找到“真实”的聚类是一个具有挑战性的问题。不同的模型和算法获得的聚类解决方案不一定提供紧凑且分离良好的聚类或最佳数量的聚类。聚类有效性指标通常用于识别这些聚类。然而，这些指标通常是相对的，用于比较聚类算法或选择聚类算法的参数。此外，这些指标的成功取决于底层数据结构。

Method: 论文为每个聚类定义了一个紧凑性函数，为聚类对定义了一组相邻点。该函数用于确定每个聚类和整个聚类分布的紧凑性。相邻点集用于定义聚类之间的间隔和整体分布间隔。

Result: 论文使用多个合成和真实数据集，证明了这些新指标的性能，并将其与其他广泛使用的聚类有效性指标进行了比较。

Conclusion: 论文提出了新的绝对聚类指数，可以有效地确定聚类的紧凑性和可分离性，并识别真实的聚类数量。

Abstract: Finding "true" clusters in a data set is a challenging problem. Clustering
solutions obtained using different models and algorithms do not necessarily
provide compact and well-separated clusters or the optimal number of clusters.
Cluster validity indices are commonly applied to identify such clusters.
Nevertheless, these indices are typically relative, and they are used to
compare clustering algorithms or choose the parameters of a clustering
algorithm. Moreover, the success of these indices depends on the underlying
data structure. This paper introduces novel absolute cluster indices to
determine both the compactness and separability of clusters. We define a
compactness function for each cluster and a set of neighboring points for
cluster pairs. This function is utilized to determine the compactness of each
cluster and the whole cluster distribution. The set of neighboring points is
used to define the margin between clusters and the overall distribution margin.
The proposed compactness and separability indices are applied to identify the
true number of clusters. Using a number of synthetic and real-world data sets,
we demonstrate the performance of these new indices and compare them with other
widely-used cluster validity indices.

</details>


### [169] [NeuroRVQ: Multi-Scale EEG Tokenization for Generative Large Brainwave Models](https://arxiv.org/abs/2510.13068)
*Konstantinos Barmpas,Na Lee,Alexandros Koliousis,Yannis Panagakis,Dimitrios A. Adamos,Nikolaos Laskaris,Stefanos Zafeiriou*

Main category: cs.LG

TL;DR: NeuroRVQ: A new EEG foundation model with a codebook-based tokenizer that improves EEG signal reconstruction and downstream task performance.


<details>
  <summary>Details</summary>
Motivation: Existing EEG foundation models are limited by their signal tokenization modules, which fail to preserve high-frequency dynamics.

Method: A codebook-based tokenizer with multi-scale feature extraction, hierarchical residual vector quantization, and an EEG signal phase- and amplitude-aware loss function.

Result: NeuroRVQ achieves lower reconstruction error and outperforms existing LBMs on various downstream tasks.

Conclusion: NeuroRVQ establishes a strong prior for codebook-based general-purpose brainwave models.

Abstract: Electroencephalography (EEG) captures neural activity across multiple
temporal and spectral scales, yielding signals that are rich but complex for
representation learning. Recently, EEG foundation models trained to predict
masked signal-tokens have shown promise for learning generalizable
representations. However, their performance is hindered by their signal
tokenization modules. Existing neural tokenizers fail to preserve
high-frequency dynamics, limiting their ability to reconstruct EEG signals with
high fidelity. We introduce NeuroRVQ, a scalable Large Brainwave Model (LBM)
centered on a codebook-based tokenizer. Our tokenizer integrates: (i)
multi-scale feature extraction modules that capture the full frequency neural
spectrum; (ii) hierarchical residual vector quantization (RVQ) codebooks for
high-resolution encoding; and, (iii) an EEG signal phase- and amplitude-aware
loss function for efficient training. This design enables efficient EEG
compression while supporting accurate reconstruction across all frequency
bands, leading to robust generative masked modeling. Our empirical results
demonstrate that NeuroRVQ achieves lower reconstruction error and outperforms
existing LBMs on a variety of downstream tasks. More broadly, NeuroRVQ
tokenizer establishes a strong prior for codebook-based general-purpose
brainwave models, enabling advances in neural decoding, generative modeling and
multimodal biosignal integration.

</details>


### [170] [Transformer-based Scalable Beamforming Optimization via Deep Residual Learning](https://arxiv.org/abs/2510.13077)
*Yubo Zhang,Xiao-Yang Liu,Xiaodong Wang*

Main category: cs.LG

TL;DR: 本文提出了一种用于大规模MU-MISO信道下行链路波束成形的无监督深度学习框架，该框架离线训练，并通过轻量级前馈计算实现动态通信环境中的实时推理。


<details>
  <summary>Details</summary>
Motivation: 解决大规模MU-MISO信道下行链路波束成形问题，提高通信效率。

Method: 采用学习优化(L2O)范式，使用多层Transformer通过残差连接迭代地细化信道和波束形成器特征，并引入课程学习(CL)、半摊销学习和滑动窗口训练三种策略来增强训练。

Result: 在低到中等SNR下，该方案优于现有基线，在高SNR下，该方案接近WMMSE性能，同时比迭代和在线学习方法实现更快的推理。

Conclusion: 所提出的无监督深度学习框架能够有效解决大规模MU-MISO信道下行链路波束成形问题，并在性能和推理速度方面取得了显著的提升。

Abstract: We develop an unsupervised deep learning framework for downlink beamforming
in large-scale MU-MISO channels. The model is trained offline, allowing
real-time inference through lightweight feedforward computations in dynamic
communication environments. Following the learning-to-optimize (L2O) paradigm,
a multi-layer Transformer iteratively refines both channel and beamformer
features via residual connections. To enhance training, three strategies are
introduced: (i) curriculum learning (CL) to improve early-stage convergence and
avoid local optima, (ii) semi-amortized learning to refine each Transformer
block with a few gradient ascent steps, and (iii) sliding-window training to
stabilize optimization by training only a subset of Transformer blocks at a
time. Extensive simulations show that the proposed scheme outperforms existing
baselines at low-to-medium SNRs and closely approaches WMMSE performance at
high SNRs, while achieving substantially faster inference than iterative and
online learning approaches.

</details>


### [171] [DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference](https://arxiv.org/abs/2510.13087)
*Aditya Puttaparthi Tirumala*

Main category: cs.LG

TL;DR: DeepCausalMMM是一个Python包，它结合了深度学习、因果推理和营销科学，以克服传统营销组合建模方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统MMM方法假设营销渠道之间相互独立，难以捕捉复杂的时间动态和非线性饱和效应。

Method: 该软件包使用门控循环单元（GRU）自动学习时间模式，并通过有向无环图（DAG）学习营销渠道之间的统计依赖性和潜在因果结构。此外，它还实现了基于Hill方程的饱和曲线，以模拟收益递减并优化预算分配。

Result: 主要创新包括：(1) 数据驱动设计，超参数和转换从数据中学习或估计；(2) 具有共享和特定区域参数的多区域建模；(3) 稳健的统计方法，包括 Huber 损失和高级正则化；(4) 综合响应曲线分析；(5) 包含 14 个以上交互式仪表板的广泛可视化套件。

Conclusion: DeepCausalMMM通过结合深度学习、因果推理和营销科学，解决了传统MMM方法的局限性，并提供了一个全面的工具，用于理解渠道饱和度，并优化预算分配。

Abstract: Marketing Mix Modeling (MMM) is a statistical technique used to estimate the
impact of marketing activities on business outcomes such as sales, revenue, or
customer visits. Traditional MMM approaches often rely on linear regression or
Bayesian hierarchical models that assume independence between marketing
channels and struggle to capture complex temporal dynamics and non-linear
saturation effects [@Hanssens2005; @Ng2021Bayesian].
  DeepCausalMMM is a Python package that addresses these limitations by
combining deep learning, causal inference, and advanced marketing science. The
package uses Gated Recurrent Units (GRUs) to automatically learn temporal
patterns such as adstock (carryover effects) and lag, while simultaneously
learning statistical dependencies and potential causal structures between
marketing channels through Directed Acyclic Graph (DAG) learning
[@Zheng2018NOTEARS; @Gong2024CausalMMM]. Additionally, it implements Hill
equation-based saturation curves to model diminishing returns and optimize
budget allocation.
  Key innovations include: (1) a data-driven design where hyperparameters and
transformations (e.g., adstock decay, saturation curves) are learned or
estimated from data with sensible defaults, rather than requiring fixed
heuristics or manual specification, (2) multi-region modeling with both shared
and region-specific parameters, (3) robust statistical methods including Huber
loss and advanced regularization, (4) comprehensive response curve analysis for
understanding channel saturation, and (5) an extensive visualization suite with
14+ interactive dashboards for business insights.

</details>


### [172] [Neural Triangular Transport Maps: A New Approach Towards Sampling in Lattice QCD](https://arxiv.org/abs/2510.13112)
*Andrey Bryutkin,Youssef Marzouk*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的基于稀疏三角变换映射的归一化流方法，用于解决格子场理论中玻尔兹曼分布的采样问题。


<details>
  <summary>Details</summary>
Motivation: 格子场理论是计算物理的基本测试平台，但由于多模态和长程相关性，对其玻尔兹曼分布进行采样仍然具有挑战性。现有的归一化流方法在大型格子上的应用受到内存需求和模型表达能力的限制。

Method: 该论文提出了一种稀疏三角变换映射，它利用格子图在周期性边界条件下的条件独立结构，并使用单调修正神经网络(MRNN)。

Result: 该方法实现了精确稀疏性和近似稀疏性之间的平衡，实现了位点并行评估和线性时间复杂度。

Conclusion: 通过在二维$\\phi^4$模型上的实验，分析了节点标记对三角映射的稀疏性和性能的影响，并与混合蒙特卡罗(HMC)和已建立的流方法(RealNVP)进行了比较。

Abstract: Lattice field theories are fundamental testbeds for computational physics;
yet, sampling their Boltzmann distributions remains challenging due to
multimodality and long-range correlations. While normalizing flows offer a
promising alternative, their application to large lattices is often constrained
by prohibitive memory requirements and the challenge of maintaining sufficient
model expressivity. We propose sparse triangular transport maps that explicitly
exploit the conditional independence structure of the lattice graph under
periodic boundary conditions using monotone rectified neural networks (MRNN).
We introduce a comprehensive framework for triangular transport maps that
navigates the fundamental trade-off between \emph{exact sparsity} (respecting
marginal conditional independence in the target distribution) and
\emph{approximate sparsity} (computational tractability without fill-ins).
Restricting each triangular map component to a local past enables site-wise
parallel evaluation and linear time complexity in lattice size $N$, while
preserving the expressive, invertible structure. Using $\phi^4$ in two
dimensions as a controlled setting, we analyze how node labelings (orderings)
affect the sparsity and performance of triangular maps. We compare against
Hybrid Monte Carlo (HMC) and established flow approaches (RealNVP).

</details>


### [173] [On the Reasoning Abilities of Masked Diffusion Language Models](https://arxiv.org/abs/2510.13117)
*Anej Svete,Ashish Sabharwal*

Main category: cs.LG

TL;DR: 本文研究了掩码扩散模型（MDM）在文本处理中的推理能力和效率。


<details>
  <summary>Details</summary>
Motivation: 探索MDM在推理问题上的计算能力和并行性限制，这是传统自回归语言模型的替代方案。

Method: 通过将MDM与链式思考（CoT）和填充循环Transformer（PLT）等推理框架联系起来，在有限精度对数宽度设置下进行分析。

Result: 证明了MDM和多项式填充的PLT在指定设置下是等价的，并且MDM可以解决所有CoT增强Transformer可以解决的问题。此外，还展示了MDM比CoT Transformer更有效的解决的问题类别（包括正则语言）。

Conclusion: 并行生成使得MDM在某些问题上比CoT Transformer具有更快的推理速度，表明MDM在特定类型的推理任务上具有优势。

Abstract: Masked diffusion models (MDMs) for text offer a compelling alternative to
traditional autoregressive language models. Parallel generation makes them
efficient, but their computational capabilities and the limitations inherent to
their parallelism remain largely unexplored. To this end, we characterize what
types of reasoning problems MDMs can provably solve and how efficiently. We do
this by connecting MDMs to the well-understood reasoning frameworks of chain of
thought (CoT) and padded looped transformers (PLTs) in the finite-precision
log-width setting: We show that MDMs and polynomially-padded PLTs are, in fact,
equivalent in this setting, and that MDMs can solve all problems that
CoT-augmented transformers can. Moreover, we showcase classes of problems
(including regular languages) for which MDMs are inherently more efficient than
CoT transformers, where parallel generation allows for substantially faster
reasoning.

</details>


### [174] [Cluster-Based Client Selection for Dependent Multi-Task Federated Learning in Edge Computing](https://arxiv.org/abs/2510.13132)
*Jieping Luo,Qiyue Li,Zhizhang Liu,Hang Qi,Jiaying Yin,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出了一种新的联邦学习框架CoDa-FL，用于在移动边缘计算环境中解决依赖多任务设置下的客户端选择问题，旨在减少完成各种学习任务所需的总时间。


<details>
  <summary>Details</summary>
Motivation: 为了在移动边缘计算环境中减少完成各种学习任务所需的总时间，研究联邦学习中依赖多任务设置下的客户端选择问题。

Method: 提出了一种面向集群和依赖感知的框架CoDa-FL，通过基于集群的客户端选择和依赖任务分配来减少所需的总时间。该方法考虑使用Earth Mover's Distance (EMD)进行客户端聚类，并结合有向无环图的任务调度机制。

Result: 数值实验验证了CoDa-FL优于现有基准，在异构MEC设置下实现了更快的收敛速度、更低的通信和计算成本以及更高的学习精度。

Conclusion: 提出的CoDa-FL框架有效地解决了移动边缘计算环境中依赖多任务联邦学习的客户端选择问题，并在性能上优于现有方法。

Abstract: We study the client selection problem in Federated Learning (FL) within
mobile edge computing (MEC) environments, particularly under the dependent
multi-task settings, to reduce the total time required to complete various
learning tasks. We propose CoDa-FL, a Cluster-oriented and Dependency-aware
framework designed to reduce the total required time via cluster-based client
selection and dependent task assignment. Our approach considers Earth Mover's
Distance (EMD) for client clustering based on their local data distributions to
lower computational cost and improve communication efficiency. We derive a
direct and explicit relationship between intra-cluster EMD and the number of
training rounds required for convergence, thereby simplifying the otherwise
complex process of obtaining the optimal solution. Additionally, we incorporate
a directed acyclic graph-based task scheduling mechanism to effectively manage
task dependencies. Through numerical experiments, we validate that our proposed
CoDa-FL outperforms existing benchmarks by achieving faster convergence, lower
communication and computational costs, and higher learning accuracy under
heterogeneous MEC settings.

</details>


### [175] [Convergence, design and training of continuous-time dropout as a random batch method](https://arxiv.org/abs/2510.13134)
*Antonio Álvarez-López,Martín Hernández*

Main category: cs.LG

TL;DR: 本文研究了连续时间模型中的dropout正则化，通过随机批量方法的视角，这是一种最初旨在降低交互粒子系统计算成本的随机抽样方案。


<details>
  <summary>Details</summary>
Motivation: 研究dropout正则化在连续时间模型中的应用。

Method: 通过在长度为h的时间间隔内对神经元批次进行采样，构建一个无偏、适定的估计器来模拟dropout。建立了预期一致误差的轨迹收敛性，h呈线性速率。在分布层面上，建立了相关连续性方程的稳定性，在温和矩假设下，全变分误差为h^{1/2}阶。

Result: 在跨epochs进行固定批量抽样的训练过程中，基于Pontryagin的伴随分析限制了最优成本和控制以及梯度下降迭代中的偏差。比较了典型批量抽样方案的收敛速度，将标准Bernoulli dropout恢复为特殊情况，并推导了产生闭式最优h的成本-精度权衡。

Conclusion: 在单层神经元ODE上进行了验证，观察到了预测的速率、正则化效果以及良好的运行时间和内存配置文件。

Abstract: We study dropout regularization in continuous-time models through the lens of
random-batch methods -- a family of stochastic sampling schemes originally
devised to reduce the computational cost of interacting particle systems. We
construct an unbiased, well-posed estimator that mimics dropout by sampling
neuron batches over time intervals of length $h$. Trajectory-wise convergence
is established with linear rate in $h$ for the expected uniform error. At the
distribution level, we establish stability for the associated continuity
equation, with total-variation error of order $h^{1/2}$ under mild moment
assumptions. During training with fixed batch sampling across epochs, a
Pontryagin-based adjoint analysis bounds deviations in the optimal cost and
control, as well as in gradient-descent iterates. On the design side, we
compare convergence rates for canonical batch sampling schemes, recover
standard Bernoulli dropout as a special case, and derive a cost--accuracy
trade-off yielding a closed-form optimal $h$. We then specialize to a
single-layer neural ODE and validate the theory on classification and flow
matching, observing the predicted rates, regularization effects, and favorable
runtime and memory profiles.

</details>


### [176] [Behavioral Embeddings of Programs: A Quasi-Dynamic Approach for Optimization Prediction](https://arxiv.org/abs/2510.13158)
*Haolin Pan,Jinyuan Dong,Hongbin Zhang,Hongyu Lin,Mingjie Xing,Yanjun Wu*

Main category: cs.LG

TL;DR: 本文提出了一种新的程序表示框架，通过探测程序在不同优化序列下的行为变化来学习程序的优化敏感性，从而超越了静态表示和动态表示之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的程序表示方法存在两难：静态表示高效但缺乏对程序行为的洞察，动态表示提供深入的性能瓶颈信息但开销大且具有不确定性。

Method: 本文提出了程序行为谱（Program Behavior Spectrum），通过使用不同的优化序列探测程序的IR，并量化其静态特征的变化。然后，使用乘积量化（Product Quantization）将连续的反应向量离散化为结构化的组合子词，并使用多任务Transformer模型PQ-BERT预训练以学习这些行为代码的深层上下文语法。

Result: 在最佳Pass预测和-Oz Benefit预测两个代表性的编译器优化任务上，该方法优于最先进的静态基线方法。

Conclusion: 本文提出的准动态框架可以有效地表示程序的优化敏感性，并在编译器优化任务中取得了良好的效果。

Abstract: Learning effective numerical representations, or embeddings, of programs is a
fundamental prerequisite for applying machine learning to automate and enhance
compiler optimization. Prevailing paradigms, however, present a dilemma. Static
representations, derived from source code or intermediate representation (IR),
are efficient and deterministic but offer limited insight into how a program
will behave or evolve under complex code transformations. Conversely, dynamic
representations, which rely on runtime profiling, provide profound insights
into performance bottlenecks but are often impractical for large-scale tasks
due to prohibitive overhead and inherent non-determinism. This paper transcends
this trade-off by proposing a novel quasi-dynamic framework for program
representation. The core insight is to model a program's optimization
sensitivity. We introduce the Program Behavior Spectrum, a new representation
generated by probing a program's IR with a diverse set of optimization
sequences and quantifying the resulting changes in its static features. To
effectively encode this high-dimensional, continuous spectrum, we pioneer a
compositional learning approach. Product Quantization is employed to discretize
the continuous reaction vectors into structured, compositional sub-words.
Subsequently, a multi-task Transformer model, termed PQ-BERT, is pre-trained to
learn the deep contextual grammar of these behavioral codes. Comprehensive
experiments on two representative compiler optimization tasks -- Best Pass
Prediction and -Oz Benefit Prediction -- demonstrate that our method
outperforms state-of-the-art static baselines. Our code is publicly available
at https://github.com/Panhaolin2001/PREP/.

</details>


### [177] [Universally Invariant Learning in Equivariant GNNs](https://arxiv.org/abs/2510.13169)
*Jiacheng Cen,Anyi Li,Ning Lin,Tingyang Xu,Yu Rong,Deli Zhao,Zihe Wang,Wenbing Huang*

Main category: cs.LG

TL;DR: 本研究提出了一种构建完整等变图神经网络(GNN)的有效框架，该框架基于几何图的规范形式和满秩可操纵基集。


<details>
  <summary>Details</summary>
Motivation: 为了实现等变GNN的完备性，网络必须有效捕获不同节点之间复杂的多体相互作用，而先前的方法通常计算成本高昂且没有多项式时间解决方案。

Method: 该方法通过两个关键组件实现完整的等变GNN：几何图的规范形式和满秩可操纵基集。利用这一发现，我们提出了一种基于EGNN和TFN构建完整等变GNN的有效算法。

Result: 实验结果表明，该模型仅需几层即可表现出卓越的完整性和出色的性能，从而显着降低了计算开销，同时保持了强大的实际功效。

Conclusion: 该研究提出了一个在理论上完善的框架，用于构建高效且实用的完整等变GNN。

Abstract: Equivariant Graph Neural Networks (GNNs) have demonstrated significant
success across various applications. To achieve completeness -- that is, the
universal approximation property over the space of equivariant functions -- the
network must effectively capture the intricate multi-body interactions among
different nodes. Prior methods attain this via deeper architectures, augmented
body orders, or increased degrees of steerable features, often at high
computational cost and without polynomial-time solutions. In this work, we
present a theoretically grounded framework for constructing complete
equivariant GNNs that is both efficient and practical. We prove that a complete
equivariant GNN can be achieved through two key components: 1) a complete
scalar function, referred to as the canonical form of the geometric graph; and
2) a full-rank steerable basis set. Leveraging this finding, we propose an
efficient algorithm for constructing complete equivariant GNNs based on two
common models: EGNN and TFN. Empirical results demonstrate that our model
demonstrates superior completeness and excellent performance with only a few
layers, thereby significantly reducing computational overhead while maintaining
strong practical efficacy.

</details>


### [178] [Information-Theoretic Criteria for Knowledge Distillation in Multimodal Learning](https://arxiv.org/abs/2510.13182)
*Rongrong Xie,Yizhou Xu,Guido Sanguinetti*

Main category: cs.LG

TL;DR: 本文研究了跨模态知识蒸馏（KD）技术，旨在通过将来自更丰富的“教师”模态的信息传递给较弱的“学生”模态来提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管跨模态KD在各种应用中取得了一些成功，但由于缺乏理论理解，它并不总能改善结果。为了解决这个问题，本文提出了跨模态互补假设（CCH）。

Method: 本文在联合高斯模型中对CCH进行了理论验证，并在包括图像、文本、视频、音频和癌症相关组学数据在内的各种多模态数据集中进一步证实了它。

Result: 研究结果表明，当教师和学生表征之间的互信息超过学生表征和标签之间的互信息时，跨模态KD是有效的。

Conclusion: 本研究为理解跨模态KD建立了一个新的理论框架，并提供了基于CCH准则选择最佳教师模态以提高较弱模态性能的实用指南。

Abstract: The rapid increase in multimodal data availability has sparked significant
interest in cross-modal knowledge distillation (KD) techniques, where richer
"teacher" modalities transfer information to weaker "student" modalities during
model training to improve performance. However, despite successes across
various applications, cross-modal KD does not always result in improved
outcomes, primarily due to a limited theoretical understanding that could
inform practice. To address this gap, we introduce the Cross-modal
Complementarity Hypothesis (CCH): we propose that cross-modal KD is effective
when the mutual information between teacher and student representations exceeds
the mutual information between the student representation and the labels. We
theoretically validate the CCH in a joint Gaussian model and further confirm it
empirically across diverse multimodal datasets, including image, text, video,
audio, and cancer-related omics data. Our study establishes a novel theoretical
framework for understanding cross-modal KD and offers practical guidelines
based on the CCH criterion to select optimal teacher modalities for improving
the performance of weaker modalities.

</details>


### [179] [CleverCatch: A Knowledge-Guided Weak Supervision Model for Fraud Detection](https://arxiv.org/abs/2510.13205)
*Amirhossein Mozafari,Kourosh Hashemi,Erfan Shafagh,Soroush Motamedi,Azar Taheri Tayebi,Mohammad A. Tayebi*

Main category: cs.LG

TL;DR: 本文提出了一种名为 CleverCatch 的知识引导弱监督模型，用于检测欺诈性处方行为，提高了准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于标记数据的有限性、不断变化的欺诈策略以及医疗记录的高维度，医疗保健欺诈检测仍然是一项严峻的挑战。传统的监督方法受到极端标签稀缺性的挑战，而纯粹的非监督方法通常无法捕捉到临床上有意义的异常。

Method: 该方法将结构化领域知识整合到一个神经架构中，该架构在共享嵌入空间内对齐规则和数据样本。通过在代表合规和违规的合成数据上联合训练编码器，CleverCatch 学习软规则嵌入，推广到复杂的真实世界数据集。

Result: 在大型真实世界数据集上的实验表明，CleverCatch 优于四种最先进的异常检测基线，在 AUC 中平均提高了 1.3%，在召回率中提高了 3.4%。

Conclusion: 将专家规则嵌入到学习过程中，不仅提高了检测精度，而且提高了透明度，为医疗保健欺诈检测等高风险领域提供了一种可解释的方法。

Abstract: Healthcare fraud detection remains a critical challenge due to limited
availability of labeled data, constantly evolving fraud tactics, and the high
dimensionality of medical records. Traditional supervised methods are
challenged by extreme label scarcity, while purely unsupervised approaches
often fail to capture clinically meaningful anomalies. In this work, we
introduce CleverCatch, a knowledge-guided weak supervision model designed to
detect fraudulent prescription behaviors with improved accuracy and
interpretability. Our approach integrates structured domain expertise into a
neural architecture that aligns rules and data samples within a shared
embedding space. By training encoders jointly on synthetic data representing
both compliance and violation, CleverCatch learns soft rule embeddings that
generalize to complex, real-world datasets. This hybrid design enables
data-driven learning to be enhanced by domain-informed constraints, bridging
the gap between expert heuristics and machine learning. Experiments on the
large-scale real-world dataset demonstrate that CleverCatch outperforms four
state-of-the-art anomaly detection baselines, yielding average improvements of
1.3\% in AUC and 3.4\% in recall. Our ablation study further highlights the
complementary role of expert rules, confirming the adaptability of the
framework. The results suggest that embedding expert rules into the learning
process not only improves detection accuracy but also increases transparency,
offering an interpretable approach for high-stakes domains such as healthcare
fraud detection.

</details>


### [180] [Performance Evaluation of Ising and QUBO Variable Encodings in Boltzmann Machine Learning](https://arxiv.org/abs/2510.13210)
*Yasushi Hasegawa,Masayuki Ohzeki*

Main category: cs.LG

TL;DR: 本文比较了玻尔兹曼机学习中Ising和QUBO编码，发现QUBO编码在随机梯度下降法下收敛较慢，但自然梯度下降法表现相似。Ising编码提供更快的收敛，而QUBO编码可以通过预处理来改善。


<details>
  <summary>Details</summary>
Motivation: 研究玻尔兹曼机学习中不同编码方式（Ising和QUBO）对模型训练的影响。

Method: 通过固定模型、采样器和步长，比较Ising和QUBO编码在玻尔兹曼机学习中的表现，并利用费sher信息矩阵等于充分统计量协方差的特性进行可视化分析。

Result: QUBO编码在Fisher信息矩阵中产生更大的交叉项，导致更多的小特征值方向和较低的谱熵，从而降低了随机梯度下降法的收敛速度。而自然梯度下降法由于重参数化不变性，在不同编码方式下表现出相似的收敛性。Ising编码提供更快的收敛速度。

Conclusion: Ising编码为基于SGD的训练提供更快的收敛，而对于QUBO编码，中心化/缩放或NGD风格的预处理可以减轻曲率病理。这些结果阐明了表征如何影响玻尔兹曼机中的信息几何和有限时间学习动态，并为变量编码和预处理提供了可操作的指导。

Abstract: We compare Ising ({-1,+1}) and QUBO ({0,1}) encodings for Boltzmann machine
learning under a controlled protocol that fixes the model, sampler, and step
size. Exploiting the identity that the Fisher information matrix (FIM) equals
the covariance of sufficient statistics, we visualize empirical moments from
model samples and reveal systematic, representation-dependent differences. QUBO
induces larger cross terms between first- and second-order statistics, creating
more small-eigenvalue directions in the FIM and lowering spectral entropy. This
ill-conditioning explains slower convergence under stochastic gradient descent
(SGD). In contrast, natural gradient descent (NGD)-which rescales updates by
the FIM metric-achieves similar convergence across encodings due to
reparameterization invariance. Practically, for SGD-based training, the Ising
encoding provides more isotropic curvature and faster convergence; for QUBO,
centering/scaling or NGD-style preconditioning mitigates curvature pathologies.
These results clarify how representation shapes information geometry and
finite-time learning dynamics in Boltzmann machines and yield actionable
guidelines for variable encoding and preprocessing.

</details>


### [181] [Towards Understanding Valuable Preference Data for Large Language Model Alignment](https://arxiv.org/abs/2510.13212)
*Zizhuo Zhang,Qizhou Wang,Shanshan Ye,Jianing Zhu,Jiangchao Yao,Bo Han,Masashi Sugiyama*

Main category: cs.LG

TL;DR: 提出了一种新的数据选择方法，以提高大型语言模型（LLM）对齐的性能，通过选择更有价值的偏好数据，可以使用更少的数据实现更好的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常使用外部奖励模型或现成的LLM来预处理原始训练数据集，以识别有价值的偏好对，但很少检查单个选择的数据点是否真正有益。本文旨在评估数据质量，并提高偏好数据选择方法的适应性。

Method: 提出了截断影响函数（TIF）来评估数据质量，并提出了两种候选评分函数（SFs），这些函数与TIF呈正相关且计算更简单。结合这些SFs以抵消其不同的误差来源，从而实现简单而有效的数据选择规则。

Result: 实验结果表明，使用更少的数据可以实现更好的对齐性能。

Conclusion: 本文的研究结果表明，偏好数据质量是模型固有的属性，并且提出的新方法可以更精确地选择有价值的偏好数据，从而提高LLM的对齐性能。

Abstract: Large language model (LLM) alignment is typically achieved through learning
from human preference comparisons, making the quality of preference data
critical to its success. Existing studies often pre-process raw training
datasets to identify valuable preference pairs using external reward models or
off-the-shelf LLMs, achieving improved overall performance but rarely examining
whether individual, selected data point is genuinely beneficial. We assess data
quality through individual influence on validation data using our newly
proposed truncated influence function (TIF), which mitigates the over-scoring
present in traditional measures and reveals that preference data quality is
inherently a property of the model. In other words, a data pair that benefits
one model may harm another. This leaves the need to improve the preference data
selection approaches to be adapting to specific models. To this end, we
introduce two candidate scoring functions (SFs) that are computationally
simpler than TIF and positively correlated with it. They are also model
dependent and can serve as potential indicators of individual data quality for
preference data selection. Furthermore, we observe that these SFs inherently
exhibit errors when compared to TIF. To this end, we combine them to offset
their diverse error sources, resulting in a simple yet effective data selection
rule that enables the models to achieve a more precise selection of valuable
preference data. We conduct experiments across diverse alignment benchmarks and
various LLM families, with results demonstrating that better alignment
performance can be achieved using less data, showing the generality of our
findings and new methods.

</details>


### [182] [Rethinking Graph Domain Adaptation: A Spectral Contrastive Perspective](https://arxiv.org/abs/2510.13254)
*Haoyu Zhang,Yuxuan Cheng,Wenqi Fan,Yulong Chen,Yifan Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种名为 FracNet 的频率感知对比图神经网络，用于解决图神经网络中的域适应问题。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络在领域适应方面存在问题，因为它们无法区分全局和局部模式，导致领域转移。

Method: 该方法将图分解为高频和低频分量，并执行频率感知的领域适应。此外，还集成了对比学习框架。

Result: 大量实验表明，该方法优于现有方法。

Conclusion: 本文提出了一种新的图神经网络领域自适应方法，并通过实验验证了其有效性。

Abstract: Graph neural networks (GNNs) have achieved remarkable success in various
domains, yet they often struggle with domain adaptation due to significant
structural distribution shifts and insufficient exploration of transferable
patterns. One of the main reasons behind this is that traditional approaches do
not treat global and local patterns discriminatingly so that some local details
in the graph may be violated after multi-layer GNN. Our key insight is that
domain shifts can be better understood through spectral analysis, where
low-frequency components often encode domain-invariant global patterns, and
high-frequency components capture domain-specific local details. As such, we
propose FracNet (\underline{\textbf{Fr}}equency \underline{\textbf{A}}ware
\underline{\textbf{C}}ontrastive Graph \underline{\textbf{Net}}work) with two
synergic modules to decompose the original graph into high-frequency and
low-frequency components and perform frequency-aware domain adaption. Moreover,
the blurring boundary problem of domain adaptation is improved by integrating
with a contrastive learning framework. Besides the practical implication, we
also provide rigorous theoretical proof to demonstrate the superiority of
FracNet. Extensive experiments further demonstrate significant improvements
over state-of-the-art approaches.

</details>


### [183] [Hypernetworks for Perspectivist Adaptation](https://arxiv.org/abs/2510.13259)
*Daniil Ignatev,Denis Paperno,Massimo Poesio*

Main category: cs.LG

TL;DR: 本文提出了一种参数高效的视角感知分类方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视角感知分类研究在参数效率方面存在瓶颈。

Method: 将超网络+适配器的组合应用于视角分类。

Result: 该方案在仇恨言论和毒性检测中可以与专门的模型竞争，同时使用更少的参数。

Conclusion: 该方案与架构无关，可以应用于各种基础模型。

Abstract: The task of perspective-aware classification introduces a bottleneck in terms
of parametric efficiency that did not get enough recognition in existing
studies. In this article, we aim to address this issue by applying an existing
architecture, the hypernetwork+adapters combination, to perspectivist
classification. Ultimately, we arrive at a solution that can compete with
specialized models in adopting user perspectives on hate speech and toxicity
detection, while also making use of considerably fewer parameters. Our solution
is architecture-agnostic and can be applied to a wide range of base models out
of the box.

</details>


### [184] [BlendFL: Blended Federated Learning for Handling Multimodal Data Heterogeneity](https://arxiv.org/abs/2510.13266)
*Alejandro Guerra-Manzanares,Omar El-Herraoui,Michail Maniatakos,Farah E. Shamout*

Main category: cs.LG

TL;DR: BlendFL 是一个新的联邦学习框架，它可以无缝地融合水平和垂直联邦学习的原理，从而解决多模态数据异构性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习框架在处理多模态数据异构性方面存在不足，因为它们只能在满足特定假设的理想环境下有效。为了解决这个问题，我们提出了 BlendFL。

Method: BlendFL 融合了水平和垂直联邦学习的原理，并采用了一种自适应的全局模型聚合策略 BlendAvg。此外，BlendFL 还具有去中心化的推理机制。

Result: 在大型真实世界多模态医疗数据集和流行的多模态基准测试中，BlendFL 在多模态和单模态分类方面均优于其他最先进的基线方法。消融研究表明，与传统方法相比，BlendFL 的收敛速度更快。

Conclusion: BlendFL 有潜力处理多模态数据异构性，并加速在医疗保健和金融等数据隐私至关重要的实际场景中的协作学习。

Abstract: One of the key challenges of collaborative machine learning, without data
sharing, is multimodal data heterogeneity in real-world settings. While
Federated Learning (FL) enables model training across multiple clients,
existing frameworks, such as horizontal and vertical FL, are only effective in
`ideal' settings that meet specific assumptions. Hence, they struggle to
address scenarios where neither all modalities nor all samples are represented
across the participating clients. To address this gap, we propose BlendFL, a
novel FL framework that seamlessly blends the principles of horizontal and
vertical FL in a synchronized and non-restrictive fashion despite the asymmetry
across clients. Specifically, any client within BlendFL can benefit from either
of the approaches, or both simultaneously, according to its available dataset.
In addition, BlendFL features a decentralized inference mechanism, empowering
clients to run collaboratively trained local models using available local data,
thereby reducing latency and reliance on central servers for inference. We also
introduce BlendAvg, an adaptive global model aggregation strategy that
prioritizes collaborative model updates based on each client's performance. We
trained and evaluated BlendFL and other state-of-the-art baselines on three
classification tasks using a large-scale real-world multimodal medical dataset
and a popular multimodal benchmark. Our results highlight BlendFL's superior
performance for both multimodal and unimodal classification. Ablation studies
demonstrate BlendFL's faster convergence compared to traditional approaches,
accelerating collaborative learning. Overall, in our study we highlight the
potential of BlendFL for handling multimodal data heterogeneity for
collaborative learning in real-world settings where data privacy is crucial,
such as in healthcare and finance.

</details>


### [185] [To Steer or Not to Steer? Mechanistic Error Reduction with Abstention for Language Models](https://arxiv.org/abs/2510.13290)
*Anna Hedström,Salim I. Amoukou,Tom Bewley,Saumitra Mishra,Manuela Veloso*

Main category: cs.LG

TL;DR: MERA是一种通过选择性干预减少语言模型(LM)误差的框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于固定、手动调整的steering strengths，经常导致欠steering或过steering。

Method: MERA通过优化干预方向和校准steering的时机和程度来解决这些限制。

Result: 在不同的数据集和LM家族的实验表明，MERA可以安全、有效、无损地纠正错误，并且优于现有的基线。

Conclusion: MERA是一种通用的、高效的mechanistic activation steering方法，可以应用于现有的steering技术之上，以进一步提高它们的性能。

Abstract: We introduce Mechanistic Error Reduction with Abstention (MERA), a principled
framework for steering language models (LMs) to mitigate errors through
selective, adaptive interventions. Unlike existing methods that rely on fixed,
manually tuned steering strengths, often resulting in under or oversteering,
MERA addresses these limitations by (i) optimising the intervention direction,
and (ii) calibrating when, and how much to steer, thereby provably improving
performance or abstaining when no confident correction is possible. Experiments
across diverse datasets, and LM families demonstrate safe, effective,
non-degrading error correction, and that MERA outperforms existing baselines.
Moreover, MERA can be applied on top of existing steering techniques to further
enhance their performance, establishing it as a general-purpose, and efficient
approach to mechanistic activation steering.

</details>


### [186] [Federated Conditional Conformal Prediction via Generative Models](https://arxiv.org/abs/2510.13297)
*Rui Xu,Sihong Xie*

Main category: cs.LG

TL;DR: 提出了一种新的联邦条件共形预测（Fed-CCP）方法，通过生成模型实现条件覆盖，以适应本地数据异质性。


<details>
  <summary>Details</summary>
Motivation: 标准的共形预测(CP)假设i.i.d.数据，这在联邦学习环境中是不成立的，因为客户端分布差异很大。现有的联邦CP方法维护每个客户端的边际覆盖率，但这种保证通常不能反映输入条件的不确定性。

Method: 利用生成模型（如正态化流或扩散模型）来近似条件数据分布，而不需要共享原始数据。这使得每个客户端都可以在本地校准反映其独特不确定性的共形分数，同时通过联邦聚合保持全局一致性。

Result: 在真实数据集上的实验表明，Fed-CCP实现了更自适应的预测集。

Conclusion: Fed-CCP方法通过生成模型实现了条件覆盖，更适应本地数据异质性，并在真实数据集上表现出更自适应的预测集。

Abstract: Conformal Prediction (CP) provides distribution-free uncertainty
quantification by constructing prediction sets that guarantee coverage of the
true labels. This reliability makes CP valuable for high-stakes federated
learning scenarios such as multi-center healthcare. However, standard CP
assumes i.i.d. data, which is violated in federated settings where client
distributions differ substantially. Existing federated CP methods address this
by maintaining marginal coverage on each client, but such guarantees often fail
to reflect input-conditional uncertainty. In this work, we propose Federated
Conditional Conformal Prediction (Fed-CCP) via generative models, which aims
for conditional coverage that adapts to local data heterogeneity. Fed-CCP
leverages generative models, such as normalizing flows or diffusion models, to
approximate conditional data distributions without requiring the sharing of raw
data. This enables each client to locally calibrate conformal scores that
reflect its unique uncertainty, while preserving global consistency through
federated aggregation. Experiments on real datasets demonstrate that Fed-CCP
achieves more adaptive prediction sets.

</details>


### [187] [Km-scale dynamical downscaling through conformalized latent diffusion models](https://arxiv.org/abs/2510.13301)
*Alessandro Brusaferri,Andrea Ballarino*

Main category: cs.LG

TL;DR: 本研究使用 conformal prediction 框架增强了降尺度流程，以解决生成扩散模型（DM）在降尺度中过度自信预测的问题，从而提高高分辨率气象场概率降尺度的可信度。


<details>
  <summary>Details</summary>
Motivation: 在高分辨率气象场中，从粗尺度模拟中获得高分辨率气象场至关重要。生成扩散模型（DM）作为一种数据驱动工具，可提供重建保真度和可扩展的采样以支持不确定性量化。但是，DM 缺乏针对过度自信预测的有限样本保证，从而导致网格点级别的不确定性估计不正确。

Method: 通过 conformal prediction 框架增强降尺度流程。具体来说，对 DM 的样本进行后处理，以得出条件分位数估计，并将其合并到针对具有有限样本边际有效性的局部自适应预测间隔的 conformalized 分位数回归过程中。

Result: 在意大利的 ERA5 再分析数据上进行了评估，结果表明，与 DM 基线相比，网格点级别的不确定性估计具有显着改善的覆盖率和稳定的概率评分。

Conclusion: Conformalized 生成模型有潜力为高分辨率气象场提供更可信的概率降尺度。

Abstract: Dynamical downscaling is crucial for deriving high-resolution meteorological
fields from coarse-scale simulations, enabling detailed analysis for critical
applications such as weather forecasting and renewable energy modeling.
Generative Diffusion models (DMs) have recently emerged as powerful data-driven
tools for this task, offering reconstruction fidelity and more scalable
sampling supporting uncertainty quantification. However, DMs lack finite-sample
guarantees against overconfident predictions, resulting in miscalibrated
grid-point-level uncertainty estimates hindering their reliability in
operational contexts. In this work, we tackle this issue by augmenting the
downscaling pipeline with a conformal prediction framework. Specifically, the
DM's samples are post-processed to derive conditional quantile estimates,
incorporated into a conformalized quantile regression procedure targeting
locally adaptive prediction intervals with finite-sample marginal validity. The
proposed approach is evaluated on ERA5 reanalysis data over Italy, downscaled
to a 2-km grid. Results demonstrate grid-point-level uncertainty estimates with
markedly improved coverage and stable probabilistic scores relative to the DM
baseline, highlighting the potential of conformalized generative models for
more trustworthy probabilistic downscaling to high-resolution meteorological
fields.

</details>


### [188] [Isolation-based Spherical Ensemble Representations for Anomaly Detection](https://arxiv.org/abs/2510.13311)
*Yang Cao,Sikun Yang,Hao Tian,Kai He,Lianyong Qi,Ming Liu,Yujiu Yang*

Main category: cs.LG

TL;DR: 提出了一种新的异常检测方法，通过使用超球体半径作为局部密度特征的代理，构建集成表示，并引入基于相似性的评分方法来衡量模式一致性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督异常检测方法存在分布假设冲突、计算效率低和难以处理不同异常类型的挑战。

Method: 提出了 ISER（基于隔离的球形集成表示），它扩展了现有的基于隔离的方法，使用超球体半径作为局部密度特征的代理，并构建集成表示，其中超球体半径编码密度信息。引入了一种新的基于相似性的评分方法，通过将集成表示与理论异常参考模式进行比较来衡量模式一致性。

Result: 在 22 个真实世界数据集上的综合实验表明，ISER 的性能优于 11 种基线方法。

Conclusion: ISER 方法优于现有方法，并在异常检测方面表现出卓越的性能。

Abstract: Anomaly detection is a critical task in data mining and management with
applications spanning fraud detection, network security, and log monitoring.
Despite extensive research, existing unsupervised anomaly detection methods
still face fundamental challenges including conflicting distributional
assumptions, computational inefficiency, and difficulty handling different
anomaly types. To address these problems, we propose ISER (Isolation-based
Spherical Ensemble Representations) that extends existing isolation-based
methods by using hypersphere radii as proxies for local density characteristics
while maintaining linear time and constant space complexity. ISER constructs
ensemble representations where hypersphere radii encode density information:
smaller radii indicate dense regions while larger radii correspond to sparse
areas. We introduce a novel similarity-based scoring method that measures
pattern consistency by comparing ensemble representations against a theoretical
anomaly reference pattern. Additionally, we enhance the performance of
Isolation Forest by using ISER and adapting the scoring function to address
axis-parallel bias and local anomaly detection limitations. Comprehensive
experiments on 22 real-world datasets demonstrate ISER's superior performance
over 11 baseline methods.

</details>


### [189] [RockNet: Distributed Learning on Ultra-Low-Power Devices](https://arxiv.org/abs/2510.13320)
*Alexander Gräfe,Fabian Mager,Marco Zimmerling,Sebastian Trimpe*

Main category: cs.LG

TL;DR: 本文提出了一种名为RockNet的新TinyML方法，专门为超低功耗硬件设计，可在时间序列分类中实现最先进的精度，而无需离线预训练。


<details>
  <summary>Details</summary>
Motivation: 由于隐私和延迟问题，人们越来越有兴趣将训练从传统的基于云的计算转移到设备上处理(TinyML)。然而，CPS通常由超低功耗微控制器组成，其有限的计算资源使得训练具有挑战性。

Method: RockNet是一种分布式学习方法，集成了ML和无线通信，利用所有设备进行专用计算高效分类器的分布式训练，这些分类器需要最小的通信开销来实现并行化。结合定制和高效的无线多跳通信协议，我们的方法克服了分布式学习中经常出现的通信瓶颈。

Result: 在包含20个超低功耗设备的测试平台上进行的硬件实验表明了RockNet的有效性。它成功地从零开始学习时间序列分类任务，超过了最新的神经网络微控制器训练方法的准确率高达2倍。当从一个中心设备扩展到20个设备时，RockNet的分布式ML架构将每个设备的内存、延迟和能耗降低了高达90%。

Conclusion: 我们的结果表明，分布式ML、分布式计算和通信的紧密集成首次实现了在具有最先进精度的超低功耗硬件上进行训练。

Abstract: As Machine Learning (ML) becomes integral to Cyber-Physical Systems (CPS),
there is growing interest in shifting training from traditional cloud-based to
on-device processing (TinyML), for example, due to privacy and latency
concerns. However, CPS often comprise ultra-low-power microcontrollers, whose
limited compute resources make training challenging. This paper presents
RockNet, a new TinyML method tailored for ultra-low-power hardware that
achieves state-of-the-art accuracy in timeseries classification, such as fault
or malware detection, without requiring offline pretraining. By leveraging that
CPS consist of multiple devices, we design a distributed learning method that
integrates ML and wireless communication. RockNet leverages all devices for
distributed training of specialized compute efficient classifiers that need
minimal communication overhead for parallelization. Combined with tailored and
efficient wireless multi-hop communication protocols, our approach overcomes
the communication bottleneck that often occurs in distributed learning.
Hardware experiments on a testbed with 20 ultra-low-power devices demonstrate
RockNet's effectiveness. It successfully learns timeseries classification tasks
from scratch, surpassing the accuracy of the latest approach for neural network
microcontroller training by up to 2x. RockNet's distributed ML architecture
reduces memory, latency and energy consumption per device by up to 90 % when
scaling from one central device to 20 devices. Our results show that a tight
integration of distributed ML, distributed computing, and communication
enables, for the first time, training on ultra-low-power hardware with
state-of-the-art accuracy.

</details>


### [190] [When In Doubt, Abstain: The Impact of Abstention on Strategic Classification](https://arxiv.org/abs/2510.13327)
*Lina Alkarmi,Ziyuan Huang,Mingyan Liu*

Main category: cs.LG

TL;DR: 本文研究了策略分类中classifier abstention的应用，探讨了它如何影响agent的行为以及principal应该如何优化利用它。


<details>
  <summary>Details</summary>
Motivation: 算法决策越来越普遍，但也容易受到寻求有利结果的agent的策略性操纵。Classifier abstention可以显著提高分类器的准确性。

Method: 本文将这种交互建模为一个Stackelberg博弈，其中principal（作为分类器）首先宣布其决策策略，然后strategic agent（作为follower）操纵其特征以获得期望的结果。本文重点关注二元分类器，其中agent操纵可观察的特征而不是其真实特征。

Result: 研究表明，即使在存在strategic agent的情况下，最佳的abstention也能确保principal的效用（或损失）不比在非abstention设置中差。此外，abstention还可以作为一种威慑操纵的手段，增加agent（尤其是那些不太合格的agent）进行操纵以获得积极结果的成本。

Conclusion: 这些结果表明，abstention是减少算法决策系统中策略行为负面影响的宝贵工具。

Abstract: Algorithmic decision making is increasingly prevalent, but often vulnerable
to strategic manipulation by agents seeking a favorable outcome. Prior research
has shown that classifier abstention (allowing a classifier to decline making a
decision due to insufficient confidence) can significantly increase classifier
accuracy. This paper studies abstention within a strategic classification
context, exploring how its introduction impacts strategic agents' responses and
how principals should optimally leverage it. We model this interaction as a
Stackelberg game where a principal, acting as the classifier, first announces
its decision policy, and then strategic agents, acting as followers, manipulate
their features to receive a desired outcome. Here, we focus on binary
classifiers where agents manipulate observable features rather than their true
features, and show that optimal abstention ensures that the principal's utility
(or loss) is no worse than in a non-abstention setting, even in the presence of
strategic agents. We also show that beyond improving accuracy, abstention can
also serve as a deterrent to manipulation, making it costlier for agents,
especially those less qualified, to manipulate to achieve a positive outcome
when manipulation costs are significant enough to affect agent behavior. These
results highlight abstention as a valuable tool for reducing the negative
effects of strategic behavior in algorithmic decision making systems.

</details>


### [191] [Thompson Sampling via Fine-Tuning of LLMs](https://arxiv.org/abs/2510.13328)
*Nicolas Menet,Aleksandar Terzić,Andreas Krause,Abbas Rahimi*

Main category: cs.LG

TL;DR: 提出了一种基于 Thompson 采样的可扩展方法，用于解决大型非结构化离散空间中的贝叶斯优化问题，避免了采集函数最大化的计算成本。


<details>
  <summary>Details</summary>
Motivation: 在大规模非结构化离散空间中，由于缺乏梯度，采集函数最大化的计算成本阻碍了贝叶斯优化。

Method: 提出了 Thompson Sampling via Fine-Tuning (ToSFiT) 方法，该方法利用提示条件的大型语言模型中嵌入的先验知识，并逐步将其调整为后验。

Result: 在三个不同的任务上验证了该方法：FAQ 响应优化、热稳定蛋白质搜索和量子电路设计。实验表明，在线微调显著提高了样本效率，而对计算效率的影响可以忽略不计。

Conclusion: 在线微调显著提高了样本效率，而对计算效率的影响可以忽略不计。

Abstract: Bayesian optimization in large unstructured discrete spaces is often hindered
by the computational cost of maximizing acquisition functions due to the
absence of gradients. We propose a scalable alternative based on Thompson
sampling that eliminates the need for acquisition function maximization by
directly parameterizing the probability that a candidate yields the maximum
reward. Our approach, Thompson Sampling via Fine-Tuning (ToSFiT) leverages the
prior knowledge embedded in prompt-conditioned large language models, and
incrementally adapts them toward the posterior. Theoretically, we derive a
novel regret bound for a variational formulation of Thompson Sampling that
matches the strong guarantees of its standard counterpart. Our analysis reveals
the critical role of careful adaptation to the posterior probability of
maximality--a principle that underpins our ToSFiT algorithm. Empirically, we
validate our method on three diverse tasks: FAQ response refinement, thermally
stable protein search, and quantum circuit design. We demonstrate that online
fine-tuning significantly improves sample efficiency, with negligible impact on
computational efficiency.

</details>


### [192] [Kernel Representation and Similarity Measure for Incomplete Data](https://arxiv.org/abs/2510.13352)
*Yang Cao,Sikun Yang,Kai He,Wenjun Ma,Ming Liu,Yujiu Yang,Jian Weng*

Main category: cs.LG

TL;DR: 提出了一种新的相似性度量方法，用于直接计算不完整数据之间的相似性，无需显式插补。


<details>
  <summary>Details</summary>
Motivation: 传统方法处理不完整数据时会丢弃数据或进行插补，导致信息丢失和相似性估计偏差。

Method: 提出了一种邻近核方法，该方法结合了数据相关的分箱和邻近分配，将数据投影到高维稀疏表示中，并提出了级联回退策略来估计缺失特征分布。

Result: 在12个真实世界的不完整数据集上进行的聚类任务表明，与现有方法相比，该方法具有优越的性能，同时保持了线性时间复杂度。

Conclusion: 该论文提出了一种有效处理不完整数据相似性度量的新方法，并在实验中验证了其优越性。

Abstract: Measuring similarity between incomplete data is a fundamental challenge in
web mining, recommendation systems, and user behavior analysis. Traditional
approaches either discard incomplete data or perform imputation as a
preprocessing step, leading to information loss and biased similarity
estimates. This paper presents the proximity kernel, a new similarity measure
that directly computes similarity between incomplete data in kernel feature
space without explicit imputation in the original space. The proposed method
introduces data-dependent binning combined with proximity assignment to project
data into a high-dimensional sparse representation that adapts to local density
variations. For missing value handling, we propose a cascading fallback
strategy to estimate missing feature distributions. We conduct clustering tasks
on the proposed kernel representation across 12 real world incomplete datasets,
demonstrating superior performance compared to existing methods while
maintaining linear time complexity. All the code are available at
https://anonymous.4open.science/r/proximity-kernel-2289.

</details>


### [193] [Generalist++: A Meta-learning Framework for Mitigating Trade-off in Adversarial Training](https://arxiv.org/abs/2510.13361)
*Yisen Wang,Yichuan Mo,Hongjun Wang,Junyi Li,Zhouchen Lin*

Main category: cs.LG

TL;DR: 提出了一种名为Generalist的框架，旨在解决对抗训练中的泛化误差和权衡问题，通过将总体目标分解为多个子任务，并分配给专门的基础学习器，最后插值它们的参数形成全局学习器。


<details>
  <summary>Details</summary>
Motivation: 对抗训练虽然是防御对抗样本最有效的方法，但存在自然精度下降和鲁棒性在不同范数约束攻击下迁移性差的问题。

Method: 将总体泛化目标分解为多个子任务，每个子任务分配给一个专门的基础学习器，在训练后期插值它们的参数形成全局学习器，并定期将全局参数重新分配给基础学习器。

Result: 理论分析和大量实验表明，与基线方法相比，Generalist框架实现了更低的泛化误差，并显著缓解了权衡问题。

Conclusion: Generalist框架为未来开发完全鲁棒的分类器提供了一个有希望的方向。

Abstract: Despite the rapid progress of neural networks, they remain highly vulnerable
to adversarial examples, for which adversarial training (AT) is currently the
most effective defense. While AT has been extensively studied, its practical
applications expose two major limitations: natural accuracy tends to degrade
significantly compared with standard training, and robustness does not transfer
well across attacks crafted under different norm constraints. Unlike prior
works that attempt to address only one issue within a single network, we
propose to partition the overall generalization goal into multiple sub-tasks,
each assigned to a dedicated base learner. By specializing in its designated
objective, each base learner quickly becomes an expert in its field. In the
later stages of training, we interpolate their parameters to form a
knowledgeable global learner, while periodically redistributing the global
parameters back to the base learners to prevent their optimization trajectories
from drifting too far from the shared target. We term this framework Generalist
and introduce three variants tailored to different application scenarios. Both
theoretical analysis and extensive experiments demonstrate that Generalist
achieves lower generalization error and significantly alleviates the trade-off
problems compared with baseline methods. Our results suggest that Generalist
provides a promising step toward developing fully robust classifiers in the
future.

</details>


### [194] [A New Perspective on Transformers in Online Reinforcement Learning for Continuous Control](https://arxiv.org/abs/2510.13367)
*Nikita Kachaev,Daniil Zelezetsky,Egor Cherepanov,Alexey K. Kovelev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 本文探讨了在在线无模型强化学习中使用transformers，并发现它们在连续控制任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: Transformer在离线或基于模型的强化学习中很有效，但在在线无模型强化学习中由于对训练设置和模型设计的敏感性而未被充分探索。

Method: 研究了如何调节输入，在actor和critic之间共享组件，以及如何切分序列数据进行训练等关键设计问题。

Result: 实验揭示了稳定的架构和训练策略，可以在完全和部分可观察的任务中实现有竞争力的性能，无论是在基于向量还是基于图像的环境中。

Conclusion: 这些发现为在在线强化学习中应用transformer提供了实践指导。

Abstract: Despite their effectiveness and popularity in offline or model-based
reinforcement learning (RL), transformers remain underexplored in online
model-free RL due to their sensitivity to training setups and model design
decisions such as how to structure the policy and value networks, share
components, or handle temporal information. In this paper, we show that
transformers can be strong baselines for continuous control in online
model-free RL. We investigate key design questions: how to condition inputs,
share components between actor and critic, and slice sequential data for
training. Our experiments reveal stable architectural and training strategies
enabling competitive performance across fully and partially observable tasks,
and in both vector- and image-based settings. These findings offer practical
guidance for applying transformers in online RL.

</details>


### [195] [Contrastive Learning-Based Dependency Modeling for Anomaly Detection in Cloud Services](https://arxiv.org/abs/2510.13368)
*Yue Xing,Yingnan Deng,Heyao Liu,Ming Wang,Yun Zi,Xiaoxuan Sun*

Main category: cs.LG

TL;DR: 本文提出了一种结合对比学习的依赖建模和异常检测方法，用于解决云服务环境中复杂依赖关系和多样化异常模式的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决云服务环境中复杂依赖关系和多样化异常模式的挑战。

Method: 该方法将服务交互抽象为依赖关系图，通过嵌入函数提取时间和结构特征，并采用图卷积机制聚合邻域信息以获得上下文感知的服务表示。然后，引入对比学习框架，构建正负样本对，以增强表示空间中正常和异常模式的可分离性。此外，设计了时间一致性约束，以保持跨时间步长的表示稳定性，并减少短期波动和噪声的影响。

Result: 在公共数据集上的实验结果表明，该方法在精确率、召回率、F1分数和AUC等关键指标上显著优于现有方法，同时在稀疏标签、监控噪声和流量波动条件下保持鲁棒性。

Conclusion: 验证了将依赖建模与对比学习相结合的有效性，为云服务异常检测提供了一个完整的技术解决方案，并在复杂环境中展示了强大的适应性和稳定性。

Abstract: This paper addresses the challenges of complex dependencies and diverse
anomaly patterns in cloud service environments by proposing a dependency
modeling and anomaly detection method that integrates contrastive learning. The
method abstracts service interactions into a dependency graph, extracts
temporal and structural features through embedding functions, and employs a
graph convolution mechanism to aggregate neighborhood information for
context-aware service representations. A contrastive learning framework is then
introduced, constructing positive and negative sample pairs to enhance the
separability of normal and abnormal patterns in the representation space.
Furthermore, a temporal consistency constraint is designed to maintain
representation stability across time steps and reduce the impact of short-term
fluctuations and noise. The overall optimization combines contrastive loss and
temporal consistency loss to ensure stable and reliable detection across
multi-dimensional features. Experiments on public datasets systematically
evaluate the method from hyperparameter, environmental, and data sensitivity
perspectives. Results show that the proposed approach significantly outperforms
existing methods on key metrics such as Precision, Recall, F1-Score, and AUC,
while maintaining robustness under conditions of sparse labeling, monitoring
noise, and traffic fluctuations. This study verifies the effectiveness of
integrating dependency modeling with contrastive learning, provides a complete
technical solution for cloud service anomaly detection, and demonstrates strong
adaptability and stability in complex environments.

</details>


### [196] [Prediction Markets with Intermittent Contributions](https://arxiv.org/abs/2510.13385)
*Michael Vitali,Pierre Pinson*

Main category: cs.LG

TL;DR: 本文提出了一种基于预测市场的通用框架，以解决数据所有权和竞争利益对利益相关者之间合作的限制，从而实现更准确的预测。


<details>
  <summary>Details</summary>
Motivation: 在数据可用性和对准确预测的需求不断增长的情况下，利益相关者之间的合作通常受到数据所有权和竞争利益的限制。

Method: 提出并分析了一个预测市场，该市场考虑了代理商的历史表现，适应随时间变化的情况，同时允许代理商随意进入和退出市场。该设计采用稳健的回归模型来学习最佳预测组合，同时处理缺失的提交。

Result: 通过使用模拟和真实世界数据的案例研究，证明了所提出的市场设计的有效性和适应性。

Conclusion: 所提出的市场设计是有效和可适应的。

Abstract: Although both data availability and the demand for accurate forecasts are
increasing, collaboration between stakeholders is often constrained by data
ownership and competitive interests. In contrast to recent proposals within
cooperative game-theoretical frameworks, we place ourselves in a more general
framework, based on prediction markets. There, independent agents trade
forecasts of uncertain future events in exchange for rewards. We introduce and
analyse a prediction market that (i) accounts for the historical performance of
the agents, (ii) adapts to time-varying conditions, while (iii) permitting
agents to enter and exit the market at will. The proposed design employs robust
regression models to learn the optimal forecasts' combination whilst handling
missing submissions. Moreover, we introduce a pay-off allocation mechanism that
considers both in-sample and out-of-sample performance while satisfying several
desirable economic properties. Case-studies using simulated and real-world data
allow demonstrating the effectiveness and adaptability of the proposed market
design.

</details>


### [197] [Going with the Flow: Approximating Banzhaf Values via Graph Neural Networks](https://arxiv.org/abs/2510.13391)
*Benjamin Kempinski,Tal Kachman*

Main category: cs.LG

TL;DR: 使用图神经网络 (GNN) 来近似基数网络流博弈中的 Banzhaf 值，通过将问题构建为图级预测任务，该方法直接从网络拓扑和控制结构中学习代理影响的可推广模式。


<details>
  <summary>Details</summary>
Motivation: 在网络流博弈中计算 Banzhaf 值对于量化多智能体系统中的智能体影响至关重要，但对于超过约 20 个智能体的系统，精确计算是难以处理的。蒙特卡罗抽样方法虽然提供统计估计，但样本复杂度高，无法在不同的网络配置中转移知识，因此不适用于大规模或动态系统。

Method: 提出了一种新的基于学习的方法，使用图神经网络 (GNN) 来近似基数网络流博弈中的 Banzhaf 值。通过将问题构建为图级预测任务，该方法直接从网络拓扑和控制结构中学习代理影响的可推广模式。使用了三种最先进的 GNN 架构：图注意力网络 (GAT)、具有边缘特征的图同构网络 (GINE) 和 EdgeConv。

Result: 结果表明，与精确方法和基于抽样的方法相比，训练后的 GNN 模型实现了高保真 Banzhaf 值近似，并且速度提高了几个数量级。最重要的是，该研究表明了强大的零样本泛化能力：在特定大小和拓扑的图上训练的模型可以准确地预测具有不同结构属性的全新网络的 Banzhaf 值，而无需重新训练。

Conclusion: 这项工作确立了 GNN 作为复杂网络系统可扩展合作博弈论分析的实用工具。

Abstract: Computing the Banzhaf value in network flow games is fundamental for
quantifying agent influence in multi-agent systems, with applications ranging
from cybersecurity to infrastructure planning. However, exact computation is
intractable for systems with more than $\sim20$ agents due to exponential
complexity $\mathcal{O}(2^m)$. While Monte Carlo sampling methods provide
statistical estimates, they suffer from high sample complexity and cannot
transfer knowledge across different network configurations, making them
impractical for large-scale or dynamic systems. We present a novel
learning-based approach using Graph Neural Networks (GNNs) to approximate
Banzhaf values in cardinal network flow games. By framing the problem as a
graph-level prediction task, our method learns generalisable patterns of agent
influence directly from network topology and control structure. We conduct a
comprehensive empirical study comparing three state-of-the-art GNN
architectures-Graph Attention Networks (GAT), Graph Isomorphism Networks with
Edge features (GINE), and EdgeConv-on a large-scale synthetic dataset of
200,000 graphs per configuration, varying in size (20-100 nodes), agent count
(5-20), and edge probability (0.5-1.0). Our results demonstrate that trained
GNN models achieve high-fidelity Banzhaf value approximation with
order-of-magnitude speedups compared to exact and sampling-based methods. Most
significantly, we show strong zero-shot generalisation: models trained on
graphs of a specific size and topology accurately predict Banzhaf values for
entirely new networks with different structural properties, without requiring
retraining. This work establishes GNNs as a practical tool for scalable
cooperative game-theoretic analysis of complex networked systems.

</details>


### [198] [Assessing the robustness of heterogeneous treatment effects in survival analysis under informative censoring](https://arxiv.org/abs/2510.13397)
*Yuxin Wang,Dennis Frauen,Jonas Schweisthal,Maresa Schröder,Stefan Feuerriegel*

Main category: cs.LG

TL;DR: 本文提出了一种评估生存分析中条件平均治疗效果(CATE)估计在存在删失偏差时的稳健性的框架。


<details>
  <summary>Details</summary>
Motivation: 临床研究中，由于副作用或其他原因，患者dropout现象普遍存在，当dropout具有信息性（即依赖于生存时间）时，会引入删失偏差，导致治疗效果估计也产生偏差。

Method: 本文使用部分识别来推导CATE的信息边界，并开发了一种新的元学习器，该学习器可以使用任意机器学习模型估计边界，并具有良好的理论特性，包括双重鲁棒性和准oracle效率。

Result: 通过数值实验和在癌症药物试验中的应用，证明了元学习器的实际价值。

Conclusion: 该框架为评估存在删失情况下估计治疗效果的稳健性提供了一种实用的工具，从而促进了生存数据在医学和流行病学中用于证据生成的可靠使用。

Abstract: Dropout is common in clinical studies, with up to half of patients leaving
early due to side effects or other reasons. When dropout is informative (i.e.,
dependent on survival time), it introduces censoring bias, because of which
treatment effect estimates are also biased. In this paper, we propose an
assumption-lean framework to assess the robustness of conditional average
treatment effect (CATE) estimates in survival analysis when facing censoring
bias. Unlike existing works that rely on strong assumptions, such as
non-informative censoring, to obtain point estimation, we use partial
identification to derive informative bounds on the CATE. Thereby, our framework
helps to identify patient subgroups where treatment is effective despite
informative censoring. We further develop a novel meta-learner that estimates
the bounds using arbitrary machine learning models and with favorable
theoretical properties, including double robustness and quasi-oracle
efficiency. We demonstrate the practical value of our meta-learner through
numerical experiments and in an application to a cancer drug trial. Together,
our framework offers a practical tool for assessing the robustness of estimated
treatment effects in the presence of censoring and thus promotes the reliable
use of survival data for evidence generation in medicine and epidemiology.

</details>


### [199] [SWIR-LightFusion: Multi-spectral Semantic Fusion of Synthetic SWIR with {Thermal} IR {(LWIR/MWIR)} and RGB](https://arxiv.org/abs/2510.13404)
*Muhammad Ishfaq Hussain,Ma Van Linh,Zubia Naz,Unse Fatima,Yeongmin Ko,Moongu Jeon*

Main category: cs.LG

TL;DR: 本研究通过从LWIR数据合成SWIR图像，并结合RGB和LWIR数据，提出了一种多模态融合框架，以提高恶劣天气条件下的场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统RGB和热红外融合在恶劣天气或光照不足条件下效果不佳，而SWIR能穿透大气干扰并更好地区分材料，但缺乏公开SWIR数据集限制了其发展。

Method: 利用对比度增强技术从LWIR数据合成SWIR图像，并提出一个多模态融合框架，该框架采用优化的编码器-解码器神经网络结构，具有模态特定的编码器和softmax门控融合头。

Result: 在公开RGB-LWIR基准和私有RGB-MWIR-SWIR数据集上的实验表明，该合成SWIR增强融合框架提高了融合图像质量（对比度、边缘清晰度、结构保真度），同时保持了实时性能。

Conclusion: 该研究成果表明，该方法在监控和自动驾驶系统中具有巨大的实际应用潜力。

Abstract: Enhancing scene understanding in adverse visibility conditions remains a
critical challenge for surveillance and autonomous navigation systems.
Conventional imaging modalities, such as RGB and thermal infrared (MWIR /
LWIR), when fused, often struggle to deliver comprehensive scene information,
particularly under conditions of atmospheric interference or inadequate
illumination. To address these limitations, Short-Wave Infrared (SWIR) imaging
has emerged as a promising modality due to its ability to penetrate atmospheric
disturbances and differentiate materials with improved clarity. However, the
advancement and widespread implementation of SWIR-based systems face
significant hurdles, primarily due to the scarcity of publicly accessible SWIR
datasets. In response to this challenge, our research introduces an approach to
synthetically generate SWIR-like structural/contrast cues (without claiming
spectral reproduction) images from existing LWIR data using advanced contrast
enhancement techniques. We then propose a multimodal fusion framework
integrating synthetic SWIR, LWIR, and RGB modalities, employing an optimized
encoder-decoder neural network architecture with modality-specific encoders and
a softmax-gated fusion head. Comprehensive experiments on public {RGB-LWIR
benchmarks (M3FD, TNO, CAMEL, MSRS, RoadScene) and an additional private real
RGB-MWIR-SWIR dataset} demonstrate that our synthetic-SWIR-enhanced fusion
framework improves fused-image quality (contrast, edge definition, structural
fidelity) while maintaining real-time performance. We also add fair trimodal
baselines (LP, LatLRR, GFF) and cascaded trimodal variants of
U2Fusion/SwinFusion under a unified protocol. The outcomes highlight
substantial potential for real-world applications in surveillance and
autonomous systems.

</details>


### [200] [Optimizing Storage Overhead of User Behavior Log for ML-embedded Mobile Apps](https://arxiv.org/abs/2510.13405)
*Chen Gong,Yan Zhuang,Zhenzhe Zheng,Yiliu Chen,Sheng Wang,Fan Wu,Guihai Chen*

Main category: cs.LG

TL;DR: AdaLog improves storage efficiency of user behavior logs in ML-embedded mobile apps without compromising model inference accuracy or latency.


<details>
  <summary>Details</summary>
Motivation: Recording user behavior data for ML models imposes substantial storage cost on mobile apps, leading to lower system responsiveness and more app uninstalls.

Method: AdaLog formulates the elimination of feature-level redundant data as a maximum weighted matching problem in hypergraphs and proposes a hierarchical algorithm. It employs a virtually hashed attribute design and an incremental update mechanism.

Result: AdaLog reduces behavior log size by 19% to 44% with minimal system overhead.

Conclusion: AdaLog provides a more efficient data foundation for broader adoption of on-device ML.

Abstract: Machine learning (ML) models are increasingly integrated into modern mobile
apps to enable personalized and intelligent services. These models typically
rely on rich input features derived from historical user behaviors to capture
user intents. However, as ML-driven services become more prevalent, recording
necessary user behavior data imposes substantial storage cost on mobile apps,
leading to lower system responsiveness and more app uninstalls. To address this
storage bottleneck, we present AdaLog, a lightweight and adaptive system
designed to improve the storage efficiency of user behavior log in ML-embedded
mobile apps, without compromising model inference accuracy or latency. We
identify two key inefficiencies in current industrial practices of user
behavior log: (i) redundant logging of overlapping behavior data across
different features and models, and (ii) sparse storage caused by storing
behaviors with heterogeneous attribute descriptions in a single log file. To
solve these issues, AdaLog first formulates the elimination of feature-level
redundant data as a maximum weighted matching problem in hypergraphs, and
proposes a hierarchical algorithm for efficient on-device deployment. Then,
AdaLog employs a virtually hashed attribute design to distribute heterogeneous
behaviors into a few log files with physically dense storage. Finally, to
ensure scalability to dynamic user behavior patterns, AdaLog designs an
incremental update mechanism to minimize the I/O operations needed for adapting
outdated behavior log. We implement a prototype of AdaLog and deploy it into
popular mobile apps in collaboration with our industry partner. Evaluations on
real-world user data show that AdaLog reduces behavior log size by 19% to 44%
with minimal system overhead (only 2 seconds latency and 15 MB memory usage),
providing a more efficient data foundation for broader adoption of on-device
ML.

</details>


### [201] [When Embedding Models Meet: Procrustes Bounds and Applications](https://arxiv.org/abs/2510.13406)
*Lucas Maystre,Alvaro Ortega Gonzalez,Charles Park,Rares Dolga,Tudor Berariu,Yu Zhao,Kamil Ciosek*

Main category: cs.LG

TL;DR: 对在类似数据上分别训练的嵌入模型进行对齐，以解决互操作性问题。


<details>
  <summary>Details</summary>
Motivation: 单独训练的嵌入模型缺乏互操作性，这给模型再训练、部分模型升级和多模态搜索等实际应用带来了挑战。

Method: 研究了当两组嵌入可以通过正交变换对齐时的情况，并提出了一种简单的对齐方法，即 Procrustes 后处理。

Result: 证明了如果成对点积近似保持，则存在一个可以紧密对齐两组嵌入的等距同构，并提供了对齐误差的严格界限。通过实验证明了该方法在保持跨再训练的兼容性、组合不同的模型进行文本检索以及改进混合模式搜索方面的有效性，并在混合模式搜索中实现了最先进的性能。

Conclusion: Procrustes 后处理能够使两个嵌入模型具有互操作性，同时保持每个嵌入空间的几何形状。

Abstract: Embedding models trained separately on similar data often produce
representations that encode stable information but are not directly
interchangeable. This lack of interoperability raises challenges in several
practical applications, such as model retraining, partial model upgrades, and
multimodal search. Driven by these challenges, we study when two sets of
embeddings can be aligned by an orthogonal transformation. We show that if
pairwise dot products are approximately preserved, then there exists an
isometry that closely aligns the two sets, and we provide a tight bound on the
alignment error. This insight yields a simple alignment recipe, Procrustes
post-processing, that makes two embedding models interoperable while preserving
the geometry of each embedding space. Empirically, we demonstrate its
effectiveness in three applications: maintaining compatibility across
retrainings, combining different models for text retrieval, and improving
mixed-modality search, where it achieves state-of-the-art performance.

</details>
