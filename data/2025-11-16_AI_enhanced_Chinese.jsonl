{"id": "2511.10063", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.10063", "abs": "https://arxiv.org/abs/2511.10063", "authors": ["Yiwen Wang", "Vivek Shah", "Marcos Antonio Vaz Salles", "Claudia Bauzer Medeiros", "Julio Cesar Dos Reis", "Yongluan Zhou"], "title": "Dolphin: An Actor-Oriented Database for Reactive Moving Object Data Management", "comment": null, "summary": "Novel reactive moving object applications require solutions to support object reactive behaviors as a way to query and update dynamic data. While moving object scenarios have long been researched in the context of spatio-temporal data management, reactive behavior is usually left to complex end-user implementations. However, it is not just a matter of hardwiring reactive constraints: the required solutions need to satisfy tight low-latency computation requirements and be scalable. This paper explores a novel approach to enrich a distributed actor-based framework with reactive functionality and complex spatial data management along with concurrency semantics. Our approach relies on a proposal of the moving actor abstraction, which is a conceptual enhancement of the actor model with reactive sensing, movement, and spatial querying capabilities. This enhancement helps developers of reactive moving object applications avoid the significant burden of implementing application-level schemes to balance performance and consistency. Based on moving actors, we define a reactive moving object data management platform, named Moving Actor-Oriented Databases (M-AODBs), and build Dolphin -- an implementation of M-AODBs. Dolphin embodies a non-intrusive actor-based design layered on top of the Microsoft Orleans distributed virtual actor framework. In a set of experimental evaluations with realistic reactive moving object scenarios, Dolphin exhibits scalability on multi-machines and provides near-real-time reaction latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u589e\u5f3a\u5206\u5e03\u5f0f actor \u6846\u67b6\u7684\u53cd\u5e94\u529f\u80fd\u3001\u590d\u6742\u7684\u7a7a\u95f4\u6570\u636e\u7ba1\u7406\u548c\u5e76\u53d1\u8bed\u4e49\u6765\u652f\u6301\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u79fb\u52a8\u5bf9\u8c61\u573a\u666f\u7814\u7a76\u901a\u5e38\u5c06\u53cd\u5e94\u884c\u4e3a\u7559\u7ed9\u6700\u7ec8\u7528\u6237\u590d\u6742\u5730\u5b9e\u73b0\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u8ba1\u7b97\u548c\u53ef\u6269\u5c55\u6027\u7684\u8981\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u79fb\u52a8 actor \u62bd\u8c61\uff0c\u5b83\u662f actor \u6a21\u578b\u7684\u6982\u5ff5\u589e\u5f3a\uff0c\u5177\u6709\u53cd\u5e94\u611f\u77e5\u3001\u79fb\u52a8\u548c\u7a7a\u95f4\u67e5\u8be2\u529f\u80fd\u3002\u57fa\u4e8e\u79fb\u52a8 actor\uff0c\u5b9a\u4e49\u4e86\u4e00\u4e2a\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u6570\u636e\u7ba1\u7406\u5e73\u53f0 M-AODBs\uff0c\u5e76\u6784\u5efa\u4e86 Dolphin -- M-AODBs \u7684\u4e00\u4e2a\u5b9e\u73b0\u3002", "result": "\u5728\u5177\u6709\u771f\u5b9e\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u573a\u666f\u7684\u4e00\u7ec4\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0cDolphin \u5728\u591a\u53f0\u673a\u5668\u4e0a\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u63a5\u8fd1\u5b9e\u65f6\u7684\u53cd\u5e94\u5ef6\u8fdf\u3002", "conclusion": "Dolphin \u80fd\u591f\u5728\u591a\u53f0\u673a\u5668\u4e0a\u6269\u5c55\uff0c\u5e76\u63d0\u4f9b\u63a5\u8fd1\u5b9e\u65f6\u7684\u53cd\u5e94\u5ef6\u8fdf\uff0c\u8bc1\u660e\u4e86 M-AODBs \u5e73\u53f0\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.10418", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.10418", "abs": "https://arxiv.org/abs/2511.10418", "authors": ["Yaqiao Zhu", "Hongkai Wen", "Mark Birkin", "Man Luo"], "title": "CityVerse: A Unified Data Platform for Multi-Task Urban Computing with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) show remarkable potential for urban computing, from spatial reasoning to predictive analytics. However, evaluating LLMs across diverse urban tasks faces two critical challenges: lack of unified platforms for consistent multi-source data access and fragmented task definitions that hinder fair comparison. To address these challenges, we present CityVerse, the first unified platform integrating multi-source urban data, capability-based task taxonomy, and dynamic simulation for systematic LLM evaluation in urban contexts. CityVerse provides: 1) coordinate-based Data APIs unifying ten categories of urban data-including spatial features, temporal dynamics, demographics, and multi-modal imagery-with over 38 million curated records; 2) Task APIs organizing 43 urban computing tasks into a four-level cognitive hierarchy: Perception, Spatial Understanding, Reasoning and Prediction, and Decision and Interaction, enabling standardized evaluation across capability levels; 3) an interactive visualization frontend supporting real-time data retrieval, multi-layer display, and simulation replay for intuitive exploration and validation. We validate the platform's effectiveness through evaluations on mainstream LLMs across representative tasks, demonstrating its capability to support reproducible and systematic assessment. CityVerse provides a reusable foundation for advancing LLMs and multi-task approaches in the urban computing domain.", "AI": {"tldr": "CityVerse\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u96c6\u6210\u4e86\u591a\u6e90\u57ce\u5e02\u6570\u636e\u3001\u57fa\u4e8e\u80fd\u529b\u7684\u4efb\u52d9\u5206\u7c7b\u548c\u52a8\u6001\u6a21\u62df\uff0c\u7528\u4e8e\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u8fdb\u884c\u7cfb\u7edf\u7684LLM\u8bc4\u4f30\u3002", "motivation": "\u8bc4\u4f30LLM\u5728\u5404\u79cd\u57ce\u5e02\u4efb\u52a1\u4e2d\u9762\u4e34\u4e24\u4e2a\u5173\u952e\u6311\u6218\uff1a\u7f3a\u4e4f\u7528\u4e8e\u4e00\u81f4\u7684\u591a\u6e90\u6570\u636e\u8bbf\u95ee\u7684\u7edf\u4e00\u5e73\u53f0\u548c\u963b\u788d\u516c\u5e73\u6bd4\u8f83\u7684\u96f6\u6563\u7684\u4efb\u52a1\u5b9a\u4e49\u3002", "method": "CityVerse\u63d0\u4f9b\uff1a1\uff09\u57fa\u4e8e\u5750\u6807\u7684\u6570\u636eAPI\uff0c\u7edf\u4e00\u4e86\u5341\u7c7b\u57ce\u5e02\u6570\u636e\uff1b2\uff09\u4efb\u52a1API\uff0c\u5c0643\u4e2a\u57ce\u5e02\u8ba1\u7b97\u4efb\u52a1\u7ec4\u7ec7\u6210\u56db\u4e2a\u7ea7\u522b\u7684\u8ba4\u77e5\u5c42\u6b21\uff1b3\uff09\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u524d\u7aef\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u68c0\u7d22\u3001\u591a\u5c42\u663e\u793a\u548c\u6a21\u62df\u91cd\u653e\u3002", "result": "\u901a\u8fc7\u5bf9\u4e3b\u6d41LLM\u5728\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u8be5\u5e73\u53f0\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u652f\u6301\u53ef\u91cd\u590d\u548c\u7cfb\u7edf\u8bc4\u4f30\u7684\u80fd\u529b\u3002", "conclusion": "CityVerse\u4e3a\u63a8\u8fdb\u57ce\u5e02\u8ba1\u7b97\u9886\u57df\u4e2d\u7684LLM\u548c\u591a\u4efb\u52a1\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2511.09998", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.09998", "abs": "https://arxiv.org/abs/2511.09998", "authors": ["Hui Dou", "Lei Jin", "Yuxuan Zhou", "Jiang He", "Yiwen Zhang"], "title": "DemoTuner: Efficient DBMS Knobs Tuning via LLM-Assisted Demonstration Reinforcement Learning", "comment": "14 pages, 9 figures", "summary": "The performance of modern DBMSs such as MySQL and PostgreSQL heavily depends on the configuration of performance-critical knobs. Manual tuning these knobs is laborious and inefficient due to the complex and high-dimensional nature of the configuration space. Among the automated tuning methods, reinforcement learning (RL)-based methods have recently sought to improve the DBMS knobs tuning process from several different perspectives. However, they still encounter challenges with slow convergence speed during offline training. In this paper, we mainly focus on how to leverage the valuable tuning hints contained in various textual documents such as DBMS manuals and web forums to improve the offline training of RL-based methods. To this end, we propose an efficient DBMS knobs tuning framework named DemoTuner via a novel LLM-assisted demonstration reinforcement learning method. Specifically, to comprehensively and accurately mine tuning hints from documents, we design a structured chain of thought prompt to employ LLMs to conduct a condition-aware tuning hints extraction task. To effectively integrate the mined tuning hints into RL agent training, we propose a hint-aware demonstration reinforcement learning algorithm HA-DDPGfD in DemoTuner. As far as we know, DemoTuner is the first work to introduce the demonstration reinforcement learning algorithm for DBMS knobs tuning. Experimental evaluations conducted on MySQL and PostgreSQL across various workloads demonstrate the significant advantages of DemoTuner in both performance improvement and online tuning cost reduction over three representative baselines including DB-BERT, GPTuner and CDBTune. Additionally, DemoTuner also exhibits superior adaptability to application scenarios with unknown workloads.", "AI": {"tldr": "\u63d0\u51faDemoTuner\u6846\u67b6\uff0c\u5229\u7528LLM\u8f85\u52a9\u7684\u6f14\u793a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u5347\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\uff08DBMS\uff09\u65cb\u94ae\u8c03\u4f18\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u624b\u52a8\u8c03\u8282\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf\u7684\u65cb\u94ae\u65e2\u8d39\u529b\u53c8\u4f4e\u6548\uff0c\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5b58\u5728\u79bb\u7ebf\u8bad\u7ec3\u6536\u655b\u901f\u5ea6\u6162\u7684\u95ee\u9898\u3002", "method": "1. \u8bbe\u8ba1\u7ed3\u6784\u5316\u7684\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ece\u6587\u672c\u4e2d\u63d0\u53d6\u8c03\u4f18\u63d0\u793a\u3002 2. \u63d0\u51fa\u4e00\u79cd\u63d0\u793a\u611f\u77e5\u7684\u6f14\u793a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5HA-DDPGfD\uff0c\u5c06\u63d0\u53d6\u7684\u8c03\u4f18\u63d0\u793a\u6574\u5408\u5230\u5f3a\u5316\u5b66\u4e60Agent\u7684\u8bad\u7ec3\u4e2d\u3002", "result": "\u5728MySQL\u548cPostgreSQL\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cDemoTuner\u5728\u6027\u80fd\u63d0\u5347\u548c\u5728\u7ebf\u8c03\u4f18\u6210\u672c\u964d\u4f4e\u65b9\u9762\u5747\u4f18\u4e8eDB-BERT\u3001GPTuner\u548cCDBTune\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002DemoTuner\u8fd8\u8868\u73b0\u51fa\u5bf9\u672a\u77e5\u5de5\u4f5c\u8d1f\u8f7d\u7684\u5353\u8d8a\u9002\u5e94\u6027\u3002", "conclusion": "DemoTuner\u662f\u7b2c\u4e00\u4e2a\u5c06\u6f14\u793a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5f15\u5165DBMS\u65cb\u94ae\u8c03\u4f18\u7684\u5de5\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8c03\u4f18\u6548\u679c\u5e76\u964d\u4f4e\u4e86\u5728\u7ebf\u8c03\u4f18\u6210\u672c\u3002"}}
{"id": "2511.10192", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.10192", "abs": "https://arxiv.org/abs/2511.10192", "authors": ["Qifeng Cai", "Hao Liang", "Chang Xu", "Tao Xie", "Wentao Zhang", "Bin Cui"], "title": "Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL", "comment": null, "summary": "The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2aSQL-aware\u7684\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u751f\u6210\u5927\u89c4\u6a21\u3001\u8bed\u4e49\u6709\u6548\u3001\u7ed3\u6784\u591a\u6837\u7684Text-to-SQL\u5bf9\u3002", "motivation": "Text-to-SQL\u7684\u6027\u80fd\u53d7\u9650\u4e8e\u7a00\u7f3a\u3001\u7b80\u5355\u548c\u4f4e\u591a\u6837\u6027\u7684\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86Text2SQL-Flow\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5728\u516d\u4e2a\u589e\u5f3a\u7ef4\u5ea6\u4e0a\u8fd0\u884c\uff0c\u5e76\u96c6\u6210\u4e86SQL\u6267\u884c\u9a8c\u8bc1\u3001\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u751f\u6210\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u8ffd\u8e2a\u548c\u6570\u636e\u5206\u7c7b\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6SQLFlow\uff0c\u5305\u542b89,544\u4e2a\u5e26\u6ce8\u91ca\u7684\u4f8b\u5b50\u3002\u5728\u5f00\u6e90\u548c\u95ed\u6e90LLM\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0cSQLFlow\u63d0\u9ad8\u4e86\u6027\u80fd\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u63a8\u8fdbText-to-SQL\u7cfb\u7edf\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u3001\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684\u57fa\u7840\uff0c\u5e76\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u6570\u636e\u5728\u73b0\u4ee3\u4eba\u5de5\u667a\u80fd\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.10138", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.10138", "abs": "https://arxiv.org/abs/2511.10138", "authors": ["Jun Zhang", "Yi Li", "Yue Liu", "Changping Wang", "Yuan Wang", "Yuling Xiong", "Xun Liu", "Haiyang Wu", "Qian Li", "Enming Zhang", "Jiawei Sun", "Xin Xu", "Zishuai Zhang", "Ruoran Liu", "Suyuan Huang", "Zhaoxin Zhang", "Zhengkai Guo", "Shuojin Yang", "Meng-Hao Guo", "Huan Yu", "Jie Jiang", "Shi-Min Hu"], "title": "GPR: Towards a Generative Pre-trained One-Model Paradigm for Large-Scale Advertising Recommendation", "comment": "12 pages, 5 figures", "summary": "As an intelligent infrastructure connecting users with commercial content, advertising recommendation systems play a central role in information flow and value creation within the digital economy. However, existing multi-stage advertising recommendation systems suffer from objective misalignment and error propagation, making it difficult to achieve global optimality, while unified generative recommendation models still struggle to meet the demands of practical industrial applications. To address these issues, we propose GPR (Generative Pre-trained Recommender), the first one-model framework that redefines advertising recommendation as an end-to-end generative task, replacing the traditional cascading paradigm with a unified generative approach. To realize GPR, we introduce three key innovations spanning unified representation, network architecture, and training strategy. First, we design a unified input schema and tokenization method tailored to advertising scenarios, mapping both ads and organic content into a shared multi-level semantic ID space, thereby enhancing semantic alignment and modeling consistency across heterogeneous data. Second, we develop the Heterogeneous Hierarchical Decoder (HHD), a dual-decoder architecture that decouples user intent modeling from ad generation, achieving a balance between training efficiency and inference flexibility while maintaining strong modeling capacity. Finally, we propose a multi-stage joint training strategy that integrates Multi-Token Prediction (MTP), Value-Aware Fine-Tuning and the Hierarchy Enhanced Policy Optimization (HEPO) algorithm, forming a complete generative recommendation pipeline that unifies interest modeling, value alignment, and policy optimization. GPR has been fully deployed in the Tencent Weixin Channels advertising system, delivering significant improvements in key business metrics including GMV and CTCVR.", "AI": {"tldr": "GPR\u662f\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6846\u67b6\uff0c\u5b83\u7528\u7edf\u4e00\u7684\u751f\u6210\u65b9\u6cd5\u4ee3\u66ff\u4e86\u4f20\u7edf\u7684\u7ea7\u8054\u6a21\u5f0f\uff0c\u89e3\u51b3\u4e86\u76ee\u6807\u4e0d\u4e00\u81f4\u548c\u8bef\u5dee\u4f20\u64ad\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u9636\u6bb5\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u76ee\u6807\u4e0d\u4e00\u81f4\u548c\u8bef\u5dee\u4f20\u64ad\u7684\u95ee\u9898\uff0c\u5e76\u4e14\u7edf\u4e00\u7684\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86GPR\uff0c\u4e00\u4e2a\u5355\u6a21\u578b\u6846\u67b6\uff0c\u5b83\u91cd\u65b0\u5b9a\u4e49\u4e86\u5e7f\u544a\u63a8\u8350\u4e3a\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u751f\u6210\u4efb\u52a1\u3002GPR\u5305\u62ec\u7edf\u4e00\u7684\u8868\u793a\uff0c\u7f51\u7edc\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u3002", "result": "GPR\u5df2\u7ecf\u5728\u817e\u8baf\u5fae\u4fe1\u9891\u9053\u5e7f\u544a\u7cfb\u7edf\u4e2d\u5168\u9762\u90e8\u7f72\uff0c\u5e76\u5728GMV\u548cCTCVR\u7b49\u5173\u952e\u4e1a\u52a1\u6307\u6807\u4e0a\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GPR\u901a\u8fc7\u7edf\u4e00\u7684\u6846\u67b6\u548c\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u7684\u7aef\u5230\u7aef\u751f\u6210\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u7684\u4e1a\u52a1\u6548\u679c\u3002"}}
{"id": "2511.09563", "categories": ["cs.AI", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.09563", "abs": "https://arxiv.org/abs/2511.09563", "authors": ["Qilong Yuan"], "title": "An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-\u03b1 Optimization", "comment": "20 pages, 4 figures", "summary": "The Joint Routing-Assignment (JRA) optimization problem simultaneously determines the assignment of items to placeholders and a Hamiltonian cycle that visits each node pair exactly once, with the objective of minimizing total travel cost. Previous studies introduced an exact mixed-integer programming (MIP) solver, along with datasets and a Gurobi implementation, showing that while the exact approach guarantees optimality, it becomes computationally inefficient for large-scale instances. To overcome this limitation, heuristic methods based on merging algorithms and shaking procedures were proposed, achieving solutions within approximately 1% deviation from the optimum. This work presents a novel and more efficient approach that attains high-accuracy, near-optimal solutions for large-scale JRA problems. The proposed method introduces a Partial Path Reconstructon (PPR) solver that first identifies key item-placeholder pairs to form a reduced subproblem, which is solved efficiently to refine the global solution. Using this PJAR framework, the initial heuristic merging solutions can be further improved, reducing the deviation by half. Moreover, the solution can be iteratively polished with PPR based solver along the optimization path to yield highly accurate tours. Additionally, a global Large-\u03b1 constraint is incorporated into the JRA model to further enhance solution optimality. Experimental evaluations on benchmark datasets with n = 300, 500, and 1000 demonstrate that the proposed method consistently delivers almost optimal solutions, achieving an average deviation of 0.00% from the ground truth while maintaining high computational efficiency. Beyond the JRA problem, the proposed framework and methodologies exhibit strong potential for broader applications. The Framework can be applied to TSP and related optimization problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u53ef\u4ee5\u4e3a\u5927\u89c4\u6a21 JRA \u95ee\u9898\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u3001\u63a5\u8fd1\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8868\u660e\uff0c\u7cbe\u786e\u65b9\u6cd5\u867d\u7136\u4fdd\u8bc1\u4e86\u6700\u4f18\u6027\uff0c\u4f46\u5bf9\u4e8e\u5927\u89c4\u6a21\u5b9e\u4f8b\u6765\u8bf4\uff0c\u8ba1\u7b97\u6548\u7387\u53d8\u5f97\u5f88\u4f4e\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u79cd\u90e8\u5206\u8def\u5f84\u91cd\u5efa (PPR) \u6c42\u89e3\u5668\uff0c\u8be5\u6c42\u89e3\u5668\u9996\u5148\u8bc6\u522b\u5173\u952e\u9879\u76ee-\u5360\u4f4d\u7b26\u5bf9\u4ee5\u5f62\u6210\u7b80\u5316\u7684\u5b50\u95ee\u9898\uff0c\u7136\u540e\u6709\u6548\u5730\u89e3\u51b3\u8be5\u5b50\u95ee\u9898\u4ee5\u4f18\u5316\u5168\u5c40\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728 n = 300\u3001500 \u548c 1000 \u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u59cb\u7ec8\u63d0\u4f9b\u51e0\u4e4e\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u4e0e\u57fa\u672c\u4e8b\u5b9e\u5e73\u5747\u504f\u5dee 0.00%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u6846\u67b6\u53ef\u4ee5\u5e94\u7528\u4e8e TSP \u548c\u76f8\u5173\u7684\u4f18\u5316\u95ee\u9898\u3002"}}
{"id": "2511.09599", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09599", "abs": "https://arxiv.org/abs/2511.09599", "authors": ["Ming Yang", "Dongrun Li", "Xin Wang", "Feng Li", "Lisheng Fan", "Chunxiao Wang", "Xiaoming Wu", "Peng Cheng"], "title": "FedeCouple: Fine-Grained Balancing of Global-Generalization and Local-Adaptability in Federated Learning", "comment": null, "summary": "In privacy-preserving mobile network transmission scenarios with heterogeneous client data, personalized federated learning methods that decouple feature extractors and classifiers have demonstrated notable advantages in enhancing learning capability. However, many existing approaches primarily focus on feature space consistency and classification personalization during local training, often neglecting the local adaptability of the extractor and the global generalization of the classifier. This oversight results in insufficient coordination and weak coupling between the components, ultimately degrading the overall model performance. To address this challenge, we propose FedeCouple, a federated learning method that balances global generalization and local adaptability at a fine-grained level. Our approach jointly learns global and local feature representations while employing dynamic knowledge distillation to enhance the generalization of personalized classifiers. We further introduce anchors to refine the feature space; their strict locality and non-transmission inherently preserve privacy and reduce communication overhead. Furthermore, we provide a theoretical analysis proving that FedeCouple converges for nonconvex objectives, with iterates approaching a stationary point as the number of communication rounds increases. Extensive experiments conducted on five image-classification datasets demonstrate that FedeCouple consistently outperforms nine baseline methods in effectiveness, stability, scalability, and security. Notably, in experiments evaluating effectiveness, FedeCouple surpasses the best baseline by a significant margin of 4.3%.", "AI": {"tldr": "FedeCouple: A federated learning method balancing global generalization and local adaptability for heterogeneous client data.", "motivation": "Existing personalized federated learning methods often neglect local extractor adaptability and global classifier generalization, leading to weak component coupling and degraded performance.", "method": "Jointly learns global/local features, uses dynamic knowledge distillation for classifier generalization, and refines the feature space with local, non-transmitted anchors.", "result": "FedeCouple outperforms nine baselines on five image-classification datasets in effectiveness, stability, scalability, and security, with a 4.3% improvement over the best baseline in effectiveness.", "conclusion": "FedeCouple balances global generalization and local adaptability, achieving superior performance in privacy-preserving federated learning scenarios."}}
{"id": "2511.09690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09690", "abs": "https://arxiv.org/abs/2511.09690", "authors": ["Omnilingual ASR team", "Gil Keren", "Artyom Kozhevnikov", "Yen Meng", "Christophe Ropers", "Matthew Setzler", "Skyler Wang", "Ife Adebara", "Michael Auli", "Can Balioglu", "Kevin Chan", "Chierh Cheng", "Joe Chuang", "Caley Droof", "Mark Duppenthaler", "Paul-Ambroise Duquenne", "Alexander Erben", "Cynthia Gao", "Gabriel Mejia Gonzalez", "Kehan Lyu", "Sagar Miglani", "Vineel Pratap", "Kaushik Ram Sadagopan", "Safiyyah Saleem", "Arina Turkatenko", "Albert Ventayol-Boada", "Zheng-Xin Yong", "Yu-An Chung", "Jean Maillard", "Rashel Moritz", "Alexandre Mourachko", "Mary Williamson", "Shireen Yates"], "title": "Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages", "comment": null, "summary": "Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.", "AI": {"tldr": "Omnilingual ASR is a large-scale ASR system designed for extensibility, enabling communities to introduce unserved languages with limited data.", "motivation": "Expanding ASR coverage to more languages is costly and limited by current architectures, raising ethical concerns when done without community collaboration.", "method": "The system scales self-supervised pre-training to 7B parameters and uses an encoder-decoder architecture for zero-shot generalization, leveraging a LLM-inspired decoder, trained on a massive, diverse corpus.", "result": "Omnilingual ASR covers over 1,600 languages, including 500 previously unserved, with substantial gains over prior systems, especially in low-resource conditions.", "conclusion": "The release of Omnilingual ASR models and tools lowers barriers for researchers and communities, inviting new forms of participation and addressing ethical considerations."}}
{"id": "2511.09559", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09559", "abs": "https://arxiv.org/abs/2511.09559", "authors": ["Tianlei Chen", "Yuxiao Chen", "Yang Li", "Feifei Wang"], "title": "Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding", "comment": null, "summary": "Automated International Classification of Diseases (ICD) coding aims to assign multiple disease codes to clinical documents, constituting a crucial multi-label text classification task in healthcare informatics. However, the task is challenging due to its large label space (10,000 to 20,000 codes) and long-tail distribution, where a few codes dominate while many rare codes lack sufficient training data. To address this, we propose a learning method that models fine-grained co-occurrence relationships among codes. Specifically, we construct a Directed Bipartite Graph Encoder with disjoint sets of common and rare code nodes. To facilitate a one-way information flow, edges are directed exclusively from common to rare codes. The nature of these connections is defined by a probability-based bias, which is derived from the conditional probability of a common code co-occurring given the presence of a rare code. This bias is then injected into the encoder's attention module, a process we term Co-occurrence Encoding. This structure empowers the graph encoder to enrich rare code representations by aggregating latent comorbidity information reflected in the statistical co-occurrence of their common counterparts. To ensure high-quality input to the graph, we utilize a large language model (LLM) to generate comprehensive descriptions for codes, enriching initial embeddings with clinical context and comorbidity information, serving as external knowledge for the statistical co-occurrence relationships in the code system. Experiments on three automated ICD coding benchmark datasets demonstrate that our method achieves state-of-the-art performance with particularly notable improvements in Macro-F1, which is the key metric for long-tail classification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 ICD \u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u5e38\u89c1\u7801\u548c\u7f55\u89c1\u7801\u4e4b\u95f4\u7684\u5171\u73b0\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\u6765\u89e3\u51b3\u957f\u5c3e\u5206\u5e03\u95ee\u9898\u3002", "motivation": "ICD \u7f16\u7801\u4efb\u52a1\u5177\u6709\u6807\u7b7e\u7a7a\u95f4\u5927\u548c\u957f\u5c3e\u5206\u5e03\u7684\u6311\u6218\uff0c\u7f55\u89c1\u7801\u7f3a\u4e4f\u8db3\u591f\u7684\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6709\u5411\u4e8c\u5206\u56fe\u7f16\u7801\u5668\uff0c\u5229\u7528\u6982\u7387\u504f\u5dee\u5c06\u5e38\u89c1\u7801\u7684\u4fe1\u606f\u4f20\u9012\u7ed9\u7f55\u89c1\u7801\uff0c\u5e76\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u63cf\u8ff0\u6765\u4e30\u5bcc\u521d\u59cb\u5d4c\u5165\u3002", "result": "\u5728\u4e09\u4e2a ICD \u7f16\u7801\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728 Macro-F1 \u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5bf9\u7801\u4e4b\u95f4\u7684\u5171\u73b0\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\uff0c\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u7f55\u89c1\u7801\u7684\u5206\u7c7b\u6027\u80fd\u3002"}}
{"id": "2511.10492", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.10492", "abs": "https://arxiv.org/abs/2511.10492", "authors": ["Yunkai Zhang", "Qiang Zhang", "Feng", "Lin", "Ruizhong Qiu", "Hanchao Yu", "Jason Liu", "Yinglong Xia", "Zhuoran Yu", "Zeyu Zheng", "Diji Yang"], "title": "Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding", "comment": null, "summary": "Optimizing recommender systems for objectives beyond accuracy, such as diversity, novelty, and personalization, is crucial for long-term user satisfaction. To this end, industrial practitioners have accumulated vast amounts of structured domain knowledge, which we term human priors (e.g., item taxonomies, temporal patterns). This knowledge is typically applied through post-hoc adjustments during ranking or post-ranking. However, this approach remains decoupled from the core model learning, which is particularly undesirable as the industry shifts to end-to-end generative recommendation foundation models. On the other hand, many methods targeting these beyond-accuracy objectives often require architecture-specific modifications and discard these valuable human priors by learning user intent in a fully unsupervised manner.\n  Instead of discarding the human priors accumulated over years of practice, we introduce a backbone-agnostic framework that seamlessly integrates these human priors directly into the end-to-end training of generative recommenders. With lightweight, prior-conditioned adapter heads inspired by efficient LLM decoding strategies, our approach guides the model to disentangle user intent along human-understandable axes (e.g., interaction types, long- vs. short-term interests). We also introduce a hierarchical composition strategy for modeling complex interactions across different prior types. Extensive experiments on three large-scale datasets demonstrate that our method significantly enhances both accuracy and beyond-accuracy objectives. We also show that human priors allow the backbone model to more effectively leverage longer context lengths and larger model sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cdbackbone-agnostic\u6846\u67b6\uff0c\u5c06\u4eba\u7c7b\u5148\u9a8c\u77e5\u8bc6\u76f4\u63a5\u6574\u5408\u5230\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u4e2d\uff0c\u4ee5\u4f18\u5316\u51c6\u786e\u6027\u548c\u8d85\u8d8a\u51c6\u786e\u6027\u7684\u76ee\u6807\u3002", "motivation": "\u4e3a\u4e86\u957f\u671f\u7528\u6237\u6ee1\u610f\u5ea6\uff0c\u4f18\u5316\u63a8\u8350\u7cfb\u7edf\u4ee5\u5b9e\u73b0\u8d85\u8d8a\u51c6\u786e\u6027\u7684\u76ee\u6807\uff08\u4f8b\u5982\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u4e2a\u6027\u5316\uff09\u81f3\u5173\u91cd\u8981\u3002\u5de5\u4e1a\u5b9e\u8df5\u8005\u79ef\u7d2f\u4e86\u5927\u91cf\u7684\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4e0e\u6838\u5fc3\u6a21\u578b\u5b66\u4e60\u8131\u94a9\uff0c\u6216\u8005\u9700\u8981\u7279\u5b9a\u4e8e\u67b6\u6784\u7684\u4fee\u6539\u5e76\u4e22\u5f03\u6709\u4ef7\u503c\u7684\u4eba\u7c7b\u5148\u9a8c\u3002", "method": "\u5f15\u5165\u4e86\u53d7\u9ad8\u6548LLM\u89e3\u7801\u7b56\u7565\u542f\u53d1\u7684\u8f7b\u91cf\u7ea7\u3001\u5148\u9a8c\u6761\u4ef6\u9002\u914d\u5668\u5934\uff0c\u4ee5\u5f15\u5bfc\u6a21\u578b\u6cbf\u7740\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u8f74\uff08\u4f8b\u5982\uff0c\u4ea4\u4e92\u7c7b\u578b\u3001\u957f\u671f\u4e0e\u77ed\u671f\u5174\u8da3\uff09\u89e3\u5f00\u7528\u6237\u610f\u56fe\u3002\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u5206\u5c42\u7ec4\u5408\u7b56\u7565\uff0c\u7528\u4e8e\u5efa\u6a21\u4e0d\u540c\u5148\u9a8c\u7c7b\u578b\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u7740\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u8d85\u8d8a\u51c6\u786e\u6027\u7684\u76ee\u6807\u3002\u4eba\u7c7b\u5148\u9a8c\u5141\u8bb8\u9aa8\u5e72\u6a21\u578b\u66f4\u6709\u6548\u5730\u5229\u7528\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u66f4\u5927\u7684\u6a21\u578b\u5c3a\u5bf8\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u4eba\u7c7b\u5148\u9a8c\u77e5\u8bc6\u6765\u6539\u8fdb\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\uff0c\u5e76\u5728\u51c6\u786e\u6027\u548c\u8d85\u8d8a\u51c6\u786e\u6027\u7684\u76ee\u6807\u4e0a\u90fd\u53d6\u5f97\u4e86\u663e\u7740\u6210\u679c\u3002"}}
{"id": "2511.09570", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09570", "abs": "https://arxiv.org/abs/2511.09570", "authors": ["David Woller", "Viktor Koz\u00e1k", "Miroslav Kulich", "Libor P\u0159eu\u010dil"], "title": "Variable Neighborhood Search for the Electric Vehicle Routing Problem", "comment": "19 pages, 6 figures", "summary": "The Electric Vehicle Routing Problem (EVRP) extends the classical Vehicle Routing Problem (VRP) to reflect the growing use of electric and hybrid vehicles in logistics. Due to the variety of constraints considered in the literature, comparing approaches across different problem variants remains challenging. A minimalistic variant of the EVRP, known as the Capacitated Green Vehicle Routing Problem (CGVRP), was the focus of the CEC-12 competition held during the 2020 IEEE World Congress on Computational Intelligence. This paper presents the competition-winning approach, based on the Variable Neighborhood Search (VNS) metaheuristic. The method achieves the best results on the full competition dataset and also outperforms a more recent algorithm published afterward.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u57282020\u5e74IEEE\u4e16\u754c\u8ba1\u7b97\u667a\u80fd\u5927\u4f1a\u7684CEC-12\u7ade\u8d5b\u4e2d\u83b7\u80dc\u7684\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u95ee\u9898\uff08EVRP\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u57fa\u4e8e\u53ef\u53d8\u90bb\u57df\u641c\u7d22\uff08VNS\uff09\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "motivation": "\u7531\u4e8e\u6587\u732e\u4e2d\u8003\u8651\u7684\u7ea6\u675f\u6761\u4ef6\u7684\u591a\u6837\u6027\uff0c\u6bd4\u8f83\u4e0d\u540c\u95ee\u9898\u53d8\u4f53\u7684\u65b9\u6848\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u95ee\u9898\uff08EVRP\uff09\u6269\u5c55\u4e86\u7ecf\u5178\u7684\u8f66\u8f86\u8def\u5f84\u95ee\u9898\uff08VRP\uff09\uff0c\u4ee5\u53cd\u6620\u7535\u52a8\u548c\u6df7\u5408\u52a8\u529b\u6c7d\u8f66\u5728\u7269\u6d41\u4e2d\u65e5\u76ca\u589e\u957f\u7684\u5e94\u7528\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u53ef\u53d8\u90bb\u57df\u641c\u7d22\uff08VNS\uff09\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5b8c\u6574\u7684\u7ade\u8d5b\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u7ed3\u679c\uff0c\u5e76\u4e14\u4f18\u4e8e\u4e4b\u540e\u53d1\u5e03\u7684\u6700\u65b0\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eVNS\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u95ee\u9898\uff08EVRP\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728CEC-12\u7ade\u8d5b\u4e2d\u83b7\u80dc\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.09611", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09611", "abs": "https://arxiv.org/abs/2511.09611", "authors": ["Ye Tian", "Ling Yang", "Jiongfan Yang", "Anran Wang", "Yu Tian", "Jiani Zheng", "Haochen Wang", "Zhiyang Teng", "Zhuochen Wang", "Yinjie Wang", "Yunhai Tong", "Mengdi Wang", "Xiangtai Li"], "title": "MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation", "comment": "Project Page: https://tyfeld.github.io/mmadaparellel.github.io/", "summary": "While thinking-aware generation aims to improve performance on complex tasks, we identify a critical failure mode where existing sequential, autoregressive approaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we propose ParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis using ParaBench reveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose a parallel multimodal diffusion framework, MMaDA-Parallel, that enables continuous, bidirectional interaction between text and images throughout the entire denoising trajectory. MMaDA-Parallel is trained with supervised finetuning and then further optimized by Parallel Reinforcement Learning (ParaRL), a novel strategy that applies semantic rewards along the trajectory to enforce cross-modal consistency. Experiments validate that our model significantly improves cross-modal alignment and semantic consistency, achieving a 6.9\\% improvement in Output Alignment on ParaBench compared to the state-of-the-art model, Bagel, establishing a more robust paradigm for thinking-aware image synthesis. Our code is open-sourced at https://github.com/tyfeld/MMaDA-Parallel", "AI": {"tldr": "\u73b0\u6709\u7684\u81ea\u56de\u5f52\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7531\u4e8e\u8bef\u5dee\u4f20\u64ad\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u8bba\u6587\u63d0\u51fa\u4e86ParaBench\u57fa\u51c6\u6765\u8bc4\u4f30\u6587\u672c\u548c\u56fe\u50cf\u8f93\u51fa\uff0c\u53d1\u73b0\u6027\u80fd\u4e0b\u964d\u4e0e\u751f\u6210\u63a8\u7406\u548c\u6700\u7ec8\u56fe\u50cf\u4e4b\u95f4\u7684\u5bf9\u9f50\u4e0d\u826f\u6709\u5173\u3002\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e76\u884c\u591a\u6a21\u6001\u6269\u6563\u6846\u67b6MMaDA-Parallel\uff0c\u901a\u8fc7\u5728\u6574\u4e2a\u53bb\u566a\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u6587\u672c\u548c\u56fe\u50cf\u4e4b\u95f4\u7684\u8fde\u7eed\u53cc\u5411\u4ea4\u4e92\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u8bad\u7ec3MMaDA-Parallel\uff0c\u7136\u540e\u901a\u8fc7\u5e76\u884c\u5f3a\u5316\u5b66\u4e60\uff08ParaRL\uff09\u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u8be5\u7b56\u7565\u6cbf\u8f68\u8ff9\u5e94\u7528\u8bed\u4e49\u5956\u52b1\u4ee5\u52a0\u5f3a\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7531\u4e8e\u8bef\u5dee\u4f20\u64ad\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e76\u884c\u591a\u6a21\u6001\u6269\u6563\u6846\u67b6MMaDA-Parallel\uff0c\u901a\u8fc7\u5728\u6574\u4e2a\u53bb\u566a\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u6587\u672c\u548c\u56fe\u50cf\u4e4b\u95f4\u7684\u8fde\u7eed\u53cc\u5411\u4ea4\u4e92\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002\u4f7f\u7528\u76d1\u7763\u5fae\u8c03\u8bad\u7ec3MMaDA-Parallel\uff0c\u7136\u540e\u901a\u8fc7\u5e76\u884c\u5f3a\u5316\u5b66\u4e60\uff08ParaRL\uff09\u8fdb\u4e00\u6b65\u4f18\u5316\u3002", "result": "\u5728ParaBench\u4e0a\uff0c\u8f93\u51fa\u5bf9\u9f50\u65b9\u9762\u6bd4\u6700\u5148\u8fdb\u7684\u6a21\u578bBagel\u63d0\u9ad8\u4e866.9%\u3002", "conclusion": "\u8be5\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u4e3a\u601d\u8003\u611f\u77e5\u56fe\u50cf\u5408\u6210\u5efa\u7acb\u4e86\u4e00\u4e2a\u66f4\u5f3a\u5927\u7684\u8303\u4f8b\u3002"}}
{"id": "2511.09700", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09700", "abs": "https://arxiv.org/abs/2511.09700", "authors": ["Warren Li", "Yiqian Wang", "Zihan Wang", "Jingbo Shang"], "title": "Order Matters: Rethinking Prompt Construction in In-Context Learning", "comment": null, "summary": "In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.", "AI": {"tldr": "\u91cd\u65b0\u8bc4\u4f30\u4e86\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u4e2d\u793a\u4f8b\u9009\u62e9\u548c\u6392\u5e8f\u7684\u91cd\u8981\u6027\uff0c\u53d1\u73b0\u6392\u5e8f\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u4e0e\u9009\u62e9\u4e0d\u540c\u793a\u4f8b\u96c6\u7684\u5f71\u54cd\u76f8\u5f53\u3002", "motivation": "\u5148\u524d\u7684\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u793a\u4f8b\u9009\u62e9\uff0c\u800c\u5ffd\u7565\u4e86\u793a\u4f8b\u6392\u5e8f\u7684\u5f71\u54cd\u3002\u672c\u6587\u65e8\u5728\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u5047\u8bbe\uff0c\u7cfb\u7edf\u5730\u6bd4\u8f83\u9009\u62e9\u548c\u6392\u5e8f\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5728\u5206\u7c7b\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u4f7f\u7528\u591a\u79cd\u5f00\u6e90\u6a21\u578b\u548cGPT-3\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u793a\u4f8b\u6392\u5e8f\u5bfc\u81f4\u7684\u6027\u80fd\u5dee\u5f02\u4e0e\u4f7f\u7528\u5b8c\u5168\u4e0d\u540c\u7684\u793a\u4f8b\u96c6\u76f8\u5f53\u3002\u4ec5\u4f7f\u7528\u5f00\u53d1\u96c6\u5373\u53ef\u8bc6\u522b\u5f3a\u6392\u5e8f\uff0c\u5176\u6027\u80fd\u63a5\u8fd1\u4e8e\u57fa\u4e8e\u6d4b\u8bd5\u6807\u7b7e\u9009\u62e9\u6700\u4f73\u6392\u5e8f\u7684oracle\u3002", "conclusion": "\u793a\u4f8b\u9009\u62e9\u548c\u6392\u5e8f\u5728\u63d0\u793a\u8bbe\u8ba1\u4e2d\u540c\u7b49\u91cd\u8981\u4e14\u76f8\u4e92\u5173\u8054\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6ICL\u4e2d\u7684\u5047\u8bbe\u3002"}}
