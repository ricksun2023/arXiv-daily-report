<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 3]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [Bias Mitigation for AI-Feedback Loops in Recommender Systems: A Systematic Literature Review and Taxonomy](https://arxiv.org/abs/2509.00109)
*Theodor Stoecker,Samed Bayer,Ingo Weber*

Main category: cs.IR

TL;DR: 这篇论文综述了在推荐系统中减轻因AI反馈循环而产生的偏差的方法，这些方法在多轮模拟或A/B测试中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 推荐系统不断地根据用户对其自身预测的反应进行重新训练，从而产生AI反馈循环，随着时间的推移，这会放大偏差并降低公平性。尽管存在这种众所周知的风险，但大多数偏差缓解技术仅在静态分割上进行测试，因此它们在多个重新训练轮次中的长期公平性仍不清楚。

Method: 该研究对347篇论文进行了筛选，最终选择了2019-2025年间发表的24篇主要研究，并从六个维度对每项研究进行编码：缓解技术、解决的偏差、动态测试设置、评估重点、应用领域和ML任务，并将它们组织成一个可重用的分类。

Result: 该分类法为行业从业者提供了一个快速检查表，用于选择稳健的方法，并为研究人员提供了一个清晰的路线图，以了解该领域最紧迫的差距。例子包括共享模拟器的短缺、不同的评估指标，以及大多数研究报告公平性或性能；只有六项研究同时使用两者。

Conclusion: 总结了现有偏差缓解方法在考虑AI反馈循环方面的研究，并指出了该领域存在的差距，为从业者和研究人员提供了指导。

Abstract: Recommender systems continually retrain on user reactions to their own
predictions, creating AI feedback loops that amplify biases and diminish
fairness over time. Despite this well-known risk, most bias mitigation
techniques are tested only on static splits, so their long-term fairness across
multiple retraining rounds remains unclear. We therefore present a systematic
literature review of bias mitigation methods that explicitly consider AI
feedback loops and are validated in multi-round simulations or live A/B tests.
Screening 347 papers yields 24 primary studies published between 2019-2025.
Each study is coded on six dimensions: mitigation technique, biases addressed,
dynamic testing set-up, evaluation focus, application domain, and ML task,
organising them into a reusable taxonomy. The taxonomy offers industry
practitioners a quick checklist for selecting robust methods and gives
researchers a clear roadmap to the field's most urgent gaps. Examples include
the shortage of shared simulators, varying evaluation metrics, and the fact
that most studies report either fairness or performance; only six use both.

</details>


### [2] [Algorithm Adaptation Bias in Recommendation System Online Experiments](https://arxiv.org/abs/2509.00199)
*Chen Zheng,Zhenyu Zhao*

Main category: cs.IR

TL;DR: 算法适应性偏差会扭曲在线实验（A/B测试）的结果，导致决策失误。


<details>
  <summary>Details</summary>
Motivation: 现有推荐系统在线实验评估中存在算法适应性偏差问题，对新模型效果评估不准确。

Method: 分析算法适应性偏差的机制，并提供实际案例。

Result: 在线实验结果通常会高估现有系统，低估新系统的性能。

Conclusion: 需要重视算法适应性偏差，并在实验设计、测量和调整等方面寻求更可靠的在线评估方法。

Abstract: Online experiments (A/B tests) are widely regarded as the gold standard for
evaluating recommender system variants and guiding launch decisions. However, a
variety of biases can distort the results of the experiment and mislead
decision-making. An underexplored but critical bias is algorithm adaptation
effect. This bias arises from the flywheel dynamics among production models,
user data, and training pipelines: new models are evaluated on user data whose
distributions are shaped by the incumbent system or tested only in a small
treatment group. As a result, the measured effect of a new product change in
modeling and user experience in this constrained experimental setting can
diverge substantially from its true impact in full deployment. In practice, the
experiment results often favor the production variant with large traffic while
underestimating the performance of the test variant with small traffic, which
leads to missing opportunities to launch a true winning arm or underestimating
the impact. This paper aims to raise awareness of algorithm adaptation bias,
situate it within the broader landscape of RecSys evaluation biases, and
motivate discussion of solutions that span experiment design, measurement, and
adjustment. We detail the mechanisms of this bias, present empirical evidence
from real-world experiments, and discuss potential methods for a more robust
online evaluation.

</details>


### [3] [Beyond Negative Transfer: Disentangled Preference-Guided Diffusion for Cross-Domain Sequential Recommendation](https://arxiv.org/abs/2509.00389)
*Xiaoxin Ye,Chengkai Huang,Hongtao Huang,Lina Yao*

Main category: cs.IR

TL;DR: 提出了一个名为 DPG-Diff 的新颖的基于扩散模型的跨域序列推荐方法，该方法解耦用户偏好，从而实现鲁棒的跨域知识转移，减轻负迁移，并过滤序列噪声。


<details>
  <summary>Details</summary>
Motivation: 跨域序列推荐 (CDSR) 利用跨域的用户行为来提高推荐质量。然而，简单地聚合序列信号会引入冲突的领域特定偏好，从而导致负迁移。序列推荐 (SR) 已经受到错误点击和冲动行为等噪声行为的影响，而 CDSR 由于项目类型和用户意图的多样性而产生的领域异质性，进一步加剧了这个问题。核心挑战是解开三个相互交织的信号：领域不变偏好、领域特定偏好和噪声。

Method: DPG-Diff 将用户偏好分解为领域不变和领域特定的组成部分，这些组成部分共同指导反向扩散过程。

Result: 在真实世界数据集上的大量实验表明，DPG-Diff 在多个指标上始终优于最先进的基线。

Conclusion: DPG-Diff 是一种专为 CDSR 定制的首个基于扩散模型的方法，它可以实现鲁棒的跨域知识转移，减轻负迁移，并过滤序列噪声。

Abstract: Cross-Domain Sequential Recommendation (CDSR) leverages user behaviors across
domains to enhance recommendation quality. However, naive aggregation of
sequential signals can introduce conflicting domain-specific preferences,
leading to negative transfer. While Sequential Recommendation (SR) already
suffers from noisy behaviors such as misclicks and impulsive actions, CDSR
further amplifies this issue due to domain heterogeneity arising from diverse
item types and user intents. The core challenge is disentangling three
intertwined signals: domain-invariant preferences, domain-specific preferences,
and noise. Diffusion Models (DMs) offer a generative denoising framework
well-suited for disentangling complex user preferences and enhancing robustness
to noise. Their iterative refinement process enables gradual denoising, making
them effective at capturing subtle preference signals. However, existing
applications in recommendation face notable limitations: sequential DMs often
conflate shared and domain-specific preferences, while cross-domain
collaborative filtering DMs neglect temporal dynamics, limiting their ability
to model evolving user preferences. To bridge these gaps, we propose
\textbf{DPG-Diff}, a novel Disentangled Preference-Guided Diffusion Model, the
first diffusion-based approach tailored for CDSR, to or best knowledge.
DPG-Diff decomposes user preferences into domain-invariant and domain-specific
components, which jointly guide the reverse diffusion process. This
disentangled guidance enables robust cross-domain knowledge transfer, mitigates
negative transfer, and filters sequential noise. Extensive experiments on
real-world datasets demonstrate that DPG-Diff consistently outperforms
state-of-the-art baselines across multiple metrics.

</details>
