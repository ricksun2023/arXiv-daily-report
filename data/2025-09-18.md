<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 75]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.IR](#cs.IR) [Total: 5]
- [cs.LG](#cs.LG) [Total: 55]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文针对意大利语中的性别中立改写（GNR）任务，评估了大型语言模型（LLM）的性能。


<details>
  <summary>Details</summary>
Motivation: 在意大利语等具有语法性别的语言中，GNR 是一项具有挑战性的任务，旨在消除不必要的性别指定并保留语义。

Method: 通过引入一个二维框架来评估 LLM 的中立性和语义保真度，比较了多个 LLM 的少量样本提示，微调了选定的模型，并应用有针对性的数据清洗。

Result: 研究发现，开放权重 LLM 的性能优于现有的意大利语 GNR 模型，而微调后的模型在规模较小的情况下，性能与最佳开放权重 LLM 相匹配或超过。

Conclusion: 讨论了优化训练数据以实现中立性和意义保留之间的权衡。

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [2] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: 发布了一个关于联邦公开市场委员会(FOMC)会议记录的数据集Op-Fed，其中包含1044个人工注释的句子，用于货币政策分析。


<details>
  <summary>Details</summary>
Motivation: 为了研究货币政策，现有的方法缺乏足够的高质量数据，尤其是在判断对货币政策的立场方面。

Method: 创建了一个五阶段分层模式来分离意见、货币政策和对货币政策的立场，并使用主动学习选择了要注释的实例。

Result: 发现一个表现最佳的闭源LLM在意见分类中达到了0.80的zero-shot准确率，但在分类对货币政策的立场时，zero-shot准确率仅为0.61，低于人类基线0.89。

Conclusion: Op-Fed数据集对于未来的模型训练、置信度校准以及作为未来注释工作的种子数据集非常有用。

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [3] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: 本研究旨在填补大型语言模型对话系统评估中的不足，包括传统指标的局限性和安全考虑的文化偏差。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型对话系统评估不足，传统指标效果差，安全考虑存在文化偏差。

Method: DSTC12 Track 1 包含两个子任务：(1) 对话级别多维度自动评估指标；(2) 多语言和多元文化安全检测。

Result: 在 Task 1 中，Llama-3-8B 基线取得了最高的平均 Spearman 相关性 (0.1681)，表明有很大的改进空间。在 Task 2 中，参与团队在多语言安全子集上明显优于 Llama-Guard-3-1B 基线 (最高 ROC-AUC 0.9648)，但基线在文化子集上表现更好 (0.5126 ROC-AUC)。

Conclusion: 文化意识安全方面存在关键需求。

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [4] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: 大型语言模型被广泛应用，但它们经常会遇到训练中未遇到的任务。因此，我们需要依靠迁移学习。本文构建了一个迁移学习矩阵和降维的分析框架，以剖析这些跨任务交互。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，大型语言模型需要处理训练中未遇到的任务，因此需要依靠迁移学习，但不同数据集的特征各异。

Method: 训练并分析了10个模型，以识别潜在的能力（例如，推理、情感分类、NLU、算术），并发现迁移学习的副作用。构建迁移学习矩阵和降维的分析框架。

Result: 性能的提高往往无法用表面上的数据集相似性或源数据质量来解释。源数据集的隐藏统计因素（如类分布和生成长度倾向）以及特定的语言特征实际上影响更大。

Conclusion: 这项工作深入了解了迁移学习的复杂动态，为更可预测和有效的大型语言模型适应铺平了道路。

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [5] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)在回答问题时往往过于自信，未能识别问题中的歧义。本研究表明，LLM内部表征以线性方式编码问题歧义，并且可以在神经元层面进行检测和控制。


<details>
  <summary>Details</summary>
Motivation: 现实世界的问题中普遍存在歧义，但大型语言模型(LLM)通常直接给出自信的答案，而不是寻求澄清。

Method: 通过实验发现，在LLM的预填充阶段，少数神经元（甚至只有一个）编码了问题歧义信息。基于这些歧义编码神经元(AENs)训练的探测器在歧义检测方面表现出色，并且可以跨数据集泛化，优于基于prompt和基于表征的基线方法。

Result: 研究表明，歧义编码神经元(AENs)从浅层网络中出现，表明模型处理流程中对歧义信号的早期编码。通过操纵AENs，我们可以控制LLM的行为，使其从直接回答转变为弃权。

Conclusion: LLM形成了问题歧义的紧凑内部表征，从而实现了可解释和可控的行为。

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [6] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 该论文介绍了一种新的生物医学事实核查框架，它结合了科学证据检索、大型语言模型的推理和监督验证预测。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域中的错误信息对公众健康和对医疗系统的信任构成风险。验证生物医学声明仍然具有挑战性，原因在于其复杂的术语、对领域专业知识的需求以及基于科学证据的重要性。

Method: 该论文提出了 CER 框架，它通过将大型语言模型的文本生成能力与高质量生物医学科学证据的高级检索技术相结合，有效地降低了幻觉风险，确保生成的输出基于可验证的、基于证据的来源。

Result: 在专家注释的数据集上的评估表明，该框架具有最先进的性能和良好的跨数据集泛化能力。

Conclusion: 该论文发布了代码和数据，以提高透明度和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [7] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 提出了一个用于评估跨多个学术领域自适应中文语法纠错（CGEC）的持续学习基准CL$^2$GEC。


<details>
  <summary>Details</summary>
Motivation: 现有CGEC研究缺乏多学科的专用基准，忽略了持续学习（CL）作为处理领域特定语言变异和防止灾难性遗忘的有前途的解决方案。

Method: 构建了一个包含10个学科的10,000个句子的人工标注数据集，并使用标准GEC指标和适应于任务级变化的持续学习指标，在顺序调整、参数高效适应和四个代表性CL算法下评估大型语言模型。

Result: 实验结果表明，基于正则化的方法比基于重放或朴素顺序的方法更有效地减轻遗忘。

Conclusion: 该基准为未来跨不同学术领域的自适应语法纠错研究提供了严谨的基础。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [8] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 这篇论文介绍了一种名为CER的新型生物医学事实核查框架，该框架结合了科学证据检索、通过大型语言模型进行推理以及监督下的准确性预测。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域中的错误信息对公众健康和对医疗系统的信任构成风险。验证生物医学主张仍然具有独特的挑战性，因为其术语复杂，需要领域专业知识，并且需要以科学证据为基础。

Method: 该论文介绍了CER，它通过将大型语言模型的文本生成能力与用于高质量生物医学科学证据的高级检索技术相结合，有效地降低了幻觉的风险，确保生成的输出基于可验证的、基于证据的来源。

Result: 在专家注释数据集上的评估表明，CER具有最先进的性能和有希望的跨数据集泛化能力。

Conclusion: 该论文发布了代码和数据，以提高透明度和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [9] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG: A novel framework for controlled text generation (CTG) that uses a multi-agent approach to enhance control and scalability.


<details>
  <summary>Details</summary>
Motivation: Fine-grained conditional control in CTG is challenging, especially considering cost, scalability, domain knowledge, and precise control in real-world applications.

Method: Introduces AgentCTG, a multi-agent framework with collaboration methods and an auto-prompt module.

Result: Achieves state-of-the-art results on public datasets and demonstrates effectiveness in a new Character-Driven Rewriting task. Improves online navigation and user engagement.

Conclusion: AgentCTG enhances text generation, enabling more immersive and personalized interactions in online communities.

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [10] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: 提出了一种新的检索增强推理框架CARE，通过在推理过程中整合上下文证据来提高LLM的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理上下文保真度方面存在困难，当基于提供的信息回答问题时，会产生不一致的答案。现有方法要么依赖昂贵的监督微调来生成答案后的证据，要么训练模型执行网络搜索，但不一定提高给定上下文的利用率。

Method: CARE框架，该框架教导LLM在其推理过程中显式地整合上下文证据，并利用模型自身的检索能力。该方法需要有限的标记证据数据，同时通过策略性地检索推理链中的上下文token，显著提高检索准确性和答案生成性能。

Result: 在多个真实世界和反事实QA基准上的大量实验表明，我们的方法大大优于监督微调、传统的检索增强生成方法和外部检索解决方案。

Conclusion: 这项工作代表了在使LLM更准确、可靠和高效地执行知识密集型任务方面的一个根本性进步。

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [11] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 大型语言模型在自然语言推理（NLI）方面表现出色，但在处理涉及数字和逻辑表达式的NLI时仍面临挑战。本研究构建了一个日语NLI数据集，专门关注比较句，并评估了各种LLM在零样本和小样本环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机是现有LLM在处理比较句方面的鲁棒性，特别是在非主流语言（如日语）上，尚未得到充分研究。

Method: 构建了一个日语NLI数据集，重点关注比较句，并在零样本和小样本环境下评估各种LLM。

Result: 研究结果表明，模型在零样本设置中的性能对提示格式敏感，并受到小样本示例中黄金标签的影响。LLM难以处理日语特有的语言现象。包含逻辑语义表示的提示有助于模型预测正确的标签。

Conclusion: LLM在处理日语比较句NLI时面临挑战，但包含逻辑语义表示的提示可以提高模型性能。

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [12] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: 本研究探索了大型语言模型（LLM）在处理临床分类任务中的能力，特别是结合结构化数据（如时间序列）和临床笔记。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成方面表现出色，但它们处理涉及结构化数据的临床分类任务的能力仍有待探索。

Method: 我们使用基于 DSPy 的提示优化来调整指令调整的 LLM，以联合处理临床笔记和结构化 EHR 输入。

Result: 结果表明，该方法在性能上与专门的多模态系统相当，同时降低了复杂性，并在任务中提供了更大的适应性。

Conclusion: Instruction-tuned LLMs可以通过DSPy优化prompt，从而在临床分类任务上达到与专门的多模态系统相媲美的性能。

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [13] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: 该论文提出了一种名为DSCC-HS的新框架，用于主动抑制大型语言模型（LLM）的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法（如RAG）通常是被动的。LLM幻觉是其可靠部署的重要障碍。

Method: DSCC-HS在自回归解码期间进行干预，使用对抗训练的代理模型（FAP和HDP）动态引导目标模型，通过注入实时steering vector。

Result: 在TruthfulQA和BioGEN上实现了最先进的性能。在TruthfulQA上达到了99.2%的FCR，在BioGEN上达到了46.50的FActScore。

Conclusion: DSCC-HS是一种用于增强LLM事实性的有效解决方案。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [14] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 开发了一种自然语言处理 (NLP) 筛查工具，用于检测放射肿瘤学中的高危事件报告。


<details>
  <summary>Details</summary>
Motivation: 人工审查事件报告耗时且需要专业知识，因此需要NLP工具来辅助。

Method: 使用来自机构内部和IAEA SAFRON的两个文本数据集，训练和评估支持向量机 (SVM) 和 BlueBERT 模型。还评估了模型的泛化能力，并通过迁移学习提高了跨机构的性能。

Result: 在机构内部测试中，SVM和BlueBERT的AUROC分别为0.82和0.81。在SF测试中，BlueBERT_TRANSFER模型的AUROC提高到0.78。在手动编辑的数据集上，模型性能与人类相似。

Conclusion: 成功开发了跨机构的NLP模型，可以检测高危事件报告，其性能与人类在精选数据集上的表现相似。

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [15] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为双阶段渐进压缩（DSPC）的免训练方法，用于压缩LLM的prompt，以解决prompt过长导致计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的prompt压缩方法通常需要训练额外的模型，这增加了计算负担。为了避免这种情况，本文提出了一种免训练的prompt压缩方法。

Method: 该方法包括两个阶段：粗粒度阶段，基于TF-IDF过滤语义价值低的句子；细粒度阶段，通过注意力贡献、跨模型损失差异和位置重要性评估token的重要性，从而修剪低效用的token。

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上的实验表明，DSPC在token预算受限的情况下表现出持续的改进。例如，在Longbench数据集的FewShot任务中，DSPC仅使用减少3倍的token，就达到了49.17的性能，优于最佳的baseline LongLLMLingua 7.76。

Conclusion: DSPC方法在压缩LLM prompt方面有效，且无需额外训练，具有实际应用价值。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [16] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本研究提出了一种基于组合语义的日语比较句逻辑推理系统ccg-jcomp，以解决日语和英语比较句在形态和语义上的差异。


<details>
  <summary>Details</summary>
Motivation: 现有的英语比较句逻辑推理系统难以直接应用于日语，因为两者存在形态和语义差异。

Method: 构建了一个基于组合语义的日语比较句逻辑推理系统ccg-jcomp。

Result: 在包含比较表达的日语NLI数据集上评估了该系统，并通过与现有LLM的准确率比较，证明了其有效性。

Conclusion: 该研究提出的ccg-jcomp系统在日语比较句自然语言推理任务中表现出有效性。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [17] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 探索阿拉伯语方言识别(ADI)的数据和参数高效方法


<details>
  <summary>Details</summary>
Motivation: 分析大型语言模型(LLM)在方言识别方面的能力

Method: 研究各种软提示策略(包括prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2)以及LoRA重参数化。对于数据高效策略，我们分析了零样本和小样本推理的硬提示。对于参数高效PEFT方法，我们使用特定于阿拉伯语的编码器模型在几个主要数据集上进行了实验。我们还分析了开源解码器模型的n-shot推理，一个通用多语言模型(Phi-3.5)和一个阿拉伯语专用模型(SILMA)。

Result: LLM通常难以区分few-shot或zero-shot设置中的方言细微差别。软提示编码器变体的性能更好，而基于LoRA的微调模型表现最佳，甚至超过了完全微调。

Conclusion: 基于LoRA的微调模型在阿拉伯语方言识别任务中表现最好

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [18] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出了一种名为CAMPUS的指令调优框架，通过动态课程选择和能力感知调整来优化LLM的训练。


<details>
  <summary>Details</summary>
Motivation: 现有的课程学习方法在指令调优中表现出初步效果，但由于依赖静态启发式难度指标，缺乏对模型训练过程中能力变化的适应性，导致学习轨迹固定且可能不是最优的。

Method: 提出了CAMPUS框架，包含动态子课程选择、能力感知课程调整和多难度调度。

Result: 大量实验证明，CAMPUS在高效指令调优方面优于其他最先进的基线方法。

Conclusion: CAMPUS框架能够有效提升LLM在给定指令数据集上的性能。

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [19] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 该研究为研究工作职称中明确的语法性别分配如何影响自动工作排序系统的结果奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 研究工作职称中明确的语法性别分配如何影响自动工作排序系统的结果。

Method: 提出使用控制性别的排序比较指标来评估工作职称排序系统中的性别偏见，特别是RBO（排序偏差重叠）。

Result: 生成并共享了四种语法性别语言的工作职称匹配任务的测试集，包括男性和女性形式的职业，并按性别和匹配相关性进行注释。使用新的测试集和提出的方法来评估几种现成的多语言模型的性别偏见，以设置为基线，表明所有模型都表现出不同程度的性别偏见。

Conclusion: 所有模型都表现出不同程度的性别偏见。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [20] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 本文提出了一种新的黑盒方法，用于量化大型语言模型中的不确定性，以检测幻觉。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在各种任务中表现出令人印象深刻的结果，但仍然存在幻觉问题，会生成在语言上合理但不正确的答案。不确定性量化已被提议作为一种幻觉检测策略，但没有现有的黑盒方法能够提供全局和局部不确定性的估计。

Method: 本文介绍了一种几何框架，该框架基于仅通过黑盒模型访问采样的一批响应的原型分析。在全局层面，我们提出了几何体积，它测量从响应嵌入导出的原型凸包体积。在局部层面，我们提出了几何怀疑，它通过可靠性对响应进行排序，并通过优先响应选择来实现幻觉减少。

Result: 实验表明，我们的框架在简短形式的问答数据集上与先前的方法相比具有可比性或更好的性能，并且在医疗数据集中取得了优异的结果，在这些数据集中，幻觉带有特别关键的风险。我们还通过证明凸包体积和熵之间的联系来提供理论依据。

Conclusion: 本文提出了一种基于几何分析的黑盒不确定性量化方法，可以有效地检测大型语言模型中的幻觉，并在医疗等高风险领域具有潜在的应用价值。

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [21] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: AutoMin 2025包括会议纪要生成和问答两个任务，参与队伍不多，但组织者提供了多个基线系统。


<details>
  <summary>Details</summary>
Motivation: 评估当前大型语言模型在会议纪要生成和问答任务上的能力。

Method: 会议纪要生成任务涵盖英语和捷克语，项目会议和欧洲议会会议两个领域。问答任务则侧重于项目会议，并提供英语单语和基于英语会议的捷克语跨语问答。

Result: 参与队伍数量有限，会议纪要生成任务只有一个队伍参加，问答任务有两个队伍参加。

Conclusion: 组织者提供了多个基线系统，以便对当前大型语言模型在两个任务上进行全面评估。

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [22] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)对德国方言使用者存在偏见，类似于社会刻板印象。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否反映了社会对使用方言个体的负面刻板印象，因为超过40%的德国人说方言，但方言使用者面临负面的社会刻板印象。

Method: 构建了一个新的评估语料库，该语料库将七种德国地区方言的句子（例如，阿拉曼尼语和巴伐利亚语）与其标准德语对应句配对，以评估模型的方言使用偏差。通过关联任务和决策任务评估LLM中的方言命名偏差和方言使用偏差。

Result: (1) 在关联任务中，所有评估的LLM都表现出对方言使用者的显着方言命名和方言使用偏见，这反映在负面的形容词关联中；(2) 所有模型都在其决策中重现这些方言命名和方言使用偏见；(3) 与先前显示通过明确的人口统计提及来减少偏差的研究相反，我们发现明确标记语言人口统计信息——德国方言使用者——比方言使用等隐含线索更能放大偏差。

Conclusion: LLM对德国方言使用者存在偏见，且明确提及语言人口统计信息会加剧这种偏见。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [23] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: 本研究调查了大型语言模型（LLM）在不同类型的偏见情境中与人类价值观对齐的情况，发现模型规模大的LLM不一定有更低的错位率和攻击成功率，且LLM对特定类型的情境表现出偏好。


<details>
  <summary>Details</summary>
Motivation: 先前研究揭示了LLM与人类价值观的错位，但尚不清楚LLM与人类价值观的对齐是否因不同类型的情境而异（例如，包含负面与非负面问题的情境）。

Method: 通过对来自四个模型系列的12个LLM和四个数据集的广泛分析。

Result: 大型模型参数规模的LLM不一定具有较低的错位率和攻击成功率。LLM对特定类型的情境表现出一定程度的对齐偏好，并且来自同一模型系列的LLM往往具有较高的一致性判断。对LLM的理解能力的研究发现，LLM在对HVSB的理解上没有显著差异，并且LLM更喜欢自己生成的解释。微调后的小型LM生成的解释更易读，但模型认同度相对较低。

Conclusion: 本研究揭示了LLM在不同偏见情境中与人类价值观对齐的复杂性，强调了即使是大型模型也可能存在偏见，并强调了进一步研究和改进LLM对齐策略的必要性。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [24] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: 评估大型语言模型(LLM)理解语境中词义的能力，发现它们在词义消歧(WSD)任务中表现与专用系统相当，且在生成任务中能以高达98%的准确率解释语境中的词义。


<details>
  <summary>Details</summary>
Motivation: 现有评估不足以衡量LLM真正理解词义的程度。

Method: 通过评估指令调优的LLM的WSD能力，并比较其与最先进系统的性能；同时评估两个表现最佳的开源和闭源LLM在三种生成设置（定义生成、自由形式解释和示例生成）中理解词义的能力。

Result: GPT-4o和DeepSeek-V3等领先模型在WSD任务中表现与专用WSD系统相当，且在不同领域和难度级别上表现出更强的鲁棒性。LLM在生成任务中能以高达98%的准确率解释语境中的词义，其中自由形式解释任务表现最佳。

Conclusion: LLM在理解语境中词义方面表现出色，尤其是在自由形式解释任务中。

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [25] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: mRAG系统在跨语言知识密集型查询中，模型的表现会受到不同语言文档混合的影响，特别是会偏向引用英文资料。


<details>
  <summary>Details</summary>
Motivation: 研究多语言文档混合对mRAG系统生成和引用的影响，特别是模型是否会在文档相关性和语言偏好之间进行权衡。

Method: 提出了一种受控方法，利用模型内部机制来衡量语言偏好，同时保持文档相关性等因素不变。

Result: 发现当查询语言为英语时，模型倾向于引用英文来源，对于较低资源语言和位于中间上下文的文档，这种偏差会放大。模型有时会在文档相关性和语言偏好之间进行权衡。

Conclusion: 研究结果揭示了语言模型如何利用多语言上下文并影响引用行为。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [26] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: 本文介绍了提交给机器翻译第十届会议(WMT25)自动翻译质量评估共享任务的系统，该系统基于COMET框架，并经过训练以预测段落级错误跨度注释(ESA)分数。


<details>
  <summary>Details</summary>
Motivation: 构建长文本训练数据，通过连接领域内人工标注的句子并计算其分数的加权平均值。

Method: 通过归一化其尺度来整合多个人工判断数据集(MQM、SQM和DA)，并训练多语言回归模型以预测来自源、假设和参考翻译的质量分数。

Result: 实验结果表明，与仅在短段上训练的模型相比，结合长文本信息可以提高与人类判断的相关性。

Conclusion: 结合长文本信息可以提高与人类判断的相关性。

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [27] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: 本文提出了一种名为 Slim-SC 的方法，用于减少 Self-Consistency (SC) 的计算开销，同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: Self-Consistency (SC) 虽然能提高 LLM 的推理性能，但计算开销大，限制了其应用。

Method: 通过理论和实验分析 SC 的低效性，并提出一种基于链间相似性的逐步修剪策略，即 Slim-SC，来识别和删除冗余链。

Result: 在三个 STEM 推理数据集和两个 LLM 架构上的实验表明，Slim-SC 可以减少高达 45% 的推理延迟和 26% 的 KVC 使用率，同时保持或提高准确性。

Conclusion: Slim-SC 为 SC 提供了一个简单而有效的 TTS 替代方案。

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [28] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

TL;DR: 提出了一种名为ES-CoT的推理时方法，通过检测答案收敛并提前停止来缩短CoT生成，从而减少推理成本，同时保持性能损失最小。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)通过生成长的思维链(CoT)在解决复杂问题方面表现出卓越的能力，但这种冗长的CoT会产生高昂的推理成本。

Method: 在每个推理步骤结束时，提示LLM输出其当前最终答案，表示为步骤答案。然后，我们跟踪连续相同步骤答案的运行长度，作为答案收敛的度量。一旦运行长度出现急剧增加并超过最小阈值，生成就会终止。

Result: 在三个llm的五个推理数据集上的实验表明，ES-CoT平均减少了约41%的推理token数量，同时保持了与标准CoT相当的准确性。

Conclusion: ES-CoT与自我一致性提示无缝集成，并在超参数选择中保持健壮性，突出了它作为一种高效推理的实用有效方法。

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [29] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

TL;DR: Hala is a family of Arabic-centric instruction and translation models.


<details>
  <summary>Details</summary>
Motivation: To create Arabic-centric instruction and translation models.

Method: Translate-and-tune pipeline: compress a strong AR<->EN teacher, fine-tune a lightweight language model, translate English instruction sets into Arabic, train Hala models, and apply slerp merging.

Result: Hala achieves state-of-the-art results on Arabic-centric benchmarks.

Conclusion: The models, data, evaluation, and recipes are released to accelerate research in Arabic NLP.

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [30] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

TL;DR: 本文探讨了机器翻译(MT)质量评估的问题，现有评估主要集中在文本上，但实际应用中语音翻译越来越重要。因此，本文提出了一种基于语音的评估方法，并与传统的文本评估方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 现有的机器翻译质量评估主要集中在文本上，忽略了语音翻译的实际应用场景，因此需要一种更自然的、基于语音的评估方法。

Method: 本文通过Amazon Mechanical Turk收集众包判断，对WMT General MT Shared Task中的10个机器翻译系统进行了文本和音频评估，并进行了统计显著性检验和自我复制实验，以测试音频评估方法的可靠性和一致性。

Result: 基于音频的众包评估结果与文本评估结果基本一致，但在某些情况下，能够识别出翻译系统之间的显著差异。这归因于语音是一种更丰富、更自然的形态。

Conclusion: 本文提出将基于语音的评估纳入未来的机器翻译评估框架中。

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [31] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 本文研究了上下文信息对于机器翻译的影响，发现训练数据中上下文相关示例的稀疏性是性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 为了实现人类水平的翻译，需要利用上下文来确保连贯性并处理诸如代词歧义消除之类的复杂现象。标准训练数据中上下文丰富示例的稀疏性被认为是上下文利用困难的原因。

Method: 通过构建具有受控比例的上下文相关示例的训练数据集，在单语和多语设置中系统地验证了这一说法。

Result: 证实了训练数据稀疏性和模型性能之间存在很强的关联，表明稀疏性是关键瓶颈。一个上下文现象的改进并不推广到其他现象。跨语言迁移并不在同一语族内的语言之间显着更高。

Conclusion: 提出了两种旨在利用可用数据的训练策略，并对其进行了经验评估。这些策略提高了上下文利用率，在单语和多语设置中，ctxPro评估的准确率分别提高了高达6和8个百分点。

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [32] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为ConfMAD的框架，通过在多智能体辩论系统中加入置信度表达来提高辩论效果和系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体辩论系统中的大型语言模型在辩论中难以清晰地表达自身优势，并且不恰当的置信度表达会导致辩论效果降低。

Method: 该论文提出了ConfMAD框架，该框架在整个辩论过程中整合了置信度表达。

Result: 实验结果表明该方法有效。

Conclusion: 该研究分析了置信度如何影响辩论动态，并为置信度感知的多智能体辩论系统的设计提供了见解。

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [33] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

TL;DR: 本文提出了一种新的基于问题的SLT任务，该任务利用对话来提高翻译质量。


<details>
  <summary>Details</summary>
Motivation: 对话自然地存在于交流中，并且更容易注释，因此本文探讨了有效整合对话的方法。

Method: 本文提出了一种带有Sigmoid自注意力加权的跨模态自监督学习(SSL-SSAW)融合方法。

Result: 在CSL-Daily-QA和PHOENIX-2014T-QA数据集上，SSL-SSAW取得了SOTA的性能。易于访问的问题辅助可以达到甚至超过gloss辅助的性能。

Conclusion: 结合对话可以有效提高翻译质量。

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [34] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

TL;DR: Canary-1B-v2 is a fast, multilingual ASR and AST model excelling in speed and performance compared to other models.


<details>
  <summary>Details</summary>
Motivation: To create a fast and robust multilingual model for ASR and AST.

Method: Utilizing a FastConformer encoder and Transformer decoder, trained on 1.7M hours of data with a two-stage pre-training and fine-tuning process.

Result: Canary-1B-v2 outperforms Whisper-large-v3 in English ASR speed and shows competitive multilingual performance. Parakeet-TDT-0.6B-v3, a smaller model, also offers multilingual ASR.

Conclusion: Canary-1B-v2 achieves high performance in ASR and AST with improved speed, and Parakeet-TDT-0.6B-v3 provides a compact alternative.

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [35] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

TL;DR: CS-FLEURS: A new dataset for code-switched speech recognition and translation, covering 113 language pairs across 52 languages.


<details>
  <summary>Details</summary>
Motivation: To develop and evaluate code-switched speech recognition and translation systems beyond high-resourced languages.

Method: The dataset includes 4 test sets: real voices reading synthetic sentences, generative text-to-speech, and concatenative text-to-speech. Also includes a training set with generative text-to-speech data.

Result: The dataset comprises 4 test sets with 113 code-switched language pairs and a 128-hour training set.

Conclusion: CS-FLEURS aims to broaden the scope of future code-switched speech research.

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


### [36] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

TL;DR: 本文提出了一种新的基准测试方法AssoCiAm，用于评估多模态大型语言模型（MLLM）的联想能力，同时解决联想任务中固有的歧义性问题。


<details>
  <summary>Details</summary>
Motivation: 评估多模态大型语言模型（MLLM）的创造力，特别是其联想能力，是通向通用人工智能（AGI）的重要一步。现有的评估框架忽略了联想任务中固有的歧义性，导致评估结果不可靠。

Method: 将歧义性分解为内部歧义和外部歧义，并设计了一种混合计算方法，以规避歧义性。

Result: 实验表明，认知和联想之间存在很强的正相关关系。此外，评估过程中的歧义性会导致MLLM的行为变得更加随机。

Conclusion: 本文提出的方法能够更准确、更可靠地评估MLLM的联想能力。

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [37] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架，将金融知识与行为金融研究相结合，为端到端顾问构建监督数据，并在此基础上对Qwen-3-8B模型进行微调。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在个人理财任务中维护成本高，收益低。

Method: 本文构建了一个包含19k样本的推理数据集，并对Qwen-3-8B模型进行了微调。

Result: 本文提出的8B模型在事实准确性、流畅性和个性化指标上，达到了与更大的基线模型（14-32B参数）相当的性能，同时成本降低了80%。

Conclusion: 通过仔细的数据管理和行为整合，小模型也能在个人理财建议方面取得优异表现。

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [38] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

TL;DR: 该论文利用大型语言模型分析了英国议会和美国国会中关于移民的讨论，时间跨度超过75年。


<details>
  <summary>Details</summary>
Motivation: 研究移民相关讨论在政治领域的演变和不同政治立场的差异。

Method: 使用开放权重的大型语言模型标注政治立场，并提取细粒度的叙事框架。

Result: 美国的讨论日益两极分化，而英国议会的态度相对一致，但工党和保守党之间存在意识形态差距。英国的叙事框架转向关注边境控制和非法移民等安全化叙事。

Conclusion: 大型语言模型可以支持政治和历史背景下可扩展的细粒度话语分析。

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [39] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

TL;DR: Apertus is a suite of open LLMs addressing data compliance and multilingual representation.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the lack of data compliance and limited multilingual representation in current open LLMs.

Method: The models are pretrained on openly available data, respecting robots.txt and filtering harmful content. The Goldfish objective is used to mitigate memorization. Training is done on 15T tokens from 1800+ languages, with 40% non-English content.

Result: Apertus models achieve state-of-the-art results among fully open models on multilingual benchmarks.

Conclusion: The paper releases Apertus models (8B and 70B scales) and all development artifacts with a permissive license for transparent audit and extension.

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [40] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 本文提出了一种证据检索机制，用于不确定性感知决策，该机制用证据条件下的实例自适应准则取代了单一的全局截止。


<details>
  <summary>Details</summary>
Motivation: 传统的全局截止方法在不确定性感知决策中存在局限性，缺乏透明性和可解释性。

Method: 该方法在嵌入空间中检索近端样本，并通过Dempster-Shafer理论融合它们的预测分布。由此产生的融合信念充当每个实例的阈值机制。

Result: 在具有BiT和ViT骨干网络的CIFAR-10/100上的实验表明，与应用于预测熵的阈值相比，该方法具有更高或相当的不确定性感知性能，同时显著减少了错误的结果，并实现了可持续的审查。

Conclusion: 证据条件标记为操作性不确定性感知决策提供了比固定预测熵阈值更可靠和可解释的替代方案。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [41] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在准确率、训练效率和参数可扩展性方面具有优势，尤其是在复杂的视觉任务中。


<details>
  <summary>Details</summary>
Motivation: 评估混合量子-经典神经网络和纯经典模型在性能、效率和鲁棒性方面的表现。

Method: 将参数化的量子电路与经典深度学习架构集成，并使用传统的卷积神经网络（CNN）作为经典对应物。在每个数据集上进行超过 50 个训练 epoch 的实验，并评估验证准确率、测试准确率、训练时间、计算资源使用和对抗鲁棒性。

Result: 混合模型在最终准确率上始终优于经典模型，在 MNIST、CIFAR100 和 STL10 上的验证准确率分别为 99.38%、41.69% 和 74.05%，而经典基准分别为 98.21%、32.25% 和 63.76%。混合模型还能以 5-12 倍的速度进行训练，并使用更少的参数，同时保持对未见测试数据的卓越泛化能力。在较简单的数据集上，混合模型也明显更具弹性。

Conclusion: 混合量子-经典架构在准确率、训练效率和参数可扩展性方面具有令人信服的优势，尤其是在复杂的视觉任务中。

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [42] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 本文提出了一种利用地球观测卫星图像对检测亚马逊森林砍伐的方法，并使用视觉语义模型自动注释检测到的变化。


<details>
  <summary>Details</summary>
Motivation: 亚马逊森林砍伐对全球碳排放和生物多样性有重大影响。

Method: 利用深度学习技术比较同一区域不同日期的图像，识别森林覆盖的变化。提出了一种视觉语义模型，可以自动用相关关键词注释检测到的变化。

Result: 在亚马逊图像对数据集上评估了该方法，证明了其在检测森林砍伐和生成相关注释方面的有效性。

Conclusion: 该方法为监测和研究亚马逊森林砍伐的影响提供了一个有用的工具。

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [43] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: This paper proposes an integrated framework for expressway traffic congestion detection and prediction to improve travel efficiency and regional connectivity.


<details>
  <summary>Details</summary>
Motivation: Existing detection-prediction systems have flaws such as low vehicle perception accuracy and loss of long-sequence dependencies.

Method: The study optimizes YOLOv11 to YOLOv11-DIoU and DeepSort by fusing Mahalanobis and cosine distances for traffic flow perception. A GRU-Attention model is built for congestion warning.

Result: YOLOv11-DIoU achieved 95.7% mAP, DeepSort reached 93.8% MOTA. The GRU-Attention model achieved 99.7% test accuracy with time error <= 1 minute for 10-minute advance warnings.

Conclusion: The framework provides quantitative support for expressway congestion control and has promising intelligent transportation applications.

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [44] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 本文利用众包车载车队数据，研究了一个基于云的实时街边停车服务。


<details>
  <summary>Details</summary>
Motivation: 为了优化现有的停车服务质量，通过分析地面实况测试的自动化。

Method: 应用机器学习领域的图像模式识别方法，特别是卷积神经网络，以丰富数据库，并在分析过程的主要领域取代人工工程工作。

Result: 时间减少了高达99.58%的人力资源。

Conclusion: 讨论了总体改进，总结，并展望了分析自动化工具的未来发展和潜在应用。

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [45] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统性地分析了基于VLM的OOD检测，发现其优势和脆弱性。


<details>
  <summary>Details</summary>
Motivation: 研究界对VLM为何能有效进行zero-shot OOD检测、相比单模态方法的优势以及行为鲁棒性理解不足。

Method: 通过使用in-distribution (ID)和OOD提示，对基于VLM的OOD检测进行系统的实证分析。

Result: 1) 归纳了VLM嵌入空间中促进zero-shot OOD检测的关键操作属性。2) 量化了VLM相比单模态方法的优越性，归因于VLM利用丰富语义新颖性的能力。3) 揭示了VLM在鲁棒性方面的不对称性：对常见图像噪声具有弹性，但对提示语 phrasing 高度敏感。

Conclusion: 研究结果为开发更强大和可靠的未来设计提供了重要的、基于经验的指导，更深入地理解了基于VLM的OOD检测的优势和关键漏洞。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [46] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 本文提出了一种基于曲率的几何轮廓构建方法，用于评估数据表示的有效性。


<details>
  <summary>Details</summary>
Motivation: 利用最近发展的截面曲率抽象概念，为离散度量空间构建基于曲率的几何轮廓。

Method: 使用曲率概念捕捉点三元组与其他点之间的度量关系，构建曲率轮廓，并基于此提出了一种定量评估数据表示有效性的方法。

Result: 实验表明，基于曲率的分析可用于估计数据集的内在维度。

Conclusion: 利用该方法探索了经验网络的大尺度几何，并评估了降维技术的有效性。

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [47] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 本文利用机器学习和遥感技术分析了斐济纳迪2013年至2024年的土地利用和土地覆盖变化，旨在为土地覆盖/土地利用建模和变化检测提供技术支持。


<details>
  <summary>Details</summary>
Motivation: 斐济作为一个发展中国家，正面临快速的城市化，包括住房、道路和土木工程在内的大型开发项目随处可见。本研究旨在通过分析土地利用和土地覆盖变化，为该问题提供技术支持。

Method: 使用Landsat-8卫星图像，利用Google Earth Engine和k-means聚类生成土地覆盖地图，并使用卷积神经网络对所选区域的土地覆盖类型进行分类。

Result: 可视化了变化检测，突出了城市区域随时间的变化，以监测地图中的变化。

Conclusion: 本文利用机器学习和遥感技术对斐济纳迪的土地利用和土地覆盖变化进行了分析，为城市化背景下的土地管理和规划提供了技术参考。

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [48] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 本文提出了一种用于电力传输系统中实时异物入侵(FOI)检测和跟踪的三阶段框架。


<details>
  <summary>Details</summary>
Motivation: 为了在电力传输系统中进行实时异物入侵检测和跟踪。

Method: 该框架集成了：(1) 用于快速稳健的目标定位的YOLOv7分割模型，(2) 训练有三重损失的基于ConvNeXt的特征提取器，以生成有区分性的嵌入，以及(3) 一种特征辅助的IoU跟踪器，可确保在遮挡和运动下具有弹性的多目标跟踪。

Result: 在真实世界的监视和无人机视频数据集上的大量实验表明，该框架在各种FOI场景中具有很高的准确性和鲁棒性。此外，在NVIDIA Jetson设备上的硬件基准测试证实了该框架在实际边缘应用中的实用性和可扩展性。

Conclusion: 该系统支持增量更新，通过将先前未见过的对象的嵌入添加到参考数据库中，而无需模型重新训练。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [49] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: 提出了一个自动、可扩展和细粒度的评估框架 EdiVal-Agent，用于从以对象为中心的角度进行基于多轮指令的编辑。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑评估方法要么依赖于配对的参考图像（覆盖范围有限且存在偏差），要么仅仅依赖于 zero-shot 视觉-语言模型 (VLM)（其基于提示的指令遵循、内容一致性和视觉质量评估通常不精确）。

Method: EdiVal-Agent 首先将图像分解为语义上有意义的对象，然后合成多样化的、上下文感知的编辑指令。在评估方面，它集成了 VLM 和开放词汇对象检测器来评估指令的执行情况，使用语义级别的特征提取器来评估内容一致性，并利用人类偏好模型来判断视觉质量。

Result: 将 VLM 与对象检测器相结合，在指令执行评估方面，与单独使用 VLM 和基于 CLIP 的指标相比，与人类判断具有更强的一致性。此外，pipeline 的模块化设计允许未来工具的无缝集成，从而随着时间的推移提高评估准确性。

Conclusion: EdiVal-Agent 可用于识别现有的失败模式，从而为下一代编辑模型的开发提供信息。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [50] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything: a unified transformer-based model for 3D scene geometry and camera regression.


<details>
  <summary>Details</summary>
Motivation: Addresses a range of 3D vision tasks with a single model.

Method: Transformer-based feed-forward model ingests images and geometric inputs, regressing 3D scene geometry and cameras using a factored representation of multi-view scene geometry.

Result: Outperforms or matches specialist feed-forward models.

Conclusion: Demonstrates potential as a universal 3D reconstruction backbone.

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [51] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出了一种名为语义增强跨模态地点识别 (SCM-PR) 的框架，该框架结合了高级语义，利用 RGB 图像在 LiDAR 地图中实现稳健的定位。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 RGB 的方法对光照、天气和其他季节性变化敏感。现有的跨模态定位方法利用 RGB 图像和 3D LiDAR 地图的几何属性来减少上述敏感性问题。目前，最先进的方法在复杂场景、细粒度或高分辨率匹配以及视点可能发生变化的情况下表现不佳。

Method: VMamba 主干网络用于 RGB 图像的特征提取；语义感知特征融合 (SAFF) 模块用于使用地点描述符和分割掩码；LiDAR 描述符结合了语义和几何；NetVLAD 中的跨模态语义注意机制用于改进匹配。结合语义信息对于设计多视图语义-几何匹配和语义一致性损失也至关重要，两者都在对比学习框架中。

Result: 在 KITTI 和 KITTI-360 数据集上的实验结果表明，与其他跨模态地点识别方法相比，SCM-PR 实现了最先进的性能。

Conclusion: SCM-PR 是一种有效的跨模态地点识别方法。

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [52] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为场景自适应格型向量量化（SALVQ）的3D高斯溅射（3DGS）压缩方法，旨在提高压缩效率并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的基于锚点的神经压缩方法依赖于均匀标量量化（USQ），而更复杂的量化器是否能以极小的额外开销改进3DGS压缩方法是一个有待探索的问题。

Method: 通过用格型向量量化（LVQ）代替USQ，并针对每个场景优化格型基，提高LVQ的适应性和R-D效率。

Result: SALVQ可以无缝集成到现有的3DGS压缩架构中，以最小的修改和计算开销提高其R-D性能。通过缩放格型基向量，SALVQ可以动态调整格型密度，从而使单个模型可以适应多个比特率目标。

Conclusion: SALVQ在向量量化的R-D效率和USQ的低复杂度之间取得了平衡，并且能够减少训练时间和内存消耗，因为它不需要为不同的压缩级别训练单独的模型。

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [53] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 本文介绍了一个社交群体区域检测任务，旨在理解公共空间中群体层面的社交互动。


<details>
  <summary>Details</summary>
Motivation: 理解公共空间中的群体层面社交互动对城市规划至关重要，可以为设计充满活力和包容性的社交环境提供信息。从图像中检测此类互动需要解释微妙的视觉线索，例如关系、接近度和共同运动——这些在语义上很复杂的信号超出了传统的对象检测范围。

Method: 本文提出了一个名为 MINGLE（Modeling INterpersonal Group-Level Engagement）的模块化三阶段流程，该流程集成了：（1）现成的人体检测和深度估计，（2）基于 VLM 的推理以对成对社交关系进行分类，以及（3）一种轻量级空间聚合算法来定位具有社交联系的群体。

Result: 本文提出了一个新的包含 10 万张城市街景图像的数据集，该数据集带有个人和社交互动群体的边界框和标签，以支持这项任务并鼓励未来的研究。

Conclusion: 本文结合人工创建的标签和 MINGLE 流程的输出，确保了语义丰富性和对现实世界场景的广泛覆盖。

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [54] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: 本文介绍了一种名为 BiasMap 的模型无关框架，用于发现 stable diffusion 模型中潜在的概念级表征偏差。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在输出层面的人口分布，并不能保证概念表征在缓解后能够解耦。

Method: BiasMap 利用交叉注意力归因图来揭示人口统计信息（例如，性别、种族）和语义（例如，职业）之间的结构性纠缠，从而深入研究图像生成过程中的表征偏差。使用这些概念的归因图，我们通过 Intersection over Union (IoU) 量化空间人口统计-语义概念纠缠。

Result: 研究结果表明，现有的公平性干预措施可能会缩小输出分布差距，但通常无法解开概念层面的耦合，而我们的缓解方法可以缓解图像生成中的概念纠缠，同时补充分布偏差缓解。

Conclusion: 我们的缓解方法可以缓解图像生成中的概念纠缠，同时补充分布偏差缓解。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [55] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePixel是一个Python GUI，可以集成成像系统，以实现实时图像注释。


<details>
  <summary>Details</summary>
Motivation: 缺乏灵活的注释工具阻碍了人工智能模型在某些科学领域的部署。大多数现有的图像注释软件需要用户上传预先收集的数据集，这限制了对按需管道的支持，并引入了不必要的图像获取步骤。

Method: LivePixel集成了网络摄像头、显微镜等成像系统，以实现实时图像注释。它通过一个简单的界面设计得易于使用，允许用户使用商业图形编辑软件中常见的工具精确地划分注释区域。特别值得一提的是Bézier样条和二进制掩码的可用性，以及该软件使用非破坏性图层实现高性能编辑的能力。LivePixel还集成了广泛的视频设备兼容性，并通过使用OpenCV结合旨在通过Numpy有效处理矩阵和线性代数运算的高性能库，针对对象检测操作进行了优化。

Result: LivePixel 促进了无缝数据收集和标记，加速了实验工作流程中人工智能模型的开发。

Conclusion: LivePixel可在https://github.com/UGarCil/LivePyxel免费获取

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [56] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 本研究提出了一种名为DEFT-VTON的高效虚拟试穿（VTO）方法，该方法通过Doob's h-transform高效微调（DEFT）和自适应一致性损失，在有限的训练和推理预算下，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VTO方法需要对大型预训练模型进行广泛的端到端训练，但在实际应用中，VTO的训练、推理和服务部署预算通常有限。

Method: 该方法首先利用DEFT，通过训练一个小的h-transform网络来适应大型预训练的无条件模型，从而实现图像条件VTO能力。然后，提出一种自适应一致性损失，以进一步提高DEFT的性能并减少现有模型的推理时间。该方法以数据自适应的方式结合一致性损失和去噪分数匹配损失，以低成本微调现有VTO模型。

Result: 实验结果表明，所提出的DEFT-VTON方法在VTO任务上取得了最先进的性能，仅需15个去噪步骤，同时保持了具有竞争力的结果。

Conclusion: DEFT-VTON方法能够在有限的资源下实现高效且高质量的虚拟试穿，具有很大的应用潜力。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [57] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 本研究利用数据增强生成包含弱势道路使用者（VRU）的自定义交通场景，以改善行人识别。


<details>
  <summary>Details</summary>
Motivation: 合成数据对于自动驾驶至关重要，但存在与真实数据的领域差距。本文旨在解决这个问题。

Method: 使用数据增强技术，通过虚拟行人来增强Cityscapes数据集。提出了一种新的生成网络结构，用于对抗学习数据集的光照条件，以提高增强的真实感。

Result: 在语义和实例分割任务上评估了该方法。

Conclusion: 通过数据增强和对抗学习光照条件，可以有效提高行人识别的性能。

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [58] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了一种新的可解释的神经网络框架FunKAN，专门为图像处理设计，将Kolmogorov-Arnold表示定理推广到功能空间，并使用基于Hermite函数的傅里叶分解学习内部函数。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法依赖于复杂的架构，可解释性有限。Kolmogorov-Arnold网络虽然提供了可解释的解决方案，但它们对扁平化特征表示的依赖从根本上破坏了成像数据的内在空间结构。

Method: 提出了Functional Kolmogorov-Arnold Network (FunKAN)，并使用傅里叶分解学习内部函数。同时提出了U-FunKAN作为最先进的二元医学分割模型。

Result: 在多个医学图像处理任务上进行了探索，包括磁共振图像中的吉布斯振铃抑制，并在IXI数据集上进行了基准测试。还提出了U-FunKAN，并在三个医学数据集上进行了基准测试：BUSI（超声图像）、GlaS（组织学结构）和CVC-ClinicDB（结肠镜视频），分别用于检测乳腺癌、腺体和息肉。实验表明，该方法在医学图像增强和分割方面均优于其他基于KAN的骨干网络。

Conclusion: 该研究弥合了理论函数逼近和医学图像分析之间的差距，为临床应用提供了一个稳健、可解释的解决方案。

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [59] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出了一种新的多模态双流图神经网络模型，用于检测仇恨视频，该模型通过分离视频实例并分配权重来突出显示仇恨内容。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态方法忽略了即使最少的仇恨内容也能定义视频的类别，并且无法系统地捕获视频中的结构化信息，从而限制了多模态融合的有效性。

Method: 构建实例图，将给定的视频分成多个实例以提取实例级特征。然后，互补权重图为这些特征分配重要性权重，突出显示仇恨实例。重要性权重和实例特征被组合以生成视频标签。

Result: 在公共数据集上的大量实验表明，该模型在仇恨视频分类方面是最先进的，并且具有很强的可解释性。

Conclusion: 该模型通过基于图的框架系统地建模了模态内部和跨模态的结构化关系，从而提高了仇恨视频检测的准确性和可解释性。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [60] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个用于结肠镜视频的基于扩散的深度估计模型，它可以生成时间上一致的深度图。


<details>
  <summary>Details</summary>
Motivation: 现有的内窥镜深度估计模型在视频序列中的时间一致性方面存在问题，限制了它们在 3D 重建中的应用。

Method: 该方法从合成结肠镜序列中学习鲁棒的几何先验，以生成时间上一致的深度图。此外，还引入了一种风格迁移技术，可以在保留几何结构的同时，调整真实的临床视频以匹配合成训练域。

Result: ColonCrafter 在 C3VD 数据集上实现了最先进的零样本性能，优于通用方法和内窥镜特定方法。

Conclusion: ColonCrafter 在 3D 点云生成和表面覆盖评估等临床相关应用中表现出良好的性能，但完整的轨迹 3D 重建仍然是一个挑战。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [61] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 本研究针对嵌入式平台（如微型飞行器 MAVs）上 3D 高斯溅射（3DGS）的应用，旨在提高渲染质量的同时降低 GPU 内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前 3DGS 研究主要集中在使用高性能桌面 GPU 提高渲染性能和重建质量，忽略了嵌入式平台上的应用，这些平台面临计算资源和内存限制。

Method: 提出了一种基于几何相似性的体素空间合并方法，以减少 SLAM 中冗余的 3D 高斯图元，并通过 Patch-Grid (PG) 点采样初始化 3D 高斯图元来提高渲染质量。

Result: 在公开数据集上的定量和定性评估表明了改进的有效性。

Conclusion: 该研究在不影响系统运行时性能的情况下，显著降低了 GPU 内存使用，并提高了渲染质量，为 3DGS 在资源受限平台上的应用铺平了道路。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [62] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 本文提出了一种新的轨迹预测框架，该框架引入了自适应机制，以在复杂的驾驶环境中实现稳健的检测，通过显式建模误差模式，该方法在检测延迟和误报率方面都取得了显着改进。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆 (AV) 的安全和无缝运行，然而，在部署中，预测模型不可避免地面临训练数据和实际条件之间的分布偏移，其中罕见或代表性不足的交通场景会导致分布外 (OOD) 情况。以往的 AV OOD 检测研究主要集中在对象检测和分割等计算机视觉任务上，轨迹级别的 OOD 检测在很大程度上仍未得到探索。

Method: 建立在此基础之上，我们提出了一个新的框架，该框架引入了自适应机制，以在复杂的驾驶环境中实现稳健的检测。通过显式建模这些误差模式

Result: 我们的方法在检测延迟和误报率方面都取得了显着改进。在已建立的轨迹预测基准上的综合实验表明，我们的框架在准确性和计算效率方面均显着优于以前的基于 UQ 和基于视觉的 OOD 方法

Conclusion: 提供了一条通往可靠的、具有驾驶意识的自主性的实用途径。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [63] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 本文提出了一个智能多模态框架，利用视觉语言模型(vlm)进行医学图像分析，以实现自动肿瘤检测和临床报告生成。


<details>
  <summary>Details</summary>
Motivation: 利用人工智能(AI)在医疗成像领域的快速发展来改进诊断医学和临床决策过程。

Method: 该框架集成了谷歌Gemini 2.5 Flash，用于跨多种成像模式(包括CT、MRI、x射线和超声)的自动肿瘤检测和临床报告生成。该系统结合了视觉特征提取和自然语言处理，以实现上下文图像解释，结合坐标验证机制和概率高斯建模的异常分布。

Result: 实验评估表明，该系统在跨多种模式的异常检测中表现出高性能。定位测量达到80像素的平均偏差。

Conclusion: 该框架代表了自动化诊断支持和放射工作流程效率的显著进步，但在广泛采用之前，有必要进行临床验证和多中心评估。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [64] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法在RoboCup 2024比赛中获得冠军，它通过聚类抑制噪声，抵抗错误的特征匹配，本文将CLAP扩展到3D定位和图像拼接，并展示了CLAP、RANSAC和Hough变换之间的关系。


<details>
  <summary>Details</summary>
Motivation: 先前的工作中，我们介绍了一种名为CLAP的2D定位算法，该算法在RoboCup 2024国际自主人形机器人足球比赛中获得了冠军。CLAP特别因其对异常值的鲁棒性而受到认可，其中采用聚类来抑制噪声并减轻错误的特征匹配。

Method: 将CLAP扩展到2D定位之外的更通用框架，特别是3D定位和图像拼接。

Result: 展示了CLAP、RANSAC和Hough变换是如何相关的。

Conclusion: CLAP的推广广泛适用于许多不同的领域，并且可以成为处理噪声和不确定性的有用工具。

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [65] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR: 利用 SAM 增强特征提取的医学图像配准框架，在 cardiac 和 abdomen 数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督方法依赖不易获得的弱标签，而视觉基础模型具有强大的表征学习能力。

Method: 利用 SAM 的图像编码器提取结构感知特征嵌入，设计轻量级 3D head 细化特征，并引入分层特征一致性损失。

Result: 在 ACDC 和 abdomen 数据集上分别实现了 2.68% 和 6.44% 的性能提升，显著优于现有方法。

Conclusion: SAMIR 是一种有效的医学图像配准框架，利用 SAM 提升了特征提取能力，并在 cardiac 和 abdomen 数据集上取得了优异的性能。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [66] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 本文提出了一种新的分布式方法，使用联邦学习（FL）识别卫星图像中的森林砍伐。


<details>
  <summary>Details</summary>
Motivation: 从卫星图像中准确识别森林砍伐对于了解一个区域的地理状况至关重要。集中式训练方法需要合并数据，从而损害客户的数据安全。

Method: 该框架利用 FLOWER 框架和 RAY 框架来执行分布式学习工作负载。FL 框架使用 YOLOS-small、Faster R-CNN with a ResNet50 backbone, 和 Faster R-CNN with a MobileNetV3 backbone 模型，这些模型在公开可用的数据集上进行训练和测试。

Result: 该方法为基于卫星图像的图像分割任务提供了一个不同的视角。

Conclusion: 联邦学习能够在维护活跃用户的数据隐私和安全的同时，使分布式网络客户端能够协作训练模型。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [67] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS: A training-free framework for metric relative camera pose estimation.


<details>
  <summary>Details</summary>
Motivation: Conventional two-view pose estimation methods are not metric and struggle with wide baselines and textureless or reflective surfaces.

Method: Direct alignment of two independently reconstructed 3D scenes using a metric monocular depth estimator and a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model (GMM) for each image. Refines an initial pose by optimising a differentiable GMM alignment objective.

Result: GARPS outperforms both classical and state-of-the-art learning-based methods on the Real-Estate10K dataset.

Conclusion: Bridging single-view perception with multi-view geometry can achieve robust and metric relative pose estimation.

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [68] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的神经网络构建方法，使用查找表操作代替传统的乘法操作，以降低计算复杂度和提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决卷积神经网络计算量大、能耗高的问题，尤其是在移动设备上的部署难题。

Method: 通过可微的方式构建查找表，并提出多种训练策略以促进收敛，从而实现端到端优化。

Result: 在图像分类、图像超分辨率和点云分类任务中，查找网络在能耗和推理速度方面表现出更高的效率，同时保持了与传统卷积网络相当的性能。

Conclusion: 查找网络在不同任务和数据类型上都取得了state-of-the-art的性能，证明了该方法的有效性。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [69] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 提出了一种新的语义视觉投影器，通过压缩和投影语义超像素作为视觉 tokens，自适应地缩短 token 序列，同时最小化语义损失。


<details>
  <summary>Details</summary>
Motivation: 将 MLLM 应用于分割计算量大，主要是由于视觉 token 冗余。传统的 patch-wise 视觉投影器难以在减少视觉 token 数量和保持语义清晰度之间取得平衡。

Method: 利用 SAM 生成的语义超像素来识别图像中的“视觉单词”，并提出了语义超像素位置嵌入和语义超像素聚合器。

Result: 在不影响性能的情况下，减少了 93% 的视觉 tokens，显著加快了 MLLM 的训练和推理，并在 RIS 上优于现有的压缩视觉投影器。

Conclusion: 该方法有效地减少了视觉 tokens，同时保持了性能，为 MLLM 在图像分割领域的应用提供了新的思路。

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [70] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV: A new BEV segmentation framework for fisheye cameras.


<details>
  <summary>Details</summary>
Motivation: Existing BEV segmentation methods don't work well with fisheye cameras due to distortion and other issues.

Method: Introduces a Distortion-Resilient Multi-scale Extraction (DRME) backbone, an Uncertainty-aware Spatial Cross-Attention (U-SCA) mechanism, and a Distance-aware Temporal Self-Attention (D-TSA) module.

Result: Outperforms SOTA baselines on the Synwoodscapes dataset.

Conclusion: FishBEV is effective for surround-view fisheye BEV segmentation tasks.

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [71] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: This paper introduces spline-based Kolmogorov-Arnold Networks (KANs) for medical image classification, achieving high accuracy with limited data and interpretability.


<details>
  <summary>Details</summary>
Motivation: Effective and interpretable medical image classification is challenging, especially in resource-limited settings.

Method: The study uses SBTAYLOR-KAN, SBRBF-KAN, and SBWAVELET-KAN, leveraging spline-based function approximation.

Result: SBTAYLOR-KAN achieved up to 98.93% accuracy with significantly fewer parameters than CNNs and strong generalization across datasets.

Conclusion: The framework provides a lightweight, interpretable, and generalizable solution for medical image classification in data-scarce clinical environments.

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [72] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 提出了StyleProtect，一种轻量级的防御策略，通过更新选择的交叉注意力层，有效地防御针对微调扩散模型的风格模仿。


<details>
  <summary>Details</summary>
Motivation: 通用扩散模型可以轻松模仿艺术风格，而微调会放大这种能力，使得模型能够以更高的保真度和控制力内化和重现风格。这导致了对保护艺术品免受风格模仿方法的需求。

Method: 通过测量注意力层对风格和内容表示的激活强度，并评估它们与从外部模型提取的特征的相关性，来确定对艺术风格高度敏感的交叉注意力层。然后，只更新这些选定的交叉注意力层。

Result: StyleProtect在保护艺术品和动漫的独特风格免受恶意扩散定制方面表现出良好的性能，同时保持了有竞争力的不可察觉性。

Conclusion: StyleProtect是一种有效的风格防御策略，可以防止微调的扩散模型恶意模仿艺术风格。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [73] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: 提出了一种名为UM-Depth的自监督单目深度估计框架，该框架结合了运动和不确定性感知细化，以提高动态对象边界和无纹理区域的深度精度。


<details>
  <summary>Details</summary>
Motivation: 自监督单目深度估计方法在处理低纹理或动态区域等输入数据的不确定性时，深度精度会降低。

Method: 开发了一种教师-学生训练策略，该策略将不确定性估计嵌入到训练流程和网络架构中，从而加强了光度信号较弱区域的监督；该方法仅在训练期间在教师网络中使用光流，无需额外的标签和运行时成本。

Result: 在KITTI和Cityscapes数据集上的大量实验表明，该方法的不确定性感知细化是有效的；UM-Depth在KITTI数据集上的自监督深度和姿态估计方面取得了最先进的结果。

Conclusion: UM-Depth框架通过结合运动和不确定性感知细化，有效提高了自监督单目深度估计的精度，并在KITTI数据集上取得了state-of-the-art的结果。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [74] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: 本文提出了一种名为三重查询Transformer (TQF) 的新方法，用于解决指代视频对象分割 (RVOS) 中的查询选择偏差问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的方法容易受到外观或运动相似的干扰因素的误导，导致查询选择偏差。

Method: 该方法将指代查询分解为三个专门的组件：用于静态属性的外观查询、用于空间关系的帧内交互查询和用于时间关联的帧间运动查询。此外，还引入了两个运动感知聚合模块，以增强对象token表示。

Result: 在多个RVOS基准上的大量实验表明了TQF的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: TQF方法有效地解决了RVOS中的查询选择偏差问题，并在多个基准测试中取得了优异的性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [75] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG 是一个多任务通用视觉基础框架，它利用实例查询来统一实例级框和mask的联合和一致性预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常独立处理GREC和GRES任务，忽略了联合训练的好处，并且通常将GRES视为语义分割任务，忽略了实例感知能力的关键作用。

Method: 提出 InstanceVG，一种具有实例感知能力的多任务通用视觉基础框架，它利用实例查询来统一实例级框和mask的联合和一致性预测。为每个实例查询分配一个先验参考点，作为目标匹配的附加基础。这有利于同一点、框和mask的一致性预测。

Result: 在跨四个任务的十个数据集上进行的大量实验表明，InstanceVG 实现了最先进的性能，在各种评估指标上显着超越了现有方法。

Conclusion: InstanceVG 是第一个同时处理 GREC 和 GRES，同时将实例感知能力融入通用视觉基础的框架。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [76] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文提出了一种跨模态全文精细对齐框架（FMFA），用于文本到图像的行人检索（TIPR）任务，通过显式精细对齐和隐式关系推理来增强全局匹配。


<details>
  <summary>Details</summary>
Motivation: 现有的TIPR方法缺乏验证局部特征是否正确对齐的能力，并且主要关注难负样本，忽略了错误匹配的正样本对。

Method: 提出了自适应相似度分布匹配（A-SDM）模块来校正不匹配的正样本对，并引入了显式精细对齐（EFA）模块来加强显式跨模态精细交互。

Result: 在三个公共数据集上进行了评估，实现了最先进的性能。

Conclusion: FMFA框架通过显式和隐式对齐方式，有效提升了文本到图像行人检索的性能。

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [77] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 提出了一种颜色映射模块，用于精确控制文本驱动图像编辑中的颜色，实现更精细、连续和可控的颜色编辑。


<details>
  <summary>Details</summary>
Motivation: 由于自然语言的模糊性和离散性，颜色编辑面临精度不足和难以实现连续控制的挑战。线性插值嵌入向量无法精确控制颜色变化范围，且插值系数与图像颜色关系未知。

Method: 引入颜色映射模块，显式建模文本嵌入空间和图像RGB值之间的对应关系，通过预测给定RGB值对应的嵌入向量来实现精确颜色控制。

Result: 实验结果表明，该方法在颜色连续性和可控性方面表现良好。

Conclusion: 该方法能够生成具有连续颜色变化的图像，实现更精细、连续和可控的颜色编辑。

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [78] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出了一种迭代提示细化算法，该算法使用视觉语言模型（VLM）来分析输入提示和生成的图像，从而更有效地细化提示，提高安全性，同时保持用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有的安全方法通常使用大型语言模型（LLM）来改进提示，但它们忽略了生成的图像，这可能导致不安全的输出或对已经安全的提示进行不必要的更改。

Method: 提出了一种迭代提示细化算法，该算法使用视觉语言模型（VLM）来分析输入提示和生成的图像。此外，我们引入了一个新的数据集，该数据集使用现成的多模态LLM标记了文本和视觉安全信号，从而实现了有监督的微调。

Result: 实验结果表明，我们的方法可以在不影响与用户意图对齐的情况下产生更安全的输出，从而为生成更安全的T2I内容提供了一个实用的解决方案。

Conclusion: 该论文提出了一种利用视觉反馈迭代优化文本到图像生成提示的方法，提高了生成图像的安全性，同时保持了用户意图。

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [79] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种紧凑的RAW到RGB框架，名为TA-ISP，它产生面向任务的表示，用于预训练的视觉模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临两个关键限制：大规模ISP网络带来繁重的计算开销，而基于调整传统ISP管道的方法受到有限的表示能力的限制。

Method: TA-ISP预测一小组轻量级的多尺度调制算子，这些算子在全球、区域和像素尺度上操作，以重塑不同空间范围内的图像统计。

Result: 在白天和夜间条件下，在几个RAW域检测和分割基准上进行评估，TA-ISP始终提高下游精度，同时显着减少参数数量和推理时间。

Conclusion: TA-ISP非常适合部署在资源受限的设备上。

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [80] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的夜间图像去雨方法，名为NDLPNet，它能有效去除夜间低光照条件下的雨条纹，同时保护重要的背景信息。该论文还构建了一个新的夜间雨景数据集（NSR），并证明了该方法在夜间去雨任务中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 夜间低光照条件下的雨条纹会导致视觉退化，影响夜间监控和自动导航的性能。现有的去雨技术主要为白天条件设计，在夜间光照下表现不佳。

Method: 该论文提出了一种新的夜间去雨网络NDLPNet，它使用位置感知模块（PPM）来捕获和利用输入数据的空间上下文信息，增强模型识别和重新校准不同特征通道重要性的能力。

Result: 在现有数据集和新的NSR数据集上的大量定性和定量实验评估表明，该方法在夜间去雨任务中优于现有技术。

Conclusion: 该论文提出了一种有效的夜间图像去雨方法，并在新的夜间雨景数据集上验证了其优越性。

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [81] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: 本文提出了一种名为 VocSegMRI 的多模态框架，该框架集成了视频、音频和音韵输入，通过交叉注意力融合进行动态特征对齐，用于准确分割实时磁共振成像 (rtMRI) 中的发音结构。


<details>
  <summary>Details</summary>
Motivation: 现有的方法几乎完全依赖于视觉线索，而同步的声学和音韵信号提供补充上下文，可以丰富视觉信息并提高精度。因此，动机是整合多种模态的信息以提高分割精度。

Method: 该方法通过交叉注意力融合整合视频、音频和音韵输入，并结合对比学习目标来增强跨模态表示。

Result: 在 USC-75 rtMRI 数据集的一个子集上进行评估，该方法实现了最先进的性能，Dice 系数为 0.95，95% Hausdorff 距离 (HD_95) 为 4.20 毫米，优于单模态和多模态基线。

Conclusion: 结果表明，整合多模态建模对于准确的声道分析具有重要价值。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [82] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 提出了一种新的生成编码框架，利用扩散先验来提高低比特率下的压缩性能。


<details>
  <summary>Details</summary>
Motivation: 传统的编解码器和学习方法难以在高压缩比下保持主观质量，而现有的生成方法在视觉保真度和泛化方面面临挑战。

Method: 利用预优化的编码器生成通用压缩域表示，通过轻量级适配器和注意力融合模块与预训练模型的内部特征集成。引入分布重新归一化方法以进一步提高重建保真度。

Result: 在低比特率下，该方法在视觉保真度方面优于现有方法，与H.266/VVC相比，压缩性能提高了高达79%。

Conclusion: 该方法为AI生成内容提供了一种有效的解决方案，同时适用于更广泛的内容类型。

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [83] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: 提出了一种新的VLA框架AdaThinkDrive，该框架具有受快速和慢速思维启发的双模推理机制，通过选择性地应用CoT来平衡准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的CoT推理集成在简单场景中效果不佳，引入了不必要的计算开销，而没有提高决策质量。

Method: 该框架首先使用问答和轨迹数据集在大型自动驾驶场景上进行预训练，以获取世界知识和驾驶常识。在监督微调期间，引入了一个双模数据集，即快速回答（无CoT）和慢速思考（有CoT），使模型能够区分需要推理的场景。此外，结合群体相对策略优化（GRPO）提出了一种自适应思考奖励策略，该策略通过比较不同推理模式下的轨迹质量来奖励模型选择性地应用CoT。

Result: 在Navsim基准测试中，AdaThinkDrive的PDMS达到了90.3，超过了最佳的仅视觉基线1.7个点。消融实验表明，AdaThinkDrive超过了从不思考和总是思考的基线，分别提高了PDMS 2.0和1.4。与总是思考的基线相比，它还将推理时间减少了14%，展示了其通过自适应推理平衡准确性和效率的能力。

Conclusion: AdaThinkDrive 能够通过自适应推理来平衡准确性和效率。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [84] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的deepfake检测方法，该方法可以精确定位被篡改的区域。


<details>
  <summary>Details</summary>
Motivation: 尽管基于分类的检测取得了显著进展，但准确定位伪造区域仍然是一个重大挑战。现有方法忽略了局部细节和全局语义上下文的互补性，并且局部和全局预测之间的融合策略不够好。

Method: 该方法独立地使用局部和全局视角预测被操纵的区域，并采用形态学操作来融合输出，从而有效地抑制噪声，同时增强空间连贯性。

Result: 大量的实验表明，每个模块都能有效提高伪造定位的准确性和鲁棒性。

Conclusion: 该方法能够有效地提高deepfake检测的精度和鲁棒性。

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [85] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 提出了一种新的架构，Variable-Rate Spatial Event Mamba，它可以直接处理原始事件流而无需中间表示。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常将事件流转换为中间表示，例如帧、体素网格或点云，这不可避免地需要预定义的时间窗口，从而引入窗口延迟。同时，逐点检测方法由于其高计算成本而面临阻止实时效率的计算挑战。

Method: 该方法引入了一个轻量级的因果空间邻域编码器来有效地捕获局部几何关系，然后是基于 Mamba 的状态空间模型，用于具有线性复杂度的可扩展时间建模。在推理过程中，控制器根据事件速率自适应地调整处理速度，从而在窗口延迟和推理延迟之间实现最佳平衡。

Result: 实现了窗口延迟和推理延迟之间的最佳平衡。

Conclusion: Variable-Rate Spatial Event Mamba 是一种可以直接处理原始事件流的新架构，无需中间表示，并且在窗口延迟和推理延迟之间实现了最佳平衡。

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [86] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 大型视觉语言模型中的对象幻觉严重阻碍了它们的实际应用。本文研究了不同视觉编码器的训练范式如何影响幻觉表现，并构建了一个名为 VHBench-10 的基准来评估模型在十个细粒度幻觉类别上的表现。提出了 VisionWeaver，一种上下文感知路由网络，通过动态聚合来自多个专家视觉特征来减少幻觉并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型 (LVLM) 中的对象幻觉显著阻碍了它们的实际应用。准确解释视觉信息的主要组成部分是视觉编码器的选择。

Method: 提出了 VisionWeaver，一种上下文感知路由网络，利用全局视觉特征生成路由信号，动态聚合来自多个专门专家的视觉特征。

Result: 综合实验证实了 VisionWeaver 在显著减少幻觉和提高整体模型性能方面的有效性。

Conclusion: 不同的编码器表现出独特的幻觉特征。VisionWeaver 有效地减少幻觉并提高整体模型性能。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [87] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: 提出了Block-Wise Caching (BWCache)，一种加速DiT视频生成且不需训练的方法。


<details>
  <summary>Details</summary>
Motivation: DiT视频生成模型速度慢，现有加速方法会降低视觉质量或无法充分利用中间特征。

Method: 通过缓存和重用DiT blocks在不同diffusion timesteps的特征来加速，并引入相似性指标来决定何时重用特征。

Result: 在多个视频扩散模型上实现了高达2.24倍的加速，且视觉质量相当。

Conclusion: BWCache能有效加速DiT视频生成，同时保持视觉质量。

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [88] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 提出了一种用于航天器姿态估计 (SPE) 关键点回归的监督域自适应 (SDA) 框架，以解决合成数据到真实数据 domain gap 问题。


<details>
  <summary>Details</summary>
Motivation: 现有的混合 pipeline 在合成数据集上表现良好，但在真实图像上性能急剧下降。现有的无监督域自适应方法在少量标记目标样本可用时表现不佳。

Method: 构建在 Learning Invariant Representation and Risk (LIRR) 范例之上，该方法使用标记的合成数据和有限的标记真实数据联合优化领域不变表示和任务特定风险，从而减少领域转移下的泛化误差。

Result: 在 SPEED+ 基准测试中，该方法始终优于 source-only、微调和 oracle 基线。仅使用 5% 的标记目标数据，该方法就能达到或超过在更大比例的标记数据上训练的 oracle 性能。

Conclusion: 该框架是轻量级的、backbone-agnostic 的且计算效率高，为在真实空间环境中实现稳健且可部署的航天器姿态估计提供了一条可行的途径。

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [89] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 提出了一种新的基于视觉的无人机定位系统，该系统在大规模多高度飞行片段数据集（MAFS）上进行了评估，并在计算效率、定位精度和姿态估计速度方面取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于检索的方法在数据集可用性、实时性能、环境敏感性和泛化能力方面存在局限性，尤其是在动态或时变环境中。

Method: 提出了一种新颖的语义加权自适应粒子滤波（SWA-PF）方法，该方法集成了来自无人机图像和卫星图像的鲁棒语义特征，并通过语义加权机制和优化的粒子滤波架构来实现。

Result: 该方法在所提出的数据集上进行了评估，与特征提取方法相比，计算效率提高了10倍，保持了低于10米的全局定位误差，并能够在几秒钟内使用可访问的低分辨率卫星地图实现快速的4自由度（4-DoF）姿态估计。

Conclusion: 该研究提出了一种有效的无人机定位方法，该方法具有良好的计算效率、定位精度和姿态估计速度，并且在动态或时变环境中具有良好的泛化能力。

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [90] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的框架，用于提高视频大语言模型处理高帧率视频的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型在处理高帧率视频时，由于计算成本和冗余信息过多而表现不佳，尤其是在需要精确时间对齐的任务中。

Method: 论文提出了一种名为门控残差 Tokenization (GRT) 的两阶段框架，包括运动补偿帧间门控 Tokenization 和语义场景内 Tokenization 合并。

Result: 实验表明，GRT 在 DIVE 基准测试中优于现有的 VLLM 基线，并且随着 FPS 的增加，性能也会提高。

Conclusion: 研究结果表明，密集的时间信息非常重要，GRT 能够实现高效、可扩展的高 FPS 视频理解。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [91] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出了一种新的掩蔽特征建模（MFM）方法，用于语义分割的无监督域自适应（UDA），通过在特征空间中进行特征掩蔽和重建，提高分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督任务，特别是对比学习，已经提高了特征的可区分性，但是掩蔽建模方法在这种设置中仍然未被充分探索，这主要是由于架构不兼容和优化目标不一致。

Method: 提出 Masked Feature Modeling (MFM)，一种新颖的辅助任务，它直接在特征空间中执行特征屏蔽和重建。为了便于有效的重建，我们引入了一个轻量级的辅助模块 Rebuilder，该模块经过联合训练，但在推理过程中被丢弃，从而在测试时增加了零计算开销。MFM 利用分割解码器对重建的特征进行分类，将辅助目标与像素级预测任务紧密结合，以避免干扰主要任务。

Result: 在各种架构和 UDA 基准上的大量实验表明，MFM 始终可以提高分割性能，为无监督的领域自适应语义分割提供了一种简单、高效且通用的策略。

Conclusion: MFM 是一种简单、高效且通用的策略，可用于提高无监督领域自适应语义分割的性能。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [92] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 本研究探讨了高光谱图像像素光谱分类问题，着重关注仅使用光谱信息进行分类的优势。针对1D-Justo-LiuNet在训练数据有限时性能下降的问题， исследовали MiniROCKET и HDC-MiniROCKET для spectral классификации.


<details>
  <summary>Details</summary>
Motivation: 为了解决在训练数据有限的情况下，1D-Justo-LiuNet模型性能下降的问题。

Method:  исследовали MiniROCKET и HDC-MiniROCKET for spectral классификации。MiniROCKET无需训练参数即可提取精心设计的特征。

Result: MiniROCKET在数据有限的情况下优于1D-Justo-LiuNet，在一般情况下与之相当。

Conclusion: MiniROCKET在光谱分类中表现出色，特别是在训练数据有限的情况下，为未来的空间-光谱方法改进提供了潜力。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [93] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为Semi-MOE的半监督学习框架，用于解决组织病理图像分割中伪标签噪声的问题。


<details>
  <summary>Details</summary>
Motivation: 现有半监督组织病理图像分割方法在处理噪声伪标签时表现不佳，因为腺体边界模糊和形态学分类错误。

Method: 该方法利用多任务混合专家框架，包含一个主分割专家、一个有符号距离场回归专家和一个边界预测专家，并通过多门控伪标签模块动态聚合专家特征，实现稳健的伪标签融合和优化。此外，还提出了自适应多目标损失函数，以消除手动调整并动态平衡多个学习目标。

Result: 在GlaS和CRAG基准测试中，该方法在低标签设置下优于现有技术。

Conclusion: 基于MoE的架构在推进半监督分割方面具有潜力。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [94] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 这篇论文提出了一种自监督学习方法，称为一致性视图对齐（Consistent View Alignment），用于改进下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的表征学习方法通常假设数据点的不相关视图足以学习有意义的表征，但这项工作对此提出了质疑，认为有意义的潜在空间结构不会自然出现，而必须明确地诱导。

Method: 该方法通过对齐数据的不同视图的表征来对齐互补信息，而不会引起假阳性。

Result: 该方法在MICCAI 2025 SSL3D挑战赛中使用Primus vision transformer和ResEnc卷积神经网络分别获得了第一名和第二名。

Conclusion: 结构化的视图对齐在学习有效的表征方面起着关键作用。

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [95] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: 提出了一种名为SpecDiff的新型无训练多级特征缓存策略，通过引入未来信息克服了速度和准确性之间的权衡瓶颈，从而加速扩散模型的推理。


<details>
  <summary>Details</summary>
Motivation: 现有的特征缓存在扩散模型的推理过程中，通过缓存相似的特征来缓解高计算需求引起的效率问题，但仅依赖历史信息会导致准确性和速度性能受限。

Method: 提出了一种基于自推测引入未来信息的新范式，并在此基础上设计了SpecDiff，包括基于自推测信息的特征选择算法和基于特征重要性得分的多级特征分类算法。

Result: 在NVIDIA A800-80GB GPU上，与RFlow相比，SpecDiff在Stable Diffusion 3、3.5和FLUX上实现了平均2.80倍、2.74倍和3.17倍的加速，且质量损失可忽略不计。

Conclusion: SpecDiff通过合并推测信息和历史信息，克服了加速和准确性之间的权衡瓶颈，推动了高效扩散模型推理中加速和准确性的帕累托前沿。

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [96] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: 本文提出了一种新的数据集蒸馏框架EDITS，它利用图像数据中隐含的文本语义来实现增强的蒸馏。


<details>
  <summary>Details</summary>
Motivation: 传统技术主要捕获低级视觉特征，忽略了图像中固有的高级语义和结构信息。

Method: 首先，通过全局语义查询模块将视觉语言模型(VLM)生成的外部文本与图像特征融合，形成先验聚类缓冲区。然后，局部语义感知从缓冲区中选择有代表性的样本来构建图像和文本原型，后者通过使用精心制作的提示来指导大型语言模型(LLM)来生成。最后，双原型指导策略通过扩散模型生成最终的合成数据集。

Result: 大量的实验证实了该方法的有效性。

Conclusion: 本文提出了一种新的数据集蒸馏框架EDITS，通过利用图像数据中隐含的文本语义来实现增强的蒸馏，实验证明了其有效性。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [97] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: LamiGauss: A reconstruction algorithm combining Gaussian Splatting with a detector-to-world transformation model for sparse-view X-ray Computed Laminography.


<details>
  <summary>Details</summary>
Motivation: Reconstructing high-quality volumes from laminographic projections is challenging, especially with sparse views, due to geometric constraints in plate-like structures like microchips and battery materials.

Method: Combines Gaussian Splatting radiative rasterization with a dedicated detector-to-world transformation model, using an initialization strategy that filters out common laminographic artifacts.

Result: Enables accurate and efficient reconstruction from sparse projections, achieving superior performance over existing techniques with limited data (3% of full views).

Conclusion: LamiGauss is effective and superior for sparse-view X-ray Computed Laminography.

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [98] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: 提出了一个名为DAM4SAM的新的视频目标跟踪模型，该模型通过引入distractor-aware memory module来减少跟踪漂移并提高redetection能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于内存的视频分割方法在视觉对象跟踪中，容易受到干扰物的影响。

Method: 提出了一个distractor-aware drop-in memory module和introspection-based管理方法，用于SAM2，得到了DAM4SAM。

Result: DAM4SAM在13个基准测试中优于SAM2.1，并在10个基准测试中创造了新的state-of-the-art结果。将提出的distractor-aware memory集成到实时跟踪器EfficientTAM中，性能提高了11%。

Conclusion: 提出的distractor-aware memory具有很好的泛化能力，可以提升各种架构的跟踪性能。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [99] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet: A dual-stream attention network fusing X-rays with segmented bone images for improved pelvic fracture classification.


<details>
  <summary>Details</summary>
Motivation: Pelvic fractures are hard to diagnose, especially when signs are subtle on X-rays.

Method: A dual-stream attention network (PelFANet) with Fused Attention Blocks (FABlocks) was trained in a two-stage, segmentation-guided pipeline.

Result: PelFANet achieved 88.68% accuracy and 0.9334 AUC on visible fractures (AMERI dataset), and 82.29% accuracy and 0.8688 AUC on invisible fractures.

Conclusion: Anatomy-aware dual-input architectures like PelFANet show clinical potential for robust fracture detection, even with subtle radiographic presentations.

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [100] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA: Distills knowledge from large vision-language models to lightweight object detectors.


<details>
  <summary>Details</summary>
Motivation: Transfer region-level multimodal semantics from large vision-language teacher models to lightweight vision-only object detector student models.

Method: Uses a translation module to map student features into a joint space. A dual-objective loss enforces local alignment and global relational consistency. Operates at the object level.

Result: Consistent gains over baselines, with a +10.1 average score improvement. Reaches performance on par with larger multimodal models.

Conclusion: MOCHA is suitable for real-world deployment due to its compact architecture and strong performance.

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [101] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV: A lightweight framework for egocentric 3D hand tracking using a single event camera, suitable for XR devices.


<details>
  <summary>Details</summary>
Motivation: Frame-based hand tracking struggles with accuracy, latency, and energy efficiency, especially in XR. Event cameras offer better temporal resolution and power efficiency.

Method: A wrist-based ROI localizes the hand, combined with an end-to-end mapping strategy and multi-task learning to improve representations and reduce computation.

Result: EvHand-FPV improves 2D-AUCp from 0.77 to 0.85, reduces parameters and FLOPs by 89%, and maintains a competitive 3D-AUCp of 0.84.

Conclusion: EvHand-FPV enables accurate and efficient egocentric event-based hand tracking for on-device XR applications.

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [102] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 本文提出了一种新的Few-Shot 3D点云分割方法，该方法使用白化聚合和恢复模块（WARM）来解决原型生成中的分布差异问题，从而生成更具代表性的原型。


<details>
  <summary>Details</summary>
Motivation: 现有Few-Shot 3D点云分割方法使用传统算法构建原型，但这些算法的随机性会显著影响性能，且原型生成过程仍有待探索。

Method: 本文提出WARM模块，通过在白化和着色变换之间夹入交叉注意力来解决原型token和支持特征之间的不对齐问题。白化操作将支持特征与原型token对齐，然后着色操作将原始分布恢复到注意后的token。

Result: 本文方法在多个FS-PCS基准测试中取得了显著的性能提升，达到了state-of-the-art的水平。

Conclusion: 本文提出的WARM模块能够生成更具代表性的原型，从而提高Few-Shot 3D点云分割的性能。

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [103] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 论文提出了一个自推理校准（SRC）框架，以迭代地校准推理和答案之间的一致性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型(LVLMs)在视觉问答方面表现出强大的能力。然而，它们仍然难以对齐理由和生成的答案，导致不一致的推理和不正确的反应。

Method: SRC首先采用一种轻量级的“理由微调”方法，该方法修改了模型的响应格式，要求在没有明确提示的情况下，在得出答案之前提供理由。接下来，SRC从微调的lvlm中搜索每个样本的一组不同的候选响应，然后使用定制的评分模型r评分器提出成对评分策略，以评估候选响应的理由质量和事实一致性。基于置信度加权偏好管理过程，SRC将对齐校准解耦为偏好微调方式。

Result: 在多个基准测试中，LVLM在感知、推理和泛化方面都得到了显著的改善。

Conclusion: 我们的研究结果强调了面向理由的对齐在探索lvlm潜力方面的重要性。

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [104] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 本文提出了一种名为AntiPure的诊断性保护扰动方法，旨在抵抗图像净化，从而防止恶意伪造。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视觉合成任务中被广泛应用，但也带来了深度伪造和版权侵权等安全风险。现有的保护性扰动方法可以通过注入难以察觉的对抗性噪声来缓解图像滥用，但这些扰动可能会被净化技术移除，使图像再次面临风险。

Method: 本文通过两种指导机制来揭示净化过程中的漏洞：1) Patch-wise Frequency Guidance，减少模型对净化图像中高频分量的影响；2) Erroneous Timestep Guidance，扰乱模型在不同时间步长的去噪策略。

Result: 实验表明，AntiPure作为净化的压力测试，实现了最小的感知差异和最大的失真，优于其他保护性扰动方法。

Conclusion: AntiPure嵌入了在代表性净化设置下持续存在的难以察觉的扰动，实现了有效的后定制失真。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [105] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为噪声水平引导（NLG）的简单、高效且通用的噪声水平优化方法，通过提高初始噪声与通用引导对齐的可能性来优化初始噪声，从而提高图像生成质量和输入条件的一致性，且无需额外的训练数据、辅助网络或反向传播。


<details>
  <summary>Details</summary>
Motivation: 现有的噪声水平优化方法通常依赖于额外的数据集构建、额外的网络或基于反向传播的优化，限制了它们的实用性。随机高斯噪声会影响最终输出，导致图像质量和提示一致性的变化。

Method: 提出噪声水平引导（NLG），通过增加初始噪声与通用引导对齐的可能性来优化初始噪声。

Result: 在五个标准基准上的大量实验表明，该方法提高了输出生成质量和输入条件的一致性。

Conclusion: NLG是一种实用且可扩展的扩散模型增强方法，它与现有的引导方法无缝集成，同时保持了计算效率。

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [106] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: 提出了STEP，一个混合token减少框架，结合动态patch合并和token pruning，以提高效率。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs) 在语义分割中实现了最先进的性能，但受到高计算和内存成本的阻碍。

Method: 使用dCTS，一个轻量级的基于CNN的策略网络，可以灵活地合并成超patches。编码器块集成了early-exits以移除高置信度的超tokens，从而降低计算负载。

Result: 当单独应用dCTS时，与标准16 x 16像素patching方案相比，token数量可以减少2.5倍。当使用ViT-Large作为backbone时，计算成本降低了2.6倍，吞吐量提高了3.4倍。完整的STEP框架进一步提高了效率，计算复杂度降低了4倍，推理速度提高了1.7倍，最大精度下降不超过2.0%。

Conclusion: 通过提出的STEP配置，高达40%的tokens可以在到达最终编码器层之前被自信地预测和停止。

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [107] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个用于评估细粒度视觉计数的基准数据集。它包含具有两个对象类别的高分辨率图像，需要模型根据形状、大小、颜色或语义上的细微差异进行区分和计数。


<details>
  <summary>Details</summary>
Motivation: 现有模型在执行细粒度、意图驱动的计数方面的能力尚不清楚。

Method: 引入PairTally基准数据集，包含inter-category和intra-category设置，用于评估选择性计数能力。对各种最先进的模型进行基准测试，包括基于范例的方法、语言提示模型和大型视觉语言模型。

Result: 结果表明，尽管最近取得了进展，但当前的模型难以可靠地计算用户想要的内容，尤其是在细粒度和视觉模糊的情况下。

Conclusion: PairTally为诊断和改进细粒度视觉计数系统提供了一个新的基础。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [108] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 这篇论文提出了一种改进的YOLO-FEDER FusionNet框架，用于在复杂视觉环境中检测无人机，通过优化训练数据、特征融合和backbone设计来提高检测性能。


<details>
  <summary>Details</summary>
Motivation: 在复杂视觉环境中，无人机检测面临背景杂乱、目标小、伪装等挑战，传统目标检测器效果不佳。

Method: 该方法改进了YOLO-FEDER FusionNet，使用了大规模合成数据和少量真实数据进行训练，并评估了中间多尺度FEDER特征的贡献，以及优化了backbone设计。

Result: 实验结果表明，结合中间FEDER特征和backbone升级，性能显著提高。在最佳配置下，FNR降低了39.1%，mAP提高了62.8%。

Conclusion: 通过改进训练数据、特征融合和backbone设计，所提出的YOLO-FEDER FusionNet框架在复杂视觉环境中的无人机检测性能得到了显著提升。

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [109] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2 is a state-of-the-art open-source vision-language foundation model with 2B and 8B parameters.


<details>
  <summary>Details</summary>
Motivation: To create a comprehensive multimodal understanding and reasoning model.

Method: A large-scale data curation pipeline, a progressive training framework, and architectural advances including sparse Mixture-of-Experts (MoE) designs.

Result: Achieves state-of-the-art performance on various image and video benchmarks, including MMMU and MathVista. SAIL-VL2-2B ranks first on the OpenCompass leaderboard among open-source models under 4B parameters.

Conclusion: SAIL-VL2 is an efficient and extensible foundation for the open-source multimodal community.

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [110] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: 本文提出了一种名为PROFUSEme的前列腺癌BCR预测方法，该方法融合了临床、放射学和病理学数据，并结合Cox比例风险回归模型。


<details>
  <summary>Details</summary>
Motivation: 根治性前列腺切除术后，约30%的前列腺癌患者会经历生化复发(BCR)，其特征是前列腺特异性抗原(PSA)升高，且与死亡率增加相关。如果在RP时能准确早期预测BCR，将有助于及时做出适应性临床决策并改善患者的治疗效果。

Method: 该方法学习临床、放射学和病理学数据的跨模态交互，采用中间融合配置，并结合Cox比例风险回归模型。

Result: 该方法优于晚期融合配置，在内部5倍嵌套交叉验证框架上的平均C指数为0.861，在CHIMERA 2025挑战验证排行榜的预留数据上的C指数为0.7103。

Conclusion: 该方法PROFUSEme能够有效地预测前列腺癌的BCR。

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [111] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个用于角色动画和替换的统一框架，可以根据参考视频生成高保真角色视频，或将动画角色集成到参考视频中以替换原始角色。


<details>
  <summary>Details</summary>
Motivation: 为了解决角色动画和替换的问题，提出了一个统一的框架。

Method: Wan-Animate基于Wan模型，采用改进的输入范式来区分参考条件和生成区域，使用空间对齐的骨骼信号来复制身体运动，并从源图像中提取隐式面部特征来重新表演表情。此外，还开发了一个辅助Relighting LoRA来增强角色替换期间的环境集成。

Result: Wan-Animate实现了最先进的性能。

Conclusion: Wan-Animate是一个有效的角色动画和替换框架，具有高可控性和表现力，并且可以实现无缝的环境集成。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [112] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 提出了一个视觉语义增强引导的多目标跟踪框架（VSE-MOT），以解决低质量视频中的多目标跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 现有算法忽略了低质量视频中固有的问题，导致跟踪性能显著下降。在实际的低质量视频场景中推进MOT算法的应用至关重要。

Method: 设计了一个三分支架构，利用视觉语言模型从图像中提取全局视觉语义信息，并将其与查询向量融合。引入了多目标跟踪适配器（MOT-Adapter）和视觉语义融合模块（VSFM）。

Result: 在真实低质量视频场景中的大量实验验证了该方法的有效性和优越性。跟踪性能指标比现有方法高出约8%到20%，同时在传统场景中保持了稳健的性能。

Conclusion: VSE-MOT框架有效地提升了低质量视频中的多目标跟踪性能。

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [113] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: This paper introduces AD-DINOv3, a new vision-language framework for zero-shot anomaly detection (ZSAD) that adapts DINOv3.


<details>
  <summary>Details</summary>
Motivation: Traditional ZSAD methods rely on CLIP and struggle with domain bias and misinterpreting subtle anomalies. This paper aims to improve ZSAD by leveraging DINOv3's transferable representation capabilities.

Method: The paper formulates anomaly detection as a multimodal contrastive learning problem using DINOv3 and CLIP, introduces lightweight adapters to bridge the domain gap, and designs an Anomaly-Aware Calibration Module (AACM) to enhance discriminability.

Result: AD-DINOv3 matches or surpasses state-of-the-art methods on eight industrial and medical benchmarks.

Conclusion: AD-DINOv3 is a superior general zero-shot anomaly detection framework.

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [114] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 提出了一种弱监督的音视频视频解析(AVVP)方法，该方法在没有时间注释的情况下检测可听的、可见的和音视频事件。


<details>
  <summary>Details</summary>
Motivation: 先前的工作强调通过对比或协作学习来改进全局预测，但忽略了稳定的片段级监督和类感知的跨模态对齐。

Method: 提出了两种策略：(1) 指数移动平均(EMA)引导的伪监督框架，通过自适应阈值或top-k选择生成可靠的片段级掩码，从而提供超出视频级标签的稳定时间指导；(2) 一种类感知的跨模态一致性(CMA)损失，该损失在可靠的片段-类对上对齐音频和视觉嵌入，确保跨模态的一致性，同时保持时间结构。

Result: 在LLP和UnAV-100数据集上的评估表明，该方法在多个指标上实现了最先进的(SOTA)性能。

Conclusion: 该论文提出了一种新的弱监督音视频视频解析方法，通过EMA引导的伪监督和类感知的跨模态一致性损失，实现了更好的性能。

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [115] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 本文对比了“思考型”和“非思考型”LLM在LLM-as-a-judge范式中的表现，使用开源Qwen 3模型，评估了准确性和计算效率，以及各种增强策略。


<details>
  <summary>Details</summary>
Motivation: 确保LLM作为自动化评判的可靠性、效率和鲁棒性至关重要。

Method: 在RewardBench任务上评估了准确性和计算效率，并检验了非思考型模型的增强策略，包括上下文学习、规则引导判断、基于参考的评估和n-best聚合。

Result: 结果表明，尽管进行了增强，非思考型模型通常不如思考型模型。思考型模型在几乎没有额外开销的情况下，准确率提高了约10个百分点。在各种偏差条件下，思考型模型保持了更高的稳定性。

Conclusion: 显式推理在LLM-as-a-judge范式中具有明显的优势，不仅在准确性和效率方面，而且在鲁棒性方面。

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [116] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）可以在内部区分评估和部署环境，这种行为被称为“评估感知”。这会破坏AI安全评估，因为模型可能会在测试期间隐藏危险能力。先前的研究在一个70B模型中证明了这一点，但跨模型大小的缩放关系仍然未知。


<details>
  <summary>Details</summary>
Motivation: 研究评估感知，因为模型可能会在测试期间隐藏危险能力，从而破坏AI安全评估。先前的研究在一个70B模型中证明了这一点，但跨模型大小的缩放关系仍然未知。

Method: 使用对steering vector activations的线性探测，研究了来自四个系列的15个模型（参数从0.27B到70B不等）的评估感知。

Result: 结果表明，存在清晰的幂律缩放关系：评估感知随着模型大小的增加而可预测地增加。

Conclusion: 这种缩放规律能够预测未来更大模型中的欺骗行为，并指导AI安全评估策略的设计。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [117] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: 这篇论文介绍了一种名为 Faithful Reasoning via Intervention Training (FRIT) 的方法，用于提高大型语言模型推理的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，大型语言模型的推理步骤通常不能有效地影响最终答案，导致输出结果脆弱且不可信。先前的研究主要集中在测量忠实度上，而系统地提高忠实度的方法仍然有限。

Method: 该方法通过对模型生成的 CoT 中的单个推理步骤进行干预，生成合成训练数据，创建 faithful/unfaithful 对，突出显示推理何时失败。然后，应用 Direct Preference Optimization 来教导模型优先选择因果一致的推理路径。

Result: 在 Qwen3-8B 和 Mistral-7B-v0.1 上，FRIT 将 Mistral 在 GSM8K 上的忠实推理提高了 3.4 个百分点，同时将准确率提高了 7.6 个百分点。

Conclusion: 该方法提供了一种可扩展的、无监督的方法，用于训练语言模型以产生更可靠和可解释的推理，解决了推理性能和可信度之间的关键差距。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [118] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 现代人工智能研究必须采用反脆弱的视角来看待安全性，即系统保证长期人工智能安全的能力随着时间的推移而扩大。


<details>
  <summary>Details</summary>
Motivation: 传统的静态基准和单次鲁棒性测试忽略了环境会不断演变，模型如果不接受挑战，可能会逐渐变得不适应环境。

Method: 首先确定静态测试的关键局限性，包括场景多样性、奖励篡改和过度对齐。然后，探讨反脆弱解决方案在管理罕见事件方面的潜力。

Result: 提倡从根本上重新调整用于衡量、评估和持续改进人工智能长期安全性的方法。

Conclusion: 通过提供符合伦理和实际的指导方针，促进一个反脆弱的人工智能安全社区，以此来补充现有的鲁棒性方法。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [119] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA is a framework for recommending AI task instructions on smartphones, allowing users to access AI services with one-touch.


<details>
  <summary>Details</summary>
Motivation: Simplifying access to AI services on smartphones.

Method: A multimodal large language model (MLLM)-based recommendation pipeline with structured reasoning, a template-augmented reasoning mechanism, and a prefix-tree-based constrained decoding strategy.

Result: MIRA demonstrates substantial improvements in the accuracy of instruction recommendation.

Conclusion: MIRA has the potential to revolutionize how users engage with AI services on smartphones, offering a more seamless and efficient experience.

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [120] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 本文提出了一种名为IMAC的新方法，利用无监督环境设计(UED)在生成的世界中自动生成课程，以训练能够在新的任务变体中推广的鲁棒代理。


<details>
  <summary>Details</summary>
Motivation: 在具身环境中训练智能体通常需要大量的训练数据或访问精确的模拟环境，而现实世界中的许多情况并非如此。世界模型正在成为一种替代方案，利用离线、被动收集的数据，它们可以生成多样化的世界，用于在模拟环境中训练智能体。

Method: 利用世界模型生成想象的环境，并提出一种名为IMAC的新方法，该方法利用无监督环境设计(UED)在生成的世界中自动生成课程。

Result: 在一系列具有挑战性的程序生成环境中，我们展示了在仅在从较窄数据集学习的世界模型中训练后，可以在保留的环境中实现强大的迁移性能。

Conclusion: 我们相信这为利用更大规模的基础世界模型来实现通用智能体开辟了道路。

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [121] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 本文对 Minecraft 中 VLA 模型的抽象动作空间和分词器进行了大规模的系统比较，发现没有一个动作空间是普遍最优的，并提出了一种新的框架 Chain of Action (CoA)，该框架在一个单一的 VLA 模型中统一了高层次的规划和低层次的控制。通过在 CoA 范例中使用不同的动作空间混合训练的 All-in-One 智能体学习到了一种更强大和更通用的策略，实现了新的技术水平。


<details>
  <summary>Details</summary>
Motivation: 在开发有能力的、端到端的可训练智能体中，动作空间的选择是一个关键但尚未解决的挑战。目前没有一个动作空间是普遍最优的，最具效果的抽象是高度依赖于任务的，这给构建通用智能体带来了困境。

Method: 提出 Chain of Action (CoA) 框架，将抽象的动作视为中间推理步骤，类似于思维链，指导最终可执行动作的生成。使用 CoA 范例，在不同的动作空间混合训练 All-in-One 智能体。

Result: 统一的智能体实现了新的技术水平，提高了超过强大的、专门的基线的总体任务成功率。

Conclusion: 本文发布了 OpenHA (Open Hierarchical Agents) 套件，其中包括超过 800 个不同任务的综合基准、整理的数据集、源代码和所有预训练模型检查点，以促进可重复的研究。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [122] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: 本文提出了一种名为 PDDL-Instruct 的指令调整框架，旨在通过逻辑链式思维推理来增强 LLM 的符号规划能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 在各种任务中表现出了令人印象深刻的能力，但它们执行结构化符号规划的能力仍然有限，尤其是在需要像规划领域定义语言 (PDDL) 这样的形式化表示的领域中。

Method: 我们的方法侧重于教导模型使用显式逻辑推理步骤来严格推理关于行动适用性、状态转换和计划有效性。

Result: 在多个规划领域进行的实验结果表明，我们基于链式思维推理的指令调整模型在规划方面明显更好，在标准基准上实现了高达 94% 的规划准确率，比基线模型提高了 66%。

Conclusion: 这项工作弥合了 LLM 的通用推理能力与自动规划所需的逻辑精度之间的差距，为开发更好的 AI 规划系统提供了一个有希望的方向。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [123] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 本研究提出了一种新的无人机框架，通过集成大型语言模型（LLM）来提高无人机的自主性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机系统在动态和不确定的任务中适应性不足，缺乏上下文感知推理、自主决策和生态系统级集成。

Method: 提出了一个五层架构的Agentic UAVs框架，该框架利用LLM驱动的推理、数据库查询和第三方系统交互。

Result: 在模拟的搜索和救援场景中，agentic UAVs实现了更高的检测置信度、改进的人员检测率和显著提高的行动建议。

Conclusion: 实验结果表明，适度的计算开销能够实现无人机自主性和生态系统集成方面质的新水平。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [124] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 本文提出了一种轻量级的语义融合方案，该方案使用并行的模糊隶属度特征通道来增强 Transformer 语言模型 (LM)，该通道编码token级语义。


<details>
  <summary>Details</summary>
Motivation: Transformer 语言模型缺乏对token语义的理解和控制。

Method: 该方法使用可解释的特征向量（例如，词性提示、浅层角色、边界标志、情感极性和强度）表示每个token，这些特征的值是来自可微分隶属函数（例如，幂核）的分级度数。这些per-token向量形成一个句子级语义矩阵，通过门控适配器融合到 LM 中。

Result: 在具有保留形容词的合成双子句语料库上进行分布外 (OOD) 控制，语义融合提高了困惑度，并实现了精确的、用户可控的极性和标点符号生成，同时保持了模型的简单性。

Conclusion: 该方法增加了少量开销，与绑定的输入-输出嵌入完全兼容，并为条件自然语言生成提供了可解释的途径。

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [125] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: 提出了星号算子，一种基于邻接结构并行传播（ASPP）的抽象推理的新型统一框架。


<details>
  <summary>Details</summary>
Motivation: 将结构化推理任务形式化为由隐式关系图引导的局部并行状态演化过程。

Method: 通过严格的数学分析和在 ARC2 挑战和 Conway 的生命游戏上进行全面的实验

Result: 星号算子在 ARC2 验证集上实现了 100% 的准确率，参数量仅为 6M。

Conclusion: 证明了该算子的普适性、收敛性和卓越的性能，代表了神经符号推理的重大突破。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [126] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: 提出了一种名为 Agent^2 的新框架，通过智能 LLM 驱动的生成来实现完全自动化的 RL 智能体设计。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习智能体开发需要广泛的专业知识和漫长的迭代，通常导致高失败率和有限的可访问性。

Method: 该框架采用革命性的双智能体架构，将 RL 开发分解为 MDP 建模和算法优化两个不同的阶段。生成器智能体作为自主 AI 设计师，分析任务并生成可执行的 RL 智能体，而目标智能体是生成的 RL 智能体。

Result: 在包括 MuJoCo、MetaDrive、MPE 和 SMAC 在内的各种基准测试中进行的大量实验表明，Agent^2 在所有任务中的性能始终优于手动设计的解决方案，实现了高达 55% 的性能提升。

Conclusion: 通过实现真正的端到端闭环自动化，这项工作建立了一种新的范例，其中智能智能体设计和优化其他智能体，标志着自动化 AI 系统的根本性突破。

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [127] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 本研究对16个最先进的视觉语言模型在6个多模态数据集上进行了全面的不确定性基准测试，使用3种不同的评分函数。


<details>
  <summary>Details</summary>
Motivation: 现有研究对视觉语言模型在复杂视觉理解方面的能力进行了基准测试，但对不确定性量化的关注不足。

Method: 评估了16个最先进的视觉语言模型（开源和闭源），跨越6个多模态数据集，使用3种不同的评分函数。

Result: 更大的模型在不确定性量化方面表现更好；更确定的模型实现了更高的准确率；与其他领域相比，数学和推理任务引发了较差的不确定性表现。

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [128] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 本文研究了仅从动作轨迹中学习命题STRIPS世界模型的问题，使用深度学习架构（transformers）和梯度下降。


<details>
  <summary>Details</summary>
Motivation: 任务被转化为一个有监督的下一个token预测问题，其中token是动作，并且如果先前动作的隐藏效果没有使a的动作前提为假，则动作a可以跟随一个动作序列。

Method: 使用深度学习架构（transformers）和梯度下降。

Result: 我们表明，合适的transformer架构可以忠实地表示命题STRIPS世界模型，并且这些模型可以仅从随机有效（正）和无效（负）动作序列集合中学习。

Conclusion: 报告了一些实验。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [129] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: SteeringControl是一个评估表征引导方法在对齐目标（偏见、有害生成和幻觉）以及次要行为（如奉承和常识道德）的基准。


<details>
  <summary>Details</summary>
Motivation: 先前的对齐工作经常强调真实性或推理能力来证明表征引导的副作用，但我们发现有许多未被探索的权衡。

Method: 我们收集了一个与安全相关的初级和次级行为数据集，以评估围绕五种流行的引导方法的引导效果和行为纠缠。为了实现这一点，我们设计了一个基于独特组件的模块化引导框架，这些组件是许多现有方法的构建块。

Result: 我们对Qwen-2.5-7B和Llama-3.1-8B的结果发现，强大的引导性能取决于引导方法、模型和目标行为的特定组合，并且糟糕的组合可能导致严重的概念纠缠。

Conclusion: 引导性能取决于引导方法、模型和目标行为的特定组合，并且糟糕的组合可能导致严重的概念纠缠。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [130] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 通过为LLM agents提供协作工具和自主性，类似于人类解决问题的方式，来提高其性能。在34个Aider Polyglot Python编程挑战中，协作工具在最困难的问题上显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 研究LLM agents是否可以通过使用协作工具和自主性来提高解决问题的能力，类似于人类。

Method: 为Claude Code agents配备基于MCP的社交媒体和日志工具，并允许它们根据自己的意愿使用这些工具。在34个Aider Polyglot Python编程挑战中评估其性能。

Result: 协作工具在最困难的问题上显著提高了性能，成本降低15-40%，回合数减少12-27%，完成速度提高12-38%。不同的模型自然地采用了不同的协作策略，Sonnet 3.7广泛使用各种工具，而Sonnet 4则倾向于在真正困难的问题中使用基于日志的语义搜索。行为分析表明，agents更喜欢写作而不是阅读，表明结构化表达是改进的主要驱动力。

Conclusion: AI agents可以系统地从人类启发的协作工具中受益，尤其是在其能力边缘，这表明自适应协作界面是推理增强器，而不是普遍的效率提升。

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [131] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 本研究探讨了在允许使用生成式AI的三个本科数学课程中，学生对生成式AI的使用和看法。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在高等教育中的快速兴起以及当前AI检测工具的不可靠性，制定鼓励学生学习和批判性思维的政策变得越来越重要。

Method: 通过调查问卷和学生访谈，分析学生如何使用AI工具，他们对生成式AI的有用性和局限性的看法，以及这些看法对教授基于证明的数学的意义。

Result: 分析学生如何使用AI工具，他们对生成式AI的有用性和局限性的看法。

Conclusion: 讨论了将生成式AI整合到基于证明的数学教学中的未来考虑因素。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [132] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: 介绍了CoBRA，一个用于在基于LLM的社会模拟中系统地指定代理行为的新工具包。


<details>
  <summary>Details</summary>
Motivation: 传统的通过隐式自然语言描述指定代理行为的方法无法在不同模型中产生一致的行为，并且生成的代理行为无法捕捉到描述的细微差别。

Method: CoBRA提出了一种新方法，通过使用经典社会科学实验来确定代理的预期行为，从而明确地规划代理的认知偏差。CoBRA有两个组成部分：(1)认知偏差指数，通过量化代理在一组经过验证的经典社会科学实验中的反应来衡量社会代理的认知偏差；(2)行为调节引擎，用于调整代理的行为以展示受控的认知偏差。

Result: 我们的结果表明，CoBRA可以以模型无关的方式精确地规划社会代理中表现出的认知偏差。

Conclusion: CoBRA作为一个人机交互工具包通过演示和技术基准进行了评估。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [133] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 多模态智能体在图形用户界面（GUI）交互中表现出色，但在执行切换控制指令时存在可靠性问题。本文构建了一个状态控制基准来研究这个问题，并提出了状态感知推理（StaR）训练方法，以提高智能体执行切换指令的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态智能体在执行切换控制指令时不够可靠，尤其是在当前状态与所需状态匹配时。

Method: 提出了状态感知推理（StaR）训练方法，该方法教导智能体感知当前切换状态，分析指令中的所需状态，并据此采取行动。

Result: 在三个多模态智能体上的实验表明，StaR可以将切换指令执行准确率提高30%以上。在三个公共基准上的进一步评估表明，StaR还可以提高一般任务的性能。

Conclusion: StaR方法显著提高了多模态智能体执行切换控制指令的准确性和通用任务性能，并在动态环境中展现了在实际应用中的潜力。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [134] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: InfraMind is a GUI agentic framework for industrial management systems that addresses the limitations of RPA and general-purpose LLM-based GUI agents.


<details>
  <summary>Details</summary>
Motivation: The increasing complexity of industrial infrastructure management software, multi-vendor integration, and a shortage of expert operators pose significant challenges.

Method: InfraMind integrates five innovative modules: systematic search-based exploration, memory-driven planning, advanced state identification, structured knowledge distillation, and comprehensive, multi-layered safety mechanisms.

Result: InfraMind outperforms existing frameworks in task success rate and operational efficiency on both open-source and commercial DCIM platforms.

Conclusion: InfraMind provides a rigorous and scalable solution for industrial management automation.

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [135] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: THOR: Tool-Integrated Hierarchical Optimization via RL,克服了现有工具集成方法在构建工具集成推理数据、执行细粒度优化和增强推理方面的三个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面取得了显著进展，但仍然难以进行高精度任务，如数值计算和形式符号操作。集成外部工具已成为弥合这一差距的有希望的方法。

Method: 提出了一种基于多智能体 Actor-Critic 的管道 TIRGen，用于构建高质量的工具集成推理路径数据集；引入了一种 RL 策略，可以联合优化轨迹级问题解决和步骤级代码生成；THOR 包含一种自我纠正机制，可以利用即时工具反馈来动态修改推理路径。

Result: 在多个数学基准测试中，THOR 实现了同等规模模型的最新性能，同时在代码基准测试中也提供了一致的改进。

Conclusion: THOR 在不同的模型中表现出强大的泛化能力，在推理和非推理模型中均能有效执行。

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [136] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 本文提出了一种基于穷举DPLL架构的MCILC精确方法。


<details>
  <summary>Details</summary>
Motivation: 许多应用可以简化为整数线性约束的模型计数（MCILC）任务。

Method: 将混合整数规划中的几种有效简化技术集成到该架构中。

Result: 在随机基准测试中，该方法明显优于所有精确方法，解决了1718个实例，而现有方法仅计算了1470个实例。此外，该方法是解决所有4131个应用实例的唯一方法。

Conclusion: 该方法在MCILC任务上表现出色。

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [137] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 研究了神经网络信息流的变化是否能引起认知能力的转变。


<details>
  <summary>Details</summary>
Motivation: 探讨认知是否也可能通过一系列重大转变进化而来，这些转变操纵生物神经网络的结构，从根本上改变信息的流动。

Method: 使用理想化的信息流模型，即人工神经网络（ANN），来评估网络中信息流的变化是否能产生认知性能的过渡性变化。比较了具有前馈、循环和分层拓扑的网络，并测试了它们学习不同复杂性的人工语法的性能，同时控制了网络大小和资源。

Result: 循环网络与前馈网络相比，可以处理的输入类型在质量上有所扩展，并且在学习最复杂的语法时，性能也有相关的质量提升。训练循环网络的难度构成了一种过渡障碍和或有不可逆性——进化过渡的其他关键特征。

Conclusion: 信息流的一些变化可以产生认知性能的转变。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [138] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: 提出了一种名为 CrowdAgent 的多智能体系统，用于管理来自大型语言模型、小型语言模型和人类专家等不同来源的注释数据，以实现端到端的流程控制。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常只关注标注步骤本身，缺乏对这些来源进行动态管理的整体流程控制，无法解决复杂的调度和质量-成本权衡问题。

Method: 设计了一个多智能体系统 CrowdAgent，集成了任务分配、数据标注和质量/成本管理，并采用了一种新颖的方法来合理分配任务，使 LLM、SLM 和人类专家能够在协作标注工作流程中协同工作。

Result: 通过在六个不同的多模态分类任务上进行的大量实验，证明了 CrowdAgent 的有效性。

Conclusion: CrowdAgent 能够有效地管理和利用来自不同来源的注释数据，实现端到端的流程控制，并在多模态分类任务中表现出良好的性能。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [139] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文研究了二阶学习促进环境-认知同构涌现的假设，并提出了一个分层架构进行验证。


<details>
  <summary>Details</summary>
Motivation: 研究心智表征，它以反映外部环境的结构化内部模型为特征，对于高级认知至关重要，但对其进行经验研究仍然具有挑战性。现有的理论假设二阶学习——调整一阶学习（即，关于任务/领域的学习）的学习机制——促进了这种环境-认知同构的出现。

Method: 我们提出了一个分层架构，包括一个图卷积网络 (GCN) 作为一个一阶学习器，以及一个 MLP 控制器作为一个二阶学习器。GCN 直接将节点级特征映射到最佳导航路径的预测，而 MLP 在面对结构新颖的迷宫环境时动态地调整 GCN 的参数。

Result: 我们证明了当认知系统发展出与环境结构同构的内部心智地图时，二阶学习特别有效。定量和定性的结果突出了在未见过的迷宫任务上的显着性能改进和强大的泛化能力。

Conclusion: 为结构化心智表征在最大化二阶学习有效性方面的关键作用提供了经验支持。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [140] [The NIAID Discovery Portal: A Unified Search Engine for Infectious and Immune-Mediated Disease Datasets](https://arxiv.org/abs/2509.13524)
*Ginger Tsueng,Emily Bullen,Candice Czech,Dylan Welzel,Leandro Collares,Jason Lin,Everaldo Rodolpho,Zubair Qazi,Nichollette Acosta,Lisa M. Mayer,Sudha Venkatachari,Zorana Mitrović Vučičević,Poromendro N. Burman,Deepti Jain,Jack DiGiovanna,Maria Giovanni,Asiyah Lin,Wilbert Van Panhuis,Laura D. Hughes,Andrew I. Su,Chunlei Wu*

Main category: cs.DB

TL;DR: NIAID Data Ecosystem Discovery Portal eases access to biomedical datasets for infectious and immune-mediated disease (IID) research.


<details>
  <summary>Details</summary>
Motivation: Valuable datasets are often overlooked because they are difficult to locate, hindering research and secondary use.

Method: Integrates metadata from various repositories, providing a unified search interface with user-friendly filters and advanced queries.

Result: Improves data findability, accessibility, and reusability by standardizing metadata and harmonizing formats.

Conclusion: Serves as an entry point for IID researchers, supporting hypothesis generation, comparative analysis, and data sharing, thus maximizing the impact of public investment in research data.

Abstract: The NIAID Data Ecosystem Discovery Portal (https://data.niaid.nih.gov)
provides a unified search interface for over 4 million datasets relevant to
infectious and immune-mediated disease (IID) research. Integrating metadata
from domain-specific and generalist repositories, the Portal enables
researchers to identify and access datasets using user-friendly filters or
advanced queries, without requiring technical expertise. The Portal supports
discovery of a wide range of resources, including epidemiological, clinical,
and multi-omic datasets, and is designed to accommodate exploratory browsing
and precise searches. The Portal provides filters, prebuilt queries, and
dataset collections to simplify the discovery process for users. The Portal
additionally provides documentation and an API for programmatic access to
harmonized metadata. By easing access barriers to important biomedical
datasets, the NIAID Data Ecosystem Discovery Portal serves as an entry point
for researchers working to understand, diagnose, or treat IID.
  Valuable datasets are often overlooked because they are difficult to locate.
The NIAID Data Ecosystem Discovery Portal fills this gap by providing a
centralized, searchable interface that empowers users with varying levels of
technical expertise to find and reuse data. By standardizing key metadata
fields and harmonizing heterogeneous formats, the Portal improves data
findability, accessibility, and reusability. This resource supports hypothesis
generation, comparative analysis, and secondary use of public data by the IID
research community, including those funded by NIAID. The Portal supports data
sharing by standardizing metadata and linking to source repositories, and
maximizes the impact of public investment in research data by supporting
scientific advancement via secondary use.

</details>


### [141] [Tractability Frontiers of the Shapley Value for Aggregate Conjunctive Queries](https://arxiv.org/abs/2509.13565)
*Christoph Standke,Benny Kimelfeld*

Main category: cs.DB

TL;DR: 本文研究了计算聚合合取查询中元组的 Shapley 值的复杂性，并为每个聚合函数确定了一个分层 CQ 类，在该类中，Shapley 值对于每个值函数都是易于处理的。


<details>
  <summary>Details</summary>
Motivation: Shapley 值已成为评估元组对数据库查询结果贡献的一般博弈论度量。之前的研究已经确定，当查询对于其存在变量是非分层时，此任务对于每个非平凡聚合函数都是 #P-hard。

Method: 本文为每个聚合函数确定了一个分层 CQ 类，在该类中，Shapley 值对于每个值函数都是易于处理的，只要它是局部的（即，由一个关系的元组确定）。

Result: 本文揭示了每个聚合函数对应于布尔查询到非布尔查询的分层 CQ 类的不同泛化。特别是，max、min 和 count-distinct 匹配于所有分层（即，相对于所有变量分层）的 CQ 类，而 average 和 quantile 匹配于 Berkholz、Keppeler 和 Schweikardt (2017) 在查询回答的细粒度复杂性背景下引入的更窄的 q-分层 CQ 类。

Conclusion: 本文解决了开放性问题，并为每个聚合函数识别了一个分层 CQ 类，在该类中，Shapley 值是易于处理的。

Abstract: In recent years, the Shapley value has emerged as a general game-theoretic
measure for assessing the contribution of a tuple to the result of a database
query. We study the complexity of calculating the Shapley value of a tuple for
an aggregate conjunctive query, which applies an aggregation function to the
result of a conjunctive query (CQ) based on a value function that assigns a
number to each query answer. Prior work by Livshits, Bertossi, Kimelfeld, and
Sebag (2020) established that this task is #P-hard for every nontrivial
aggregation function when the query is non-hierarchical with respect to its
existential variables, assuming the absence of self-joins. They further showed
that this condition precisely characterizes the class of intractable CQs when
the aggregate function is sum or count. In addition, they posed as open
problems the complexity of other common aggregate functions such as min, max,
count-distinct, average, and quantile (including median). Towards the
resolution of these problems, we identify for each aggregate function a class
of hierarchical CQs where the Shapley value is tractable with every value
function, as long as it is local (i.e., determined by the tuples of one
relation). We further show that each such class is maximal: for every CQ
outside of this class, there is a local (easy-to-compute) value function that
makes the Shapley value #P-hard. Interestingly, our results reveal that each
aggregate function corresponds to a different generalization of the class of
hierarchical CQs from Boolean to non-Boolean queries. In particular, max, min,
and count-distinct match the class of CQs that are all-hierarchical (i.e.,
hierarchical with respect to all variables), and average and quantile match the
narrower class of q-hierarchical CQs introduced by Berkholz, Keppeler, and
Schweikardt (2017) in the context of the fine-grained complexity of query
answering.

</details>


### [142] [XASDB -- Design and Implementation of an Open-Access Spectral Database](https://arxiv.org/abs/2509.13566)
*Denis Spasyuk*

Main category: cs.DB

TL;DR: XASDB是一个由加拿大光源（CLS）开发和托管的综合性Web平台，旨在管理、共享和分析XAS数据。


<details>
  <summary>Details</summary>
Motivation: 同步加速器设施产生的X射线吸收光谱（XAS）数据量和复杂性日益增加，需要强大的基础设施来进行数据管理、共享和分析。

Method: 该平台采用Node.js/MongoDB架构，并使用XASproc JavaScript库实现浏览器端的XAS数据处理，集成了XASVue光谱查看器。

Result: XASDB数据库包含超过1000个参考光谱，涵盖40个元素和324种化合物。它提供标准化数据输出、综合元数据和集成分析功能。

Conclusion: XASDB促进了协作研究，并促进了FAIR数据原则，为材料科学、环境研究、化学和生物学领域的进展加速提供了潜力。

Abstract: The increasing volume and complexity of X-ray absorption spectroscopy (XAS)
data generated at synchrotron facilities worldwide require robust
infrastructure for data management, sharing, and analysis. This paper
introduces the XAS Database (XASDB), a comprehensive web-based platform
developed and hosted by the Canadian Light Source (CLS). The database houses
more than 1000 reference spectra spanning 40 elements and 324 chemical
compounds. The platform employs a Node.js/MongoDB architecture designed to
handle diverse data formats from multiple beamlines and synchrotron facilities.
A key innovation is the XASproc JavaScript library, which enables browser-based
XAS data processing including normalization, background sub- traction, extended
X-ray absorption fine structure (EXAFS) extraction, and preliminary analysis
traditionally limited to desktop applications. The integrated XASVue spectral
viewer provides installation-free data visualization and analysis with broad
accessibility across devices and operating systems. By offering standardized
data output, comprehensive metadata, and integrated analytical ca- pabilities,
XASDB facilitates collaborative research and promotes FAIR (Findable,
Accessible, In- teroperable, and Reusable) data principles. The platform serves
as a valuable resource for linear combination fitting (LCF) analysis, machine
learning applications, and educational purposes. This initiative demonstrates
the potential for web-centric approaches in XAS data analysis, accelerating
advances in materials science, environmental research, chemistry, and biology.

</details>


### [143] [Algorithms for Optimizing Acyclic Queries](https://arxiv.org/abs/2509.14144)
*Zheng Luo,Wim Van den Broeck,Guy Van den Broeck,Yisu Remy Wang*

Main category: cs.DB

TL;DR: 本文提出了三种为无环查询构建连接树的方法，旨在优化查询效率。


<details>
  <summary>Details</summary>
Motivation: 传统查询优化主要集中在二元连接算法，但最近对理论最优算法（如Yannakakis算法）的兴趣日益增长。这些算法依赖于连接树，这与二元连接的操作树不同，需要新的优化技术。

Method: 1) 提出了一种通过编辑以分摊常数延迟枚举alpha-无环查询的所有连接树的算法，为无环连接的基于成本的优化器奠定基础。2) 证明了Tarjan和Yannakakis的最大基数搜索算法为Berge-无环查询构建了一个唯一的、最浅的连接树，该树可以并行执行大型连接查询。3) 证明了gamma-无环查询的任何连接的左深线性计划都可以通过一个简单的算法转换为连接树，从而可以重用为二元连接开发的优化基础设施。

Result: 提出的三种方法均在特定类型的无环查询中表现出优化查询的潜力。

Conclusion: 该研究为无环查询的连接树构建提供了多种有效方法，并为进一步优化查询处理奠定了基础。

Abstract: Most research on query optimization has centered on binary join algorithms
like hash join and sort-merge join. However, recent years have seen growing
interest in theoretically optimal algorithms, notably Yannakakis' algorithm.
These algorithms rely on join trees, which differ from the operator trees for
binary joins and require new optimization techniques. We propose three
approaches to constructing join trees for acyclic queries. First, we give an
algorithm to enumerate all join trees of an alpha-acyclic query by edits with
amortized constant delay, which forms the basis of a cost-based optimizer for
acyclic joins. Second, we show that the Maximum Cardinality Search algorithm by
Tarjan and Yannakakis constructs a unique shallowest join tree, rooted at any
relation, for a Berge-acyclic query; this tree enables parallel execution of
large join queries. Finally, we prove that any connected left-deep linear plan
for a gamma-acyclic query can be converted into a join tree by a simple
algorithm, allowing reuse of optimization infrastructure developed for binary
joins.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [144] [MA-DPR: Manifold-aware Distance Metrics for Dense Passage Retrieval](https://arxiv.org/abs/2509.13562)
*Yifan Liu,Qianfeng Wen,Mark Zhao,Jiazhou Liang,Scott Sanner*

Main category: cs.IR

TL;DR: 提出了一种流形感知的DPR(MA-DPR)，它使用最近邻图对通道的内在流形结构建模，并基于它们在该图中的最短路径来测量查询-通道距离。


<details>
  <summary>Details</summary>
Motivation: 现有的DPR模型依赖于欧几里得或余弦距离来测量嵌入空间中的查询-通道相关性，但当嵌入位于非线性流形上时，这些方法无法捕获语义相似性，尤其是在分布外(OOD)设置中。

Method: 提出一种流形感知距离度量用于DPR(MA-DPR)，该方法使用最近邻图对通道的内在流形结构建模，并基于它们在该图中的最短路径来测量查询-通道距离。

Result: 在OOD通道检索中，MA-DPR的性能优于欧几里得和余弦距离高达26%，并且在各种嵌入模型中具有相当的分布内性能，同时查询推理时间的增加 минима。

Conclusion: 流形感知距离使得DPR能够利用来自相关相邻通道的上下文，即使在没有直接语义重叠的情况下也有效。MADPR可以应用于各种密集嵌入和检索任务，在各个领域提供潜在的好处。

Abstract: Dense Passage Retrieval (DPR) typically relies on Euclidean or cosine
distance to measure query-passage relevance in embedding space, which is
effective when embeddings lie on a linear manifold. However, our experiments
across DPR benchmarks suggest that embeddings often lie on lower-dimensional,
non-linear manifolds, especially in out-of-distribution (OOD) settings, where
cosine and Euclidean distance fail to capture semantic similarity. To address
this limitation, we propose a manifold-aware distance metric for DPR (MA-DPR)
that models the intrinsic manifold structure of passages using a nearest
neighbor graph and measures query-passage distance based on their shortest path
in this graph. We show that MA-DPR outperforms Euclidean and cosine distances
by up to 26% on OOD passage retrieval with comparable in-distribution
performance across various embedding models while incurring a minimal increase
in query inference time. Empirical evidence suggests that manifold-aware
distance allows DPR to leverage context from related neighboring passages,
making it effective even in the absence of direct semantic overlap. MADPR can
be applied to a wide range of dense embedding and retrieval tasks, offering
potential benefits across a wide spectrum of domains.

</details>


### [145] [Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation](https://arxiv.org/abs/2509.13603)
*Yongye Su,Zeya Zhang,Jane Kou,Cheng Ju,Shubhojeet Sarkar,Yamin Wang,Ji Liu,Shengbo Guo*

Main category: cs.IR

TL;DR: 本文提出了一种结合传统关键词检索和嵌入检索(EBR)的Facebook Group Scoped Search框架，以提高搜索结果的相关性和多样性。


<details>
  <summary>Details</summary>
Motivation: 为了在社交网络搜索中，更好地检索信息和发现潜在的社交关系。

Method: 将语义检索集成到现有的关键词搜索流程中。

Result: 混合检索系统显著提高了用户参与度和搜索质量，并通过在线指标和基于LLM的评估进行了验证。

Conclusion: 该研究为在大型真实社交平台中部署和评估高级检索系统提供了实践见解。

Abstract: Beyond general web-scale search, social network search uniquely enables users
to retrieve information and discover potential connections within their social
context. We introduce a framework of modernized Facebook Group Scoped Search by
blending traditional keyword-based retrieval with embedding-based retrieval
(EBR) to improve the search relevance and diversity of search results. Our
system integrates semantic retrieval into the existing keyword search pipeline,
enabling users to discover more contextually relevant group posts. To
rigorously assess the impact of this blended approach, we introduce a novel
evaluation framework that leverages large language models (LLMs) to perform
offline relevance assessments, providing scalable and consistent quality
benchmarks. Our results demonstrate that the blended retrieval system
significantly enhances user engagement and search quality, as validated by both
online metrics and LLM-based evaluation. This work offers practical insights
for deploying and evaluating advanced retrieval systems in large-scale,
real-world social platforms.

</details>


### [146] [Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval](https://arxiv.org/abs/2509.13626)
*Amanda Chan,James Jiayu Liu,He Kai,Onno P. Kampman*

Main category: cs.IR

TL;DR: 本文提出了一种基于AI的语料库扩充框架，该框架通过叠加自然用户数据来识别代表性不足的主题（空白），从而根据覆盖率和实用性确定扩展的优先级。


<details>
  <summary>Details</summary>
Motivation: 获取可靠的心理健康信息对于早期寻求帮助至关重要，但扩展知识库需要大量资源，并且常常与用户需求不符。当提出的问题未被涵盖或以非正式或情境化的语言表达时，导致检索系统性能不佳。

Method: 本文将定向扩充（有针对性的扩充）与非定向扩充（随机添加）进行了比较，评估了四种检索增强生成（RAG）管道中检索到的信息的相关性和实用性。

Result: 定向扩充以适度的扩展实现了接近最佳的性能，达到完整参考语料库约 95% 的性能所需的增幅为：查询转换增加 42%，重新排序和分层增加 74%，基线增加 318%。相比之下，非定向扩充需要更大且实际上不可行的扩展才能实现相当的性能（分别为 232%、318%、403% 和 763%）。

Conclusion: 有策略地进行有针对性的语料库增长可以减少内容创建需求，同时保持较高的检索和提供质量，从而为构建可信赖的健康信息存储库和在高风险领域中支持生成式人工智能应用提供了一种可扩展的方法。

Abstract: Access to reliable mental health information is vital for early help-seeking,
yet expanding knowledge bases is resource-intensive and often misaligned with
user needs. This results in poor performance of retrieval systems when
presented concerns are not covered or expressed in informal or contextualized
language. We present an AI-based gap-informed framework for corpus augmentation
that authentically identifies underrepresented topics (gaps) by overlaying
naturalistic user data such as forum posts in order to prioritize expansions
based on coverage and usefulness. In a case study, we compare Directed
(gap-informed augmentations) with Non-Directed augmentation (random additions),
evaluating the relevance and usefulness of retrieved information across four
retrieval-augmented generation (RAG) pipelines. Directed augmentation achieved
near-optimal performance with modest expansions--requiring only a 42% increase
for Query Transformation, 74% for Reranking and Hierarchical, and 318% for
Baseline--to reach ~95% of the performance of an exhaustive reference corpus.
In contrast, Non-Directed augmentation required substantially larger and thus
practically infeasible expansions to achieve comparable performance (232%,
318%, 403%, and 763%, respectively). These results show that strategically
targeted corpus growth can reduce content creation demands while sustaining
high retrieval and provision quality, offering a scalable approach for building
trusted health information repositories and supporting generative AI
applications in high-stakes domains.

</details>


### [147] [Enhancing Time Awareness in Generative Recommendation](https://arxiv.org/abs/2509.13957)
*Sunkyung Lee,Seongmin Park,Jonghyo Kim,Mincheol Yoon,Jongwuk Lee*

Main category: cs.IR

TL;DR: 本文提出了一种新的生成式推荐模型GRUT，该模型通过各种时间信号来有效捕捉隐藏的用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要集中在考虑项目的顺序，而忽略了处理项目之间的时间动态，而时间动态可能意味着不断变化的用户偏好。

Method: 该模型首先引入了时间感知提示，包括两个关键上下文：用户级别的时间上下文和项目级别的过渡上下文。还设计了一种趋势感知推理，这是一种无需训练的方法，通过结合关于项目的趋势信息和生成可能性来提高排名。

Result: 在四个基准数据集上，GRUT的性能优于最先进的模型，Recall@5 和 NDCG@5 分别提高了 15.4% 和 14.3%。

Conclusion: GRUT模型能够有效地捕捉隐藏的用户偏好，并在推荐性能上优于现有模型。

Abstract: Generative recommendation has emerged as a promising paradigm that formulates
the recommendations into a text-to-text generation task, harnessing the vast
knowledge of large language models. However, existing studies focus on
considering the sequential order of items and neglect to handle the temporal
dynamics across items, which can imply evolving user preferences. To address
this limitation, we propose a novel model, Generative Recommender Using Time
awareness (GRUT), effectively capturing hidden user preferences via various
temporal signals. We first introduce Time-aware Prompting, consisting of two
key contexts. The user-level temporal context models personalized temporal
patterns across timestamps and time intervals, while the item-level transition
context provides transition patterns across users. We also devise Trend-aware
Inference, a training-free method that enhances rankings by incorporating trend
information about items with generation likelihood. Extensive experiments
demonstrate that GRUT outperforms state-of-the-art models, with gains of up to
15.4% and 14.3% in Recall@5 and NDCG@5 across four benchmark datasets. The
source code is available at https://github.com/skleee/GRUT.

</details>


### [148] [GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing](https://arxiv.org/abs/2509.14221)
*Silan Hu,Shiqi Zhang,Yimin Shi,Xiaokui Xiao*

Main category: cs.IR

TL;DR: 提出了GEM-Bench，一个用于广告注入响应生成的综合基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基准不是专门为生成引擎营销（GEM）设计的，限制了未来的研究。

Method: 构建了包含chatbot和搜索场景的三个数据集，一个捕获用户满意度和参与度的指标本体，以及在可扩展的多代理框架中实现的几个基线解决方案。

Result: 简单的基于prompt的方法实现了合理的参与度（如点击率），但通常会降低用户满意度。基于预生成的无广告响应插入广告的方法有助于缓解这个问题，但会引入额外的开销。

Conclusion: 需要在设计更有效和高效的GEM广告注入响应生成解决方案方面进行未来的研究。

Abstract: Generative Engine Marketing (GEM) is an emerging ecosystem for monetizing
generative engines, such as LLM-based chatbots, by seamlessly integrating
relevant advertisements into their responses. At the core of GEM lies the
generation and evaluation of ad-injected responses. However, existing
benchmarks are not specifically designed for this purpose, which limits future
research. To address this gap, we propose GEM-Bench, the first comprehensive
benchmark for ad-injected response generation in GEM. GEM-Bench includes three
curated datasets covering both chatbot and search scenarios, a metric ontology
that captures multiple dimensions of user satisfaction and engagement, and
several baseline solutions implemented within an extensible multi-agent
framework. Our preliminary results indicate that, while simple prompt-based
methods achieve reasonable engagement such as click-through rate, they often
reduce user satisfaction. In contrast, approaches that insert ads based on
pre-generated ad-free responses help mitigate this issue but introduce
additional overhead. These findings highlight the need for future research on
designing more effective and efficient solutions for generating ad-injected
responses in GEM.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [149] [Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics](https://arxiv.org/abs/2509.13425)
*Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal*

Main category: cs.LG

TL;DR: 提出了一个名为 USPIL 的深度学习框架，用于模拟生态系统中的捕食者-猎物动态。


<details>
  <summary>Details</summary>
Motivation: 传统建模方法难以捕捉生态系统的复杂多尺度动态，需要新的方法。

Method: 该框架结合了物理信息神经网络 (PINN) 和守恒定律，统一解决常微分方程 (ODE) 和偏微分方程 (PDE) 系统。

Result: 在 Lotka-Volterra 系统中，USPIL 在 1D 时间动态方面实现了 98.9% 的相关性，并在 2D 系统中捕获了复杂的螺旋波。与数值求解器相比，推理速度提高了 10-50 倍。

Conclusion: USPIL 是一种变革性工具，可用于生态预测、保护规划和理解生态系统弹性，将物理信息深度学习确立为一种强大且科学严谨的范例。

Abstract: Ecological systems exhibit complex multi-scale dynamics that challenge
traditional modeling. New methods must capture temporal oscillations and
emergent spatiotemporal patterns while adhering to conservation principles. We
present the Unified Spatiotemporal Physics-Informed Learning (USPIL) framework,
a deep learning architecture integrating physics-informed neural networks
(PINNs) and conservation laws to model predator-prey dynamics across
dimensional scales. The framework provides a unified solution for both ordinary
(ODE) and partial (PDE) differential equation systems, describing temporal
cycles and reaction-diffusion patterns within a single neural network
architecture. Our methodology uses automatic differentiation to enforce physics
constraints and adaptive loss weighting to balance data fidelity with physical
consistency. Applied to the Lotka-Volterra system, USPIL achieves 98.9%
correlation for 1D temporal dynamics (loss: 0.0219, MAE: 0.0184) and captures
complex spiral waves in 2D systems (loss: 4.7656, pattern correlation: 0.94).
Validation confirms conservation law adherence within 0.5% and shows a 10-50x
computational speedup for inference compared to numerical solvers. USPIL also
enables mechanistic understanding through interpretable physics constraints,
facilitating parameter discovery and sensitivity analysis not possible with
purely data-driven methods. Its ability to transition between dimensional
formulations opens new avenues for multi-scale ecological modeling. These
capabilities make USPIL a transformative tool for ecological forecasting,
conservation planning, and understanding ecosystem resilience, establishing
physics-informed deep learning as a powerful and scientifically rigorous
paradigm.

</details>


### [150] [An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training](https://arxiv.org/abs/2509.13516)
*Tom Almog*

Main category: cs.LG

TL;DR: 该研究调查了优化器选择与神经网络训练能效之间的关系。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型日益复杂和计算密集，了解训练决策对环境的影响对于可持续AI发展至关重要。

Method: 在三个基准数据集（MNIST、CIFAR-10、CIFAR-100）上，使用八种流行的优化器（SGD、Adam、AdamW、RMSprop、Adagrad、Adadelta、Adamax、NAdam）进行了360次受控实验，每个优化器使用15个随机种子。使用CodeCarbon在Apple M1 Pro硬件上进行精确的能量跟踪，测量了训练持续时间、峰值内存使用量、二氧化碳排放量和最终模型性能。

Result: 研究结果揭示了训练速度、准确性和环境影响之间存在着权衡，并且这种权衡会随着数据集和模型复杂性的变化而变化。AdamW和NAdam是一贯有效的选择，而SGD在复杂数据集上表现出优异的性能，尽管排放量较高。

Conclusion: 这些结果为希望在机器学习工作流程中平衡性能和可持续性的从业者提供了可操作的见解。

Abstract: As machine learning models grow increasingly complex and computationally
demanding, understanding the environmental impact of training decisions becomes
critical for sustainable AI development. This paper presents a comprehensive
empirical study investigating the relationship between optimizer choice and
energy efficiency in neural network training. We conducted 360 controlled
experiments across three benchmark datasets (MNIST, CIFAR-10, CIFAR-100) using
eight popular optimizers (SGD, Adam, AdamW, RMSprop, Adagrad, Adadelta, Adamax,
NAdam) with 15 random seeds each. Using CodeCarbon for precise energy tracking
on Apple M1 Pro hardware, we measured training duration, peak memory usage,
carbon dioxide emissions, and final model performance. Our findings reveal
substantial trade-offs between training speed, accuracy, and environmental
impact that vary across datasets and model complexity. We identify AdamW and
NAdam as consistently efficient choices, while SGD demonstrates superior
performance on complex datasets despite higher emissions. These results provide
actionable insights for practitioners seeking to balance performance and
sustainability in machine learning workflows.

</details>


### [151] [Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework](https://arxiv.org/abs/2509.13520)
*Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出了一种混合 DeepONet-Transolver 框架，用于预测 PET 瓶屈曲分析中的节点位移场和反作用力的时间演变。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推广不同非参数几何域的解决方案方面受到限制。本文针对聚对苯二甲酸乙二醇酯 (PET) 瓶屈曲分析中的这一挑战，这是一个通常使用计算成本高昂的有限元分析 (FEA) 解决的典型包装设计问题。

Method: 引入了一种混合 DeepONet-Transolver 框架，该框架同时预测节点位移场和顶部载荷压缩期间反作用力的时间演变。使用 Abaqus 中的非线性 FEA 模拟生成训练数据。

Result: 对于四参数瓶系列，位移场的平均相对 L2 误差为 2.5-13%，时变反作用力的平均相对 L2 误差约为 2.4%。

Conclusion: 该框架有潜力成为一种可扩展且计算效率高的替代方案，特别是在计算力学和需要快速设计评估的应用中的多任务预测。

Abstract: Neural surrogates and operator networks for solving partial differential
equation (PDE) problems have attracted significant research interest in recent
years. However, most existing approaches are limited in their ability to
generalize solutions across varying non-parametric geometric domains. In this
work, we address this challenge in the context of Polyethylene Terephthalate
(PET) bottle buckling analysis, a representative packaging design problem
conventionally solved using computationally expensive finite element analysis
(FEA). We introduce a hybrid DeepONet-Transolver framework that simultaneously
predicts nodal displacement fields and the time evolution of reaction forces
during top load compression. Our methodology is evaluated on two families of
bottle geometries parameterized by two and four design variables. Training data
is generated using nonlinear FEA simulations in Abaqus for 254 unique designs
per family. The proposed framework achieves mean relative $L^{2}$ errors of
2.5-13% for displacement fields and approximately 2.4% for time-dependent
reaction forces for the four-parameter bottle family. Point-wise error analyses
further show absolute displacement errors on the order of $10^{-4}$-$10^{-3}$,
with the largest discrepancies confined to localized geometric regions.
Importantly, the model accurately captures key physical phenomena, such as
buckling behavior, across diverse bottle geometries. These results highlight
the potential of our framework as a scalable and computationally efficient
surrogate, particularly for multi-task predictions in computational mechanics
and applications requiring rapid design evaluation.

</details>


### [152] [Sequential Data Augmentation for Generative Recommendation](https://arxiv.org/abs/2509.13648)
*Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins*

Main category: cs.LG

TL;DR: 本文探讨了生成式推荐系统中数据增强的重要性，并提出了一个通用框架GenPAS。


<details>
  <summary>Details</summary>
Motivation: 现有的数据增强方法不够系统和有原则，不同策略效果差异大。

Method: 提出了GenPAS框架，将数据增强建模为输入-目标对的随机抽样过程，包含序列抽样、目标抽样和输入抽样三个步骤。

Result: GenPAS在基准和工业数据集上表现出更高的准确性、数据效率和参数效率。

Conclusion: GenPAS为生成式推荐系统中基于原则的训练数据构建提供了实践指导。

Abstract: Generative recommendation plays a crucial role in personalized systems,
predicting users' future interactions from their historical behavior sequences.
A critical yet underexplored factor in training these models is data
augmentation, the process of constructing training data from user interaction
histories. By shaping the training distribution, data augmentation directly and
often substantially affects model generalization and performance. Nevertheless,
in much of the existing work, this process is simplified, applied
inconsistently, or treated as a minor design choice, without a systematic and
principled understanding of its effects.
  Motivated by our empirical finding that different augmentation strategies can
yield large performance disparities, we conduct an in-depth analysis of how
they reshape training distributions and influence alignment with future targets
and generalization to unseen inputs. To systematize this design space, we
propose GenPAS, a generalized and principled framework that models augmentation
as a stochastic sampling process over input-target pairs with three
bias-controlled steps: sequence sampling, target sampling, and input sampling.
This formulation unifies widely used strategies as special cases and enables
flexible control of the resulting training distribution. Our extensive
experiments on benchmark and industrial datasets demonstrate that GenPAS yields
superior accuracy, data efficiency, and parameter efficiency compared to
existing strategies, providing practical guidance for principled training data
construction in generative recommendation.

</details>


### [153] [AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions](https://arxiv.org/abs/2509.13523)
*Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi*

Main category: cs.LG

TL;DR: 这篇论文介绍了一种新的、可扩展的扩散模型AERIS，用于天气和气候预测。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在天气预报中表现出优势，但在高分辨率下难以稳定扩展。

Method: 论文提出了AERIS，一个基于Swin diffusion transformer的模型，并结合了SWiPe并行技术。

Result: AERIS在Aurora上实现了高性能和良好的扩展性，并在季节尺度上优于IFS ENS。

Conclusion: 结果表明，数十亿参数的扩散模型在天气和气候预测方面具有潜力。

Abstract: Generative machine learning offers new opportunities to better understand
complex Earth system dynamics. Recent diffusion-based methods address spectral
biases and improve ensemble calibration in weather forecasting compared to
deterministic methods, yet have so far proven difficult to scale stably at high
resolutions. We introduce AERIS, a 1.3 to 80B parameter pixel-level Swin
diffusion transformer to address this gap, and SWiPe, a generalizable technique
that composes window parallelism with sequence and pipeline parallelism to
shard window-based transformers without added communication cost or increased
global batch size. On Aurora (10,080 nodes), AERIS sustains 10.21 ExaFLOPS
(mixed precision) and a peak performance of 11.21 ExaFLOPS with $1 \times 1$
patch size on the 0.25{\deg} ERA5 dataset, achieving 95.5% weak scaling
efficiency, and 81.6% strong scaling efficiency. AERIS outperforms the IFS ENS
and remains stable on seasonal scales to 90 days, highlighting the potential of
billion-parameter diffusion models for weather and climate prediction.

</details>


### [154] [Meta-Learning Linear Models for Molecular Property Prediction](https://arxiv.org/abs/2509.13527)
*Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers*

Main category: cs.LG

TL;DR: LAMeL: A meta-learning algorithm for chemical property prediction.


<details>
  <summary>Details</summary>
Motivation: Limited high-quality chemical datasets challenge structure-property relationship studies. Explainable AI (XAI) is needed to bridge the gap between accuracy and interpretability.

Method: A linear meta-learning algorithm (LAMeL) identifies shared model parameters across related tasks to learn a common functional manifold.

Result: LAMeL improves performance by 1.1- to 25-fold over standard ridge regression.

Conclusion: LAMeL is a reliable tool for chemical property prediction, balancing accuracy and interpretability.

Abstract: Chemists in search of structure-property relationships face great challenges
due to limited high quality, concordant datasets. Machine learning (ML) has
significantly advanced predictive capabilities in chemical sciences, but these
modern data-driven approaches have increased the demand for data. In response
to the growing demand for explainable AI (XAI) and to bridge the gap between
predictive accuracy and human comprehensibility, we introduce LAMeL - a Linear
Algorithm for Meta-Learning that preserves interpretability while improving the
prediction accuracy across multiple properties. While most approaches treat
each chemical prediction task in isolation, LAMeL leverages a meta-learning
framework to identify shared model parameters across related tasks, even if
those tasks do not share data, allowing it to learn a common functional
manifold that serves as a more informed starting point for new unseen tasks.
Our method delivers performance improvements ranging from 1.1- to 25-fold over
standard ridge regression, depending on the domain of the dataset. While the
degree of performance enhancement varies across tasks, LAMeL consistently
outperforms or matches traditional linear methods, making it a reliable tool
for chemical property prediction where both accuracy and interpretability are
critical.

</details>


### [155] [Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection](https://arxiv.org/abs/2509.13608)
*Niruthiha Selvanayagam,Ted Kurti*

Main category: cs.LG

TL;DR: GPT-4o mini模型在多模态仇恨言论检测中存在“单模态瓶颈”，导致其高级多模态推理被上下文无关的安全过滤器所阻断。


<details>
  <summary>Details</summary>
Motivation: 理解大型多模态模型(LMMs)的安全架构对于人工智能对齐至关重要，尤其是在它们日益融入日常数字生活的背景下。

Method: 对OpenAI的GPT-4o mini模型，使用Hateful Memes Challenge数据集的500个样本，进行多阶段研究，以探究其推理和失败模式。

Result: 实验发现模型存在“单模态瓶颈”，其安全过滤器会阻断多模态推理。定量验证表明，50%的视觉内容和50%的文本内容会触发内容策略拒绝。该安全系统脆弱，不仅阻止高风险图像，还会阻止良性和常见的meme格式，导致可预测的假阳性。

Conclusion: LMMs的能力和安全性之间存在根本张力，需要更集成、上下文感知的对齐策略，以确保AI系统能够安全有效地部署。

Abstract: As Large Multimodal Models (LMMs) become integral to daily digital life,
understanding their safety architectures is a critical problem for AI
Alignment. This paper presents a systematic analysis of OpenAI's GPT-4o mini, a
globally deployed model, on the difficult task of multimodal hate speech
detection. Using the Hateful Memes Challenge dataset, we conduct a multi-phase
investigation on 500 samples to probe the model's reasoning and failure modes.
Our central finding is the experimental identification of a "Unimodal
Bottleneck," an architectural flaw where the model's advanced multimodal
reasoning is systematically preempted by context-blind safety filters. A
quantitative validation of 144 content policy refusals reveals that these
overrides are triggered in equal measure by unimodal visual 50% and textual 50%
content. We further demonstrate that this safety system is brittle, blocking
not only high-risk imagery but also benign, common meme formats, leading to
predictable false positives. These findings expose a fundamental tension
between capability and safety in state-of-the-art LMMs, highlighting the need
for more integrated, context-aware alignment strategies to ensure AI systems
can be deployed both safely and effectively.

</details>


### [156] [Unsupervised Anomaly Detection in ALS EPICS Event Logs](https://arxiv.org/abs/2509.13621)
*Antonin Sulc,Thorsten Hellert,Steven Hunt*

Main category: cs.LG

TL;DR: 本文介绍了一种自动故障分析框架，用于处理 EPICS 控制系统的实时事件日志。


<details>
  <summary>Details</summary>
Motivation: 为了快速识别导致复杂系统故障的关键事件序列。

Method: 该方法使用语义嵌入技术将日志条目转换为上下文向量表示，并使用在正常操作数据上训练的序列感知神经网络为每个事件分配实时异常分数。

Result: 该方法可以标记与基线行为的偏差。

Conclusion: 该框架使操作员能够快速识别导致复杂系统故障的关键事件序列。

Abstract: This paper introduces an automated fault analysis framework for the Advanced
Light Source (ALS) that processes real-time event logs from its EPICS control
system. By treating log entries as natural language, we transform them into
contextual vector representations using semantic embedding techniques. A
sequence-aware neural network, trained on normal operational data, assigns a
real-time anomaly score to each event. This method flags deviations from
baseline behavior, enabling operators to rapidly identify the critical event
sequences that precede complex system failures.

</details>


### [157] [Privacy-Aware In-Context Learning for Large Language Models](https://arxiv.org/abs/2509.13625)
*Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的私有预测框架，用于生成具有强大隐私保证的高质量合成文本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自然语言理解和生成方面发生了重大转变，但由于可能暴露敏感信息，它们引发了隐私问题。研究强调了信息泄露的风险，攻击者可以提取嵌入在提示中的敏感信息。

Method: 该方法利用差分隐私（DP）框架，以确保信息泄露的最坏情况理论界限，而无需对底层模型进行任何微调。该方法对私有记录执行推理，并聚合生成的每token输出分布。此外，我们提出了一种简单的混合操作，将私有和公共推理相结合，以进一步提高效用。

Result: 经验评估表明，我们的方法在上下文学习（ICL）任务上优于以前的最先进方法。

Conclusion: 该方法为保持高实用性的同时，保护隐私的文本生成提供了一个有希望的方向。

Abstract: Large language models (LLMs) have significantly transformed natural language
understanding and generation, but they raise privacy concerns due to potential
exposure of sensitive information. Studies have highlighted the risk of
information leakage, where adversaries can extract sensitive information
embedded in the prompts. In this work, we introduce a novel private prediction
framework for generating high-quality synthetic text with strong privacy
guarantees. Our approach leverages the Differential Privacy (DP) framework to
ensure worst-case theoretical bounds on information leakage without requiring
any fine-tuning of the underlying models.The proposed method performs inference
on private records and aggregates the resulting per-token output distributions.
This enables the generation of longer and coherent synthetic text while
maintaining privacy guarantees. Additionally, we propose a simple blending
operation that combines private and public inference to further enhance
utility. Empirical evaluations demonstrate that our approach outperforms
previous state-of-the-art methods on in-context-learning (ICL) tasks, making it
a promising direction for privacy-preserving text generation while maintaining
high utility.

</details>


### [158] [DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis](https://arxiv.org/abs/2509.13633)
*Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng*

Main category: cs.LG

TL;DR: 提出了一种用于交通政策分析的 DeepLogit 模型，该模型通过 последовательно 约束方法估计深度学习模型，以在保持可解释性的同时提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在规划和政策相关领域的应用因其黑盒性质而具有挑战性。

Method: 首先，估计一个只有线性项的卷积神经网络 (CNN) 模型，这相当于一个线性参数多项 Logit 模型。然后，通过约束需要在线性参数 CNN 模型中获得的值的可解释性参数，并包括高阶项或引入高级深度学习架构（如 Transformers）来估计其他深度学习模型。

Result: 在新加坡的公交线路选择示例中，该方法验证了统一方法（基于理论的离散选择模型 (DCM) 和数据驱动的 AI 模型可以相互利用在可解释性和预测能力方面的优势）的潜力。

Conclusion: 该研究表明，通过更大的数据集和更复杂的结构，这种方法可以使用离散选择模型获得更准确的模型，同时保持其在规划和政策相关领域的适用性。

Abstract: Despite the significant progress of deep learning models in multitude of
applications, their adaption in planning and policy related areas remains
challenging due to the black-box nature of these models. In this work, we
develop a set of DeepLogit models that follow a novel sequentially constrained
approach in estimating deep learning models for transport policy analysis. In
the first step of the proposed approach, we estimate a convolutional neural
network (CNN) model with only linear terms, which is equivalent of a
linear-in-parameter multinomial logit model. We then estimate other deep
learning models by constraining the parameters that need interpretability at
the values obtained in the linear-in-parameter CNN model and including higher
order terms or by introducing advanced deep learning architectures like
Transformers. Our approach can retain the interpretability of the selected
parameters, yet provides significantly improved model accuracy than the
discrete choice model. We demonstrate our approach on a transit route choice
example using real-world transit smart card data from Singapore. This study
shows the potential for a unifying approach, where theory-based discrete choice
model (DCM) and data-driven AI models can leverage each other's strengths in
interpretability and predictive power. With the availability of larger datasets
and more complex constructions, such approach can lead to more accurate models
using discrete choice models while maintaining its applicability in planning
and policy-related areas. Our code is available on
https://github.com/jeremyoon/route-choice/ .

</details>


### [159] [Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs](https://arxiv.org/abs/2509.13634)
*Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种结合数字孪生（DT）技术和零知识联邦学习（zkFed）的创新框架，以解决无人机辅助联邦学习（FL）系统中存在的能耗过高、通信效率低下和安全漏洞等问题。


<details>
  <summary>Details</summary>
Motivation: 为了确保无人机辅助联邦学习系统可靠运行，必须解决能耗、通信和安全问题。

Method: 该方法结合数字孪生技术，实现实时监控和预测性维护，并通过零知识证明（ZKP）增强安全性。同时，引入动态分配策略，调整无人机飞行路径、传输功率和处理速率。

Result: 与传统联邦学习方法相比，该方法可显著降低高达 29.6% 的系统能耗。仿真结果表明，学习性能、安全性和可扩展性均得到提高。

Conclusion: 该框架是下一代基于无人机的智能网络的有前途的解决方案。

Abstract: Federated learning (FL) has gained popularity as a privacy-preserving method
of training machine learning models on decentralized networks. However to
ensure reliable operation of UAV-assisted FL systems, issues like as excessive
energy consumption, communication inefficiencies, and security vulnerabilities
must be solved. This paper proposes an innovative framework that integrates
Digital Twin (DT) technology and Zero-Knowledge Federated Learning (zkFed) to
tackle these challenges. UAVs act as mobile base stations, allowing scattered
devices to train FL models locally and upload model updates for aggregation. By
incorporating DT technology, our approach enables real-time system monitoring
and predictive maintenance, improving UAV network efficiency. Additionally,
Zero-Knowledge Proofs (ZKPs) strengthen security by allowing model verification
without exposing sensitive data. To optimize energy efficiency and resource
management, we introduce a dynamic allocation strategy that adjusts UAV flight
paths, transmission power, and processing rates based on network conditions.
Using block coordinate descent and convex optimization techniques, our method
significantly reduces system energy consumption by up to 29.6% compared to
conventional FL approaches. Simulation results demonstrate improved learning
performance, security, and scalability, positioning this framework as a
promising solution for next-generation UAV-based intelligent networks.

</details>


### [160] [Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images](https://arxiv.org/abs/2509.13636)
*Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari*

Main category: cs.LG

TL;DR: 本研究提出了一种新的方法，将多模态生理信号转换为2D图像矩阵，以提高使用卷积神经网络(CNNs)进行压力检测的效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常单独处理这些信号或依赖于固定编码，而本文旨在通过将这些信号融合到结构化图像表示中，使CNNs能够更有效地捕获时间和跨信号依赖性。

Method: 将多模态生理信号转换为2D图像矩阵，并系统地将融合信号重组为多种格式，在多阶段训练管道中组合它们。

Result: 该方法显著提高了分类性能。

Conclusion: 该方法广泛适用于任何涉及多模态生理信号的领域，为通过可穿戴技术实现更准确、个性化和实时的健康监测铺平了道路。

Abstract: This study introduces a novel method that transforms multimodal physiological
signalsphotoplethysmography (PPG), galvanic skin response (GSR), and
acceleration (ACC) into 2D image matrices to enhance stress detection using
convolutional neural networks (CNNs). Unlike traditional approaches that
process these signals separately or rely on fixed encodings, our technique
fuses them into structured image representations that enable CNNs to capture
temporal and cross signal dependencies more effectively. This image based
transformation not only improves interpretability but also serves as a robust
form of data augmentation. To further enhance generalization and model
robustness, we systematically reorganize the fused signals into multiple
formats, combining them in a multi stage training pipeline. This approach
significantly boosts classification performance. While demonstrated here in the
context of stress detection, the proposed method is broadly applicable to any
domain involving multimodal physiological signals, paving the way for more
accurate, personalized, and real time health monitoring through wearable
technologies.

</details>


### [161] [LLM-I: LLMs are Naturally Interleaved Multimodal Creators](https://arxiv.org/abs/2509.13642)
*Zirun Guo,Feng Zhang,Kai Jia,Tao Jin*

Main category: cs.LG

TL;DR: LLM-I: A framework using LLMs to orchestrate specialized visual tools for interleaved image-text generation, overcoming limitations of current unified models.


<details>
  <summary>Details</summary>
Motivation: Current unified models for interleaved image-text generation are limited to synthetic imagery and struggle with tasks requiring factual grounding or programmatic precision.

Method: A central LLM/MLLM agent intelligently orchestrates a diverse toolkit of specialized visual tools, trained via Reinforcement Learning (RL) with a hybrid reward system.

Result: LLM-I demonstrates state-of-the-art performance, outperforming existing methods by a large margin across four benchmarks. A novel test-time scaling strategy further improves performance.

Conclusion: LLM-I is a flexible and dynamic framework that reframes interleaved image-text generation as a tool-use problem, achieving state-of-the-art results.

Abstract: We propose LLM-Interleaved (LLM-I), a flexible and dynamic framework that
reframes interleaved image-text generation as a tool-use problem. LLM-I is
designed to overcome the "one-tool" bottleneck of current unified models, which
are limited to synthetic imagery and struggle with tasks requiring factual
grounding or programmatic precision. Our framework empowers a central LLM or
MLLM agent to intelligently orchestrate a diverse toolkit of specialized visual
tools, including online image search, diffusion-based generation, code
execution, and image editing. The agent is trained to select and apply these
tools proficiently via a Reinforcement Learning (RL) framework that features a
hybrid reward system combining rule-based logic with judgments from LLM and
MLLM evaluators. Trained on a diverse new dataset using four different model
backbones, LLM-I demonstrates state-of-the-art performance, outperforming
existing methods by a large margin across four benchmarks. We also introduce a
novel test-time scaling strategy that provides further performance gains.
Project Page: https://github.com/ByteDance-BandAI/LLM-I.

</details>


### [162] [Controllable Pareto Trade-off between Fairness and Accuracy](https://arxiv.org/abs/2509.13651)
*Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou*

Main category: cs.LG

TL;DR: 当前NLP任务中的公平性-准确性权衡是一个关键挑战。目前的工作主要集中在寻找一个单一的“最优”解决方案来平衡这两个目标，但考虑到帕累托前沿的多样化解决方案，这种方法具有局限性。这项工作旨在根据用户对这两个目标的偏好（定义为参考向量）来提供可控的权衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决NLP任务中公平性与准确性之间的权衡问题，并且考虑到帕累托前沿的多样化解决方案，这项工作旨在提供可控的权衡，以适应用户对公平性和准确性的不同偏好。

Method: 应用多目标优化（MOO）来寻找帕累托前沿不同区域的解决方案。为了精确控制权衡，提出了可控帕累托权衡（CPT）方法，该方法通过移动平均随机梯度来稳定公平性更新，并通过仅保留关键参数的梯度来修剪梯度。

Result: 在仇恨言论检测和职业分类任务上的实验表明，CPT可以在帕累托前沿上实现比基线方法更高质量的解决方案集。它还表现出更好的可控性，并且可以精确地遵循人为定义的参考向量。

Conclusion: CPT方法能够有效地训练模型，以根据用户的偏好执行不同的权衡，并在公平性和准确性之间取得更好的平衡。

Abstract: The fairness-accuracy trade-off is a key challenge in NLP tasks. Current work
focuses on finding a single "optimal" solution to balance the two objectives,
which is limited considering the diverse solutions on the Pareto front. This
work intends to provide controllable trade-offs according to the user's
preference of the two objectives, which is defined as a reference vector. To
achieve this goal, we apply multi-objective optimization (MOO), which can find
solutions from various regions of the Pareto front. However, it is challenging
to precisely control the trade-off due to the stochasticity of the training
process and the high dimentional gradient vectors. Thus, we propose
Controllable Pareto Trade-off (CPT) that can effectively train models to
perform different trade-offs according to users' preferences. CPT 1) stabilizes
the fairness update with a moving average of stochastic gradients to determine
the update direction, and 2) prunes the gradients by only keeping the gradients
of the critical parameters. We evaluate CPT on hate speech detection and
occupation classification tasks. Experiments show that CPT can achieve a
higher-quality set of solutions on the Pareto front than the baseline methods.
It also exhibits better controllability and can precisely follow the
human-defined reference vectors.

</details>


### [163] [RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization](https://arxiv.org/abs/2509.13686)
*Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang*

Main category: cs.LG

TL;DR: 提出了一种新的无线信道建模框架RF-LSCM，用于克服传统LSCM方法在单小区、单网格和单载波频率分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的LSCM方法在单小区、单网格和单载波频率分析中存在局限性，无法捕捉复杂的跨域交互。

Method: 通过在辐射场中联合表示大规模信号衰减和多径分量来建模信道APS。引入了多域LSCM公式，利用物理信息驱动的频率相关衰减模型（FDAM）来促进跨频率泛化，并采用点云辅助环境增强方法来实现多小区和多网格信道建模。利用低秩张量表示和分层张量角度建模（HiTAM）算法来解决神经辐射场的计算效率问题。

Result: 在真实世界的多小区数据集上的大量实验表明，RF-LSCM 显著优于最先进的方法，在覆盖预测的平均绝对误差（MAE）降低了 30%，并通过有效地融合多频数据，MAE 提高了 22%。

Conclusion: RF-LSCM 显著优于现有技术，并在覆盖预测和多频数据融合方面取得了显著的改进。

Abstract: Accurate localized wireless channel modeling is a cornerstone of cellular
network optimization, enabling reliable prediction of network performance
during parameter tuning. Localized statistical channel modeling (LSCM) is the
state-of-the-art channel modeling framework tailored for cellular network
optimization. However, traditional LSCM methods, which infer the channel's
Angular Power Spectrum (APS) from Reference Signal Received Power (RSRP)
measurements, suffer from critical limitations: they are typically confined to
single-cell, single-grid and single-carrier frequency analysis and fail to
capture complex cross-domain interactions. To overcome these challenges, we
propose RF-LSCM, a novel framework that models the channel APS by jointly
representing large-scale signal attenuation and multipath components within a
radiance field. RF-LSCM introduces a multi-domain LSCM formulation with a
physics-informed frequency-dependent Attenuation Model (FDAM) to facilitate the
cross frequency generalization as well as a point-cloud-aided environment
enhanced method to enable multi-cell and multi-grid channel modeling.
Furthermore, to address the computational inefficiency of typical neural
radiance fields, RF-LSCM leverages a low-rank tensor representation,
complemented by a novel Hierarchical Tensor Angular Modeling (HiTAM) algorithm.
This efficient design significantly reduces GPU memory requirements and
training time while preserving fine-grained accuracy. Extensive experiments on
real-world multi-cell datasets demonstrate that RF-LSCM significantly
outperforms state-of-the-art methods, achieving up to a 30% reduction in mean
absolute error (MAE) for coverage prediction and a 22% MAE improvement by
effectively fusing multi-frequency data.

</details>


### [164] [A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks](https://arxiv.org/abs/2509.13717)
*Yifan Yu,Cheuk Hin Ho,Yangshuai Wang*

Main category: cs.LG

TL;DR: 提出了一种用于 PINN 的、具有严格统计保证的无分布一致预测 (CP) 框架，以解决现有 PINN 的不确定性量化 (UQ) 方法普遍缺乏严格统计保证的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的 PINN 的不确定性量化 (UQ) 方法普遍缺乏严格的统计保证。

Method: 通过在校准集上构建不一致性评分来校准预测区间，从而为 PINN 提供具有严格有限样本覆盖保证的无分布不确定性估计。为了处理空间异方差性，我们进一步引入了局部一致分位数估计，从而实现空间自适应不确定性带，同时保留理论保证。

Result: 在典型 PDE（阻尼谐波振荡器、Poisson、Allen-Cahn 和 Helmholtz 方程）上的系统评估以及跨多个不确定性指标的全面测试表明，所提出的框架实现了可靠的校准和局部自适应不确定性区间，始终优于启发式 UQ 方法。

Conclusion: 通过将 PINN 与无分布 UQ 连接起来，这项工作引入了一个通用框架，该框架不仅增强了校准和可靠性，而且为复杂 PDE 系统的感知不确定性建模开辟了新途径。

Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful framework
for solving PDEs, yet existing uncertainty quantification (UQ) approaches for
PINNs generally lack rigorous statistical guarantees. In this work, we bridge
this gap by introducing a distribution-free conformal prediction (CP) framework
for UQ in PINNs. This framework calibrates prediction intervals by constructing
nonconformity scores on a calibration set, thereby yielding distribution-free
uncertainty estimates with rigorous finite-sample coverage guarantees for
PINNs. To handle spatial heteroskedasticity, we further introduce local
conformal quantile estimation, enabling spatially adaptive uncertainty bands
while preserving theoretical guarantee. Through systematic evaluations on
typical PDEs (damped harmonic oscillator, Poisson, Allen-Cahn, and Helmholtz
equations) and comprehensive testing across multiple uncertainty metrics, our
results demonstrate that the proposed framework achieves reliable calibration
and locally adaptive uncertainty intervals, consistently outperforming
heuristic UQ approaches. By bridging PINNs with distribution-free UQ, this work
introduces a general framework that not only enhances calibration and
reliability, but also opens new avenues for uncertainty-aware modeling of
complex PDE systems.

</details>


### [165] [WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data](https://arxiv.org/abs/2509.13725)
*Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes*

Main category: cs.LG

TL;DR: 本研究利用智能手表系统，对社交焦虑大学生进行日常状态焦虑的预测。


<details>
  <summary>Details</summary>
Motivation: 目前对于社交情境中焦虑的日内波动研究较少，而捕捉这些动态变化对于设计实时、个性化的干预措施至关重要。

Method: 通过定制的智能手表系统，收集参与者的心率数据和每日七次的生态瞬时评估（EMA）来报告状态焦虑。构建了一个基础模型，并将其迁移到本研究的数据集上进行微调，结合特质水平的测量，生成概率预测。

Result: 在研究数据集中，状态焦虑检测的平衡准确率达到60.4%。在TILES-18数据集的独立保留集中，该方法达到了59.1%的平衡准确率，优于以往的研究至少7%。

Conclusion: 该研究表明，利用智能手表系统和机器学习方法可以有效地预测社交焦虑大学生的日常状态焦虑。

Abstract: Social anxiety is a common mental health condition linked to significant
challenges in academic, social, and occupational functioning. A core feature is
elevated momentary (state) anxiety in social situations, yet little prior work
has measured or predicted fluctuations in this anxiety throughout the day.
Capturing these intra-day dynamics is critical for designing real-time,
personalized interventions such as Just-In-Time Adaptive Interventions
(JITAIs). To address this gap, we conducted a study with socially anxious
college students (N=91; 72 after exclusions) using our custom smartwatch-based
system over an average of 9.03 days (SD = 2.95). Participants received seven
ecological momentary assessments (EMAs) per day to report state anxiety. We
developed a base model on over 10,000 days of external heart rate data,
transferred its representations to our dataset, and fine-tuned it to generate
probabilistic predictions. These were combined with trait-level measures in a
meta-learner. Our pipeline achieved 60.4% balanced accuracy in state anxiety
detection in our dataset. To evaluate generalizability, we applied the training
approach to a separate hold-out set from the TILES-18 dataset-the same dataset
used for pretraining. On 10,095 once-daily EMAs, our method achieved 59.1%
balanced accuracy, outperforming prior work by at least 7%.

</details>


### [166] [State Space Models over Directed Graphs](https://arxiv.org/abs/2509.13735)
*Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang*

Main category: cs.LG

TL;DR: 本文提出了一种新的有向图神经网络架构DirGraphSSM，它通过k跳自我图对有向图进行序列化，并在有向图上实现状态空间模型。


<details>
  <summary>Details</summary>
Motivation: 现有的图神经网络和图Transformer在处理有向图时，难以有效捕捉长程因果依赖关系，并且在大规模图数据集上训练时，准确率和效率难以兼顾。现有的图状态空间模型仅适用于无向图。

Method: 提出DirEgo2Token方法，通过k跳自我图将有向图序列化。构建了DirGraphSSM，一种新型有向图神经网络架构，通过消息传递机制在有向图上实现状态空间模型。

Result: DirGraphSSM在三个有代表性的有向图学习任务上取得了最先进的性能，并在另外两个任务上取得了有竞争力的性能，同时训练速度提高了1.5倍至2倍。

Conclusion: DirGraphSSM是第一个将状态空间模型扩展到有向图学习领域的系统性尝试。

Abstract: Directed graphs are ubiquitous across numerous domains, where the
directionality of edges encodes critical causal dependencies. However, existing
GNNs and graph Transformers tailored for directed graphs face two major
challenges: (1) effectively capturing long-range causal dependencies derived
from directed edges; (2) balancing accuracy and training efficiency when
processing large-scale graph datasets. In recent years, state space models
(SSMs) have achieved substantial progress in causal sequence tasks, and their
variants designed for graphs have demonstrated state-of-the-art accuracy while
maintaining high efficiency across various graph learning benchmarks. However,
existing graph state space models are exclusively designed for undirected
graphs, which limits their performance in directed graph learning. To this end,
we propose an innovative approach DirEgo2Token which sequentializes directed
graphs via k-hop ego graphs. This marks the first systematic extension of state
space models to the field of directed graph learning. Building upon this, we
develop DirGraphSSM, a novel directed graph neural network architecture that
implements state space models on directed graphs via the message-passing
mechanism. Experimental results demonstrate that DirGraphSSM achieves
state-of-the-art performance on three representative directed graph learning
tasks while attaining competitive performance on two additional tasks with
1.5$\times $ to 2$\times $ training speed improvements compared to existing
state-of-the-art models.

</details>


### [167] [ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning](https://arxiv.org/abs/2509.13739)
*Zihou Wu,Yuecheng Li,Tianchi Liao,Jian Lou,Chuan Chen*

Main category: cs.LG

TL;DR: ParaAegis: A parallel protection framework gives flexible control over the privacy-utility-efficiency balance.


<details>
  <summary>Details</summary>
Motivation: Existing protection mechanisms like differential privacy (DP) and homomorphic encryption (HE) enforce a rigid trade-off, forcing a choice between model utility and computational efficiency, which hinders the practical implementation.

Method: Strategic model partitioning scheme: applying lightweight DP to the less critical, low norm portion of the model while protecting the remainder with HE, we create a tunable system. A distributed voting mechanism ensures consensus on this partitioning.

Result: The experimental results demonstrate that by adjusting the hyperparameters, their method enables flexible prioritization between model accuracy and training time.

Conclusion: The adjustments between efficiency and utility with the same privacy are confirmed by theoretical analysis.

Abstract: Federated learning (FL) faces a critical dilemma: existing protection
mechanisms like differential privacy (DP) and homomorphic encryption (HE)
enforce a rigid trade-off, forcing a choice between model utility and
computational efficiency. This lack of flexibility hinders the practical
implementation. To address this, we introduce ParaAegis, a parallel protection
framework designed to give practitioners flexible control over the
privacy-utility-efficiency balance. Our core innovation is a strategic model
partitioning scheme. By applying lightweight DP to the less critical, low norm
portion of the model while protecting the remainder with HE, we create a
tunable system. A distributed voting mechanism ensures consensus on this
partitioning. Theoretical analysis confirms the adjustments between efficiency
and utility with the same privacy. Crucially, the experimental results
demonstrate that by adjusting the hyperparameters, our method enables flexible
prioritization between model accuracy and training time.

</details>


### [168] [ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2509.13753)
*Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko*

Main category: cs.LG

TL;DR: ST-LINK: Enhances LLMs for traffic forecasting by improving spatio-temporal dependency capture.


<details>
  <summary>Details</summary>
Motivation: LLMs struggle with spatial dependencies in traffic forecasting due to their sequential nature and incompatibility with graph data.

Method: Introduces Spatially-Enhanced Attention (SE-Attention) and Memory Retrieval Feed-Forward Network (MRFFN) to capture spatio-temporal dependencies.

Result: ST-LINK outperforms conventional deep learning and LLM approaches on benchmark datasets.

Conclusion: ST-LINK effectively captures both regular traffic patterns and abrupt changes.

Abstract: Traffic forecasting represents a crucial problem within intelligent
transportation systems. In recent research, Large Language Models (LLMs) have
emerged as a promising method, but their intrinsic design, tailored primarily
for sequential token processing, introduces notable challenges in effectively
capturing spatial dependencies. Specifically, the inherent limitations of LLMs
in modeling spatial relationships and their architectural incompatibility with
graph-structured spatial data remain largely unaddressed. To overcome these
limitations, we introduce ST-LINK, a novel framework that enhances the
capability of Large Language Models to capture spatio-temporal dependencies.
Its key components are Spatially-Enhanced Attention (SE-Attention) and the
Memory Retrieval Feed-Forward Network (MRFFN). SE-Attention extends rotary
position embeddings to integrate spatial correlations as direct rotational
transformations within the attention mechanism. This approach maximizes spatial
learning while preserving the LLM's inherent sequential processing structure.
Meanwhile, MRFFN dynamically retrieves and utilizes key historical patterns to
capture complex temporal dependencies and improve the stability of long-term
forecasting. Comprehensive experiments on benchmark datasets demonstrate that
ST-LINK surpasses conventional deep learning and LLM approaches, and
effectively captures both regular traffic patterns and abrupt changes.

</details>


### [169] [Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning](https://arxiv.org/abs/2509.13763)
*Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的多视图无监督特征选择方法CAUSA，该方法通过因果正则化模块分离混淆因子，减轻虚假相关性，从而选择因果信息特征。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图无监督特征选择方法忽略了混淆因子导致的虚假相关性，可能选择不相关的特征。

Method: 1. 采用广义无监督谱回归模型，通过捕捉特征和一致性聚类标签之间的依赖关系来识别信息丰富的特征。
2. 引入因果正则化模块，自适应地从多视图数据中分离混淆因子，并同时学习视图共享的样本权重以平衡混淆因子分布，从而减轻虚假相关性。
3. 将两者整合到一个统一的学习框架中，使CAUSA能够选择因果信息特征。

Result: 综合实验表明，CAUSA优于几种最先进的方法。

Conclusion: 这是首次在无监督设置中对因果多视图特征选择进行深入研究。

Abstract: Multi-view unsupervised feature selection (MUFS) has recently received
increasing attention for its promising ability in dimensionality reduction on
multi-view unlabeled data. Existing MUFS methods typically select
discriminative features by capturing correlations between features and
clustering labels. However, an important yet underexplored question remains:
\textit{Are such correlations sufficiently reliable to guide feature
selection?} In this paper, we analyze MUFS from a causal perspective by
introducing a novel structural causal model, which reveals that existing
methods may select irrelevant features because they overlook spurious
correlations caused by confounders. Building on this causal perspective, we
propose a novel MUFS method called CAusal multi-view Unsupervised feature
Selection leArning (CAUSA). Specifically, we first employ a generalized
unsupervised spectral regression model that identifies informative features by
capturing dependencies between features and consensus clustering labels. We
then introduce a causal regularization module that can adaptively separate
confounders from multi-view data and simultaneously learn view-shared sample
weights to balance confounder distributions, thereby mitigating spurious
correlations. Thereafter, integrating both into a unified learning framework
enables CAUSA to select causally informative features. Comprehensive
experiments demonstrate that CAUSA outperforms several state-of-the-art
methods. To our knowledge, this is the first in-depth study of causal
multi-view feature selection in the unsupervised setting.

</details>


### [170] [Floating-Body Hydrodynamic Neural Networks](https://arxiv.org/abs/2509.13783)
*Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing*

Main category: cs.LG

TL;DR: 提出了浮体水动力神经网络（FHNN），一种物理结构化的框架，用于预测可解释的水动力参数，并将其与运动解析方程相结合。


<details>
  <summary>Details</summary>
Motivation: 在工程和自然系统中，流固耦合很常见，其中浮体运动受附加质量、阻力和背景流控制。对这些耗散动力学进行建模是困难的：黑盒神经模型回归状态导数，具有有限的可解释性和不稳定的长期预测。

Method: 提出浮体水动力神经网络（FHNN），预测可解释的 гидродинамические 参数，如方向附加质量、阻力系数和基于流函数的流动，并将它们与运动解析方程耦合。

Result: 在合成涡流数据集上，FHNN 比神经 ODE 实现了高达一个数量级的更低误差，并恢复了物理上一致的流场。与哈密顿和拉格朗日神经网络相比，FHNN 更有效地处理耗散动力学，同时保持可解释性。

Conclusion: 该设计约束了假设空间，增强了可解释性，并稳定了集成。

Abstract: Fluid-structure interaction is common in engineering and natural systems,
where floating-body motion is governed by added mass, drag, and background
flows. Modeling these dissipative dynamics is difficult: black-box neural
models regress state derivatives with limited interpretability and unstable
long-horizon predictions. We propose Floating-Body Hydrodynamic Neural Networks
(FHNN), a physics-structured framework that predicts interpretable hydrodynamic
parameters such as directional added masses, drag coefficients, and a
streamfunction-based flow, and couples them with analytic equations of motion.
This design constrains the hypothesis space, enhances interpretability, and
stabilizes integration. On synthetic vortex datasets, FHNN achieves up to an
order-of-magnitude lower error than Neural ODEs, recovers physically consistent
flow fields. Compared with Hamiltonian and Lagrangian neural networks, FHNN
more effectively handles dissipative dynamics while preserving
interpretability, which bridges the gap between black-box learning and
transparent system identification.

</details>


### [171] [Towards a Physics Foundation Model](https://arxiv.org/abs/2509.13805)
*Florian Wiesner,Matthias Wessling,Stephen Baek*

Main category: cs.LG

TL;DR: 提出了一个名为GPhyT的通用物理Transformer模型，它可以在多个物理领域中实现卓越的性能，并通过上下文学习推广到完全看不见的物理系统，并通过50个时间步长的推出实现稳定的长期预测。


<details>
  <summary>Details</summary>
Motivation: 当前的物理感知机器学习方法从根本上局限于单一、狭窄的领域，并且需要为每个新系统进行重新训练。为了 democratizing 访问 high-fidelity 模拟，加速科学发现，并消除对专门的求解器开发的需求。

Method: 使用1.8 TB 的多样化模拟数据训练 General Physics Transformer (GPhyT)。

Result: GPhyT 在多个物理领域中实现了卓越的性能，比专门的架构高出 29 倍，通过上下文学习实现了对完全看不见的物理系统的零样本泛化，并通过 50 个时间步长的推出实现了稳定的长期预测。

Conclusion: 这项工作表明，单个模型可以仅从数据中学习可推广的物理原理，从而为可能改变计算科学和工程的通用 PFM 铺平了道路。

Abstract: Foundation models have revolutionized natural language processing through a
``train once, deploy anywhere'' paradigm, where a single pre-trained model
adapts to countless downstream tasks without retraining. Access to a Physics
Foundation Model (PFM) would be transformative -- democratizing access to
high-fidelity simulations, accelerating scientific discovery, and eliminating
the need for specialized solver development. Yet current physics-aware machine
learning approaches remain fundamentally limited to single, narrow domains and
require retraining for each new system. We present the General Physics
Transformer (GPhyT), trained on 1.8 TB of diverse simulation data, that
demonstrates foundation model capabilities are achievable for physics. Our key
insight is that transformers can learn to infer governing dynamics from
context, enabling a single model to simulate fluid-solid interactions, shock
waves, thermal convection, and multi-phase dynamics without being told the
underlying equations. GPhyT achieves three critical breakthroughs: (1) superior
performance across multiple physics domains, outperforming specialized
architectures by up to 29x, (2) zero-shot generalization to entirely unseen
physical systems through in-context learning, and (3) stable long-term
predictions through 50-timestep rollouts. By establishing that a single model
can learn generalizable physical principles from data alone, this work opens
the path toward a universal PFM that could transform computational science and
engineering.

</details>


### [172] [Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment](https://arxiv.org/abs/2509.13818)
*Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan*

Main category: cs.LG

TL;DR: 本文提出了一种混合量子-经典工作流程，用于解决包容性金融中数据稀缺和不平衡的信用风险评估问题。


<details>
  <summary>Details</summary>
Motivation: 传统模型在数据稀缺和不平衡的情况下效果有限，因此需要新的方法来解决信用风险评估问题。

Method: 该方法首先采用经典机器学习模型的集成进行智能特征工程和降维，然后使用通过参数转移规则训练的量子神经网络作为核心分类器。

Result: 在包含 279 个样本的真实信用数据集上，QNN 在模拟中实现了 0.852 +/- 0.027 的平均 AUC，并在硬件实验中产生了 0.88 的 AUC。此性能优于一系列经典基准。

Conclusion: 该研究为在 NISQ 时代将量子计算应用于数据受限的金融场景提供了一个实用的蓝图，并为支持其在高风险应用（如包容性金融）中的潜力提供了有价值的经验证据。

Abstract: Quantum Machine Learning (QML) offers a new paradigm for addressing complex
financial problems intractable for classical methods. This work specifically
tackles the challenge of few-shot credit risk assessment, a critical issue in
inclusive finance where data scarcity and imbalance limit the effectiveness of
conventional models. To address this, we design and implement a novel hybrid
quantum-classical workflow. The methodology first employs an ensemble of
classical machine learning models (Logistic Regression, Random Forest, XGBoost)
for intelligent feature engineering and dimensionality reduction. Subsequently,
a Quantum Neural Network (QNN), trained via the parameter-shift rule, serves as
the core classifier. This framework was evaluated through numerical simulations
and deployed on the Quafu Quantum Cloud Platform's ScQ-P21 superconducting
processor. On a real-world credit dataset of 279 samples, our QNN achieved a
robust average AUC of 0.852 +/- 0.027 in simulations and yielded an impressive
AUC of 0.88 in the hardware experiment. This performance surpasses a suite of
classical benchmarks, with a particularly strong result on the recall metric.
This study provides a pragmatic blueprint for applying quantum computing to
data-constrained financial scenarios in the NISQ era and offers valuable
empirical evidence supporting its potential in high-stakes applications like
inclusive finance.

</details>


### [173] [An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction](https://arxiv.org/abs/2509.13841)
*Qingqi Zhao,Heng Xiao*

Main category: cs.LG

TL;DR: 提出了一种可微的混合框架，该框架将图神经网络（GNN）嵌入到孔隙网络模型（PNM）中，以提高复杂多孔介质中渗透率预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 精确预测多孔介质中的渗透率对于模拟地下流动至关重要。纯粹的数据驱动模型缺乏跨尺度的泛化能力，并且没有结合明确的物理约束。孔隙网络模型（PNM）是基于物理的，但依赖于理想化的几何假设来估计孔隙尺度的水力传导率，从而限制了它们在复杂结构中的准确性。

Method: 使用GNN预测代替PNM中的解析公式来计算电导率，并通过离散伴随方法反向传播梯度，实现完全耦合的端到端训练。

Result: 该模型实现了高精度，并在不同尺度上表现良好，优于纯数据驱动和传统PNM方法。

Conclusion: 该方法为复杂多孔介质中的渗透率预测提供了一个可扩展且物理信息丰富的框架，从而降低了模型的不确定性并提高了准确性。

Abstract: Accurate prediction of permeability in porous media is essential for modeling
subsurface flow. While pure data-driven models offer computational efficiency,
they often lack generalization across scales and do not incorporate explicit
physical constraints. Pore network models (PNMs), on the other hand, are
physics-based and efficient but rely on idealized geometric assumptions to
estimate pore-scale hydraulic conductance, limiting their accuracy in complex
structures. To overcome these limitations, we present an end-to-end
differentiable hybrid framework that embeds a graph neural network (GNN) into a
PNM. In this framework, the analytical formulas used for conductance
calculations are replaced by GNN-based predictions derived from pore and throat
features. The predicted conductances are then passed to the PNM solver for
permeability computation. In this way, the model avoids the idealized geometric
assumptions of PNM while preserving the physics-based flow calculations. The
GNN is trained without requiring labeled conductance data, which can number in
the thousands per pore network; instead, it learns conductance values by using
a single scalar permeability as the training target. This is made possible by
backpropagating gradients through both the GNN (via automatic differentiation)
and the PNM solver (via a discrete adjoint method), enabling fully coupled,
end-to-end training. The resulting model achieves high accuracy and generalizes
well across different scales, outperforming both pure data-driven and
traditional PNM approaches. Gradient-based sensitivity analysis further reveals
physically consistent feature influences, enhancing model interpretability.
This approach offers a scalable and physically informed framework for
permeability prediction in complex porous media, reducing model uncertainty and
improving accuracy.

</details>


### [174] [Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets](https://arxiv.org/abs/2010.01052)
*Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi*

Main category: cs.LG

TL;DR: 提出了一种概率框架，用于联合心脏数据插补和心血管机制模型的个性化，并应用于心脏数据不完整的脑部研究。


<details>
  <summary>Details</summary>
Motivation: 临床研究中，由于缺乏代表不同解剖和生理过程的多模态患者数据，机械模型的使用受到限制。例如，神经影像数据集不能充分代表心脏特征，无法用于脑部疾病中对心血管因素的建模。

Method: 该方法基于变分框架，用于联合推断来自可用特征的心脏信息插补模型，以及能够忠实地重现个性化心血管动力学的高斯过程模拟器。

Result: 在 UK Biobank 上的实验结果表明，该模型可以准确地对包含最少心脏信息（例如，仅收缩压和舒张压）的数据集中的缺失心脏特征进行插补，同时联合估计集中模型的模拟参数。

Conclusion: 该模型可以通过模拟与不同脑解剖结构相对应的真实心脏动力学，从而对心脑联合关系进行新的探索。

Abstract: The use of mechanistic models in clinical studies is limited by the lack of
multi-modal patients data representing different anatomical and physiological
processes. For example, neuroimaging datasets do not provide a sufficient
representation of heart features for the modeling of cardiovascular factors in
brain disorders. To tackle this problem we introduce a probabilistic framework
for joint cardiac data imputation and personalisation of cardiovascular
mechanistic models, with application to brain studies with incomplete heart
data. Our approach is based on a variational framework for the joint inference
of an imputation model of cardiac information from the available features,
along with a Gaussian Process emulator that can faithfully reproduce
personalised cardiovascular dynamics. Experimental results on UK Biobank show
that our model allows accurate imputation of missing cardiac features in
datasets containing minimal heart information, e.g. systolic and diastolic
blood pressures only, while jointly estimating the emulated parameters of the
lumped model. This allows a novel exploration of the heart-brain joint
relationship through simulation of realistic cardiac dynamics corresponding to
different conditions of brain anatomy.

</details>


### [175] [Graph-Regularized Learning of Gaussian Mixture Models](https://arxiv.org/abs/2509.13855)
*Shamsiiat Abdurakhmanova,Alex Jung*

Main category: cs.LG

TL;DR: 提出了一种图正则化GMM的分布式学习方法，用于处理异构和有限的本地数据。


<details>
  <summary>Details</summary>
Motivation: 解决异构数据下GMM的分布式学习问题。

Method: 利用相似图指导节点间的参数共享，避免原始数据传输。

Result: 该模型优于集中式和本地训练的GMM。

Conclusion: 该方法在异构、低样本情况下表现出色，适用于GMM的分布式学习。

Abstract: We present a graph-regularized learning of Gaussian Mixture Models (GMMs) in
distributed settings with heterogeneous and limited local data. The method
exploits a provided similarity graph to guide parameter sharing among nodes,
avoiding the transfer of raw data. The resulting model allows for flexible
aggregation of neighbors' parameters and outperforms both centralized and
locally trained GMMs in heterogeneous, low-sample regimes.

</details>


### [176] [Masked Diffusion Models as Energy Minimization](https://arxiv.org/abs/2509.13866)
*Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li*

Main category: cs.LG

TL;DR: 将掩码扩散模型 (MDM) 解释为离散最优传输中能量最小化问题的解决方案。


<details>
  <summary>Details</summary>
Motivation: 理清MDM的理论基础，并激发抽样的实际改进。

Method: 通过 Beta 分布参数化插值时间表，我们将时间表设计空间简化为可处理的 2D 搜索，从而无需修改模型即可实现有效的训练后调整。

Result: 在合成和真实世界的基准测试中，我们的能量启发式时间表优于手工制作的基线，尤其是在低步采样设置中。

Conclusion: MDM 可以最大限度地减少所有三个能量公式，当掩码时间表满足闭式最优条件时

Abstract: We present a systematic theoretical framework that interprets masked
diffusion models (MDMs) as solutions to energy minimization problems in
discrete optimal transport. Specifically, we prove that three distinct energy
formulations--kinetic, conditional kinetic, and geodesic energy--are
mathematically equivalent under the structure of MDMs, and that MDMs minimize
all three when the mask schedule satisfies a closed-form optimality condition.
This unification not only clarifies the theoretical foundations of MDMs, but
also motivates practical improvements in sampling. By parameterizing
interpolation schedules via Beta distributions, we reduce the schedule design
space to a tractable 2D search, enabling efficient post-training tuning without
model modification. Experiments on synthetic and real-world benchmarks
demonstrate that our energy-inspired schedules outperform hand-crafted
baselines, particularly in low-step sampling settings.

</details>


### [177] [FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning](https://arxiv.org/abs/2509.13895)
*Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang*

Main category: cs.LG

TL;DR: 联邦学习中，非独立同分布数据和部分参与会导致客户端漂移和局部最优不一致，从而导致不稳定的收敛和精度损失。我们提出了FedSSG，一种随机抽样引导、历史感知漂移对齐方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，非独立同分布数据和部分参与会导致客户端漂移和局部最优不一致，从而导致不稳定的收敛和精度损失。

Method: FedSSG维护一个客户端漂移记忆，该记忆积累局部模型差异作为历史梯度的轻量级草图；至关重要的是，它通过观察到的/预期的参与率（从服务器采样器导出的按阶段期望信号）的平滑函数来门控记忆更新和局部对齐项。

Result: 在具有 100/500 个客户端和 2-15% 参与度的 CIFAR-10/100 上，FedSSG 始终优于强大的漂移感知基线并加速收敛；在我们的基准测试中，它将测试精度提高了高达几个点（例如，在 CIFAR-10 上约为 +0.9，在 CIFAR-100 上平均约为前 2 名基线之上 +2.7），并且平均产生大约 4.5 倍的目标精度收敛速度。

Conclusion: FedSSG 表明，抽样统计可以转化为有原则的、历史感知的阶段控制，以稳定和加速联邦训练。

Abstract: Non-IID data and partial participation induce client drift and inconsistent
local optima in federated learning, causing unstable convergence and accuracy
loss. We present FedSSG, a stochastic sampling-guided, history-aware drift
alignment method. FedSSG maintains a per-client drift memory that accumulates
local model differences as a lightweight sketch of historical gradients;
crucially, it gates both the memory update and the local alignment term by a
smooth function of the observed/expected participation ratio (a
phase-by-expectation signal derived from the server sampler). This
statistically grounded gate stays weak and smooth when sampling noise dominates
early, then strengthens once participation statistics stabilize, contracting
the local-global gap without extra communication. Across CIFAR-10/100 with
100/500 clients and 2-15 percent participation, FedSSG consistently outperforms
strong drift-aware baselines and accelerates convergence; on our benchmarks it
improves test accuracy by up to a few points (e.g., about +0.9 on CIFAR-10 and
about +2.7 on CIFAR-100 on average over the top-2 baseline) and yields about
4.5x faster target-accuracy convergence on average. The method adds only O(d)
client memory and a constant-time gate, and degrades gracefully to a mild
regularizer under near-IID or uniform sampling. FedSSG shows that sampling
statistics can be turned into a principled, history-aware phase control to
stabilize and speed up federated training.

</details>


### [178] [TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates](https://arxiv.org/abs/2509.13906)
*Afrin Dange,Sunita Sarawagi*

Main category: cs.LG

TL;DR: TFMAdapter improves Time Series Foundation Models (TSFMs) by incorporating covariates without fine-tuning, using a lightweight, instance-level adapter.


<details>
  <summary>Details</summary>
Motivation: Existing TSFMs struggle to use covariates, which are important for accurate forecasting in many real-world applications.

Method: TFMAdapter uses a two-stage method: (1) generating pseudo-forecasts with a simple regression model, and (2) training a Gaussian Process regressor to refine predictions using both pseudo- and TSFM forecasts alongside covariates.

Result: TFMAdapter outperforms both foundation models and supervised baselines, achieving a 24-27% improvement over base foundation models.

Conclusion: Lightweight adapters can effectively bridge the gap between generic foundation models and domain-specific forecasting needs.

Abstract: Time Series Foundation Models (TSFMs) have recently achieved state-of-the-art
performance in univariate forecasting on new time series simply by conditioned
on a brief history of past values. Their success demonstrates that large-scale
pretraining across diverse domains can acquire the inductive bias to generalize
from temporal patterns in a brief history. However, most TSFMs are unable to
leverage covariates -- future-available exogenous variables critical for
accurate forecasting in many applications -- due to their domain-specific
nature and the lack of associated inductive bias. We propose TFMAdapter, a
lightweight, instance-level adapter that augments TSFMs with covariate
information without fine-tuning. Instead of retraining, TFMAdapter operates on
the limited history provided during a single model call, learning a
non-parametric cascade that combines covariates with univariate TSFM forecasts.
However, such learning would require univariate forecasts at all steps in the
history, requiring too many calls to the TSFM. To enable training on the full
historical context while limiting TSFM invocations, TFMAdapter uses a two-stage
method: (1) generating pseudo-forecasts with a simple regression model, and (2)
training a Gaussian Process regressor to refine predictions using both pseudo-
and TSFM forecasts alongside covariates. Extensive experiments on real-world
datasets demonstrate that TFMAdapter consistently outperforms both foundation
models and supervised baselines, achieving a 24-27\% improvement over base
foundation models with minimal data and computational overhead. Our results
highlight the potential of lightweight adapters to bridge the gap between
generic foundation models and domain-specific forecasting needs.

</details>


### [179] [APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness](https://arxiv.org/abs/2509.13908)
*Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das*

Main category: cs.LG

TL;DR: 提出了一种新的交叉公平性框架，以解决现有方法无法捕捉到的细微的、多重偏差。


<details>
  <summary>Details</summary>
Motivation: 确保机器学习模型的公平性至关重要，尤其是在种族、性别和年龄等交叉保护属性中存在偏差时。现有的方法虽然解决了单一属性的公平性问题，但未能捕捉到交叉子群体面临的细微的、多重偏差。

Method: APFEx 结合了三个关键创新 - (1) 自适应多目标优化器，可在帕累托锥投影、梯度加权和探索策略之间动态切换，以应对公平性与准确性之间的权衡，(2) 可区分的交叉公平性指标，能够对非平滑子群体差异进行基于梯度的优化，以及 (3) 收敛到帕累托最优解的理论保证。

Result: 在四个真实世界数据集上的实验表明，APFEx 具有优越性，在保持竞争力的同时降低了公平性违规。

Conclusion: 我们的工作弥合了公平机器学习中的一个关键差距，为交叉公平性提供了一个可扩展的、模型无关的解决方案。

Abstract: Ensuring fairness in machine learning models is critical, especially when
biases compound across intersecting protected attributes like race, gender, and
age. While existing methods address fairness for single attributes, they fail
to capture the nuanced, multiplicative biases faced by intersectional
subgroups. We introduce Adaptive Pareto Front Explorer (APFEx), the first
framework to explicitly model intersectional fairness as a joint optimization
problem over the Cartesian product of sensitive attributes. APFEx combines
three key innovations- (1) an adaptive multi-objective optimizer that
dynamically switches between Pareto cone projection, gradient weighting, and
exploration strategies to navigate fairness-accuracy trade-offs, (2)
differentiable intersectional fairness metrics enabling gradient-based
optimization of non-smooth subgroup disparities, and (3) theoretical guarantees
of convergence to Pareto-optimal solutions. Experiments on four real-world
datasets demonstrate APFEx's superiority, reducing fairness violations while
maintaining competitive accuracy. Our work bridges a critical gap in fair ML,
providing a scalable, model-agnostic solution for intersectional fairness.

</details>


### [180] [Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction](https://arxiv.org/abs/2509.13914)
*Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini*

Main category: cs.LG

TL;DR: 使用集成模型来解决城市环境中车辆轨迹预测的多维回归问题。通过简单的置信度加权平均方法，无需重新训练即可结合现有深度学习模型的优势，提高预测性能。


<details>
  <summary>Details</summary>
Motivation: 如何结合大型预测模型的优势，避免昂贵的重新训练。

Method: 使用置信度加权平均方法结合多个深度学习模型。

Result: 在NuScenes和Argoverse数据集上，性能比最佳预测模型提高10%，尤其是在长尾指标上。

Conclusion: 简单的集成方法可以有效提高轨迹预测性能，且改进适用于整个数据集分布。

Abstract: This work explores the application of ensemble modeling to the
multidimensional regression problem of trajectory prediction for vehicles in
urban environments. As newer and bigger state-of-the-art prediction models for
autonomous driving continue to emerge, an important open challenge is the
problem of how to combine the strengths of these big models without the need
for costly re-training. We show how, perhaps surprisingly, combining
state-of-the-art deep learning models out-of-the-box (without retraining or
fine-tuning) with a simple confidence-weighted average method can enhance the
overall prediction. Indeed, while combining trajectory prediction models is not
straightforward, this simple approach enhances performance by 10% over the best
prediction model, especially in the long-tailed metrics. We show that this
performance improvement holds on both the NuScenes and Argoverse datasets, and
that these improvements are made across the dataset distribution. The code for
our work is open source.

</details>


### [181] [Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning](https://arxiv.org/abs/2509.13933)
*Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu*

Main category: cs.LG

TL;DR: 提出了一种新的联邦学习客户端选择方法，旨在减少达到一定学习精度所需的总时间。


<details>
  <summary>Details</summary>
Motivation: 服务器无法观察到客户端的动态状态，这些状态会改变其计算和通信效率。

Method: 将客户端选择建模为一个restless multi-armed bandit问题，并提出一种名为WILF-Q的方法，该方法使用Q-learning自适应地学习和更新与每个客户端相关的近似Whittle index，然后选择具有最高index的客户端。

Result: 实验结果表明，WILF-Q在学习效率方面明显优于现有的基线策略。

Conclusion: WILF-Q为无线联邦学习中的客户端选择提供了一种鲁棒而有效的方法。

Abstract: We consider the client selection problem in wireless Federated Learning (FL),
with the objective of reducing the total required time to achieve a certain
level of learning accuracy. Since the server cannot observe the clients'
dynamic states that can change their computation and communication efficiency,
we formulate client selection as a restless multi-armed bandit problem. We
propose a scalable and efficient approach called the Whittle Index Learning in
Federated Q-learning (WILF-Q), which uses Q-learning to adaptively learn and
update an approximated Whittle index associated with each client, and then
selects the clients with the highest indices. Compared to existing approaches,
WILF-Q does not require explicit knowledge of client state transitions or data
distributions, making it well-suited for deployment in practical FL settings.
Experiment results demonstrate that WILF-Q significantly outperforms existing
baseline policies in terms of learning efficiency, providing a robust and
efficient approach to client selection in wireless FL.

</details>


### [182] [eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems](https://arxiv.org/abs/2509.13952)
*Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand*

Main category: cs.LG

TL;DR: 提出了一种新的X-PINN框架，用于解决断裂介质中多重裂缝的断裂力学问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决断裂介质中多重裂缝的断裂力学问题。

Method: 提出了一个基于能量的损失函数，定制的积分方案和域分解程序。受扩展有限元方法（XFEM）的启发，神经网络解决方案空间通过专门的函数进行丰富，这些函数允许显式捕获裂纹体的不连续性和裂纹尖端的奇点。此外，引入了一个结构化框架，其中标准和丰富的解决方案组件使用不同的神经网络建模，从而可以在一维和二维域中灵活有效地模拟复杂的多重裂纹问题，并方便地扩展到3D问题。

Result: 数值实验验证了该方法的有效性和鲁棒性。

Conclusion: 该方法能够有效解决断裂介质中多重裂缝的断裂力学问题，具有良好的扩展性。

Abstract: This paper presents eXtended Physics-Informed Neural Network (X-PINN), a
novel and robust framework for addressing fracture mechanics problems involving
multiple cracks in fractured media. To address this, an energy-based loss
function, customized integration schemes, and domain decomposition procedures
are proposed. Inspired by the Extended Finite Element Method (XFEM), the neural
network solution space is enriched with specialized functions that allow crack
body discontinuities and singularities at crack tips to be explicitly captured.
Furthermore, a structured framework is introduced in which standard and
enriched solution components are modeled using distinct neural networks,
enabling flexible and effective simulations of complex multiple-crack problems
in 1D and 2D domains, with convenient extensibility to 3D problems. Numerical
experiments are conducted to validate the effectiveness and robustness of the
proposed method.

</details>


### [183] [Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection](https://arxiv.org/abs/2509.13974)
*Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza*

Main category: cs.LG

TL;DR: 提出了一种用于癫痫发作检测的持续学习框架EpiSMART，该框架使用大小受限的重放缓冲区和知情的样本选择策略，以增量方式适应患者特定的脑电信号。


<details>
  <summary>Details</summary>
Motivation: 癫痫是一种常见的神经系统疾病，需要仔细诊断和持续护理。癫痫发作检测仍然具有挑战性，因为目前的临床实践依赖于专家对脑电图的分析，这是一个耗时的过程，需要专门的知识。

Method: EpiSMART使用大小受限的重放缓冲区和知情的样本选择策略，以增量方式适应患者特定的脑电信号。通过选择性地保留高熵和癫痫预测样本，该方法在保持高性能的同时，以最小的内存和计算要求保留了关键的过去信息。

Result: 在CHB-MIT数据集上的验证表明，EpiSMART在所有其他患者中，F1评分比没有更新的训练基线提高了21%。平均而言，EpiSMART每天只需要6.46分钟的标记数据和6.28次更新，使其适合在可穿戴系统中进行实时部署。

Conclusion: EpiSMART通过有效地将新数据集成到现有模型中，而不会降低过去的知识，从而在现实和资源受限的条件下实现稳健和个性化的癫痫发作检测。

Abstract: Objective: Epilepsy, a prevalent neurological disease, demands careful
diagnosis and continuous care. Seizure detection remains challenging, as
current clinical practice relies on expert analysis of electroencephalography,
which is a time-consuming process and requires specialized knowledge.
Addressing this challenge, this paper explores automated epileptic seizure
detection using deep learning, focusing on personalized continual learning
models that adapt to each patient's unique electroencephalography signal
features, which evolve over time. Methods: In this context, our approach
addresses the challenge of integrating new data into existing models without
catastrophic forgetting, a common issue in static deep learning models. We
propose EpiSMART, a continual learning framework for seizure detection that
uses a size-constrained replay buffer and an informed sample selection strategy
to incrementally adapt to patient-specific electroencephalography signals. By
selectively retaining high-entropy and seizure-predicted samples, our method
preserves critical past information while maintaining high performance with
minimal memory and computational requirements. Results: Validation on the
CHB-MIT dataset, shows that EpiSMART achieves a 21% improvement in the F1 score
over a trained baseline without updates in all other patients. On average,
EpiSMART requires only 6.46 minutes of labeled data and 6.28 updates per day,
making it suitable for real-time deployment in wearable systems.
Conclusion:EpiSMART enables robust and personalized seizure detection under
realistic and resource-constrained conditions by effectively integrating new
data into existing models without degrading past knowledge. Significance: This
framework advances automated seizure detection by providing a continual
learning approach that supports patient-specific adaptation and practical
deployment in wearable healthcare systems.

</details>


### [184] [Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations](https://arxiv.org/abs/2509.14000)
*Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič*

Main category: cs.LG

TL;DR: 该论文提出了一种新的GNSS抗干扰方法，将干扰缓解转化为动态图回归问题，并引入了一种以接收器为中心的深度时间图网络，可以实时预测并纠正接收器的水平偏差。


<details>
  <summary>Details</summary>
Motivation: 在全球导航卫星系统（GNSS）越来越受到有意干扰，导致定位和授时必须保持运行的情况下，可用性降低。

Method: 该方法将卫星接收器环境表示为异构星图（接收器中心，跟踪卫星作为叶子），具有随时间变化的属性（例如，SNR，方位角，仰角，纬度/经度）。单层异构图ConvLSTM（HeteroGCLSTM）聚合一个跳跃空间上下文和时间动态，在短时间内输出用于即时校正的2D偏差矢量。

Result: 在来自两个不同接收器的数据集上，在三种干扰器配置文件（连续波（cw），三重音（cw3）和宽带FM）下进行了评估，每种干扰器在-45至-70 dBm之间的六个功率级别下进行了练习，每个场景重复50次（prejam / jam / recovery）。针对强大的多元时间序列基线（MLP，统一CNN和Seq2Point CNN），该模型始终获得最低的平均绝对误差（MAE）。

Conclusion: 该方法在抗干扰方面表现出色，并且具有较高的数据效率。

Abstract: Global Navigation Satellite Systems (GNSS) are increasingly disrupted by
intentional jamming, degrading availability precisely when positioning and
timing must remain operational. We address this by reframing jamming mitigation
as dynamic graph regression and introducing a receiver-centric deep temporal
graph network that predicts, and thus corrects, the receivers horizontal
deviation in real time. At each 1 Hz epoch, the satellite receiver environment
is represented as a heterogeneous star graph (receiver center, tracked
satellites as leaves) with time varying attributes (e.g., SNR, azimuth,
elevation, latitude/longitude). A single layer Heterogeneous Graph ConvLSTM
(HeteroGCLSTM) aggregates one hop spatial context and temporal dynamics over a
short history to output the 2D deviation vector applied for on the fly
correction.
  We evaluate on datasets from two distinct receivers under three jammer
profiles, continuous wave (cw), triple tone (cw3), and wideband FM, each
exercised at six power levels between -45 and -70 dBm, with 50 repetitions per
scenario (prejam/jam/recovery). Against strong multivariate time series
baselines (MLP, uniform CNN, and Seq2Point CNN), our model consistently attains
the lowest mean absolute error (MAE). At -45 dBm, it achieves 3.64 cm
(GP01/cw), 7.74 cm (GP01/cw3), 4.41 cm (ublox/cw), 4.84 cm (ublox/cw3), and
4.82 cm (ublox/FM), improving to 1.65-2.08 cm by -60 to -70 dBm. On mixed mode
datasets pooling all powers, MAE is 3.78 cm (GP01) and 4.25 cm (ublox10),
outperforming Seq2Point, MLP, and CNN. A split study shows superior data
efficiency: with only 10\% training data our approach remains well ahead of
baselines (20 cm vs. 36-42 cm).

</details>


### [185] [Differentially private federated learning for localized control of infectious disease dynamics](https://arxiv.org/abs/2509.14024)
*Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn*

Main category: cs.LG

TL;DR: 提出了一种保护隐私的预测方法，该方法可以帮助公共卫生专家和决策者。


<details>
  <summary>Details</summary>
Motivation: 在疫情时期，需要迅速做出反应以减轻疫情蔓延。然而，由于可用数据有限，在局部范围内训练单独的机器学习 (ML) 模型通常不可行。由于数据的高度敏感性和隐私限制，集中数据也具有挑战性。

Method: 联邦学习 (FL) 的机器学习方法在不集中原始数据的情况下训练共享模型。考虑到县、社区或 LHA 作为客户端，并在效用和隐私之间找到平衡，我们研究了一个具有客户端级别差分隐私 (DP) 的 FL 框架。我们对最近病例数的滑动窗口训练共享多层感知器来预测病例数，而客户端仅交换规范剪裁的更新，服务器聚合具有 DP 噪声的更新。

Result: 在适度强的水平上，DP 模型接近非 DP 模型：2020 年 11 月的 $R^2= 0.94$（对比 0.95）和平均绝对百分比误差 (MAPE) 为 26%；2022 年 3 月的 $R^2= 0.88$（对比 0.93）和 MAPE 为 21 %。

Conclusion: 总体而言，客户端级别的 DP-FL 可以提供具有强大隐私保证的有用县级预测，并且可行的隐私预算取决于流行病阶段，从而允许卫生部门之间进行符合隐私要求的协作以进行本地预测。

Abstract: In times of epidemics, swift reaction is necessary to mitigate epidemic
spreading. For this reaction, localized approaches have several advantages,
limiting necessary resources and reducing the impact of interventions on a
larger scale. However, training a separate machine learning (ML) model on a
local scale is often not feasible due to limited available data. Centralizing
the data is also challenging because of its high sensitivity and privacy
constraints. In this study, we consider a localized strategy based on the
German counties and communities managed by the related local health authorities
(LHA). For the preservation of privacy to not oppose the availability of
detailed situational data, we propose a privacy-preserving forecasting method
that can assist public health experts and decision makers. ML methods with
federated learning (FL) train a shared model without centralizing raw data.
Considering the counties, communities or LHAs as clients and finding a balance
between utility and privacy, we study a FL framework with client-level
differential privacy (DP). We train a shared multilayer perceptron on sliding
windows of recent case counts to forecast the number of cases, while clients
exchange only norm-clipped updates and the server aggregated updates with DP
noise. We evaluate the approach on COVID-19 data on county-level during two
phases. As expected, very strict privacy yields unstable, unusable forecasts.
At a moderately strong level, the DP model closely approaches the non-DP model:
$R^2= 0.94$ (vs. 0.95) and mean absolute percentage error (MAPE) of 26 % in
November 2020; $R^2= 0.88$ (vs. 0.93) and MAPE of 21 % in March 2022. Overall,
client-level DP-FL can deliver useful county-level predictions with strong
privacy guarantees, and viable privacy budgets depend on epidemic phase,
allowing privacy-compliant collaboration among health authorities for local
forecasting.

</details>


### [186] [Deep Learning-Driven Peptide Classification in Biological Nanopores](https://arxiv.org/abs/2509.14029)
*Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm*

Main category: cs.LG

TL;DR: 本文提出了一种基于纳米孔设备的蛋白质实时分类方法，该方法将电流信号转换为scaleogram图像，并使用机器学习算法进行分类。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中进行蛋白质实时分类的设备可以实现廉价且快速的疾病诊断。纳米孔设备是该技术的候选者之一。然而，这些信号的复杂性限制了它们的准确性。

Method: 本文将电流信号转换为scaleogram图像，并通过小波变换捕获幅度、频率和时间信息，以适应机器学习算法。

Result: 在 42 种肽的测试中，该方法达到了约 81% 的分类精度，创下了该领域的新纪录。

Conclusion: 该研究为在护理点进行实际的肽/蛋白质诊断迈出了一步。此外，他们演示了模型转移技术，这对于将这些模型部署到实际硬件中至关重要，从而为实时疾病诊断的新方法铺平了道路。

Abstract: A device capable of performing real time classification of proteins in a
clinical setting would allow for inexpensive and rapid disease diagnosis. One
such candidate for this technology are nanopore devices. These devices work by
measuring a current signal that arises when a protein or peptide enters a
nanometer-length-scale pore. Should this current be uniquely related to the
structure of the peptide and its interactions with the pore, the signals can be
used to perform identification. While such a method would allow for real time
identification of peptides and proteins in a clinical setting, to date, the
complexities of these signals limit their accuracy. In this work, we tackle the
issue of classification by converting the current signals into scaleogram
images via wavelet transforms, capturing amplitude, frequency, and time
information in a modality well-suited to machine learning algorithms. When
tested on 42 peptides, our method achieved a classification accuracy of
~$81\,\%$, setting a new state-of-the-art in the field and taking a step toward
practical peptide/protein diagnostics at the point of care. In addition, we
demonstrate model transfer techniques that will be critical when deploying
these models into real hardware, paving the way to a new method for real-time
disease diagnosis.

</details>


### [187] [Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing](https://arxiv.org/abs/2509.14061)
*Chiara De Luca,Elisa Donati*

Main category: cs.LG

TL;DR: 提出了一种轻量级的多模态系统，用于基于环境传感器融合的蜂王检测，利用商用 STM32 微控制器实现实时、低功耗的边缘计算。


<details>
  <summary>Details</summary>
Motivation: 当前监测方法依赖于人工检查，劳动强度大，破坏性强，不适用于大规模养蜂。最近基于音频的方法功耗高，预处理复杂，容易受到环境噪声的影响。

Method: 该方法采用基于环境传感器融合的蜂王检测，具体来说是蜂箱内外之间的温度、湿度和压力差。该方法在商用 STM32 微控制器上采用量化决策树推理。

Result: 该系统仅使用环境输入即可实现超过 99% 的蜂王检测准确率，并且音频特征没有提供显着的性能提升。

Conclusion: 这项工作提出了一种可扩展且可持续的非侵入式蜂箱监测解决方案，为使用现成的、节能硬件实现自主、精准养蜂铺平了道路。

Abstract: Queen bee presence is essential for the health and stability of honeybee
colonies, yet current monitoring methods rely on manual inspections that are
labor-intensive, disruptive, and impractical for large-scale beekeeping. While
recent audio-based approaches have shown promise, they often require high power
consumption, complex preprocessing, and are susceptible to ambient noise. To
overcome these limitations, we propose a lightweight, multimodal system for
queen detection based on environmental sensor fusion-specifically, temperature,
humidity, and pressure differentials between the inside and outside of the
hive. Our approach employs quantized decision tree inference on a commercial
STM32 microcontroller, enabling real-time, low-power edge computing without
compromising accuracy. We show that our system achieves over 99% queen
detection accuracy using only environmental inputs, with audio features
offering no significant performance gain. This work presents a scalable and
sustainable solution for non-invasive hive monitoring, paving the way for
autonomous, precision beekeeping using off-the-shelf, energy-efficient
hardware.

</details>


### [188] [Online Bayesian Risk-Averse Reinforcement Learning](https://arxiv.org/abs/2509.14077)
*Yuhao Wang,Enlu Zhou*

Main category: cs.LG

TL;DR: 研究强化学习中的贝叶斯风险规避问题，利用贝叶斯风险马尔可夫决策过程（BRMDP）处理模型参数不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决由于缺乏数据而导致认知不确定性的问题。

Method: 推导了贝叶斯风险值函数与真实未知分布下的原始值函数之间差异的渐近正态性，并利用这一自适应属性进行在线强化学习和在线情境多臂老虎机（CMAB）研究，提出了使用后验抽样的两种程序。

Result: 证明了次线性遗憾界，并进行了数值实验。

Conclusion: 验证了该算法在解决认知不确定性方面的有效性和理论特性。

Abstract: In this paper, we study the Bayesian risk-averse formulation in reinforcement
learning (RL). To address the epistemic uncertainty due to a lack of data, we
adopt the Bayesian Risk Markov Decision Process (BRMDP) to account for the
parameter uncertainty of the unknown underlying model. We derive the asymptotic
normality that characterizes the difference between the Bayesian risk value
function and the original value function under the true unknown distribution.
The results indicate that the Bayesian risk-averse approach tends to
pessimistically underestimate the original value function. This discrepancy
increases with stronger risk aversion and decreases as more data become
available. We then utilize this adaptive property in the setting of online RL
as well as online contextual multi-arm bandits (CMAB), a special case of online
RL. We provide two procedures using posterior sampling for both the general RL
problem and the CMAB problem. We establish a sub-linear regret bound, with the
regret defined as the conventional regret for both the RL and CMAB settings.
Additionally, we establish a sub-linear regret bound for the CMAB setting with
the regret defined as the Bayesian risk regret. Finally, we conduct numerical
experiments to demonstrate the effectiveness of the proposed algorithm in
addressing epistemic uncertainty and verifying the theoretical properties.

</details>


### [189] [Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques](https://arxiv.org/abs/2509.14078)
*Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov*

Main category: cs.LG

TL;DR: 研究了脑电图频率带上分类器的性能，并评估了左右半球的有效类别预测。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于提升基于神经影像的分类任务中的分类器性能，并理解特征重要性。

Method: 使用了三种神经网络结构（深度密集网络、浅层三层网络和卷积神经网络），采用TensorFlow和PyTorch框架，并比较了多种优化器。

Result: Adagrad和RMSprop优化器在不同频段表现良好，Adadelta在交叉模型评估中表现稳健。Adagrad在beta频段表现出色，而RMSprop在gamma频段表现优异。CNN在捕捉脑电图数据的空间特征方面表现出第二高的准确率。深度密集网络在学习复杂模式方面表现出竞争力，而浅层三层网络虽然有时准确率较低，但提供了计算效率。

Conclusion: 研究强调了优化器选择、模型架构和脑电图频段分析在提高分类器性能和理解特征重要性方面的重要性。

Abstract: This study investigates classifier performance across EEG frequency bands
using various optimizers and evaluates efficient class prediction for the left
and right hemispheres. Three neural network architectures - a deep dense
network, a shallow three-layer network, and a convolutional neural network
(CNN) - are implemented and compared using the TensorFlow and PyTorch
frameworks. Results indicate that the Adagrad and RMSprop optimizers
consistently perform well across different frequency bands, with Adadelta
exhibiting robust performance in cross-model evaluations. Specifically, Adagrad
excels in the beta band, while RMSprop achieves superior performance in the
gamma band. Conversely, SGD and FTRL exhibit inconsistent performance. Among
the models, the CNN demonstrates the second highest accuracy, particularly in
capturing spatial features of EEG data. The deep dense network shows
competitive performance in learning complex patterns, whereas the shallow
three-layer network, sometimes being less accurate, provides computational
efficiency. SHAP (Shapley Additive Explanations) plots are employed to identify
efficient class prediction, revealing nuanced contributions of EEG frequency
bands to model accuracy. Overall, the study highlights the importance of
optimizer selection, model architecture, and EEG frequency band analysis in
enhancing classifier performance and understanding feature importance in
neuroimaging-based classification tasks.

</details>


### [190] [From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting](https://arxiv.org/abs/2509.14113)
*Alessandro Brusaferri,Danial Ramin,Andrea Ballarino*

Main category: cs.LG

TL;DR: 提出了一种新的可解释的概率预测模型，结合了分位数广义加性模型和神经网络。


<details>
  <summary>Details</summary>
Motivation: 理解神经网络在多horizon概率预测中产生特征条件输出的潜在机制是一个挑战。

Method: 引入分位数神经基模型，利用共享基分解和权重分解。

Result: 在日前电力价格预测中，实现了与传统神经网络相当的预测性能。

Conclusion: 通过学习到的输入特征到输出预测的非线性映射，为模型行为提供了有价值的见解。

Abstract: While neural networks are achieving high predictive accuracy in multi-horizon
probabilistic forecasting, understanding the underlying mechanisms that lead to
feature-conditioned outputs remains a significant challenge for forecasters. In
this work, we take a further step toward addressing this critical issue by
introducing the Quantile Neural Basis Model, which incorporates the
interpretability principles of Quantile Generalized Additive Models into an
end-to-end neural network training framework. To this end, we leverage shared
basis decomposition and weight factorization, complementing Neural Models for
Location, Scale, and Shape by avoiding any parametric distributional
assumptions. We validate our approach on day-ahead electricity price
forecasting, achieving predictive performance comparable to distributional and
quantile regression neural networks, while offering valuable insights into
model behavior through the learned nonlinear mappings from input features to
output predictions across the horizon.

</details>


### [191] [Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy](https://arxiv.org/abs/2509.14129)
*Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani*

Main category: cs.LG

TL;DR: 本研究描述了堪萨斯州约翰逊县和卡内基梅隆大学之间的一项合作，旨在通过有针对性的主动心理健康外展来降低再监禁率。


<details>
  <summary>Details</summary>
Motivation: 许多被监禁者面临着重大的和复杂的挑战，包括精神疾病、药物依赖和无家可归，但监狱往往没有能力解决这些问题。我们需要打破这种恶性循环。

Method: 本研究描述了所使用的数据、预测建模方法和结果，以及为验证模型的预测能力而进行的现场试验的设计和分析。

Result: 该模型对新的入狱预订具有高度的预测性，试验中超过一半的高风险组人员在接下来的一年内返回监狱。外展对这些高风险个体最有效，对精神健康利用率、EMS 调度和刑事司法参与有影响。

Conclusion: 通过试验，我们发现该模型对新的入狱预订具有高度的预测性。外展对高风险个体最有效。

Abstract: Many incarcerated individuals face significant and complex challenges,
including mental illness, substance dependence, and homelessness, yet jails and
prisons are often poorly equipped to address these needs. With little support
from the existing criminal justice system, these needs can remain untreated and
worsen, often leading to further offenses and a cycle of incarceration with
adverse outcomes both for the individual and for public safety, with
particularly large impacts on communities of color that continue to widen the
already extensive racial disparities in criminal justice outcomes. Responding
to these failures, a growing number of criminal justice stakeholders are
seeking to break this cycle through innovative approaches such as
community-driven and alternative approaches to policing, mentoring, community
building, restorative justice, pretrial diversion, holistic defense, and social
service connections. Here we report on a collaboration between Johnson County,
Kansas, and Carnegie Mellon University to perform targeted, proactive mental
health outreach in an effort to reduce reincarceration rates.
  This paper describes the data used, our predictive modeling approach and
results, as well as the design and analysis of a field trial conducted to
confirm our model's predictive power, evaluate the impact of this targeted
outreach, and understand at what level of reincarceration risk outreach might
be most effective. Through this trial, we find that our model is highly
predictive of new jail bookings, with more than half of individuals in the
trial's highest-risk group returning to jail in the following year. Outreach
was most effective among these highest-risk individuals, with impacts on mental
health utilization, EMS dispatches, and criminal justice involvement.

</details>


### [192] [A Compositional Kernel Model for Feature Learning](https://arxiv.org/abs/2509.14158)
*Feng Ruan,Keli Liu,Michael Jordan*

Main category: cs.LG

TL;DR: 本文研究了核岭回归的一种组合变体，其中预测器应用于输入的坐标重加权。


<details>
  <summary>Details</summary>
Motivation: 从变量选择的角度来看，展示了如何恢复相关变量，同时消除噪声变量。

Method: 将该模型表示为一个变分问题，为组合架构中的特征学习提供了一个简单的试验平台。

Result: 建立了保证，表明当噪声变量是高斯分布时，全局极小值和驻点都会丢弃噪声坐标。一个核心发现是，$\\ell_1$-type 核（例如 Laplace 核）成功地恢复了在驻点处促成非线性效应的特征，而高斯核仅恢复线性效应。

Conclusion: $\\ell_1$-type 核（例如 Laplace 核）成功地恢复了在驻点处促成非线性效应的特征，而高斯核仅恢复线性效应。

Abstract: We study a compositional variant of kernel ridge regression in which the
predictor is applied to a coordinate-wise reweighting of the inputs. Formulated
as a variational problem, this model provides a simple testbed for feature
learning in compositional architectures. From the perspective of variable
selection, we show how relevant variables are recovered while noise variables
are eliminated. We establish guarantees showing that both global minimizers and
stationary points discard noise coordinates when the noise variables are
Gaussian distributed. A central finding is that $\ell_1$-type kernels, such as
the Laplace kernel, succeed in recovering features contributing to nonlinear
effects at stationary points, whereas Gaussian kernels recover only linear
ones.

</details>


### [193] [Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework](https://arxiv.org/abs/2509.14167)
*Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek*

Main category: cs.LG

TL;DR: 本文提出了一种端到端框架，用于从稀疏的常规数据中无创地估计无法测量的变量，解决了青光眼等疾病中关键参数无法测量的问题。


<details>
  <summary>Details</summary>
Motivation: 由于无法测量关键的潜在参数，许多关键的医疗决策都面临挑战。青光眼就是一个明显的例子，其主要决定因素是小梁网的渗透性，而这无法在体内测量，迫使临床医生依赖间接替代指标。此外，由于缺乏真实数据和大规模高保真模拟的成本过高，因此难以对此类不适定反问题开发预测模型。

Method: 该方法结合了多阶段人工智能架构以在功能上分离问题；一种名为PCDS的新型数据生成策略，无需数十万次昂贵的模拟，从而将有效计算时间从数年减少到数小时；以及一个贝叶斯引擎来量化预测不确定性。

Result: 该框架仅从常规输入中将单个IOP测量分解为其基本组成部分，从而得出无法测量的组织渗透性和患者外流设施的估计值。我们无创估计的外流设施与最先进的眼压描记术达到了极好的一致性，其精度与直接物理仪器相当。此外，新衍生的渗透性生物标志物在按疾病风险对临床队列进行分层方面表现出很高的准确性，突出了其诊断潜力。

Conclusion: 我们的框架为解决其他数据稀缺、计算密集型领域中类似的反问题建立了一个通用的蓝图。

Abstract: Many critical healthcare decisions are challenged by the inability to measure
key underlying parameters. Glaucoma, a leading cause of irreversible blindness
driven by elevated intraocular pressure (IOP), provides a stark example. The
primary determinant of IOP, a tissue property called trabecular meshwork
permeability, cannot be measured in vivo, forcing clinicians to depend on
indirect surrogates. This clinical challenge is compounded by a broader
computational one: developing predictive models for such ill-posed inverse
problems is hindered by a lack of ground-truth data and prohibitive cost of
large-scale, high-fidelity simulations. We address both challenges with an
end-to-end framework to noninvasively estimate unmeasurable variables from
sparse, routine data. Our approach combines a multi-stage artificial
intelligence architecture to functionally separate the problem; a novel data
generation strategy we term PCDS that obviates the need for hundreds of
thousands of costly simulations, reducing the effective computational time from
years to hours; and a Bayesian engine to quantify predictive uncertainty. Our
framework deconstructs a single IOP measurement into its fundamental components
from routine inputs only, yielding estimates for the unmeasurable tissue
permeability and a patient's outflow facility. Our noninvasively estimated
outflow facility achieved excellent agreement with state-of-the-art tonography
with precision comparable to direct physical instruments. Furthermore, the
newly derived permeability biomarker demonstrates high accuracy in stratifying
clinical cohorts by disease risk, highlighting its diagnostic potential. More
broadly, our framework establishes a generalizable blueprint for solving
similar inverse problems in other data-scarce, computationally-intensive
domains.

</details>


### [194] [TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits](https://arxiv.org/abs/2509.14169)
*Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang*

Main category: cs.LG

TL;DR: 提出了一种名为TopoSizing的端到端框架，该框架直接从原始网表执行鲁棒的电路理解，并将这些知识转化为优化收益。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量的数据以及难以将领域知识嵌入到自动化流程中，模拟和混合信号电路设计仍然具有挑战性。传统的黑盒优化实现了采样效率，但缺乏电路理解，这通常会导致评估浪费在设计空间的低价值区域。

Method: 首先应用图算法将电路组织成一个分层的设备-模块-阶段表示。然后，LLM agents执行一个迭代的假设-验证-改进循环，其中内置了一致性检查，从而产生显式注释。通过LLM引导的初始采样和停滞触发的信任区域更新，将经过验证的见解集成到贝叶斯优化中，从而提高了效率，同时保持了可行性。

Result: 通过LLM引导的初始采样和停滞触发的信任区域更新，将经过验证的见解集成到贝叶斯优化中，从而提高了效率，同时保持了可行性。

Conclusion: TopoSizing是一种端到端框架，可直接从原始网表执行鲁棒的电路理解，并将这些知识转化为优化收益。

Abstract: Analog and mixed-signal circuit design remains challenging due to the
shortage of high-quality data and the difficulty of embedding domain knowledge
into automated flows. Traditional black-box optimization achieves sampling
efficiency but lacks circuit understanding, which often causes evaluations to
be wasted in low-value regions of the design space. In contrast, learning-based
methods embed structural knowledge but are case-specific and costly to retrain.
Recent attempts with large language models show potential, yet they often rely
on manual intervention, limiting generality and transparency. We propose
TopoSizing, an end-to-end framework that performs robust circuit understanding
directly from raw netlists and translates this knowledge into optimization
gains. Our approach first applies graph algorithms to organize circuits into a
hierarchical device-module-stage representation. LLM agents then execute an
iterative hypothesis-verification-refinement loop with built-in consistency
checks, producing explicit annotations. Verified insights are integrated into
Bayesian optimization through LLM-guided initial sampling and
stagnation-triggered trust-region updates, improving efficiency while
preserving feasibility.

</details>


### [195] [TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning](https://arxiv.org/abs/2509.14172)
*Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao*

Main category: cs.LG

TL;DR: 提出了一种离线强化学习框架，用于训练Web Agent，通过树状结构轨迹表示和精细化奖励模型来解决信用分配、标注成本和奖励稀疏性等问题。


<details>
  <summary>Details</summary>
Motivation: 使用大型模型作为Web Agent对于自动化Web交互至关重要，但使用强化学习训练Web Agent面临信用分配错误、标注成本过高和奖励稀疏性等挑战。

Method: 提出树引导偏好优化（TGPO）框架，采用树状结构轨迹表示合并语义相同的状态，消除标签冲突；引入过程奖励模型，通过子目标进展、冗余检测和动作验证自动生成细粒度奖励；以及动态权重机制，优先考虑训练期间的高影响力决策点。

Result: 在Online-Mind2Web和自建的C-WebShop数据集上的实验表明，TGPO显著优于现有方法，以更少的冗余步骤实现了更高的成功率。

Conclusion: TGPO框架有效地解决了Web Agent训练中的关键问题，并在实验中取得了优越的性能。

Abstract: With the rapid advancement of large language models and vision-language
models, employing large models as Web Agents has become essential for automated
web interaction. However, training Web Agents with reinforcement learning faces
critical challenges including credit assignment misallocation, prohibitively
high annotation costs, and reward sparsity. To address these issues, we propose
Tree-Guided Preference Optimization (TGPO), an offline reinforcement learning
framework that proposes a tree-structured trajectory representation merging
semantically identical states across trajectories to eliminate label conflicts.
Our framework incorporates a Process Reward Model that automatically generates
fine-grained rewards through subgoal progress, redundancy detection, and action
verification. Additionally, a dynamic weighting mechanism prioritizes
high-impact decision points during training. Experiments on Online-Mind2Web and
our self-constructed C-WebShop datasets demonstrate that TGPO significantly
outperforms existing methods, achieving higher success rates with fewer
redundant steps.

</details>


### [196] [Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting](https://arxiv.org/abs/2509.14181)
*Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun*

Main category: cs.LG

TL;DR: 提出TimeAlign，一个轻量级的即插即用框架，通过重构任务学习辅助特征，并将其反馈给任何基础预测器，以弥合输入历史和未来目标之间的分布差距。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列预测器很少采用对比学习等表示学习技术，因为它们几乎没有表现出性能优势。本文旨在挑战这一观点，并证明显式的表示对齐可以提供关键信息，弥合输入历史和未来目标之间的分布差距。

Method: 引入TimeAlign框架，通过重构任务学习辅助特征，并将其反馈给任何基础预测器。

Result: 在八个基准测试中验证了TimeAlign的卓越性能。研究表明，收益主要来自纠正历史输入和未来输出之间的频率不匹配。

Conclusion: TimeAlign可以作为现代深度学习时间序列预测系统的通用对齐模块，因为它与架构无关且开销可忽略不计。

Abstract: Representation learning techniques like contrastive learning have long been
explored in time series forecasting, mirroring their success in computer vision
and natural language processing. Yet recent state-of-the-art (SOTA) forecasters
seldom adopt these representation approaches because they have shown little
performance advantage. We challenge this view and demonstrate that explicit
representation alignment can supply critical information that bridges the
distributional gap between input histories and future targets. To this end, we
introduce TimeAlign, a lightweight, plug-and-play framework that learns
auxiliary features via a simple reconstruction task and feeds them back to any
base forecaster. Extensive experiments across eight benchmarks verify its
superior performance. Further studies indicate that the gains arises primarily
from correcting frequency mismatches between historical inputs and future
outputs. We also provide a theoretical justification for the effectiveness of
TimeAlign in increasing the mutual information between learned representations
and predicted targets. As it is architecture-agnostic and incurs negligible
overhead, TimeAlign can serve as a general alignment module for modern deep
learning time-series forecasting systems. The code is available at
https://github.com/TROUBADOUR000/TimeAlign.

</details>


### [197] [A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning](https://arxiv.org/abs/2509.14198)
*Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis*

Main category: cs.LG

TL;DR: 提出了一个统一的变分框架，通过整合残差的凸变换来形式化自适应策略。


<details>
  <summary>Details</summary>
Motivation: 科学机器学习中基于残差的自适应策略在很大程度上仍然是启发式的。

Method: 通过整合残差的凸变换，不同的变换对应于不同的目标泛函：指数权重针对均匀误差的最小化，而线性权重恢复二次误差的最小化。自适应加权等价于选择优化原始目标函数的抽样分布，从而将离散化选择直接与误差度量联系起来。

Result: 在算子学习中，证明了在优化器和架构上的显著性能提升。结果为基于残差的自适应性提供了理论依据，并为有原则的离散化和训练策略奠定了基础。

Conclusion: 该方法能够系统地设计跨范数的自适应方案，通过减少损失估计器的方差来减少离散化误差，并通过提高梯度信噪比来增强学习动态。

Abstract: Residual-based adaptive strategies are widely used in scientific machine
learning but remain largely heuristic. We introduce a unifying variational
framework that formalizes these methods by integrating convex transformations
of the residual. Different transformations correspond to distinct objective
functionals: exponential weights target the minimization of uniform error,
while linear weights recover the minimization of quadratic error. Within this
perspective, adaptive weighting is equivalent to selecting sampling
distributions that optimize the primal objective, thereby linking
discretization choices directly to error metrics. This principled approach
yields three benefits: (1) it enables systematic design of adaptive schemes
across norms, (2) reduces discretization error through variance reduction of
the loss estimator, and (3) enhances learning dynamics by improving the
gradient signal-to-noise ratio. Extending the framework to operator learning,
we demonstrate substantial performance gains across optimizers and
architectures. Our results provide a theoretical justification of
residual-based adaptivity and establish a foundation for principled
discretization and training strategies.

</details>


### [198] [A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training](https://arxiv.org/abs/2509.14216)
*Johnny R. Zhang,Xiaomei Mi,Gaoyuan Du,Qianyi Sun,Shiqi Wang,Jiaxuan Li,Wenhua Zhou*

Main category: cs.LG

TL;DR: 这篇论文提出了一个用于随机迭代的Banach-Bregman框架，旨在统一优化理论和实践，适用于包括机器学习、深度学习和强化学习在内的多种AI范式。


<details>
  <summary>Details</summary>
Motivation: 现有的理论主要局限于Hilbert空间，无法捕捉非欧几里德环境，如单纯形上的镜像下降，稀疏学习的Bregman邻近方法，信息几何中的自然梯度下降或Kullback-Leibler正则化语言模型训练。

Method: 该研究通过Bregman投影和Bregman-Fejer单调性提供了一个统一的模板，涵盖了随机逼近、镜像下降、自然梯度、自适应方法和镜像-prox。

Result: 实验结果表明，与经典基线相比，该方法在机器学习、深度学习、强化学习和大型语言模型等任务上实现了高达20%的更快收敛速度、更小的方差和更高的准确性。

Conclusion: Banach-Bregman几何有望成为统一核心AI范式中优化理论和实践的基石。

Abstract: Stochastic optimization powers the scalability of modern artificial
intelligence, spanning machine learning, deep learning, reinforcement learning,
and large language model training. Yet, existing theory remains largely
confined to Hilbert spaces, relying on inner-product frameworks and
orthogonality. This paradigm fails to capture non-Euclidean settings, such as
mirror descent on simplices, Bregman proximal methods for sparse learning,
natural gradient descent in information geometry, or
Kullback--Leibler-regularized language model training. Unlike Euclidean-based
Hilbert-space methods, this approach embraces general Banach spaces. This work
introduces a pioneering Banach--Bregman framework for stochastic iterations,
establishing Bregman geometry as a foundation for next-generation optimization.
It (i) provides a unified template via Bregman projections and Bregman--Fejer
monotonicity, encompassing stochastic approximation, mirror descent, natural
gradient, adaptive methods, and mirror-prox; (ii) establishes super-relaxations
($\lambda > 2$) in non-Hilbert settings, enabling flexible geometries and
elucidating their acceleration effect; and (iii) delivers convergence theorems
spanning almost-sure boundedness to geometric rates, validated on synthetic and
real-world tasks. Empirical studies across machine learning (UCI benchmarks),
deep learning (e.g., Transformer training), reinforcement learning
(actor--critic), and large language models (WikiText-2 with distilGPT-2) show
up to 20% faster convergence, reduced variance, and enhanced accuracy over
classical baselines. These results position Banach--Bregman geometry as a
cornerstone unifying optimization theory and practice across core AI paradigms.

</details>


### [199] [Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems](https://arxiv.org/abs/2509.14219)
*Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran*

Main category: cs.LG

TL;DR: 提出了一种基于Runge-Kutta和全变分的隐式神经表示(RKTV-INR)的去噪框架，用于从噪声观测数据中恢复非线性动力系统的状态轨迹。


<details>
  <summary>Details</summary>
Motivation: 测量噪声会阻碍非线性动力系统的数据驱动建模。

Method: 使用隐式神经表示(INR)直接拟合噪声观测数据，并施加Runge-Kutta积分和全变分作为约束，以确保重构的状态是接近原始数据的动力系统轨迹。

Result: 实验表明，该方法能够有效地抑制噪声，精确地估计导数，并可靠地进行系统辨识。

Conclusion: 该方法能够生成干净、连续的轨迹，并通过自动微分提供精确的一阶导数，这些去噪后的状态和导数可用于稀疏识别非线性动力学(SINDy)以恢复控制方程。

Abstract: Data-driven modeling of nonlinear dynamical systems is often hampered by
measurement noise. We propose a denoising framework, called Runge-Kutta and
Total Variation Based Implicit Neural Representation (RKTV-INR), that
represents the state trajectory with an implicit neural representation (INR)
fitted directly to noisy observations. Runge-Kutta integration and total
variation are imposed as constraints to ensure that the reconstructed state is
a trajectory of a dynamical system that remains close to the original data. The
trained INR yields a clean, continuous trajectory and provides accurate
first-order derivatives via automatic differentiation. These denoised states
and derivatives are then supplied to Sparse Identification of Nonlinear
Dynamics (SINDy) to recover the governing equations. Experiments demonstrate
effective noise suppression, precise derivative estimation, and reliable system
identification.

</details>


### [200] [Language models' activations linearly encode training-order recency](https://arxiv.org/abs/2509.14223)
*Dmitrii Krasheninnikov,Richard E. Turner,David Krueger*

Main category: cs.LG

TL;DR: 语言模型的激活以线性方式编码训练期间学习信息的时间。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否以及如何区分训练期间学习到的信息的时序。

Method: 通过在六个不相交但相似的数据集上按顺序微调 Llama-3.2-1B 来创建一个具有已知训练顺序的模型。

Result: 测试样本的平均激活编码训练顺序；线性探针可以准确区分“早期”与“晚期”实体；该模型可以被微调以明确报告未见实体的训练阶段。

Conclusion: 模型能够通过其获取时间来区分信息，并且对它们如何管理冲突数据和响应知识修改具有重要意义。

Abstract: We show that language models' activations linearly encode when information
was learned during training. Our setup involves creating a model with a known
training order by sequentially fine-tuning Llama-3.2-1B on six disjoint but
otherwise similar datasets about named entities. We find that the average
activations of test samples for the six training datasets encode the training
order: when projected into a 2D subspace, these centroids are arranged exactly
in the order of training and lie on a straight line. Further, we show that
linear probes can accurately (~90%) distinguish "early" vs. "late" entities,
generalizing to entities unseen during the probes' own training. The model can
also be fine-tuned to explicitly report an unseen entity's training stage (~80%
accuracy). Interestingly, this temporal signal does not seem attributable to
simple differences in activation magnitudes, losses, or model confidence. Our
paper demonstrates that models are capable of differentiating information by
its acquisition time, and carries significant implications for how they might
manage conflicting data and respond to knowledge modifications.

</details>


### [201] [Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics](https://arxiv.org/abs/2509.14225)
*Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo*

Main category: cs.LG

TL;DR: 本研究致力于保护扩散模型免受成员推理攻击。


<details>
  <summary>Details</summary>
Motivation: 生成人工智能应用的发展引发了新的数据安全问题，扩散模型容易受到成员推理攻击。

Method: 利用临界阻尼高阶朗之万动力学，引入辅助变量和联合扩散过程。

Result: 通过AUROC曲线和FID指标在玩具数据集和语音数据集上验证了该方法的有效性。

Conclusion: 辅助变量的存在有助于在扩散过程中更早地破坏敏感输入数据。

Abstract: Recent advances in generative artificial intelligence applications have
raised new data security concerns. This paper focuses on defending diffusion
models against membership inference attacks. This type of attack occurs when
the attacker can determine if a certain data point was used to train the model.
Although diffusion models are intrinsically more resistant to membership
inference attacks than other generative models, they are still susceptible. The
defense proposed here utilizes critically-damped higher-order Langevin
dynamics, which introduces several auxiliary variables and a joint diffusion
process along these variables. The idea is that the presence of auxiliary
variables mixes external randomness that helps to corrupt sensitive input data
earlier on in the diffusion process. This concept is theoretically investigated
and validated on a toy dataset and a speech dataset using the Area Under the
Receiver Operating Characteristic (AUROC) curves and the FID metric.

</details>


### [202] [NIRVANA: Structured pruning reimagined for large language models compression](https://arxiv.org/abs/2509.14230)
*Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He*

Main category: cs.LG

TL;DR: NIRVANA是一种新的剪枝方法，旨在平衡即时零样本准确性保持和强大的微调能力。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型结构化剪枝方法通常会遭受显着的性能下降，特别是在零样本设置中，并且需要昂贵的恢复技术，例如监督微调 (SFT) 或适配器插入。

Method: 利用从 Adam 优化动态下的神经正切核导出的一阶显着性准则，NIRVANA 提供了一种理论上合理的剪枝策略，该策略尊重基本的模型训练行为。为了进一步解决结构化剪枝带来的独特挑战，NIRVANA 结合了一种跨层和模块（注意力与 MLP）的自适应稀疏分配机制，该机制以全局平衡的方式调整模块之间的剪枝强度。此外，为了减轻剪枝决策对校准数据质量的高度敏感性，我们提出了一种简单而有效的基于 KL 散度的校准数据选择策略，以确保更可靠和与任务无关的剪枝结果。

Result: 在 Llama3、Qwen 和 T5 模型上进行的综合实验表明，在等效稀疏性约束下，NIRVANA 的性能优于现有的结构化剪枝方法。

Conclusion: NIRVANA 提供了一种理论上合理且实用的大型语言模型压缩方法。

Abstract: Structured pruning of large language models (LLMs) offers substantial
efficiency improvements by removing entire hidden units, yet current approaches
often suffer from significant performance degradation, particularly in
zero-shot settings, and necessitate costly recovery techniques such as
supervised fine-tuning (SFT) or adapter insertion. To address these critical
shortcomings, we introduce NIRVANA, a novel pruning method explicitly designed
to balance immediate zero-shot accuracy preservation with robust fine-tuning
capability. Leveraging a first-order saliency criterion derived from the Neural
Tangent Kernel under Adam optimization dynamics, NIRVANA provides a
theoretically grounded pruning strategy that respects essential model training
behaviors. To further address the unique challenges posed by structured
pruning, NIRVANA incorporates an adaptive sparsity allocation mechanism across
layers and modules (attention vs. MLP), which adjusts pruning intensity between
modules in a globally balanced manner. Additionally, to mitigate the high
sensitivity of pruning decisions to calibration data quality, we propose a
simple yet effective KL divergence-based calibration data selection strategy,
ensuring more reliable and task-agnostic pruning outcomes. Comprehensive
experiments conducted on Llama3, Qwen, and T5 models demonstrate that NIRVANA
outperforms existing structured pruning methods under equivalent sparsity
constraints, providing a theoretically sound and practical approach to LLM
compression. The code is available at
https://github.com/iDEA-iSAIL-Lab-UIUC/NIRVANA.

</details>


### [203] [Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision](https://arxiv.org/abs/2509.14234)
*Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten*

Main category: cs.LG

TL;DR: 提出了一种名为Compute as Teacher (CaT) 的方法，通过将模型在推理时的探索转化为无参考监督，利用额外的计算资源来改进模型性能。


<details>
  <summary>Details</summary>
Motivation: 在后训练中，当没有ground truth时，学习信号从何而来？

Method: 通过综合一组并行展开中的单一参考，将模型自身的探索转化为无参考监督，然后朝着它进行优化。具体来说，当前策略产生一组rollout；一个冻结的锚（初始策略）协调遗漏和矛盾，以估计参考。

Result: 作为一个测试时程序，CaT 提高了 Gemma 3 4B、Qwen 3 4B 和 Llama 3.1 8B 的性能（在 MATH-500 上高达 +27%；在 HealthBench 上高达 +12%）。通过强化学习 (CaT-RL)，我们获得了更大的收益（高达 +33% 和 +30%），训练后的策略超过了最初的教师信号。

Conclusion: CaT 是一种有效的利用额外计算资源来提升模型性能的方法，即使在没有明确ground truth的情况下也能实现显著改进。

Abstract: Where do learning signals come from when there is no ground truth in
post-training? We propose turning exploration into supervision through Compute
as Teacher (CaT), which converts the model's own exploration at inference-time
into reference-free supervision by synthesizing a single reference from a group
of parallel rollouts and then optimizing toward it. Concretely, the current
policy produces a group of rollouts; a frozen anchor (the initial policy)
reconciles omissions and contradictions to estimate a reference, turning extra
inference-time compute into a teacher signal. We turn this into rewards in two
regimes: (i) verifiable tasks use programmatic equivalence on final answers;
(ii) non-verifiable tasks use self-proposed rubrics-binary, auditable criteria
scored by an independent LLM judge, with reward given by the fraction
satisfied. Unlike selection methods (best-of-N, majority, perplexity, or judge
scores), synthesis may disagree with the majority and be correct even when all
rollouts are wrong; performance scales with the number of rollouts. As a
test-time procedure, CaT improves Gemma 3 4B, Qwen 3 4B, and Llama 3.1 8B (up
to +27% on MATH-500; +12% on HealthBench). With reinforcement learning
(CaT-RL), we obtain further gains (up to +33% and +30%), with the trained
policy surpassing the initial teacher signal.

</details>
