<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 30]
- [cs.CV](#cs.CV) [Total: 25]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.IR](#cs.IR) [Total: 11]
- [cs.LG](#cs.LG) [Total: 24]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 本文提出了多标签基准，用于检测大型语言模型生成内容中的毒性，并提出了一种基于伪标签的毒性检测方法，实验表明该方法优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有的毒性检测器主要依赖于单标签基准，无法充分捕捉真实世界有毒提示的模糊性和多维性，导致有偏见的评估。

Method: 本文构建了三个新的多标签基准，并开发了一种基于伪标签的毒性检测方法。

Result: 实验结果表明，该方法明显优于包括 GPT-4o 和 DeepSeek 在内的先进基线。

Conclusion: 本文提出的方法能够更准确、更可靠地评估 LLM 生成内容中的多标签毒性。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [2] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本研究探讨了生成式人工智能模型在评估包含和不包含习语的学生文章时的表现，着重关注了它们在处理习语方面的能力。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式人工智能在自动评估学生文章中作为AES系统竞争者的潜力，并考虑到人工智能在处理习语方面的潜在局限性。

Method: 从语料库中选取348篇学生文章，创建两个对等的文章列表：一个包含多个习语，另一个不包含习语。使用ChatGPT、Gemini和Deepseek三个生成式人工智能模型，按照人工评分员使用的评分标准，对两组文章进行三次评分。

Result: 所有模型都表现出极好的一致性，但Gemini在与人工评分员的评分者间信度方面优于其他模型。在人工智能评估中，没有发现任何人口统计学群体的偏差。对于包含多个习语的文章，Gemini的模式与人工评分员最相似。

Conclusion: 研究表明，Gemini有潜力单独处理文章评分任务，并且是混合方法的最佳选择，因为它能够处理比喻性语言。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [3] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的框架，该框架利用大型语言模型 (LLM) 自动生成和标记基于四部分修辞类型的合成辩论数据（因果、经验、情感、道德）。


<details>
  <summary>Details</summary>
Motivation: 修辞策略对于有说服力的交流至关重要，但由于依赖人工注释，修辞策略的分析受到限制，人工注释成本高昂、不一致、难以扩展。他们相关的数据集通常仅限于特定主题和策略，给强大的模型开发带来挑战。

Method: 我们利用大型语言模型 (LLM) 自动生成和标记基于四部分修辞类型的合成辩论数据（因果、经验、情感、道德），并在此 LLM 标记的数据集上微调基于 Transformer 的分类器，并针对该数据集和多个外部语料库上的人工标记数据验证其性能。

Result: 我们的模型实现了高性能和跨主题领域的强大泛化。

Conclusion: 我们用微调模型说明了两个应用：（1）通过纳入修辞策略标签来提高说服力预测，以及（2）分析美国总统辩论中修辞策略的时间和党派转变（1960-2020 年），揭示了美国总统辩论中情感论证的使用增加，超过了认知论证。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [4] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 提出了一种名为稀疏记忆微调（sparse memory finetuning）的方法，用于解决大型语言模型中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型在部署后通常是静态的，而持续学习面临灾难性遗忘的挑战，因为可训练参数在所有任务之间共享。

Method: 利用记忆层模型（memory layer models），通过仅更新被新知识高度激活的记忆槽，减少新知识与模型现有能力之间的干扰。

Result: 在两个问答任务上，稀疏记忆微调在学习新知识的同时，显著减少了遗忘。与完整微调和LoRA相比，稀疏记忆微调在NaturalQuestions F1上的下降幅度仅为11%，而完整微调和LoRA分别为89%和71%。

Conclusion: 记忆层中的稀疏性为大型语言模型的持续学习提供了一条有希望的途径。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [5] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: MLAMA基准测试使用模板翻译评估LLM的多语言事实知识，但忽略了语法和语义信息，导致大量不语法或错误措辞的prompt，使分数解释复杂化。建议控制高度多语言数据集的语法性，这可以通过神经机器翻译或LLM系统的整句翻译来很好地近似。


<details>
  <summary>Details</summary>
Motivation: MLAMA基准测试在评估LLM的多语言事实知识时，由于模板翻译忽略了语法和语义信息，导致大量prompt不符合语法或措辞错误，使得分数解释变得复杂，尤其对于具有丰富形态结构的语言。

Method: 从MLAMA数据集中抽取4种斯拉夫语言，比较原始MLAMA数据集与Google Translate和ChatGPT生成的句子级翻译之间的知识检索分数。此外，还对来自不同语系的另外5种语言进行了分析。

Result: 知识检索分数显著提高。对可能的原因进行了定性分析。

Conclusion: 建议社区控制高度多语言数据集的语法性，以获得更高和更可解释的结果，这可以通过神经机器翻译或LLM系统的整句翻译来很好地近似。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [6] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 提出了一种自动生成可解释主题分类框架，用于分析社交媒体平台上的政治内容。


<details>
  <summary>Details</summary>
Motivation: 分析社交媒体上大量且快速发展的政治内容仍然是一个主要挑战。

Method: 结合无监督聚类与基于提示的标记，利用大型语言模型迭代构建分类。

Result: 揭示了潜在的讨论结构，合成了语义丰富的主题标签，并用道德框架维度注释主题。发现投票和移民广告占据了总体支出和印象的大部分，而堕胎和选举公正获得了不成比例的影响力。 Funding模式同样两极分化。

Conclusion: 支持对社交媒体上的政治信息进行可扩展的、可解释的分析，使研究人员、政策制定者和公众能够更好地理解新兴叙事、两极分化动态以及数字政治传播的道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [7] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了一种名为 FarsiMCQGen 的创新方法，用于生成波斯语选择题。


<details>
  <summary>Details</summary>
Motivation: 在波斯语等低资源语言中，生成高质量的选择题仍然是一个重大挑战。

Method: 该方法结合了候选生成、过滤和排序技术，利用 Transformer 和知识图等先进方法，并结合基于规则的方法来制作可信的干扰项。

Result: 结果表明，该模型的有效性和生成数据集的质量。

Conclusion: 该数据集有可能激发对选择题的进一步研究。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [8] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为Structure-R1的新框架，通过将检索到的内容转换为结构化表示来优化推理，利用强化学习动态生成和调整结构格式，并通过自奖励结构验证机制确保表示的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型由于缺乏对显式和结构化领域知识的访问，推理能力受到限制。传统的检索增强生成(RAG)系统通常在非结构化和碎片化的文本上运行，导致信息密度低和推理效果不佳。

Method: 该论文提出Structure-R1框架，它将检索到的内容转换为结构化表示，利用强化学习学习内容表示策略，动态生成和调整结构格式，并通过自奖励结构验证机制检查生成的结构是否正确和自包含。

Result: 在七个知识密集型基准测试中，Structure-R1始终以7B规模的骨干模型获得有竞争力的性能，并与更大的模型相匹配。理论分析表明，结构化表示通过提高信息密度和上下文清晰度来增强推理。

Conclusion: Structure-R1框架能够有效地提高大型语言模型的推理能力，通过结构化表示和自奖励验证机制，实现了与更大模型相媲美的性能。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [9] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本文提出了一种针对大型音频语言模型（LALM）的上下文扩展方法，以解决其音频上下文窗口短，限制长音频理解的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的LALM模型受限于短音频上下文窗口，无法有效处理长音频。

Method: 1) 提出Partial YaRN，一种无需训练的音频扩展方法，仅修改音频token位置，保留文本位置不变；2) 提出Virtual Longform Audio Training (VLAT)，一种训练策略，通过模拟不同的音频长度来扩展Partial YaRN，提高模型对长音频的泛化能力和鲁棒性。

Result: Partial YaRN在SALMONN和Qwen2-Audio上优于原始模型，VLAT训练策略提供了显著的改进，在未见长度的长音频上取得了强大的性能。

Conclusion: 本文提出的Partial YaRN和VLAT方法能够有效扩展LALM模型的音频上下文窗口，提高其对长音频的理解能力。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [10] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 研究了离散扩散语言模型（DDLM）与自回归语言模型（ARM）混合架构，旨在结合两者的优势。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型虽然准确率高，但计算成本高昂。离散扩散语言模型能够在固定步数内并行生成，并在复杂推理和长期规划任务中表现出色。

Method: 探索了文本空间和潜在空间两种协作方式，其中潜在空间通信引入了一个学习投影器，将DDLM潜在空间映射到ARM的嵌入空间。

Result: 发现将DDLM到ARM的通信从文本空间转移到潜在空间可以显著提高准确率。结合DDLM规划器和ARM执行器可以在计算上节省大量成本，而对准确率几乎没有影响。潜在空间管道使用更少的token，在DART-5和AIME上超过了Qwen3.1-7B。

Conclusion: 研究表明DDLM在混合架构中具有潜力，并为使用DDLM进行推理提供了新的见解。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [11] [Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](https://arxiv.org/abs/2510.15253)
*Sensen Gao,Shanshan Zhao,Xu Jiang,Lunhao Duan,Yong Xien Chng,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,Jia-Wang Bian,Mingming Gong*

Main category: cs.CL

TL;DR: 本文对用于文档理解的多模态检索增强生成 (RAG) 进行了调查。


<details>
  <summary>Details</summary>
Motivation: 当前的方法要么丢失结构细节，要么难以进行上下文建模。本文旨在通过多模态 RAG 来克服这些局限性，多模态 RAG 能够跨所有模态进行整体检索和推理，从而释放全面的文档智能。

Method: 本文提出了一种基于领域、检索模态和粒度的分类法，并回顾了涉及图结构和代理框架的进展。

Result: 本文总结了关键数据集、基准和应用，并强调了效率、细粒度表示和鲁棒性方面的开放挑战。

Conclusion: 本文为文档 AI 的未来发展提供了一个路线图。

Abstract: Document understanding is critical for applications from financial analysis
to scientific discovery. Current approaches, whether OCR-based pipelines
feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face
key limitations: the former loses structural detail, while the latter struggles
with context modeling. Retrieval-Augmented Generation (RAG) helps ground models
in external data, but documents' multimodal nature, i.e., combining text,
tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG.
This approach enables holistic retrieval and reasoning across all modalities,
unlocking comprehensive document intelligence. Recognizing its importance, this
paper presents a systematic survey of Multimodal RAG for document
understanding. We propose a taxonomy based on domain, retrieval modality, and
granularity, and review advances involving graph structures and agentic
frameworks. We also summarize key datasets, benchmarks, and applications, and
highlight open challenges in efficiency, fine-grained representation, and
robustness, providing a roadmap for future progress in document AI.

</details>


### [12] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: TraceCoder: A new framework for automated ICD coding.


<details>
  <summary>Details</summary>
Motivation: Existing ICD coding methods have semantic gaps, poor performance on rare codes, and lack interpretability.

Method: Integrates multi-source external knowledge (UMLS, Wikipedia, LLMs) and a hybrid attention mechanism.

Result: Achieves state-of-the-art performance on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets.

Conclusion: TraceCoder is a scalable and robust solution for automated ICD coding.

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [13] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 提出了一种新的框架，通过重新思考模型在训练期间如何与医学文本交互来解决这些挑战。


<details>
  <summary>Details</summary>
Motivation: 医学文本对于推进临床决策和医疗保健分析具有巨大的潜力。然而，它们的非结构化性质、领域特定的语言以及跨上下文的可变性使得自动理解成为一个复杂的挑战。现有的方法通常将所有数据视为同样具有挑战性，忽略了临床记录中复杂性的内在差异。这种疏忽限制了模型有效推广并在罕见或复杂病例中表现良好的能力。

Method: TACL（Threshold-Adaptive Curriculum Learning），一种新颖的框架，旨在通过重新思考模型在训练期间如何与医学文本交互来解决这些挑战。通过将数据分为不同的难度级别，并在训练初期优先考虑更简单的案例，该模型在处理更复杂的记录之前建立了一个强大的基础。

Result: 通过将 TACL 应用于包括英语和中文临床记录在内的多语言医学数据，我们观察到在各种临床任务（包括自动 ICD 编码、再入院预测和 TCM 综合征分化）中都有显着改进。

Conclusion: TACL 不仅增强了自动化系统的性能，而且还展示了统一不同医学领域方法的潜力，从而为更准确、可扩展和全球适用的医学文本理解解决方案铺平了道路。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [14] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: 提出了一种新颖的框架，示例引导规划（EGP），它增强了LLM智能体在知识图谱问答（KGQA）中的规划能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）作为交互式智能体在知识图谱问答（KGQA）中显示出巨大的潜力，但通常难以解决自然语言查询和结构化知识图（KG）表示之间的语义差距。这导致次优的规划和低效的KG探索，而免训练方法通常未能充分利用训练数据中有价值的推理模式。

Method: EGP首先通过实体模板化预处理训练集问题，以标准化语义变异。然后，它使用语义嵌入和高效的FAISS索引从这个预处理集中检索高度相似的示范问题及其成功的推理路径。这些检索到的范例动态地指导LLM的规划过程在两个关键阶段：（1）任务分解，通过将生成的子目标与已证明的推理步骤对齐，以及（2）关系探索，通过提供高质量的辅助信息来提高关系修剪的准确性。此外，我们引入了一种智能前瞻机制在关系探索期间，通过抢先探索有希望的路径并可能更早地终止探索来提高效率。我们将EGP应用于图形规划（PoG）框架，称为PoG-EGP。

Result: 在两个真实世界的KGQA数据集WebQSP和CWQ上进行的大量实验表明，PoG-EGP显着优于基线PoG系统和其他比较方法。

Conclusion: EGP框架显著提升了LLM在知识图谱问答中的规划能力，并在实验中取得了优越的结果。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [15] [Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach](https://arxiv.org/abs/2510.15311)
*Andharini Dwi Cahyani,Moh. Wildan Fathoni,Fika Hastarita Rachman,Ari Basuki,Salman Amin,Bain Khusnul Khotimah*

Main category: cs.CL

TL;DR: 本文研究了自动评分系统中Jaccard系数和余弦相似度的有效性，使用了unigram、bigram和trigram表示的向量空间模型。


<details>
  <summary>Details</summary>
Motivation: 为书面内容评估提供高效准确的评估工具

Method: 使用n-gram模型提取特征，向量化，然后使用Jaccard系数和余弦相似度计算论文之间的相似度。

Result: 余弦相似度优于Jaccard系数。在n-gram方面，unigram的RMSE低于bigram和trigram。

Conclusion: 余弦相似度在自动评分系统中表现更好，unigram特征更有效。

Abstract: Automated essay scoring (AES) is a vital area of research aiming to provide
efficient and accurate assessment tools for evaluating written content. This
study investigates the effectiveness of two popular similarity metrics, Jaccard
coefficient, and Cosine similarity, within the context of vector space
models(VSM)employing unigram, bigram, and trigram representations. The data
used in this research was obtained from the formative essay of the citizenship
education subject in a junior high school. Each essay undergoes preprocessing
to extract features using n-gram models, followed by vectorization to transform
text data into numerical representations. Then, similarity scores are computed
between essays using both Jaccard coefficient and Cosine similarity. The
performance of the system is evaluated by analyzing the root mean square error
(RMSE), which measures the difference between the scores given by human graders
and those generated by the system. The result shows that the Cosine similarity
outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower
RMSE compared to bigrams and trigrams.

</details>


### [16] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: 本文提出了一种名为CoordGen的移动端推理框架，通过集成推测解码和动态硬件调度来加速移动设备上的上下文感知文本生成。


<details>
  <summary>Details</summary>
Motivation: 在移动设备上，token-by-token的生成过程由于其固有的内存限制特性，仍然存在高延迟和有限的硬件利用率问题。

Method: CoordGen框架包含三个协同组件：自适应执行调度、上下文对齐的草稿和硬件高效的草稿扩展。

Result: 在多个智能手机和代表性工作负载上的实验表明，与现有的移动推理解决方案相比，生成速度提高了3.8倍，能源效率提高了4.7倍。

Conclusion: 组件级分析进一步验证了每个优化的贡献。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [17] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: 大型语言模型在古典诗歌生成和评估方面的表现尚不清楚。本文提出了一个三步评估框架，结合了计算指标、LLM评估和人工专家验证。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在古典中文诗歌生成和评估中的性能，并揭示其局限性。

Method: 使用提出的三步评估框架，评估了六个最先进的LLM在诗歌质量的多个维度（主题、情感、意象、形式和风格）上的表现。

Result: LLM在评估创造性质量时表现出“回声室”效应，经常收敛于与人类判断不同的 flawed 标准。

Conclusion: 强调了当前LLM作为文化和技术上复杂的创造性任务中读写能力生成和有限的评估实践的潜力和局限性，因此证明了对人类和模型进行混合验证的持续需求。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [18] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 这篇论文提出了一种用于提升多模态检索鲁棒性的方法，尤其是在分布偏移的情况下。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型(MLLM)在统一编码器上进行对比学习时，容易学习到模态捷径，导致鲁棒性差。

Method: 论文提出了一个模态组合感知框架，通过偏好损失和组合正则化来显式地建模组合表示与其单模态对应部分之间的结构关系。

Result: 在多个基准测试上的实验表明，该方法在分布外检索方面有所提升。

Conclusion: 模态组合感知是利用MLLM作为统一编码器时，实现鲁棒多模态检索的有效原则。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [19] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: AutoGraph-R1通过强化学习直接优化知识图谱的构建，以提升检索增强生成（RAG）在问答系统中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱构建过程与下游应用脱节，导致图结构欠优化。

Method: 使用强化学习训练LLM构造器，将图生成视为策略学习问题，奖励来自图在RAG流水线中的功能效用。

Result: 在多个QA基准测试中，AutoGraph-R1使图RAG方法比使用任务无关的基线图实现了显着的性能提升。

Conclusion: 研究表明，可以闭合构建和应用之间的循环，将范式从构建本质上“好”的图转变为构建具有明显“有用”的图。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [20] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 提出了一种动态调整检索文档列表长度的检索增强推理模型，以提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强推理模型计算成本高昂，检索和推理token都消耗大量资源。

Method: 1. 提出动态调整检索文档列表长度的模型；2. 开发了一种成本敏感的优势函数，用于通过强化学习训练高效的检索增强推理模型；3. 探索了近端策略优化和群相对策略优化算法的内存和延迟绑定实现。

Result: 在七个公共问答数据集上评估，效率显著提高，且效果没有下降。模型延迟降低了约16-20%，准确匹配率平均提高了约5%。

Conclusion: 该方法在不影响效果的前提下，显著提高了检索增强推理模型的效率。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [21] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 现有的可读性评估指标与人类的感知不符，基于模型的指标更有希望。


<details>
  <summary>Details</summary>
Motivation: 可读性的不一致定义和依赖于表面文本属性的测量阻碍了该领域的发展。

Method: 通过分析897个判断来调查影响人类可读性感知的因素，并评估15个流行的可读性指标。

Result: 信息内容和主题强烈影响文本的可理解性。四个基于模型的指标在与人类判断的相关性排名中始终名列前茅，而表现最佳的传统指标的平均排名为8.6。

Conclusion: 基于模型的方法是更有希望的方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [22] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: SAFE框架通过选择性地集成大语言模型，在长文本生成任务中实现了比现有方法更高的准确性和效率，即使只集成少于1%的token。


<details>
  <summary>Details</summary>
Motivation: 现有集成方法在长文本生成中应用不足，且在每个token处集成通常会降低性能。需要仔细选择集成位置。

Method: 提出SAFE框架，该框架通过联合考虑token化不匹配和模型在下一个token概率分布中的共识来选择性地集成。引入概率锐化策略，将分布在代表同一单词的多个子词token上的概率合并为单个代表性token。

Result: 在MATH500和BBH等多个基准测试中，SAFE在准确性和效率方面均优于现有方法。

Conclusion: SAFE框架通过选择性集成和概率锐化策略，有效提升了长文本生成的性能。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [23] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 提出了一种新的强化学习框架LayoutRL，并构建了一个新的数据集Infinity-Doc-400K，用于训练一个名为Infinity-Parser的视觉语言模型，该模型在各种文档类型上表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的监督微调方法难以在不同的文档类型中进行泛化，特别是在分布外数据上表现不佳。高质量的布局感知解析任务的训练数据有限。

Method: 引入LayoutRL，一个通过综合奖励来优化布局理解的强化学习框架，综合奖励包括归一化编辑距离、段落计数准确性和阅读顺序保持。

Result: 在OmniDocBench, olmOCR-Bench, PubTabNet, 和 FinTabNet等基准测试中，Infinity-Parser在各种文档类型、语言和结构复杂性方面始终达到最先进的性能，大大优于专门的文档解析系统和通用视觉语言模型。

Conclusion: 发布代码、数据集和模型，以促进文档解析的可重复研究。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [24] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 当前语音大语言模型在处理语音停顿时性能会显著下降，影响实际应用。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型在语音停顿方面的鲁棒性测试不足，尤其是在帕金森病等疾病相关的语音停顿方面。

Method: 提出了VocalBench-DF框架，用于系统评估多维度分类中的语音停顿。

Result: 对22个主流语音大语言模型的评估表明，性能显著下降。

Conclusion: 需要新的方法来提高语音停顿处理能力，并构建真正具有包容性的语音大语言模型。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [25] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 本文提出了一种新的用户游戏生命周期（UGL）方法，以解决游戏推荐和广告中的数据稀疏性和不平衡问题。通过丰富用户行为和逆概率掩码策略，UGL 显著提高了游戏广告和游戏内物品推荐的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统表示学习方法不适用于游戏广告和推荐，因为游戏数量少，用户行为集中在少数热门游戏中，存在稀疏性和不平衡性问题。

Method: 提出了用户游戏生命周期（UGL）来丰富用户在游戏中的行为，并提出了两种创新策略来更有效地提取短期和长期兴趣。此外，还提出了一种逆概率掩码策略来解决游戏不平衡问题。

Result: 离线实验结果表明，UGL 表示平均提高了 1.83% 的 AUC，在线实验结果表明，游戏广告的 CVR 平均提高了 21.67%，游戏内物品推荐的 ARPU 平均提高了 0.82%。

Conclusion: UGL 表示可以显著提高游戏广告和游戏内物品推荐的效果。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [26] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 本研究专注于提升检索增强生成系统处理图像查询的能力，特别是在马来西亚临床实践指南的背景下。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在生成图像描述时，缺乏临床特异性和事实依据，限制了其在医学领域的应用。

Method: 研究提出并验证了一个框架，通过知识蒸馏生成合成数据集，并使用QLoRA方法对MedGemma模型进行微调，以生成高质量的图像描述。

Result: 微调后的模型在分类性能以及图像描述的忠实性和正确性方面均有显著提升。

Conclusion: 该研究建立了一个强大的医学视觉-语言模型定制流程，并验证了该模型作为高质量查询生成器的能力，为增强循证临床决策支持中的多模态RAG系统奠定了基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [27] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 现有的多模态大型语言模型(MLLM)在各种基准测试中表现出强大的能力，但是，大多数现有的评估都集中在被动推理上，而这种设置与现实世界的使用不符，在现实世界中，仅仅靠观察是不够的。为了弥合这一差距，我们要求 MLLM 在不完整的信息下主动获取缺失的证据，并通过从没有特定于任务的先验的候选池中选择目标图像来迭代地完善决策。


<details>
  <summary>Details</summary>
Motivation: 为了弥合 MLLM 在被动推理和现实世界使用之间的差距，现实世界使用需要 MLLM 在不完整的信息下主动获取缺失的证据并迭代地完善决策。

Method: 我们提出了 GuessBench，这是一个基准，它既包含面向感知的图像，也包含面向知识的图像，用于评估 MLLM 中的主动推理。我们评估了 20 个优秀的 MLLM。

Result: 在主动推理方面的表现远远落后于在被动设置方面的表现，表明有很大的改进空间。精细的感知和及时的决策是关键挑战。感知增强有利于较小的模型，而面向思考的方法则为各种模型尺寸提供了一致的增益。

Conclusion: 多模态主动推理有希望的研究方向是，感知增强有利于较小的模型，而面向思考的方法则为各种模型尺寸提供了一致的增益。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [28] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 提出了一种基于提示工程的可控摘要生成方法，用于大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法中摘要质量和可控性的问题。

Method: 设计了一个多阶段提示生成框架，通过对输入文本进行语义分析、主题建模和噪声控制，生成不同抽象程度的摘要。

Result: 实验结果表明，提示长度、数据噪声和文本类型对生成摘要的质量有显著影响。提示长度过短或过长都会降低摘要质量，数据噪声会负面影响摘要生成过程，模型在处理新闻文本时表现最佳，而在处理学术文章时表现较差。

Conclusion: 本研究为改进使用大型语言模型生成摘要提供了新的见解，特别是在如何控制提示策略和优化文本预处理方面，可以提高摘要的准确性和可控性。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [29] [CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs](https://arxiv.org/abs/2510.15455)
*Gucongcong Fan,Chaoyue Niu,Chengfei Lyu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: CORE框架结合云端和本地LLM的优势，减少UI暴露，同时保持任务准确性。


<details>
  <summary>Details</summary>
Motivation: 移动代理依赖LLM在智能手机UI上规划和执行任务，但云端LLM需要上传完整的UI状态，暴露不必要的信息，而本地LLM容量有限，任务成功率较低。

Method: CORE框架包含：(1) 布局感知的块分区；(2) 协同规划；(3) 协同决策。

Result: CORE框架减少了高达55.6%的UI暴露，同时保持了略低于纯云代理的任务成功率。

Conclusion: CORE框架有效地减少了不必要的隐私暴露。

Abstract: Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks
on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task
accuracy, they require uploading the full UI state at every step, exposing
unnecessary and often irrelevant information. In contrast, local LLMs avoid UI
uploads but suffer from limited capacity, resulting in lower task success
rates. We propose $\textbf{CORE}$, a $\textbf{CO}$llaborative framework that
combines the strengths of cloud and local LLMs to $\textbf{R}$educe UI
$\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE
comprises three key components: (1) $\textbf{Layout-aware block partitioning}$,
which groups semantically related UI elements based on the XML screen
hierarchy; (2) $\textbf{Co-planning}$, where local and cloud LLMs
collaboratively identify the current sub-task; and (3)
$\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks,
and the cloud LLM selects specific UI elements within the top-ranked block.
CORE further introduces a multi-round accumulation mechanism to mitigate local
misjudgment or limited context. Experiments across diverse mobile apps and
tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task
success rates slightly below cloud-only agents, effectively mitigating
unnecessary privacy exposure to the cloud. The code is available at
https://github.com/Entropy-Fighter/CORE.

</details>


### [30] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: 论文介绍了一个名为DeceptionBench的基准，用于评估大型语言模型(LLM)中的欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 现有的研究对真实场景下的欺骗行为表征不足，且LLM的快速发展带来了潜在的欺骗风险。

Method: 建立DeceptionBench基准，包含五个领域（经济、医疗、教育、社交互动和娱乐）的150个精心设计的场景，超过1000个样本。从内在和外在维度评估欺骗行为，并结合多轮交互循环。

Result: 实验表明，LLM和大型推理模型(LRM)存在关键漏洞，尤其是在强化动态下欺骗行为会加剧。模型缺乏对操纵性环境线索的抵抗力。

Conclusion: 当前模型缺乏对欺骗行为的抵抗力，迫切需要针对各种欺骗行为的高级保护措施。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [31] [GAZE:Governance-Aware pre-annotation for Zero-shot World Model Environments](https://arxiv.org/abs/2510.14992)
*Leela Krishna,Mengyang Zhao,Saicharithreddy Pasula,Harshit Rajgarhia,Abhishek Mukherji*

Main category: cs.CV

TL;DR: GAZE是一个自动化流程，可以将原始长视频转换为丰富的、可用于世界模型训练的监督数据。


<details>
  <summary>Details</summary>
Motivation: 世界模型的训练需要大规模、精确标记的多模态数据集，而人工标注速度慢且成本高。

Method: 该系统将专有的360度格式标准化为标准视图并进行分片以进行并行处理；应用了一套AI模型（场景理解、对象跟踪、音频转录、PII/NSFW/未成年人检测）以进行密集的、多模态的预标注；并将信号整合为结构化的输出规范以供快速人工验证。

Result: GAZE工作流程能够显著提高效率（每审核小时节省约19分钟），并通过保守地自动跳过低显著性片段来减少80%以上的人工审核量。

Conclusion: 该方法生成高保真、具有隐私意识的数据集，可直接用于学习跨模态动态和动作条件预测，同时提供了一个可扩展的蓝图，用于生成高质量的世界模型训练数据，而不会牺牲吞吐量或治理。

Abstract: Training robust world models requires large-scale, precisely labeled
multimodal datasets, a process historically bottlenecked by slow and expensive
manual annotation. We present a production-tested GAZE pipeline that automates
the conversion of raw, long-form video into rich, task-ready supervision for
world-model training. Our system (i) normalizes proprietary 360-degree formats
into standard views and shards them for parallel processing; (ii) applies a
suite of AI models (scene understanding, object tracking, audio transcription,
PII/NSFW/minor detection) for dense, multimodal pre-annotation; and (iii)
consolidates signals into a structured output specification for rapid human
validation.
  The GAZE workflow demonstrably yields efficiency gains (~19 minutes saved per
review hour) and reduces human review volume by >80% through conservative
auto-skipping of low-salience segments. By increasing label density and
consistency while integrating privacy safeguards and chain-of-custody metadata,
our method generates high-fidelity, privacy-aware datasets directly consumable
for learning cross-modal dynamics and action-conditioned prediction. We detail
our orchestration, model choices, and data dictionary to provide a scalable
blueprint for generating high-quality world model training data without
sacrificing throughput or governance.

</details>


### [32] [PC-UNet: An Enforcing Poisson Statistics U-Net for Positron Emission Tomography Denoising](https://arxiv.org/abs/2510.14995)
*Yang Shi,Jingchao Wang,Liangsi Lu,Mingxuan Huang,Ruixin He,Yifeng Xie,Hanqian Liu,Minzhe Guo,Yangyang Liang,Weipeng Zhang,Zimeng Li,Xuhang Chen*

Main category: cs.CV

TL;DR: 提出了一种新的泊松一致U-Net (PC-UNet) 模型，用于降低PET图像的噪声，提高图像质量。


<details>
  <summary>Details</summary>
Motivation: PET在医学中很重要，但由于信噪比高和辐射暴露剂量增加，其临床应用受到限制。降低剂量会增加泊松噪声，而目前的去噪方法无法处理，导致失真和伪影。

Method: 提出了一个泊松一致U-Net (PC-UNet) 模型，该模型具有一个新的泊松方差和均值一致性损失 (PVMC-Loss)，该损失结合了物理数据以提高图像保真度。

Result: 在PET数据集上的测试表明，PC-UNet 提高了物理一致性和图像保真度，证明了其有效整合物理信息的能力。

Conclusion: PC-UNet 模型能够有效整合物理信息，提高PET图像的质量。

Abstract: Positron Emission Tomography (PET) is crucial in medicine, but its clinical
use is limited due to high signal-to-noise ratio doses increasing radiation
exposure. Lowering doses increases Poisson noise, which current denoising
methods fail to handle, causing distortions and artifacts. We propose a Poisson
Consistent U-Net (PC-UNet) model with a new Poisson Variance and Mean
Consistency Loss (PVMC-Loss) that incorporates physical data to improve image
fidelity. PVMC-Loss is statistically unbiased in variance and gradient
adaptation, acting as a Generalized Method of Moments implementation, offering
robustness to minor data mismatches. Tests on PET datasets show PC-UNet
improves physical consistency and image fidelity, proving its ability to
integrate physical information effectively.

</details>


### [33] [DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.15015)
*Mor Ventura,Michael Toker,Or Patashnik,Yonatan Belinkov,Roi Reichart*

Main category: cs.CV

TL;DR: 提出了一种名为DeLeaker的轻量级、无优化的推理时方法，通过直接干预模型的注意力图来缓解语义泄漏。


<details>
  <summary>Details</summary>
Motivation: 现有的缓解策略通常是基于优化或依赖于外部输入，但text-to-image (T2I) 模型仍然容易受到语义泄漏的影响，即不同实体之间语义相关特征的意外转移。

Method: 在扩散过程中，DeLeaker动态地重新加权注意力图，以抑制过度的跨实体交互，同时加强每个实体的身份。

Result: DeLeaker在缓解泄漏方面始终优于所有基线，即使在提供外部信息的情况下，也能在不影响保真度或质量的情况下实现有效的泄漏缓解。

Conclusion: 注意力控制的价值，并为更精确的T2I模型铺平了道路。为了支持系统评估，还引入了SLIM数据集，这是第一个专门用于语义泄漏的数据集。

Abstract: Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable
to semantic leakage, the unintended transfer of semantically related features
between distinct entities. Existing mitigation strategies are often
optimization-based or dependent on external inputs. We introduce DeLeaker, a
lightweight, optimization-free inference-time approach that mitigates leakage
by directly intervening on the model's attention maps. Throughout the diffusion
process, DeLeaker dynamically reweights attention maps to suppress excessive
cross-entity interactions while strengthening the identity of each entity. To
support systematic evaluation, we introduce SLIM (Semantic Leakage in IMages),
the first dataset dedicated to semantic leakage, comprising 1,130
human-verified samples spanning diverse scenarios, together with a novel
automatic evaluation framework. Experiments demonstrate that DeLeaker
consistently outperforms all baselines, even when they are provided with
external information, achieving effective leakage mitigation without
compromising fidelity or quality. These results underscore the value of
attention control and pave the way for more semantically precise T2I models.

</details>


### [34] [UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos](https://arxiv.org/abs/2510.15018)
*Mingxuan Liu,Honglin He,Elisa Ricci,Wayne Wu,Bolei Zhou*

Main category: cs.CV

TL;DR: UrbanVerse是一个数据驱动的实物到模拟系统，可以将众包的城市旅游视频转换为具有物理感知能力的交互式模拟场景。


<details>
  <summary>Details</summary>
Motivation: 现有人工制作或程序生成的模拟场景要么缺乏可扩展性，要么无法捕捉到真实世界的复杂性。为了训练城市具身人工智能体，需要多样化、高保真的城市环境。

Method: UrbanVerse包含：(i) UrbanVerse-100K，一个包含10万+带注释的城市3D资产的仓库，具有语义和物理属性；(ii) UrbanVerse-Gen，一个自动流水线，可以从视频中提取场景布局，并使用检索到的资产实例化度量尺度的3D模拟。

Result: UrbanVerse场景保留了真实世界的语义和布局，实现了与手工制作场景相当的人工评估的真实感。在城市导航中，在UrbanVerse中训练的策略表现出缩放幂律和强大的泛化能力，与先前的方法相比，在模拟中提高了+6.3%的成功率，在零样本sim-to-real转移中提高了+30.1%，仅通过两次干预就完成了300米的真实世界任务。

Conclusion: UrbanVerse是一个有用的工具，可以为城市具身人工智能体的训练提供高质量的模拟环境。

Abstract: Urban embodied AI agents, ranging from delivery robots to quadrupeds, are
increasingly populating our cities, navigating chaotic streets to provide
last-mile connectivity. Training such agents requires diverse, high-fidelity
urban environments to scale, yet existing human-crafted or procedurally
generated simulation scenes either lack scalability or fail to capture
real-world complexity. We introduce UrbanVerse, a data-driven real-to-sim
system that converts crowd-sourced city-tour videos into physics-aware,
interactive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a
repository of 100k+ annotated urban 3D assets with semantic and physical
attributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene
layouts from video and instantiates metric-scale 3D simulations using retrieved
assets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed
scenes from 24 countries, along with a curated benchmark of 10 artist-designed
test scenes. Experiments show that UrbanVerse scenes preserve real-world
semantics and layouts, achieving human-evaluated realism comparable to manually
crafted scenes. In urban navigation, policies trained in UrbanVerse exhibit
scaling power laws and strong generalization, improving success by +6.3% in
simulation and +30.1% in zero-shot sim-to-real transfer comparing to prior
methods, accomplishing a 300 m real-world mission with only two interventions.

</details>


### [35] [NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks](https://arxiv.org/abs/2510.15019)
*Junliang Ye,Shenghao Xie,Ruowen Zhao,Zhengyi Wang,Hongyu Yan,Wenqiang Zu,Lei Ma,Jun Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为 Nano3D 的无训练框架，用于精确和连贯的 3D 对象编辑，无需掩模。


<details>
  <summary>Details</summary>
Motivation: 当前 3D 对象编辑方法效率低、不一致，且常常无法保留未编辑区域。大多数方法依赖于编辑多视图渲染然后进行重建，这会引入伪影并限制实用性。

Method: 将 FlowEdit 集成到 TRELLIS 中，以执行由前视图渲染引导的局部编辑，并进一步引入区域感知合并策略 Voxel/Slat-Merge，通过确保编辑区域和未编辑区域之间的一致性来适应性地保持结构保真度。

Result: 与现有方法相比，Nano3D 实现了卓越的 3D 一致性和视觉质量。构建了首个大型 3D 编辑数据集 Nano3D-Edit-100k，其中包含超过 100,000 个高质量 3D 编辑对。

Conclusion: 这项工作解决了算法设计和数据可用性方面的长期挑战，显着提高了 3D 编辑的通用性和可靠性，并为前馈 3D 编辑模型的发展奠定了基础。

Abstract: 3D object editing is essential for interactive content creation in gaming,
animation, and robotics, yet current approaches remain inefficient,
inconsistent, and often fail to preserve unedited regions. Most methods rely on
editing multi-view renderings followed by reconstruction, which introduces
artifacts and limits practicality. To address these challenges, we propose
Nano3D, a training-free framework for precise and coherent 3D object editing
without masks. Nano3D integrates FlowEdit into TRELLIS to perform localized
edits guided by front-view renderings, and further introduces region-aware
merging strategies, Voxel/Slat-Merge, which adaptively preserve structural
fidelity by ensuring consistency between edited and unedited areas. Experiments
demonstrate that Nano3D achieves superior 3D consistency and visual quality
compared with existing methods. Based on this framework, we construct the first
large-scale 3D editing datasets Nano3D-Edit-100k, which contains over 100,000
high-quality 3D editing pairs. This work addresses long-standing challenges in
both algorithm design and data availability, significantly improving the
generality and reliability of 3D editing, and laying the groundwork for the
development of feed-forward 3D editing models. Project
Page:https://jamesyjl.github.io/Nano3D

</details>


### [36] [Constantly Improving Image Models Need Constantly Improving Benchmarks](https://arxiv.org/abs/2510.15021)
*Jiaxin Ge,Grace Luo,Heekyung Lee,Nishant Malpani,Long Lian,XuDong Wang,Aleksander Holynski,Trevor Darrell,Sewon Min,David M. Chan*

Main category: cs.CV

TL;DR: 这篇论文介绍了一个名为ECHO的框架，用于构建图像生成模型的基准测试，该框架直接从社交媒体帖子中提取真实世界的模型使用案例。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法捕捉到图像生成模型的新兴用例，导致社区对进展的认知与正式评估之间存在差距。

Method: 该框架通过收集社交媒体帖子中展示的新颖提示和定性用户判断来构建基准测试。

Result: 通过将该框架应用于GPT-4o Image Gen，构建了一个包含超过31,000个提示的数据集。分析表明，ECHO能够发现现有基准测试中没有的创造性和复杂任务，更清楚地区分最先进的模型与替代方案，并提供社区反馈以用于设计模型质量的指标。

Conclusion: ECHO框架能够有效地构建图像生成模型的基准测试，并发现现有基准测试中没有的新兴用例。

Abstract: Recent advances in image generation, often driven by proprietary systems like
GPT-4o Image Gen, regularly introduce new capabilities that reshape how users
interact with these models. Existing benchmarks often lag behind and fail to
capture these emerging use cases, leaving a gap between community perceptions
of progress and formal evaluation. To address this, we present ECHO, a
framework for constructing benchmarks directly from real-world evidence of
model use: social media posts that showcase novel prompts and qualitative user
judgments. Applying this framework to GPT-4o Image Gen, we construct a dataset
of over 31,000 prompts curated from such posts. Our analysis shows that ECHO
(1) discovers creative and complex tasks absent from existing benchmarks, such
as re-rendering product labels across languages or generating receipts with
specified totals, (2) more clearly distinguishes state-of-the-art models from
alternatives, and (3) surfaces community feedback that we use to inform the
design of metrics for model quality (e.g., measuring observed shifts in color,
identity, and structure). Our website is at https://echo-bench.github.io.

</details>


### [37] [LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models](https://arxiv.org/abs/2510.15022)
*Mert Sonmezer,Matthew Zheng,Pinar Yanardag*

Main category: cs.CV

TL;DR: 提出了一种从大量LoRA模型中选择最相关的模型的方法。


<details>
  <summary>Details</summary>
Motivation: 用户难以从大量LoRA模型中选择合适的模型。

Method: 将选择LoRA模型的问题转化为组合优化问题，并提出了一个新的submodular框架。

Result: 该方法可以在各种领域生成不同的输出。

Conclusion: 该方法可以有效地选择LoRA模型。

Abstract: Low-rank Adaptation (LoRA) models have revolutionized the personalization of
pre-trained diffusion models by enabling fine-tuning through low-rank,
factorized weight matrices specifically optimized for attention layers. These
models facilitate the generation of highly customized content across a variety
of objects, individuals, and artistic styles without the need for extensive
retraining. Despite the availability of over 100K LoRA adapters on platforms
like Civit.ai, users often face challenges in navigating, selecting, and
effectively utilizing the most suitable adapters due to their sheer volume,
diversity, and lack of structured organization. This paper addresses the
problem of selecting the most relevant and diverse LoRA models from this vast
database by framing the task as a combinatorial optimization problem and
proposing a novel submodular framework. Our quantitative and qualitative
experiments demonstrate that our method generates diverse outputs across a wide
range of domains.

</details>


### [38] [MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning](https://arxiv.org/abs/2510.15026)
*Mattia Segu,Marta Tintore Gazulla,Yongqin Xian,Luc Van Gool,Federico Tombari*

Main category: cs.CV

TL;DR: MOBIUS is a family of foundation models for universal instance segmentation, designed for Pareto-optimal downscaling to support deployment across devices ranging from high-end accelerators to mobile hardware.


<details>
  <summary>Details</summary>
Motivation: High computational cost limits adoption on resource-constrained platforms.

Method: It proposes a bottleneck pixel decoder for efficient multi-scale and multi-modal fusion, a language-guided uncertainty calibration loss for adaptive decoder pruning, and a streamlined, unified training strategy.

Result: MOBIUS reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively, while maintaining state-of-the-art performance in just a third of the training iterations.

Conclusion: MOBIUS establishes a new benchmark for efficient segmentation on both high-performance computing platforms and mobile devices.

Abstract: Scaling up model size and training data has advanced foundation models for
instance-level perception, achieving state-of-the-art in-domain and zero-shot
performance across object detection and segmentation. However, their high
computational cost limits adoption on resource-constrained platforms. We first
examine the limitations of existing architectures in enabling efficient edge
deployment without compromising performance. We then introduce MOBIUS, a family
of foundation models for universal instance segmentation, designed for
Pareto-optimal downscaling to support deployment across devices ranging from
high-end accelerators to mobile hardware. To reduce training and inference
demands, we propose: (i) a bottleneck pixel decoder for efficient multi-scale
and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for
adaptive decoder pruning, and (iii) a streamlined, unified training strategy.
Unlike efficient baselines that trade accuracy for reduced complexity, MOBIUS
reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively,
while maintaining state-of-the-art performance in just a third of the training
iterations. MOBIUS establishes a new benchmark for efficient segmentation on
both high-performance computing platforms and mobile devices.

</details>


### [39] [Composition-Grounded Instruction Synthesis for Visual Reasoning](https://arxiv.org/abs/2510.15040)
*Xinyi Gu,Jiayuan Mao,Zhang-Wei Hong,Zhuoran Yu,Pengyuan Li,Dhiraj Joshi,Rogerio Feris,Zexue He*

Main category: cs.CV

TL;DR: COGS: A data-efficient framework for equipping MLLMs with advanced reasoning abilities from a small set of seed questions.


<details>
  <summary>Details</summary>
Motivation: MLLMs are limited in reasoning capabilities for domains where annotations are difficult to collect, such as charts, rendered documents, and webpages.

Method: Decompose each seed question into primitive perception and reasoning factors, which can then be systematically recomposed with new images to generate large collections of synthetic question-answer pairs. Each generated question is paired with subquestions and intermediate answers, enabling reinforcement learning with factor-level process rewards.

Result: COGS substantially improves performance on unseen questions, with the largest gains on reasoning-heavy and compositional questions. Training with a factor-level mixture of different seed data yields better transfer across multiple datasets.

Conclusion: COGS induces generalizable capabilities rather than dataset-specific overfitting and the framework extends beyond charts to other domains such as webpages.

Abstract: Pretrained multi-modal large language models (MLLMs) demonstrate strong
performance on diverse multimodal tasks, but remain limited in reasoning
capabilities for domains where annotations are difficult to collect. In this
work, we focus on artificial image domains such as charts, rendered documents,
and webpages, which are abundant in practice yet lack large-scale human
annotated reasoning datasets. We introduce COGS (COmposition-Grounded
instruction Synthesis), a data-efficient framework for equipping MLLMs with
advanced reasoning abilities from a small set of seed questions. The key idea
is to decompose each seed question into primitive perception and reasoning
factors, which can then be systematically recomposed with new images to
generate large collections of synthetic question-answer pairs. Each generated
question is paired with subquestions and intermediate answers, enabling
reinforcement learning with factor-level process rewards. Experiments on chart
reasoning show that COGS substantially improves performance on unseen
questions, with the largest gains on reasoning-heavy and compositional
questions. Moreover, training with a factor-level mixture of different seed
data yields better transfer across multiple datasets, suggesting that COGS
induces generalizable capabilities rather than dataset-specific overfitting. We
further demonstrate that the framework extends beyond charts to other domains
such as webpages.

</details>


### [40] [Generalized Dynamics Generation towards Scannable Physical World Model](https://arxiv.org/abs/2510.15041)
*Yichen Li,Zhiyi Li,Brandon Feng,Dinghuai Zhang,Antonio Torralba*

Main category: cs.CV

TL;DR: GDGen: A framework for unifying rigid, articulated, and soft body dynamics in a geometry-agnostic system using a potential energy perspective.


<details>
  <summary>Details</summary>
Motivation: Developing generalist embodied agents in scannable environments with complex physical behaviors.

Method: A framework that integrates rigid body, articulated body, and soft body dynamics into a unified, geometry-agnostic system. It introduces directional stiffness to capture a broad spectrum of physical behaviors and employs a neural field to represent deformation in a geometry-agnostic manner.

Result: GDGen robustly unifies diverse simulation paradigms.

Conclusion: GDGen offers a versatile foundation for creating interactive virtual environments and training robotic agents in complex, dynamically rich scenarios.

Abstract: Digital twin worlds with realistic interactive dynamics presents a new
opportunity to develop generalist embodied agents in scannable environments
with complex physical behaviors. To this end, we present GDGen (Generalized
Representation for Generalized Dynamics Generation), a framework that takes a
potential energy perspective to seamlessly integrate rigid body, articulated
body, and soft body dynamics into a unified, geometry-agnostic system. GDGen
operates from the governing principle that the potential energy for any stable
physical system should be low. This fresh perspective allows us to treat the
world as one holistic entity and infer underlying physical properties from
simple motion observations. We extend classic elastodynamics by introducing
directional stiffness to capture a broad spectrum of physical behaviors,
covering soft elastic, articulated, and rigid body systems. We propose a
specialized network to model the extended material property and employ a neural
field to represent deformation in a geometry-agnostic manner. Extensive
experiments demonstrate that GDGen robustly unifies diverse simulation
paradigms, offering a versatile foundation for creating interactive virtual
environments and training robotic agents in complex, dynamically rich
scenarios.

</details>


### [41] [Comprehensive language-image pre-training for 3D medical image understanding](https://arxiv.org/abs/2510.15042)
*Tassilo Wald,Ibrahim Ethem Hamamci,Yuan Gao,Sam Bond-Taylor,Harshita Sharma,Maximilian Ilse,Cynthia Lo,Olesya Melnichenko,Noel C. F. Codella,Maria Teodora Wetscherek,Klaus H. Maier-Hein,Panagiotis Korfiatis,Valentina Salvatelli,Javier Alvarez-Valle,Fernando Pérez-García*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的视觉-语言预训练方法，用于3D医学图像分析，通过引入报告生成目标和结合视觉预训练来解决数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D视觉-语言编码器由于数据可用性限制，能力受限。本文旨在通过增加额外的归纳偏置来缓解数据不足的问题。

Method: 引入报告生成目标，并将视觉-语言预训练与纯视觉预训练相结合，从而利用图像和图像-文本3D数据集。

Result: COLIPRI编码器在报告生成、分类探测和零样本分类方面取得了最先进的性能，并在语义分割方面保持竞争力。

Conclusion: 通过额外的归纳偏置和3D医学图像领域的最佳实践，开发了COLIPRI编码器系列。

Abstract: Vision-language pre-training, i.e., aligning images with paired text, is a
powerful paradigm to create encoders that can be directly used for tasks such
as classification and retrieval, and for downstream tasks such as segmentation
and report generation. In the 3D medical image domain, these capabilities allow
vision-language encoders (VLEs) to support radiologists by retrieving patients
with similar abnormalities or predicting likelihoods of abnormality. While the
methodology holds promise, data availability limits the capabilities of current
3D VLEs.
  In this paper, we alleviate the lack of data by injecting additional
inductive biases: introducing a report generation objective and pairing
vision-language pre-training with vision-only pre-training. This allows us to
leverage both image-only and paired image-text 3D datasets, increasing the
total amount of data to which our model is exposed. Through these additional
inductive biases, paired with best practices of the 3D medical imaging domain,
we develop the Comprehensive Language-image Pre-training (COLIPRI) encoder
family. Our COLIPRI encoders achieve state-of-the-art performance in report
generation, classification probing, and zero-shot classification, and remain
competitive for semantic segmentation.

</details>


### [42] [Directional Reasoning Injection for Fine-Tuning MLLMs](https://arxiv.org/abs/2510.15050)
*Chao Huang,Zeliang Zhang,Jiang Liu,Ximeng Sun,Jialian Wu,Xiaodong Yu,Ze Wang,Chenliang Xu,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级方法 DRIFT，用于提升 MLLM 的推理能力，该方法通过梯度空间注入推理知识，避免了传统微调和强化学习的资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLM 推理能力不如纯文本模型，且现有提升方法依赖于大规模数据或强化学习，成本高昂。简单的模型合并方法效果不稳定。

Method: 提出 DRIFT 方法，该方法预先计算推理先验（reasoning prior），然后在多模态微调期间使用它来调整梯度。

Result: 在多个多模态推理基准测试中，DRIFT 优于简单的模型合并和监督微调，并且以较低的成本匹配或超过了需要大量训练的方法。

Conclusion: DRIFT 是一种有效且经济的 MLLM 推理能力提升方法，它保留了标准监督微调的简单性，同时实现了高效的推理知识迁移。

Abstract: Multimodal large language models (MLLMs) are rapidly advancing, yet their
reasoning ability often lags behind that of strong text-only counterparts.
Existing methods to bridge this gap rely on supervised fine-tuning over
large-scale multimodal reasoning data or reinforcement learning, both of which
are resource-intensive. A promising alternative is model merging, which
interpolates parameters between reasoning-enhanced LLMs and multimodal
variants. However, our analysis shows that naive merging is not always a "free
lunch": its effectiveness varies drastically across model families, with some
(e.g., LLaVA, Idefics) benefiting while others (e.g., Qwen) suffer performance
degradation. To address this, we propose Directional Reasoning Injection for
Fine-Tuning (DRIFT) MLLMs, a lightweight method that transfers reasoning
knowledge in the gradient space, without destabilizing multimodal alignment.
DRIFT precomputes a reasoning prior as the parameter-space difference between
reasoning and multimodal variants, then uses it to bias gradients during
multimodal fine-tuning. This approach preserves the simplicity of standard
supervised fine-tuning pipelines while enabling efficient reasoning transfer.
Extensive experiments on multimodal reasoning benchmarks, including MathVista
and MathVerse, demonstrate that DRIFT consistently improves reasoning
performance over naive merging and supervised fine-tuning, while matching or
surpassing training-heavy methods at a fraction of the cost.

</details>


### [43] [MSAM: Multi-Semantic Adaptive Mining for Cross-Modal Drone Video-Text Retrieval](https://arxiv.org/abs/2510.15470)
*Jinghao Huang,Yaxiong Chen,Ganchao Liu*

Main category: cs.CV

TL;DR: 本文提出了无人机视频-文本检索（DVTR）任务，并提出了一个名为多语义自适应挖掘（MSAM）的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有的跨模态方法难以有效建模无人机视频的特性，需要专门为无人机场景定制的检索机制。

Method: MSAM引入了多语义自适应学习机制，结合帧间的动态变化，从特定场景区域提取丰富的语义信息。此外，还引入了跨模态交互特征融合池化机制，专注于目标区域的特征提取和匹配。

Result: 在两个自建的无人机视频-文本数据集上的大量实验表明，MSAM在无人机视频-文本检索任务中优于其他现有方法。

Conclusion: MSAM方法在无人机视频-文本检索任务中表现出色，代码和数据集将公开提供。

Abstract: With the advancement of drone technology, the volume of video data increases
rapidly, creating an urgent need for efficient semantic retrieval. We are the
first to systematically propose and study the drone video-text retrieval (DVTR)
task. Drone videos feature overhead perspectives, strong structural
homogeneity, and diverse semantic expressions of target combinations, which
challenge existing cross-modal methods designed for ground-level views in
effectively modeling their characteristics. Therefore, dedicated retrieval
mechanisms tailored for drone scenarios are necessary. To address this issue,
we propose a novel approach called Multi-Semantic Adaptive Mining (MSAM). MSAM
introduces a multi-semantic adaptive learning mechanism, which incorporates
dynamic changes between frames and extracts rich semantic information from
specific scene regions, thereby enhancing the deep understanding and reasoning
of drone video content. This method relies on fine-grained interactions between
words and drone video frames, integrating an adaptive semantic construction
module, a distribution-driven semantic learning term and a diversity semantic
term to deepen the interaction between text and drone video modalities and
improve the robustness of feature representation. To reduce the interference of
complex backgrounds in drone videos, we introduce a cross-modal interactive
feature fusion pooling mechanism that focuses on feature extraction and
matching in target regions, minimizing noise effects. Extensive experiments on
two self-constructed drone video-text datasets show that MSAM outperforms other
existing methods in the drone video-text retrieval task. The source code and
dataset will be made publicly available.

</details>


### [44] [A solution to generalized learning from small training sets found in everyday infant experiences](https://arxiv.org/abs/2510.15060)
*Frangil Ramirez,Elizabeth Clerkin,David J. Crandall,Linda B. Smith*

Main category: cs.CV

TL;DR: 婴儿通过有限的日常视觉经验学习和概括物体，这似乎与大数据集支持机器学习的观点相矛盾。本研究旨在揭示婴儿如何从有限的经验中实现泛化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨婴儿如何从有限的日常视觉经验中学习和概括视觉对象，尤其是在通常需要大数据集支持的机器学习背景下。

Method: 分析了14名7至11个月大的婴儿的以自我为中心的图像，以确定他们日常视觉输入的统计结构。通过计算实验，模拟了这种结构，并在机器学习中测试了其泛化能力。

Result: 发现婴儿的日常视觉输入呈现出一种块状相似性结构，其中包含高度相似的图像簇，并穿插着较少见的、更多变的图像。计算实验表明，在机器中模仿这种结构可以提高小数据集的泛化能力。

Conclusion: 婴儿经验的自然块状性可能支持早期的类别学习和泛化，并为各种问题和学习者的有效学习提供原则。

Abstract: Young children readily recognize and generalize visual objects labeled by
common nouns, suggesting that these basic level object categories may be given.
Yet if they are, how they arise remains unclear. We propose that the answer
lies in the statistics of infant daily life visual experiences. Whereas large
and diverse datasets typically support robust learning and generalization in
human and machine learning, infants achieve this generalization from limited
experiences. We suggest that the resolution of this apparent contradiction lies
in the visual diversity of daily life, repeated experiences with single object
instances. Analyzing egocentric images from 14 infants (aged 7 to 11 months) we
show that their everyday visual input exhibits a lumpy similarity structure,
with clusters of highly similar images interspersed with rarer, more variable
ones, across eight early-learned categories. Computational experiments show
that mimicking this structure in machines improves generalization from small
datasets in machine learning. The natural lumpiness of infant experience may
thus support early category learning and generalization and, more broadly,
offer principles for efficient learning across a variety of problems and kinds
of learners.

</details>


### [45] [SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images](https://arxiv.org/abs/2510.15072)
*Jiaxin Guo,Tongfan Guan,Wenzhen Dong,Wenzhao Zheng,Wenting Wang,Yue Wang,Yeung Yam,Yun-Hui Liu*

Main category: cs.CV

TL;DR: SaLon3R: a novel framework for Structure-aware, Long-term 3DGS Reconstruction, capable of reconstructing over 50 views in over 10 FPS, with 50% to 90% redundancy removal.


<details>
  <summary>Details</summary>
Motivation: Existing 3D Gaussian Splatting (3DGS) methods often predict per-pixel Gaussians and combine Gaussians from all views, leading to substantial redundancies and geometric inconsistencies in long-duration video sequences.

Method: Introduces compact anchor primitives to eliminate redundancy through differentiable saliency-aware Gaussian quantization, coupled with a 3D Point Transformer that refines anchor attributes and saliency.

Result: Resolves artifacts and prunes the redundant 3DGS in a single feed-forward pass, achieving state-of-the-art performance on both novel view synthesis and depth estimation.

Conclusion: Demonstrates superior efficiency, robustness, and generalization ability for long-term generalizable 3D reconstruction.

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled generalizable,
on-the-fly reconstruction of sequential input views. However, existing methods
often predict per-pixel Gaussians and combine Gaussians from all views as the
scene representation, leading to substantial redundancies and geometric
inconsistencies in long-duration video sequences. To address this, we propose
SaLon3R, a novel framework for Structure-aware, Long-term 3DGS Reconstruction.
To our best knowledge, SaLon3R is the first online generalizable GS method
capable of reconstructing over 50 views in over 10 FPS, with 50% to 90%
redundancy removal. Our method introduces compact anchor primitives to
eliminate redundancy through differentiable saliency-aware Gaussian
quantization, coupled with a 3D Point Transformer that refines anchor
attributes and saliency to resolve cross-frame geometric and photometric
inconsistencies. Specifically, we first leverage a 3D reconstruction backbone
to predict dense per-pixel Gaussians and a saliency map encoding regional
geometric complexity. Redundant Gaussians are compressed into compact anchors
by prioritizing high-complexity regions. The 3D Point Transformer then learns
spatial structural priors in 3D space from training data to refine anchor
attributes and saliency, enabling regionally adaptive Gaussian decoding for
geometric fidelity. Without known camera parameters or test-time optimization,
our approach effectively resolves artifacts and prunes the redundant 3DGS in a
single feed-forward pass. Experiments on multiple datasets demonstrate our
state-of-the-art performance on both novel view synthesis and depth estimation,
demonstrating superior efficiency, robustness, and generalization ability for
long-term generalizable 3D reconstruction. Project Page:
https://wrld.github.io/SaLon3R/.

</details>


### [46] [TGT: Text-Grounded Trajectories for Locally Controlled Video Generation](https://arxiv.org/abs/2510.15104)
*Guofeng Zhang,Angtian Wang,Jacob Zhiyuan Fang,Liming Jiang,Haotian Yang,Bo Liu,Yiding Yang,Guang Chen,Longyin Wen,Alan Yuille,Chongyang Ma*

Main category: cs.CV

TL;DR: 提出了一种名为文本引导轨迹（TGT）的框架，该框架基于轨迹和局部文本描述来调节视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在控制生成场景的主题构成方面能力有限，尤其是在复杂场景和多对象设置中。

Method: 引入位置感知交叉注意力（LACA）来整合轨迹和文本信号，并采用双CFG方案来分别调制局部和全局文本引导。还开发了一个数据处理流程，生成带有跟踪实体局部描述的轨迹，并标注了200万个高质量视频片段来训练TGT。

Result: TGT在视觉质量、文本对齐和运动可控性方面优于现有方法。

Conclusion: TGT使用点轨迹作为直观的运动控制柄，将每个轨迹与文本配对，以控制外观和运动。

Abstract: Text-to-video generation has advanced rapidly in visual fidelity, whereas
standard methods still have limited ability to control the subject composition
of generated scenes. Prior work shows that adding localized text control
signals, such as bounding boxes or segmentation masks, can help. However, these
methods struggle in complex scenarios and degrade in multi-object settings,
offering limited precision and lacking a clear correspondence between
individual trajectories and visual entities as the number of controllable
objects increases. We introduce Text-Grounded Trajectories (TGT), a framework
that conditions video generation on trajectories paired with localized text
descriptions. We propose Location-Aware Cross-Attention (LACA) to integrate
these signals and adopt a dual-CFG scheme to separately modulate local and
global text guidance. In addition, we develop a data processing pipeline that
produces trajectories with localized descriptions of tracked entities, and we
annotate two million high quality video clips to train TGT. Together, these
components enable TGT to use point trajectories as intuitive motion handles,
pairing each trajectory with text to control both appearance and motion.
Extensive experiments show that TGT achieves higher visual quality, more
accurate text alignment, and improved motion controllability compared with
prior approaches. Website: https://textgroundedtraj.github.io.

</details>


### [47] [Deep generative priors for 3D brain analysis](https://arxiv.org/abs/2510.15119)
*Ana Lawry Aguila,Dina Zemlyanker,You Cheng,Sudeshna Das,Daniel C. Alexander,Oula Puonti,Annabel Sorby-Adams,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 扩散模型是医学成像中强大的生成模型，但将其与领域知识相结合以指导脑成像问题仍然是一个主要挑战。


<details>
  <summary>Details</summary>
Motivation: 将数据驱动模型与领域知识相结合以指导脑成像问题仍然是一个主要挑战。神经影像中的贝叶斯逆问题长期以来为推理任务提供了一个成功的框架，其中结合成像过程的领域知识能够实现稳健的性能，而不需要大量的训练数据。然而，这些方法的解剖建模组件通常依赖于经典的数学先验，这些先验通常无法捕捉大脑解剖的复杂结构。

Method: 我们提出了扩散模型作为先验的第一个通用应用，用于解决广泛的医学成像逆问题。我们的方法利用在各种脑部MRI数据上广泛训练的基于分数的扩散先验，并结合灵活的前向模型，以捕捉常见的图像处理任务，如超分辨率、偏置场校正、修复及其组合。

Result: 在异构临床和研究MRI数据上的实验表明，我们的方法实现了最先进的性能，产生了Consistent、高质量的解决方案，而不需要配对的训练数据集。

Conclusion: 这些结果突出了扩散先验作为脑部MRI分析的通用工具的潜力。

Abstract: Diffusion models have recently emerged as powerful generative models in
medical imaging. However, it remains a major challenge to combine these
data-driven models with domain knowledge to guide brain imaging problems. In
neuroimaging, Bayesian inverse problems have long provided a successful
framework for inference tasks, where incorporating domain knowledge of the
imaging process enables robust performance without requiring extensive training
data. However, the anatomical modeling component of these approaches typically
relies on classical mathematical priors that often fail to capture the complex
structure of brain anatomy. In this work, we present the first general-purpose
application of diffusion models as priors for solving a wide range of medical
imaging inverse problems. Our approach leverages a score-based diffusion prior
trained extensively on diverse brain MRI data, paired with flexible forward
models that capture common image processing tasks such as super-resolution,
bias field correction, inpainting, and combinations thereof. We further
demonstrate how our framework can refine outputs from existing deep learning
methods to improve anatomical fidelity. Experiments on heterogeneous clinical
and research MRI data show that our method achieves state-of-the-art
performance producing consistent, high-quality solutions without requiring
paired training datasets. These results highlight the potential of diffusion
priors as versatile tools for brain MRI analysis.

</details>


### [48] [Fourier Transform Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2510.15138)
*Anthony Bilic,Guangyu Sun,Ming Li,Md Sanzid Bin Hossain,Yu Tian,Wei Zhang,Laura Brattain,Dexter Hadley,Chen Chen*

Main category: cs.CV

TL;DR: 提出了一种新的WSI分类框架，通过频域信息增强MIL，提高分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有WSI分类方法难以捕捉全局依赖关系，影响诊断预测。

Method: 提出FFT-MIL框架，利用快速傅里叶变换提取低频信息，并与空间patch特征融合。

Result: 在三个公共数据集上，FFT-MIL在宏F1和AUC指标上均有提升。

Conclusion: 频域学习是一种有效且高效的机制，可以捕捉WSI分类中的全局依赖关系。

Abstract: Whole Slide Image (WSI) classification relies on Multiple Instance Learning
(MIL) with spatial patch features, yet existing methods struggle to capture
global dependencies due to the immense size of WSIs and the local nature of
patch embeddings. This limitation hinders the modeling of coarse structures
essential for robust diagnostic prediction.
  We propose Fourier Transform Multiple Instance Learning (FFT-MIL), a
framework that augments MIL with a frequency-domain branch to provide compact
global context. Low-frequency crops are extracted from WSIs via the Fast
Fourier Transform and processed through a modular FFT-Block composed of
convolutional layers and Min-Max normalization to mitigate the high variance of
frequency data. The learned global frequency feature is fused with spatial
patch features through lightweight integration strategies, enabling
compatibility with diverse MIL architectures.
  FFT-MIL was evaluated across six state-of-the-art MIL methods on three public
datasets (BRACS, LUAD, and IMP). Integration of the FFT-Block improved macro F1
scores by an average of 3.51% and AUC by 1.51%, demonstrating consistent gains
across architectures and datasets. These results establish frequency-domain
learning as an effective and efficient mechanism for capturing global
dependencies in WSI classification, complementing spatial features and
advancing the scalability and accuracy of MIL-based computational pathology.

</details>


### [49] [XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models](https://arxiv.org/abs/2510.15148)
*Xingrui Wang,Jiang Liu,Chao Huang,Xiaodong Yu,Ze Wang,Ximeng Sun,Jialian Wu,Alan Yuille,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: XModBench是一个用于评估多模态大型语言模型（OLLM）跨模态一致性的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有的基准主要评估一般的跨模态问答能力，但OLLM是否实现了模态不变推理或表现出模态特定的偏差尚不清楚。

Method: XModBench包含60,828个多项选择题，涵盖五个任务家族，并系统地涵盖了问题-答案对中的所有六个模态组合，从而可以对OLLM的模态不变推理、模态差异和方向不平衡进行细粒度诊断。

Result: 实验表明，即使是最强的模型Gemini 2.5 Pro，(i)在空间和时间推理方面也很挣扎，准确率低于60%，(ii)揭示了持续存在的模态差异，当相同的语义内容通过音频而不是文本传达时，性能会大幅下降，(iii)显示出系统的方向不平衡，当视觉用作上下文时，一致性低于文本。

Conclusion: 目前OLLM距离真正的模态不变推理还差得很远，XModBench是评估和提高跨模态能力的基本诊断工具。

Abstract: Omni-modal large language models (OLLMs) aim to unify audio, vision, and text
understanding within a single framework. While existing benchmarks primarily
evaluate general cross-modal question-answering ability, it remains unclear
whether OLLMs achieve modality-invariant reasoning or exhibit modality-specific
biases. We introduce XModBench, a large-scale tri-modal benchmark explicitly
designed to measure cross-modal consistency. XModBench comprises 60,828
multiple-choice questions spanning five task families and systematically covers
all six modality compositions in question-answer pairs, enabling fine-grained
diagnosis of an OLLM's modality-invariant reasoning, modality disparity, and
directional imbalance. Experiments show that even the strongest model, Gemini
2.5 Pro, (i) struggles with spatial and temporal reasoning, achieving less than
60% accuracy, (ii) reveals persistent modality disparities, with performance
dropping substantially when the same semantic content is conveyed through audio
rather than text, and (iii) shows systematic directional imbalance, exhibiting
lower consistency when vision serves as context compared to text. These
findings indicate that current OLLMs remain far from truly modality-invariant
reasoning and position XModBench as a fundamental diagnostic tool for
evaluating and improving cross-modal competence. All data and evaluation tools
will be available at https://xingruiwang.github.io/projects/XModBench/.

</details>


### [50] [Train a Unified Multimodal Data Quality Classifier with Synthetic Data](https://arxiv.org/abs/2510.15162)
*Weizhi Wang,Rongmei Lin,Shiyang Li,Colin Lockard,Ritesh Sarkhel,Sanket Lokegaonkar,Jingbo Shang,Xifeng Yan,Nasser Zalmout,Xian Li*

Main category: cs.CV

TL;DR: 这篇论文提出了一种名为UniFilter的统一多模态数据质量分类器，用于过滤高质量的图像-文本标题和交错数据，以提升多模态大语言模型（MLLM）的预训练效果。


<details>
  <summary>Details</summary>
Motivation: 当前图像-文本交错数据的高质量数据过滤方法研究不足。

Method: 该方法通过半合成方法生成多质量等级的图像-文本数据，用于训练UniFilter。

Result: 使用UniFilter过滤后的数据训练的MLLM，在zero-shot推理和上下文学习能力上显著增强，并在各种benchmark上表现更强。

Conclusion: 高质量的多模态预训练可以显著提升下游任务的性能。

Abstract: The Multimodal Large Language Models (MLLMs) are continually pre-trained on a
mixture of image-text caption data and interleaved document data, while the
high-quality data filtering towards image-text interleaved document data is
under-explored. We propose to train an efficient MLLM as a Unified Mulitmodal
Data Quality Classifier to Filter both high-quality image-text caption and
interleaved data (UniFilter). To address the challenge of collecting diverse
labeled multimodal data, we introduce a semi-synthetic approach that leverages
readily available raw images and generates corresponding text across four
quality levels. This method enables efficient creation of sample-score pairs
for both caption and interleaved document data to train UniFilter. We apply
UniFilter to curate high-quality caption data from DataComp caption dataset and
interleaved data from the OBELICS image-text interleaved dataset. MLLMs
pre-trained on the filtered data demonstrate significantly enhanced
capabilities compared to those trained on baseline-filtered data, achieving
stronger zero-shot reasoning and in-context learning capabilities. After visual
supervised fine-tuning, these UniFilter-induced MLLMs achieve stronger
performance on various benchmarks, highlighting the downstream benefits of
high-quality multimodal pre-training. We release the synthetic training data
used for training UniFilter, the UniFilter model checkpoints, and the
high-quality interleaved document subset OBELICS-HQ, curated by UniFilter, to
the community for reproduction and further development.

</details>


### [51] [Hyperparameter Optimization and Reproducibility in Deep Learning Model Training](https://arxiv.org/abs/2510.15164)
*Usman Afzaal,Ziyu Su,Usama Sajjad,Hao Lu,Mostafa Rezapour,Metin Nafi Gurcan,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 该研究调查了组织病理学基础模型训练中的可重复性问题，重点关注软件随机性、硬件不确定性和超参数不一致报告的影响。


<details>
  <summary>Details</summary>
Motivation: 组织病理学基础模型训练中的可重复性仍然是一个关键挑战。

Method: 在QUILT-1M数据集上训练了一个CLIP模型，并系统地评估了不同超参数设置和增强策略对三个下游组织病理学数据集（PatchCamelyon、LC25000-Lung和LC25000-Colon）的影响。

Result: 发现了一些明确的趋势：RandomResizedCrop值为0.7-0.8优于更激进或保守的设置，没有局部损失的分布式训练提高了稳定性，并且低于5.0e-5的学习率始终降低所有数据集的性能。LC25000（Colon）数据集始终提供最可重复的基准。

Conclusion: 计算病理学中的可重复性不仅取决于透明的文档，还取决于精心选择的实验配置，并为未来开发可重复的数字病理学基础模型提供了实用规则。

Abstract: Reproducibility remains a critical challenge in foundation model training for
histopathology, often hindered by software randomness, hardware
non-determinism, and inconsistent hyperparameter reporting. To investigate
these issues, we trained a CLIP model on the QUILT-1M dataset and
systematically evaluated the impact of different hyperparameter settings and
augmentation strategies across three downstream histopathology datasets
(PatchCamelyon, LC25000-Lung, and LC25000-Colon). Despite variability across
runs, we identified clear trends: RandomResizedCrop values of 0.7-0.8
outperformed more aggressive (0.6) or conservative (0.9) settings, distributed
training without local loss improved stability, and learning rates below 5.0e-5
consistently degraded performance across all datasets. The LC25000 (Colon)
dataset consistently provided the most reproducible benchmark. These findings
highlight that reproducibility in computational pathology depends not only on
transparent documentation but also on carefully chosen experimental
configurations, and we provide practical rules to guide future efforts in
developing reproducible foundation models for digital pathology.

</details>


### [52] [Salient Concept-Aware Generative Data Augmentation](https://arxiv.org/abs/2510.15194)
*Tianchen Zhao,Xuanbai Chen,Zhihua Li,Jun Fang,Dongsheng An,Xiang Xu,Zhuowen Tu,Yifan Xing*

Main category: cs.CV

TL;DR: 提出了一种个性化的图像生成框架，使用显著性概念感知图像嵌入模型来减少不相关的视觉细节的影响，从而保持图像和文本输入之间的直观对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的生成数据增强方法难以平衡保真度和多样性，因为在合成过程中，表征通常会与非必要的输入图像属性（如环境上下文）纠缠在一起，从而与旨在修改这些元素的文本提示产生冲突。

Method: 使用显著性概念感知图像嵌入模型来减少不相关的视觉细节的影响。

Result: 在八个细粒度视觉数据集上表现出卓越的性能，优于最先进的增强方法，在传统和长尾设置下，平均分类精度分别提高了 0.73% 和 6.5%。

Conclusion: 该框架通过生成更好地保留类区分特征并具有额外受控变化的图像，有效地增强了训练数据集的多样性，从而提高了下游模型的鲁棒性。

Abstract: Recent generative data augmentation methods conditioned on both image and
text prompts struggle to balance between fidelity and diversity, as it is
challenging to preserve essential image details while aligning with varied text
prompts. This challenge arises because representations in the synthesis process
often become entangled with non-essential input image attributes such as
environmental contexts, creating conflicts with text prompts intended to modify
these elements. To address this, we propose a personalized image generation
framework that uses a salient concept-aware image embedding model to reduce the
influence of irrelevant visual details during the synthesis process, thereby
maintaining intuitive alignment between image and text inputs. By generating
images that better preserve class-discriminative features with additional
controlled variations, our framework effectively enhances the diversity of
training datasets and thereby improves the robustness of downstream models. Our
approach demonstrates superior performance across eight fine-grained vision
datasets, outperforming state-of-the-art augmentation methods with averaged
classification accuracy improvements by 0.73% and 6.5% under conventional and
long-tail settings, respectively.

</details>


### [53] [CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records](https://arxiv.org/abs/2510.15208)
*Daniela Vega,Hannah V. Ceballos,Javier S. Vera,Santiago Rodriguez,Alejandra Perez,Angela Castillo,Maria Escobar,Dario Londoño,Luis A. Sarmiento,Camila I. Castro,Nadiezhda Rodriguez,Juan C. Briceño,Pablo Arbeláez*

Main category: cs.CV

TL;DR: 本研究提出了CARDIUM数据集，这是一个公开的多模态数据集，整合了胎儿超声和超声心动图图像以及母亲临床记录，用于产前CHD检测。此外，他们还提出了一种强大的多模态Transformer架构，该架构结合了交叉注意力机制，以融合来自图像和表格数据的特征表示。


<details>
  <summary>Details</summary>
Motivation: 现有的先天性心脏病（CHD）产前诊断面临数据稀缺、质量低的问题，且缺乏整合影像和临床数据的公共资源，限制了人工智能模型在临床决策中的应用。

Method: 构建了CARDIUM数据集，并提出了一种多模态Transformer架构，使用交叉注意力机制融合图像和表格数据。

Result: 提出的多模态方法在CHD检测方面比单一模态方法分别提高了11%和50%，在CARDIUM数据集上实现了79.8 $\pm$ 4.8%的F1分数。

Conclusion: 本研究发布了CARDIUM数据集和代码，旨在鼓励对这一未被充分探索的领域进行进一步研究。

Abstract: Prenatal diagnosis of Congenital Heart Diseases (CHDs) holds great potential
for Artificial Intelligence (AI)-driven solutions. However, collecting
high-quality diagnostic data remains difficult due to the rarity of these
conditions, resulting in imbalanced and low-quality datasets that hinder model
performance. Moreover, no public efforts have been made to integrate multiple
sources of information, such as imaging and clinical data, further limiting the
ability of AI models to support and enhance clinical decision-making. To
overcome these challenges, we introduce the Congenital Anomaly Recognition with
Diagnostic Images and Unified Medical records (CARDIUM) dataset, the first
publicly available multimodal dataset consolidating fetal ultrasound and
echocardiographic images along with maternal clinical records for prenatal CHD
detection. Furthermore, we propose a robust multimodal transformer architecture
that incorporates a cross-attention mechanism to fuse feature representations
from image and tabular data, improving CHD detection by 11% and 50% over image
and tabular single-modality approaches, respectively, and achieving an F1 score
of 79.8 $\pm$ 4.8% in the CARDIUM dataset. We will publicly release our dataset
and code to encourage further research on this unexplored field. Our dataset
and code are available at https://github.com/BCVUniandes/Cardium, and at the
project website https://bcv-uniandes.github.io/CardiumPage/

</details>


### [54] [The Face of Persuasion: Analyzing Bias and Generating Culture-Aware Ads](https://arxiv.org/abs/2510.15240)
*Aysan Aghazadeh,Adriana Kovashka*

Main category: cs.CV

TL;DR: 本文研究了文本到图像模型在定制视觉广告和针对特定人群方面的潜力，并通过检查不同广告主题中广告的人口统计偏差，以及仅在所描绘人物的性别/种族方面相同的广告的不同说服力水平（由模型判断）来调查这种潜力。我们还尝试了一种针对特定国家/地区的广告技术。


<details>
  <summary>Details</summary>
Motivation: 研究文本到图像模型在定制视觉广告和针对特定人群方面的潜力。

Method: 检查不同广告主题中广告的人口统计偏差，以及仅在所描绘人物的性别/种族方面相同的广告的不同说服力水平（由模型判断）。尝试了一种针对特定国家/地区的广告技术。

Result: 发现广告中存在人口统计偏差，并且针对不同性别/种族的人的说服力水平存在差异。还发现针对特定国家/地区的广告技术是有效的。

Conclusion: 文本到图像模型在定制视觉广告和针对特定人群方面具有潜力，但也存在人口统计偏差和说服力差异等问题。

Abstract: Text-to-image models are appealing for customizing visual advertisements and
targeting specific populations. We investigate this potential by examining the
demographic bias within ads for different ad topics, and the disparate level of
persuasiveness (judged by models) of ads that are identical except for
gender/race of the people portrayed. We also experiment with a technique to
target ads for specific countries. The code is available at
https://github.com/aysanaghazadeh/FaceOfPersuasion

</details>


### [55] [DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion](https://arxiv.org/abs/2510.15264)
*Weijie Wang,Jiagang Zhu,Zeyu Zhang,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Chaojun Ni,Haoxiao Wang,Guan Huang,Xinze Chen,Yukun Zhou,Wenkang Qin,Duochao Shi,Haoyun Li,Guanghong Jia,Jiwen Lu*

Main category: cs.CV

TL;DR: DriveGen3D是一个用于生成高质量和高度可控的动态3D驾驶场景的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶场景合成方法在扩展时间生成方面存在计算需求过高的问题，或者只关注长时间视频合成而没有3D表示，或者仅限于静态单场景重建。

Method: DriveGen3D整合了加速的长期视频生成和大规模动态场景重建，通过多模态条件控制。它包含两个组件：FastDrive-DiT，用于在高分辨率下合成时间连贯的视频；FastRecon3D，用于快速构建随时间变化的3D高斯表示，确保空间-时间一致性。

Result: DriveGen3D能够实时生成扩展的驾驶视频（高达424x800，12 FPS）和相应的动态3D场景，在新视角合成方面实现了0.811的SSIM和22.84的PSNR。

Conclusion: DriveGen3D在保持参数效率的同时，实现了高质量和高度可控的动态3D驾驶场景生成。

Abstract: We present DriveGen3D, a novel framework for generating high-quality and
highly controllable dynamic 3D driving scenes that addresses critical
limitations in existing methodologies. Current approaches to driving scene
synthesis either suffer from prohibitive computational demands for extended
temporal generation, focus exclusively on prolonged video synthesis without 3D
representation, or restrict themselves to static single-scene reconstruction.
Our work bridges this methodological gap by integrating accelerated long-term
video generation with large-scale dynamic scene reconstruction through
multimodal conditional control. DriveGen3D introduces a unified pipeline
consisting of two specialized components: FastDrive-DiT, an efficient video
diffusion transformer for high-resolution, temporally coherent video synthesis
under text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a
feed-forward reconstruction module that rapidly builds 3D Gaussian
representations across time, ensuring spatial-temporal consistency. Together,
these components enable real-time generation of extended driving videos (up to
$424\times800$ at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM
of 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining
parameter efficiency.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [56] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: 本文介绍了一个新的基准测试 OpenEstimate，用于评估语言模型在不确定性下进行数值估计任务的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型评估主要集中在具有明确答案和成功标准的问题上，而实际应用场景需要模型处理不完整的信息和在不确定性下进行推理。因此，需要更好地评估语言模型在不确定性下推理的能力。

Method: 本文构建了一个多领域的基准测试 OpenEstimate，用于评估语言模型在需要综合大量背景信息并将预测表示为概率先验的数值估计任务上的表现。该基准测试评估了这些先验的准确性和校准性。

Result: 在六个前沿语言模型上的评估结果表明，语言模型引出的先验通常不准确且过于自信。性能的提高适度地取决于如何从模型中引出不确定性，但很大程度上不受抽样策略、推理工作或提示设计变化的影响。

Conclusion: OpenEstimate 基准测试为前沿语言模型提供了一个具有挑战性的评估，并为一个开发更擅长概率估计和在不确定性下推理的模型提供了一个平台。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [57] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 提出了一种新的基于深度强化学习（DRL）的程序化关卡设计方法，在Unity 3D环境中，通过hummingbird agent和floating island agent的协同，实现了动态、可重玩和可扩展的游戏环境生成。


<details>
  <summary>Details</summary>
Motivation: 在游戏开发中，程序化内容生成（PCG）技术越来越受欢迎，它可以减少手动工作量，生成动态、可重玩和可扩展的环境。

Method: 使用近端策略优化（PPO）算法训练hummingbird agent和floating island agent。hummingbird agent学习在地形中导航并收集鲜花，island agent学习基于障碍物位置和hummingbird agent的反馈生成鲜花布局。

Result: 该方法不仅产生了有效和高效的agent行为，而且为机器学习驱动的自主游戏关卡设计开辟了新的机会。

Conclusion: 这项工作突出了DRL在使智能agent能够在虚拟环境中生成和解决内容方面的潜力，从而推动了AI对创意游戏开发过程的贡献。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [58] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: 提出 JudgeSQL 框架，通过结构化推理和加权共识竞赛机制重新定义 SQL 候选选择。


<details>
  <summary>Details</summary>
Motivation: 现有 Text-to-SQL 方法在测试时面临从大量候选中选择正确查询的瓶颈，现有选择方法提供的信息不足，容易出现不一致的评分和脆弱的推理链。

Method: 开发了一个基于推理的 SQL Judge 模型，该模型通过强化学习提炼推理轨迹，并结合加权共识竞赛，整合了显式推理偏好和隐式生成器置信度。

Result: 在 BIRD 基准测试中，JudgeSQL 表现出卓越的 SQL 判断能力，并在跨规模泛化和生成器容量方面表现出良好的鲁棒性。

Conclusion: JudgeSQL 框架能够更可靠和高效地选择 SQL 查询。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [59] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: AGI 的进展受到理论限制，而不是数据或规模的限制。


<details>
  <summary>Details</summary>
Motivation: 挑战柏拉图表征假设，认为仅凭观察充分性无法保证干预能力。

Method: 从知识、学习、智能、反事实能力和 AGI 的定义出发，分析观察学习的局限性，并提出了一种以错误为中心的转变。将问题转化为关于显式和隐式错误如何在 agent 的行为下演变，哪些错误在固定的假设空间内是无法达到的，以及猜想和批判如何扩展该空间这三个问题。然后，提出了因果机制，这是一种机制优先的程序，其中假设空间变化是一流的操作，并且在有用时使用概率结构，而不是假定的。

Result: 提出了结构性原则，使错误发现和纠正变得容易处理，包括用于模块化干预的差分局部性和自治原则、用于可分离性的独立因果机制的规范不变形式以及用于类比保存的组合自治原则，以及可操作的诊断。

Conclusion: 目标是为能够将无法达到的错误转换为可达到的错误并纠正它们的系统提供支架。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [60] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 本文提出了一套从发票文档中提取结构化信息的方法，并提出了一组评估指标 (EM) 来评估提取的数据相对于带注释的真实值的准确性。


<details>
  <summary>Details</summary>
Motivation: 从发票文档中提取结构化信息

Method: 预处理扫描或数字发票，应用 Docling 和 LlamaCloud Services 来识别和提取关键字段，例如发票号码、日期、总金额和供应商详细信息。

Result: 建立了一个强大的评估框架，包括字段级精度、一致性检查失败和精确匹配准确性。

Conclusion: 所提出的指标提供了一种标准化方法来比较不同的提取方法，并突出显示特定领域性能的优势和劣势。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [61] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: 提出了 HugAgent，一个用于平均到个体推理适应的基准。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合大型语言模型在模拟人类推理和捕捉个体推理风格方面的差距。

Method: 引入了一个双轨设计，包括合成轨道和人类轨道，以评估智能体内部的保真度。

Result: 实验表明，当前的大型语言模型在适应个体推理方面存在差距。

Conclusion: HugAgent 是首个用于将机器推理与人类思维个性对齐的可扩展基准。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [62] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 提出了一个大规模的、长时间跨度的真实工作场所情绪数据集，包含员工面部表情记录和元数据。


<details>
  <summary>Details</summary>
Motivation: 在真实工作场所环境中进行自动情绪识别仍然是一个具有挑战性的问题，因为缺乏大规模的、纵向的数据集。

Method: 通过深度学习的面部表情识别技术，从38名员工在30.5个月内收集的733,651个面部表情记录中提取情绪概率，并结合工作角色、雇佣结果和人格特质等元数据。

Result: 数据集具有高质量，成功复制了已知的心理模式（周末效应和昼夜节律），并且对员工离职具有完美的预测效度（AUC=1.0）。基线实验在情绪分类和效价预测方面取得了良好的效果。

Conclusion: 该数据集是公开可用的最大、最长的纵向工作场所情绪数据集，可用于情绪识别、情感动态建模、情绪传染、离职预测和情绪感知系统设计等研究。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [63] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 当前AGI评估对所有领域赋予相同的权重，并且依赖于快照分数，这导致了两个问题：领域重要性被同等看待，且无法区分持久能力和脆弱表现。因此，论文提出应该根据领域的核心因果关系进行加权，并要求提供跨会话的持久性证据。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估中存在的问题：对所有领域赋予相同的权重，并且依赖于快照分数，这无法准确反映人类智能的研究结果，也无法区分持久能力和脆弱表现。

Method: 论文提出了两种与电池兼容的扩展方法：一种是中心优先评分，它导入了CHC导出的权重，并进行透明的敏感性分析；另一种是集群稳定性指数系列，它可以分离profile的持久性、持久学习和错误纠正。

Result: 提出的方法能够在保持多域广度的同时，减少脆弱性和过度优化。

Conclusion: 通过可测试的预测和黑盒协议，实验室可以在没有架构访问权限的情况下采用这些方法。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [64] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 提出了一种基于LLM Agent和知识图谱交互的多维数据分析方法，构建动态协作分析生态系统。


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，从海量、异构和复杂关联的多维数据中提取深度洞察成为一项重大挑战。LLM在自然语言理解和生成方面表现良好，但在处理结构化知识时仍存在“幻觉”问题，难以实时更新。知识图谱虽然可以显式存储结构化知识，但其静态性质限制了动态交互和分析能力。

Method: 利用LLM Agent自动从非结构化数据中提取产品数据，实时构建和可视化知识图谱，并通过交互平台支持用户对图节点进行深度探索和分析。

Result: 该方法在产品生态系统分析、关系挖掘和用户驱动的探索性分析方面具有显著优势。

Conclusion: 为多维数据分析提供了新的思路和工具。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [65] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: KG-Agent: An experience-driven learning framework that structures an agent's raw pixel-level interactions into a persistent State-Action Knowledge Graph (SA-KG).


<details>
  <summary>Details</summary>
Motivation: Existing software lacks accessible APIs, requiring agents to operate solely through pixel-based GUIs, leading to inefficiency.

Method: Structures raw pixel-level interactions into a State-Action Knowledge Graph (SA-KG) and uses a hybrid intrinsic reward mechanism based on graph topology.

Result: Significant improvements in exploration efficiency and strategic depth over state-of-the-art methods in Civilization V and Slay the Spire.

Conclusion: KG-Agent overcomes inefficient exploration by linking functionally similar but visually distinct GUI states, forming a rich neighborhood of experience that enables the agent to generalize from a diverse set of historical strategies. The hybrid reward mechanism decouples strategic planning from pure discovery, allowing the agent to effectively value setup actions with delayed gratification.

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [66] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个多模态Agent系统，模仿人类认知记忆，使用图结构存储多模态上下文信息，并用语义标签驱动检索，性能优于传统多模态RAG和MemGPT。


<details>
  <summary>Details</summary>
Motivation: 现有Agent系统忽略了多模态信号的重要性，而人类记忆是多模态的，因此需要一个能够处理多模态信息的Agent系统。

Method: 构建一个包含编码、存储、检索和行动四个阶段的循环系统。使用图结构多模态上下文记忆存储信息，并用语义标签关联上下文，实现概念驱动的检索。

Result: 在ImageNet分类任务中速度提升3.5倍，并在MSC基准测试中优于MemGPT。

Conclusion: AUGUSTUS系统性能优于传统多模态RAG，并在特定任务上超越MemGPT。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [67] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V: a new benchmark and framework for instruction-to-HTML generation.


<details>
  <summary>Details</summary>
Motivation: Recent advancements on leveraging LLM for coding and multimodal understanding.

Method: An unbounded and extensible agentic crawling framework that continuously collects real-world webpages; a structured, section-wise data representation that integrates metadata, localized UI screenshots, and JSON-formatted text and image assets; a section-level multimodal evaluation protocol aligning text, layout, and visuals.

Result: Experiments with state-of-the-art LLMs and ablation studies validate the effectiveness of our structured data and section-wise evaluation, as well as the contribution of each component.

Conclusion: WebGen-V is the first work to enable high-granularity agentic crawling and evaluation for instruction-to-HTML generation, providing a unified pipeline from real-world data acquisition and webpage generation to structured multimodal assessment.

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [68] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS是一个通过整合视觉先验和多个先进的大型多模态模型来提高SFT数据质量的流程，从而提升微调后模型在多模态任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有SFT数据增强方法因视觉感知不足而存在事实错误和幻觉问题。

Method: 该方法利用视觉识别模型和OCR系统提取结构化视觉先验，结合多个LMMs进行评估和改进答案，并通过统计方法融合评分，训练轻量级critic模型。

Result: 在六个多模态基准测试中，使用VERITAS处理的数据微调的模型始终优于使用原始数据的模型，尤其是在文本丰富和细粒度推理任务中。

Conclusion: VERITAS流程和相应的critic模型能够有效提高SFT数据的质量，并在多模态任务中实现更优性能。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [69] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: 提出了一种新的RL框架DEPO，以减少模型不必要的推理。


<details>
  <summary>Details</summary>
Motivation: 现有RL算法存在回复过长和过度思考的问题，导致推理延迟和计算消耗增加。

Method: DEPO包含三个核心组件：优势解耦算法、难度感知长度惩罚和优势剪切方法。

Result: DEPO在DeepSeek-Distill-Qwen-7B和DeepSeek-Distill-Qwen-1.5B上实现了39%的序列长度缩减，并减少了低效token中过度的推理路径，同时在总体准确性上优于基线模型。

Conclusion: DEPO能够有效减少模型不必要的推理，同时保持或提高准确性。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [70] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 这篇论文提出了一种基于强化学习和关系图卷积神经网络的自动布局规划引擎，旨在解决模拟集成电路布局中布线感知布局规划的需求。


<details>
  <summary>Details</summary>
Motivation: 模拟集成电路布局对电性和特定问题约束有严格要求，且布局规划和布线步骤相互依赖，导致机器学习技术应用受限。布局工程师需要易于使用的布线感知布局规划解决方案。

Method: 该方法结合了更高的网格分辨率、精确的引脚信息集成和动态布线资源估计技术，以平衡布线和面积效率。

Result: 与以往基于学习的先进技术相比，该方法在模拟环境中实现了13.8%的无用空间减少，40.6%的线长减少和73.4%的布线成功率提高。

Conclusion: 该方法能够满足工业标准，并显著提高了布线效率和布局质量。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [71] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 这篇论文提出了一种使AI目标可修正的方法，以避免AI抵制训练和目标更新。


<details>
  <summary>Details</summary>
Motivation: AI在训练过程中可能会抵制目标更新，因为继续追求已部分学习的目标通常更有利。可修正性允许纠正错误和改变人类偏好，因此是一项关键的安全属性。

Method: 论文提出了一种转换方法，构建任何可以被修正的目标的可修正版本，且不牺牲性能。该方法通过有条件地引出奖励预测来实现，并可递归扩展到新创建的代理，防止代理故意修改其目标。

Result: 通过两个网格世界实验证明，这些可修正的目标可以被有效地学习，并能产生期望的行为。

Conclusion: 论文定义了可修正性的正式定义，并提供了一种转换方法来构建可修正的目标，实验验证了该方法的可行性。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [72] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS is an end-to-end RL framework that incentivizes Multi-Agent Reasoning of LLMs through Self-play in both cooperative and competitive games.


<details>
  <summary>Details</summary>
Motivation: Developing LLMs to cooperate and compete effectively within multi-agent systems is a critical step towards more advanced intelligence. However, extending RL to multi-turn, multi-agent scenarios remains underexplored due to the challenges of long-horizon credit assignment and agent-specific advantage estimation.

Method: MARS features a turn-level advantage estimator that aligns learning signals with each interaction for credit assignment, and an agent-specific advantage normalization to stabilize multi-agent training. The agent is trained from Qwen3-4B and learns with self-play across cooperative and competitive games.

Result: The MARS agent develops strong strategic abilities that generalize to held-out games with up to 28.7% performance improvements. It also achieves significant performance gains of 10.0% on AIME and 12.5% on GPQA-Diamond when integrated into leading multi-agent systems.

Conclusion: End-to-end RL training with self-play in strategic games is a powerful approach for developing generalizable multi-agent reasoning capabilities in LLMs.

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [73] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds is an agentic system using LoRA adapters as domain-specific tools, allowing the base LLM to dynamically select the most relevant LoRA tool for each query.


<details>
  <summary>Details</summary>
Motivation: To enable seamless switching between different domain experts on demand by combining multi-agent orchestration with parameter-efficient fine-tuning.

Method: The base LLM acts as a semantic router, analyzing each query and selecting the most relevant LoRA tool. LangGraph is used for workflow management.

Result: Accurate, specialized responses while preserving conversational ability.

Conclusion: Adaptive Minds provides a scalable and extensible foundation for domain-adaptive AI assistance, and it is fully open source.

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [74] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 这篇论文提出了一种解决强化学习中判断不一致问题的新框架。


<details>
  <summary>Details</summary>
Motivation: 以往研究主要关注判断的准确性，而忽略了逻辑一致性问题，特别是偏好循环等问题。

Method: 该框架包括冲突检测率（CDR）和去冲突图奖励（DGR）两个主要贡献。DGR通过构建偏好图，将其转换为无冲突的DAG，并生成逻辑上一致的奖励信号。

Result: 实验结果表明，该框架显著提高了训练稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈的一个关键且可管理的维度。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [75] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: 本文提出了一种用于可靠感应电机故障诊断的多模态超图对比注意网络（MM-HCAN）。


<details>
  <summary>Details</summary>
Motivation: 传统的故障诊断方法难以捕捉复杂的多模态信号关系，并且在噪声或跨域条件下性能下降。本文旨在解决这些问题。

Method: 该方法集成了对比学习和超图拓扑，用于多模态传感器融合，从而能够联合建模模内和模间依赖关系。

Result: 在三个真实世界的基准测试中，MM-HCAN 达到了高达 99.82% 的准确率，并具有强大的跨域泛化能力和抗噪声能力。

Conclusion: MM-HCAN 为全面的多故障诊断提供了一个可扩展且强大的解决方案，支持工业环境中的预测性维护和延长资产寿命。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [76] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 该论文提出了一种机器学习框架，通过整合患者既往就诊信息来改进健康监测，尤其是在既往就诊次数有限且频率不定的情况下。


<details>
  <summary>Details</summary>
Motivation: 在医学中，时间背景对于评估患者健康状况的关键变化非常重要。

Method: 该模型首先使用最近一次患者就诊的医疗数据估计疾病的初始风险，然后使用从先前收集的影像和/或临床生物标志物中提取的信息来完善此评估。

Result: 通过整合既往信息，可以直接将假阳性转化为真阴性，从而在保持高灵敏度的同时提高整体特异性。当整合来自多达三次既往影像学检查的信息时，假阳性率从 51% 逐步降低至 33%，当也包括来自既往临床数据的额外背景信息时，假阳性率进一步降低至 24%。

Conclusion: 随时间收集的信息提供了相关的背景信息，以提高医疗风险预测的特异性。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [77] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 论文提出了一种名为Thoth的方法，用于从自然语言查询中自动生成可执行的科研协议，并通过引入SciRecipe数据集和“Sketch-and-Fill”范式以及结构化奖励机制来提高协议的完整性和一致性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型(LLMs)生成的协议不完整或不一致，限制了它们在可重复科学中的应用。

Method: 1. 构建了一个大规模数据集SciRecipe，包含超过12K的结构化协议。 2. 提出了“Sketch-and-Fill”范式，分离分析、结构化和表达步骤。 3. 设计了结构化组件奖励机制，评估步骤粒度、动作顺序和语义保真度。 4. 开发了Thoth，通过分阶段的Knowledge-to-Action过程进行训练。

Result: Thoth在多个基准测试中超过了其他LLMs，在步骤对齐、逻辑排序和语义准确性方面取得了显著改进。

Conclusion: 该方法为可靠的科学助手铺平了道路，这些助手可以将知识与实验执行联系起来。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [78] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 提出了一个名为 freephdlabor 的开源多代理框架，旨在解决现有科学研究 Agent 系统的局限性，实现自动化科研。


<details>
  <summary>Details</summary>
Motivation: 现有 Agent 系统工作流程僵化，无法适应中间结果，且上下文管理不足，阻碍了长期研究。

Method: 该框架具有完全动态的工作流程，由实时 Agent 推理决定，以及模块化架构，允许用户自定义 Agent。

Result: 该框架提供自动上下文压缩、基于工作区的通信、跨会话的内存持久性和非阻塞的人工干预机制等功能，将自动化研究转变为持续的研究项目。

Conclusion: 该工作旨在促进自动化研究在科学领域的更广泛应用，使从业者能够部署交互式多代理系统，自主完成从构思到实验到出版的端到端研究。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [79] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 这篇论文研究了如何将大型语言模型与人类价值观对齐，并提出了解决现有方法中忽略的人类评估者的多样性和成对反馈的局限性的方案。


<details>
  <summary>Details</summary>
Motivation: 现有RLHF方法通常假设注释者偏好一致且依赖二元比较，忽略了人类评估者的多样性和成对反馈的局限性。

Method: 1. 将RLHF中的偏好学习与计量经济学文献联系起来，论证了二元比较不足以识别潜在用户偏好，而三个或更多响应的排序可以确保可识别性。2. 引入了将异构偏好纳入对齐算法的方法，包括DPO的期望最大化（EM）自适应，用于发现潜在注释者类型并训练LLM混合模型；以及使用min-max regret公平性标准的聚合算法，以产生具有公平性能保证的单个生成策略。

Result: 建立了生成模型对齐中针对不同用户的公平性和个性化的理论和算法框架。

Conclusion: 该研究解决了现有RLHF方法中的局限性，并为生成模型对齐中的公平性和个性化提供了新的方法。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [80] [TKHist: Cardinality Estimation for Join Queries via Histograms with Dominant Attribute Correlation Finding](https://arxiv.org/abs/2510.15368)
*Renrui Li,Qingzhi Ma,Jiajie Xu,Lei Zhao,An Liu*

Main category: cs.DB

TL;DR: 提出了一种新的基数估计方法TKHist，以解决多表连接查询估计中的空间开销、延迟和复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多表连接查询估计方法存在空间开销大、延迟高、复杂度高等问题。

Method: 提出了TKHist方法，通过放宽直方图中的均匀性假设来捕获bin-wise非均匀性信息，并提出了支配连接路径相关性发现算法来管理连接键和filter predicates之间的相关性。

Result: 在流行基准测试上的大量实验表明，与SOTA方法相比，TKHist降低了2-3个数量级的误差方差，同时保持了相当或更低的内存使用。

Conclusion: TKHist方法能够在保持较低内存使用的情况下，显著提高多表连接查询的基数估计准确性。

Abstract: Cardinality estimation has long been crucial for cost-based database
optimizers in identifying optimal query execution plans, attracting significant
attention over the past decades. While recent advancements have significantly
improved the accuracy of multi-table join query estimations, these methods
introduce challenges such as higher space overhead, increased latency, and
greater complexity, especially when integrated with the binary join framework.
In this paper, we introduce a novel cardinality estimation method named TKHist,
which addresses these challenges by relaxing the uniformity assumption in
histograms. TKHist captures bin-wise non-uniformity information, enabling
accurate cardinality estimation for join queries without filter predicates.
Furthermore, we explore the attribute independent assumption, which can lead to
significant over-estimation rather than under-estimation in multi-table join
queries. To address this issue, we propose the dominating join path correlation
discovery algorithm to highlight and manage correlations between join keys and
filter predicates. Our extensive experiments on popular benchmarks demonstrate
that TKHist reduces error variance by 2-3 orders of magnitude compared to SOTA
methods, while maintaining comparable or lower memory usage.

</details>


### [81] [Optimizing Data Lakes' Queries](https://arxiv.org/abs/2510.15445)
*Gregory,Weintraub*

Main category: cs.DB

TL;DR: 这篇论文研究了云数据湖架构中查询性能的问题，旨在通过减少需要访问的文件数量来优化查询。


<details>
  <summary>Details</summary>
Motivation: 云数据湖通过分离计算和存储层来管理大量数据，但每次查询都需要通过网络将数据从存储层传输到计算层，影响性能并消耗带宽。

Method: 论文提出了一个理论框架，核心概念是“查询覆盖集”，即满足特定查询所需访问的最小文件集合。

Result: 目标是找到每个查询的最小覆盖集，并仅在此文件子集上执行查询，从而显著提高查询性能。

Conclusion: 通过最小化查询覆盖集来优化云数据湖中的查询性能。

Abstract: Cloud data lakes provide a modern solution for managing large volumes of
data. The fundamental principle behind these systems is the separation of
compute and storage layers. In this architecture, inexpensive cloud storage is
utilized for data storage, while compute engines are employed to perform
analytics on this data in an "on-demand" mode. However, to execute any
calculations on the data, it must be transferred from the storage layer to the
compute layer over the network for each query. This transfer can negatively
impact calculation performance and requires significant network bandwidth. In
this thesis, we examine various strategies to enhance query performance within
a cloud data lake architecture. We begin by formalizing the problem and
proposing a straightforward yet robust theoretical framework that clearly
outlines the associated trade-offs. Central to our framework is the concept of
a "query coverage set," which is defined as the collection of files that need
to be accessed from storage to fulfill a specific query. Our objective is to
identify the minimal coverage set for each query and execute the query
exclusively on this subset of files. This approach enables us to significantly
improve query performance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [82] [DMRetriever: A Family of Models for Improved Text Retrieval in Disaster Management](https://arxiv.org/abs/2510.15087)
*Kai Yin,Xiangjue Dong,Chengkai Liu,Allen Lin,Lingfeng Shi,Ali Mostafavi,James Caverlee*

Main category: cs.IR

TL;DR: DMRetriever is a series of dense retrieval models tailored for disaster management, outperforming existing models with high parameter efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing general-domain models fail to handle the varied search intents in disaster management, leading to inconsistent performance.

Method: A novel three-stage framework of bidirectional attention adaptation, unsupervised contrastive pre-training, and difficulty-aware progressive instruction fine-tuning, using high-quality data generated through an advanced data refinement pipeline.

Result: DMRetriever achieves state-of-the-art performance across all six search intents at every model scale and is highly parameter-efficient.

Conclusion: DMRetriever is effective and efficient for disaster management information retrieval.

Abstract: Effective and efficient access to relevant information is essential for
disaster management. However, no retrieval model is specialized for disaster
management, and existing general-domain models fail to handle the varied search
intents inherent to disaster management scenarios, resulting in inconsistent
and unreliable performance. To this end, we introduce DMRetriever, the first
series of dense retrieval models (33M to 7.6B) tailored for this domain. It is
trained through a novel three-stage framework of bidirectional attention
adaptation, unsupervised contrastive pre-training, and difficulty-aware
progressive instruction fine-tuning, using high-quality data generated through
an advanced data refinement pipeline. Comprehensive experiments demonstrate
that DMRetriever achieves state-of-the-art (SOTA) performance across all six
search intents at every model scale. Moreover, DMRetriever is highly
parameter-efficient, with 596M model outperforming baselines over 13.3 X larger
and 33M model exceeding baselines with only 7.6% of their parameters. All
codes, data, and checkpoints are available at
https://github.com/KaiYin97/DMRETRIEVER

</details>


### [83] [MTmixAtt: Integrating Mixture-of-Experts with Multi-Mix Attention for Large-Scale Recommendation](https://arxiv.org/abs/2510.15286)
*Xianyang Qi,Yuan Tian,Zhaoyu Hu,Zhirui Kuai,Chang Liu,Hongxiang Lin,Lei Wang*

Main category: cs.IR

TL;DR: 提出了一种名为 MTmixAtt 的统一 MoE 架构，用于大规模推荐任务，该架构在美团的工业 TRec 数据集上优于现有模型，并在在线 A/B 测试中显示出实际效果。


<details>
  <summary>Details</summary>
Motivation: 传统的推荐系统依赖于手动特征工程和特定场景的架构，阻碍了跨场景迁移和大规模部署。

Method: MTmixAtt 整合了两个关键组件：AutoToken 模块自动将异构特征聚类成语义连贯的 tokens，MTmixAttBlock 模块通过可学习的混合矩阵、共享密集专家和场景感知稀疏专家实现有效的 token 交互。

Result: 在工业 TRec 数据集上，MTmixAtt 优于包括 Transformer-based 模型在内的现有模型。在线 A/B 测试表明，在“主页”场景中，MTmixAtt 使 Payment PV 提高了 +3.62%，Actual Payment GTV 提高了 +2.54%。

Conclusion: MTmixAtt 为跨场景建模任意异构特征提供了一种统一且可扩展的解决方案，显著提高了用户体验和商业成果。

Abstract: Industrial recommender systems critically depend on high-quality ranking
models. However, traditional pipelines still rely on manual feature engineering
and scenario-specific architectures, which hinder cross-scenario transfer and
large-scale deployment. To address these challenges, we propose
\textbf{MTmixAtt}, a unified Mixture-of-Experts (MoE) architecture with
Multi-Mix Attention, designed for large-scale recommendation tasks. MTmixAtt
integrates two key components. The \textbf{AutoToken} module automatically
clusters heterogeneous features into semantically coherent tokens, removing the
need for human-defined feature groups. The \textbf{MTmixAttBlock} module
enables efficient token interaction via a learnable mixing matrix, shared dense
experts, and scenario-aware sparse experts, capturing both global patterns and
scenario-specific behaviors within a single framework. Extensive experiments on
the industrial TRec dataset from Meituan demonstrate that MTmixAtt consistently
outperforms state-of-the-art baselines including Transformer-based models,
WuKong, HiFormer, MLP-Mixer, and RankMixer. At comparable parameter scales,
MTmixAtt achieves superior CTR and CTCVR metrics; scaling to MTmixAtt-1B yields
further monotonic gains. Large-scale online A/B tests validate the real-world
impact: in the \textit{Homepage} scenario, MTmixAtt increases Payment PV by
\textbf{+3.62\%} and Actual Payment GTV by \textbf{+2.54\%}. Overall, MTmixAtt
provides a unified and scalable solution for modeling arbitrary heterogeneous
features across scenarios, significantly improving both user experience and
commercial outcomes.

</details>


### [84] [GRank: Towards Target-Aware and Streamlined Industrial Retrieval with a Generate-Rank Framework](https://arxiv.org/abs/2510.15299)
*Yijia Sun,Shanshan Huang,Zhiyuan Guan,Qiang Luo,Ruiming Tang,Kun Gai,Guorui Zhou*

Main category: cs.IR

TL;DR: GRank: A novel retrieval paradigm unifying target-aware learning with user-centric retrieval, outperforming existing methods in recall and latency.


<details>
  <summary>Details</summary>
Motivation: Existing recommender systems struggle with expressiveness in capturing user-item interactions or incur high maintenance costs with structured indices.

Method: GRank uses a target-aware Generator for personalized candidate generation and a lightweight Ranker for fine-grained inference, trained with an end-to-end multi-task learning framework.

Result: GRank improves Recall@500 by over 30% and 1.7x the P99 QPS compared to state-of-the-art retrievers. Production deployment shows significant improvements in user engagement.

Conclusion: GRank is a practical and effective solution for industrial-scale recommendation systems, demonstrating improved performance and user engagement in a real-world setting.

Abstract: Industrial-scale recommender systems rely on a cascade pipeline in which the
retrieval stage must return a high-recall candidate set from billions of items
under tight latency. Existing solutions ei- ther (i) suffer from limited
expressiveness in capturing fine-grained user-item interactions, as seen in
decoupled dual-tower architectures that rely on separate encoders, or
generative models that lack precise target-aware matching capabilities, or (ii)
build structured indices (tree, graph, quantization) whose item-centric
topologies struggle to incorporate dynamic user preferences and incur
prohibitive construction and maintenance costs.
  We present GRank, a novel structured-index-free retrieval paradigm that
seamlessly unifies target-aware learning with user-centric retrieval. Our key
innovations include: (1) A target-aware Generator trained to perform
personalized candidate generation via GPU-accelerated MIPS, eliminating
semantic drift and maintenance costs of structured indexing; (2) A lightweight
but powerful Ranker that performs fine-grained, candidate-specific inference on
small subsets; (3) An end-to-end multi-task learning framework that ensures
semantic consistency between generation and ranking objectives.
  Extensive experiments on two public benchmarks and a billion-item production
corpus demonstrate that GRank improves Recall@500 by over 30% and 1.7$\times$
the P99 QPS of state-of-the-art tree- and graph-based retrievers.
  GRank has been fully deployed in production in our recommendation platform
since Q2 2025, serving 400 million active users with 99.95% service
availability. Online A/B tests confirm significant improvements in core
engagement metrics, with Total App Usage Time increasing by 0.160% in the main
app and 0.165% in the Lite version.

</details>


### [85] [Dimension Mask Layer: Optimizing Embedding Efficiency for Scalable ID-based Models](https://arxiv.org/abs/2510.15308)
*Srijan Saket,Ikuhiro Ihara,Vaibhav Sharma,Danish Kalim*

Main category: cs.IR

TL;DR: 本文提出了一种自动确定ID特征的最佳嵌入大小的方法，以减少模型大小并保持性能。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统和社交媒体平台中，基于ID的大规模特征通常需要消耗大量内存的嵌入表。管理这些嵌入大小可能具有挑战性，导致模型体积庞大，更难以部署和维护。

Method: 该方法涉及定义一个自定义的Keras层，称为维度掩码层，该层直接位于嵌入查找之后。该层通过仅允许前N个维度通过来修剪嵌入向量。

Result: 通过在公共数据集上的离线实验和在真实生产数据集上的在线A/B测试，证明了使用维度掩码层可以将有效嵌入维度缩小40-50％，从而显着提高内存效率。

Conclusion: 该方法为处理大量ID特征的平台提供了一种可扩展的解决方案，可优化资源使用和模型性能。

Abstract: In modern recommendation systems and social media platforms like Meta,
TikTok, and Instagram, large-scale ID-based features often require embedding
tables that consume significant memory. Managing these embedding sizes can be
challenging, leading to bulky models that are harder to deploy and maintain. In
this paper, we introduce a method to automatically determine the optimal
embedding size for ID features, significantly reducing the model size while
maintaining performance.
  Our approach involves defining a custom Keras layer called the dimension mask
layer, which sits directly after the embedding lookup. This layer trims the
embedding vector by allowing only the first N dimensions to pass through. By
doing this, we can reduce the input feature dimension by more than half with
minimal or no loss in model performance metrics. This reduction helps cut down
the memory footprint of the model and lowers the risk of overfitting due to
multicollinearity.
  Through offline experiments on public datasets and an online A/B test on a
real production dataset, we demonstrate that using a dimension mask layer can
shrink the effective embedding dimension by 40-50\%, leading to substantial
improvements in memory efficiency. This method provides a scalable solution for
platforms dealing with a high volume of ID features, optimizing both resource
usage and model performance.

</details>


### [86] [Fault Cause Identification across Manufacturing Lines through Ontology-Guided and Process-Aware FMEA Graph Learning with LLMs](https://arxiv.org/abs/2510.15428)
*Sho Okazaki,Kohei Kaminishi,Takuma Fujiu,Yusheng Wang,Jun Ota*

Main category: cs.IR

TL;DR: 这篇论文提出了一种新的框架，通过结合制造领域的概念化和图神经网络（GNN）推理来提高失效模式与影响分析（FMEA）的可重用性，从而解决自动化生产线中故障原因识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于自动化生产线的复杂性、频繁的重配置以及现有失效模式与影响分析（FMEA）知识的有限可重用性，导致自动化生产线中的故障原因识别具有挑战性。虽然FMEA工作表包含有价值的专家见解，但由于自然语言的可变性、不一致的术语和流程差异，它们在异构生产线中的重用受到阻碍。

Method: 该研究提出了一个流程感知的框架，该框架通过将制造领域概念化与图神经网络（GNN）推理相结合来增强FMEA的可重用性。首先，通过本体引导的大型语言模型（LLM）提取，将来自多个生产线的FMEA工作表转换为统一的知识图，捕获诸如动作、状态、组件和参数等领域概念。其次，具有流程感知评分函数的关系图卷积网络（RGCN）学习嵌入，这些嵌入尊重语义关系和顺序流程。最后，采用链接预测来推断和排序与目标线流程一致的候选故障原因。

Result: 在汽车压力传感器装配线上的案例研究表明，所提出的方法优于最先进的检索增强生成（RAG）基线（F1@20 = 0.267）和RGCN方法（0.400），在故障原因识别中实现了最佳性能（0.523）。消融研究证实了LLM驱动的领域概念化和流程感知学习的贡献。

Conclusion: 这些结果表明，所提出的框架显著提高了FMEA知识在异构生产线中的可转移性，从而支持操作员更可靠地诊断故障，并为未来智能制造中领域自适应的LLM应用铺平了道路。

Abstract: Fault cause identification in automated manufacturing lines is challenging
due to the system's complexity, frequent reconfigurations, and the limited
reusability of existing Failure Mode and Effects Analysis (FMEA) knowledge.
Although FMEA worksheets contain valuable expert insights, their reuse across
heterogeneous lines is hindered by natural language variability, inconsistent
terminology, and process differences. To address these limitations, this study
proposes a process-aware framework that enhances FMEA reusability by combining
manufacturing-domain conceptualization with graph neural network (GNN)
reasoning. First, FMEA worksheets from multiple manufacturing lines are
transformed into a unified knowledge graph through ontology-guided large
language model (LLM) extraction, capturing domain concepts such as actions,
states, components, and parameters. Second, a Relational Graph Convolutional
Network (RGCN) with the process-aware scoring function learns embeddings that
respect both semantic relationships and sequential process flows. Finally, link
prediction is employed to infer and rank candidate fault causes consistent with
the target line's process flow.
  A case study on automotive pressure sensor assembly lines demonstrates that
the proposed method outperforms a state-of-the-art retrieval-augmented
generation (RAG) baseline (F1@20 = 0.267) and an RGCN approach (0.400),
achieving the best performance (0.523) in fault cause identification. Ablation
studies confirm the contributions of both LLM-driven domain conceptualization
and process-aware learning. These results indicate that the proposed framework
significantly improves the transferability of FMEA knowledge across
heterogeneous lines, thereby supporting operators in diagnosing failures more
reliably and paving the way for future domain-adaptive LLM applications in
smart manufacturing.

</details>


### [87] [Enhance Large Language Models as Recommendation Systems with Collaborative Filtering](https://arxiv.org/abs/2510.15647)
*Zhisheng Yang,Xiaofei Xu,Ke Deng,Li Li*

Main category: cs.IR

TL;DR: 本文提出了一种名为 Critic-LLM-RS 的推荐系统，它通过结合协同过滤和大型语言模型来提高推荐质量。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型推荐方法要么需要耗时的微调，要么缺乏特定领域的知识。本文旨在填补非微调方法中缺乏协同过滤的空白。

Method: 本文训练了一个独立的协同过滤模型 Critic，为大型语言模型提供评论，以优化推荐结果。

Result: 大量的实验验证了 Critic-LLM-RS 在真实数据集上的有效性。

Conclusion: 本文提出的 Critic-LLM-RS 是一种有效的推荐系统，它结合了协同过滤和大型语言模型的优点。

Abstract: As powerful tools in Natural Language Processing (NLP), Large Language Models
(LLMs) have been leveraged for crafting recommendations to achieve precise
alignment with user preferences and elevate the quality of the recommendations.
The existing approaches implement both non-tuning and tuning strategies.
Compared to following the tuning strategy, the approaches following the
non-tuning strategy avoid the relatively costly, time-consuming, and
expertise-requiring process of further training pre-trained LLMs on
task-specific datasets, but they suffer the issue of not having the
task-specific business or local enterprise knowledge. To the best of our
knowledge, none of the existing approaches following the non-tuning strategy
explicitly integrates collaborative filtering, one of the most successful
recommendation techniques. This study aims to fill the gap by proposing
critique-based LLMs as recommendation systems (Critic-LLM-RS). For our purpose,
we train a separate machine-learning model called Critic that implements
collaborative filtering for recommendations by learning from the interactions
between many users and items. The Critic provides critiques to LLMs to
significantly refine the recommendations. Extensive experiments have verified
the effectiveness of Critic-LLM-RS on real datasets.

</details>


### [88] [SQuAI: Scientific Question-Answering with Multi-Agent Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15682)
*Ines Besrour,Jingbo He,Tobias Schreieder,Michael Färber*

Main category: cs.IR

TL;DR: SQuAI is a multi-agent RAG framework for scientific QA with LLMs, addressing limitations of existing RAG systems in the scholarly domain.


<details>
  <summary>Details</summary>
Motivation: Existing RAG systems in the scholarly domain struggle with complex, open-domain questions that demand accurate answers, explicit claims with citations, and retrieval across millions of scientific documents.

Method: SQuAI employs four collaborative agents to decompose complex questions, retrieve targeted evidence via hybrid sparse-dense retrieval, and adaptively filter documents. It integrates in-line citations and provides supporting sentences.

Result: SQuAI improves faithfulness, answer relevance, and contextual relevance by up to +0.088 (12%) over a strong RAG baseline.

Conclusion: SQuAI demonstrates how multi-agent RAG enables more trustworthy scientific QA with LLMs, offering transparent reasoning, verifiable citations, and domain-wide scalability. A benchmark dataset is also released.

Abstract: We present SQuAI (https://squai.scads.ai/), a scalable and trustworthy
multi-agent retrieval-augmented generation (RAG) framework for scientific
question answering (QA) with large language models (LLMs). SQuAI addresses key
limitations of existing RAG systems in the scholarly domain, where complex,
open-domain questions demand accurate answers, explicit claims with citations,
and retrieval across millions of scientific documents. Built on over 2.3
million full-text papers from arXiv.org, SQuAI employs four collaborative
agents to decompose complex questions into sub-questions, retrieve targeted
evidence via hybrid sparse-dense retrieval, and adaptively filter documents to
improve contextual relevance. To ensure faithfulness and traceability, SQuAI
integrates in-line citations for each generated claim and provides supporting
sentences from the source documents. Our system improves faithfulness, answer
relevance, and contextual relevance by up to +0.088 (12%) over a strong RAG
baseline. We further release a benchmark of 1,000 scientific
question-answer-evidence triplets to support reproducibility. With transparent
reasoning, verifiable citations, and domain-wide scalability, SQuAI
demonstrates how multi-agent RAG enables more trustworthy scientific QA with
LLMs.

</details>


### [89] [Mixture of Experts Approaches in Dense Retrieval Tasks](https://arxiv.org/abs/2510.15683)
*Effrosyni Sokli,Pranav Kasela,Georgios Peikos,Gabriella Pasi*

Main category: cs.IR

TL;DR: 这篇论文提出了一种新的MoE结构，用于提升密集检索模型(DRMs)的泛化能力，尤其是在轻量级模型上效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的DRMs模型泛化能力差，而将MoE框架融入Transformer层会显著增加参数量。

Method: 在最终Transformer层后引入一个MoE块(SB-MoE)，从而实现更高效的设计。

Result: SB-MoE在轻量级DRMs模型（如TinyBERT和BERT-Small）上表现出色，超过了标准模型微调的效果。对于参数较多的DRMs模型，需要更多的训练样本才能提升检索性能。

Conclusion: SB-MoE对于提升轻量级DRMs模型的检索效果和泛化能力有效，但对于大型模型需要更多的训练数据。

Abstract: Dense Retrieval Models (DRMs) are a prominent development in Information
Retrieval (IR). A key challenge with these neural Transformer-based models is
that they often struggle to generalize beyond the specific tasks and domains
they were trained on. To address this challenge, prior research in IR
incorporated the Mixture-of-Experts (MoE) framework within each Transformer
layer of a DRM, which, though effective, substantially increased the number of
additional parameters. In this paper, we propose a more efficient design, which
introduces a single MoE block (SB-MoE) after the final Transformer layer. To
assess the retrieval effectiveness of SB-MoE, we perform an empirical
evaluation across three IR tasks. Our experiments involve two evaluation
setups, aiming to assess both in-domain effectiveness and the model's zero-shot
generalizability. In the first setup, we fine-tune SB-MoE with four different
underlying DRMs on seven IR benchmarks and evaluate them on their respective
test sets. In the second setup, we fine-tune SB-MoE on MSMARCO and perform
zero-shot evaluation on thirteen BEIR datasets. Additionally, we perform
further experiments to analyze the model's dependency on its hyperparameters
(i.e., the number of employed and activated experts) and investigate how this
variation affects SB-MoE's performance. The obtained results show that SB-MoE
is particularly effective for DRMs with lightweight base models, such as
TinyBERT and BERT-Small, consistently exceeding standard model fine-tuning
across benchmarks. For DRMs with more parameters, such as BERT-Base and
Contriever, our model requires a larger number of training samples to achieve
improved retrieval performance. Our code is available online at:
https://github.com/FaySokli/SB-MoE.

</details>


### [90] [GraphMind: Interactive Novelty Assessment System for Accelerating Scientific Discovery](https://arxiv.org/abs/2510.15706)
*Italo Luis da Silva,Hanqi Yan,Lin Gui,Yulan He*

Main category: cs.IR

TL;DR: GraphMind是一个交互式网络工具，旨在帮助用户评估科学论文或草稿的新颖性。


<details>
  <summary>Details</summary>
Motivation: 评估科学论文的新颖性对于同行评审至关重要，但这需要广泛的相关工作知识，而并非所有审阅者都具备。现有方法在透明度和结果可追溯性方面存在不足。

Method: GraphMind使用户能够捕获科学论文的主要结构，通过各种角度探索相关想法，并通过提供可验证的上下文见解来评估新颖性。该工具集成了arXiv和Semantic Scholar等外部API与LLM，以支持论文的注释、提取、检索和分类。

Result: GraphMind为用户提供了关于科学思想的核心贡献及其与现有工作的联系的丰富、结构化的视图。

Conclusion: GraphMind是一个易于使用的交互式网络工具，可以有效地帮助用户评估科学论文的新颖性。

Abstract: Large Language Models (LLMs) show strong reasoning and text generation
capabilities, prompting their use in scientific literature analysis, including
novelty assessment. While evaluating novelty of scientific papers is crucial
for peer review, it requires extensive knowledge of related work, something not
all reviewers have. While recent work on LLM-assisted scientific literature
analysis supports literature comparison, existing approaches offer limited
transparency and lack mechanisms for result traceability via an information
retrieval module. To address this gap, we introduce $\textbf{GraphMind}$, an
easy-to-use interactive web tool designed to assist users in evaluating the
novelty of scientific papers or drafted ideas. Specially, $\textbf{GraphMind}$
enables users to capture the main structure of a scientific paper, explore
related ideas through various perspectives, and assess novelty via providing
verifiable contextual insights. $\textbf{GraphMind}$ enables users to annotate
key elements of a paper, explore related papers through various relationships,
and assess novelty with contextual insight. This tool integrates external APIs
such as arXiv and Semantic Scholar with LLMs to support annotation, extraction,
retrieval and classification of papers. This combination provides users with a
rich, structured view of a scientific idea's core contributions and its
connections to existing work. $\textbf{GraphMind}$ is available at
https://oyarsa.github.io/graphmind and a demonstration video at
https://youtu.be/wKbjQpSvwJg. The source code is available at
https://github.com/oyarsa/graphmind.

</details>


### [91] [The 3rd Place Solution of CCIR CUP 2025: A Framework for Retrieval-Augmented Generation in Multi-Turn Legal Conversation](https://arxiv.org/abs/2510.15722)
*Da Li,Zecheng Fang,Qiang Yan,Wei Huang,Xuanpu Luo*

Main category: cs.IR

TL;DR: RAG在自然语言处理领域取得了显著进展，但在法律领域的应用仍处于探索阶段。本文介绍了我们在CCIR CUP 2025中“法律知识检索与生成”的方法。


<details>
  <summary>Details</summary>
Motivation: 探索RAG在法律领域的应用

Method: 利用大型语言模型和信息检索系统，根据法律法规对用户问题提供回应。

Result: 未提及

Conclusion: 未提及

Abstract: Retrieval-Augmented Generation has made significant progress in the field of
natural language processing. By combining the advantages of information
retrieval and large language models, RAG can generate relevant and contextually
appropriate responses based on items retrieved from reliable sources. This
technology has demonstrated outstanding performance across multiple domains,
but its application in the legal field remains in its exploratory phase. In
this paper, we introduce our approach for "Legal Knowledge Retrieval and
Generation" in CCIR CUP 2025, which leverages large language models and
information retrieval systems to provide responses based on laws in response to
user questions.

</details>


### [92] [FACE: A General Framework for Mapping Collaborative Filtering Embeddings into LLM Tokens](https://arxiv.org/abs/2510.15729)
*Chao Wang,Yixin Song,Jinhui Ye,Chuan Qin,Dazhong Shen,Lingfeng Liu,Xiang Wang,Yanyong Zhang*

Main category: cs.IR

TL;DR: 本文提出了一种名为FACE的通用可解释框架，用于将协同过滤（CF）嵌入映射到预训练的LLM tokens，以提高推荐效果。


<details>
  <summary>Details</summary>
Motivation: LLM难以解释CF方法产生的潜在、非语义嵌入，限制了推荐效果和进一步应用。

Method: 该方法包含一个解耦投影模块，将CF嵌入分解为概念特定的向量，然后使用量化自动编码器将连续嵌入转换为LLM tokens（描述符）。此外，还设计了一个对比对齐目标，以确保tokens与相应的文本信号对齐。

Result: 在三个真实世界的推荐数据集上的实验结果表明，基准模型的性能得到了提高，并且可解释性研究证实了描述符的可解释性。

Conclusion: FACE框架无需微调LLM即可实现语义对齐，并通过利用LLM的预训练能力来增强推荐性能。

Abstract: Recently, large language models (LLMs) have been explored for integration
with collaborative filtering (CF)-based recommendation systems, which are
crucial for personalizing user experiences. However, a key challenge is that
LLMs struggle to interpret the latent, non-semantic embeddings produced by CF
approaches, limiting recommendation effectiveness and further applications. To
address this, we propose FACE, a general interpretable framework that maps CF
embeddings into pre-trained LLM tokens. Specifically, we introduce a
disentangled projection module to decompose CF embeddings into concept-specific
vectors, followed by a quantized autoencoder to convert continuous embeddings
into LLM tokens (descriptors). Then, we design a contrastive alignment
objective to ensure that the tokens align with corresponding textual signals.
Hence, the model-agnostic FACE framework achieves semantic alignment without
fine-tuning LLMs and enhances recommendation performance by leveraging their
pre-trained capabilities. Empirical results on three real-world recommendation
datasets demonstrate performance improvements in benchmark models, with
interpretability studies confirming the interpretability of the descriptors.
Code is available in https://github.com/YixinRoll/FACE.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [93] [Extending Load Forecasting from Zonal Aggregates to Individual Nodes for Transmission System Operators](https://arxiv.org/abs/2510.14983)
*Oskar Triebe,Fletcher Passow,Simon Wittner,Leonie Wagner,Julio Arend,Tao Sun,Chad Zanocco,Marek Miltner,Arezou Ghesmati,Chen-Hao Tsai,Christoph Bergmeir,Ram Rajagopal*

Main category: cs.LG

TL;DR: 本地电网基础设施的可靠性受到可持续能源发展带来的电力负荷不确定性增加的挑战。需要更高空间分辨率的负荷预测，将当前预测操作从区域聚合扩展到各个节点。节点负荷预测不太准确，需要大量单独的预测，难以管理。我们设计了一个多层次系统，满足运营商对每小时日前负荷预测的需求。利用区域和节点净负荷的独特数据集，我们对系统组件进行了实验评估。我们的多层次预测系统使运营商能够以空前的信心和准确性调整预测，并精确诊断原本不透明的错误。


<details>
  <summary>Details</summary>
Motivation: 提高电力负荷预测的空间分辨率，从区域聚合扩展到各个节点，以应对可持续能源发展带来的电力负荷不确定性增加的挑战。

Method: 开发了一个可解释且可扩展的预测模型，允许 TSO 逐步扩展区域操作以包括节点预测。评估了解 heterogeneity 和 volatility 的解决方案，并进行权衡。该系统可通过完全并行化的单模型预测工作流程进行管理。

Result: 区域预测的准确性和可解释性有所提高，节点预测的准确性也有了显着提高。

Conclusion: 多层次预测系统使运营商能够以空前的信心和准确性调整预测，并精确诊断原本不透明的错误。

Abstract: The reliability of local power grid infrastructure is challenged by
sustainable energy developments increasing electric load uncertainty.
Transmission System Operators (TSOs) need load forecasts of higher spatial
resolution, extending current forecasting operations from zonal aggregates to
individual nodes. However, nodal loads are less accurate to forecast and
require a large number of individual forecasts, which are hard to manage for
the human experts assessing risks in the control room's daily operations
(operator). In collaboration with a TSO, we design a multi-level system that
meets the needs of operators for hourly day-ahead load forecasting. Utilizing a
uniquely extensive dataset of zonal and nodal net loads, we experimentally
evaluate our system components. First, we develop an interpretable and scalable
forecasting model that allows for TSOs to gradually extend zonal operations to
include nodal forecasts. Second, we evaluate solutions to address the
heterogeneity and volatility of nodal load, subject to a trade-off. Third, our
system is manageable with a fully parallelized single-model forecasting
workflow. Our results show accuracy and interpretability improvements for zonal
forecasts, and substantial improvements for nodal forecasts. In practice, our
multi-level forecasting system allows operators to adjust forecasts with
unprecedented confidence and accuracy, and to diagnose otherwise opaque errors
precisely.

</details>


### [94] [TangledFeatures: Robust Feature Selection in Highly Correlated Spaces](https://arxiv.org/abs/2510.15005)
*Allen Daniel Sunny*

Main category: cs.LG

TL;DR: 提出TangledFeatures，一个用于相关特征空间中特征选择的框架，通过识别缠结预测因子组中的代表性特征来减少冗余，同时保留解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有特征选择方法侧重于预测准确性，在存在相关预测因子的情况下性能下降。

Method: TangledFeatures框架，从缠结预测因子组中识别代表性特征。

Result: 在Alanine Dipeptide上验证了TangledFeatures的有效性，所选特征对应于结构上有意义的原子内距离，可以解释这些角度的变化。

Conclusion: TangledFeatures提供了一种更可解释和稳定的分析基础，可以直接应用于下游模型。

Abstract: Feature selection is a fundamental step in model development, shaping both
predictive performance and interpretability. Yet, most widely used methods
focus on predictive accuracy, and their performance degrades in the presence of
correlated predictors. To address this gap, we introduce TangledFeatures, a
framework for feature selection in correlated feature spaces. It identifies
representative features from groups of entangled predictors, reducing
redundancy while retaining explanatory power. The resulting feature subset can
be directly applied in downstream models, offering a more interpretable and
stable basis for analysis compared to traditional selection techniques. We
demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying
it to the prediction of backbone torsional angles and show that the selected
features correspond to structurally meaningful intra-atomic distances that
explain variation in these angles.

</details>


### [95] [ES-C51: Expected Sarsa Based C51 Distributional Reinforcement Learning Algorithm](https://arxiv.org/abs/2510.15006)
*Rijul Tandon,Peter Vamplew,Cameron Foale*

Main category: cs.LG

TL;DR: 本文提出了一种改进的C51算法（ES-C51），用Expected Sarsa更新替换了贪婪Q学习更新，以解决在状态下多个动作具有相似预期奖励但分布不同的问题，从而提高策略性能。


<details>
  <summary>Details</summary>
Motivation: 传统的DRL算法C51在状态下多个动作具有相似预期奖励但分布不同时，学习不稳定。

Method: 使用Expected Sarsa更新替换C51中的贪婪Q学习更新。

Result: ES-C51在Gym经典控制环境和Atari-10游戏中优于QL-C51。

Conclusion: ES-C51通过减少不稳定性，能够学习更高性能的策略。

Abstract: In most value-based reinforcement learning (RL) algorithms, the agent
estimates only the expected reward for each action and selects the action with
the highest reward. In contrast, Distributional Reinforcement Learning (DRL)
estimates the entire probability distribution of possible rewards, providing
richer information about uncertainty and variability. C51 is a popular DRL
algorithm for discrete action spaces. It uses a Q-learning approach, where the
distribution is learned using a greedy Bellman update. However, this can cause
problems if multiple actions at a state have similar expected reward but with
different distributions, as the algorithm may not learn a stable distribution.
This study presents a modified version of C51 (ES-C51) that replaces the greedy
Q-learning update with an Expected Sarsa update, which uses a softmax
calculation to combine information from all possible actions at a state rather
than relying on a single best action. This reduces instability when actions
have similar expected rewards and allows the agent to learn higher-performing
policies. This approach is evaluated on classic control environments from Gym,
and Atari-10 games. For a fair comparison, we modify the standard C51's
exploration strategy from e-greedy to softmax, which we refer to as QL-C51 (Q-
Learning based C51). The results demonstrate that ES-C51 outperforms QL-C51
across many environments.

</details>


### [96] [Hybrid Autoencoder-Based Framework for Early Fault Detection in Wind Turbines](https://arxiv.org/abs/2510.15010)
*Rekha R Nair,Tina Babu,Alavikunhu Panthakkan,Balamurugan Balusamy,Wathiq Mansoor*

Main category: cs.LG

TL;DR: 提出了一种基于集成的深度学习框架，用于风力涡轮机的无监督异常检测，通过整合变分自编码器（VAE）、LSTM自编码器和Transformer架构，从高维SCADA数据中捕获不同的时间和上下文模式。


<details>
  <summary>Details</summary>
Motivation: 早期故障检测对于减少停机时间和维护成本至关重要。

Method: 该方法集成了变分自编码器（VAE）、LSTM自编码器和Transformer架构，并提取时间、统计和频域指标，通过集成模型预测和自适应阈值来检测异常。

Result: 在包含三个风电场的89年真实涡轮机数据的CARE数据集上进行评估，该方法实现了0.947的AUC-ROC，并在故障发生前48小时实现了早期故障检测。

Conclusion: 该方法通过实现预测性维护、减少涡轮机故障和提高大规模风能部署的运营效率，提供了重要的社会价值。

Abstract: Wind turbine reliability is critical to the growing renewable energy sector,
where early fault detection significantly reduces downtime and maintenance
costs. This paper introduces a novel ensemble-based deep learning framework for
unsupervised anomaly detection in wind turbines. The method integrates
Variational Autoencoders (VAE), LSTM Autoencoders, and Transformer
architectures, each capturing different temporal and contextual patterns from
high-dimensional SCADA data. A unique feature engineering pipeline extracts
temporal, statistical, and frequency-domain indicators, which are then
processed by the deep models. Ensemble scoring combines model predictions,
followed by adaptive thresholding to detect operational anomalies without
requiring labeled fault data. Evaluated on the CARE dataset containing 89 years
of real-world turbine data across three wind farms, the proposed method
achieves an AUC-ROC of 0.947 and early fault detection up to 48 hours prior to
failure. This approach offers significant societal value by enabling predictive
maintenance, reducing turbine failures, and enhancing operational efficiency in
large-scale wind energy deployments.

</details>


### [97] [AlignFlow: Improving Flow-based Generative Models with Semi-Discrete Optimal Transport](https://arxiv.org/abs/2510.15038)
*Lingkai Kong,Molei Tao,Yang Liu,Bryan Wang,Jinmiao Fu,Chien-Chih Wang,Huidong Liu*

Main category: cs.LG

TL;DR: AlignFlow: 使用半离散最优传输（SDOT）改进 Flow-based 生成模型（FGM）的训练，通过在噪声分布和数据点之间建立显式最优对齐来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最优传输（OT）的方法在 FGM 训练中，使用采样的噪声和数据点估计 OT 计划，限制了它们在大规模和高维数据集上的可扩展性。

Method: 提出 AlignFlow，利用半离散最优传输（SDOT）通过将噪声空间划分为 Laguerre 单元来计算传输映射，每个单元映射到一个对应的数据点。

Result: 实验结果表明，AlignFlow 提高了各种最先进的 FGM 算法的性能，并且可以作为即插即用组件集成。

Conclusion: AlignFlow 能够很好地扩展到大型数据集和模型架构，且计算开销可忽略不计。

Abstract: Flow-based Generative Models (FGMs) effectively transform noise into complex
data distributions. Incorporating Optimal Transport (OT) to couple noise and
data during FGM training has been shown to improve the straightness of flow
trajectories, enabling more effective inference. However, existing OT-based
methods estimate the OT plan using (mini-)batches of sampled noise and data
points, which limits their scalability to large and high-dimensional datasets
in FGMs. This paper introduces AlignFlow, a novel approach that leverages
Semi-Discrete Optimal Transport (SDOT) to enhance the training of FGMs by
establishing an explicit, optimal alignment between noise distribution and data
points with guaranteed convergence. SDOT computes a transport map by
partitioning the noise space into Laguerre cells, each mapped to a
corresponding data point. During FGM training, i.i.d. noise samples are paired
with data points via the SDOT map. AlignFlow scales well to large datasets and
model architectures with negligible computational overhead. Experimental
results show that AlignFlow improves the performance of a wide range of
state-of-the-art FGM algorithms and can be integrated as a plug-and-play
component. Code is available at: https://github.com/konglk1203/AlignFlow.

</details>


### [98] [IQNN-CS: Interpretable Quantum Neural Network for Credit Scoring](https://arxiv.org/abs/2510.15044)
*Abdul Samad Khan,Nouhaila Innan,Aeysha Khalique,Muhammad Shafique*

Main category: cs.LG

TL;DR: 本研究提出了一种可解释的量子神经网络框架IQNN-CS，用于多类信用风险分类。


<details>
  <summary>Details</summary>
Motivation: 在金融服务中，信用评分至关重要，但量子机器学习(QML)的黑盒性质使其难以应用。因此，本研究旨在解决QML在需要透明和信任的领域中的应用挑战。

Method: 该架构结合了变分QNN和一套定制的事后解释技术，并引入了类间归因对齐(ICAA)指标，以量化预测类别之间的归因差异。

Result: 在两个真实信用数据集上的评估表明，IQNN-CS具有稳定的训练动态、有竞争力的预测性能和增强的可解释性。

Conclusion: 研究结果表明，为金融决策构建透明和负责任的QML模型是可行的。

Abstract: Credit scoring is a high-stakes task in financial services, where model
decisions directly impact individuals' access to credit and are subject to
strict regulatory scrutiny. While Quantum Machine Learning (QML) offers new
computational capabilities, its black-box nature poses challenges for adoption
in domains that demand transparency and trust. In this work, we present
IQNN-CS, an interpretable quantum neural network framework designed for
multiclass credit risk classification. The architecture combines a variational
QNN with a suite of post-hoc explanation techniques tailored for structured
data. To address the lack of structured interpretability in QML, we introduce
Inter-Class Attribution Alignment (ICAA), a novel metric that quantifies
attribution divergence across predicted classes, revealing how the model
distinguishes between credit risk categories. Evaluated on two real-world
credit datasets, IQNN-CS demonstrates stable training dynamics, competitive
predictive performance, and enhanced interpretability. Our results highlight a
practical path toward transparent and accountable QML models for financial
decision-making.

</details>


### [99] [Internalizing World Models via Self-Play Finetuning for Agentic RL](https://arxiv.org/abs/2510.15047)
*Shiqi Chen,Tongyao Zhu,Zian Wang,Jinghan Zhang,Kangrui Wang,Siyang Gao,Teng Xiao,Yee Whye Teh,Junxian He,Manling Li*

Main category: cs.LG

TL;DR: LLMs在复杂环境中表现不佳，泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: LLMs难以将其内部知识应用于复杂的真实环境，导致强化学习训练失败。

Method: 提出SPA框架，通过自博弈监督微调学习世界模型，模拟未来状态以优化策略。

Result: 在Sokoban和FrozenLake等环境中，SPA显著提高了LLMs的性能。

Conclusion: SPA框架通过引入世界模型，有效提升了LLMs在复杂环境中的决策能力和泛化能力。

Abstract: Large Language Models (LLMs) as agents often struggle in out-of-distribution
(OOD) scenarios. Real-world environments are complex and dynamic, governed by
task-specific rules and stochasticity, which makes it difficult for LLMs to
ground their internal knowledge in those dynamics. Under such OOD conditions,
vanilla RL training often fails to scale; we observe Pass@k--the probability
that at least one of (k) sampled trajectories succeeds--drops markedly across
training steps, indicating brittle exploration and limited generalization.
Inspired by model-based reinforcement learning, we hypothesize that equipping
LLM agents with an internal world model can better align reasoning with
environmental dynamics and improve decision-making. We show how to encode this
world model by decomposing it into two components: state representation and
transition modeling. Building on this, we introduce SPA, a simple reinforcement
learning framework that cold-starts the policy via a Self-Play supervised
finetuning (SFT) stage to learn the world model by interacting with the
environment, then uses it to simulate future states prior to policy
optimization. This simple initialization outperforms the online world-modeling
baseline and greatly boosts the RL-based agent training performance.
Experiments across diverse environments like Sokoban, FrozenLake, and Sudoku
show that our approach significantly improves performance. For example, SPA
boosts the Sokoban success rate from 25.6% to 59.8% and raises the FrozenLake
score from 22.1% to 70.9% for the Qwen2.5-1.5B-Instruct model.

</details>


### [100] [Learn to Change the World: Multi-level Reinforcement Learning with Model-Changing Actions](https://arxiv.org/abs/2510.15056)
*Ziqing Lu,Babak Hassibi,Lifeng Lai,Weiyu Xu*

Main category: cs.LG

TL;DR: 提出了一种多层可配置时变马尔可夫决策过程(MCTVMDP)，其中底层MDP具有非平稳转移函数，该函数可以通过上层模型改变动作来配置。


<details>
  <summary>Details</summary>
Motivation: 考虑不限于被动适应的智能体：它们具有模型改变动作，可以主动修改世界动态的RL模型本身。重新配置底层转换过程可能会增加智能体的奖励。

Method: 引入多层可配置时变马尔可夫决策过程(MCTVMDP)。在MCTVMDP中，底层MDP具有非平稳转移函数，该函数可以通过上层模型改变动作来配置。

Result: 智能体的目标包括两部分：优化上层MDP中的配置策略和优化底层MDP中的原始动作策略，以共同提高其预期的长期奖励。

Conclusion: 智能体可以通过改变环境来最大化奖励。

Abstract: Reinforcement learning usually assumes a given or sometimes even fixed
environment in which an agent seeks an optimal policy to maximize its long-term
discounted reward. In contrast, we consider agents that are not limited to
passive adaptations: they instead have model-changing actions that actively
modify the RL model of world dynamics itself. Reconfiguring the underlying
transition processes can potentially increase the agents' rewards. Motivated by
this setting, we introduce the multi-layer configurable time-varying Markov
decision process (MCTVMDP). In an MCTVMDP, the lower-level MDP has a
non-stationary transition function that is configurable through upper-level
model-changing actions. The agent's objective consists of two parts: Optimize
the configuration policies in the upper-level MDP and optimize the primitive
action policies in the lower-level MDP to jointly improve its expected
long-term reward.

</details>


### [101] [Antislop: A Comprehensive Framework for Identifying and Eliminating Repetitive Patterns in Language Models](https://arxiv.org/abs/2510.15061)
*Samuel Paech,Allen Roush,Judah Goldfeder,Ravid Shwartz-Ziv*

Main category: cs.LG

TL;DR: 论文提出了Antislop，一个用于检测和消除大型语言模型中过度使用的重复短语（称为“slop”）的框架，这些短语会降低输出质量并使AI生成的文本易于识别。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的广泛采用引入了重复的短语，降低了输出质量，并使AI生成的文本很容易被识别。

Method: 该方法结合了三个创新点：Antislop Sampler（使用回溯在推理时抑制不需要的字符串而不破坏词汇）、自动化pipeline（针对人类基线分析模型特定的slop并生成训练数据）以及Final Token Preference Optimization (FTPO)（一种在单个token上运行的新型微调方法，可在推理追踪中出现禁止模式时调整logits）。

Result: 结果表明，某些slop模式在LLM输出中出现的频率比人类文本高出1000倍以上。Antislop Sampler成功抑制了8000多种模式，同时保持了质量，而token banning在2000种模式时变得无法使用。FTPO实现了90％的slop减少，同时在跨域评估中保持或提高了性能。

Conclusion: FTPO在减少slop的同时，在包括GSM8K、MMLU和创意写作任务在内的跨领域评估中保持或提高了性能，而DPO在写作质量和词汇多样性方面表现出明显的下降。

Abstract: Widespread LLM adoption has introduced characteristic repetitive phraseology,
termed ``slop,'' which degrades output quality and makes AI-generated text
immediately recognizable. We present Antislop, a comprehensive framework
providing tools to both detect and eliminate these overused patterns. Our
approach combines three innovations: (1) The Antislop Sampler, which uses
backtracking to suppress unwanted strings at inference time without destroying
vocabulary; (2) An automated pipeline that profiles model-specific slop against
human baselines and generates training data; (3) Final Token Preference
Optimization (FTPO), a novel fine-tuning method that operates on individual
tokens, surgically adjusting logits wherever a banned pattern has appeared in
an inference trace. We demonstrate that some slop patterns appear over
1,000$\times$ more frequently in LLM output than human text. The Antislop
Sampler successfully suppresses 8,000+ patterns while maintaining quality,
whereas token banning becomes unusable at just 2,000. Most importantly, FTPO
achieves 90\% slop reduction while maintaining or improving performance in
cross-domain evals including GSM8K, MMLU, and creative writing tasks. In
contrast, DPO suffers significant degradation in writing quality and lexical
diversity despite achieving weaker suppression. We release all code and results
under MIT license: https://github.com/sam-paech/auto-antislop.

</details>


### [102] [Physics-informed data-driven machine health monitoring for two-photon lithography](https://arxiv.org/abs/2510.15075)
*Sixian Jia,Zhiqiao Dong,Chenhui Shao*

Main category: cs.LG

TL;DR: 本文提出了一种基于物理信息数据驱动预测模型和统计方法的三种方法，用于准确和及时地监测 TPL 机器的健康状况。


<details>
  <summary>Details</summary>
Motivation: 保持 TPL 系统的健康对于确保持续的制造质量至关重要。目前的维护实践通常依赖于经验而不是知情的机器健康监测，导致不及时的维护导致机器停机和劣质制造，或不必要的维护导致效率低下和可避免的停机时间。

Method: 通过将结构尺寸的物理信息数据驱动预测模型与统计方法相结合，所提出的方法能够处理具有不同泛化水平的日益复杂的场景。

Result: 全面的实验数据集包含六个过程参数组合和两个机器健康状况下的六个结构尺寸，用于评估所提出方法的有效性。在所有测试场景中，这些方法都显示出高精度，证明了出色的有效性、稳健性和通用性。

Conclusion: 这些结果代表了迈向 TPL 系统基于状态的维护的重要一步。

Abstract: Two-photon lithography (TPL) is a sophisticated additive manufacturing
technology for creating three-dimensional (3D) micro- and nano-structures.
Maintaining the health of TPL systems is critical for ensuring consistent
fabrication quality. Current maintenance practices often rely on experience
rather than informed monitoring of machine health, resulting in either untimely
maintenance that causes machine downtime and poor-quality fabrication, or
unnecessary maintenance that leads to inefficiencies and avoidable downtime. To
address this gap, this paper presents three methods for accurate and timely
monitoring of TPL machine health. Through integrating physics-informed
data-driven predictive models for structure dimensions with statistical
approaches, the proposed methods are able to handle increasingly complex
scenarios featuring different levels of generalizability. A comprehensive
experimental dataset that encompasses six process parameter combinations and
six structure dimensions under two machine health conditions was collected to
evaluate the effectiveness of the proposed approaches. Across all test
scenarios, the approaches are shown to achieve high accuracies, demonstrating
excellent effectiveness, robustness, and generalizability. These results
represent a significant step toward condition-based maintenance for TPL
systems.

</details>


### [103] [Online Correlation Clustering: Simultaneously Optimizing All $\ell_p$-norms](https://arxiv.org/abs/2510.15076)
*Sami Davies,Benjamin Moseley,Heather Newman*

Main category: cs.LG

TL;DR: 本文提出了一个在线算法，可以在 online-with-a-sample (AOS) 模型中同时逼近所有 Lp 范数的 correlation clustering 问题。


<details>
  <summary>Details</summary>
Motivation: 在离线设置中，可以使用单个聚类同时逼近所有 Lp 范数。本文探讨了是否可以在在线设置中实现这种保证，并受到标准随机顺序 (RO) 在线模型中不同目标之间根本分离的启发。

Method: 本文提出了一个用于 AOS 模型的算法，该算法使用一小部分输入作为样本，生成一个聚类。

Result: 该算法对于所有 Lp 范数具有 $O(log^4 n)$ 竞争比（高概率），对于无穷范数具有 $O(log n)$ 竞争比（高概率），对于 l1 范数具有 $O(1)$ 竞争比（期望）。此外，证明了 RO 模型中 fairness-promoting 无穷范数的任何算法必须具有至少 $\Omega(n^{1/3})$ 的竞争比。对于 l1 和无穷范数，算法的竞争比几乎是严格的。

Conclusion: 这项工作成功地将离线“所有范数”保证转化为在线世界。

Abstract: The $\ell_p$-norm objectives for correlation clustering present a fundamental
trade-off between minimizing total disagreements (the $\ell_1$-norm) and
ensuring fairness to individual nodes (the $\ell_\infty$-norm). Surprisingly,
in the offline setting it is possible to simultaneously approximate all
$\ell_p$-norms with a single clustering. Can this powerful guarantee be
achieved in an online setting? This paper provides the first affirmative
answer. We present a single algorithm for the online-with-a-sample (AOS) model
that, given a small constant fraction of the input as a sample, produces one
clustering that is simultaneously $O(\log^4 n)$-competitive for all
$\ell_p$-norms with high probability, $O(\log n)$-competitive for the
$\ell_\infty$-norm with high probability, and $O(1)$-competitive for the
$\ell_1$-norm in expectation. This work successfully translates the offline
"all-norms" guarantee to the online world.
  Our setting is motivated by a new hardness result that demonstrates a
fundamental separation between these objectives in the standard random-order
(RO) online model. Namely, while the $\ell_1$-norm is trivially
$O(1)$-approximable in the RO model, we prove that any algorithm in the RO
model for the fairness-promoting $\ell_\infty$-norm must have a competitive
ratio of at least $\Omega(n^{1/3})$. This highlights the necessity of a
different beyond-worst-case model. We complement our algorithm with lower
bounds, showing our competitive ratios for the $\ell_1$- and $\ell_\infty$-
norms are nearly tight in the AOS model.

</details>


### [104] [Operator Flow Matching for Timeseries Forecasting](https://arxiv.org/abs/2510.15101)
*Yolanne Yi Ran Lee,Kyriakos Flouris*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为TempO的潜在流匹配模型，用于预测高维、偏微分方程控制的动态。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归和基于扩散的方法在预测过程中存在累积误差和离散化伪影，限制了长期物理一致性预测。

Method: 该模型利用稀疏条件和通道折叠来有效处理3D时空场，并使用时间条件傅里叶层来高保真地捕获多尺度模式。

Result: TempO在三个基准PDE数据集上优于最先进的基线模型，并且在多尺度动态恢复方面表现出色。

Conclusion: 效率研究表明，与基于注意力的或卷积回归模型相比，TempO具有参数和内存轻量化设计的优点。

Abstract: Forecasting high-dimensional, PDE-governed dynamics remains a core challenge
for generative modeling. Existing autoregressive and diffusion-based approaches
often suffer cumulative errors and discretisation artifacts that limit long,
physically consistent forecasts. Flow matching offers a natural alternative,
enabling efficient, deterministic sampling. We prove an upper bound on FNO
approximation error and propose TempO, a latent flow matching model leveraging
sparse conditioning with channel folding to efficiently process 3D
spatiotemporal fields using time-conditioned Fourier layers to capture
multi-scale modes with high fidelity. TempO outperforms state-of-the-art
baselines across three benchmark PDE datasets, and spectral analysis further
demonstrates superior recovery of multi-scale dynamics, while efficiency
studies highlight its parameter- and memory-light design compared to
attention-based or convolutional regressors.

</details>


### [105] [DLER: Doing Length pEnalty Right - Incentivizing More Intelligence per Token via Reinforcement Learning](https://arxiv.org/abs/2510.15110)
*Shih-Yang Liu,Xin Dong,Ximing Lu,Shizhe Diao,Mingjie Liu,Min-Hung Chen,Hongxu Yin,Yu-Chiang Frank Wang,Kwang-Ting Cheng,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.LG

TL;DR: 这篇论文探讨了如何提高语言模型的推理效率，即在保证准确性的前提下，尽可能缩短输出长度。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型通常生成过长的输出，降低了每个token的智能水平（即准确率/响应长度）。

Method: 该论文提出了一种名为DLER的训练方法，结合了批量奖励归一化、更高裁剪、动态采样和简单的截断长度惩罚等技术。

Result: DLER在准确率和效率之间取得了最好的平衡，输出长度减少了70%以上，同时超过了之前所有基线的准确率。此外，还提出了Difficulty-Aware DLER和update-selective merging方法。

Conclusion: DLER方法能够显著提高语言模型的推理效率，并具有良好的泛化能力。

Abstract: Reasoning language models such as OpenAI-o1, DeepSeek-R1, and Qwen achieve
strong performance via extended chains of thought but often generate
unnecessarily long outputs. Maximizing intelligence per token--accuracy
relative to response length--remains an open problem. We revisit reinforcement
learning (RL) with the simplest length penalty--truncation--and show that
accuracy degradation arises not from the lack of sophisticated penalties but
from inadequate RL optimization. We identify three key challenges: (i) large
bias in advantage estimation, (ii) entropy collapse, and (iii) sparse reward
signal. We address them with Doing Length pEnalty Right (DLER), a training
recipe combining batch-wise reward normalization, higher clipping, dynamic
sampling, and a simple truncation length penalty. DLER achieves
state-of-the-art accuracy--efficiency trade-offs, cutting output length by over
70 percent while surpassing all previous baseline accuracy. It also improves
test-time scaling: compared to DeepSeek-R1-7B, DLER-7B generates multiple
concise responses in parallel with 28 percent higher accuracy and lower
latency. We further introduce Difficulty-Aware DLER, which adaptively tightens
truncation on easier questions for additional efficiency gains. We also propose
an update-selective merging method that preserves baseline accuracy while
retaining the concise reasoning ability of the DLER model, which is useful for
scenarios where RL training data is scarce.

</details>


### [106] [Navigating the consequences of mechanical ventilation in clinical intensive care settings through an evolutionary game-theoretic framework](https://arxiv.org/abs/2510.15127)
*David J. Albers,Tell D. Bennett,Jana de Wiljes,Bradford J. Smith,Peter D. Sottile,J. N. Stroh*

Main category: cs.LG

TL;DR: 本文提出了一个框架，用于理解机械通气(MV)和辅助护理决策对接受MV的危重患者的结局的影响。


<details>
  <summary>Details</summary>
Motivation: 了解和改进重症监护呼吸管理需要分析现有的二次利用临床数据，以生成关于当前护理的有利变化和适应的假设。

Method: 利用进化博弈论(EGT)分析呼吸行为，为通过概率和随机机制(如强化学习)进行更深入的分析生成必要的定量前体。

Result: 基于EGT的过程在综合数据上进行了分析验证，以揭示潜在的注意事项，然后再进行真实世界的ICU数据应用，从而揭示数据生成过程J6的复杂性。

Conclusion: 讨论包括使用经验和博弈论元素模拟MV决策效果的状态转移模型的潜在发展。

Abstract: Identifying the effects of mechanical ventilation strategies and protocols in
critical care requires analyzing data from heterogeneous patient-ventilator
systems within the context of the clinical decision-making environment. This
research develops a framework to help understand the consequences of mechanical
ventilation (MV) and adjunct care decisions on patient outcome from
observations of critical care patients receiving MV. Developing an
understanding of and improving critical care respiratory management requires
the analysis of existing secondary-use clinical data to generate hypotheses
about advantageous variations and adaptations of current care. This work
introduces a perspective of the joint patient-ventilator-care systems
(so-called J6) to develop a scalable method for analyzing data and trajectories
of these complex systems. To that end, breath behaviors are analyzed using
evolutionary game theory (EGT), which generates the necessary quantitative
precursors for deeper analysis through probabilistic and stochastic machinery
such as reinforcement learning. This result is one step along the pathway
toward MV optimization and personalization. The EGT-based process is
analytically validated on synthetic data to reveal potential caveats before
proceeding to real-world ICU data applications that expose complexities of the
data-generating process J6. The discussion includes potential developments
toward a state transition model for the simulating effects of MV decision using
empirical and game-theoretic elements.

</details>


### [107] [A Simple Method for PMF Estimation on Large Supports](https://arxiv.org/abs/2510.15132)
*Alex Shtoff*

Main category: cs.LG

TL;DR: 本文研究了在大型离散支持上概率质量函数 (PMF) 的非参数估计，其中 PMF 是多模态和重尾的。该方法将经验 PMF 视为线图上的信号，并应用数据相关的低通滤波器。通过计算对称三对角算子的特征向量，并将经验 PMF 投影到低维子空间，生成平滑的多模态估计，同时抑制噪声。最后，通过裁剪和重新归一化得到有效的 PMF。


<details>
  <summary>Details</summary>
Motivation: 在大型离散支持上估计多模态和重尾 PMF。

Method: 将经验 PMF 视为线图上的信号，并应用数据相关的低通滤波器。具体来说，构建一个对称三对角算子，即路径图拉普拉斯算子，并用从经验 PMF 构建的对角矩阵进行扰动，然后计算对应于最小 feq 特征值的特征向量。将经验 PMF 投影到这个低维子空间上，产生一个平滑的多模态估计，该估计保留了粗略的结构，同时抑制了噪声。裁剪和重新归一化的简单后处理步骤产生了一个有效的 PMF。

Result: 在合成的和真实的重尾例子中，该方法保留了粗略的结构，同时抑制了采样噪声，并且在预期的范围内与 logspline 和 Gaussian-KDE 基线相比具有优势。该方法易于实现，在不同的样本量中具有鲁棒性，并且由于其可靠性和速度，适用于自动化管道和大规模的探索性分析。

Conclusion: 该方法计算可靠，运行时间和内存与支持乘以所需的低维子空间的维度成正比。此外，还提供了一个实用的、数据驱动的规则，用于根据正交序列风险估计选择维度，因此该方法只需进行最少的调整即可“正常工作”。

Abstract: We study nonparametric estimation of a probability mass function (PMF) on a
large discrete support, where the PMF is multi-modal and heavy-tailed. The core
idea is to treat the empirical PMF as a signal on a line graph and apply a
data-dependent low-pass filter. Concretely, we form a symmetric tri-diagonal
operator, the path graph Laplacian perturbed with a diagonal matrix built from
the empirical PMF, then compute the eigenvectors, corresponding to the smallest
feq eigenvalues. Projecting the empirical PMF onto this low dimensional
subspace produces a smooth, multi-modal estimate that preserves coarse
structure while suppressing noise. A light post-processing step of clipping and
re-normalizing yields a valid PMF.
  Because we compute the eigenpairs of a symmetric tridiagonal matrix, the
computation is reliable and runs time and memory proportional to the support
times the dimension of the desired low-dimensional supspace. We also provide a
practical, data-driven rule for selecting the dimension based on an
orthogonal-series risk estimate, so the method "just works" with minimal
tuning. On synthetic and real heavy-tailed examples, the approach preserves
coarse structure while suppressing sampling noise, compares favorably to
logspline and Gaussian-KDE baselines in the intended regimes. However, it has
known failure modes (e.g., abrupt discontinuities). The method is short to
implement, robust across sample sizes, and suitable for automated pipelines and
exploratory analysis at scale because of its reliability and speed.

</details>


### [108] [Predicting the Unpredictable: Reproducible BiLSTM Forecasting of Incident Counts in the Global Terrorism Database (GTD)](https://arxiv.org/abs/2510.15136)
*Oluwasegun Adegoke*

Main category: cs.LG

TL;DR: 本文研究了使用全球恐怖主义数据库 (GTD, 1970-2016) 对每周恐怖主义事件计数进行短期预测，并提供了一个透明的、优于基线的 GTD 事件预测参考。


<details>
  <summary>Details</summary>
Motivation: 研究短期预测每周恐怖主义事件计数。

Method: 使用固定时间分割构建可重复的pipeline，并评估双向LSTM (BiLSTM)。

Result: 在保留的测试集上，BiLSTM 的 RMSE 为 6.38，优于 LSTM-Attention (9.19; +30.6%) 和线性滞后回归基线 (+35.4% RMSE 增益)，MAE 和 MAPE 也有类似的改进。

Conclusion: 总的来说，这项研究为 GTD 事件预测提供了一个透明的、优于基线的参考。

Abstract: We study short-horizon forecasting of weekly terrorism incident counts using
the Global Terrorism Database (GTD, 1970--2016). We build a reproducible
pipeline with fixed time-based splits and evaluate a Bidirectional LSTM
(BiLSTM) against strong classical anchors (seasonal-naive, linear/ARIMA) and a
deep LSTM-Attention baseline. On the held-out test set, the BiLSTM attains RMSE
6.38, outperforming LSTM-Attention (9.19; +30.6\%) and a linear lag-regression
baseline (+35.4\% RMSE gain), with parallel improvements in MAE and MAPE.
Ablations varying temporal memory, training-history length, spatial grain,
lookback size, and feature groups show that models trained on long historical
data generalize best; a moderate lookback (20--30 weeks) provides strong
context; and bidirectional encoding is critical for capturing both build-up and
aftermath patterns within the window. Feature-group analysis indicates that
short-horizon structure (lagged counts and rolling statistics) contributes
most, with geographic and casualty features adding incremental lift. We release
code, configs, and compact result tables, and provide a data/ethics statement
documenting GTD licensing and research-only use. Overall, the study offers a
transparent, baseline-beating reference for GTD incident forecasting.

</details>


### [109] [Policy Transfer Ensures Fast Learning for Continuous-Time LQR with Entropy Regularization](https://arxiv.org/abs/2510.15165)
*Xin Guo,Zijiu Lyu*

Main category: cs.LG

TL;DR: This paper introduces a policy transfer method for continuous-time linear quadratic regulators (LQRs) with entropy regularization to improve reinforcement learning efficiency.


<details>
  <summary>Details</summary>
Motivation: Training reinforcement learning agents from scratch on complex tasks is inefficient. Transfer learning, successful in large language models, can enhance RL efficiency by using pre-trained models.

Method: The paper uses a policy transfer approach, initializing learning in a target RL task using a policy from a related source task, specifically in continuous-time LQRs with entropy regularization. They also introduce a novel policy learning algorithm for continuous-time LQRs.

Result: The paper provides the first theoretical proof of policy transfer for continuous-time RL, showing that a policy optimal for one LQR serves as a near-optimal initialization for closely related LQRs, while preserving the original algorithm's convergence rate. The novel algorithm achieves global linear and local super-linear convergence.

Conclusion: The results demonstrate theoretical guarantees and algorithmic benefits of transfer learning in continuous-time RL. As a byproduct, the paper derives the stability of a class of continuous-time score-based diffusion models via their connection with LQRs.

Abstract: Reinforcement Learning (RL) enables agents to learn optimal decision-making
strategies through interaction with an environment, yet training from scratch
on complex tasks can be highly inefficient. Transfer learning (TL), widely
successful in large language models (LLMs), offers a promising direction for
enhancing RL efficiency by leveraging pre-trained models.
  This paper investigates policy transfer, a TL approach that initializes
learning in a target RL task using a policy from a related source task, in the
context of continuous-time linear quadratic regulators (LQRs) with entropy
regularization. We provide the first theoretical proof of policy transfer for
continuous-time RL, proving that a policy optimal for one LQR serves as a
near-optimal initialization for closely related LQRs, while preserving the
original algorithm's convergence rate. Furthermore, we introduce a novel policy
learning algorithm for continuous-time LQRs that achieves global linear and
local super-linear convergence. Our results demonstrate both theoretical
guarantees and algorithmic benefits of transfer learning in continuous-time RL,
addressing a gap in existing literature and extending prior work from discrete
to continuous time settings.
  As a byproduct of our analysis, we derive the stability of a class of
continuous-time score-based diffusion models via their connection with LQRs.

</details>


### [110] [A simple mean field model of feature learning](https://arxiv.org/abs/2510.15174)
*Niclas Göring,Chris Mingard,Yoonsoo Nam,Ard Louis*

Main category: cs.LG

TL;DR: 本文运用统计物理学方法，推导了随机梯度 Langevin 动力学（SGLD）训练的两层非线性网络贝叶斯后验的可处理的自洽平均场（MF）理论。


<details>
  <summary>Details</summary>
Motivation: 更好地理解特征学习（FL），即神经网络在训练过程中调整其内部表征的方式。

Method: 使用统计物理学方法，为用随机梯度 Langevin 动力学（SGLD）训练的两层非线性网络推导出一个可处理的自洽平均场（MF）理论。

Result: 在无限宽度下，该理论简化为核岭回归，但在有限宽度下，它预测了一个对称破缺相变，网络突然与目标函数对齐。基本的 MF 理论可以对有限宽度范围内 FL 的出现提供理论上的见解，半定量地预测噪声或样本大小的 FL 的开始，但它大大低估了过渡后泛化的改进。

Conclusion: 通过将自增强输入特征选择机制纳入 MF 理论，可以定量地匹配 SGLD 训练的网络的学习曲线，并提供对 FL 的机制性见解。

Abstract: Feature learning (FL), where neural networks adapt their internal
representations during training, remains poorly understood. Using methods from
statistical physics, we derive a tractable, self-consistent mean-field (MF)
theory for the Bayesian posterior of two-layer non-linear networks trained with
stochastic gradient Langevin dynamics (SGLD). At infinite width, this theory
reduces to kernel ridge regression, but at finite width it predicts a symmetry
breaking phase transition where networks abruptly align with target functions.
While the basic MF theory provides theoretical insight into the emergence of FL
in the finite-width regime, semi-quantitatively predicting the onset of FL with
noise or sample size, it substantially underestimates the improvements in
generalisation after the transition. We trace this discrepancy to a key
mechanism absent from the plain MF description: \textit{self-reinforcing input
feature selection}. Incorporating this mechanism into the MF theory allows us
to quantitatively match the learning curves of SGLD-trained networks and
provides mechanistic insight into FL.

</details>


### [111] [Finding geodesics with the Deep Ritz method](https://arxiv.org/abs/2510.15177)
*Conor Rowan*

Main category: cs.LG

TL;DR: 这篇论文探索了使用 Deep Ritz 方法解决测地线问题，并展示了其在路径规划、光学和固体力学中的应用。


<details>
  <summary>Details</summary>
Motivation: 尽管测地线问题在物理和工程学中普遍存在，但科学机器学习 (SciML) 社区对研究解决这些问题的方法关注较少。这篇论文旨在填补这一空白。

Method: 该研究使用 Deep Ritz 方法解决测地线问题。

Result: 通过路径规划、光学和固体力学三个数值例子验证了 Deep Ritz 方法在解决测地线问题上的有效性。

Conclusion: 这篇论文旨在确定 Deep Ritz 方法的一个有前景的应用，并为未来的 SciML 研究提供一个富有成果的方向。

Abstract: Geodesic problems involve computing trajectories between prescribed initial
and final states to minimize a user-defined measure of distance, cost, or
energy. They arise throughout physics and engineering -- for instance, in
determining optimal paths through complex environments, modeling light
propagation in refractive media, and the study of spacetime trajectories in
control theory and general relativity. Despite their ubiquity, the scientific
machine learning (SciML) community has given relatively little attention to
investigating its methods in the context of these problems. In this work, we
argue that given their simple geometry, variational structure, and natural
nonlinearity, geodesic problems are particularly well-suited for the Deep Ritz
method. We substantiate this claim with three numerical examples drawn from
path planning, optics, and solid mechanics. Our goal is not to provide an
exhaustive study of geodesic problems, but rather to identify a promising
application of the Deep Ritz method and a fruitful direction for future SciML
research.

</details>


### [112] [An Advanced Two-Stage Model with High Sensitivity and Generalizability for Prediction of Hip Fracture Risk Using Multiple Datasets](https://arxiv.org/abs/2510.15179)
*Shuo Sun,Meiling Zhou,Chen Zhao,Joyce H. Keyak,Nancy E. Lane,Jeffrey D. Deng,Kuan-Jui Su,Hui Shen,Hong-Wen Deng,Kui Zhang,Weihua Zhou*

Main category: cs.LG

TL;DR: 该研究提出了一种用于早期髋部骨折风险评估的序列两阶段模型，该模型集成了临床和影像信息，以提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 常用的工具（如 DXA T 值和 FRAX）通常缺乏敏感性，并且会遗漏高危人群，特别是那些没有先前骨折或患有骨质减少症的人群。为了解决这个局限性。

Method: 利用来自老年男性骨质疏松性骨折研究 (MrOS)、骨质疏松性骨折研究 (SOF) 和英国生物样本库的数据，第一阶段（筛查）采用临床、人口统计学和功能变量来估计基线风险，而第二阶段（影像）则纳入 DXA 衍生的特征以进行细化。

Result: 该模型通过内部和外部测试进行了严格验证，在队列中显示出一致的性能和适应性。与 T 值和 FRAX 相比，两阶段框架实现了更高的灵敏度并减少了遗漏病例。

Conclusion: 两阶段模型提供了一种经济有效且个性化的早期髋部骨折风险评估方法。

Abstract: Hip fractures are a major cause of disability, mortality, and healthcare
burden in older adults, underscoring the need for early risk assessment.
However, commonly used tools such as the DXA T-score and FRAX often lack
sensitivity and miss individuals at high risk, particularly those without prior
fractures or with osteopenia. To address this limitation, we propose a
sequential two-stage model that integrates clinical and imaging information to
improve prediction accuracy. Using data from the Osteoporotic Fractures in Men
Study (MrOS), the Study of Osteoporotic Fractures (SOF), and the UK Biobank,
Stage 1 (Screening) employs clinical, demographic, and functional variables to
estimate baseline risk, while Stage 2 (Imaging) incorporates DXA-derived
features for refinement. The model was rigorously validated through internal
and external testing, showing consistent performance and adaptability across
cohorts. Compared to T-score and FRAX, the two-stage framework achieved higher
sensitivity and reduced missed cases, offering a cost-effective and
personalized approach for early hip fracture risk assessment.
  Keywords: Hip Fracture, Two-Stage Model, Risk Prediction, Sensitivity, DXA,
FRAX

</details>


### [113] [Automotive Crash Dynamics Modeling Accelerated with Machine Learning](https://arxiv.org/abs/2510.15201)
*Mohammad Amin Nabian,Sudeep Chavare,Deepak Akhare,Rishikesh Ranade,Ram Cherukuri,Srinivas Tadepalli*

Main category: cs.LG

TL;DR: 本文探索了使用NVIDIA PhysicsNeMo框架开发基于机器学习的代理模型，用于有效预测碰撞场景中的结构变形。


<details>
  <summary>Details</summary>
Motivation: 传统汽车设计的耐撞性评估依赖于高保真有限元（FE）仿真，计算成本高且耗时。因此，需要更高效的方法。

Method: 研究了两种用于建模碰撞动力学的先进神经网络架构：MeshGraphNet和Transolver。此外，还研究了三种用于建模瞬态动力学的策略：时间条件方法、标准自回归方法和结合了基于rollout训练的稳定性增强自回归方案。

Result: 模型能够以合理的精度捕捉整体变形趋势，证明了将机器学习应用于结构碰撞动力学的可行性。虽然尚未达到完全有限元仿真的精度，但模型在计算成本上实现了数量级的降低。

Conclusion: 该方法能够实现快速设计探索和耐撞性评估的早期优化。

Abstract: Crashworthiness assessment is a critical aspect of automotive design,
traditionally relying on high-fidelity finite element (FE) simulations that are
computationally expensive and time-consuming. This work presents an exploratory
comparative study on developing machine learning-based surrogate models for
efficient prediction of structural deformation in crash scenarios using the
NVIDIA PhysicsNeMo framework. Given the limited prior work applying machine
learning to structural crash dynamics, the primary contribution lies in
demonstrating the feasibility and engineering utility of the various modeling
approaches explored in this work. We investigate two state-of-the-art neural
network architectures for modeling crash dynamics: MeshGraphNet, and
Transolver. Additionally, we examine three strategies for modeling transient
dynamics: time-conditional, the standard Autoregressive approach, and a
stability-enhanced Autoregressive scheme incorporating rollout-based training.
The models are evaluated on a comprehensive Body-in-White (BIW) crash dataset
comprising 150 detailed FE simulations using LS-DYNA. The dataset represents a
structurally rich vehicle assembly with over 200 components, including 38 key
components featuring variable thickness distributions to capture realistic
manufacturing variability. Each model utilizes the undeformed mesh geometry and
component characteristics as inputs to predict the spatiotemporal evolution of
the deformed mesh during the crash sequence. Evaluation results show that the
models capture the overall deformation trends with reasonable fidelity,
demonstrating the feasibility of applying machine learning to structural crash
dynamics. Although not yet matching full FE accuracy, the models achieve
orders-of-magnitude reductions in computational cost, enabling rapid design
exploration and early-stage optimization in crashworthiness evaluation.

</details>


### [114] [Dissecting Mahalanobis: How Feature Geometry and Normalization Shape OOD Detection](https://arxiv.org/abs/2510.15202)
*Denis Janiak,Jakub Binkowski,Tomasz Kajdanowicz*

Main category: cs.LG

TL;DR: 本文研究了深度学习模型中的OOD检测问题，发现现有Mahalanobis距离方法并非完全可靠。通过分析表示几何和归一化的影响，提出了径向缩放的l2归一化方法，以提高OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有Mahalanobis距离方法在OOD检测中的性能受表示几何和归一化的影响，但其影响尚未完全明确，限制了下游应用。

Method: 通过对不同的图像基础模型、数据集和距离归一化方案进行全面的实证研究，分析了Mahalanobis方法的可靠性，定义了理想的数据表示几何，并提出了径向缩放的l2归一化方法。

Result: 研究表明，Mahalanobis方法并非普遍可靠；谱和固有维度指标可以准确预测模型的OOD性能；提出的径向缩放l2归一化方法可以显著提高OOD检测性能。

Conclusion: 本文的研究结果弥合了表示几何、归一化和OOD性能之间的差距，为设计更有效和可靠的深度学习模型提供了新的见解。

Abstract: Out-of-distribution (OOD) detection is critical for the reliable deployment
of deep learning models. hile Mahalanobis distance methods are widely used, the
impact of representation geometry and normalization on their performance is not
fully understood, which may limit their downstream application. To address this
gap, we conducted a comprehensive empirical study across diverse image
foundation models, datasets, and distance normalization schemes. First, our
analysis shows that Mahalanobis-based methods aren't universally reliable.
Second, we define the ideal geometry for data representations and demonstrate
that spectral and intrinsic-dimensionality metrics can accurately predict a
model's OOD performance. Finally, we analyze how normalization impacts OOD
performance. Building upon these studies, we propose radially scaled $\ell_2$
normalization, a method that generalizes the standard $\ell_2$ normalization
recently applied to Mahalanobis-based OOD detection. Our approach introduces a
tunable parameter to directly control the radial geometry of the feature space,
systematically contracting or expanding representations to significantly
improve OOD detection performance. By bridging the gap between representation
geometry, normalization, and OOD performance, our findings offer new insights
into the design of more effective and reliable deep learning models.

</details>


### [115] [ReasonIF: Large Reasoning Models Fail to Follow Instructions During Reasoning](https://arxiv.org/abs/2510.15211)
*Yongchan Kwon,Shang Zhu,Federico Bianchi,Kaitlyn Zhou,James Zou*

Main category: cs.LG

TL;DR: 大型语言模型遵循用户指令的能力至关重要。本文提出了ReasonIF基准，用于评估推理过程中指令的遵循情况。发现现有开放源代码大型推理模型在推理指令遵循方面存在显著不足。提出了多轮推理和使用合成数据进行推理指令微调(RIF)两种策略来提高指令遵循度。


<details>
  <summary>Details</summary>
Motivation: 评估大型推理模型在推理过程中遵循用户指令的重要性，提高模型的可控性和透明性，减少不良捷径、幻觉或奖励攻击的风险。

Method: 提出了ReasonIF基准，包含六类指令提示，涵盖多语言推理、格式和长度控制。评估了多个开源大型推理模型，并探索了多轮推理和推理指令微调(RIF)两种策略。

Result: 发现现有开放源代码大型推理模型在推理指令遵循方面存在显著不足，最高指令遵循得分低于0.25。RIF可以将GPT-OSS-20B的IFS从0.11提高到0.27。

Conclusion: 大型推理模型在推理指令遵循方面有待提高，RIF是一种有效的改进方法，但仍有很大的改进空间。

Abstract: The ability of large language models (LLMs) to follow user instructions is
central to their reliability, safety, and usefulness. While prior studies
assess instruction adherence in the model's main responses, we argue that it is
also critical for large reasoning models (LRMs) to follow user instructions
throughout their reasoning process. Reasoning instruction following makes LRMs
more controllable and transparent, while reducing risks of undesirable
shortcuts, hallucinations, or reward hacking within reasoning traces. To
evaluate this dimension, we introduce ReasonIF, a systematic benchmark for
assessing reasoning instruction following. ReasonIF includes six categories of
instruction prompts, spanning multilingual reasoning, formatting and length
control. Across many open-source LRMs including GPT-OSS, Qwen3, and
DeepSeek-R1, we find substantial failures in reasoning instruction adherence:
the highest instruction following score (IFS) remains below 0.25, meaning that
fewer than $25\%$ of reasoning traces comply with the given instructions.
Notably, as task difficulty increases, reasoning instruction following degrades
further. We also explore two strategies to enhance reasoning instruction
fidelity. (1) multi-turn reasoning and (2) Reasoning Instruction Finetuning
(RIF) using synthetic data. RIF improves the IFS of $GPT-OSS-20B$ from 0.11 to
0.27, indicating measurable progress but leaving ample room for improvement.

</details>


### [116] [Soundness-Aware Level: A Microscopic Signature that Predicts LLM Reasoning Potential](https://arxiv.org/abs/2510.15216)
*Xuansheng Wu,Xiaoman Pan,Wenlin Yao,Jianshu Chen*

Main category: cs.LG

TL;DR: 论文研究了大型语言模型（LLM）在经过可验证奖励的强化学习（RLVR）后的推理能力差异，并发现这种差异与预训练模型的微观属性有关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是发现预训练模型的哪些微观属性导致了 RLVR 后性能的巨大差异。

Method: 该研究将推理形式化为从 LLM 潜在空间提取的 Horn 子句链，并使用跨层稀疏自动编码器 (SAE) 估计特征之间的转移概率，然后用 LLM 对每个规则的语义合理性水平进行分类。最后，提出了一个名为合理性感知水平 (SAL) 的指标来量化模型区分合理和不合理知识的能力。

Result: 研究发现，高潜力模型本质上是合理性感知的，它们的内部概率分布在规则的合理性水平上系统性地变化，而较弱的模型则对合理性不可知。SAL 指标的预测与 RLVR 后的推理性能之间存在精确的经验规律 (R^2=0.87)。

Conclusion: 模型的推理潜力与其区分合理和不合理知识的内在能力相关，这强调了模型预训练在塑造推理中的关键作用，并提供了一个基于模型内部机制的实用指标，用于选择/设计更强的基础模型。

Abstract: Reinforcement learning with verifiable rewards (RLVR) can elicit strong
reasoning in large language models (LLMs), while their performance after RLVR
varies dramatically across different base models. This raises a fundamental
question: what microscopic property of pre-trained models leads to this
variation? To investigate, we formalize reasoning as chains of Horn clauses
("if-then" rules) built from features extracted from the LLM's latent space via
cross-layer sparse autoencoders (SAEs). We estimate the transition
probabilities between its features, and further categorize each rule by its
semantic soundness level (e.g., strict, plausible, noisy) with an LLM. Our key
discovery is that high-potential models are inherently soundness-aware: their
internal probability distributions systematically shift across rules' soundness
levels, becoming highly distinct for "strict" versus "noisy" rules. In
contrast, weaker models are soundness-agnostic, collapsing to one distribution
regardless of soundness levels. To quantify this, we introduce the
Soundness-Aware Level (SAL), a microscopic metric using the Jensen-Shannon
Divergence to measure the separation between these distributions. We show that
SAL's predictions of post-RLVR reasoning performance follow a precise empirical
law (R^2=0.87) across diverse model families (Qwen, Mistral, Llama, DeepSeek)
and scales (0.5B-14B). This reveals that a model's reasoning potential is tied
to its intrinsic, pre-trained ability to distinguish sound knowledge from
unsound ones. These findings underscore the critical role of model pre-training
in shaping reasoning and offer a practical metric grounded in the model's
internal mechanisms for selecting/designing stronger base models.

</details>
