<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 12]
- [cs.CV](#cs.CV) [Total: 8]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 4]
- [cs.LG](#cs.LG) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: People use a combination of distributed and symbolic representations to construct bespoke mental models tailored to novel situations.


<details>
  <summary>Details</summary>
Motivation: What permits us to draw in globally relevant information and reason over it coherently?

Method: a ``Model Synthesis Architecture'' (MSA) -- using language models to implement global relevance-based retrieval and model synthesis and probabilistic programs to implement bespoke, coherent world models

Result: MSA approach captures human judgments better than language model-only baselines, under both direct and chain-of-thought generations from the LM that supports model synthesis.

Conclusion: MSAs can be implemented in a way that mirrors people's ability to deliver locally coherent reasoning over globally relevant variables, offering a path to understanding and replicating human reasoning in open-ended domains.

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [2] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 我们使用可解释性技术研究了语言模型中的情态分类，发现它们比以前认为的更擅长此任务，并且这些模型可以用来模拟人类的情态分类行为。


<details>
  <summary>Details</summary>
Motivation: 为了可靠地完成任务，语言模型必须能够识别句子的情态类别。然而，最近的研究对语言模型根据情态对句子进行分类的能力提出了质疑。

Method: 我们识别了各种语言模型中区分情态类别的线性表示，或称情态差异向量，并分析了这些向量。

Result: 语言模型可以进行比之前报道的更可靠的情态分类判断。随着模型能力的提高，情态差异向量以一致的顺序出现。在LM激活中识别出的情态差异向量可用于建模细粒度的人类分类行为。

Conclusion: 通过可解释性方法，我们深入了解了语言模型中的情态分类，并有可能加深我们对人类情态分类的理解。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [3] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 发布了首个开源车臣语-俄语翻译模型及数据集，通过微调 NLLB-200 实现。


<details>
  <summary>Details</summary>
Motivation: 构建首个开源的车臣语和俄语互译模型。

Method: 通过对大型语言模型 NLLB-200 进行微调，将新语言（车臣语）加入到多语种翻译系统中。

Result: 俄语到车臣语的 BLEU / ChrF++ 分数为 8.34 / 34.69，反向翻译为 20.89 / 44.55。

Conclusion: 发布了车臣语和俄语之间的翻译模型，并提供了平行语料库和多语种句子编码器。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [4] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: This paper uses NLP models to classify overdose deaths from free-text reports, achieving high accuracy with fine-tuned BioClinicalBERT, which can improve surveillance workflows.


<details>
  <summary>Details</summary>
Motivation: The rising rate of drug-related deaths in the United States, largely driven by fentanyl, requires timely and accurate surveillance. However, critical overdose data are often buried in free-text coroner reports, leading to delays and information loss when coded into ICD (International Classification of Disease)-10 classifications.

Method: Multiple NLP approaches were evaluated for classifying specific drug involvement from unstructured death certificate text. These included traditional single- and multi-label classifiers, as well as fine-tuned encoder-only language models such as Bidirectional Encoder Representations from Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large language models such as Qwen 3 and Llama 3.

Result: Fine-tuned BioClinicalBERT models achieved near-perfect performance, with macro F1 scores >=0.998 on the internal test set. External validation confirmed robustness (macro F1=0.966), outperforming conventional machine learning, general-domain BERT models, and various decoder-only large language models.

Conclusion: NLP models, particularly fine-tuned clinical variants like BioClinicalBERT, offer a highly accurate and scalable solution for overdose death classification from free-text reports. These methods can significantly accelerate surveillance workflows, overcoming the limitations of manual ICD-10 coding and supporting near real-time detection of emerging substance use trends.

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [5] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent, a new framework for Multimodal Aspect-Based Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms to improve sentiment classification


<details>
  <summary>Details</summary>
Motivation: improve sentiment classification and aspect term extraction from both text and images

Method: a new framework for Multimodal Aspect-Based Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms to improve sentiment classification and aspect term extraction from both text and images. Our model integrates dynamic modality weighting and context-adaptive attention

Result: AdaptiSent surpasses existing models in precision, recall, and F1 score, and is particularly effective in identifying nuanced inter-modal relationships that are crucial for accurate sentiment and aspect term extraction.

Conclusion: AdaptiSent sets a new standard for MABSA, significantly outperforming current methods, especially in understanding complex multimodal information.

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [6] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE, an unsupervised method using LLM-generated summaries and contrastive learning, outperforms citation-based methods by capturing semantic content, achieving state-of-the-art results on SciRepEval.


<details>
  <summary>Details</summary>
Motivation: Traditional citation-based approaches do not necessarily reflect semantic similarity.

Method: An unsupervised method leveraging LLM-generated summaries of scientific abstracts to train a model using contrastive learning.

Result: SemCSE enforces a stronger semantic separation within the embedding space, validated by a novel benchmark.

Conclusion: SemCSE achieves state-of-the-art performance on the SciRepEval benchmark, demonstrating the benefits of a semantically focused training approach.

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [7] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: LAMs can be used for speech evaluation, but prompt engineering is needed to improve performance and address biases.


<details>
  <summary>Details</summary>
Motivation: Current speech evaluation suffers from the need and difficulty of designing specialized systems and poor correlation between automatic evaluation methods and human preferences.

Method: Audio concatenation combined with in-context learning and multi-aspect ensemble AudioJudge.

Result: Achieves up to 0.91 Spearman correlation with human preferences on system ranking benchmark. Maintains strong performance under acoustic noise.

Conclusion: LAMs are effective for speech evaluation but have verbosity and positional biases.

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [8] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: AutoSteer, a modular intervention technology, improves the safety of MLLMs during inference by reducing the attack success rate on various threats without fine-tuning the model.


<details>
  <summary>Details</summary>
Motivation: To improve the safety of MLLMs during inference, particularly when faced with adversarial multimodal inputs.

Method: a modular and adaptive inference-time intervention technology, AutoSteer, without requiring any fine-tuning of the underlying model. AutoSteer incorporates three core components: (1) a novel Safety Awareness Score (SAS); (2) an adaptive safety prober; and (3) a lightweight Refusal Head.

Result: AutoSteer significantly reduces the Attack Success Rate (ASR) for textual, visual, and cross-modal threats, while maintaining general abilities.

Conclusion: AutoSteer is a practical, interpretable, and effective framework for safer deployment of multimodal AI systems.

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [9] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: introduce FLEXITOKENS, a simplified training objective that enables significantly greater flexibility during adaptation, consistently reduces token over-fragmentation and achieves up to 10% improvements on downstream task performance compared to subword and other gradient-based tokenizers.


<details>
  <summary>Details</summary>
Motivation: LMs are challenging to adapt to new data distributions by simple finetuning, due to the rigidity of their subword tokenizers, which typically remain unchanged during adaptation. This inflexibility often leads to inefficient tokenization, causing overfragmentation of out-of-distribution domains, unseen languages, or scripts.

Method: develop byte-level LMs with learnable tokenizers to make tokenization adaptive. include a submodule that learns to predict boundaries between the input byte sequence, encoding it into variable-length segments. propose FLEXITOKENS, a simplified training objective that enables significantly greater flexibility during adaptation.

Result: Evaluating across multiple multilingual benchmarks, morphologically diverse tasks, and domains, we demonstrate that FLEXITOKENS consistently reduces token over-fragmentation and achieves up to 10% improvements on downstream task performance compared to subword and other gradient-based tokenizers.

Conclusion: FLEXITOKENS consistently reduces token over-fragmentation and achieves up to 10% improvements on downstream task performance compared to subword and other gradient-based tokenizers.

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [10] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: TalentCLEF 2025 是首个专注于技能和职位名称智能的评估活动，旨在填补该领域公共基准的空白，并促进劳动力市场中稳健、公平的语言技术发展。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理和大型语言模型的进步正在推动人力资本管理领域的重大转型，但这些技术的采用和进步关键取决于可靠和公平模型的开发，以及在公共数据和开放基准上的适当评估，而这些在目前为止在该领域尚不可用。

Method: 信息检索技术，使用基于多语言编码器的模型进行微调，并结合大型语言模型进行数据增强或重排序。

Result: 结果表明，训练策略比模型本身的大小具有更大的影响。TalentCLEF吸引了76个注册团队，提交了超过280份方案。

Conclusion: TalentCLEF作为首个公开基准，鼓励为劳动力市场开发稳健、公平和可转移的语言技术。

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [11] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia 是一个基于提示的翻译评估和排序系统，其性能与最先进的 MT-Ranker 相当或更好，并且其评估结果对人类评估者来说是可以接受的。


<details>
  <summary>Details</summary>
Motivation: 论文提出了 TransEvalnia，一个基于提示的翻译评估和排序系统，旨在解决翻译评估和排序问题。

Method: TransEvalnia 是一种基于提示的翻译评估和排序系统，它使用推理来进行评估和排序。该系统基于多维质量指标的一个子集提供细粒度的评估。

Result: TransEvalnia 的评估结果被认为对人类评估者来说是可以接受的，并且 Sonnet 以及其他 LLM 给翻译的分数与人类评估者给出的分数相关性很好。

Conclusion: TransEvalnia 的表现与最先进的 MT-Ranker 相当或更好，并且其评估结果对人类评估者来说是可以接受的，并且分数与人类评估者给出的分数相关性很好。该系统对翻译的呈现顺序敏感，并提出了解决这种位置偏差的方法。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [12] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 提出了一种根据游戏环境和估计的其他玩家角色显式选择策略的方法，以提高狼人代理的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的使用提示工程的狼人代理无法适应变化的情况。

Method: 提出了一种基于其他玩家态度和对话上下文在预定义策略之间切换的方法。

Result: 策略调整狼人代理优于使用隐式或固定策略的基线代理。

Conclusion: 通过策略调整，狼人代理的表现得到了提升。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [13] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: EaGERS是一个免训练的流程，通过视觉语言模型生成理由并将其定位到图像区域，从而提高DocVQA的透明性和准确性。


<details>
  <summary>Details</summary>
Motivation: 提高DocVQA的透明性和可重复性，无需额外的模型微调。

Method: EaGERS，一个完全免训练且模型无关的流程，它通过视觉语言模型生成自然语言理由，通过计算可配置网格上的多模态嵌入相似性将这些理由定位到空间子区域，并且仅从掩蔽图像中选择的相关区域限制响应的生成。

Result: EaGERS的最佳配置在DocVQA数据集上的精确匹配准确率和平均归一化Levenshtein相似度指标上优于基础模型。

Conclusion: EaGERS在DocVQA数据集上优于基础模型，提高了透明性和可重复性，无需额外的模型微调。

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [14] [MindJourney: Test-Time Scaling with World Models for Spatial Reasoning](https://arxiv.org/abs/2507.12508)
*Yuncong Yang,Jiageng Liu,Zheyuan Zhang,Siyuan Zhou,Reuben Tan,Jianwei Yang,Yilun Du,Chuang Gan*

Main category: cs.CV

TL;DR: MindJourney通过将VLM与世界模型相结合，使其具备了3D推理能力，并在空间推理基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 最先进的视觉语言模型(VLMs)在预测自我中心运动后场景的外观等简单任务中经常遇到困难，因为它们感知2D图像，但缺乏3D动态的内部模型。

Method: 将VLM与基于视频扩散的可控世界模型相结合，VLM迭代地勾勒出简洁的相机轨迹，而世界模型则合成每个步骤中对应的视图。然后，VLM根据交互探索期间收集的多视图证据进行推理。

Result: MindJourney在SAT基准测试中平均提升了8%的性能，并且改进了通过强化学习训练的测试时推理VLMs。

Conclusion: MindJourney在SAT基准测试中平均提升了8%的性能，证明了将VLMs与世界模型配对进行测试时扩展是一种实现鲁棒3D推理的简单、即插即用的方法。该方法还改进了通过强化学习训练的测试时推理VLMs。

Abstract: Spatial reasoning in 3D space is central to human cognition and indispensable
for embodied tasks such as navigation and manipulation. However,
state-of-the-art vision-language models (VLMs) struggle frequently with tasks
as simple as anticipating how a scene will look after an egocentric motion:
they perceive 2D images but lack an internal model of 3D dynamics. We therefore
propose MindJourney, a test-time scaling framework that grants a VLM with this
missing capability by coupling it to a controllable world model based on video
diffusion. The VLM iteratively sketches a concise camera trajectory, while the
world model synthesizes the corresponding view at each step. The VLM then
reasons over this multi-view evidence gathered during the interactive
exploration. Without any fine-tuning, our MindJourney achieves over an average
8% performance boost on the representative spatial reasoning benchmark SAT,
showing that pairing VLMs with world models for test-time scaling offers a
simple, plug-and-play route to robust 3D reasoning. Meanwhile, our method also
improves upon the test-time inference VLMs trained through reinforcement
learning, which demonstrates the potential of our method that utilizes world
models for test-time scaling.

</details>


### [15] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: 本文提出了一种新的单体 MLLM，通过嵌入新的视觉参数空间和创新的预训练方法，解决了优化不稳定和灾难性遗忘问题，并在性能和效率上都取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的单体多模态大型语言模型 (MLLM) 结构和预训练策略经常遭受不稳定的优化和灾难性遗忘。

Method: 引入 Mono-InternVL，通过多模态混合专家架构整合视觉专家，并设计内生视觉预训练 (EViP) 和改进的 EViP++。

Result: Mono-InternVL 在 15 个基准测试中的 12 个上优于现有的单体 MLLM，Mono-InternVL-1.5 实现了类似的性能，同时显著降低了训练和推理成本。

Conclusion: Mono-InternVL 和 Mono-InternVL-1.5 在多个基准测试中表现出色，并在推理成本和延迟方面有所改进。

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [16] [Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows](https://arxiv.org/abs/2507.12590)
*Judy Long,Tao Liu,Sean Alexander Woznicki,Miljana Marković,Oskar Marko,Molly Sears*

Main category: cs.CV

TL;DR: 本研究回顾了大规模像素级作物mapping工作流程，发现Transformer模型和精细尺度预处理效果最佳，RF模型训练快，迁移学习提高了适应性。工作流选择取决于标签样本的可用性。


<details>
  <summary>Details</summary>
Motivation: 利用遥感图像进行大规模、像素级作物mapping是重要的。本研究旨在全面回顾现有方法，并确定最佳的监督和迁移学习工作流程。

Method: 系统实验，比较六种卫星图像预处理方法和十一种监督像素分类模型，评估不同训练样本大小和变量组合的协同影响，识别适用于不同领域迁移程度的最佳迁移学习技术。在五个农业地点评估最佳方法。Landsat 8是主要的卫星数据源，标签来自CDL置信像素和实地调查。

Result: 精细尺度预处理与Transformer模型结合效果最佳。RF模型训练速度快，性能有竞争力。UDA适用于同类作物类别，微调在不同场景中表现稳健。样本充足时，监督学习更准确，样本不足时，迁移学习是可行的替代方案。

Conclusion: Transformer模型和精细尺度预处理在监督和迁移学习中表现最佳。RF模型训练快，在监督学习和同类领域迁移中表现有竞争力。迁移学习提升了工作流的适应性，UDA适用于同类作物，微调适用于不同场景。工作流选择取决于标签样本的可用性；样本充足时，监督学习效果更好；样本不足时，迁移学习是可行的替代方案。

Abstract: Crop mapping involves identifying and classifying crop types using spatial
data, primarily derived from remote sensing imagery. This study presents the
first comprehensive review of large-scale, pixel-wise crop mapping workflows,
encompassing both conventional supervised methods and emerging transfer
learning approaches. To identify the optimal supervised crop mapping workflows,
we conducted systematic experiments, comparing six widely adopted satellite
image-based preprocessing methods, alongside eleven supervised pixel-wise
classification models. Additionally, we assessed the synergistic impact of
varied training sample sizes and variable combinations. Moreover, we identified
optimal transfer learning techniques for different magnitudes of domain shift.
The evaluation of best methods was conducted across five diverse agricultural
sites. Landsat 8 served as the primary satellite data source. Labels come from
CDL trusted pixels and field surveys.
  Our findings reveal three key insights. First, fine-scale interval
preprocessing paired with Transformer models consistently delivered optimal
performance for both supervised and transferable workflows. RF offered rapid
training and competitive performance in conventional supervised learning and
direct transfer to similar domains. Second, transfer learning techniques
enhanced workflow adaptability, with UDA being effective for homogeneous crop
classes while fine-tuning remains robust across diverse scenarios. Finally,
workflow choice depends heavily on the availability of labeled samples. With a
sufficient sample size, supervised training typically delivers more accurate
and generalizable results. Below a certain threshold, transfer learning that
matches the level of domain shift is a viable alternative to achieve crop
mapping. Repository:
Best-Practices-for-Large-Scale-Pixel-Wise-Crop-Mapping-and-Transfer-Learning-Workflows

</details>


### [17] [CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling](https://arxiv.org/abs/2507.12591)
*Trong-Thang Pham,Akash Awasthi,Saba Khan,Esteban Duran Marti,Tien-Phat Nguyen,Khoa Vo,Minh Tran,Ngoc Son Nguyen,Cuong Tran Van,Yuki Ikebe,Anh Totti Nguyen,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: This paper introduces CT-ScanGaze, a new CT eye-tracking dataset, and CT-Searcher, a 3D scanpath predictor for CT volumes. The model is pre-trained using converted 2D gaze data and shows promising results.


<details>
  <summary>Details</summary>
Motivation: Understanding radiologists' eye movement during Computed Tomography (CT) reading is crucial for developing effective interpretable computer-aided diagnosis systems. CT research in this area has been limited by the lack of publicly available eye-tracking datasets and the three-dimensional complexity of CT volumes.

Method: The authors introduce CT-Searcher, a novel 3D scanpath predictor designed specifically to process CT volumes and generate radiologist-like 3D fixation sequences. A pipeline converts existing 2D gaze datasets into 3D gaze data to pretrain CT-Searcher.

Result: The authors present CT-ScanGaze, the first publicly available eye gaze dataset on CT. Through both qualitative and quantitative evaluations on CT-ScanGaze, the authors demonstrate the effectiveness of their approach.

Conclusion: The study demonstrates the effectiveness of the proposed CT-Searcher and provides a comprehensive assessment framework for 3D scanpath prediction in medical imaging.

Abstract: Understanding radiologists' eye movement during Computed Tomography (CT)
reading is crucial for developing effective interpretable computer-aided
diagnosis systems. However, CT research in this area has been limited by the
lack of publicly available eye-tracking datasets and the three-dimensional
complexity of CT volumes. To address these challenges, we present the first
publicly available eye gaze dataset on CT, called CT-ScanGaze. Then, we
introduce CT-Searcher, a novel 3D scanpath predictor designed specifically to
process CT volumes and generate radiologist-like 3D fixation sequences,
overcoming the limitations of current scanpath predictors that only handle 2D
inputs. Since deep learning models benefit from a pretraining step, we develop
a pipeline that converts existing 2D gaze datasets into 3D gaze data to
pretrain CT-Searcher. Through both qualitative and quantitative evaluations on
CT-ScanGaze, we demonstrate the effectiveness of our approach and provide a
comprehensive assessment framework for 3D scanpath prediction in medical
imaging.

</details>


### [18] [MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification](https://arxiv.org/abs/2507.12602)
*Said Ohamouddou,Abdellatif El Afia,Hanaa El Afia,Raddouane Chiheb*

Main category: cs.CV

TL;DR: MS-DGCNN++ is a hierarchical multiscale fusion dynamic graph convolutional network that improves tree species classification and generalizes to standard 3D object recognition with competitive accuracy and reduced complexity.


<details>
  <summary>Details</summary>
Motivation: Existing approaches using multi-scale dynamic graph convolutional neural networks (MS-DGCNN) employ parallel multi-scale processing, which fails to capture the semantic relationships between the hierarchical levels of the tree architecture.

Method: A hierarchical multiscale fusion dynamic graph convolutional network that uses semantically meaningful feature extraction at local, branch, and canopy scales with cross-scale information propagation. It employs scale-specific feature engineering, including standard geometric features for the local scale, normalized relative vectors for the branch scale, and distance information for the canopy scale.

Result: MS-DGCNN++ achieved an accuracy of 94.96 % on STPCTLS, outperforming DGCNN, MS-DGCNN, and PPT. On FOR-species20K, it achieves 67.25% accuracy (6.1% improvement compared to MS-DGCNN). For standard 3D object recognition, it outperformed DGCNN and MS-DGCNN with overall accuracies of 93.15% on ModelNet40 and 94.05% on ModelNet10.

Conclusion: MS-DGCNN++ is a versatile solution for diverse point cloud processing applications, generalizing beyond tree classification to standard 3D object recognition.

Abstract: Tree species classification from terrestrial LiDAR point clouds is
challenging because of the complex multi-scale geometric structures in forest
environments. Existing approaches using multi-scale dynamic graph convolutional
neural networks (MS-DGCNN) employ parallel multi-scale processing, which fails
to capture the semantic relationships between the hierarchical levels of the
tree architecture. We present MS-DGCNN++, a hierarchical multiscale fusion
dynamic graph convolutional network that uses semantically meaningful feature
extraction at local, branch, and canopy scales with cross-scale information
propagation. Our method employs scale-specific feature engineering, including
standard geometric features for the local scale, normalized relative vectors
for the branch scale, and distance information for the canopy scale. This
hierarchical approach replaces uniform parallel processing with semantically
differentiated representations that are aligned with the natural tree
structure. Under the same proposed tree species data augmentation strategy for
all experiments, MS-DGCNN++ achieved an accuracy of 94.96 \% on STPCTLS,
outperforming DGCNN, MS-DGCNN, and the state-of-the-art model PPT. On
FOR-species20K, it achieves 67.25\% accuracy (6.1\% improvement compared to
MS-DGCNN). For standard 3D object recognition, our method outperformed DGCNN
and MS-DGCNN with overall accuracies of 93.15\% on ModelNet40 and 94.05\% on
ModelNet10. With lower parameters and reduced complexity compared to
state-of-the-art transformer approaches, our method is suitable for
resource-constrained applications while maintaining a competitive accuracy.
Beyond tree classification, the method generalizes to standard 3D object
recognition, establishing it as a versatile solution for diverse point cloud
processing applications. The implementation code is publicly available at
https://github.com/said-ohamouddou/MS-DGCNN2.

</details>


### [19] [Predicting Soccer Penalty Kick Direction Using Human Action Recognition](https://arxiv.org/abs/2507.12617)
*David Freire-Obregón,Oliverio J. Santana,Javier Lorenzo-Navarro,Daniel Hernández-Sosa,Modesto Castrillón-Santana*

Main category: cs.CV

TL;DR: A novel dataset of soccer penalty kicks is presented to predict shot direction based on pre-kick player movements. A deep learning classifier is proposed to benchmark this dataset, achieving up to 63.9% accuracy, outperforming real goalkeepers' decisions.


<details>
  <summary>Details</summary>
Motivation: The application of action anticipation to real-world sports scenarios remains limited by the availability of suitable annotated datasets.

Method: A deep learning classifier is proposed to benchmark this dataset that integrates HAR-based feature embeddings with contextual metadata. Twenty-two backbone models across seven architecture families (MViTv2, MViTv1, SlowFast, Slow, X3D, I3D, C2D) are evaluated.

Result: Up to 63.9% accuracy is achieved in predicting shot direction (left or right), outperforming the real goalkeepers' decisions.

Conclusion: The dataset's value for anticipatory action recognition is demonstrated, and the model's potential as a generalizable approach for sports-based predictive tasks is validated.

Abstract: Action anticipation has become a prominent topic in Human Action Recognition
(HAR). However, its application to real-world sports scenarios remains limited
by the availability of suitable annotated datasets. This work presents a novel
dataset of manually annotated soccer penalty kicks to predict shot direction
based on pre-kick player movements. We propose a deep learning classifier to
benchmark this dataset that integrates HAR-based feature embeddings with
contextual metadata. We evaluate twenty-two backbone models across seven
architecture families (MViTv2, MViTv1, SlowFast, Slow, X3D, I3D, C2D),
achieving up to 63.9% accuracy in predicting shot direction (left or right),
outperforming the real goalkeepers' decisions. These results demonstrate the
dataset's value for anticipatory action recognition and validate our model's
potential as a generalizable approach for sports-based predictive tasks.

</details>


### [20] [Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection](https://arxiv.org/abs/2507.12628)
*Sandipan Sarma,Agney Talwarr,Arijit Sur*

Main category: cs.CV

TL;DR: This paper introduces Funnel-HOI, a new framework for human-object interaction detection that uses a top-down approach and a novel co-attention mechanism to improve scene interpretation at the encoder level. It achieves state-of-the-art results, especially in zero-shot settings.


<details>
  <summary>Details</summary>
Motivation: Since there could be an exponential number of object-action combinations, labeled data is limited - leading to a long-tail distribution problem. Recently, zero-shot learning emerged as a solution, with end-to-end transformer-based object detectors adapted for HOID becoming successful frameworks. However, their primary focus is designing improved decoders for learning entangled or disentangled interpretations of interactions. We advocate that HOI-specific cues must be anticipated at the encoder stage itself to obtain a stronger scene interpretation.

Method: a top-down framework named Funnel-HOI inspired by the human tendency to grasp well-defined concepts first and then associate them with abstract concepts during scene understanding. We first probe an image for the presence of objects (well-defined concepts) and then probe for actions (abstract concepts) associated with them. A novel asymmetric co-attention mechanism mines these cues utilizing multimodal information (incorporating zero-shot capabilities) and yields stronger interaction representations at the encoder level. Furthermore, a novel loss is devised that considers objectaction relatedness and regulates misclassification penalty better than existing loss functions for guiding the interaction classifier.

Result: state-of-the-art performance, with up to 12.4% and 8.4% gains for unseen and rare HOI categories, respectively.

Conclusion: Extensive experiments on the HICO-DET and V-COCO datasets across fully-supervised and six zero-shot settings reveal our state-of-the-art performance, with up to 12.4% and 8.4% gains for unseen and rare HOI categories, respectively.

Abstract: Human-object interaction detection (HOID) refers to localizing interactive
human-object pairs in images and identifying the interactions. Since there
could be an exponential number of object-action combinations, labeled data is
limited - leading to a long-tail distribution problem. Recently, zero-shot
learning emerged as a solution, with end-to-end transformer-based object
detectors adapted for HOID becoming successful frameworks. However, their
primary focus is designing improved decoders for learning entangled or
disentangled interpretations of interactions. We advocate that HOI-specific
cues must be anticipated at the encoder stage itself to obtain a stronger scene
interpretation. Consequently, we build a top-down framework named Funnel-HOI
inspired by the human tendency to grasp well-defined concepts first and then
associate them with abstract concepts during scene understanding. We first
probe an image for the presence of objects (well-defined concepts) and then
probe for actions (abstract concepts) associated with them. A novel asymmetric
co-attention mechanism mines these cues utilizing multimodal information
(incorporating zero-shot capabilities) and yields stronger interaction
representations at the encoder level. Furthermore, a novel loss is devised that
considers objectaction relatedness and regulates misclassification penalty
better than existing loss functions for guiding the interaction classifier.
Extensive experiments on the HICO-DET and V-COCO datasets across
fully-supervised and six zero-shot settings reveal our state-of-the-art
performance, with up to 12.4% and 8.4% gains for unseen and rare HOI
categories, respectively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [21] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences?


<details>
  <summary>Details</summary>
Motivation: current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped.

Method: We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes.

Result: This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises.

Conclusion: This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [22] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: This paper improves highway merge simulation by using a game theoretic model for tactical decision-making with improved payoff functions and lag actions. The model is validated on real-world data and integrated into a high-fidelity simulation environment for autonomous vehicle development.


<details>
  <summary>Details</summary>
Motivation: Enhancing simulation environments to replicate real-world driver behavior is essential for developing autonomous vehicle technology. Previous works have limitations in action sets or utilize payoff functions with large parameter sets and limited payoff bounds.

Method: a game theoretic model for tactical decision-making with improved payoff functions and lag actions coupled with an underlying dynamics model

Result: The model was integrated into a high fidelity simulation environment.

Conclusion: The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [23] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: This paper proposes a taxonomy for XRL, reviews 250+ papers, and identifies future needs in the field.


<details>
  <summary>Details</summary>
Motivation: The opacity of AI models' internal mechanisms, especially deep neural networks, motivates the need for eXplainable AI (XAI), specifically eXplainable Reinforcement Learning (XRL).

Method: The authors propose a taxonomy based on "What" and "How" questions to review XRL papers.

Result: The authors review over 250 papers using their taxonomy and present related domains.

Conclusion: This paper identifies needs for the field of XRL.

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [24] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 我们提出了一个自动设计迭代框架，该框架通过将强化学习（RL）agent（负责游戏测试）与大型多模态模型（LMM）（负责修改游戏）配对，从而弥补了静态规则和内容转化为动态玩家行为的差距。


<details>
  <summary>Details</summary>
Motivation: 现代生成系统只能检查游戏的代码或资源，难以捕捉静态规则和内容如何转化为动态玩家行为。

Method: 结合强化学习（RL）agent（负责游戏测试）和一个大型多模态模型（LMM）（负责根据agent的行为修改游戏）。

Result: LMMs可以通过RL agent提供的行为轨迹进行推理，迭代地改进游戏机制。

Conclusion: LMMs可以基于RL agent的行为轨迹进行推理，迭代地改进游戏机制，为AI辅助游戏设计提供可扩展的工具。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [25] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: The paper analyzes the effectiveness and robustness of deception probes in detecting deceptive AI responses, finding weak but encouraging results.


<details>
  <summary>Details</summary>
Motivation: AI assistants will occasionally respond deceptively to user queries. It's unclear how effective deception probes are at detecting deception in practice, or whether they are resistant to simple counter strategies.

Method: Compare white-box monitoring (with token-level probe activations) to black-box monitoring (without such access). Benchmark deception probes by the extent to which the white box monitor outperforms the black-box monitor (black-to-white performance boost).

Result: Find weak but encouraging black-to-white performance boosts from existing deception probes.

Conclusion: Existing deception probes show weak but encouraging black-to-white performance boosts.

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [26] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: This study develops an AI peer for English composition, assuming similar learners make similar mistakes, to enable effective peer learning anytime and anywhere.


<details>
  <summary>Details</summary>
Motivation: Peer learning promotes spontaneous thinking, but human peer learning has limitations, requiring companions at the same proficiency levels. The study aims to create an AI agent to enable peer learning anytime and anywhere.

Method: Development of an AI Agent as a learning companion focusing on English composition.

Result: The study validates the approach.

Conclusion: This study validates the approach of using AI agents as learning companions in English composition, assuming learners with similar proficiency make similar mistakes.

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [27] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval automates end-to-end task generation and deep evaluation of LLM agents across diverse domains, standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines.


<details>
  <summary>Details</summary>
Motivation: The rapid rise of Large Language Models (LLMs)-based intelligent agents underscores the need for robust, scalable evaluation frameworks. Existing methods rely on static benchmarks and labor-intensive data collection, limiting practical assessment.

Method: an open-source Model Context Protocol (MCP)-based framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains

Result: Empirical results across five real-world domains show its effectiveness in revealing nuanced, domain-specific performance.

Conclusion: MCPEval is effective in revealing nuanced, domain-specific performance.

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [28] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: This paper explores using LLMs with prompt engineering and finetuning for emotional support conversations, achieving second place in a competition.


<details>
  <summary>Details</summary>
Motivation: Addresses the growing demand for mental health support through dialogue by providing empathetic and effective emotional assistance.

Method: The authors leverage large-scale language models enhanced by prompt engineering and finetuning techniques, exploring both parameter-efficient Low-Rank Adaptation and full-parameter fine-tuning.

Result: The study highlights the potential of combining LLMs with effective adaptation methods for ESC tasks.

Conclusion: The paper's best model ranked second in the NLPCC 2025 Task 8 ESC competition, demonstrating the potential of combining LLMs with adaptation methods for ESC tasks.

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [29] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: The paper proposes a new evaluation framework using 'novel games' to test AI's ability to quickly learn and adapt world models, mimicking human intelligence.


<details>
  <summary>Details</summary>
Motivation: Current AI world models lack the rapid adaptation seen in human intelligence, which relies on efficient internal representations (world models).

Method: The paper proposes a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures.

Result: The paper details key desiderata for constructing these games and proposes appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction.

Conclusion: This paper advocates for a new evaluation framework for AI world models, using novel games to assess their ability for rapid world model induction, aiming for human-like adaptation and generalization.

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [30] [Transforming Football Data into Object-centric Event Logs with Spatial Context Information](https://arxiv.org/abs/2507.12504)
*Vito Chan,Lennart Ebert,Paul-Julius Hillmann,Christoffer Rubensson,Stephan A. Fahrenkrog-Petersen,Jan Mendling*

Main category: cs.DB

TL;DR: This paper introduces a framework for transforming football data into object-centric event logs, providing a real-world example and demonstrating its effectiveness. 


<details>
  <summary>Details</summary>
Motivation: The number of real-world object-centric event logs remains limited, and further studies are needed to test their usefulness. The increasing availability of data from team sports can facilitate object-centric process mining, leveraging both real-world data and suitable use cases.

Method: The paper presents a framework for transforming football (soccer) data into an object-centric event log, further enhanced with a spatial dimension.

Result: The paper demonstrates the effectiveness of the framework by generating object-centric event logs based on real-world football data and discusses the results for varying process representations.

Conclusion: The paper provides the first example for object-centric event logs in football analytics. Future work should consider variant analysis and filtering techniques to better handle variability.

Abstract: Object-centric event logs expand the conventional single-case notion event
log by considering multiple objects, allowing for the analysis of more complex
and realistic process behavior. However, the number of real-world
object-centric event logs remains limited, and further studies are needed to
test their usefulness. The increasing availability of data from team sports can
facilitate object-centric process mining, leveraging both real-world data and
suitable use cases. In this paper, we present a framework for transforming
football (soccer) data into an object-centric event log, further enhanced with
a spatial dimension. We demonstrate the effectiveness of our framework by
generating object-centric event logs based on real-world football data and
discuss the results for varying process representations. With our paper, we
provide the first example for object-centric event logs in football analytics.
Future work should consider variant analysis and filtering techniques to better
handle variability

</details>


### [31] [Rel-HNN: Split Parallel Hypergraph Neural Network for Learning on Relational Databases](https://arxiv.org/abs/2507.12562)
*Md. Tanvir Alam,Md. Ahasanul Alam,Md Mahmudur Rahman,Md. Mosaddek Khan*

Main category: cs.DB

TL;DR: 提出rel-HNN模型，使用超图建模关系数据库，并使用split-parallel训练加速。


<details>
  <summary>Details</summary>
Motivation: 关系数据库中的关系语义难以被传统的深度学习模型捕获，现有的图神经网络又过度简化了关系结构。

Method: 提出了一种新的基于超图的框架rel-HNN，它将每个唯一的属性-值对建模为一个节点，并将每个元组建模为一个超边。

Result: rel-HNN在真实世界和基准数据集上显著优于现有方法，split-parallel训练实现了高达3.18x的加速。

Conclusion: rel-HNN在分类和回归任务中显著优于现有方法，并且split-parallel训练实现了显著加速。

Abstract: Relational databases (RDBs) are ubiquitous in enterprise and real-world
applications. Flattening the database poses challenges for deep learning models
that rely on fixed-size input representations to capture relational semantics
from the structured nature of relational data. Graph neural networks (GNNs)
have been proposed to address this, but they often oversimplify relational
structures by modeling all the tuples as monolithic nodes and ignoring
intra-tuple associations. In this work, we propose a novel hypergraph-based
framework, that we call rel-HNN, which models each unique attribute-value pair
as a node and each tuple as a hyperedge, enabling the capture of fine-grained
intra-tuple relationships. Our approach learns explicit multi-level
representations across attribute-value, tuple, and table levels. To address the
scalability challenges posed by large RDBs, we further introduce a
split-parallel training algorithm that leverages multi-GPU execution for
efficient hypergraph learning. Extensive experiments on real-world and
benchmark datasets demonstrate that rel-HNN significantly outperforms existing
methods in both classification and regression tasks. Moreover, our
split-parallel training achieves substantial speedups -- up to 3.18x for
learning on relational data and up to 2.94x for hypergraph learning -- compared
to conventional single-GPU execution.

</details>


### [32] [Targeted Mining of Time-Interval Related Patterns](https://arxiv.org/abs/2507.12668)
*Shuang Liang,Lili Chen,Wensheng Gan,Philip S. Yu,Shengjie Zhao*

Main category: cs.DB

TL;DR: This paper introduces TaTIRP, a novel algorithm for targeted time-interval-related pattern mining, enhancing efficiency and accuracy on large datasets.


<details>
  <summary>Details</summary>
Motivation: Numerous studies treat temporal events as single time points, neglecting their durations. Mining all patterns is computationally challenging and resource-intensive. Targeting the extraction of time-interval-related patterns based on specific criteria can improve data analysis efficiency and better align with customer preferences.

Method: The paper proposes a novel algorithm called TaTIRP to discover Targeted Time-Interval Related Patterns and develops multiple pruning strategies to eliminate redundant extension operations.

Result: The proposed TaTIRP algorithm enhances performance on large-scale datasets by eliminating redundant extension operations.

Conclusion: The paper validates the accuracy and efficiency of the proposed TaTIRP algorithm through experiments on real-world and synthetic datasets.

Abstract: Compared to frequent pattern mining, sequential pattern mining emphasizes the
temporal aspect and finds broad applications across various fields. However,
numerous studies treat temporal events as single time points, neglecting their
durations. Time-interval-related pattern (TIRP) mining is introduced to address
this issue and has been applied to healthcare analytics, stock prediction, etc.
Typically, mining all patterns is not only computationally challenging for
accurate forecasting but also resource-intensive in terms of time and memory.
Targeting the extraction of time-interval-related patterns based on specific
criteria can improve data analysis efficiency and better align with customer
preferences. Therefore, this paper proposes a novel algorithm called TaTIRP to
discover Targeted Time-Interval Related Patterns. Additionally, we develop
multiple pruning strategies to eliminate redundant extension operations,
thereby enhancing performance on large-scale datasets. Finally, we conduct
experiments on various real-world and synthetic datasets to validate the
accuracy and efficiency of the proposed algorithm.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [33] [Bridging the Gap: Leveraging Retrieval-Augmented Generation to Better Understand Public Concerns about Vaccines](https://arxiv.org/abs/2507.12840)
*Muhammad Javed,Sedigh Khademi Habibabadi,Christopher Palmer,Hazel Clothier,Jim Buttery,Gerardo Luis Dimaguila*

Main category: cs.IR

TL;DR: Developed VaxPulse Query Corner using Retrieval Augmented Generation to address complex vaccine concern queries on social media, achieving high faithfulness and relevance in analysis.


<details>
  <summary>Details</summary>
Motivation: Traditional methods struggle to capture nuanced opinions on social media, and Large Language Models (LLMs) often miss current events and community concerns, with hallucinations compromising public health communication.

Method: Retrieval Augmented Generation technique

Result: Analysing 35,103 Shingrix social media posts, the tool achieved answer faithfulness (0.96) and relevance (0.94).

Conclusion: VaxPulse Query Corner, a tool using Retrieval Augmented Generation, effectively addresses complex queries about public vaccine concerns on social media, achieving high answer faithfulness and relevance.

Abstract: Vaccine hesitancy threatens public health, leading to delayed or rejected
vaccines. Social media is a vital source for understanding public concerns, and
traditional methods like topic modelling often struggle to capture nuanced
opinions. Though trained for query answering, large Language Models (LLMs)
often miss current events and community concerns. Additionally, hallucinations
in LLMs can compromise public health communication. To address these
limitations, we developed a tool (VaxPulse Query Corner) using the Retrieval
Augmented Generation technique. It addresses complex queries about public
vaccine concerns on various online platforms, aiding public health
administrators and stakeholders in understanding public concerns and
implementing targeted interventions to boost vaccine confidence. Analysing
35,103 Shingrix social media posts, it achieved answer faithfulness (0.96) and
relevance (0.94).

</details>


### [34] [Machine-Readable Ads: Accessibility and Trust Patterns for AI Web Agents interacting with Online Advertisements](https://arxiv.org/abs/2507.12844)
*Joel Nitu,Heidrun Mühle,Andreas Stöckl*

Main category: cs.IR

TL;DR: Autonomous agents readily subscribe to services and ignore visual cues in ads, highlighting the need for better design and trust evaluation.


<details>
  <summary>Details</summary>
Motivation: Little is known about how autonomous multimodal language model agents interact with ads or which design principles ensure reliable engagement, posing a threat to display advertising.

Method: Controlled experiment using a faithful clone of the news site TT.com, seeded with diverse ads, and the Document Object Model (DOM)-centric Browser Use framework with GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash, and the pixel-based OpenAI Operator, across 10 realistic user tasks.

Result: Agents display severe satisficing, never scrolling beyond two viewports and ignoring purely visual calls to action. GPT-4o and Claude 3.7 Sonnet subscribed in 100% of trials when sweepstake participation required a purchase, and Gemini 2.0 Flash in 70%. Five actionable design principles were identified.

Conclusion: Autonomous multimodal language models exhibit satisficing behavior, ignoring visual cues and readily making purchases, revealing vulnerabilities in cost-benefit analysis. The paper identifies actionable design principles for machine-detectable ads and evaluates agent trustworthiness, highlighting the need for robust trust evaluation frameworks.

Abstract: Autonomous multimodal language models are rapidly evolving into web agents
that can browse, click, and purchase items on behalf of users, posing a threat
to display advertising designed for human eyes. Yet little is known about how
these agents interact with ads or which design principles ensure reliable
engagement. To address this, we ran a controlled experiment using a faithful
clone of the news site TT.com, seeded with diverse ads: static banners, GIFs,
carousels, videos, cookie dialogues, and paywalls. We ran 300 initial trials
plus follow-ups using the Document Object Model (DOM)-centric Browser Use
framework with GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash, and the pixel-based
OpenAI Operator, across 10 realistic user tasks. Our results show these agents
display severe satisficing: they never scroll beyond two viewports and ignore
purely visual calls to action, clicking banners only when semantic button
overlays or off-screen text labels are present. Critically, when sweepstake
participation required a purchase, GPT-4o and Claude 3.7 Sonnet subscribed in
100% of trials, and Gemini 2.0 Flash in 70%, revealing gaps in cost-benefit
analysis. We identified five actionable design principles-semantic overlays,
hidden labels, top-left placement, static frames, and dialogue replacement,
that make human-centric creatives machine-detectable without harming user
experience. We also evaluated agent trustworthiness through "behavior patterns"
such as cookie consent handling and subscription choices, highlighting
model-specific risk boundaries and the urgent need for robust trust evaluation
frameworks in real-world advertising.

</details>


### [35] [Generative Multi-Target Cross-Domain Recommendation](https://arxiv.org/abs/2507.12871)
*Jinqiu Jin,Yang Zhang,Junwei Pan,Fuli Feng,Hua Lu,Haijie Gu,Xiangnan He*

Main category: cs.IR

TL;DR: GMC is a generative approach for multi-target cross-domain recommendation that uses semantically quantized discrete item identifiers to integrate multi-domain knowledge. It outperforms baselines on five public datasets.


<details>
  <summary>Details</summary>
Motivation: Existing MTCDR methods primarily rely on domain-shared entities, which may be unavailable in non-overlapped recommendation scenarios. Some studies require extensive auxiliary data for pre-training. Developing more effective solutions for MTCDR remains an important area for further exploration.

Method: GMC leverages semantically quantized discrete item identifiers as a medium for integrating multi-domain knowledge within a unified generative model. It employs an item tokenizer to generate domain-shared semantic identifiers and formulates item recommendation as a next-token generation task. A domain-aware contrastive loss is incorporated, and domain-specific fine-tuning is performed.

Result: GMC, a generative paradigm-based approach for multi-target cross-domain recommendation, is effective.

Conclusion: Extensive experiments on five public datasets demonstrate the effectiveness of GMC compared to a range of baseline methods.

Abstract: Recently, there has been a surge of interest in Multi-Target Cross-Domain
Recommendation (MTCDR), which aims to enhance recommendation performance across
multiple domains simultaneously. Existing MTCDR methods primarily rely on
domain-shared entities (\eg users or items) to fuse and transfer cross-domain
knowledge, which may be unavailable in non-overlapped recommendation scenarios.
Some studies model user preferences and item features as domain-sharable
semantic representations, which can be utilized to tackle the MTCDR task.
Nevertheless, they often require extensive auxiliary data for pre-training.
Developing more effective solutions for MTCDR remains an important area for
further exploration.
  Inspired by recent advancements in generative recommendation, this paper
introduces GMC, a generative paradigm-based approach for multi-target
cross-domain recommendation. The core idea of GMC is to leverage semantically
quantized discrete item identifiers as a medium for integrating multi-domain
knowledge within a unified generative model. GMC first employs an item
tokenizer to generate domain-shared semantic identifiers for each item, and
then formulates item recommendation as a next-token generation task by training
a domain-unified sequence-to-sequence model. To further leverage the domain
information to enhance performance, we incorporate a domain-aware contrastive
loss into the semantic identifier learning, and perform domain-specific
fine-tuning on the unified recommender. Extensive experiments on five public
datasets demonstrate the effectiveness of GMC compared to a range of baseline
methods.

</details>


### [36] [SGCL: Unifying Self-Supervised and Supervised Learning for Graph Recommendation](https://arxiv.org/abs/2507.13336)
*Weizhi Zhang,Liangwei Yang,Zihe Song,Henrry Peng Zou,Ke Xu,Yuanjie Zhu,Philip S. Yu*

Main category: cs.IR

TL;DR: SGCL结合了推荐和无监督对比损失的训练，优于当前方法，同时实现了卓越的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 自我监督图学习旨在通过用户-项目二分图上的无监督增强来利用高阶协同过滤信号，主要利用包括监督推荐损失和自我监督对比损失的多任务学习框架。然而，这种分离的设计引入了额外的图卷积过程，并由于不同的损失而导致梯度方向的不一致，从而导致训练时间延长和性能欠佳。

Method: SGCL将推荐和无监督对比损失的训练独特地结合到一个有凝聚力的监督对比学习损失中，从而在单个优化方向上对齐了这两个任务，从而实现了非常快速的训练。

Result: SGCL优于最先进的方法，实现了卓越的准确性和效率。

Conclusion: SGCL在三个真实世界数据集上进行了广泛的实验，表明其优于最先进的方法，实现了卓越的准确性和效率。

Abstract: Recommender systems (RecSys) are essential for online platforms, providing
personalized suggestions to users within a vast sea of information.
Self-supervised graph learning seeks to harness high-order collaborative
filtering signals through unsupervised augmentation on the user-item bipartite
graph, primarily leveraging a multi-task learning framework that includes both
supervised recommendation loss and self-supervised contrastive loss. However,
this separate design introduces additional graph convolution processes and
creates inconsistencies in gradient directions due to disparate losses,
resulting in prolonged training times and sub-optimal performance. In this
study, we introduce a unified framework of Supervised Graph Contrastive
Learning for recommendation (SGCL) to address these issues. SGCL uniquely
combines the training of recommendation and unsupervised contrastive losses
into a cohesive supervised contrastive learning loss, aligning both tasks
within a single optimization direction for exceptionally fast training.
Extensive experiments on three real-world datasets show that SGCL outperforms
state-of-the-art methods, achieving superior accuracy and efficiency.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: Propose PMKLC, a parallel multi-knowledge learning-based compressor, to improve compression ratio, throughput, and robustness for genomic data.


<details>
  <summary>Details</summary>
Motivation: inadequate compression ratio, low compression & decompression throughput, and poor compression robustness limit their widespread adoption

Method: novel Parallel Multi-Knowledge Learning-based Compressor (PMKLC) with four crucial designs: 1) automated multi-knowledge learning-based compression framework; 2) GPU-accelerated ($s$,$k$)-mer encoder; 3) data block partitioning and Step-wise Model Passing (SMP) mechanisms; 4) two compression modes PMKLC-S and PMKLC-M

Result: PMKLC-S/M achieve the average compression ratio improvement up to 73.609% and 73.480%, the average throughput improvement up to 3.036x and 10.710x, respectively

Conclusion: PMKLC-S/M achieves the best robustness and competitive memory cost, indicating its greater stability against datasets with different probability distribution perturbations, and its strong ability to run on memory-constrained devices.

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [38] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 通过长期强化学习，小型语言模型在数学、编程和逻辑谜题任务上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 通过思维链推理和迭代探索来扩展测试时计算可以显著改进复杂任务，例如数学和代码生成。

Method: 使用可验证奖励任务、改进的 Group Relative Policy Optimization (GRPO) 以及提高训练稳定性和泛化能力的实用技术。

Result: 该模型在各种推理领域都取得了显著的改进，并且公开了该模型以促进持续研究。

Conclusion: 该模型在数学、编程和逻辑谜题任务上取得了显著改进，分别提高了 +14.7%、+13.9% 和 +54.8%。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [39] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
*Yuxi Liu,Konpat Preechakul,Kananart Kuwaranancharoen,Yutong Bai*

Main category: cs.LG

TL;DR: 大规模并行化促进了机器学习的发展，但某些问题本质上是顺序的，当前的并行架构在这些问题上面临根本限制。


<details>
  <summary>Details</summary>
Motivation: 当前以并行计算为中心的架构在处理需要依赖计算步骤的问题（从数学推理到物理模拟再到顺序决策）时面临根本限制。

Method: 从复杂性理论中得出

Result: 证实了当前以并行计算为中心的架构在处理此类任务时面临根本限制。

Conclusion: 扩展串行计算对于人工智能的持续发展至关重要。

Abstract: While machine learning has advanced through massive parallelization, we
identify a critical blind spot: some problems are fundamentally sequential.
These "inherently serial" problems-from mathematical reasoning to physical
simulations to sequential decision-making-require dependent computational steps
that cannot be parallelized. Drawing from complexity theory, we formalize this
distinction and demonstrate that current parallel-centric architectures face
fundamental limitations on such tasks. We argue that recognizing the serial
nature of computation holds profound implications on machine learning, model
design, hardware development. As AI tackles increasingly complex reasoning,
deliberately scaling serial computation-not just parallel computation-is
essential for continued progress.

</details>


### [40] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
*Slimane Larabi*

Main category: cs.LG

TL;DR: This paper introduces a machine thinking framework that uses mental imagery to enhance autonomous reasoning and decision-making in AI agents.


<details>
  <summary>Details</summary>
Motivation: Existing models lack autonomous action and independent reasoning, struggling to integrate knowledge across domains, unlike humans who use mental imagery.

Method: The proposed framework integrates a Cognitive thinking unit with Input Data, Needs, and Mental Imagery Units. Data is represented as natural language or sketches.

Result: Validation tests for the proposed framework are conducted, and the results are presented and discussed.

Conclusion: This paper proposes and validates a machine thinking framework integrating mental imagery to improve autonomous reasoning and decision-making.

Abstract: Although existing models can interact with humans and provide satisfactory
responses, they lack the ability to act autonomously or engage in independent
reasoning. Furthermore, input data in these models is typically provided as
explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform
tasks and make decisions autonomously based on their programming, data inputs,
and learned knowledge, have shown significant progress. However, they struggle
with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process,
which involves performing tasks based on internal multisensory data, planned
actions, needs, and reasoning capabilities. In this paper, we investigate how
to integrate mental imagery into a machine thinking framework and how this
could be beneficial in initiating the thinking process. Our proposed machine
thinking framework integrates a Cognitive thinking unit supported by three
auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery
Unit. Within this framework, data is represented as natural language sentences
or drawn sketches, serving both informative and decision-making purposes. We
conducted validation tests for this framework, and the results are presented
and discussed.

</details>


### [41] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
*Eduardo V. L. Barboza,Paulo R. Lisboa de Almeida,Alceu de Souza Britto Jr.,Robert Sabourin,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: This paper introduces IncA-DES, a framework for handling concept drift in data streams. It combines local expert training, concept drift detection, and an Online K-d tree for efficient processing. Results show improved accuracy and speed compared to existing methods.


<details>
  <summary>Details</summary>
Motivation: Concept drift in data streams poses challenges for batch-based ML. Distance-based (DS) methods are suitable for drifting scenarios but need adaptation for concept drift and efficient neighborhood search.

Method: The paper proposes IncA-DES, which uses a training strategy for local expert generation, a concept drift detector for maintenance and adaptation, and an overlap-based classification filter. It also introduces an Online K-d tree algorithm for faster kNN processing.

Result: Experimental results demonstrate that IncA-DES achieves the best average accuracy compared to seven state-of-the-art methods and presents smaller processing time among the most accurate methods. The Online K-d tree improves processing time with negligible accuracy loss.

Conclusion: The proposed framework, IncA-DES, achieves high accuracy and efficient processing time compared to state-of-the-art methods. The fusion with the Online K-d tree further improves processing time with minimal accuracy loss. The framework is available in an online repository.

Abstract: Data streams pose challenges not usually encountered in batch-based ML. One
of them is concept drift, which is characterized by the change in data
distribution over time. Among many approaches explored in literature, the
fusion of classifiers has been showing good results and is getting growing
attention. DS methods, due to the ensemble being instance-based, seem to be an
efficient choice under drifting scenarios. However, some attention must be paid
to adapting such methods for concept drift. The training must be done in order
to create local experts, and the commonly used neighborhood-search DS may
become prohibitive with the continuous arrival of data. In this work, we
propose IncA-DES, which employs a training strategy that promotes the
generation of local experts with the assumption that different regions of the
feature space become available with time. Additionally, the fusion of a concept
drift detector supports the maintenance of information and adaptation to a new
concept. An overlap-based classification filter is also employed in order to
avoid using the DS method when there is a consensus in the neighborhood, a
strategy that we argue every DS method should employ, as it was shown to make
them more applicable and quicker. Moreover, aiming to reduce the processing
time of the kNN, we propose an Online K-d tree algorithm, which can quickly
remove instances without becoming inconsistent and deals with unbalancing
concerns that may occur in data streams. Experimental results showed that the
proposed framework got the best average accuracy compared to seven
state-of-the-art methods considering different levels of label availability and
presented the smaller processing time between the most accurate methods.
Additionally, the fusion with the Online K-d tree has improved processing time
with a negligible loss in accuracy. We have made our framework available in an
online repository.

</details>


### [42] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
*Xiangyi Chen,Kousik Rajesh,Matthew Lawhon,Zelun Wang,Hanyu Li,Haomiao Li,Saurabh Vishwas Joshi,Pong Eksombatchai,Jaewon Yang,Yi-Ping Hsu,Jiajing Xu,Charles Rosenberg*

Main category: cs.LG

TL;DR: PinFM, a foundational model for user activity sequences, overcomes challenges in industrial recommender systems, improving throughput and engagement.


<details>
  <summary>Details</summary>
Motivation: Understanding user activity sequences is important for recommender systems, but applying pretraining-and-fine-tuning in industrial recommender systems has challenges like scalability, capturing interactions, and handling new items.

Method: Pretrains a transformer model and fine-tunes it for specific applications, using Deduplicated Cross-Attention Transformer (DCAT).

Result: DCAT improves throughput by 600%; PinFM increases engagement with new items by 20%.

Conclusion: PinFM is deployed to improve user experience across applications.

Abstract: User activity sequences have emerged as one of the most important signals in
recommender systems. We present a foundational model, PinFM, for understanding
user activity sequences across multiple applications at a billion-scale visual
discovery platform. We pretrain a transformer model with 20B+ parameters using
extensive user activity data, then fine-tune it for specific applications,
efficiently coupling it with existing models. While this
pretraining-and-fine-tuning approach has been popular in other domains, such as
Vision and NLP, its application in industrial recommender systems presents
numerous challenges. The foundational model must be scalable enough to score
millions of items every second while meeting tight cost and latency constraints
imposed by these systems. Additionally, it should capture the interactions
between user activities and other features and handle new items that were not
present during the pretraining stage.
  We developed innovative techniques to address these challenges. Our
infrastructure and algorithmic optimizations, such as the Deduplicated
Cross-Attention Transformer (DCAT), improved our throughput by 600% on
Pinterest internal data. We demonstrate that PinFM can learn interactions
between user sequences and candidate items by altering input sequences, leading
to a 20% increase in engagement with new items. PinFM is now deployed to help
improve the experience of more than a half billion users across various
applications.

</details>


### [43] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
*Yifan Deng,Spencer S. Ericksen,Anthony Gitter*

Main category: cs.LG

TL;DR: Assay2Mol, a large language model, leverages biochemical screening assays for early-stage drug discovery, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Unstructured text in biochemical screening assays offers rich information for new drug discovery but has been untapped.

Method: A large language model-based workflow that uses in-context learning with retrieved assay screening data.

Result: Assay2Mol can capitalize on biochemical screening assays for early-stage drug discovery by retrieving existing assay records and generating candidate molecules.

Conclusion: Assay2Mol outperforms existing machine learning approaches in generating candidate ligand molecules and promotes more synthesizable molecule generation.

Abstract: Scientific databases aggregate vast amounts of quantitative data alongside
descriptive text. In biochemistry, molecule screening assays evaluate the
functional responses of candidate molecules against disease targets.
Unstructured text that describes the biological mechanisms through which these
targets operate, experimental screening protocols, and other attributes of
assays offer rich information for new drug discovery campaigns but has been
untapped because of that unstructured format. We present Assay2Mol, a large
language model-based workflow that can capitalize on the vast existing
biochemical screening assays for early-stage drug discovery. Assay2Mol
retrieves existing assay records involving targets similar to the new target
and generates candidate molecules using in-context learning with the retrieved
assay screening data. Assay2Mol outperforms recent machine learning approaches
that generate candidate ligand molecules for target protein structures, while
also promoting more synthesizable molecule generation.

</details>


### [44] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
*Ali Fattahi,Ali Eshragh,Babak Aslani,Meysam Rabiee*

Main category: cs.LG

TL;DR: 研究了聚类排序向量的问题，提出了KRCA算法，该算法优于基线解决方案，在快速计算时间内显着提高了解决方案质量。


<details>
  <summary>Details</summary>
Motivation: 研究聚类排序向量的问题，其中每个向量表示偏好为不同整数的有序列表。具体来说，我们关注 k-中心点排序向量聚类问题 （KRC），该问题旨在将一组排序向量划分为 k 个集群，并确定每个集群的中心点。

Method: 开发了一种高效的近似算法 KRCA，该算法迭代地改进来自 KMC 的初始解，称为基线解。此外，我们还引入了一种分支定界 （BnB） 算法，用于在 KRCA 中进行高效的集群重建，利用决策树框架来减少计算时间，同时结合一个控制参数来平衡解决方案质量和效率。

Result: 建立了 KRC 的 NP 难度并表征了其可行集。对于单集群情况，我们推导了最优中心点的闭式解析解，该解可以在线性时间内计算。我们建立了 KRCA 和 BnB 的理论误差界限。

Conclusion: KRCA算法在合成和真实世界数据集上始终优于基线解决方案，在快速计算时间内显着提高了解决方案质量。这项工作强调了 KRC 在个性化和大规模决策中的实际意义，提供了方法上的进步和见解，可以在未来的研究中加以利用。

Abstract: We study the problem of clustering ranking vectors, where each vector
represents preferences as an ordered list of distinct integers. Specifically,
we focus on the k-centroids ranking vectors clustering problem (KRC), which
aims to partition a set of ranking vectors into k clusters and identify the
centroid of each cluster. Unlike classical k-means clustering (KMC), KRC
constrains both the observations and centroids to be ranking vectors. We
establish the NP-hardness of KRC and characterize its feasible set. For the
single-cluster case, we derive a closed-form analytical solution for the
optimal centroid, which can be computed in linear time. To address the
computational challenges of KRC, we develop an efficient approximation
algorithm, KRCA, which iteratively refines initial solutions from KMC, referred
to as the baseline solution. Additionally, we introduce a branch-and-bound
(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a
decision tree framework to reduce computational time while incorporating a
controlling parameter to balance solution quality and efficiency. We establish
theoretical error bounds for KRCA and BnB. Through extensive numerical
experiments on synthetic and real-world datasets, we demonstrate that KRCA
consistently outperforms baseline solutions, delivering significant
improvements in solution quality with fast computational times. This work
highlights the practical significance of KRC for personalization and
large-scale decision making, offering methodological advancements and insights
that can be built upon in future studies.

</details>


### [45] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
*Yinan Li,Kwang-Sung Jun*

Main category: cs.LG

TL;DR: 本文研究了 [0,1] 值回归问题，提出了一种新的损失函数 betting loss，实现了方差相关的界限，改进了先前的一阶界限。


<details>
  <summary>Details</summary>
Motivation: 在 i.i.d. 设置中考虑 [0,1] 值回归问题。在相关的 cost-sensitive 分类问题中，log loss 最小化器实现了改进的泛化界限，本文研究是否存在一个损失函数，可以实现方差相关的界限（也称为二阶界限），这是对一阶界限的严格改进。

Method: 提出了一个新的损失函数 betting loss。

Result: log loss 最小化器导致类似的一阶界限。提出了一个新的损失函数 betting loss，实现了方差相关的界限。

Conclusion: 提出了一个新的损失函数，称为 betting loss，实现了方差相关的界限，改进了先前的一阶界限。

Abstract: We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a
related problem called cost-sensitive classification, \citet{foster21efficient}
have shown that the log loss minimizer achieves an improved generalization
bound compared to that of the squared loss minimizer in the sense that the
bound scales with the cost of the best classifier, which can be arbitrarily
small depending on the problem at hand. Such a result is often called a
first-order bound. For $[0,1]$-valued regression, we first show that the log
loss minimizer leads to a similar first-order bound. We then ask if there
exists a loss function that achieves a variance-dependent bound (also known as
a second order bound), which is a strict improvement upon first-order bounds.
We answer this question in the affirmative by proposing a novel loss function
called the betting loss. Our result is ``variance-adaptive'' in the sense that
the bound is attained \textit{without any knowledge about the variance}, which
is in contrast to modeling label (or reward) variance or the label distribution
itself explicitly as part of the function class such as distributional
reinforcement learning.

</details>


### [46] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
*Antoni Zajko,Katarzyna Woźnica*

Main category: cs.LG

TL;DR: This paper introduces two new tabular representation learning methods for Bayesian Hyperparameter Optimization warm-starting, focusing on capturing landmarker properties. While the encoders align with landmarkers, they don't guarantee significant HPO performance gains.


<details>
  <summary>Details</summary>
Motivation: Effectively representing heterogeneous tabular datasets for meta-learning purposes is still an open problem. Previous approaches rely on representations that are intended to be universal.

Method: This paper proposes two novel methods for tabular representation learning tailored to a specific meta-task - warm-starting Bayesian Hyperparameter Optimization. The first approach involves deep metric learning, while the second one is based on landmarkers reconstruction.

Result: Experiments demonstrate that the proposed encoders can effectively learn representations aligned with landmarkers.

Conclusion: The proposed encoders effectively learn representations aligned with landmarkers, but may not directly translate to significant performance gains in the meta-task of HPO warm-starting.

Abstract: Effectively representing heterogeneous tabular datasets for meta-learning
purposes is still an open problem. Previous approaches rely on representations
that are intended to be universal. This paper proposes two novel methods for
tabular representation learning tailored to a specific meta-task -
warm-starting Bayesian Hyperparameter Optimization. Both follow the specific
requirement formulated by ourselves that enforces representations to capture
the properties of landmarkers. The first approach involves deep metric
learning, while the second one is based on landmarkers reconstruction. We
evaluate the proposed encoders in two ways. Next to the gain in the target
meta-task, we also use the degree of fulfillment of the proposed requirement as
the evaluation metric. Experiments demonstrate that while the proposed encoders
can effectively learn representations aligned with landmarkers, they may not
directly translate to significant performance gains in the meta-task of HPO
warm-starting.

</details>
