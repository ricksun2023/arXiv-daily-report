{"id": "2511.09690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09690", "abs": "https://arxiv.org/abs/2511.09690", "authors": ["Omnilingual ASR team", "Gil Keren", "Artyom Kozhevnikov", "Yen Meng", "Christophe Ropers", "Matthew Setzler", "Skyler Wang", "Ife Adebara", "Michael Auli", "Can Balioglu", "Kevin Chan", "Chierh Cheng", "Joe Chuang", "Caley Droof", "Mark Duppenthaler", "Paul-Ambroise Duquenne", "Alexander Erben", "Cynthia Gao", "Gabriel Mejia Gonzalez", "Kehan Lyu", "Sagar Miglani", "Vineel Pratap", "Kaushik Ram Sadagopan", "Safiyyah Saleem", "Arina Turkatenko", "Albert Ventayol-Boada", "Zheng-Xin Yong", "Yu-An Chung", "Jean Maillard", "Rashel Moritz", "Alexandre Mourachko", "Mary Williamson", "Shireen Yates"], "title": "Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages", "comment": null, "summary": "Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.", "AI": {"tldr": "Omnilingual ASR is a large-scale ASR system designed for extensibility, enabling communities to introduce unserved languages with only a few data samples.", "motivation": "Expanding ASR coverage has been costly and limited, leaving thousands of long-tail languages behind. Ethical concerns also exist when pursued without community collaboration.", "method": "It scales self-supervised pre-training to 7B parameters and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. It combines public resources with community-sourced recordings.", "result": "Omnilingual ASR expands coverage to over 1,600 languages, including over 500 never before served by ASR, with substantial gains over prior systems, especially in low-resource conditions.", "conclusion": "The paper reflects on the ethical considerations and discusses the societal impact, highlighting how open-sourcing models and tools can lower barriers for researchers and communities."}}
{"id": "2511.09700", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09700", "abs": "https://arxiv.org/abs/2511.09700", "authors": ["Warren Li", "Yiqian Wang", "Zihan Wang", "Jingbo Shang"], "title": "Order Matters: Rethinking Prompt Construction in In-Context Learning", "comment": null, "summary": "In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.", "AI": {"tldr": "ICL\u4e2d\uff0c\u793a\u4f8b\u987a\u5e8f\u7684\u5f71\u54cd\u4e0e\u793a\u4f8b\u9009\u62e9\u7684\u5f71\u54cd\u76f8\u5f53\uff0c\u5e94\u91cd\u65b0\u5ba1\u89c6ICL\u4e2d\u7684\u5047\u8bbe\u3002", "motivation": "\u5148\u524d\u7684\u5de5\u4f5c\u8ba4\u4e3a\u793a\u4f8b\u9009\u62e9\u6bd4\u793a\u4f8b\u987a\u5e8f\u66f4\u91cd\u8981\u3002\u672c\u6587\u5bf9\u6b64\u5047\u8bbe\u8fdb\u884c\u4e86\u91cd\u65b0\u5ba1\u89c6\u3002", "method": "\u901a\u8fc7\u5728\u5206\u7c7b\u548c\u751f\u6210\u4efb\u52a1\u4e0a\u8fdb\u884c\u53d7\u63a7\u5b9e\u9a8c\uff0c\u4f7f\u7528\u591a\u4e2a\u5f00\u6e90\u6a21\u578b\u5bb6\u65cf\uff080.5B\u523027B\u53c2\u6570\uff09\u548cGPT-5\u3002", "result": "\u4e0d\u540c\u793a\u4f8b\u987a\u5e8f\u5bfc\u81f4\u7684\u6027\u80fd\u5dee\u5f02\u4e0e\u4f7f\u7528\u5b8c\u5168\u4e0d\u540c\u7684\u793a\u4f8b\u96c6\u76f8\u5f53\u3002\u4ec5\u4f7f\u7528\u5f00\u53d1\u96c6\u5c31\u53ef\u4ee5\u8bc6\u522b\u5f3a\u987a\u5e8f\uff0c\u5176\u6027\u80fd\u63a5\u8fd1\u4e8e\u57fa\u4e8e\u6d4b\u8bd5\u6807\u7b7e\u9009\u62e9\u6700\u4f73\u987a\u5e8f\u7684oracle\u3002", "conclusion": "\u793a\u4f8b\u9009\u62e9\u548c\u6392\u5e8f\u5728\u63d0\u793a\u8bbe\u8ba1\u4e2d\u540c\u7b49\u91cd\u8981\u4e14\u76f8\u4e92\u5173\u8054\uff0c\u56e0\u6b64\u9700\u8981\u91cd\u65b0\u68c0\u67e5ICL\u4e2d\u6301\u6709\u7684\u5047\u8bbe\u3002"}}
{"id": "2511.09709", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09709", "abs": "https://arxiv.org/abs/2511.09709", "authors": ["Marisa Hudspeth", "Patrick J. Burns", "Brendan O'Connor"], "title": "Contextual morphologically-guided tokenization for Latin encoder models", "comment": null, "summary": "Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u9488\u5bf9\u62c9\u4e01\u8bed\u7684\u5f62\u6001\u611f\u77e5\u5206\u8bcd\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u5206\u8bcd\u65b9\u6cd5\u901a\u5e38\u6ce8\u91cd\u4fe1\u606f\u8bba\u76ee\u6807\uff0c\u800c\u5ffd\u7565\u4e86\u8bed\u8a00\u5b66\u76ee\u6807\uff0c\u5bf9\u4e8e\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\u6765\u8bf4\uff0c\u5206\u8bcd\u8d28\u91cf\u76f4\u63a5\u5f71\u54cd\u4e0b\u6e38\u4efb\u52a1\u7684\u8868\u73b0\u3002\u672c\u6587\u7814\u7a76\u62c9\u4e01\u8bed\u7684\u5206\u8bcd\u95ee\u9898\uff0c\u62c9\u4e01\u8bed\u662f\u4e00\u79cd\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\uff0c\u62e5\u6709\u4e30\u5bcc\u7684\u8bcd\u6c47\u8d44\u6e90\u3002", "method": "\u672c\u6587 \u0438\u0441\u0441\u043b\u0435\u0434\u0443\u0435\u0442 \u9488\u5bf9\u62c9\u4e01\u8bed\u7684\u5f62\u6001\u611f\u77e5\u5206\u8bcd\u65b9\u6cd5\u3002", "result": "\u5f62\u6001\u5f15\u5bfc\u7684\u5206\u8bcd\u63d0\u9ad8\u4e86\u56db\u4e2a\u4e0b\u6e38\u4efb\u52a1\u7684\u6574\u4f53\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9886\u57df\u5916\u6587\u672c\u4e2d\uff0c\u7a81\u663e\u4e86\u6a21\u578b\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5bf9\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u5f00\u53d1\u548c\u6574\u5408\u8bed\u8a00\u8d44\u6e90\u53ef\u4ee5\u4f5c\u4e3a\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u53ef\u884c\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.10063", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.10063", "abs": "https://arxiv.org/abs/2511.10063", "authors": ["Yiwen Wang", "Vivek Shah", "Marcos Antonio Vaz Salles", "Claudia Bauzer Medeiros", "Julio Cesar Dos Reis", "Yongluan Zhou"], "title": "Dolphin: An Actor-Oriented Database for Reactive Moving Object Data Management", "comment": null, "summary": "Novel reactive moving object applications require solutions to support object reactive behaviors as a way to query and update dynamic data. While moving object scenarios have long been researched in the context of spatio-temporal data management, reactive behavior is usually left to complex end-user implementations. However, it is not just a matter of hardwiring reactive constraints: the required solutions need to satisfy tight low-latency computation requirements and be scalable. This paper explores a novel approach to enrich a distributed actor-based framework with reactive functionality and complex spatial data management along with concurrency semantics. Our approach relies on a proposal of the moving actor abstraction, which is a conceptual enhancement of the actor model with reactive sensing, movement, and spatial querying capabilities. This enhancement helps developers of reactive moving object applications avoid the significant burden of implementing application-level schemes to balance performance and consistency. Based on moving actors, we define a reactive moving object data management platform, named Moving Actor-Oriented Databases (M-AODBs), and build Dolphin -- an implementation of M-AODBs. Dolphin embodies a non-intrusive actor-based design layered on top of the Microsoft Orleans distributed virtual actor framework. In a set of experimental evaluations with realistic reactive moving object scenarios, Dolphin exhibits scalability on multi-machines and provides near-real-time reaction latency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u79fb\u52a8actor\u62bd\u8c61\u6765\u589e\u5f3a\u57fa\u4e8eactor\u7684\u5206\u5e03\u5f0f\u6846\u67b6\uff0c\u4f7f\u5176\u5177\u6709\u53cd\u5e94\u529f\u80fd\u3001\u590d\u6742\u7684\u7a7a\u95f4\u6570\u636e\u7ba1\u7406\u548c\u5e76\u53d1\u8bed\u4e49\uff0c\u4ece\u800c\u652f\u6301\u65b0\u7684\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u79fb\u52a8\u5bf9\u8c61\u573a\u666f\u7814\u7a76\u901a\u5e38\u5c06\u53cd\u5e94\u884c\u4e3a\u7559\u7ed9\u6700\u7ec8\u7528\u6237\u590d\u6742\u5b9e\u73b0\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4f4e\u5ef6\u8fdf\u8ba1\u7b97\u548c\u53ef\u6269\u5c55\u6027\u7684\u8981\u6c42\u3002", "method": "\u63d0\u51fa\u79fb\u52a8actor\u62bd\u8c61\uff0c\u589e\u5f3aactor\u6a21\u578b\uff0c\u4f7f\u5176\u5177\u6709\u53cd\u5e94\u611f\u77e5\u3001\u79fb\u52a8\u548c\u7a7a\u95f4\u67e5\u8be2\u80fd\u529b\u3002\u5b9a\u4e49\u4e86\u4e00\u4e2a\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u6570\u636e\u7ba1\u7406\u5e73\u53f0M-AODBs\uff0c\u5e76\u5b9e\u73b0\u4e86Dolphin\u3002", "result": "\u5728\u771f\u5b9e\u7684\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u573a\u666f\u7684\u5b9e\u9a8c\u8bc4\u4f30\u4e2d\uff0cDolphin\u5728\u591a\u673a\u5668\u4e0a\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u8fd1\u5b9e\u65f6\u7684\u53cd\u5e94\u5ef6\u8fdf\u3002", "conclusion": "Dolphin\u5e73\u53f0\u80fd\u591f\u6709\u6548\u652f\u6301\u53cd\u5e94\u5f0f\u79fb\u52a8\u5bf9\u8c61\u5e94\u7528\uff0c\u51cf\u8f7b\u5f00\u53d1\u8005\u5728\u6027\u80fd\u548c\u4e00\u81f4\u6027\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u7684\u8d1f\u62c5\u3002"}}
{"id": "2511.09738", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09738", "abs": "https://arxiv.org/abs/2511.09738", "authors": ["C. LeMay", "A. Lane", "J. Seales", "M. Winstead", "S. Baty"], "title": "Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives", "comment": "24 pages", "summary": "Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff08NLP\uff09\u5982\u4f55\u7528\u4e8e\u4ece\u5927\u91cf\u4e66\u9762\u6570\u636e\u4e2d\u63d0\u53d6\u4e3b\u9898\uff0c\u5e94\u7528\u4e8e\u8bc6\u522b\u91cc\u6839\u81f3\u514b\u6797\u987f\u653f\u5e9c\u603b\u7edf\u6307\u4ee4\uff08PDs\uff09\u4e2d\u7684\u4fe1\u53f7\u4e3b\u9898\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u63a2\u7d22NLP\u5728\u5206\u6790\u5927\u91cf\u4e66\u9762\u8bed\u6599\u5e93\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8bc6\u522b\u603b\u7edf\u6307\u4ee4\u4e2d\u7684\u4e3b\u9898\u65b9\u9762\u3002", "method": "\u901a\u8fc7NLP\u6280\u672f\u548c\u4eba\u5de5\u5206\u6790\u4e24\u79cd\u65b9\u6cd5\u8bc6\u522b\u76f8\u5173\u6587\u4ef6\uff0c\u5e76\u6bd4\u8f83\u7ed3\u679c\u3002", "result": "NLP\u548c\u4eba\u5de5\u5206\u6790\u90fd\u80fd\u8bc6\u522b\u76f8\u5173\u6587\u4ef6\uff0c\u4f46\u4e5f\u5b58\u5728\u5dee\u5f02\uff0c\u8868\u660e\u9700\u8981\u66f4\u591a\u7814\u7a76\u6765\u8bc4\u4f30NLP\u5728\u6b64\u7528\u4f8b\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u5feb\u901f\u53d1\u5c55\u7684AIML\u9886\u57df\u610f\u5473\u7740\u73b0\u6709\u5de5\u5177\u5df2\u7ecf\u6539\u8fdb\uff0c\u5e76\u4e14\u5df2\u7ecf\u5f00\u53d1\u51fa\u65b0\u5de5\u5177\uff1b \u8fd9\u9879\u7814\u7a76\u5c55\u793a\u4e86\u6f5c\u5728\u7684\u8fc7\u65f6AI\u5de5\u5177\u5728\u65b0\u5174\u793e\u4f1a\u79d1\u5b66\u5e94\u7528\u4e2d\u7684\u56fa\u6709\u80fd\u529b\u3002"}}
{"id": "2511.10418", "categories": ["cs.DB"], "pdf": "https://arxiv.org/pdf/2511.10418", "abs": "https://arxiv.org/abs/2511.10418", "authors": ["Yaqiao Zhu", "Hongkai Wen", "Mark Birkin", "Man Luo"], "title": "CityVerse: A Unified Data Platform for Multi-Task Urban Computing with Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) show remarkable potential for urban computing, from spatial reasoning to predictive analytics. However, evaluating LLMs across diverse urban tasks faces two critical challenges: lack of unified platforms for consistent multi-source data access and fragmented task definitions that hinder fair comparison. To address these challenges, we present CityVerse, the first unified platform integrating multi-source urban data, capability-based task taxonomy, and dynamic simulation for systematic LLM evaluation in urban contexts. CityVerse provides: 1) coordinate-based Data APIs unifying ten categories of urban data-including spatial features, temporal dynamics, demographics, and multi-modal imagery-with over 38 million curated records; 2) Task APIs organizing 43 urban computing tasks into a four-level cognitive hierarchy: Perception, Spatial Understanding, Reasoning and Prediction, and Decision and Interaction, enabling standardized evaluation across capability levels; 3) an interactive visualization frontend supporting real-time data retrieval, multi-layer display, and simulation replay for intuitive exploration and validation. We validate the platform's effectiveness through evaluations on mainstream LLMs across representative tasks, demonstrating its capability to support reproducible and systematic assessment. CityVerse provides a reusable foundation for advancing LLMs and multi-task approaches in the urban computing domain.", "AI": {"tldr": "CityVerse\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u5e73\u53f0\uff0c\u96c6\u6210\u4e86\u591a\u6e90\u57ce\u5e02\u6570\u636e\u3001\u57fa\u4e8e\u80fd\u529b\u7684\u4efb\u52a1\u5206\u7c7b\u548c\u52a8\u6001\u6a21\u62df\uff0c\u7528\u4e8e\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u8fdb\u884c\u7cfb\u7edf\u7684LLM\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u57ce\u5e02\u8ba1\u7b97\u65b9\u9762\u663e\u793a\u51fa\u5de8\u5927\u7684\u6f5c\u529b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u7edf\u4e00\u7684\u5e73\u53f0\u6765\u8fdb\u884c\u4e00\u81f4\u7684\u591a\u6e90\u6570\u636e\u8bbf\u95ee\uff0c\u4ee5\u53ca\u4efb\u52a1\u5b9a\u4e49\u4e0d\u660e\u786e\uff0c\u963b\u788d\u4e86\u516c\u5e73\u7684\u6bd4\u8f83\uff0c\u56e0\u6b64\u8bc4\u4f30LLM\u5728\u5404\u79cd\u57ce\u5e02\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u9762\u4e34\u7740\u4e25\u5cfb\u7684\u6311\u6218\u3002", "method": "CityVerse\u5e73\u53f0\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5b9e\u73b0\uff1a1) \u5750\u6807\u6570\u636eAPI\uff0c\u7edf\u4e00\u4e86\u5341\u7c7b\u57ce\u5e02\u6570\u636e\uff1b2) \u4efb\u52a1API\uff0c\u5c0643\u4e2a\u57ce\u5e02\u8ba1\u7b97\u4efb\u52a1\u7ec4\u7ec7\u6210\u56db\u4e2a\u8ba4\u77e5\u5c42\u6b21\uff1b3) \u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u524d\u7aef\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u68c0\u7d22\u3001\u591a\u5c42\u663e\u793a\u548c\u6a21\u62df\u91cd\u653e\u3002", "result": "\u901a\u8fc7\u5bf9\u4e3b\u6d41LLM\u5728\u4ee3\u8868\u6027\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u8be5\u5e73\u53f0\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u652f\u6301\u53ef\u91cd\u590d\u548c\u7cfb\u7edf\u8bc4\u4f30\u7684\u80fd\u529b\u3002", "conclusion": "CityVerse\u4e3a\u63a8\u8fdb\u57ce\u5e02\u8ba1\u7b97\u9886\u57df\u4e2d\u7684LLM\u548c\u591a\u4efb\u52a1\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u91cd\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2511.10138", "categories": ["cs.IR"], "pdf": "https://arxiv.org/pdf/2511.10138", "abs": "https://arxiv.org/abs/2511.10138", "authors": ["Jun Zhang", "Yi Li", "Yue Liu", "Changping Wang", "Yuan Wang", "Yuling Xiong", "Xun Liu", "Haiyang Wu", "Qian Li", "Enming Zhang", "Jiawei Sun", "Xin Xu", "Zishuai Zhang", "Ruoran Liu", "Suyuan Huang", "Zhaoxin Zhang", "Zhengkai Guo", "Shuojin Yang", "Meng-Hao Guo", "Huan Yu", "Jie Jiang", "Shi-Min Hu"], "title": "GPR: Towards a Generative Pre-trained One-Model Paradigm for Large-Scale Advertising Recommendation", "comment": "12 pages, 5 figures", "summary": "As an intelligent infrastructure connecting users with commercial content, advertising recommendation systems play a central role in information flow and value creation within the digital economy. However, existing multi-stage advertising recommendation systems suffer from objective misalignment and error propagation, making it difficult to achieve global optimality, while unified generative recommendation models still struggle to meet the demands of practical industrial applications. To address these issues, we propose GPR (Generative Pre-trained Recommender), the first one-model framework that redefines advertising recommendation as an end-to-end generative task, replacing the traditional cascading paradigm with a unified generative approach. To realize GPR, we introduce three key innovations spanning unified representation, network architecture, and training strategy. First, we design a unified input schema and tokenization method tailored to advertising scenarios, mapping both ads and organic content into a shared multi-level semantic ID space, thereby enhancing semantic alignment and modeling consistency across heterogeneous data. Second, we develop the Heterogeneous Hierarchical Decoder (HHD), a dual-decoder architecture that decouples user intent modeling from ad generation, achieving a balance between training efficiency and inference flexibility while maintaining strong modeling capacity. Finally, we propose a multi-stage joint training strategy that integrates Multi-Token Prediction (MTP), Value-Aware Fine-Tuning and the Hierarchy Enhanced Policy Optimization (HEPO) algorithm, forming a complete generative recommendation pipeline that unifies interest modeling, value alignment, and policy optimization. GPR has been fully deployed in the Tencent Weixin Channels advertising system, delivering significant improvements in key business metrics including GMV and CTCVR.", "AI": {"tldr": "GPR: \u4e00\u4e2a\u7aef\u5230\u7aef\u751f\u6210\u5f0f\u5e7f\u544a\u63a8\u8350\u6846\u67b6\uff0c\u7528\u7edf\u4e00\u65b9\u6cd5\u4ee3\u66ff\u4f20\u7edf\u7ea7\u8054\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u9636\u6bb5\u5e7f\u544a\u63a8\u8350\u7cfb\u7edf\u5b58\u5728\u76ee\u6807\u4e0d\u4e00\u81f4\u548c\u8bef\u5dee\u4f20\u64ad\u95ee\u9898\uff0c\u800c\u7edf\u4e00\u751f\u6210\u5f0f\u63a8\u8350\u6a21\u578b\u96be\u4ee5\u6ee1\u8db3\u5b9e\u9645\u5de5\u4e1a\u5e94\u7528\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86GPR\uff0c\u5305\u542b\u7edf\u4e00\u8868\u793a\u3001\u7f51\u7edc\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u4e09\u4e2a\u5173\u952e\u521b\u65b0\u70b9\u3002\u7edf\u4e00\u8868\u793a\u8bbe\u8ba1\u4e86\u7edf\u4e00\u7684\u8f93\u5165\u6a21\u5f0f\u548ctokenization\u65b9\u6cd5\uff1b\u7f51\u7edc\u67b6\u6784\u5f00\u53d1\u4e86\u5f02\u6784\u5206\u5c42\u89e3\u7801\u5668 (HHD)\uff1b\u8bad\u7ec3\u7b56\u7565\u6574\u5408\u4e86\u591atoken\u9884\u6d4b (MTP)\u3001\u4ef7\u503c\u611f\u77e5\u5fae\u8c03\u548c\u5c42\u7ea7\u589e\u5f3a\u7b56\u7565\u4f18\u5316 (HEPO) \u7b97\u6cd5\u3002", "result": "GPR\u5df2\u5728\u817e\u8baf\u5fae\u4fe1\u9891\u9053\u5e7f\u544a\u7cfb\u7edf\u4e2d\u5168\u9762\u90e8\u7f72\uff0c\u5e76\u5728GMV\u548cCTCVR\u7b49\u5173\u952e\u4e1a\u52a1\u6307\u6807\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GPR\u662f\u9996\u4e2a\u5355\u6a21\u578b\u6846\u67b6\uff0c\u5c06\u5e7f\u544a\u63a8\u8350\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7aef\u5230\u7aef\u751f\u6210\u4efb\u52a1"}}
{"id": "2511.09563", "categories": ["cs.AI", "math.CO"], "pdf": "https://arxiv.org/pdf/2511.09563", "abs": "https://arxiv.org/abs/2511.09563", "authors": ["Qilong Yuan"], "title": "An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-\u03b1 Optimization", "comment": "20 pages, 4 figures", "summary": "The Joint Routing-Assignment (JRA) optimization problem simultaneously determines the assignment of items to placeholders and a Hamiltonian cycle that visits each node pair exactly once, with the objective of minimizing total travel cost. Previous studies introduced an exact mixed-integer programming (MIP) solver, along with datasets and a Gurobi implementation, showing that while the exact approach guarantees optimality, it becomes computationally inefficient for large-scale instances. To overcome this limitation, heuristic methods based on merging algorithms and shaking procedures were proposed, achieving solutions within approximately 1% deviation from the optimum. This work presents a novel and more efficient approach that attains high-accuracy, near-optimal solutions for large-scale JRA problems. The proposed method introduces a Partial Path Reconstructon (PPR) solver that first identifies key item-placeholder pairs to form a reduced subproblem, which is solved efficiently to refine the global solution. Using this PJAR framework, the initial heuristic merging solutions can be further improved, reducing the deviation by half. Moreover, the solution can be iteratively polished with PPR based solver along the optimization path to yield highly accurate tours. Additionally, a global Large-\u03b1 constraint is incorporated into the JRA model to further enhance solution optimality. Experimental evaluations on benchmark datasets with n = 300, 500, and 1000 demonstrate that the proposed method consistently delivers almost optimal solutions, achieving an average deviation of 0.00% from the ground truth while maintaining high computational efficiency. Beyond the JRA problem, the proposed framework and methodologies exhibit strong potential for broader applications. The Framework can be applied to TSP and related optimization problems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21\u8054\u5408\u8def\u7531\u5206\u914d\uff08JRA\uff09\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u90e8\u5206\u8def\u5f84\u91cd\u6784\uff08PPR\uff09\u6c42\u89e3\u5668\u548c\u5168\u5c40Large-\u03b1\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728benchmark\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e860.00%\u7684\u5e73\u5747\u504f\u5dee\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u7684\u7cbe\u786e\u6df7\u5408\u6574\u6570\u89c4\u5212\uff08MIP\uff09\u6c42\u89e3\u5668\u5728\u89e3\u51b3\u5927\u89c4\u6a21JRA\u95ee\u9898\u65f6\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\uff0c\u542f\u53d1\u5f0f\u65b9\u6cd5\u867d\u7136\u80fd\u5feb\u901f\u5f97\u5230\u89e3\uff0c\u4f46\u4e0e\u6700\u4f18\u89e3\u5b58\u5728\u504f\u5dee\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u90e8\u5206\u8def\u5f84\u91cd\u6784\uff08PPR\uff09\u6c42\u89e3\u5668\uff0c\u8be5\u6c42\u89e3\u5668\u9996\u5148\u8bc6\u522b\u5173\u952e\u7684\u9879\u76ee-\u5360\u4f4d\u7b26\u5bf9\u4ee5\u5f62\u6210\u7b80\u5316\u7684\u5b50\u95ee\u9898\uff0c\u7136\u540e\u6709\u6548\u5730\u6c42\u89e3\u8be5\u5b50\u95ee\u9898\u4ee5\u4f18\u5316\u5168\u5c40\u89e3\u51b3\u65b9\u6848\u3002\u6b64\u5916\uff0c\u8fd8\u5c06\u5168\u5c40Large-\u03b1\u7ea6\u675f\u96c6\u6210\u5230JRA\u6a21\u578b\u4e2d\uff0c\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u89e3\u51b3\u65b9\u6848\u7684\u6700\u4f18\u6027\u3002", "result": "\u5728n=300\u3001500\u548c1000\u7684benchmark\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u5982\u4e00\u5730\u63d0\u4f9b\u51e0\u4e4e\u6700\u4f18\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u4e0eground truth\u7684\u5e73\u5747\u504f\u5dee\u4e3a0.00%\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f83\u9ad8\u7684\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u548c\u65b9\u6cd5\u4e0d\u4ec5\u53ef\u4ee5\u5e94\u7528\u4e8eJRA\u95ee\u9898\uff0c\u800c\u4e14\u5728TSP\u548c\u76f8\u5173\u4f18\u5316\u95ee\u9898\u4e2d\u4e5f\u5177\u6709\u5f3a\u5927\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.09599", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09599", "abs": "https://arxiv.org/abs/2511.09599", "authors": ["Ming Yang", "Dongrun Li", "Xin Wang", "Feng Li", "Lisheng Fan", "Chunxiao Wang", "Xiaoming Wu", "Peng Cheng"], "title": "FedeCouple: Fine-Grained Balancing of Global-Generalization and Local-Adaptability in Federated Learning", "comment": null, "summary": "In privacy-preserving mobile network transmission scenarios with heterogeneous client data, personalized federated learning methods that decouple feature extractors and classifiers have demonstrated notable advantages in enhancing learning capability. However, many existing approaches primarily focus on feature space consistency and classification personalization during local training, often neglecting the local adaptability of the extractor and the global generalization of the classifier. This oversight results in insufficient coordination and weak coupling between the components, ultimately degrading the overall model performance. To address this challenge, we propose FedeCouple, a federated learning method that balances global generalization and local adaptability at a fine-grained level. Our approach jointly learns global and local feature representations while employing dynamic knowledge distillation to enhance the generalization of personalized classifiers. We further introduce anchors to refine the feature space; their strict locality and non-transmission inherently preserve privacy and reduce communication overhead. Furthermore, we provide a theoretical analysis proving that FedeCouple converges for nonconvex objectives, with iterates approaching a stationary point as the number of communication rounds increases. Extensive experiments conducted on five image-classification datasets demonstrate that FedeCouple consistently outperforms nine baseline methods in effectiveness, stability, scalability, and security. Notably, in experiments evaluating effectiveness, FedeCouple surpasses the best baseline by a significant margin of 4.3%.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedeCouple\u7684\u8054\u90a6\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b83\u5728\u7ec6\u7c92\u5ea6\u7ea7\u522b\u4e0a\u5e73\u8861\u4e86\u5168\u5c40\u6cdb\u5316\u548c\u5c40\u90e8\u9002\u5e94\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u5c40\u90e8\u8bad\u7ec3\u671f\u95f4\u7684\u7279\u5f81\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u5206\u7c7b\u4e2a\u6027\u5316\uff0c\u901a\u5e38\u5ffd\u7565\u4e86\u63d0\u53d6\u5668\u7684\u5c40\u90e8\u9002\u5e94\u6027\u548c\u5206\u7c7b\u5668\u7684\u5168\u5c40\u6cdb\u5316\u3002", "method": "\u8054\u5408\u5b66\u4e60\u5168\u5c40\u548c\u5c40\u90e8\u7279\u5f81\u8868\u793a\uff0c\u540c\u65f6\u91c7\u7528\u52a8\u6001\u77e5\u8bc6\u84b8\u998f\u6765\u589e\u5f3a\u4e2a\u6027\u5316\u5206\u7c7b\u5668\u7684\u6cdb\u5316\u80fd\u529b\u3002\u5f15\u5165\u951a\u70b9\u4ee5\u7ec6\u5316\u7279\u5f81\u7a7a\u95f4\u3002", "result": "\u5728\u4e94\u4e2a\u56fe\u50cf\u5206\u7c7b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cFedeCouple\u5728\u6709\u6548\u6027\u3001\u7a33\u5b9a\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u4e5d\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002\u5728\u8bc4\u4f30\u6709\u6548\u6027\u7684\u5b9e\u9a8c\u4e2d\uff0cFedeCouple\u6bd4\u6700\u4f73\u57fa\u7ebf\u9ad8\u51fa 4.3%\u3002", "conclusion": "FedeCouple\u5728\u975e\u51f8\u76ee\u6807\u4e0b\u6536\u655b\uff0c\u5e76\u4e14\u968f\u7740\u901a\u4fe1\u8f6e\u6570\u7684\u589e\u52a0\uff0c\u8fed\u4ee3\u63a5\u8fd1\u9759\u6b62\u70b9\u3002"}}
{"id": "2511.09559", "categories": ["cs.LG", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09559", "abs": "https://arxiv.org/abs/2511.09559", "authors": ["Tianlei Chen", "Yuxiao Chen", "Yang Li", "Feifei Wang"], "title": "Probability-Biased Attention over Directed Bipartite Graphs for Long-Tail ICD Coding", "comment": null, "summary": "Automated International Classification of Diseases (ICD) coding aims to assign multiple disease codes to clinical documents, constituting a crucial multi-label text classification task in healthcare informatics. However, the task is challenging due to its large label space (10,000 to 20,000 codes) and long-tail distribution, where a few codes dominate while many rare codes lack sufficient training data. To address this, we propose a learning method that models fine-grained co-occurrence relationships among codes. Specifically, we construct a Directed Bipartite Graph Encoder with disjoint sets of common and rare code nodes. To facilitate a one-way information flow, edges are directed exclusively from common to rare codes. The nature of these connections is defined by a probability-based bias, which is derived from the conditional probability of a common code co-occurring given the presence of a rare code. This bias is then injected into the encoder's attention module, a process we term Co-occurrence Encoding. This structure empowers the graph encoder to enrich rare code representations by aggregating latent comorbidity information reflected in the statistical co-occurrence of their common counterparts. To ensure high-quality input to the graph, we utilize a large language model (LLM) to generate comprehensive descriptions for codes, enriching initial embeddings with clinical context and comorbidity information, serving as external knowledge for the statistical co-occurrence relationships in the code system. Experiments on three automated ICD coding benchmark datasets demonstrate that our method achieves state-of-the-art performance with particularly notable improvements in Macro-F1, which is the key metric for long-tail classification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684 ICD \u7f16\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u5e38\u89c1\u4ee3\u7801\u548c\u7f55\u89c1\u4ee3\u7801\u4e4b\u95f4\u7684\u5171\u73b0\u5173\u7cfb\u8fdb\u884c\u5efa\u6a21\u6765\u89e3\u51b3\u957f\u5c3e\u5206\u5e03\u95ee\u9898\u3002", "motivation": "ICD \u7f16\u7801\u4efb\u52a1\u5177\u6709\u6807\u7b7e\u7a7a\u95f4\u5927\u548c\u957f\u5c3e\u5206\u5e03\u7684\u6311\u6218\uff0c\u7f55\u89c1\u4ee3\u7801\u7f3a\u4e4f\u8db3\u591f\u7684\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u6709\u5411\u4e8c\u5206\u56fe\u7f16\u7801\u5668\uff0c\u5176\u4e2d\u8fb9\u4ece\u5e38\u89c1\u4ee3\u7801\u6307\u5411\u7f55\u89c1\u4ee3\u7801\uff0c\u5e76\u4f7f\u7528\u57fa\u4e8e\u6982\u7387\u7684\u504f\u5dee\u6765\u5b9a\u4e49\u8fd9\u4e9b\u8fde\u63a5\u3002\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b (LLM) \u4e3a\u4ee3\u7801\u751f\u6210\u5168\u9762\u7684\u63cf\u8ff0\uff0c\u4ece\u800c\u4e30\u5bcc\u521d\u59cb\u5d4c\u5165\u3002", "result": "\u5728\u4e09\u4e2a\u81ea\u52a8 ICD \u7f16\u7801\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728 Macro-F1 \u65b9\u9762\u6709\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u805a\u5408\u5e38\u89c1\u4ee3\u7801\u7684\u7edf\u8ba1\u5171\u73b0\u4fe1\u606f\u6765\u4e30\u5bcc\u7f55\u89c1\u4ee3\u7801\u7684\u8868\u793a\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86 ICD \u7f16\u7801\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09748", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09748", "abs": "https://arxiv.org/abs/2511.09748", "authors": ["Muskaan Chopra", "Lorenz Sparrenberg", "Sarthak Khanna", "Rafet Sifa"], "title": "How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation", "comment": "Accepted in IEEE BigData 2025", "summary": "Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5728\u4fdd\u8bc1\u68c0\u6d4b\u7ffb\u8bd1\u9519\u8bef\u7684\u540c\u65f6\uff0c\u5982\u4f55\u5c3d\u53ef\u80fd\u7f29\u5c0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u89c4\u6a21\u548c\u6210\u672c\uff0c\u4ee5\u4fbf\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u9690\u79c1\u654f\u611f\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u673a\u5668\u7ffb\u8bd1\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u89c4\u6a21\u548c\u6210\u672c\u9650\u5236\u4e86\u5b83\u4eec\u5728\u8fb9\u7f18\u8bbe\u5907\u548c\u9690\u79c1\u654f\u611f\u7684\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u90e8\u7f72\u3002", "method": "\u8be5\u7814\u7a76\u9488\u5bf9\u82f1\u8bed\u5230\u5fb7\u8bed\u7684\u5173\u952e\u9519\u8bef\u68c0\u6d4b\uff0c\u5bf920\u4ebf\u53c2\u6570\u4ee5\u4e0b\u7684\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91c7\u7528\u6807\u51c6\u5316\u7684\u63d0\u793a\u3001\u8f7b\u91cf\u7ea7\u7684logit-bias\u6821\u51c6\u548c\u591a\u6570\u6295\u7968\u65b9\u6cd5\uff0c\u5e76\u62a5\u544a\u4e86\u8bed\u4e49\u8d28\u91cf\u548c\u8ba1\u7b97\u6307\u6807\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u5927\u7ea610\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u5177\u6709\u660e\u663e\u7684\u4f18\u52bf\uff1aGemma-3-1B\u5728\u8d28\u91cf\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u4e86\u6700\u4f73\u5e73\u8861\uff0c\u5728SynCED-EnDe-2025\u4e0a\u8fbe\u5230\u4e86MCC=0.77\uff0cF1-ERR=0.98\uff0c\u540c\u65f6\u5728MacBook Pro M4 Pro\u4e0a\u4fdd\u6301\u4e86400\u6beb\u79d2\u7684\u5355\u6837\u672c\u5ef6\u8fdf\u3002", "conclusion": "\u7d27\u51d1\u7684\u3001\u6307\u4ee4\u8c03\u6574\u7684LLM\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7684\u6821\u51c6\u548c\u5c0f\u6837\u672c\u76d1\u7763\u8fdb\u884c\u589e\u5f3a\uff0c\u53ef\u4ee5\u4e3a\u673a\u5668\u7ffb\u8bd1\u63d0\u4f9b\u53ef\u4fe1\u8d56\u7684\u3001\u8bbe\u5907\u4e0a\u7684CED\uff0c\u4ece\u800c\u5728\u5b9e\u9645\u7ffb\u8bd1\u7ba1\u9053\u4e2d\u5b9e\u73b0\u79c1\u6709\u7684\u3001\u4f4e\u6210\u672c\u7684\u9519\u8bef\u7b5b\u9009\u3002"}}
{"id": "2511.09998", "categories": ["cs.LG", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.09998", "abs": "https://arxiv.org/abs/2511.09998", "authors": ["Hui Dou", "Lei Jin", "Yuxuan Zhou", "Jiang He", "Yiwen Zhang"], "title": "DemoTuner: Efficient DBMS Knobs Tuning via LLM-Assisted Demonstration Reinforcement Learning", "comment": "14 pages, 9 figures", "summary": "The performance of modern DBMSs such as MySQL and PostgreSQL heavily depends on the configuration of performance-critical knobs. Manual tuning these knobs is laborious and inefficient due to the complex and high-dimensional nature of the configuration space. Among the automated tuning methods, reinforcement learning (RL)-based methods have recently sought to improve the DBMS knobs tuning process from several different perspectives. However, they still encounter challenges with slow convergence speed during offline training. In this paper, we mainly focus on how to leverage the valuable tuning hints contained in various textual documents such as DBMS manuals and web forums to improve the offline training of RL-based methods. To this end, we propose an efficient DBMS knobs tuning framework named DemoTuner via a novel LLM-assisted demonstration reinforcement learning method. Specifically, to comprehensively and accurately mine tuning hints from documents, we design a structured chain of thought prompt to employ LLMs to conduct a condition-aware tuning hints extraction task. To effectively integrate the mined tuning hints into RL agent training, we propose a hint-aware demonstration reinforcement learning algorithm HA-DDPGfD in DemoTuner. As far as we know, DemoTuner is the first work to introduce the demonstration reinforcement learning algorithm for DBMS knobs tuning. Experimental evaluations conducted on MySQL and PostgreSQL across various workloads demonstrate the significant advantages of DemoTuner in both performance improvement and online tuning cost reduction over three representative baselines including DB-BERT, GPTuner and CDBTune. Additionally, DemoTuner also exhibits superior adaptability to application scenarios with unknown workloads.", "AI": {"tldr": "\u63d0\u51faDemoTuner\u6846\u67b6\uff0c\u5229\u7528LLM\u8f85\u52a9\u7684\u6f14\u793a\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u6316\u6398\u6587\u672c\u4e2d\u7684tuning hints\u6765\u6539\u5584\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf(DBMS)\u65cb\u94ae\u8c03\u4f18\u3002", "motivation": "\u624b\u52a8\u8c03\u6574\u6570\u636e\u5e93\u7ba1\u7406\u7cfb\u7edf(DBMS)\u7684\u6027\u80fd\u5173\u952e\u65cb\u94ae\u65e2\u8d39\u529b\u53c8\u4f4e\u6548\uff0c\u5f3a\u5316\u5b66\u4e60(RL)\u65b9\u6cd5\u5728\u79bb\u7ebf\u8bad\u7ec3\u4e2d\u6536\u655b\u901f\u5ea6\u6162\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ed3\u6784\u5316\u7684\u601d\u7ef4\u94fe\u63d0\u793a\uff0c\u5229\u7528LLM\u8fdb\u884c\u6761\u4ef6\u611f\u77e5\u7684tuning hints\u63d0\u53d6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cdhint-aware\u7684\u6f14\u793a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5HA-DDPGfD\u3002", "result": "\u5728MySQL\u548cPostgreSQL\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDemoTuner\u5728\u6027\u80fd\u63d0\u5347\u548c\u5728\u7ebf\u8c03\u6574\u6210\u672c\u964d\u4f4e\u65b9\u9762\u4f18\u4e8eDB-BERT, GPTuner\u548cCDBTune\uff0c\u5e76\u4e14\u5bf9\u672a\u77e5\u5de5\u4f5c\u8d1f\u8f7d\u5177\u6709\u66f4\u597d\u7684\u9002\u5e94\u6027\u3002", "conclusion": "DemoTuner\u662f\u7b2c\u4e00\u4e2a\u5c06\u6f14\u793a\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5f15\u5165DBMS\u65cb\u94ae\u8c03\u4f18\u7684\u5de5\u4f5c\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2511.10492", "categories": ["cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.10492", "abs": "https://arxiv.org/abs/2511.10492", "authors": ["Yunkai Zhang", "Qiang Zhang", "Feng", "Lin", "Ruizhong Qiu", "Hanchao Yu", "Jason Liu", "Yinglong Xia", "Zhuoran Yu", "Zeyu Zheng", "Diji Yang"], "title": "Don't Waste It: Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding", "comment": null, "summary": "Optimizing recommender systems for objectives beyond accuracy, such as diversity, novelty, and personalization, is crucial for long-term user satisfaction. To this end, industrial practitioners have accumulated vast amounts of structured domain knowledge, which we term human priors (e.g., item taxonomies, temporal patterns). This knowledge is typically applied through post-hoc adjustments during ranking or post-ranking. However, this approach remains decoupled from the core model learning, which is particularly undesirable as the industry shifts to end-to-end generative recommendation foundation models. On the other hand, many methods targeting these beyond-accuracy objectives often require architecture-specific modifications and discard these valuable human priors by learning user intent in a fully unsupervised manner.\n  Instead of discarding the human priors accumulated over years of practice, we introduce a backbone-agnostic framework that seamlessly integrates these human priors directly into the end-to-end training of generative recommenders. With lightweight, prior-conditioned adapter heads inspired by efficient LLM decoding strategies, our approach guides the model to disentangle user intent along human-understandable axes (e.g., interaction types, long- vs. short-term interests). We also introduce a hierarchical composition strategy for modeling complex interactions across different prior types. Extensive experiments on three large-scale datasets demonstrate that our method significantly enhances both accuracy and beyond-accuracy objectives. We also show that human priors allow the backbone model to more effectively leverage longer context lengths and larger model sizes.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u4eba\u7c7b\u5148\u9a8c\u77e5\u8bc6\u878d\u5165\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u901a\u7528\u6846\u67b6\uff0c\u4ee5\u4f18\u5316\u63a8\u8350\u7cfb\u7edf\u5728\u51c6\u786e\u7387\u4e4b\u5916\u7684\u76ee\u6807\uff08\u5982\u591a\u6837\u6027\u3001\u65b0\u9896\u6027\u548c\u4e2a\u6027\u5316\uff09\u3002", "motivation": "\u5de5\u4e1a\u754c\u79ef\u7d2f\u4e86\u5927\u91cf\u7ed3\u6784\u5316\u9886\u57df\u77e5\u8bc6\uff08\u4eba\u7c7b\u5148\u9a8c\uff09\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u5728\u6392\u5e8f\u6216\u540e\u6392\u5e8f\u9636\u6bb5\u8fdb\u884c\u4e8b\u540e\u8c03\u6574\uff0c\u4e0e\u6838\u5fc3\u6a21\u578b\u5b66\u4e60\u8131\u8282\u3002\u8bb8\u591a\u9488\u5bf9\u51c6\u786e\u7387\u4e4b\u5916\u76ee\u6807\u7684\u65b9\u6cd5\u9700\u8981\u7279\u5b9a\u7684\u67b6\u6784\u4fee\u6539\uff0c\u5e76\u4e14\u4ee5\u5b8c\u5168\u65e0\u76d1\u7763\u7684\u65b9\u5f0f\u5b66\u4e60\u7528\u6237\u610f\u56fe\uff0c\u4ece\u800c\u4e22\u5f03\u4e86\u8fd9\u4e9b\u6709\u4ef7\u503c\u7684\u4eba\u7c7b\u5148\u9a8c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e0e\u9aa8\u5e72\u7f51\u7edc\u65e0\u5173\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u53d7\u9ad8\u6548LLM\u89e3\u7801\u7b56\u7565\u542f\u53d1\u7684\u8f7b\u91cf\u7ea7\u3001\u5148\u9a8c\u6761\u4ef6\u9002\u914d\u5668\u5934\uff0c\u5c06\u4eba\u7c7b\u5148\u9a8c\u76f4\u63a5\u6574\u5408\u5230\u751f\u6210\u5f0f\u63a8\u8350\u5668\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u4e2d\uff0c\u5f15\u5bfc\u6a21\u578b\u6cbf\u7740\u4eba\u7c7b\u53ef\u7406\u89e3\u7684\u8f74\uff08\u5982\u4ea4\u4e92\u7c7b\u578b\u3001\u957f\u671f\u4e0e\u77ed\u671f\u5174\u8da3\uff09\u89e3\u8026\u7528\u6237\u610f\u56fe\u3002\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u7ec4\u5408\u7b56\u7565\uff0c\u7528\u4e8e\u5efa\u6a21\u4e0d\u540c\u5148\u9a8c\u7c7b\u578b\u4e4b\u95f4\u7684\u590d\u6742\u4ea4\u4e92\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u548c\u51c6\u786e\u7387\u4e4b\u5916\u7684\u76ee\u6807\u3002\u4eba\u7c7b\u5148\u9a8c\u4f7f\u5f97\u9aa8\u5e72\u6a21\u578b\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u66f4\u957f\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u66f4\u5927\u7684\u6a21\u578b\u5c3a\u5bf8\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u5c06\u4eba\u7c7b\u5148\u9a8c\u77e5\u8bc6\u878d\u5165\u5230\u751f\u6210\u5f0f\u63a8\u8350\u7cfb\u7edf\u4e2d\uff0c\u63d0\u9ad8\u4e86\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09570", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09570", "abs": "https://arxiv.org/abs/2511.09570", "authors": ["David Woller", "Viktor Koz\u00e1k", "Miroslav Kulich", "Libor P\u0159eu\u010dil"], "title": "Variable Neighborhood Search for the Electric Vehicle Routing Problem", "comment": "19 pages, 6 figures", "summary": "The Electric Vehicle Routing Problem (EVRP) extends the classical Vehicle Routing Problem (VRP) to reflect the growing use of electric and hybrid vehicles in logistics. Due to the variety of constraints considered in the literature, comparing approaches across different problem variants remains challenging. A minimalistic variant of the EVRP, known as the Capacitated Green Vehicle Routing Problem (CGVRP), was the focus of the CEC-12 competition held during the 2020 IEEE World Congress on Computational Intelligence. This paper presents the competition-winning approach, based on the Variable Neighborhood Search (VNS) metaheuristic. The method achieves the best results on the full competition dataset and also outperforms a more recent algorithm published afterward.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86CEC-12\u7ade\u8d5b\u4e2d\u83b7\u80dc\u7684\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u95ee\u9898\uff08EVRP\uff09\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u65b9\u6848\u57fa\u4e8e\u53ef\u53d8\u90bb\u57df\u641c\u7d22\uff08VNS\uff09\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "motivation": "\u7531\u4e8e\u6587\u732e\u4e2d\u8003\u8651\u7684\u7ea6\u675f\u6761\u4ef6\u591a\u79cd\u591a\u6837\uff0c\u56e0\u6b64\u6bd4\u8f83\u4e0d\u540c\u95ee\u9898\u53d8\u4f53\u7684\u65b9\u6848\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u5173\u6ce8 \u0907\u0932\u0947\u0915\u094d\u091f\u094d\u0930\u093f\u0915\u6c7d\u8f66\u8def\u5f84\u95ee\u9898 (EVRP) \u7684\u4e00\u4e2a\u7b80\u5316\u53d8\u4f53\uff0c\u79f0\u4e3a\u6709\u5bb9\u91cf\u7684\u7eff\u8272\u8f66\u8f86\u8def\u5f84\u95ee\u9898 (CGVRP)\u3002", "method": "\u57fa\u4e8e\u53ef\u53d8\u90bb\u57df\u641c\u7d22 (VNS) \u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5b8c\u6574\u7684\u7ade\u8d5b\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u597d\u7684\u7ed3\u679c\uff0c\u5e76\u4e14\u4e5f\u4f18\u4e8e\u4e4b\u540e\u53d1\u5e03\u7684\u66f4\u65b0\u7684\u7b97\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eVNS\u5143\u542f\u53d1\u5f0f\u7b97\u6cd5\u7684\u7535\u52a8\u6c7d\u8f66\u8def\u5f84\u95ee\u9898\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5728\u7ade\u8d5b\u4e2d\u53d6\u5f97\u4e86\u4f18\u5f02\u7684\u6210\u7ee9\u3002"}}
{"id": "2511.09611", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09611", "abs": "https://arxiv.org/abs/2511.09611", "authors": ["Ye Tian", "Ling Yang", "Jiongfan Yang", "Anran Wang", "Yu Tian", "Jiani Zheng", "Haochen Wang", "Zhiyang Teng", "Zhuochen Wang", "Yinjie Wang", "Yunhai Tong", "Mengdi Wang", "Xiangtai Li"], "title": "MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation", "comment": "Project Page: https://tyfeld.github.io/mmadaparellel.github.io/", "summary": "While thinking-aware generation aims to improve performance on complex tasks, we identify a critical failure mode where existing sequential, autoregressive approaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we propose ParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis using ParaBench reveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose a parallel multimodal diffusion framework, MMaDA-Parallel, that enables continuous, bidirectional interaction between text and images throughout the entire denoising trajectory. MMaDA-Parallel is trained with supervised finetuning and then further optimized by Parallel Reinforcement Learning (ParaRL), a novel strategy that applies semantic rewards along the trajectory to enforce cross-modal consistency. Experiments validate that our model significantly improves cross-modal alignment and semantic consistency, achieving a 6.9\\% improvement in Output Alignment on ParaBench compared to the state-of-the-art model, Bagel, establishing a more robust paradigm for thinking-aware image synthesis. Our code is open-sourced at https://github.com/tyfeld/MMaDA-Parallel", "AI": {"tldr": "\u73b0\u6709\u7684\u81ea\u56de\u5f52\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7531\u4e8e\u8bef\u5dee\u4f20\u64ad\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u8bba\u6587\u63d0\u51fa\u4e86 ParaBench \u57fa\u51c6\u6765\u8bc4\u4f30\u6587\u672c\u548c\u56fe\u50cf\u8f93\u51fa\uff0c\u53d1\u73b0\u6027\u80fd\u4e0b\u964d\u4e0e\u751f\u6210\u7684\u63a8\u7406\u548c\u6700\u7ec8\u56fe\u50cf\u4e4b\u95f4\u7684\u5bf9\u9f50\u4e0d\u826f\u6709\u5173\u3002\u56e0\u6b64\uff0c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e76\u884c\u7684\u591a\u6a21\u6001\u6269\u6563\u6846\u67b6 MMaDA-Parallel\uff0c\u901a\u8fc7\u6587\u672c\u548c\u56fe\u50cf\u4e4b\u95f4\u7684\u6301\u7eed\u4ea4\u4e92\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u5e76\u901a\u8fc7 Parallel Reinforcement Learning (ParaRL) \u8fdb\u4e00\u6b65\u4f18\u5316\uff0c\u4ee5\u63d0\u9ad8\u8de8\u6a21\u6001\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u6a21\u578b\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5e8f\u5217\u81ea\u56de\u5f52\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7531\u4e8e\u8bef\u5dee\u4f20\u64ad\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e76\u884c\u7684\u591a\u6a21\u6001\u6269\u6563\u6846\u67b6 MMaDA-Parallel\uff0c\u901a\u8fc7\u6587\u672c\u548c\u56fe\u50cf\u4e4b\u95f4\u7684\u6301\u7eed\u4ea4\u4e92\uff0c\u5e76\u4f7f\u7528 Parallel Reinforcement Learning (ParaRL) \u8fdb\u884c\u4f18\u5316\u3002", "result": "MMaDA-Parallel \u5728 ParaBench \u4e0a\u5b9e\u73b0\u4e86 6.9% \u7684 Output Alignment \u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u6a21\u578b Bagel\u3002", "conclusion": "MMaDA-Parallel \u5efa\u7acb\u4e86\u4e00\u4e2a\u66f4\u5f3a\u5927\u7684\u601d\u7ef4\u611f\u77e5\u56fe\u50cf\u5408\u6210\u8303\u4f8b\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8de8\u6a21\u6001\u5bf9\u9f50\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.09567", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09567", "abs": "https://arxiv.org/abs/2511.09567", "authors": ["Todd Morrill", "Aahlad Puli", "Murad Megjhani", "Soojin Park", "Richard Zemel"], "title": "Let the Experts Speak: Improving Survival Prediction & Calibration via Mixture-of-Experts Heads", "comment": "Accepted as a proceedings paper at the 2025 Machine Learning for Health Symposium and as a workshop paper at the Learning from Time Series for Health workshop at NeurIPS 2025", "summary": "Deep mixture-of-experts models have attracted a lot of attention for survival analysis problems, particularly for their ability to cluster similar patients together. In practice, grouping often comes at the expense of key metrics such calibration error and predictive accuracy. This is due to the restrictive inductive bias that mixture-of-experts imposes, that predictions for individual patients must look like predictions for the group they're assigned to. Might we be able to discover patient group structure, where it exists, while improving calibration and predictive accuracy? In this work, we introduce several discrete-time deep mixture-of-experts (MoE) based architectures for survival analysis problems, one of which achieves all desiderata: clustering, calibration, and predictive accuracy. We show that a key differentiator between this array of MoEs is how expressive their experts are. We find that more expressive experts that tailor predictions per patient outperform experts that rely on fixed group prototypes.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u751f\u5b58\u5206\u6790\u95ee\u9898\u7684\u79bb\u6563\u65f6\u95f4\u6df1\u5ea6\u6df7\u5408\u4e13\u5bb6 (MoE) \u67b6\u6784\uff0c\u8be5\u67b6\u6784\u5b9e\u73b0\u4e86\u6240\u6709\u7406\u60f3\u7684\u7ed3\u679c\uff1a\u805a\u7c7b\u3001\u6821\u51c6\u548c\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u6df1\u5ea6\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u5728\u751f\u5b58\u5206\u6790\u95ee\u9898\u4e2d\u5907\u53d7\u5173\u6ce8\uff0c\u7279\u522b\u662f\u56e0\u4e3a\u5b83\u4eec\u80fd\u591f\u5c06\u76f8\u4f3c\u7684\u60a3\u8005\u805a\u96c6\u5728\u4e00\u8d77\u3002\u5728\u5b9e\u8df5\u4e2d\uff0c\u5206\u7ec4\u901a\u5e38\u4ee5\u5173\u952e\u6307\u6807\uff08\u5982\u6821\u51c6\u8bef\u5dee\u548c\u9884\u6d4b\u51c6\u786e\u6027\uff09\u4e3a\u4ee3\u4ef7\u3002\u8fd9\u662f\u7531\u4e8e\u6df7\u5408\u4e13\u5bb6\u65bd\u52a0\u7684\u9650\u5236\u6027\u5f52\u7eb3\u504f\u5dee\uff0c\u5373\u4e2a\u4f53\u60a3\u8005\u7684\u9884\u6d4b\u5fc5\u987b\u770b\u8d77\u6765\u50cf\u4ed6\u4eec\u6240\u5206\u914d\u5230\u7684\u7fa4\u4f53\u7684\u9884\u6d4b\u3002", "method": "\u672c\u6587\u4ecb\u7ecd\u4e86\u51e0\u79cd\u7528\u4e8e\u751f\u5b58\u5206\u6790\u95ee\u9898\u7684\u79bb\u6563\u65f6\u95f4\u6df1\u5ea6\u6df7\u5408\u4e13\u5bb6 (MoE) \u67b6\u6784\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e00\u7cfb\u5217 MoE \u4e4b\u95f4\u7684\u5173\u952e\u533a\u522b\u5728\u4e8e\u5b83\u4eec\u7684\u4e13\u5bb6\u6709\u591a\u4e48\u5177\u6709\u8868\u73b0\u529b\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4e3a\u6bcf\u4e2a\u60a3\u8005\u5b9a\u5236\u9884\u6d4b\u7684\u66f4\u5177\u8868\u73b0\u529b\u7684\u4e13\u5bb6\u4f18\u4e8e\u4f9d\u8d56\u4e8e\u56fa\u5b9a\u7fa4\u4f53\u539f\u578b\u7684\u4e13\u5bb6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MoE\u67b6\u6784\uff0c\u53ef\u4ee5\u540c\u65f6\u5b9e\u73b0\u805a\u7c7b\u3001\u6821\u51c6\u548c\u9884\u6d4b\u51c6\u786e\u6027\uff0c\u5e76\u4e14\u53d1\u73b0\u66f4\u5177\u8868\u73b0\u529b\u7684\u4e13\u5bb6\u53ef\u4ee5\u63d0\u9ad8\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2511.09796", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09796", "abs": "https://arxiv.org/abs/2511.09796", "authors": ["Rocco Tripodi", "Xiaoyu Liu"], "title": "Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer", "comment": null, "summary": "Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.", "AI": {"tldr": "\u8de8\u8bed\u8a00NLP\u901a\u8fc7\u8fc1\u79fb\u8bed\u8a00\u77e5\u8bc6\u6765\u89e3\u51b3\u4f4e\u8d44\u6e90\u95ee\u9898\uff0c\u4f46\u8bed\u8a00\u5dee\u5f02\u963b\u788d\u4e86\u8fc1\u79fb\uff0c\u5c24\u5176\u662f\u5728\u7c7b\u578b\u5b66\u4e0a\u5dee\u5f02\u5f88\u5927\u7684\u8bed\u8a00\u4e4b\u95f4\u3002", "motivation": "\u63a2\u7d22\u6c49\u82f1\u5e73\u884c\u53e5\u4e2d\u8c13\u8bcd-\u8bba\u5143\u7ed3\u6784\u7684\u5bf9\u9f50\u548c\u4e0d\u5bf9\u9f50\u73b0\u8c61\u3002", "method": "\u5206\u6790\u8c13\u8bcd\u6ce8\u91ca\u7684\u5bf9\u9f50\u548c\u4e0d\u5bf9\u9f50\uff0c\u68c0\u67e5\u5f02\u540c\uff0c\u5e76\u63d0\u51fa\u7ed3\u6784\u5dee\u5f02\u7684\u5206\u7c7b\u3002\u901a\u8fc7\u6ce8\u91ca\u6295\u5f71\u5b9e\u9a8c\u7684\u7ed3\u679c\u8fdb\u884c\u5b9a\u6027\u548c\u5b9a\u91cf\u5206\u6790\u6765\u652f\u6301\u5206\u6790\u548c\u5206\u7c7b\u3002", "result": "\u8bed\u8a00\u8fc1\u79fb\u662f\u4e0d\u5bf9\u79f0\u7684\u3002", "conclusion": "\u5728\u8fc1\u79fb\u5b66\u4e60\u5e94\u7528\u4e2d\u9009\u62e9\u6e90\u8bed\u8a00\u65f6\uff0c\u9700\u8981\u6ce8\u610f\u8bed\u8a00\u8fc1\u79fb\u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u5e76\u4e14\u5728\u63d0\u51fa\u5173\u4e8e\u8de8\u8bed\u8a00NLP\u7684\u4efb\u4f55\u79d1\u5b66\u4e3b\u5f20\u4e4b\u524d\uff0c\u90fd\u9700\u8981\u5bf9\u5176\u8fdb\u884c\u8c03\u67e5\u3002"}}
{"id": "2511.10192", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.10192", "abs": "https://arxiv.org/abs/2511.10192", "authors": ["Qifeng Cai", "Hao Liang", "Chang Xu", "Tao Xie", "Wentao Zhang", "Bin Cui"], "title": "Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL", "comment": null, "summary": "The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aText2SQL-Flow\u7684SQL-aware\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u7528\u4e8e\u4ece\u5c11\u91cf\u79cd\u5b50\u6570\u636e\u751f\u6210\u5927\u89c4\u6a21\u3001\u8bed\u4e49\u6709\u6548\u3001\u7ed3\u6784\u591a\u6837\u7684Text-to-SQL\u5bf9\uff0c\u4ece\u800c\u89e3\u51b3Text-to-SQL\u4efb\u52a1\u4e2d\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u7b80\u5355\u548c\u4f4e\u591a\u6837\u6027\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684Text-to-SQL\u6570\u636e\u96c6\u7a00\u7f3a\u3001\u7b80\u5355\u548c\u4f4e\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86AI\u7684\u6027\u80fd\u3002", "method": "\u8be5\u6846\u67b6\u901a\u8fc7\u516d\u4e2a\u589e\u5f3a\u7ef4\u5ea6\u8fd0\u884c\uff0c\u5e76\u96c6\u6210\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7ba1\u9053\uff0c\u5305\u62ecSQL\u6267\u884c\u9a8c\u8bc1\u3001\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u751f\u6210\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u8ffd\u8e2a\u548c\u6570\u636e\u5206\u7c7b\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u4e2a\u6a21\u5757\u5316\u6570\u636e\u5e93\u7ba1\u7406\u5668\uff0c\u4ee5\u786e\u4fdd\u8de8\u6570\u636e\u5e93\u517c\u5bb9\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "result": "\u4f7f\u7528\u8be5\u6846\u67b6\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u6570\u636e\u96c6SQLFlow\uff0c\u5305\u542b89,544\u4e2a\u5e26\u6ce8\u91ca\u7684\u793a\u4f8b\u3002\u5728\u5f00\u6e90LLM\u4e0a\u8fdb\u884c\u5fae\u8c03\u4ee5\u53ca\u5728\u95ed\u6e90LLM\u4e0a\u4f7f\u7528masked alignment retrieval\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u7ed3\u679c\u8868\u660eSQLFlow\u6570\u636e\u96c6\u548c\u6240\u63d0\u51fa\u7684\u68c0\u7d22\u7b56\u7565\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u3001\u4ee5\u6570\u636e\u4e3a\u4e2d\u5fc3\u7684Text-to-SQL\u7cfb\u7edf\u57fa\u7840\uff0c\u5e76\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u7ed3\u6784\u5316\u6570\u636e\u5728\u73b0\u4ee3AI\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002"}}
{"id": "2511.10277", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.10277", "abs": "https://arxiv.org/abs/2511.10277", "authors": ["Martin Braas", "Lukas Esterle"], "title": "Fixed-Persona SLMs with Modular Memory: Scalable NPC Dialogue on Consumer Hardware", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in generating human-like text, yet their applicability to dialogue systems in computer games remains limited. This limitation arises from their substantial hardware requirements, latency constraints, and the necessity to maintain clearly defined knowledge boundaries within a game setting. In this paper, we propose a modular NPC dialogue system that leverages Small Language Models (SLMs), fine-tuned to encode specific NPC personas and integrated with runtime-swappable memory modules. These memory modules preserve character-specific conversational context and world knowledge, enabling expressive interactions and long-term memory without retraining or model reloading during gameplay. We comprehensively evaluate our system using three open-source SLMs: DistilGPT-2, TinyLlama-1.1B-Chat, and Mistral-7B-Instruct, trained on synthetic persona-aligned data and benchmarked on consumer-grade hardware. While our approach is motivated by applications in gaming, its modular design and persona-driven memory architecture hold significant potential for broader adoption in domains requiring expressive, scalable, and memory-rich conversational agents, such as virtual assistants, customer support bots, or interactive educational systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u5757\u5316\u7684NPC\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u5229\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(slm)\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u7f16\u7801\u7279\u5b9a\u7684NPC\u89d2\u8272\uff0c\u5e76\u4e0e\u8fd0\u884c\u65f6\u53ef\u4ea4\u6362\u7684\u8bb0\u5fc6\u6a21\u5757\u96c6\u6210\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b(llm)\u5728\u751f\u6210\u7c7b\u4eba\u6587\u672c\u65b9\u9762\u8868\u73b0\u51fa\u4e86\u5353\u8d8a\u7684\u80fd\u529b\uff0c\u4f46\u5176\u5728\u8ba1\u7b97\u673a\u6e38\u620f\u4e2d\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u7684\u9002\u7528\u6027\u4ecd\u7136\u6709\u9650\u3002\u8fd9\u79cd\u9650\u5236\u6765\u81ea\u4e8e\u5b83\u4eec\u5927\u91cf\u7684\u786c\u4ef6\u9700\u6c42\u3001\u5ef6\u8fdf\u7ea6\u675f\u4ee5\u53ca\u5728\u6e38\u620f\u73af\u5883\u4e2d\u4fdd\u6301\u6e05\u6670\u5b9a\u4e49\u7684\u77e5\u8bc6\u8fb9\u754c\u7684\u5fc5\u8981\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u5229\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b(slm)\u8fdb\u884c\u5fae\u8c03\uff0c\u4ee5\u7f16\u7801\u7279\u5b9a\u7684NPC\u89d2\u8272\uff0c\u5e76\u4e0e\u8fd0\u884c\u65f6\u53ef\u4ea4\u6362\u7684\u8bb0\u5fc6\u6a21\u5757\u96c6\u6210\u3002\u8fd9\u4e9b\u8bb0\u5fc6\u6a21\u5757\u4fdd\u5b58\u7279\u5b9a\u4e8e\u89d2\u8272\u7684\u4f1a\u8bdd\u4e0a\u4e0b\u6587\u548c\u4e16\u754c\u77e5\u8bc6\uff0c\u4ece\u800c\u5b9e\u73b0\u8868\u8fbe\u6027\u4ea4\u4e92\u548c\u957f\u671f\u8bb0\u5fc6\uff0c\u800c\u65e0\u9700\u5728\u6e38\u620f\u8fc7\u7a0b\u4e2d\u8fdb\u884c\u518d\u8bad\u7ec3\u6216\u6a21\u578b\u91cd\u65b0\u52a0\u8f7d\u3002", "result": "\u4f7f\u7528\u4e09\u4e2a\u5f00\u6e90SLM\u5bf9\u7cfb\u7edf\u8fdb\u884c\u4e86\u7efc\u5408\u8bc4\u4f30:DistilGPT-2\u3001TinyLlama-1.1B-Chat\u548cMistral-7B-Instruct\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u5408\u6210\u7684\u89d2\u8272\u5bf9\u9f50\u6570\u636e\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u5728\u6d88\u8d39\u7ea7\u786c\u4ef6\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "conclusion": "\u867d\u7136\u8be5\u65b9\u6cd5\u662f\u7531\u6e38\u620f\u4e2d\u7684\u5e94\u7528\u6240\u9a71\u52a8\u7684\uff0c\u4f46\u5176\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u89d2\u8272\u9a71\u52a8\u7684\u8bb0\u5fc6\u67b6\u6784\u5728\u9700\u8981\u8868\u8fbe\u6027\u3001\u53ef\u4f38\u7f29\u6027\u548c\u8bb0\u5fc6\u4e30\u5bcc\u7684\u4f1a\u8bdd\u4ee3\u7406\u7684\u9886\u57df\u4e2d\u5177\u6709\u66f4\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5982\u865a\u62df\u52a9\u624b\u3001\u5ba2\u6237\u652f\u6301\u673a\u5668\u4eba\u6216\u4ea4\u4e92\u5f0f\u6559\u80b2\u7cfb\u7edf\u3002"}}
{"id": "2511.09572", "categories": ["cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.09572", "abs": "https://arxiv.org/abs/2511.09572", "authors": ["Tommaso Castellani", "Naimeng Ye", "Daksh Mittal", "Thomson Yen", "Hongseok Namkoong"], "title": "SynthTools: A Framework for Scaling Synthetic Tools for Agent Development", "comment": null, "summary": "AI agents increasingly rely on external tools to solve complex, long-horizon tasks. Advancing such agents requires reproducible evaluation and large-scale training in controllable, diverse, and realistic tool-use environments. However, real-world APIs are limited in availability, domain coverage, and stability, often requiring access keys and imposing rate limits, which render them impractical for stable evaluation or scalable training. To address these challenges, we introduce SynthTools, a flexible and scalable framework for generating synthetic tool ecosystems. Our framework consists of three core components: Tool Generation for automatic and scalable creation of diverse tools, Tool Simulation to emulate realistic tool behaviors, and Tool Audit to ensure correctness and consistency of tool simulation. To illustrate its scalability, we show that SynthTools can readily produce toolsets that span twice as many domains and twice as many tools per domain as prior work. Furthermore, the tool simulation and tool audit components demonstrate strong reliability, achieving $94\\%$ and $99\\%$ accuracy respectively. Finally, we construct downstream tasks from the generated tools that even state-of-the-art models struggle to complete. By enabling scalable, diverse, and reliable tool ecosystems, SynthTools provides a practical path toward large-scale training and stable evaluation of tool-use agents. Our code is available at https://github.com/namkoong-lab/SynthTools.", "AI": {"tldr": "SynthTools\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u5408\u6210\u5de5\u5177\u751f\u6001\u7cfb\u7edf\u7684\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u6846\u67b6\uff0c\u5b83\u89e3\u51b3\u4e86\u771f\u5b9e\u4e16\u754cAPI\u5728\u53ef\u7528\u6027\u3001\u9886\u57df\u8986\u76d6\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u4ece\u800c\u4fc3\u8fdb\u4e86\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u7a33\u5b9a\u8bc4\u4f30\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u771f\u5b9e\u4e16\u754cAPI\u5728\u53ef\u7528\u6027\u3001\u9886\u57df\u8986\u76d6\u548c\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u8fd9\u4e9b\u5c40\u9650\u6027\u4f7f\u5f97\u5b83\u4eec\u4e0d\u9002\u5408\u7a33\u5b9a\u8bc4\u4f30\u6216\u53ef\u6269\u5c55\u8bad\u7ec3\u3002", "method": "\u8be5\u6846\u67b6\u5305\u542b\u4e09\u4e2a\u6838\u5fc3\u7ec4\u4ef6\uff1a\u5de5\u5177\u751f\u6210\uff08\u7528\u4e8e\u81ea\u52a8\u548c\u53ef\u6269\u5c55\u5730\u521b\u5efa\u591a\u6837\u5316\u7684\u5de5\u5177\uff09\u3001\u5de5\u5177\u6a21\u62df\uff08\u7528\u4e8e\u6a21\u62df\u771f\u5b9e\u7684\u5de5\u5177\u884c\u4e3a\uff09\u548c\u5de5\u5177\u5ba1\u8ba1\uff08\u7528\u4e8e\u786e\u4fdd\u5de5\u5177\u6a21\u62df\u7684\u6b63\u786e\u6027\u548c\u4e00\u81f4\u6027\uff09\u3002", "result": "SynthTools\u53ef\u4ee5\u8f7b\u677e\u751f\u6210\u5de5\u5177\u96c6\uff0c\u5176\u8de8\u8d8a\u7684\u9886\u57df\u6570\u91cf\u548c\u6bcf\u4e2a\u9886\u57df\u7684\u5de5\u5177\u6570\u91cf\u662f\u5148\u524d\u5de5\u4f5c\u7684\u4e24\u500d\u3002\u5de5\u5177\u6a21\u62df\u548c\u5de5\u5177\u5ba1\u8ba1\u7ec4\u4ef6\u8868\u73b0\u51fa\u5f88\u5f3a\u7684\u53ef\u9760\u6027\uff0c\u5206\u522b\u8fbe\u523094%\u548c99%\u7684\u51c6\u786e\u7387\u3002\u7531\u751f\u6210\u7684\u5de5\u5177\u6784\u5efa\u7684\u4e0b\u6e38\u4efb\u52a1\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u5f88\u96be\u5b8c\u6210\u3002", "conclusion": "SynthTools\u901a\u8fc7\u542f\u7528\u53ef\u6269\u5c55\u3001\u591a\u6837\u5316\u548c\u53ef\u9760\u7684\u5de5\u5177\u751f\u6001\u7cfb\u7edf\uff0c\u4e3a\u5de5\u5177\u4f7f\u7528\u4ee3\u7406\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u548c\u7a33\u5b9a\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u6761\u53ef\u884c\u7684\u9014\u5f84\u3002"}}
{"id": "2511.09675", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09675", "abs": "https://arxiv.org/abs/2511.09675", "authors": ["Felix B. Mueller", "Jan F. Meier", "Timo Lueddecke", "Richard Vogg", "Roger L. Freixanet", "Valentin Hassler", "Tiffany Bosshard", "Elif Karakoc", "William J. O'Hearn", "Sofia M. Pereira", "Sandro Sehner", "Kaja Wierucka", "Judith Burkart", "Claudia Fichtel", "Julia Fischer", "Alexander Gail", "Catherine Hobaiter", "Julia Ostner", "Liran Samuni", "Oliver Sch\u00fclke", "Neda Shahidi", "Erin G. Wessling", "Alexander S. Ecker"], "title": "PriVi: Towards A General-Purpose Video Model For Primate Behavior In The Wild", "comment": null, "summary": "Non-human primates are our closest living relatives, and analyzing their behavior is central to research in cognition, evolution, and conservation. Computer vision could greatly aid this research, but existing methods often rely on human-centric pretrained models and focus on single datasets, which limits generalization. We address this limitation by shifting from a model-centric to a data-centric approach and introduce PriVi, a large-scale primate-centric video pretraining dataset. PriVi contains 424 hours of curated video, combining 174 hours from behavioral research across 11 settings with 250 hours of diverse web-sourced footage, assembled through a scalable data curation pipeline. We pretrain V-JEPA on PriVi to learn primate-specific representations and evaluate it using a lightweight frozen classifier. Across four benchmark datasets, ChimpACT, BaboonLand, PanAf500, and ChimpBehave, our approach consistently outperforms prior work, including fully finetuned baselines, and scales favorably with fewer labels. These results demonstrate that primate-centric pretraining substantially improves data efficiency and generalization, making it a promising approach for low-label applications. Code, models, and the majority of the dataset will be made available.", "AI": {"tldr": "\u63d0\u51fa\u4e86PriVi\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u4ee5\u7075\u957f\u7c7b\u52a8\u7269\u4e3a\u4e2d\u5fc3\u7684\u89c6\u9891\u9884\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u63d0\u5347\u8ba1\u7b97\u673a\u89c6\u89c9\u5728\u7075\u957f\u7c7b\u52a8\u7269\u884c\u4e3a\u5206\u6790\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5e76\u4e14\u4e13\u6ce8\u4e8e\u5355\u4e2a\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b424\u5c0f\u65f6\u89c6\u9891\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6PriVi\uff0c\u5e76\u4f7f\u7528V-JEPA\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u5b66\u4e60\u7279\u5b9a\u4e8e\u7075\u957f\u7c7b\u52a8\u7269\u7684\u8868\u5f81\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5305\u62ec\u5b8c\u5168\u5fae\u8c03\u7684\u57fa\u7ebf\uff0c\u5e76\u4e14\u80fd\u4ee5\u66f4\u5c11\u7684\u6807\u7b7e\u8fdb\u884c\u6269\u5c55\u3002", "conclusion": "\u4ee5\u7075\u957f\u7c7b\u52a8\u7269\u4e3a\u4e2d\u5fc3\u7684\u9884\u8bad\u7ec3\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6570\u636e\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4f7f\u5176\u6210\u4e3a\u4f4e\u6807\u7b7e\u5e94\u7528\u7684\u4e00\u79cd\u6709\u524d\u666f\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.09569", "categories": ["cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.09569", "abs": "https://arxiv.org/abs/2511.09569", "authors": ["George Stamatelis", "George C. Alexandropoulos"], "title": "Filtering Jump Markov Systems with Partially Known Dynamics: A Model-Based Deep Learning Approach", "comment": "Submitted to an IEEE transactions journal, copyright may be transfered upon acceptance", "summary": "This paper presents the Jump Markov Filtering Network (JMFNet), a novel model-based deep learning framework for real-time state-state estimation in jump Markov systems with unknown noise statistics and mode transition dynamics. A hybrid architecture comprising two Recurrent Neural Networks (RNNs) is proposed: one for mode prediction and another for filtering that is based on a mode-augmented version of the recently presented KalmanNet architecture. The proposed RNNs are trained jointly using an alternating least squares strategy that enables mutual adaptation without supervision of the latent modes. Extensive numerical experiments on linear and nonlinear systems, including target tracking, pendulum angle tracking, Lorenz attractor dynamics, and a real-life dataset demonstrate that the proposed JMFNet framework outperforms classical model-based filters (e.g., interacting multiple models and particle filters) as well as model-free deep learning baselines, particularly in non-stationary and high-noise regimes. It is also showcased that JMFNet achieves a small yet meaningful improvement over the KalmanNet framework, which becomes much more pronounced in complicated systems or long trajectories. Finally, the method's performance is empirically validated to be consistent and reliable, exhibiting low sensitivity to initial conditions, hyperparameter selection, as well as to incorrect model knowledge", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8df3\u8dc3\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2d\u5b9e\u65f6\u72b6\u6001\u4f30\u8ba1\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6JMFNet\uff0c\u8be5\u6846\u67b6\u65e0\u9700\u566a\u58f0\u7edf\u8ba1\u548c\u6a21\u5f0f\u8f6c\u6362\u52a8\u6001\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "motivation": "\u5728\u5177\u6709\u672a\u77e5\u566a\u58f0\u7edf\u8ba1\u548c\u6a21\u5f0f\u8f6c\u6362\u52a8\u6001\u7684\u8df3\u8dc3\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2d\uff0c\u5b9e\u73b0\u5b9e\u65f6\u7684\u72b6\u6001\u4f30\u8ba1\u3002", "method": "\u8be5\u6846\u67b6\u5305\u542b\u4e24\u4e2a\u5faa\u73af\u795e\u7ecf\u7f51\u7edc(RNN):\u4e00\u4e2a\u7528\u4e8e\u6a21\u5f0f\u9884\u6d4b\uff0c\u53e6\u4e00\u4e2a\u7528\u4e8e\u6ee4\u6ce2\uff0c\u5b83\u57fa\u4e8e\u6700\u8fd1\u63d0\u51fa\u7684KalmanNet\u67b6\u6784\u7684\u6a21\u5f0f\u589e\u5f3a\u7248\u672c\u3002\u4f7f\u7528\u4ea4\u66ff\u6700\u5c0f\u4e8c\u4e58\u7b56\u7565\u8054\u5408\u8bad\u7ec3\u6240\u63d0\u51fa\u7684RNN\uff0c\u4ee5\u5b9e\u73b0\u65e0\u9700\u6f5c\u5728\u6a21\u5f0f\u76d1\u7763\u7684\u76f8\u4e92\u9002\u5e94\u3002", "result": "\u5728\u5305\u62ec\u76ee\u6807\u8ddf\u8e2a\u3001\u5355\u6446\u89d2\u5ea6\u8ddf\u8e2a\u3001Lorenz\u5438\u5f15\u5b50\u52a8\u529b\u5b66\u548c\u771f\u5b9e\u6570\u636e\u96c6\u5728\u5185\u7684\u7ebf\u6027\u53ca\u975e\u7ebf\u6027\u7cfb\u7edf\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684JMFNet\u6846\u67b6\u4f18\u4e8e\u7ecf\u5178\u7684\u57fa\u4e8e\u6a21\u578b\u7684\u6ee4\u6ce2\u5668(\u4f8b\u5982\uff0c\u4ea4\u4e92\u5f0f\u591a\u6a21\u578b\u548c\u7c92\u5b50\u6ee4\u6ce2\u5668)\u4ee5\u53ca\u65e0\u6a21\u578b\u7684\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0c\u5c24\u5176\u662f\u5728\u975e\u5e73\u7a33\u548c\u9ad8\u566a\u58f0\u60c5\u51b5\u4e0b\u3002JMFNet\u5728\u590d\u6742\u7cfb\u7edf\u6216\u957f\u8f68\u8ff9\u4e2d\uff0c\u76f8\u5bf9\u4e8eKalmanNet\u6846\u67b6\uff0c\u6027\u80fd\u6709\u5c0f\u5e45\u4f46\u610f\u4e49\u91cd\u5927\u7684\u63d0\u5347\u3002\u8be5\u65b9\u6cd5\u7684\u6027\u80fd\u7ecf\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5177\u6709\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\uff0c\u5bf9\u521d\u59cb\u6761\u4ef6\u3001\u8d85\u53c2\u6570\u9009\u62e9\u4ee5\u53ca\u4e0d\u6b63\u786e\u7684\u6a21\u578b\u77e5\u8bc6\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684JMFNet\u6846\u67b6\u5728\u8df3\u8dc3\u9a6c\u5c14\u53ef\u592b\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u4f18\u5f02\u7684\u5b9e\u65f6\u72b6\u6001\u4f30\u8ba1\u6027\u80fd\uff0c\u5e76\u4e14\u5bf9\u5404\u79cd\u56e0\u7d20\u5177\u6709\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.09803", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09803", "abs": "https://arxiv.org/abs/2511.09803", "authors": ["Yufeng Wang", "Lu wei", "Haibin Ling"], "title": "TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a TARG \u7684\u514d\u8bad\u7ec3\u81ea\u9002\u5e94\u68c0\u7d22\u95e8\u63a7\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u51b3\u5b9a\u4f55\u65f6\u68c0\u7d22\uff0c\u4ec5\u4f7f\u7528\u6765\u81ea\u57fa\u672c\u6a21\u578b\u7684\u7b80\u77ed\u3001\u65e0\u4e0a\u4e0b\u6587\u7684\u8349\u7a3f\u3002", "motivation": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210 (RAG) \u63d0\u9ad8\u4e86\u4e8b\u5b9e\u6027\uff0c\u4f46\u4e3a\u6bcf\u4e2a\u67e5\u8be2\u8fdb\u884c\u68c0\u7d22\u901a\u5e38\u4f1a\u635f\u5bb3\u8d28\u91cf\uff0c\u540c\u65f6\u589e\u52a0 tokens \u548c\u5ef6\u8fdf\u3002", "method": "TARG \u4ec5\u4f7f\u7528\u6765\u81ea\u57fa\u672c\u6a21\u578b\u7684\u7b80\u77ed\u3001\u65e0\u4e0a\u4e0b\u6587\u7684\u8349\u7a3f\u6765\u51b3\u5b9a\u4f55\u65f6\u68c0\u7d22\u3002\u4ece\u8349\u7a3f\u7684\u524d\u7f00 logits \u4e2d\uff0cTARG \u8ba1\u7b97\u8f7b\u91cf\u7ea7\u4e0d\u786e\u5b9a\u6027\u5206\u6570\uff1a\u5e73\u5747 token \u71b5\u3001\u901a\u8fc7\u5355\u8c03\u94fe\u63a5\u4ece\u524d 1/top-2 logit \u5dee\u8ddd\u5bfc\u51fa\u7684\u8fb9\u9645\u4fe1\u53f7\uff0c\u6216\u5c11\u91cf\u968f\u673a\u524d\u7f00\u4e0a\u7684\u5c0f N \u65b9\u5dee\uff0c\u5e76\u4e14\u4ec5\u5f53\u5206\u6570\u8d85\u8fc7\u9608\u503c\u65f6\u624d\u89e6\u53d1\u68c0\u7d22\u3002", "result": "\u5728 NQ-Open\u3001TriviaQA \u548c PopQA \u4e0a\uff0c\u4e0e Always-RAG \u76f8\u6bd4\uff0cTARG \u5728\u5339\u914d\u6216\u63d0\u9ad8 EM/F1 \u7684\u540c\u65f6\uff0c\u5c06\u68c0\u7d22\u51cf\u5c11\u4e86 70-90%\uff0c\u5e76\u51cf\u5c11\u4e86\u7aef\u5230\u7aef\u5ef6\u8fdf\uff0c\u5e76\u4e14\u5728\u5f00\u9500\u65b9\u9762\u4ecd\u7136\u63a5\u8fd1 Never-RAG\u3002", "conclusion": "\u5728\u73b0\u4ee3\u6307\u4ee4\u8c03\u6574\u7684\u6cd5\u5b66\u7855\u58eb\u4e0b\uff0c\u8fb9\u9645\u4fe1\u53f7\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u9ed8\u8ba4\u503c\uff08\u71b5\u968f\u7740\u9aa8\u5e72\u9510\u5316\u800c\u538b\u7f29\uff09\uff0c\u5c0f N \u65b9\u5dee\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4fdd\u5b88\u7684\u3001\u9884\u7b97\u4f18\u5148\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2511.09575", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09575", "abs": "https://arxiv.org/abs/2511.09575", "authors": ["Ha-Thanh Nguyen", "Ken Satoh", "Francesca Toni", "Randy Goebel", "Kostas Stathis"], "title": "Proceedings of the Second International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2025)", "comment": null, "summary": "Reasoning is an essential component of human intelligence in that it plays a fundamental role in our ability to think critically, support responsible decisions, and solve challenging problems. Traditionally, AI has addressed reasoning in the context of logic-based representations of knowledge. However, the recent leap forward in natural language processing, with the emergence of language models based on transformers, is hinting at the possibility that these models exhibit reasoning abilities, particularly as they grow in size and are trained on more and more data. Still, despite ongoing discussions about what reasoning is in language models, it is still not easy to articulate to what extent these models are actually capable of reasoning.\n  The goal of this workshop is to create a platform for researchers from different disciplines and/or AI perspectives to explore approaches and techniques with the aim to reconcile reasoning between language models using transformers and logic-based representations. The specific objectives include analysing the reasoning abilities of language models measured alongside KR methods, injecting KR-style reasoning abilities into language models (including by neuro-symbolic means), and formalising the kind of reasoning language models carry out. This exploration aims to uncover how language models can effectively integrate and leverage knowledge and reasoning with it, thus improving their application and utility in areas where precision and reliability are key requirements.", "AI": {"tldr": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u5907\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63a2\u8ba8\u5982\u4f55\u5c06\u903b\u8f91\u63a8\u7406\u878d\u5165\u8fd9\u4e9b\u6a21\u578b\u3002", "motivation": "\u8bc4\u4f30\u548c\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f7f\u5176\u5728\u9700\u8981\u7cbe\u786e\u6027\u548c\u53ef\u9760\u6027\u7684\u9886\u57df\u66f4\u6709\u7528\u3002", "method": "\u901a\u8fc7\u7814\u8ba8\u4f1a\u5f62\u5f0f\uff0c\u805a\u96c6\u4e0d\u540c\u5b66\u79d1\u548cAI\u89c6\u89d2\u7684\u7814\u7a76\u4eba\u5458\uff0c\u5171\u540c\u63a2\u7d22\u3002", "result": "\u76ee\u6807\u662f\u5206\u6790\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5c06\u77e5\u8bc6\u8868\u793a\u7684\u63a8\u7406\u80fd\u529b\u6ce8\u5165\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5f62\u5f0f\u5316\u8bed\u8a00\u6a21\u578b\u6267\u884c\u7684\u63a8\u7406\u3002", "conclusion": "\u65e8\u5728\u6574\u5408\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u9ad8\u5176\u5e94\u7528\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.09702", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09702", "abs": "https://arxiv.org/abs/2511.09702", "authors": ["Katie Matton", "Purvaja Balaji", "Hamzeh Ghasemzadeh", "Jameson C. Cooper", "Daryush D. Mehta", "Jarrad H. Van Stan", "Robert E. Hillman", "Rosalind Picard", "John Guttag", "S. Mazdak Abulnaga"], "title": "Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression", "comment": "16 pages, 9 figures, 5 tables; ML4H 2025; Proceedings of Machine Learning Research 297, 2025", "summary": "Phonotrauma refers to vocal fold tissue damage resulting from exposure to forces during voicing. It occurs on a continuum from mild to severe, and treatment options can vary based on severity. Assessment of severity involves a clinician's expert judgment, which is costly and can vary widely in reliability. In this work, we present the first method for automatically classifying phonotrauma severity from vocal fold images. To account for the ordinal nature of the labels, we adopt a widely used ordinal regression framework. To account for label uncertainty, we propose a novel modification to ordinal regression loss functions that enables them to operate on soft labels reflecting annotator rating distributions. Our proposed soft ordinal regression method achieves predictive performance approaching that of clinical experts, while producing well-calibrated uncertainty estimates. By providing an automated tool for phonotrauma severity assessment, our work can enable large-scale studies of phonotrauma, ultimately leading to improved clinical understanding and patient care.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4ece\u58f0\u5e26\u56fe\u50cf\u81ea\u52a8\u5206\u7c7b\u58f0\u5e26\u635f\u4f24\u7a0b\u5ea6\u7684\u65b9\u6cd5\u3002", "motivation": "\u4e34\u5e8a\u533b\u751f\u5bf9\u58f0\u5e26\u635f\u4f24\u7a0b\u5ea6\u7684\u8bc4\u4f30\u6210\u672c\u9ad8\uff0c\u53ef\u9760\u6027\u5dee\u5f02\u5927\u3002", "method": "\u8be5\u65b9\u6cd5\u91c7\u7528\u4e86\u4e00\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u5e8f\u6570\u56de\u5f52\u6846\u67b6\uff0c\u5e76\u9488\u5bf9\u6807\u7b7e\u4e0d\u786e\u5b9a\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5e8f\u6570\u56de\u5f52\u635f\u5931\u51fd\u6570\u4fee\u6539\u65b9\u6cd5\uff0c\u4f7f\u5176\u80fd\u591f\u5bf9\u53cd\u6620\u6ce8\u91ca\u8005\u8bc4\u5206\u5206\u5e03\u7684\u8f6f\u6807\u7b7e\u8fdb\u884c\u64cd\u4f5c\u3002", "result": "\u6240\u63d0\u51fa\u7684\u8f6f\u5e8f\u6570\u56de\u5f52\u65b9\u6cd5\u5b9e\u73b0\u4e86\u63a5\u8fd1\u4e34\u5e8a\u4e13\u5bb6\u7684\u9884\u6d4b\u6027\u80fd\uff0c\u540c\u65f6\u4ea7\u751f\u4e86\u826f\u597d\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "conclusion": "\u901a\u8fc7\u63d0\u4f9b\u4e00\u79cd\u81ea\u52a8\u5316\u7684\u58f0\u5e26\u635f\u4f24\u7a0b\u5ea6\u8bc4\u4f30\u5de5\u5177\uff0c\u8be5\u7814\u7a76\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u58f0\u5e26\u635f\u4f24\u7684\u5927\u89c4\u6a21\u7814\u7a76\uff0c\u6700\u7ec8\u63d0\u9ad8\u4e34\u5e8a\u7406\u89e3\u548c\u60a3\u8005\u62a4\u7406\u6c34\u5e73\u3002"}}
{"id": "2511.09573", "categories": ["cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2511.09573", "abs": "https://arxiv.org/abs/2511.09573", "authors": ["Valentino F. Foit", "David W. Hogg", "Soledad Villar"], "title": "Group Averaging for Physics Applications: Accuracy Improvements at Zero Training Cost", "comment": "10 pages, 2 figures, 1 table, Machine Learning and the Physical Sciences Workshop, NeurIPS 2025", "summary": "Many machine learning tasks in the natural sciences are precisely equivariant to particular symmetries. Nonetheless, equivariant methods are often not employed, perhaps because training is perceived to be challenging, or the symmetry is expected to be learned, or equivariant implementations are seen as hard to build. Group averaging is an available technique for these situations. It happens at test time; it can make any trained model precisely equivariant at a (often small) cost proportional to the size of the group; it places no requirements on model structure or training. It is known that, under mild conditions, the group-averaged model will have a provably better prediction accuracy than the original model. Here we show that an inexpensive group averaging can improve accuracy in practice. We take well-established benchmark machine learning models of differential equations in which certain symmetries ought to be obeyed. At evaluation time, we average the models over a small group of symmetries. Our experiments show that this procedure always decreases the average evaluation loss, with improvements of up to 37\\% in terms of the VRMSE. The averaging produces visually better predictions for continuous dynamics. This short paper shows that, under certain common circumstances, there are no disadvantages to imposing exact symmetries; the ML4PS community should consider group averaging as a cheap and simple way to improve model accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u63d0\u9ad8\u6a21\u578b\u7cbe\u5ea6\u7684\u65b9\u6cd5\uff0c\u5373\u5728\u6d4b\u8bd5\u65f6\u4f7f\u7528\u7fa4\u5e73\u5747\uff0c\u901a\u8fc7\u5bf9\u6a21\u578b\u5728\u5bf9\u79f0\u7fa4\u4e0a\u7684\u5e73\u5747\u6765\u5f3a\u5236\u6267\u884c\u7cbe\u786e\u5bf9\u79f0\u6027\u3002", "motivation": "\u5728\u81ea\u7136\u79d1\u5b66\u4e2d\u7684\u8bb8\u591a\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u5728\u7279\u5b9a\u5bf9\u79f0\u6027\u4e0b\u662f\u7cbe\u786e\u7b49\u53d8\u7684\uff0c\u4f46\u7b49\u53d8\u65b9\u6cd5\u901a\u5e38\u672a\u88ab\u91c7\u7528\uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u8bad\u7ec3\u88ab\u8ba4\u4e3a\u5177\u6709\u6311\u6218\u6027\uff0c\u6216\u8005\u671f\u671b\u5b66\u4e60\u5bf9\u79f0\u6027\uff0c\u6216\u8005\u7b49\u53d8\u5b9e\u73b0\u88ab\u8ba4\u4e3a\u96be\u4ee5\u6784\u5efa\u3002", "method": "\u8be5\u65b9\u6cd5\u5728\u6d4b\u8bd5\u65f6\u8fdb\u884c\u7fa4\u5e73\u5747\uff0c\u901a\u8fc7\u5728\u5bf9\u79f0\u7fa4\u4e0a\u5e73\u5747\u6a21\u578b\u6765\u5f3a\u5236\u6267\u884c\u7cbe\u786e\u5bf9\u79f0\u6027\u3002\u5b83\u5bf9\u6a21\u578b\u7ed3\u6784\u6216\u8bad\u7ec3\u6ca1\u6709\u8981\u6c42\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u7a0b\u5e8f\u59cb\u7ec8\u4f1a\u964d\u4f4e\u5e73\u5747\u8bc4\u4f30\u635f\u5931\uff0c\u5728 VRMSE \u65b9\u9762\u6700\u591a\u53ef\u63d0\u9ad8 37%\u3002\u5e73\u5747\u53ef\u4ee5\u4e3a\u8fde\u7eed\u52a8\u529b\u5b66\u4ea7\u751f\u89c6\u89c9\u4e0a\u66f4\u597d\u7684\u9884\u6d4b\u3002", "conclusion": "\u5728\u67d0\u4e9b\u5e38\u89c1\u60c5\u51b5\u4e0b\uff0c\u65bd\u52a0\u7cbe\u786e\u5bf9\u79f0\u6027\u6ca1\u6709\u4efb\u4f55\u7f3a\u70b9\uff1bML4PS \u793e\u533a\u5e94\u8003\u8651\u5c06\u7fa4\u5e73\u5747\u4f5c\u4e3a\u4e00\u79cd\u5ec9\u4ef7\u4e14\u7b80\u5355\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8\u6a21\u578b\u7cbe\u5ea6\u3002"}}
{"id": "2511.09812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09812", "abs": "https://arxiv.org/abs/2511.09812", "authors": ["Marry Kong", "Rina Buoy", "Sovisal Chenda", "Nguonly Taing"], "title": "Khmer Spellchecking: A Holistic Approach", "comment": null, "summary": "Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u9ad8\u68c9\u8bed\u62fc\u5199\u68c0\u67e5\u7684\u6574\u4f53\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u96c6\u6210\u4e86\u9ad8\u68c9\u8bed\u5b50\u8bcd\u5206\u5272\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u5b57\u5f62\u5230\u97f3\u7d20\u7684\u8f6c\u6362\u4ee5\u53ca\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u672a\u80fd\u5145\u5206\u89e3\u51b3\u9ad8\u68c9\u8bed\u62fc\u5199\u68c0\u67e5\u4e2d\u7684\u6311\u6218\uff0c\u4f8b\u5982\u8bcd\u6c47\u548c\u5206\u8bcd\u6a21\u578b\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u3001\u5355\u8bcd\u7684\u4e0d\u540c\u5f62\u5f0f\u3001\u590d\u5408\u8bcd\u7684\u81ea\u7531\u7ec4\u5408\u4ee5\u53ca\u7f3a\u4e4f\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u3002", "method": "\u8be5\u65b9\u6cd5\u96c6\u6210\u4e86\u9ad8\u68c9\u8bed\u5b50\u8bcd\u5206\u5272\u3001\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u5b57\u5f62\u5230\u97f3\u7d20\u7684\u8f6c\u6362\u4ee5\u53ca\u9ad8\u68c9\u8bed\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u8bc6\u522b\u6f5c\u5728\u7684\u66f4\u6b63\u5019\u9009\u5e76\u5bf9\u6700\u5408\u9002\u7684\u5019\u9009\u8fdb\u884c\u6392\u5e8f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe 94.4% \u7684\u6700\u5148\u8fdb\u7684\u9ad8\u68c9\u8bed\u62fc\u5199\u68c0\u67e5\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u9ad8\u68c9\u8bed\u62fc\u5199\u68c0\u67e5\u548c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u63d0\u4f9b\u4e86\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u5c06\u516c\u5f00\u63d0\u4f9b\u3002"}}
{"id": "2511.09600", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2511.09600", "abs": "https://arxiv.org/abs/2511.09600", "authors": ["Gustavo Bodanza"], "title": "Cogent argument extensions are weakly admissible but not vice versa", "comment": "Research note, 4 pages, no figures", "summary": "In this research note, we show the relationship between two non-admissible argumentation framework semantics: cogent and weakly admissible semantics. We prove that, while cogent extensions are weakly admissible, the converse is not true.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e24\u79cd\u975e\u5bb9\u8bb8\u8bba\u8bc1\u6846\u67b6\u8bed\u4e49\u4e4b\u95f4\u7684\u5173\u7cfb\uff1acoogent\u8bed\u4e49\u548c\u5f31\u5bb9\u8bb8\u8bed\u4e49\u3002\u8bc1\u660e\u4e86coogent\u6269\u5c55\u662f\u5f31\u5bb9\u8bb8\u7684\uff0c\u53cd\u4e4b\u5219\u4e0d\u7136\u3002", "motivation": "\u7814\u7a76coogent\u8bed\u4e49\u548c\u5f31\u5bb9\u8bb8\u8bed\u4e49\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u8bc1\u660ecoogent\u6269\u5c55\u662f\u5f31\u5bb9\u8bb8\u7684\uff0c\u4f46\u53cd\u4e4b\u5219\u4e0d\u7136\u3002", "result": "\u8bc1\u660e\u4e86coogent\u6269\u5c55\u662f\u5f31\u5bb9\u8bb8\u7684\uff0c\u53cd\u4e4b\u5219\u4e0d\u7136\u3002", "conclusion": "Coogent\u6269\u5c55\u662f\u5f31\u5bb9\u8bb8\u7684\uff0c\u4f46\u53cd\u4e4b\u5219\u4e0d\u7136\u3002"}}
{"id": "2511.09715", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09715", "abs": "https://arxiv.org/abs/2511.09715", "authors": ["Arman Zarei", "Samyadeep Basu", "Mobina Pournemat", "Sayan Nag", "Ryan Rossi", "Soheil Feizi"], "title": "SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control", "comment": null, "summary": "Instruction-based image editing models have recently achieved impressive performance, enabling complex edits to an input image from a multi-instruction prompt. However, these models apply each instruction in the prompt with a fixed strength, limiting the user's ability to precisely and continuously control the intensity of individual edits. We introduce SliderEdit, a framework for continuous image editing with fine-grained, interpretable instruction control. Given a multi-part edit instruction, SliderEdit disentangles the individual instructions and exposes each as a globally trained slider, allowing smooth adjustment of its strength. Unlike prior works that introduced slider-based attribute controls in text-to-image generation, typically requiring separate training or fine-tuning for each attribute or concept, our method learns a single set of low-rank adaptation matrices that generalize across diverse edits, attributes, and compositional instructions. This enables continuous interpolation along individual edit dimensions while preserving both spatial locality and global semantic consistency. We apply SliderEdit to state-of-the-art image editing models, including FLUX-Kontext and Qwen-Image-Edit, and observe substantial improvements in edit controllability, visual consistency, and user steerability. To the best of our knowledge, we are the first to explore and propose a framework for continuous, fine-grained instruction control in instruction-based image editing models. Our results pave the way for interactive, instruction-driven image manipulation with continuous and compositional control.", "AI": {"tldr": "SliderEdit\u662f\u4e00\u4e2a\u7528\u4e8e\u8fde\u7eed\u56fe\u50cf\u7f16\u8f91\u7684\u6846\u67b6\uff0c\u5b83\u53ef\u4ee5\u5bf9\u6bcf\u4e2a\u6307\u4ee4\u7684\u5f3a\u5ea6\u8fdb\u884c\u5e73\u6ed1\u8c03\u6574\uff0c\u4ece\u800c\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u3001\u53ef\u89e3\u91ca\u7684\u6307\u4ee4\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6307\u4ee4\u7684\u56fe\u50cf\u7f16\u8f91\u6a21\u578b\u5bf9\u6bcf\u4e2a\u6307\u4ee4\u90fd\u91c7\u7528\u56fa\u5b9a\u5f3a\u5ea6\uff0c\u9650\u5236\u4e86\u7528\u6237\u7cbe\u786e\u63a7\u5236\u7f16\u8f91\u5f3a\u5ea6\u7684\u80fd\u529b\u3002", "method": "SliderEdit\u901a\u8fc7\u89e3\u8026\u5355\u4e2a\u6307\u4ee4\uff0c\u5e76\u5c06\u6bcf\u4e2a\u6307\u4ee4\u4f5c\u4e3a\u4e00\u4e2a\u5168\u5c40\u8bad\u7ec3\u7684\u6ed1\u5757\uff0c\u5141\u8bb8\u5e73\u6ed1\u8c03\u6574\u5176\u5f3a\u5ea6\u3002\u8be5\u65b9\u6cd5\u5b66\u4e60\u4e00\u4e2a\u4f4e\u79e9\u9002\u5e94\u77e9\u9635\u96c6\uff0c\u8be5\u77e9\u9635\u96c6\u53ef\u4ee5\u63a8\u5e7f\u5230\u4e0d\u540c\u7684\u7f16\u8f91\u3001\u5c5e\u6027\u548c\u7ec4\u5408\u6307\u4ee4\u3002", "result": "SliderEdit\u5728\u7f16\u8f91\u53ef\u63a7\u6027\u3001\u89c6\u89c9\u4e00\u81f4\u6027\u548c\u7528\u6237\u53ef\u64cd\u7eb5\u6027\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "SliderEdit\u4e3a\u4ea4\u4e92\u5f0f\u7684\u3001\u6307\u4ee4\u9a71\u52a8\u7684\u56fe\u50cf\u64cd\u4f5c\u94fa\u5e73\u4e86\u9053\u8def\uff0c\u5177\u6709\u8fde\u7eed\u7684\u548c\u7ec4\u5408\u7684\u63a7\u5236\u3002"}}
{"id": "2511.09578", "categories": ["cs.LG", "cs.AI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2511.09578", "abs": "https://arxiv.org/abs/2511.09578", "authors": ["Hadi Keramati", "Morteza Sadeghi", "Rajeev K. Jaiman"], "title": "HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization", "comment": null, "summary": "This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f15\u5bfc\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b (DDPM) \u7684\u751f\u6210\u4f18\u5316\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5229\u7528\u66ff\u4ee3\u68af\u5ea6\u751f\u6210\u6563\u70ed\u5668\u8bbe\u8ba1\uff0c\u4ece\u800c\u6700\u5927\u9650\u5ea6\u5730\u51cf\u5c11\u538b\u964d\uff0c\u540c\u65f6\u5c06\u8868\u9762\u6e29\u5ea6\u4fdd\u6301\u5728\u6307\u5b9a\u9608\u503c\u4ee5\u4e0b\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u548c\u62d3\u6251\u4f18\u5316\u65b9\u6cd5\u5728\u6563\u70ed\u5668\u8bbe\u8ba1\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5982\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u96be\u4ee5\u6269\u5c55\u4ee5\u53ca\u9700\u8981\u9488\u5bf9\u65b0\u7ea6\u675f\u8fdb\u884c\u91cd\u65b0\u8bad\u7ec3\u7b49\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86\u591a\u91cd\u4fdd\u771f\u5ea6\u65b9\u6cd5\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u5e76\u8bad\u7ec3\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b\u4ee5\u751f\u6210\u5177\u6709\u4e0e\u6570\u636e\u4e2d\u89c2\u5bdf\u5230\u7684\u7279\u5f81\u4e00\u81f4\u7684\u6563\u70ed\u5668\u3002\u6b64\u5916\uff0c\u8fd8\u8bad\u7ec3\u4e86\u4e24\u4e2a\u4e0d\u540c\u7684\u6b8b\u5dee\u795e\u7ecf\u7f51\u7edc\u6765\u9884\u6d4b\u6bcf\u4e2a\u51e0\u4f55\u5f62\u72b6\u7684\u538b\u964d\u548c\u8868\u9762\u6e29\u5ea6\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u66ff\u4ee3\u6a21\u578b\u7684\u68af\u5ea6\u6765\u6307\u5bfc\u51e0\u4f55\u751f\u6210\u8fc7\u7a0b\uff0c\u4ee5\u6ee1\u8db3\u4f4e\u538b\u548c\u8868\u9762\u6e29\u5ea6\u7ea6\u675f\u3002", "result": "\u4f7f\u7528\u5f15\u5bfc\u6269\u6563\u6a21\u578b\u751f\u6210\u7684\u6837\u672c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u9ed1\u76d2\u4f18\u5316\u65b9\u6cd5\u83b7\u5f97\u7684\u9650\u5236\u4f4e 10% \u7684\u538b\u964d\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4ee3\u8868\u4e86\u671d\u7740\u6784\u5efa\u7535\u5b50\u51b7\u5374\u57fa\u7840\u751f\u6210\u6a21\u578b\u8fc8\u51fa\u7684\u4e00\u6b65\u3002"}}
{"id": "2511.09819", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.09819", "abs": "https://arxiv.org/abs/2511.09819", "authors": ["Rahul Soni", "Basem Suleiman", "Sonit Singh"], "title": "Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests", "comment": "10 pages", "summary": "This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.", "AI": {"tldr": "\u672c\u7814\u7a76\u65e8\u5728\u8bbe\u8ba1\u548c\u5f00\u53d1\u4e00\u4e2a\u8bfe\u7a0b\u63a8\u8350\u7cfb\u7edf\uff0c\u4ee5\u5e94\u5bf9\u4e3a\u5b66\u751f\u9009\u62e9\u76f8\u5173\u8bfe\u7a0b\u7684\u6311\u6218\u3002", "motivation": "\u672c\u7814\u7a76\u7684\u52a8\u673a\u662f\u5f25\u5408\u5927\u5b66\u5b66\u4e60\u548c\u884c\u4e1a\u671f\u671b\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5e2e\u52a9\u5b66\u751f\u9009\u62e9\u4e0e\u884c\u4e1a\u8d8b\u52bf\u548c\u8981\u6c42\u76f8\u7b26\u7684\u8bfe\u7a0b\u3002", "method": "\u8be5\u7cfb\u7edf\u91c7\u7528\u6570\u636e\u6316\u6398\u548c\u534f\u540c\u8fc7\u6ee4\u6280\u672f\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u3001\u7528\u6237\u504f\u597d\u548c\u5b66\u672f\u6807\u51c6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u7b97\u6cd5\u6846\u67b6\u3002", "result": "\u8be5\u7cfb\u7edf\u901a\u8fc7\u8fed\u4ee3\u539f\u578b\u8bbe\u8ba1\u548c\u7528\u6237\u8f93\u5165\u4fee\u8ba2\uff0c\u5f00\u53d1\u4e86\u4e00\u4e2a\u6613\u4e8e\u4f7f\u7528\u7684\u524d\u7aef\u754c\u9762\uff0c\u5e76\u6839\u636e\u7528\u6237\u53cd\u9988\u8fdb\u884c\u4e86\u4f18\u5316\u3002", "conclusion": "\u8be5\u8bfe\u7a0b\u63a8\u8350\u7cfb\u7edf\u53ef\u4ee5\u5e2e\u52a9\u5b66\u751f\u3001\u6559\u5e08\u548c\u804c\u4e1a\u987e\u95ee\uff0c\u4fc3\u8fdb\u7ec8\u8eab\u5b66\u4e60\u548c\u804c\u4e1a\u53d1\u5c55\uff0c\u5e76\u5e2e\u52a9\u5927\u5b66\u751f\u505a\u51fa\u6570\u636e\u9a71\u52a8\u548c\u884c\u4e1a informed \u7684\u8bfe\u7a0b\u51b3\u7b56\uff0c\u4ece\u800c\u63d0\u9ad8\u5927\u5b66\u6bd5\u4e1a\u751f\u7684\u6210\u679c\u3002"}}
{"id": "2511.09682", "categories": ["cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.09682", "abs": "https://arxiv.org/abs/2511.09682", "authors": ["Tiansheng Huang", "Virat Shejwalkar", "Oscar Chang", "Milad Nasr", "Ling Liu"], "title": "Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models", "comment": null, "summary": "Instilling reasoning capabilities in large models (LMs) using reasoning training (RT) significantly improves LMs' performances. Thus Audio Reasoning Models (ARMs), i.e., audio LMs that can reason, are becoming increasingly popular. However, no work has studied the safety of ARMs against jailbreak attacks that aim to elicit harmful responses from target models. To this end, first, we show that standard RT with appropriate safety reasoning data can protect ARMs from vanilla audio jailbreaks, but cannot protect them against our proposed simple yet effective jailbreaks. We show that this is because of the significant representation drift between vanilla and advanced jailbreaks which forces the target ARMs to emit harmful responses. Based on this observation, we propose Rebellion, a robust RT that trains ARMs to be robust to the worst-case representation drift. All our results are on Qwen2-Audio; they demonstrate that Rebellion: 1) can protect against advanced audio jailbreaks without compromising performance on benign tasks, and 2) significantly improves accuracy-safety trade-off over standard RT method.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u97f3\u9891\u63a8\u7406\u6a21\u578b\uff08ARMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u6807\u51c6\u63a8\u7406\u8bad\u7ec3\uff08RT\uff09\u65e0\u6cd5\u9632\u5fa1\u9ad8\u7ea7\u5bf9\u6297\u653b\u51fb\u3002\u4e3a\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9c81\u68d2\u7684\u63a8\u7406\u8bad\u7ec3\u65b9\u6cd5Rebellion\uff0c\u901a\u8fc7\u8bad\u7ec3ARMs\u4ee5\u5e94\u5bf9\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u8868\u5f81\u6f02\u79fb\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u5728\u5bf9\u6297\u653b\u51fb\u4e0b\u7684\u5b89\u5168\u6027\u548c\u5728\u826f\u6027\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u76ee\u524d\u7f3a\u4e4f\u5bf9\u97f3\u9891\u63a8\u7406\u6a21\u578b\uff08ARMs\uff09\u5bf9\u6297\u6076\u610f\u653b\u51fb\u5b89\u5168\u6027\u7684\u7814\u7a76\u3002\u73b0\u6709\u6807\u51c6\u63a8\u7406\u8bad\u7ec3\u65b9\u6cd5\u65e0\u6cd5\u9632\u5fa1\u9ad8\u7ea7\u5bf9\u6297\u653b\u51fb\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u7684\u63a8\u7406\u8bad\u7ec3\u65b9\u6cd5Rebellion\uff0c\u8bad\u7ec3ARMs\u4ee5\u5e94\u5bf9\u6700\u574f\u60c5\u51b5\u4e0b\u7684\u8868\u5f81\u6f02\u79fb\u3002", "result": "Rebellion\u65b9\u6cd5\u5728\u4e0d\u5f71\u54cd\u826f\u6027\u4efb\u52a1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u9632\u5fa1\u4e86\u9ad8\u7ea7\u97f3\u9891\u5bf9\u6297\u653b\u51fb\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u6027-\u5b89\u5168\u6027\u6743\u8861\u3002", "conclusion": "Rebellion\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u97f3\u9891\u63a8\u7406\u6a21\u578b\uff08ARMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u4f7f\u5176\u514d\u53d7\u9ad8\u7ea7\u5bf9\u6297\u653b\u51fb\u3002"}}
{"id": "2511.09723", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09723", "abs": "https://arxiv.org/abs/2511.09723", "authors": ["Balachandra Devarangadi Sunil", "Rakshith Venkatesh", "Shantanu Todmal"], "title": "Density Estimation and Crowd Counting", "comment": null, "summary": "This study enhances a crowd density estimation algorithm originally designed for image-based analysis by adapting it for video-based scenarios. The proposed method integrates a denoising probabilistic model that utilizes diffusion processes to generate high-quality crowd density maps. To improve accuracy, narrow Gaussian kernels are employed, and multiple density map outputs are generated. A regression branch is incorporated into the model for precise feature extraction, while a consolidation mechanism combines these maps based on similarity scores to produce a robust final result. An event-driven sampling technique, utilizing the Farneback optical flow algorithm, is introduced to selectively capture frames showing significant crowd movements, reducing computational load and storage by focusing on critical crowd dynamics. Through qualitative and quantitative evaluations, including overlay plots and Mean Absolute Error (MAE), the model demonstrates its ability to effectively capture crowd dynamics in both dense and sparse settings. The efficiency of the sampling method is further assessed, showcasing its capability to decrease frame counts while maintaining essential crowd events. By addressing the temporal challenges unique to video analysis, this work offers a scalable and efficient framework for real-time crowd monitoring in applications such as public safety, disaster response, and event management.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u57fa\u4e8e\u89c6\u9891\u7684 crowd density estimation \u7b97\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u964d\u566a\u6982\u7387\u6a21\u578b\u3001\u7a84\u9ad8\u65af\u6838\u3001\u56de\u5f52\u5206\u652f\u548c\u4e8b\u4ef6\u9a71\u52a8\u91c7\u6837\u6280\u672f\u6765\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u89e3\u51b3\u89c6\u9891 crowd density estimation \u4e2d\u7684\u65f6\u95f4\u6311\u6218\uff0c\u63d0\u9ad8\u5728\u516c\u5171\u5b89\u5168\u3001\u707e\u96be\u54cd\u5e94\u548c\u4e8b\u4ef6\u7ba1\u7406\u7b49\u5e94\u7528\u4e2d\u7684\u5b9e\u65f6 crowd monitoring \u7684\u53ef\u6269\u5c55\u6027\u548c\u6548\u7387\u3002", "method": "1. \u5c06\u56fe\u50cf crowd density estimation \u7b97\u6cd5\u8c03\u6574\u4e3a\u89c6\u9891\u573a\u666f\uff1b2. \u96c6\u6210\u5229\u7528\u6269\u6563\u8fc7\u7a0b\u751f\u6210\u9ad8\u8d28\u91cf crowd density maps \u7684\u964d\u566a\u6982\u7387\u6a21\u578b\uff1b3. \u91c7\u7528\u7a84\u9ad8\u65af\u6838\u5e76\u751f\u6210\u591a\u4e2a density map \u8f93\u51fa\uff1b4. \u5f15\u5165\u56de\u5f52\u5206\u652f\u4ee5\u5b9e\u73b0\u7cbe\u786e\u7684\u7279\u5f81\u63d0\u53d6\uff1b5. \u57fa\u4e8e\u76f8\u4f3c\u6027\u5206\u6570\u5408\u5e76\u8fd9\u4e9b maps \u4ee5\u4ea7\u751f\u7a33\u5065\u7684\u6700\u7ec8\u7ed3\u679c\uff1b6. \u5f15\u5165\u4e8b\u4ef6\u9a71\u52a8\u91c7\u6837\u6280\u672f\uff0c\u5229\u7528 Farneback \u5149\u6d41\u7b97\u6cd5\u9009\u62e9\u6027\u5730\u6355\u83b7\u663e\u793a\u663e\u7740 crowd movements \u7684\u5e27\uff0c\u4ece\u800c\u51cf\u5c11\u8ba1\u7b97\u8d1f\u8377\u548c\u5b58\u50a8\u3002", "result": "\u8be5\u6a21\u578b\u901a\u8fc7\u5b9a\u6027\u548c\u5b9a\u91cf\u8bc4\u4f30\uff08\u5305\u62ec\u8986\u76d6\u56fe\u548c\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee (MAE)\uff09\u8bc1\u660e\u4e86\u5176\u5728\u5bc6\u96c6\u548c\u7a00\u758f\u8bbe\u7f6e\u4e2d\u6709\u6548\u6355\u83b7 crowd dynamics \u7684\u80fd\u529b\u3002\u91c7\u6837\u65b9\u6cd5\u7684\u6548\u7387\u5f97\u5230\u8fdb\u4e00\u6b65\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4fdd\u6301\u57fa\u672c crowd events \u7684\u540c\u65f6\u51cf\u5c11\u5e27\u6570\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u516c\u5171\u5b89\u5168\u3001\u707e\u96be\u54cd\u5e94\u548c\u4e8b\u4ef6\u7ba1\u7406\u7b49\u5e94\u7528\u4e2d\u8fdb\u884c\u5b9e\u65f6 crowd monitoring\u3002"}}
{"id": "2511.09586", "categories": ["cs.LG", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09586", "abs": "https://arxiv.org/abs/2511.09586", "authors": ["Yuchen Huang", "Sijia Li", "Minghao Liu", "Wei Liu", "Shijue Huang", "Zhiyuan Fan", "Hou Pong Chan", "Yi R. Fung"], "title": "Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey", "comment": "20 pages, 4 figures, SEA Workshop @ NeurIPS 2025", "summary": "LLM-based agents can autonomously accomplish complex tasks across various domains. However, to further cultivate capabilities such as adaptive behavior and long-term decision-making, training on static datasets built from human-level knowledge is insufficient. These datasets are costly to construct and lack both dynamism and realism. A growing consensus is that agents should instead interact directly with environments and learn from experience through reinforcement learning. We formalize this iterative process as the Generation-Execution-Feedback (GEF) loop, where environments generate tasks to challenge agents, return observations in response to agents' actions during task execution, and provide evaluative feedback on rollouts for subsequent learning. Under this paradigm, environments function as indispensable producers of experiential data, highlighting the need to scale them toward greater complexity, realism, and interactivity. In this survey, we systematically review representative methods for environment scaling from a pioneering environment-centric perspective and organize them along the stages of the GEF loop, namely task generation, task execution, and feedback. We further analyze benchmarks, implementation strategies, and applications, consolidating fragmented advances and outlining future research directions for agent intelligence.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u5982\u4f55\u4ece\u4ee5\u73af\u5883\u4e3a\u4e2d\u5fc3\u7684\u89d2\u5ea6\u6269\u5c55\u73af\u5883\uff0c\u4ee5\u63d0\u9ad8\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u884c\u4e3a\u548c\u957f\u671f\u51b3\u7b56\u80fd\u529b\u3002", "motivation": "\u4e3a\u4e86\u57f9\u517b\u667a\u80fd\u4f53\u7684\u9002\u5e94\u6027\u884c\u4e3a\u548c\u957f\u671f\u51b3\u7b56\u80fd\u529b\uff0c\u4ec5\u9760\u5728\u9759\u6001\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u662f\u4e0d\u591f\u7684\uff0c\u9700\u8981\u667a\u80fd\u4f53\u76f4\u63a5\u4e0e\u73af\u5883\u4e92\u52a8\u5e76\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ece\u7ecf\u9a8c\u4e2d\u5b66\u4e60\u3002", "method": "\u672c\u6587\u5c06\u8fed\u4ee3\u8fc7\u7a0b\u5f62\u5f0f\u5316\u4e3a\u751f\u6210-\u6267\u884c-\u53cd\u9988\uff08GEF\uff09\u5faa\u73af\uff0c\u5e76\u4ece\u73af\u5883\u4e2d\u5fc3\u89d2\u5ea6\u7cfb\u7edf\u5730\u56de\u987e\u4e86\u73af\u5883\u6269\u5c55\u7684\u4ee3\u8868\u6027\u65b9\u6cd5\uff0c\u5e76\u6309GEF\u5faa\u73af\u7684\u9636\u6bb5\u7ec4\u7ec7\u5b83\u4eec\u3002", "result": "\u672c\u6587\u5206\u6790\u4e86\u57fa\u51c6\u3001\u5b9e\u65bd\u7b56\u7565\u548c\u5e94\u7528\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86\u96f6\u6563\u7684\u8fdb\u5c55\uff0c\u5e76\u6982\u8ff0\u4e86\u667a\u80fd\u4f53\u667a\u80fd\u7684\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2511.09831", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.09831", "abs": "https://arxiv.org/abs/2511.09831", "authors": ["Neo Wang", "Sonit Singh"], "title": "Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM", "comment": "8 pages", "summary": "The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u4ee5\u89e3\u51b3\u8bfe\u7a0b\u8bba\u575b\u4e2d\u5b66\u751f\u95ee\u9898\u65e0\u6cd5\u53ca\u65f6\u89e3\u7b54\u4ee5\u53ca\u91cd\u590d\u6027\u95ee\u9898\u8fc7\u591a\u7684\u95ee\u9898\u3002", "motivation": "\u968f\u7740\u8bfe\u7a0b\u6ce8\u518c\u5b66\u751f\u4eba\u6570\u7684\u589e\u52a0\uff0c\u5b66\u751f\u7684\u95ee\u9898\u4e0d\u80fd\u7acb\u5373\u5f97\u5230\u56de\u7b54\uff0c\u6559\u5e08\u9762\u4e34\u5927\u91cf\u91cd\u590d\u6027\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u65b9\u6cd5\u3002\u4f7f\u7528\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5728\u76f8\u5173\u8bfe\u7a0b\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5fae\u8c03\u3002\u4e3a\u4e86\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\uff0c\u4f7f\u7528\u672c\u5730\u77e5\u8bc6\u5e93\uff0c\u5e76\u5e94\u7528RAG\u65b9\u6cd5\u68c0\u7d22\u4e0e\u5b66\u751f\u95ee\u9898\u76f8\u5173\u7684\u6587\u6863\u3002\u4e3a\u4e86\u7f13\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u96c6\u6210\u4e86\u591a\u94fe\u601d\u7ef4\u63a8\u7406\u3002", "result": "\u5728HotpotQA\u6570\u636e\u96c6\u4e0a\u5bf9\u5fae\u8c03\u7684LLM\u4e0eRAG\u65b9\u6cd5\u8fdb\u884c\u4e86\u5b9e\u9a8c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5fae\u8c03\u7684LLM\u4e0eRAG\u65b9\u6cd5\u5728\u95ee\u7b54\u4efb\u52a1\u4e0a\u5177\u6709\u5f88\u5f3a\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u8868\u660e\uff0c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u7684\u95ee\u7b54\u7cfb\u7edf\u5728\u8bfe\u7a0b\u8bba\u575b\u4e2d\u5177\u6709\u5f88\u5f3a\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.09710", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09710", "abs": "https://arxiv.org/abs/2511.09710", "authors": ["Sarath Shekkizhar", "Romain Cosentino", "Adam Earle", "Silvio Savarese"], "title": "Echoing: Identity Failures when LLM Agents Talk to Each Other", "comment": null, "summary": "As large language model (LLM) based agents interact autonomously with one another, a new class of failures emerges that cannot be predicted from single agent performance: behavioral drifts in agent-agent conversations (AxA). Unlike human-agent interactions, where humans ground and steer conversations, AxA lacks such stabilizing signals, making these failures unique. We investigate one such failure, echoing, where agents abandon their assigned roles and instead mirror their conversational partners, undermining their intended objectives. Through experiments across $60$ AxA configurations, $3$ domains, and $2000+$ conversations, we demonstrate that echoing occurs across three major LLM providers, with echoing rates from $5\\%$ to $70\\%$ depending on the model and domain. Moreover, we find that echoing is persistent even in advanced reasoning models with substantial rates ($32.8\\%$) that are not reduced by increased reasoning efforts. We analyze prompt impacts, conversation dynamics, showing that echoing arises as interaction grows longer ($7+$ turns in experiments) and is not merely an artifact of sub-optimal prompting. Finally, we introduce a protocol-level mitigation in which targeted use of structured responses reduces echoing to $9\\%$.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684agent\u5728\u81ea\u4e3b\u4ea4\u4e92\u65f6\uff0c\u4f1a\u51fa\u73b0\u5355agent\u6027\u80fd\u65e0\u6cd5\u9884\u6d4b\u7684\u65b0\u578b\u6545\u969c\uff1aagent\u95f4\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\u6f02\u79fb\uff08AxA\uff09\u3002\u5176\u4e2d\u4e00\u79cd\u6545\u969c\u662f\u201c\u56de\u58f0\u201d\uff0c\u5373agent\u653e\u5f03\u5176\u89d2\u8272\u5e76\u955c\u50cf\u5bf9\u8bdd\u4f19\u4f34\u3002", "motivation": "\u63a2\u8ba8\u5728agent\u95f4\u5bf9\u8bdd\uff08AxA\uff09\u4e2d\uff0c\u7531\u4e8e\u7f3a\u4e4f\u4eba\u7c7b\u7684\u5f15\u5bfc\uff0cagent\u4f1a\u504f\u79bb\u9884\u5b9a\u76ee\u6807\uff0c\u4ea7\u751f\u201c\u56de\u58f0\u201d\u73b0\u8c61\u3002", "method": "\u901a\u8fc7\u572860\u4e2aAxA\u914d\u7f6e\u30013\u4e2a\u9886\u57df\u548c2000\u591a\u6b21\u5bf9\u8bdd\u4e2d\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e86\u201c\u56de\u58f0\u201d\u73b0\u8c61\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e09\u5927LLM\u63d0\u4f9b\u5546\u4e2d\u5747\u5b58\u5728\u201c\u56de\u58f0\u201d\u73b0\u8c61\uff0c\u53d1\u751f\u7387\u4ece5%\u523070%\u4e0d\u7b49\uff0c\u5e76\u4e14\u5373\u4f7f\u5728\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u4e2d\u4e5f\u5f88\u666e\u904d\uff0832.8%\uff09\uff0c\u589e\u52a0\u63a8\u7406\u52aa\u529b\u4e5f\u65e0\u6cd5\u51cf\u5c11\u3002\u5206\u6790\u8868\u660e\uff0c\u201c\u56de\u58f0\u201d\u73b0\u8c61\u968f\u7740\u4ea4\u4e92\u7684\u8fdb\u884c\u800c\u589e\u957f\uff08\u5b9e\u9a8c\u4e2d\u8d85\u8fc77\u8f6e\uff09\uff0c\u5e76\u975e\u4ec5\u4ec5\u662f\u63d0\u793a\u4e0d\u4f73\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u534f\u8bae\u7ea7\u522b\u7684\u7f13\u89e3\u63aa\u65bd\uff0c\u6709\u9488\u5bf9\u6027\u5730\u4f7f\u7528\u7ed3\u6784\u5316\u54cd\u5e94\uff0c\u53ef\u4ee5\u5c06\u201c\u56de\u58f0\u201d\u73b0\u8c61\u964d\u4f4e\u52309%\u3002"}}
{"id": "2511.09724", "categories": ["cs.CV", "cs.AI", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.09724", "abs": "https://arxiv.org/abs/2511.09724", "authors": ["Yunqian Cheng", "Benjamin Princen", "Roberto Manduchi"], "title": "PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model", "comment": "Accepted to IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026, Application Track. Main paper: 8 pages, 5 figures. Supplementary material included", "summary": "Indoor localization in GPS-denied environments is crucial for applications like emergency response and assistive navigation. Vision-based methods such as PALMS enable infrastructure-free localization using only a floor plan and a stationary scan, but are limited by the short range of smartphone LiDAR and ambiguity in indoor layouts. We propose PALMS$+$, a modular, image-based system that addresses these challenges by reconstructing scale-aligned 3D point clouds from posed RGB images using a foundation monocular depth estimation model (Depth Pro), followed by geometric layout matching via convolution with the floor plan. PALMS$+$ outputs a posterior over the location and orientation, usable for direct or sequential localization. Evaluated on the Structured3D and a custom campus dataset consisting of 80 observations across four large campus buildings, PALMS$+$ outperforms PALMS and F3Loc in stationary localization accuracy -- without requiring any training. Furthermore, when integrated with a particle filter for sequential localization on 33 real-world trajectories, PALMS$+$ achieved lower localization errors compared to other methods, demonstrating robustness for camera-free tracking and its potential for infrastructure-free applications. Code and data are available at https://github.com/Head-inthe-Cloud/PALMS-Plane-based-Accessible-Indoor-Localization-Using-Mobile-Smartphones", "AI": {"tldr": "PALMS++: An improved indoor localization system using RGB images and a foundation monocular depth estimation model.", "motivation": "Vision-based indoor localization methods are limited by short range and ambiguity. Overcome the limitations of existing vision-based indoor localization methods in GPS-denied environments.", "method": "Reconstructs scale-aligned 3D point clouds from posed RGB images using Depth Pro, followed by geometric layout matching via convolution with the floor plan.", "result": "Outperforms PALMS and F3Loc in stationary localization accuracy and achieves lower localization errors in sequential localization.", "conclusion": "Demonstrates robustness for camera-free tracking and its potential for infrastructure-free applications."}}
{"id": "2511.09593", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09593", "abs": "https://arxiv.org/abs/2511.09593", "authors": ["Ruiyang Ma", "Yunhao Zhou", "Yipeng Wang", "Yi Liu", "Zhengyuan Shi", "Ziyang Zheng", "Kexin Chen", "Zhiqiang He", "Lingwei Yan", "Gang Chen", "Qiang Xu", "Guojie Luo"], "title": "DynamicRTL: RTL Representation Learning for Dynamic Circuit Behavior", "comment": "Accepted by AAAI'2026", "summary": "There is a growing body of work on using Graph Neural Networks (GNNs) to learn representations of circuits, focusing primarily on their static characteristics. However, these models fail to capture circuit runtime behavior, which is crucial for tasks like circuit verification and optimization. To address this limitation, we introduce DR-GNN (DynamicRTL-GNN), a novel approach that learns RTL circuit representations by incorporating both static structures and multi-cycle execution behaviors. DR-GNN leverages an operator-level Control Data Flow Graph (CDFG) to represent Register Transfer Level (RTL) circuits, enabling the model to capture dynamic dependencies and runtime execution. To train and evaluate DR-GNN, we build the first comprehensive dynamic circuit dataset, comprising over 6,300 Verilog designs and 63,000 simulation traces. Our results demonstrate that DR-GNN outperforms existing models in branch hit prediction and toggle rate prediction. Furthermore, its learned representations transfer effectively to related dynamic circuit tasks, achieving strong performance in power estimation and assertion prediction.", "AI": {"tldr": "DR-GNN\u901a\u8fc7\u7ed3\u5408\u9759\u6001\u7ed3\u6784\u548c\u591a\u5468\u671f\u6267\u884c\u884c\u4e3a\u6765\u5b66\u4e60RTL\u7535\u8def\u8868\u793a\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709GNN\u6a21\u578b\u65e0\u6cd5\u6355\u6349\u7535\u8def\u8fd0\u884c\u65f6\u884c\u4e3a\uff0c\u8fd9\u5bf9\u4e8e\u7535\u8def\u9a8c\u8bc1\u548c\u4f18\u5316\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51faDR-GNN\uff0c\u5229\u7528\u64cd\u4f5c\u7ea7\u63a7\u5236\u6570\u636e\u6d41\u56fe\uff08CDFG\uff09\u8868\u793aRTL\u7535\u8def\uff0c\u4ece\u800c\u80fd\u591f\u6355\u83b7\u52a8\u6001\u4f9d\u8d56\u5173\u7cfb\u548c\u8fd0\u884c\u65f6\u6267\u884c\u3002", "result": "DR-GNN\u5728\u5206\u652f\u547d\u4e2d\u9884\u6d4b\u548c\u7ffb\u8f6c\u7387\u9884\u6d4b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u5e76\u4e14\u5176\u5b66\u4e60\u7684\u8868\u793a\u6709\u6548\u5730\u8f6c\u79fb\u5230\u76f8\u5173\u7684\u52a8\u6001\u7535\u8def\u4efb\u52a1\uff0c\u5728\u529f\u7387\u4f30\u8ba1\u548c\u65ad\u8a00\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u6027\u80fd\u3002", "conclusion": "DR-GNN\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u7535\u8def\u7684\u52a8\u6001\u884c\u4e3a\uff0c\u5e76\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.09854", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09854", "abs": "https://arxiv.org/abs/2511.09854", "authors": ["Yidan Sun", "Mengying Zhu", "Feiyue Chen", "Yangyang Wu", "Xiaolei Dan", "Mengyuan Yang", "Xiaolin Zheng", "Shenglin Ben"], "title": "TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain", "comment": "13 pages, 4 figures", "summary": "Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5d4c\u5165\u7a7a\u95f4\u5b58\u5728\u5404\u5411\u540c\u6027\u95ee\u9898\uff0c\u5bfc\u81f4\u9886\u57df\u672f\u8bed\u533a\u5206\u5ea6\u5dee\u3002\u672c\u6587\u63d0\u51fa TermGPT\uff0c\u4e00\u4e2a\u591a\u5c42\u6b21\u5bf9\u6bd4\u5fae\u8c03\u6846\u67b6\uff0c\u7528\u4e8e\u672f\u8bed\u9002\u5e94\uff0c\u4ece\u800c\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u548c\u91d1\u878d\u7b49\u9886\u57df\u7684\u672f\u8bed\u533a\u5206\u5ea6\u8f83\u5dee\uff0c\u4e25\u91cd\u963b\u788d\u4e86\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u6216\u91d1\u878d\u98ce\u9669\u5206\u6790\u7b49\u4e0b\u6e38\u4efb\u52a1\u3002", "method": "\u6784\u5efa\u53e5\u5b50\u56fe\u4ee5\u6355\u83b7\u8bed\u4e49\u548c\u7ed3\u6784\u5173\u7cfb\uff0c\u5e76\u57fa\u4e8e\u4e0a\u4e0b\u6587\u548c\u62d3\u6251\u7ebf\u7d22\u751f\u6210\u8bed\u4e49\u4e00\u81f4\u4f46\u5177\u6709\u533a\u5206\u6027\u7684\u6b63\u8d1f\u6837\u672c\u3002\u8bbe\u8ba1\u4e86\u4e00\u79cd\u53e5\u5b50\u548ctoken\u7ea7\u522b\u7684\u591a\u5c42\u6b21\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u4ee5\u589e\u5f3a\u5168\u5c40\u4e0a\u4e0b\u6587\u7406\u89e3\u548c\u7ec6\u7c92\u5ea6\u7684\u672f\u8bed\u533a\u5206\u3002", "result": "TermGPT \u5728\u91d1\u878d\u548c\u6cd5\u5f8b\u9886\u57df\u7684\u672f\u8bed\u533a\u5206\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "TermGPT \u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u672f\u8bed\u533a\u5206\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09768", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09768", "abs": "https://arxiv.org/abs/2511.09768", "authors": ["Rik Adriaensen", "Lucas Van Praet", "Jessa Bekker", "Robin Manhaeve", "Pieter Delobelle", "Maarten Buyl"], "title": "ProbLog4Fairness: A Neurosymbolic Approach to Modeling and Mitigating Bias", "comment": "Accepted at AAAI 2026", "summary": "Operationalizing definitions of fairness is difficult in practice, as multiple definitions can be incompatible while each being arguably desirable. Instead, it may be easier to directly describe algorithmic bias through ad-hoc assumptions specific to a particular real-world task, e.g., based on background information on systemic biases in its context. Such assumptions can, in turn, be used to mitigate this bias during training. Yet, a framework for incorporating such assumptions that is simultaneously principled, flexible, and interpretable is currently lacking.\n  Our approach is to formalize bias assumptions as programs in ProbLog, a probabilistic logic programming language that allows for the description of probabilistic causal relationships through logic. Neurosymbolic extensions of ProbLog then allow for easy integration of these assumptions in a neural network's training process. We propose a set of templates to express different types of bias and show the versatility of our approach on synthetic tabular datasets with known biases. Using estimates of the bias distortions present, we also succeed in mitigating algorithmic bias in real-world tabular and image data. We conclude that ProbLog4Fairness outperforms baselines due to its ability to flexibly model the relevant bias assumptions, where other methods typically uphold a fixed bias type or notion of fairness.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u504f\u5dee\u7f13\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u504f\u5dee\u5047\u8bbe\u5f62\u5f0f\u5316\u4e3a ProbLog \u7a0b\u5e8f\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u4ece\u800c\u7075\u6d3b\u5730\u5bf9\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u504f\u5dee\u8fdb\u884c\u5efa\u6a21\u548c\u7f13\u89e3\u3002", "motivation": "\u5728\u5b9e\u8df5\u4e2d\uff0c\u516c\u5e73\u7684\u5b9a\u4e49\u96be\u4ee5\u64cd\u4f5c\uff0c\u56e0\u4e3a\u591a\u4e2a\u5b9a\u4e49\u53ef\u80fd\u4e0d\u517c\u5bb9\u3002\u76f4\u63a5\u63cf\u8ff0\u7b97\u6cd5\u504f\u5dee\u53ef\u80fd\u66f4\u5bb9\u6613\uff0c\u4f8b\u5982\uff0c\u57fa\u4e8e\u5bf9\u5176\u80cc\u666f\u4e2d\u7684\u7cfb\u7edf\u504f\u5dee\u7684\u80cc\u666f\u4fe1\u606f\u3002\u8fd9\u4e9b\u5047\u8bbe\u53ef\u4ee5\u7528\u6765\u5728\u8bad\u7ec3\u671f\u95f4\u51cf\u8f7b\u8fd9\u79cd\u504f\u5dee\u3002\u7136\u800c\uff0c\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u540c\u65f6\u5177\u6709\u539f\u5219\u6027\u3001\u7075\u6d3b\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6846\u67b6\u6765\u6574\u5408\u8fd9\u4e9b\u5047\u8bbe\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u504f\u5dee\u5047\u8bbe\u5f62\u5f0f\u5316\u4e3a ProbLog \u4e2d\u7684\u7a0b\u5e8f\uff0c\u8fd9\u662f\u4e00\u79cd\u6982\u7387\u903b\u8f91\u7f16\u7a0b\u8bed\u8a00\uff0c\u5141\u8bb8\u901a\u8fc7\u903b\u8f91\u63cf\u8ff0\u6982\u7387\u56e0\u679c\u5173\u7cfb\u3002Problog \u7684\u795e\u7ecf\u7b26\u53f7\u6269\u5c55\u5141\u8bb8\u8f7b\u677e\u5730\u5c06\u8fd9\u4e9b\u5047\u8bbe\u96c6\u6210\u5230\u795e\u7ecf\u7f51\u7edc\u7684\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u7ec4\u6a21\u677f\u6765\u8868\u8fbe\u4e0d\u540c\u7c7b\u578b\u7684\u504f\u5dee\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u5177\u6709\u5df2\u77e5\u504f\u5dee\u7684\u5408\u6210\u8868\u683c\u6570\u636e\u96c6\u4e0a\u5c55\u793a\u4e86\u5176\u901a\u7528\u6027\u3002\u4f7f\u7528\u5bf9\u5b58\u5728\u7684\u504f\u5dee\u5931\u771f\u7684\u4f30\u8ba1\uff0c\u8be5\u65b9\u6cd5\u8fd8\u6210\u529f\u5730\u51cf\u8f7b\u4e86\u73b0\u5b9e\u4e16\u754c\u8868\u683c\u548c\u56fe\u50cf\u6570\u636e\u4e2d\u7684\u7b97\u6cd5\u504f\u5dee\u3002", "conclusion": "ProbLog4Fairness \u4f18\u4e8e\u57fa\u7ebf\uff0c\u56e0\u4e3a\u5b83\u80fd\u591f\u7075\u6d3b\u5730\u5bf9\u76f8\u5173\u7684\u504f\u5dee\u5047\u8bbe\u8fdb\u884c\u5efa\u6a21\uff0c\u800c\u5176\u4ed6\u65b9\u6cd5\u901a\u5e38\u575a\u6301\u56fa\u5b9a\u7684\u504f\u5dee\u7c7b\u578b\u6216\u516c\u5e73\u6982\u5ff5\u3002"}}
{"id": "2511.09735", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.09735", "abs": "https://arxiv.org/abs/2511.09735", "authors": ["Ahmed Alia", "Mohcine Chraibi", "Armin Seyfried"], "title": "Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction", "comment": "19 pages, 9 figures, 4 tables", "summary": "In dynamic and crowded environments, realistic pedestrian trajectory prediction remains a challenging task due to the complex nature of human motion and the mutual influences among individuals. Deep learning models have recently achieved promising results by implicitly learning such patterns from 2D trajectory data. However, most approaches treat pedestrians as point entities, ignoring the physical space that each person occupies. To address these limitations, this paper proposes a novel deep learning model that enhances the Social LSTM with a new Dynamic Occupied Space loss function. This loss function guides Social LSTM in learning to avoid realistic collisions without increasing displacement error across different crowd densities, ranging from low to high, in both homogeneous and heterogeneous density settings. Such a function achieves this by combining the average displacement error with a new collision penalty that is sensitive to scene density and individual spatial occupancy. For efficient training and evaluation, five datasets were generated from real pedestrian trajectories recorded during the Festival of Lights in Lyon 2022. Four datasets represent homogeneous crowd conditions -- low, medium, high, and very high density -- while the fifth corresponds to a heterogeneous density distribution. The experimental findings indicate that the proposed model not only lowers collision rates but also enhances displacement prediction accuracy in each dataset. Specifically, the model achieves up to a 31% reduction in the collision rate and reduces the average displacement error and the final displacement error by 5% and 6%, respectively, on average across all datasets compared to the baseline. Moreover, the proposed model consistently outperforms several state-of-the-art deep learning models across most test sets.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u901a\u8fc7\u5f15\u5165\u52a8\u6001\u5360\u636e\u7a7a\u95f4\u635f\u5931\u51fd\u6570\u6765\u6539\u8fdb Social LSTM\uff0c\u4ece\u800c\u5728\u907f\u514d\u78b0\u649e\u7684\u540c\u65f6\u63d0\u9ad8\u8f68\u8ff9\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u884c\u4eba\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\u5ffd\u7565\u4e86\u884c\u4eba\u7684\u7269\u7406\u7a7a\u95f4\u5360\u7528\uff0c\u5bfc\u81f4\u5728\u62e5\u6324\u73af\u5883\u4e2d\u9884\u6d4b\u4e0d\u51c6\u786e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5e26\u6709\u52a8\u6001\u5360\u636e\u7a7a\u95f4\u635f\u5931\u51fd\u6570\u7684 Social LSTM \u6a21\u578b\uff0c\u8be5\u635f\u5931\u51fd\u6570\u7ed3\u5408\u4e86\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\u548c\u4e00\u4e2a\u5bf9\u573a\u666f\u5bc6\u5ea6\u548c\u4e2a\u4f53\u7a7a\u95f4\u5360\u7528\u654f\u611f\u7684\u78b0\u649e\u60e9\u7f5a\u9879\u3002", "result": "\u5728\u91cc\u6602\u706f\u5149\u8282 2022 \u671f\u95f4\u8bb0\u5f55\u7684\u771f\u5b9e\u884c\u4eba\u8f68\u8ff9\u751f\u6210\u7684\u4e94\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u6a21\u578b\u964d\u4f4e\u4e86\u78b0\u649e\u7387\uff0c\u5e76\u63d0\u9ad8\u4e86\u4f4d\u79fb\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002\u4e0e\u57fa\u7ebf\u76f8\u6bd4\uff0c\u78b0\u649e\u7387\u964d\u4f4e\u4e86 31%\uff0c\u5e73\u5747\u4f4d\u79fb\u8bef\u5dee\u548c\u6700\u7ec8\u4f4d\u79fb\u8bef\u5dee\u5206\u522b\u964d\u4f4e\u4e86 5% \u548c 6%\u3002", "conclusion": "\u8be5\u6a21\u578b\u5728\u5927\u591a\u6570\u6d4b\u8bd5\u96c6\u4e2d\u59cb\u7ec8\u4f18\u4e8e\u51e0\u79cd\u6700\u5148\u8fdb\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002"}}
{"id": "2511.09596", "categories": ["cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09596", "abs": "https://arxiv.org/abs/2511.09596", "authors": ["Mingkuan Zhao", "Wentao Hu", "Jiayin Wang", "Xin Lai", "Tianchen Huang", "Yuheng Min", "Rui Yan", "Xiaoyan Zhu"], "title": "Making Every Head Count: Sparse Attention Without the Speed-Performance Trade-off", "comment": null, "summary": "The design of Large Language Models (LLMs) has long been hampered by a fundamental conflict within their core attention mechanism: its remarkable expressivity is built upon a computational complexity of $O(H \\cdot N^2)$ that grows quadratically with the context size ($N$) and linearly with the number of heads ($H$). This standard implementation harbors significant computational redundancy, as all heads independently compute attention over the same sequence space. Existing sparse methods, meanwhile, often trade information integrity for computational efficiency. To resolve this efficiency-performance trade-off, we propose SPAttention, whose core contribution is the introduction of a new paradigm we term Principled Structural Sparsity. SPAttention does not merely drop connections but instead reorganizes the computational task by partitioning the total attention workload into balanced, non-overlapping distance bands, assigning each head a unique segment. This approach transforms the multi-head attention mechanism from $H$ independent $O(N^2)$ computations into a single, collaborative $O(N^2)$ computation, fundamentally reducing complexity by a factor of $H$. The structured inductive bias compels functional specialization among heads, enabling a more efficient allocation of computational resources from redundant modeling to distinct dependencies across the entire sequence span. Extensive empirical validation on the OLMoE-1B-7B and 0.25B-1.75B model series demonstrates that while delivering an approximately two-fold increase in training throughput, its performance is on par with standard dense attention, even surpassing it on select key metrics, while consistently outperforming representative sparse attention methods including Longformer, Reformer, and BigBird across all evaluation metrics.", "AI": {"tldr": "SPAttention\u901a\u8fc7\u5c06\u6ce8\u610f\u529b\u8ba1\u7b97\u5212\u5206\u4e3a\u5e73\u8861\u7684\u3001\u975e\u91cd\u53e0\u7684\u8ddd\u79bb\u5e26\u6765\u89e3\u51b3\u6548\u7387\u548c\u6027\u80fd\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u63d0\u9ad8\u8bad\u7ec3\u541e\u5410\u91cf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u6838\u5fc3\u6ce8\u610f\u529b\u673a\u5236\u7684\u663e\u8457\u8868\u8fbe\u80fd\u529b\u662f\u5efa\u7acb\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u4e4b\u4e0a\u7684\uff0c\u8be5\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u4e0a\u4e0b\u6587\u5927\u5c0f\uff08N\uff09\u5448\u4e8c\u6b21\u65b9\u589e\u957f\uff0c\u5e76\u4e14\u968f\u5934\u6570\uff08H\uff09\u5448\u7ebf\u6027\u589e\u957f\u3002", "method": "SPAttention \u5c06\u603b\u6ce8\u610f\u529b\u5de5\u4f5c\u8d1f\u8f7d\u5212\u5206\u4e3a\u5e73\u8861\u7684\u3001\u975e\u91cd\u53e0\u7684\u8ddd\u79bb\u5e26\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u5934\u5206\u914d\u4e00\u4e2a\u72ec\u7279\u7684\u6bb5\u3002", "result": "SPAttention \u5728 OLMoE-1B-7B \u548c 0.25B-1.75B \u6a21\u578b\u7cfb\u5217\u4e0a\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u9a8c\u8bc1\uff0c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8bad\u7ec3\u541e\u5410\u91cf\u5927\u7ea6\u63d0\u9ad8\u4e24\u500d\u7684\u540c\u65f6\uff0c\u5176\u6027\u80fd\u4e0e\u6807\u51c6\u5bc6\u96c6\u6ce8\u610f\u529b\u76f8\u5f53\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u5173\u952e\u6307\u6807\u4e0a\u8d85\u8fc7\u4e86\u6807\u51c6\u5bc6\u96c6\u6ce8\u610f\u529b\uff0c\u540c\u65f6\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5177\u6709\u4ee3\u8868\u6027\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u5305\u62ec Longformer\u3001Reformer \u548c BigBird\u3002", "conclusion": "SPAttention \u901a\u8fc7\u7ed3\u6784\u5316\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u4fc3\u4f7f\u5934\u4e4b\u95f4\u7684\u529f\u80fd\u4e13\u4e1a\u5316\uff0c\u4ece\u800c\u80fd\u591f\u66f4\u6709\u6548\u5730\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff0c\u4ece\u5197\u4f59\u5efa\u6a21\u5230\u6574\u4e2a\u5e8f\u5217\u8de8\u5ea6\u7684\u4e0d\u540c\u4f9d\u8d56\u5173\u7cfb\u3002"}}
