<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.CV](#cs.CV) [Total: 7]
- [cs.AI](#cs.AI) [Total: 9]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.IR](#cs.IR) [Total: 9]
- [cs.LG](#cs.LG) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MALIBU Benchmark: Multi-Agent LLM Implicit Bias Uncovered](https://arxiv.org/abs/2507.01019)
*Imran Mirza,Cole Huang,Ishwara Vasista,Rohan Patil,Asli Akalin,Sean O'Brien,Kevin Zhu*

Main category: cs.CL

TL;DR: MALIBU是一个评估LLM多智能体系统中社会偏见的基准。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统越来越多地用于基于角色的交互。然而，如果设计不仔细，这些系统会强化大型语言模型 (LLM) 中的隐含偏见，从而引发人们对公平和公正代表性的担忧。

Method: 通过基于场景的评估来评估基于 LLM 的多智能体系统中的偏差。AI 模型在预定义的环境中完成任务，他们的反应经过一个基于 LLM 的多智能体判断系统分两个阶段的评估。

Result: 量化了 LLM 生成的输出中的偏差，

Conclusion: 偏差缓解可能更偏向边缘化角色，而不是真正的中立，这表明需要在多智能体系统中进行细致的检测、平衡的公平策略和透明的评估基准。

Abstract: Multi-agent systems, which consist of multiple AI models interacting within a
shared environment, are increasingly used for persona-based interactions.
However, if not carefully designed, these systems can reinforce implicit biases
in large language models (LLMs), raising concerns about fairness and equitable
representation. We present MALIBU, a novel benchmark developed to assess the
degree to which LLM-based multi-agent systems implicitly reinforce social
biases and stereotypes. MALIBU evaluates bias in LLM-based multi-agent systems
through scenario-based assessments. AI models complete tasks within predefined
contexts, and their responses undergo evaluation by an LLM-based multi-agent
judging system in two phases. In the first phase, judges score responses
labeled with specific demographic personas (e.g., gender, race, religion)
across four metrics. In the second phase, judges compare paired responses
assigned to different personas, scoring them and selecting the superior
response. Our study quantifies biases in LLM-generated outputs, revealing that
bias mitigation may favor marginalized personas over true neutrality,
emphasizing the need for nuanced detection, balanced fairness strategies, and
transparent evaluation benchmarks in multi-agent systems.

</details>


### [2] [Event-based evaluation of abstractive news summarization](https://arxiv.org/abs/2507.01160)
*Huiling You,Samia Touileb,Erik Velldal,Lilja Øvrelid*

Main category: cs.CL

TL;DR: evaluate the quality of abstractive summaries by calculating overlapping events between generated summaries, reference summaries, and the original news articles


<details>
  <summary>Details</summary>
Motivation: The evaluation of automatically generated summaries relies heavily on human-authored summaries as gold references, by calculating overlapping units or similarity scores. News articles report events, and ideally so should the summaries.

Method: evaluate the quality of abstractive summaries by calculating overlapping events between generated summaries, reference summaries, and the original news articles

Result: experiment on a richly annotated Norwegian dataset comprising both events annotations and summaries authored by expert human annotators

Conclusion: The approach provides more insight into the event information contained in the summaries.

Abstract: An abstractive summary of a news article contains its most important
information in a condensed version. The evaluation of automatically generated
summaries by generative language models relies heavily on human-authored
summaries as gold references, by calculating overlapping units or similarity
scores. News articles report events, and ideally so should the summaries. In
this work, we propose to evaluate the quality of abstractive summaries by
calculating overlapping events between generated summaries, reference
summaries, and the original news articles. We experiment on a richly annotated
Norwegian dataset comprising both events annotations and summaries authored by
expert human annotators. Our approach provides more insight into the event
information contained in the summaries.

</details>


### [3] [Matching and Linking Entries in Historical Swedish Encyclopedias](https://arxiv.org/abs/2507.01170)
*Simon Börjesson,Erik Ersmark,Pierre Nugues*

Main category: cs.CL

TL;DR: 本文使用数字化版本的 Nordisk familjebok，通过语义嵌入匹配条目，提取地理条目并链接到 Wikidata，从而识别地理趋势的转变，发现焦点从欧洲转移到其他地区，反映了一战的影响。


<details>
  <summary>Details</summary>
Motivation: Nordisk familjebok 是一部 19 世纪和 20 世纪的瑞典百科全书。它由一个专家团队编写，旨在成为一个知识参考，强调精确性和准确性。随着新版本的发布，条目的选择和内容不断发展，反映了瑞典的知识变化。

Method: 使用基于 Transformer 的分类器从两个版本中提取地理条目，并将它们链接到 Wikidata。使用语义句子嵌入将原始文本重新分割成条目，并在第一版和第二版之间匹配条目对。

Result: 能够识别 1876-1899 年和 1904-1926 年间编写的第一版和第二版之间的地理趋势和可能的转变。

Conclusion: 观察到从第一版到第二版，地理焦点从欧洲略微但显著地转移到北美、非洲、亚洲、澳大利亚和斯堪的纳维亚北部，证实了第一次世界大战的影响和新势力的崛起。

Abstract: The \textit{Nordisk familjebok} is a Swedish encyclopedia from the 19th and
20th centuries. It was written by a team of experts and aimed to be an
intellectual reference, stressing precision and accuracy. This encyclopedia had
four main editions remarkable by their size, ranging from 20 to 38 volumes. As
a consequence, the \textit{Nordisk familjebok} had a considerable influence in
universities, schools, the media, and society overall. As new editions were
released, the selection of entries and their content evolved, reflecting
intellectual changes in Sweden.
  In this paper, we used digitized versions from \textit{Project Runeberg}. We
first resegmented the raw text into entries and matched pairs of entries
between the first and second editions using semantic sentence embeddings. We
then extracted the geographical entries from both editions using a
transformer-based classifier and linked them to Wikidata. This enabled us to
identify geographic trends and possible shifts between the first and second
editions, written between 1876-1899 and 1904-1926, respectively.
  Interpreting the results, we observe a small but significant shift in
geographic focus away from Europe and towards North America, Africa, Asia,
Australia, and northern Scandinavia from the first to the second edition,
confirming the influence of the First World War and the rise of new powers. The
code and data are available on GitHub at
https://github.com/sibbo/nordisk-familjebok.

</details>


### [4] [MEGA: xLSTM with Multihead Exponential Gated Fusion for Precise Aspect-based Sentiment Analysis](https://arxiv.org/abs/2507.01213)
*Adamu Lawan,Juhua Pu,Haruna Yunusa,Jawad Muhammad,Muhammad Lawan*

Main category: cs.CL

TL;DR: 提出了一种新的ABSA框架（MEGA），该框架结合了xLSTM和多头指数门控融合，以提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的ABSA方法难以平衡计算效率与高性能：深度学习模型通常缺乏全局上下文，transformers需要大量的计算资源，而基于Mamba的方法面临CUDA依赖性并降低了局部相关性。

Method: 提出了一种新颖的框架，该框架集成了具有前向和部分翻转后向（PF-mLSTM）流的双向mLSTM架构。引入了一种基于mLSTM的多头交叉指数门控融合机制（MECGAF），该机制动态地将前向mLSTM输出（作为查询和键）与PF-mLSTM输出（作为值）相结合，从而优化了短程依赖性捕获，同时保持了全局上下文和效率。

Result: MEGA在ABSA任务中实现了卓越的准确性和效率，优于现有技术水平。

Conclusion: MEGA在ABSA任务中表现出色，在三个基准数据集上优于最先进的基线，并在准确性和效率方面均表现出色。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a critical Natural Language
Processing (NLP) task that extracts aspects from text and determines their
associated sentiments, enabling fine-grained analysis of user opinions.
Existing ABSA methods struggle to balance computational efficiency with high
performance: deep learning models often lack global context, transformers
demand significant computational resources, and Mamba-based approaches face
CUDA dependency and diminished local correlations. Recent advancements in
Extended Long Short-Term Memory (xLSTM) models, particularly their efficient
modeling of long-range dependencies, have significantly advanced the NLP
community. However, their potential in ABSA remains untapped. To this end, we
propose xLSTM with Multihead Exponential Gated Fusion (MEGA), a novel framework
integrating a bi-directional mLSTM architecture with forward and partially
flipped backward (PF-mLSTM) streams. The PF-mLSTM enhances localized context
modeling by processing the initial sequence segment in reverse with dedicated
parameters, preserving critical short-range patterns. We further introduce an
mLSTM-based multihead cross exponential gated fusion mechanism (MECGAF) that
dynamically combines forward mLSTM outputs as query and key with PF-mLSTM
outputs as value, optimizing short-range dependency capture while maintaining
global context and efficiency. Experimental results on three benchmark datasets
demonstrate that MEGA outperforms state-of-the-art baselines, achieving
superior accuracy and efficiency in ABSA tasks.

</details>


### [5] [The Medium Is Not the Message: Deconfounding Text Embeddings via Linear Concept Erasure](https://arxiv.org/abs/2507.01234)
*Yu Fan,Yang Tian,Shauli Ravfogel,Mrinmaya Sachan,Elliott Ash,Alexander Hoyle*

Main category: cs.CL

TL;DR: 该论文提出了一种去偏算法，用于消除文本嵌入中的混淆因素，实验表明该算法可以提高文档相似性和聚类指标。


<details>
  <summary>Details</summary>
Motivation: 基于嵌入的文本序列之间的相似性度量可能受到文本的来源或语言等虚假属性的影响，而不仅仅是受我们最关心的内容维度的影响。这些文档混淆因素给许多应用带来了问题，尤其是那些需要汇集来自不同语料库的文本的应用。

Method: 去偏算法

Result: 文档相似性和聚类指标在所评估的每个嵌入变体和任务中都有所改进，而且改进幅度通常很大。有趣的是，在分布外基准上的性能没有受到影响，这表明嵌入没有以其他方式降级。

Conclusion: 消除了编码器表示中关于观察到的混淆因素的信息的去偏算法，大大减少了这些偏差，且计算成本极低。

Abstract: Embedding-based similarity metrics between text sequences can be influenced
not just by the content dimensions we most care about, but can also be biased
by spurious attributes like the text's source or language. These document
confounders cause problems for many applications, but especially those that
need to pool texts from different corpora. This paper shows that a debiasing
algorithm that removes information about observed confounders from the encoder
representations substantially reduces these biases at a minimal computational
cost. Document similarity and clustering metrics improve across every embedding
variant and task we evaluate -- often dramatically. Interestingly, performance
on out-of-distribution benchmarks is not impacted, indicating that the
embeddings are not otherwise degraded.

</details>


### [6] [GAIus: Combining Genai with Legal Clauses Retrieval for Knowledge-based Assistant](https://arxiv.org/abs/2507.01259)
*Michał Matak,Jarosław A. Chudziak*

Main category: cs.CL

TL;DR: This paper explores the use of large language models for legal information retrieval in non-English speaking countries, introduces a new LLM-based agent (gAIus) for Polish legal code, and demonstrates significant performance improvements over existing models.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the capability of large language models to provide accurate answers and references for legal matters in non-English and non-Chinese speaking countries. It discusses the history of legal information retrieval, the difference between case law and statute law, and analyzes recent research in the field.

Method: The paper introduces gAIus, a cognitive LLM-based agent architecture, using a retrieval mechanism that is more explainable and human-friendly than embedding-based approaches. A dataset based on Polish law apprenticeship entrance exam questions was created to evaluate the method.

Result: The proposed architecture significantly improved the performance of gpt-3.5-turbo-0125 by 419%, surpassing gpt-4o and increasing the gpt-4o-mini score from 31% to 86%.

Conclusion: The paper concludes by outlining potential future research directions and applications of the findings.

Abstract: In this paper we discuss the capability of large language models to base
their answer and provide proper references when dealing with legal matters of
non-english and non-chinese speaking country. We discuss the history of legal
information retrieval, the difference between case law and statute law, its
impact on the legal tasks and analyze the latest research in this field. Basing
on that background we introduce gAIus, the architecture of the cognitive
LLM-based agent, whose responses are based on the knowledge retrieved from
certain legal act, which is Polish Civil Code. We propose a retrieval mechanism
which is more explainable, human-friendly and achieves better results than
embedding-based approaches. To evaluate our method we create special dataset
based on single-choice questions from entrance exams for law apprenticeships
conducted in Poland. The proposed architecture critically leveraged the
abilities of used large language models, improving the gpt-3.5-turbo-0125 by
419%, allowing it to beat gpt-4o and lifting gpt-4o-mini score from 31% to 86%.
At the end of our paper we show the possible future path of research and
potential applications of our findings.

</details>


### [7] [Evaluating Large Language Models for Multimodal Simulated Ophthalmic Decision-Making in Diabetic Retinopathy and Glaucoma Screening](https://arxiv.org/abs/2507.01278)
*Cindy Lie Tabuse,David Restepo,Carolina Gracitelli,Fernando Korn Malerbi,Caio Regatieri,Luis Filipe Nakayama*

Main category: cs.CL

TL;DR: GPT-4's ability to interpret retinal fundus photographs for diabetic retinopathy and glaucoma screening was evaluated. It showed moderate performance for DR but poor performance for glaucoma, with metadata having no significant impact. LLMs may assist in education, documentation, or image annotation workflows in ophthalmology, but are not suitable for clinical use.


<details>
  <summary>Details</summary>
Motivation: LLMs can simulate clinical reasoning based on natural language prompts, but their utility in ophthalmology is largely unexplored. This study evaluated GPT-4's ability to interpret structured textual descriptions of retinal fundus photographs and simulate clinical decisions for diabetic retinopathy (DR) and glaucoma screening, including the impact of adding real or synthetic clinical metadata.

Method: GPT-4 received structured prompts describing each image, with or without patient metadata. The model was tasked with assigning an ICDR severity score, recommending DR referral, and estimating the cup-to-disc ratio for glaucoma referral. Performance was evaluated using accuracy, macro and weighted F1 scores, and Cohen's kappa. McNemar's test and change rate analysis were used to assess the influence of metadata.

Result: GPT-4 showed moderate performance for ICDR classification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25), driven mainly by correct identification of normal cases. Performance improved in the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For glaucoma referral, performance was poor across all settings (accuracy ~78%, F1 <0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes (McNemar p > 0.05), and predictions remained consistent across conditions.

Conclusion: GPT-4 can simulate basic ophthalmic decision-making from structured prompts but lacks precision for complex tasks. While not suitable for clinical use, LLMs may assist in education, documentation, or image annotation workflows in ophthalmology.

Abstract: Large language models (LLMs) can simulate clinical reasoning based on natural
language prompts, but their utility in ophthalmology is largely unexplored.
This study evaluated GPT-4's ability to interpret structured textual
descriptions of retinal fundus photographs and simulate clinical decisions for
diabetic retinopathy (DR) and glaucoma screening, including the impact of
adding real or synthetic clinical metadata. We conducted a retrospective
diagnostic validation study using 300 annotated fundus images. GPT-4 received
structured prompts describing each image, with or without patient metadata. The
model was tasked with assigning an ICDR severity score, recommending DR
referral, and estimating the cup-to-disc ratio for glaucoma referral.
Performance was evaluated using accuracy, macro and weighted F1 scores, and
Cohen's kappa. McNemar's test and change rate analysis were used to assess the
influence of metadata. GPT-4 showed moderate performance for ICDR
classification (accuracy 67.5%, macro F1 0.33, weighted F1 0.67, kappa 0.25),
driven mainly by correct identification of normal cases. Performance improved
in the binary DR referral task (accuracy 82.3%, F1 0.54, kappa 0.44). For
glaucoma referral, performance was poor across all settings (accuracy ~78%, F1
<0.04, kappa <0.03). Metadata inclusion did not significantly affect outcomes
(McNemar p > 0.05), and predictions remained consistent across conditions.
GPT-4 can simulate basic ophthalmic decision-making from structured prompts but
lacks precision for complex tasks. While not suitable for clinical use, LLMs
may assist in education, documentation, or image annotation workflows in
ophthalmology.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/abs/2507.01099)
*Zeyi Liu,Shuang Li,Eric Cousineau,Siyuan Feng,Benjamin Burchfiel,Shuran Song*

Main category: cs.CV

TL;DR: This paper proposes a 4D video generation model that enforces multi-view 3D consistency of videos by supervising the model with cross-view pointmap alignment during training. The model produces more visually stable and spatially aligned predictions and can be used to recover robot end-effector trajectories.


<details>
  <summary>Details</summary>
Motivation: Generating videos that are both temporally coherent and geometrically consistent across camera views remains a significant challenge.

Method: a 4D video generation model that enforces multi-view 3D consistency of videos by supervising the model with cross-view pointmap alignment during training

Result: produces more visually stable and spatially aligned predictions across multiple simulated and real-world robotic datasets

Conclusion: The predicted 4D videos can be used to recover robot end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting robust robot manipulation and generalization to novel camera viewpoints.

Abstract: Understanding and predicting the dynamics of the physical world can enhance a
robot's ability to plan and interact effectively in complex environments. While
recent video generation models have shown strong potential in modeling dynamic
scenes, generating videos that are both temporally coherent and geometrically
consistent across camera views remains a significant challenge. To address
this, we propose a 4D video generation model that enforces multi-view 3D
consistency of videos by supervising the model with cross-view pointmap
alignment during training. This geometric supervision enables the model to
learn a shared 3D representation of the scene, allowing it to predict future
video sequences from novel viewpoints based solely on the given RGB-D
observations, without requiring camera poses as inputs. Compared to existing
baselines, our method produces more visually stable and spatially aligned
predictions across multiple simulated and real-world robotic datasets. We
further show that the predicted 4D videos can be used to recover robot
end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting
robust robot manipulation and generalization to novel camera viewpoints.

</details>


### [9] [Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions](https://arxiv.org/abs/2507.01123)
*Rahul A. Burange,Harsh K. Shinde,Omkar Mutyalwar*

Main category: cs.CV

TL;DR: This study uses deep learning and satellite data to improve landslide detection and prediction, which can help with early warnings and disaster management.


<details>
  <summary>Details</summary>
Motivation: Accurate landslide detection and prediction are crucial due to the severe threats landslides pose to infrastructure, economies, and human lives. Automated detection has become more effective with advancements in deep learning and remote sensing.

Method: The study integrates multi-source satellite imagery (Sentinel-2, ALOS PALSAR-derived slope and DEM) with deep learning models (U-Net, DeepLabV3+, Res-Net) and geospatial analysis techniques to enhance landslide identification and prediction.

Result: The study evaluates the performance of multiple deep learning segmentation models and assesses the impact of terrain characteristics, vegetation cover, and rainfall on detection accuracy.

Conclusion: This study's findings highlight the potential of deep learning and multi-source remote sensing in developing robust, scalable, and transferable landslide prediction models, contributing to early warning systems, disaster risk management, and sustainable land-use planning.

Abstract: Landslides pose severe threats to infrastructure, economies, and human lives,
necessitating accurate detection and predictive mapping across diverse
geographic regions. With advancements in deep learning and remote sensing,
automated landslide detection has become increasingly effective. This study
presents a comprehensive approach integrating multi-source satellite imagery
and deep learning models to enhance landslide identification and prediction. We
leverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and
Digital Elevation Model (DEM) layers to capture critical environmental features
influencing landslide occurrences. Various geospatial analysis techniques are
employed to assess the impact of terra in characteristics, vegetation cover,
and rainfall on detection accuracy. Additionally, we evaluate the performance
of multiple stateof-the-art deep learning segmentation models, including U-Net,
DeepLabV3+, and Res-Net, to determine their effectiveness in landslide
detection. The proposed framework contributes to the development of reliable
early warning systems, improved disaster risk management, and sustainable
land-use planning. Our findings provide valuable insights into the potential of
deep learning and multi-source remote sensing in creating robust, scalable, and
transferable landslide prediction models.

</details>


### [10] [cp_measure: API-first feature extraction for image-based profiling workflows](https://arxiv.org/abs/2507.01163)
*Alán F. Muñoz,Tim Treis,Alexandr A. Kalinin,Shatavisha Dasgupta,Fabian Theis,Anne E. Carpenter,Shantanu Singh*

Main category: cs.CV

TL;DR: cp_measure is a Python library that extracts CellProfiler's core measurement capabilities into a modular, API-first tool designed for programmatic feature extraction, enabling reproducible, automated image-based profiling pipelines that scale effectively for machine learning applications in computational biology.


<details>
  <summary>Details</summary>
Motivation: current tools like CellProfiler can generate these feature sets, they pose significant barriers to automated and reproducible analyses, hindering machine learning workflows

Method: a Python library that extracts CellProfiler's core measurement capabilities into a modular, API-first tool designed for programmatic feature extraction

Result: cp_measure features retain high fidelity with CellProfiler features while enabling seamless integration with the scientific Python ecosystem

Conclusion: cp_measure enables reproducible, automated image-based profiling pipelines that scale effectively for machine learning applications in computational biology.

Abstract: Biological image analysis has traditionally focused on measuring specific
visual properties of interest for cells or other entities. A complementary
paradigm gaining increasing traction is image-based profiling - quantifying
many distinct visual features to form comprehensive profiles which may reveal
hidden patterns in cellular states, drug responses, and disease mechanisms.
While current tools like CellProfiler can generate these feature sets, they
pose significant barriers to automated and reproducible analyses, hindering
machine learning workflows. Here we introduce cp_measure, a Python library that
extracts CellProfiler's core measurement capabilities into a modular, API-first
tool designed for programmatic feature extraction. We demonstrate that
cp_measure features retain high fidelity with CellProfiler features while
enabling seamless integration with the scientific Python ecosystem. Through
applications to 3D astrocyte imaging and spatial transcriptomics, we showcase
how cp_measure enables reproducible, automated image-based profiling pipelines
that scale effectively for machine learning applications in computational
biology.

</details>


### [11] [Rapid Salient Object Detection with Difference Convolutional Neural Networks](https://arxiv.org/abs/2507.01182)
*Zhuo Su,Li Liu,Matthias Müller,Jiehua Zhang,Diana Wofk,Ming-Ming Cheng,Matti Pietikäinen*

Main category: cs.CV

TL;DR: 提出了一种高效的网络设计，结合了传统SOD方法和现代CNN的表示能力，实现了在资源受限设备上的实时显著目标检测。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的设备上部署具有实时性能的显著目标检测(SOD)面临挑战，现有的领先模型计算成本高昂。

Method: 结合了SOD的传统方法和现代CNN的表示能力，利用像素差卷积(PDCs)来编码特征对比，并引入差分卷积重参数化(DCR)策略将PDCs嵌入到标准卷积中，减少推理时的计算和参数。此外，还引入了时空差分卷积(STDC)用于视频SOD，通过时空对比捕获来增强标准3D卷积。

Result: SDNet和STDNet在效率和精度上取得了显著的改进，在Jetson Orin设备上，参数小于1M的模型在流式图像和视频上的运行速度分别为46 FPS和150 FPS，比第二好的轻量级模型快2倍以上和3倍以上，并且具有更高的精度。

Conclusion: SDNet和STDNet在图像和视频SOD上实现了效率和精度上的显著提升，在Jetson Orin设备上，参数小于1M的模型在流式图像和视频上的运行速度分别为46 FPS和150 FPS，在我们的实验中，速度比第二好的轻量级模型快2倍以上和3倍以上，并且具有更高的精度。

Abstract: This paper addresses the challenge of deploying salient object detection
(SOD) on resource-constrained devices with real-time performance. While recent
advances in deep neural networks have improved SOD, existing top-leading models
are computationally expensive. We propose an efficient network design that
combines traditional wisdom on SOD and the representation power of modern CNNs.
Like biologically-inspired classical SOD methods relying on computing contrast
cues to determine saliency of image regions, our model leverages Pixel
Difference Convolutions (PDCs) to encode the feature contrasts. Differently,
PDCs are incorporated in a CNN architecture so that the valuable contrast cues
are extracted from rich feature maps. For efficiency, we introduce a difference
convolution reparameterization (DCR) strategy that embeds PDCs into standard
convolutions, eliminating computation and parameters at inference.
Additionally, we introduce SpatioTemporal Difference Convolution (STDC) for
video SOD, enhancing the standard 3D convolution with spatiotemporal contrast
capture. Our models, SDNet for image SOD and STDNet for video SOD, achieve
significant improvements in efficiency-accuracy trade-offs. On a Jetson Orin
device, our models with $<$ 1M parameters operate at 46 FPS and 150 FPS on
streamed images and videos, surpassing the second-best lightweight models in
our experiments by more than $2\times$ and $3\times$ in speed with superior
accuracy. Code will be available at https://github.com/hellozhuo/stdnet.git.

</details>


### [12] [Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using Hölder Divergence and Mutual Information-Enhanced Knowledge Transfer](https://arxiv.org/abs/2507.01254)
*Runze Cheng,Xihang Qiu,Ming Li,Ye Zhang,Chun Li,Fei Yu*

Main category: cs.CV

TL;DR: This paper introduces a new MRI brain tumor segmentation framework that is robust to missing modalities by using Holder divergence and mutual information.


<details>
  <summary>Details</summary>
Motivation: Conventional methods for brain tumor segmentation struggle when certain MRI modalities are missing due to issues such as image quality, protocol inconsistencies, patient allergies, or financial constraints.

Method: The paper proposes a robust single-modality parallel processing framework that leverages Holder divergence and mutual information to maintain modality-specific features and dynamically adjust network parameters.

Result: The model achieves high segmentation accuracy even with incomplete modalities by quantifying discrepancies between predictions and ground-truth labels using divergence- and information-based loss functions.

Conclusion: The proposed framework demonstrates superior performance over existing methods in handling missing modalities, as shown by evaluations on the BraTS 2018 and BraTS 2020 datasets.

Abstract: Multimodal MRI provides critical complementary information for accurate brain
tumor segmentation. However, conventional methods struggle when certain
modalities are missing due to issues such as image quality, protocol
inconsistencies, patient allergies, or financial constraints. To address this,
we propose a robust single-modality parallel processing framework that achieves
high segmentation accuracy even with incomplete modalities. Leveraging Holder
divergence and mutual information, our model maintains modality-specific
features while dynamically adjusting network parameters based on the available
inputs. By using these divergence- and information-based loss functions, the
framework effectively quantifies discrepancies between predictions and
ground-truth labels, resulting in consistently accurate segmentation. Extensive
evaluations on the BraTS 2018 and BraTS 2020 datasets demonstrate superior
performance over existing methods in handling missing modalities.

</details>


### [13] [AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation](https://arxiv.org/abs/2507.01255)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 该论文提出了 AIGVE-MACS，一个用于评估 AI 生成视频的模型，它不仅提供数值评分，还能提供多方面的语言评论反馈。


<details>
  <summary>Details</summary>
Motivation: 现有的评估指标仅限于生成数值分数，缺乏解释性注释，导致可解释性低，与人类评估的一致性差。因此，需要一个鲁棒且可解释的评估框架。

Method: 该论文提出了 AIGVE-MACS，一个统一的 AI 生成视频评估模型，它结合了视觉-语言模型，并采用了新的 token-wise 加权损失和动态帧采样策略，以更好地与人类评估者对齐。

Result: AIGVE-MACS 在评分相关性和评论质量方面均达到了最先进的性能，并且通过 AIGVE-MACS 的反馈驱动视频生成的迭代改进，实现了 53.5% 的质量提升。

Conclusion: AIGVE-MACS 显著优于现有基线模型（包括 GPT-4o 和 VideoScore），并在视频生成质量上实现了 53.5% 的提升，为全面、与人类对齐的 AI 生成视频评估建立了一个新范式。该论文发布了 AIGVE-BENCH 2 和 AIGVE-MACS。

Abstract: The rapid advancement of AI-generated video models has created a pressing
need for robust and interpretable evaluation frameworks. Existing metrics are
limited to producing numerical scores without explanatory comments, resulting
in low interpretability and human evaluation alignment. To address those
challenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video
Evaluation(AIGVE), which can provide not only numerical scores but also
multi-aspect language comment feedback in evaluating these generated videos.
Central to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising
2,500 AI-generated videos and 22,500 human-annotated detailed comments and
numerical scores across nine critical evaluation aspects. Leveraging
AIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a
novel token-wise weighted loss and a dynamic frame sampling strategy to better
align with human evaluators. Comprehensive experiments across supervised and
zero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art
performance in both scoring correlation and comment quality, significantly
outperforming prior baselines including GPT-4o and VideoScore. In addition, we
further showcase a multi-agent refinement framework where feedback from
AIGVE-MACS drives iterative improvements in video generation, leading to 53.5%
quality enhancement. This work establishes a new paradigm for comprehensive,
human-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2
and AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.

</details>


### [14] [Advancements in Weed Mapping: A Systematic Review](https://arxiv.org/abs/2507.01269)
*Mohammad Jahanbakht,Alex Olsen,Ross Marchant,Emilie Fillols,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: This review addresses the gap in comprehensive weed mapping literature by systematically examining data acquisition, processing, and mapping techniques to guide future research and improve weed management.


<details>
  <summary>Details</summary>
Motivation: The lack of comprehensive literature reviews specifically focused on weed mapping, particularly a structured analysis spanning the entire mapping pipeline, limits progress in the field.

Method: A systematic review following PRISMA guidelines was conducted to examine state-of-the-art methods in data acquisition, data processing, and mapping techniques.

Result: The review critically evaluates and synthesizes key findings from the literature to provide a holistic understanding of the weed mapping landscape.

Conclusion: This review provides a holistic understanding of the weed mapping landscape, serving as a foundational reference to guide future research and support the development of efficient, scalable, and sustainable weed management systems.

Abstract: Weed mapping plays a critical role in precision management by providing
accurate and timely data on weed distribution, enabling targeted control and
reduced herbicide use. This minimizes environmental impacts, supports
sustainable land management, and improves outcomes across agricultural and
natural environments. Recent advances in weed mapping leverage ground-vehicle
Red Green Blue (RGB) cameras, satellite and drone-based remote sensing combined
with sensors such as spectral, Near Infra-Red (NIR), and thermal cameras. The
resulting data are processed using advanced techniques including big data
analytics and machine learning, significantly improving the spatial and
temporal resolution of weed maps and enabling site-specific management
decisions. Despite a growing body of research in this domain, there is a lack
of comprehensive literature reviews specifically focused on weed mapping. In
particular, the absence of a structured analysis spanning the entire mapping
pipeline, from data acquisition to processing techniques and mapping tools,
limits progress in the field. This review addresses these gaps by
systematically examining state-of-the-art methods in data acquisition (sensor
and platform technologies), data processing (including annotation and
modelling), and mapping techniques (such as spatiotemporal analysis and
decision support tools). Following PRISMA guidelines, we critically evaluate
and synthesize key findings from the literature to provide a holistic
understanding of the weed mapping landscape. This review serves as a
foundational reference to guide future research and support the development of
efficient, scalable, and sustainable weed management systems.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Rethinking the Illusion of Thinking](https://arxiv.org/abs/2507.01231)
*Iñaki Dellibarda Varela,Pablo Romero-Sorozabal,Eduardo Rocon,Manuel Cebrian*

Main category: cs.AI

TL;DR: This paper clarifies the debate around Apple's 'The Illusion of Thinking' paper, showing that LRMs have limitations in Towers of Hanoi but can solve River Crossing with solvable configurations, suggesting they are stochastic searchers and require fine-grained ablations for real progress.


<details>
  <summary>Details</summary>
Motivation: Apple ignited controversy by publishing 'The Illusion of Thinking,' prompting heated debate within the AI community. Critics seized upon the findings as conclusive evidence that Large Reasoning Models (LRMs) lack genuine reasoning capabilities, branding them as mere stochastic parrots. Meanwhile, defenders fired back, condemning the experimental setup as flawed and the conclusions overstated. We clarify this debate

Method: replicating and refining two of the original study's most contentious benchmarks: Towers of Hanoi and River Crossing. By introducing incremental stepwise prompting and agentic collaborative dialogue

Result: previously reported failures solving the Towers of Hanoi were not purely result of output constraints, but also partly a result of cognition limitations: LRMs still stumble when complexity rises moderately (around 8 disks). Moreover, the River Crossing results initially heralded as catastrophic failures turn out to hinge upon testing unsolvable configurations. Once we limit tests strictly to solvable problems-LRMs effortlessly solve large instances involving over 100 agent pairs.

Conclusion: LRMs are stochastic, RL-tuned searchers in a discrete state space we barely understand. Real progress in symbolic, long-horizon reasoning demands mapping that terrain through fine-grained ablations like those introduced here.

Abstract: Earlier this year, Apple ignited controversy by publishing "The Illusion of
Thinking," prompting heated debate within the AI community. Critics seized upon
the findings as conclusive evidence that Large Reasoning Models (LRMs) lack
genuine reasoning capabilities, branding them as mere stochastic parrots.
Meanwhile, defenders-spearheaded by Lawsen et al. (2025)-fired back, condemning
the experimental setup as flawed and the conclusions overstated. We clarify
this debate by replicating and refining two of the original study's most
contentious benchmarks: Towers of Hanoi and River Crossing. By introducing
incremental stepwise prompting and agentic collaborative dialogue, we show that
previously reported failures solving the Towers of Hanoi were not purely result
of output constraints, but also partly a result of cognition limitations: LRMs
still stumble when complexity rises moderately (around 8 disks). Moreover, the
River Crossing results initially heralded as catastrophic failures turn out to
hinge upon testing unsolvable configurations. Once we limit tests strictly to
solvable problems-LRMs effortlessly solve large instances involving over 100
agent pairs. Our findings ultimately defy simplistic narratives: today's LRMs
are stochastic, RL-tuned searchers in a discrete state space we barely
understand. Real progress in symbolic, long-horizon reasoning demands mapping
that terrain through fine-grained ablations like those introduced here.

</details>


### [16] [Beyond Black-Box AI: Interpretable Hybrid Systems for Dementia Care](https://arxiv.org/abs/2507.01282)
*Matthew JY Kang,Wenli Yang,Monica R Roberts,Byeong Ho Kang,Charles B Malpas*

Main category: cs.AI

TL;DR: 大型语言模型在医疗诊断中的应用受到数据驱动范例的限制，未来的研究应侧重于提高可解释性和临床医生理解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的最新繁荣重新点燃了人工智能（AI）系统可以帮助医疗诊断的希望。然而，尽管基准分数令人眼花缭乱，但LLM助手尚未在床边提供可衡量的改进。本次范围审查旨在强调人工智能在临床环境中做出实际贡献受到限制的领域，特别是在痴呆症诊断和护理方面。

Method: 范围审查

Result: 医生对LLM的邻近使用并没有导致更好的诊断准确性或速度。关键限制在于数据驱动的范例：缺乏透明度的黑盒输出、容易产生幻觉以及薄弱的因果推理。将统计学习与专家基于规则的知识相结合，并在整个过程中让临床医生参与的混合方法有助于恢复可解释性。正如PEIRS和ATHENA-CDS等例子所见，它们也更适合现有的临床工作流程。

Conclusion: 未来的决策支持应优先考虑通过将预测与临床意义的原因联系起来的解释连贯性。这可以通过神经符号或混合人工智能来实现，将LLM的语言能力与人类因果专业知识相结合。未来的研究不仅应通过准确性来衡量成功，还应通过临床医生理解、工作流程适应和患者结果的改进来衡量。

Abstract: The recent boom of large language models (LLMs) has re-ignited the hope that
artificial intelligence (AI) systems could aid medical diagnosis. Yet despite
dazzling benchmark scores, LLM assistants have yet to deliver measurable
improvements at the bedside. This scoping review aims to highlight the areas
where AI is limited to make practical contributions in the clinical setting,
specifically in dementia diagnosis and care.
  Standalone machine-learning models excel at pattern recognition but seldom
provide actionable, interpretable guidance, eroding clinician trust. Adjacent
use of LLMs by physicians did not result in better diagnostic accuracy or
speed. Key limitations trace to the data-driven paradigm: black-box outputs
which lack transparency, vulnerability to hallucinations, and weak causal
reasoning. Hybrid approaches that combine statistical learning with expert
rule-based knowledge, and involve clinicians throughout the process help bring
back interpretability. They also fit better with existing clinical workflows,
as seen in examples like PEIRS and ATHENA-CDS.
  Future decision-support should prioritise explanatory coherence by linking
predictions to clinically meaningful causes. This can be done through
neuro-symbolic or hybrid AI that combines the language ability of LLMs with
human causal expertise. AI researchers have addressed this direction, with
explainable AI and neuro-symbolic AI being the next logical steps in further
advancement in AI. However, they are still based on data-driven knowledge
integration instead of human-in-the-loop approaches. Future research should
measure success not only by accuracy but by improvements in clinician
understanding, workflow fit, and patient outcomes. A better understanding of
what helps improve human-computer interactions is greatly needed for AI systems
to become part of clinical practice.

</details>


### [17] [AI Agents and Agentic AI-Navigating a Plethora of Concepts for Future Manufacturing](https://arxiv.org/abs/2507.01376)
*Yinwang Ren,Yangyang Liu,Tang Ji,Xun Xu*

Main category: cs.AI

TL;DR: This paper reviews LLM-Agents, MLLM-Agents, and Agentic AI, exploring their applications in smart manufacturing and potential challenges.


<details>
  <summary>Details</summary>
Motivation: the definitions, capability boundaries, and practical applications of these emerging AI paradigms in smart manufacturing remain unclear

Method: systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI

Result: LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents (MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in information processing, environmental perception, and autonomous decision-making, opening new avenues for smart manufacturing

Conclusion: This study systematically reviews the evolution of AI and AI agent technologies, examines the core concepts and technological advancements of LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential applications in and integration into manufacturing, along with the potential challenges they may face.

Abstract: AI agents are autonomous systems designed to perceive, reason, and act within
dynamic environments. With the rapid advancements in generative AI (GenAI),
large language models (LLMs) and multimodal large language models (MLLMs) have
significantly improved AI agents' capabilities in semantic comprehension,
complex reasoning, and autonomous decision-making. At the same time, the rise
of Agentic AI highlights adaptability and goal-directed autonomy in dynamic and
complex environments. LLMs-based AI Agents (LLM-Agents), MLLMs-based AI Agents
(MLLM-Agents), and Agentic AI contribute to expanding AI's capabilities in
information processing, environmental perception, and autonomous
decision-making, opening new avenues for smart manufacturing. However, the
definitions, capability boundaries, and practical applications of these
emerging AI paradigms in smart manufacturing remain unclear. To address this
gap, this study systematically reviews the evolution of AI and AI agent
technologies, examines the core concepts and technological advancements of
LLM-Agents, MLLM-Agents, and Agentic AI, and explores their potential
applications in and integration into manufacturing, along with the potential
challenges they may face.

</details>


### [18] [A Fuzzy Approach to the Specification, Verification and Validation of Risk-Based Ethical Decision Making Models](https://arxiv.org/abs/2507.01410)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: Formal method to describe Ethical Decision Making models based on ethical risk assessment, models can be verified and validated using fuzzy Petri nets, a case study from the medical field is considered.


<details>
  <summary>Details</summary>
Motivation: The ontological and epistemic complexities inherent in the moral domain make it challenging to establish clear standards for evaluating the performance of a moral machine.

Method: We present a formal method to describe Ethical Decision Making models based on ethical risk assessment. Then, we show how these models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets.

Result: These models that are specified as fuzzy rules can be verified and validated using fuzzy Petri nets.

Conclusion: A case study from the medical field is considered to illustrate the proposed approach.

Abstract: The ontological and epistemic complexities inherent in the moral domain make
it challenging to establish clear standards for evaluating the performance of a
moral machine. In this paper, we present a formal method to describe Ethical
Decision Making models based on ethical risk assessment. Then, we show how
these models that are specified as fuzzy rules can be verified and validated
using fuzzy Petri nets. A case study from the medical field is considered to
illustrate the proposed approach.

</details>


### [19] [Pensieve Grader: An AI-Powered, Ready-to-Use Platform for Effortless Handwritten STEM Grading](https://arxiv.org/abs/2507.01431)
*Yoonseok Yang,Minjune Kim,Marlon Rondinelli,Keren Shao*

Main category: cs.AI

TL;DR: Pensieve is an AI-assisted grading platform that reduces grading time by 65% with high agreement with instructors.


<details>
  <summary>Details</summary>
Motivation: Grading handwritten, open-ended responses remains a major bottleneck in large university STEM courses.

Method: an AI-assisted grading platform that leverages large language models (LLMs) to transcribe and evaluate student work

Result: Pensieve has been deployed in real-world courses at over 20 institutions and has graded more than 300,000 student responses. Empirical results across four core STEM disciplines: Computer Science, Mathematics, Physics, and Chemistry.

Conclusion: Pensieve reduces grading time by an average of 65%, while maintaining a 95.4% agreement rate with instructor-assigned grades for high-confidence predictions.

Abstract: Grading handwritten, open-ended responses remains a major bottleneck in large
university STEM courses. We introduce Pensieve (https://www.pensieve.co), an
AI-assisted grading platform that leverages large language models (LLMs) to
transcribe and evaluate student work, providing instructors with rubric-aligned
scores, transcriptions, and confidence ratings. Unlike prior tools that focus
narrowly on specific tasks like transcription or rubric generation, Pensieve
supports the entire grading pipeline-from scanned student submissions to final
feedback-within a human-in-the-loop interface.
  Pensieve has been deployed in real-world courses at over 20 institutions and
has graded more than 300,000 student responses. We present system details and
empirical results across four core STEM disciplines: Computer Science,
Mathematics, Physics, and Chemistry. Our findings show that Pensieve reduces
grading time by an average of 65%, while maintaining a 95.4% agreement rate
with instructor-assigned grades for high-confidence predictions.

</details>


### [20] [Using multi-agent architecture to mitigate the risk of LLM hallucinations](https://arxiv.org/abs/2507.01446)
*Abd Elrahman Amer,Magdi Amer*

Main category: cs.AI

TL;DR: A multi-agent system using LLMs and fuzzy logic addresses customer requests via SMS, reducing hallucination risks.


<details>
  <summary>Details</summary>
Motivation: Improving customer service quality and response time are critical factors for maintaining customer loyalty and increasing a company's market share. The risk of hallucination remains a major challenge.

Method: LLM based agents with fuzzy logic

Result: A multi-agent system to handle customer requests sent via SMS.

Conclusion: This paper presents a multi-agent system to handle customer requests sent via SMS, integrating LLM based agents with fuzzy logic to mitigate hallucination risks.

Abstract: Improving customer service quality and response time are critical factors for
maintaining customer loyalty and increasing a company's market share. While
adopting emerging technologies such as Large Language Models (LLMs) is becoming
a necessity to achieve these goals, the risk of hallucination remains a major
challenge. In this paper, we present a multi-agent system to handle customer
requests sent via SMS. This system integrates LLM based agents with fuzzy logic
to mitigate hallucination risks.

</details>


### [21] [Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning](https://arxiv.org/abs/2507.01489)
*Yanfei Zhang*

Main category: cs.AI

TL;DR: This paper introduces Agent-as-tool, a hierarchical framework for LLM agents that separates tool calling from reasoning, achieving improved performance on the Bamboogle dataset.


<details>
  <summary>Details</summary>
Motivation: Previous studies struggle with simultaneously deciding the tool calling and reasoning processes, and rely on unprocessed tool results, burdening the model's reasoning capability.

Method: The paper proposes a hierarchical framework called Agent-as-tool that separates the tool calling process from the reasoning process.

Result: The Agent-as-tool framework achieves comparable results with slight reinforcement fine-tuning and outperforms Search-R1 on the Bamboogle dataset with 63.2% exact match and 75.2% cover exact match.

Conclusion: The proposed Agent-as-tool framework achieves comparable or better performance by detaching the tool calling and reasoning processes, as demonstrated on the Bamboogle dataset.

Abstract: Large Language Models (LLMs) have emerged as one of the most significant
technological advancements in artificial intelligence in recent years. Their
ability to understand, generate, and reason with natural language has
transformed how we interact with AI systems. With the development of LLM-based
agents and reinforcement-learning-based reasoning models, the study of applying
reinforcement learning in agent frameworks has become a new research focus.
However, all previous studies face the challenge of deciding the tool calling
process and the reasoning process simultaneously, and the chain of reasoning
was solely relied on the unprocessed raw result with redundant information and
symbols unrelated to the task from the tool, which impose a heavy burden on the
model's capability to reason. Therefore, in our research, we proposed a
hierarchical framework Agent-as-tool that detach the tool calling process and
the reasoning process, which enables the model to focus on the verbally
reasoning process while the tool calling process is handled by another agent.
Our work had achieved comparable results with only a slight reinforcement
fine-tuning on 180 samples, and had achieved exceptionally well performance in
Bamboogle with 63.2% of exact match and 75.2% in cover exact match, exceeding
Search-R1 by 4.8% in exact match and 3.2% in cover exact match.

</details>


### [22] [T3DM: Test-Time Training-Guided Distribution Shift Modelling for Temporal Knowledge Graph Reasoning](https://arxiv.org/abs/2507.01597)
*Yuehang Si,Zefan Zeng,Jincai Huang,Qing Cheng*

Main category: cs.AI

TL;DR: T3DM通过分布特征建模和对抗性负抽样，提高了时间知识图推理的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的时间知识图推理(TKGR)研究面临两个重大挑战：训练和测试样本之间事件分布偏移建模不足，以及依赖随机实体替换生成负样本，这通常导致低质量抽样。

Method: 一种用于训练TKGR模型的新的分布特征建模方法，测试时训练引导的分布偏移建模(T3DM)，以根据分布偏移调整模型，并确保模型推理的全局一致性。此外，设计了一种负抽样策略，以基于对抗性训练生成更高质量的负四元组。

Result: T3DM提供了更好、更稳健的结果。

Conclusion: T3DM在大多数情况下比最先进的基线提供更好、更稳健的结果。

Abstract: Temporal Knowledge Graph (TKG) is an efficient method for describing the
dynamic development of facts along a timeline. Most research on TKG reasoning
(TKGR) focuses on modelling the repetition of global facts and designing
patterns of local historical facts. However, they face two significant
challenges: inadequate modeling of the event distribution shift between
training and test samples, and reliance on random entity substitution for
generating negative samples, which often results in low-quality sampling. To
this end, we propose a novel distributional feature modeling approach for
training TKGR models, Test-Time Training-guided Distribution shift Modelling
(T3DM), to adjust the model based on distribution shift and ensure the global
consistency of model reasoning. In addition, we design a negative-sampling
strategy to generate higher-quality negative quadruples based on adversarial
training. Extensive experiments show that T3DM provides better and more robust
results than the state-of-the-art baselines in most cases.

</details>


### [23] [Agent Ideate: A Framework for Product Idea Generation from Patents Using Agentic AI](https://arxiv.org/abs/2507.01717)
*Gopichand Kanumolu,Ashok Urlana,Charaka Vinayak Kumar,Bala Mallikarjunarao Garlapati*

Main category: cs.AI

TL;DR: 本文利用大型语言模型（LLM）和自主代理来挖掘专利并从中生成产品概念。


<details>
  <summary>Details</summary>
Motivation: 专利包含丰富的技术知识，可以激发创新的产品创意，但访问和解释这些信息仍然是一个挑战。

Method: 我们设计了Agent Ideate，一个从专利中自动生成基于产品的商业想法的框架。 我们在三个领域（计算机科学、自然语言处理和材料化学）试验了开源LLM和基于Agent的架构。

Result: 评估结果表明，在想法质量、相关性和新颖性方面，Agent方法始终优于独立的LLM。

Conclusion: 结合LLM和Agent工作流可以通过释放专利数据中商业想法产生的未开发潜力，从而显著增强创新管道。

Abstract: Patents contain rich technical knowledge that can inspire innovative product
ideas, yet accessing and interpreting this information remains a challenge.
This work explores the use of Large Language Models (LLMs) and autonomous
agents to mine and generate product concepts from a given patent. In this work,
we design Agent Ideate, a framework for automatically generating product-based
business ideas from patents. We experimented with open-source LLMs and
agent-based architectures across three domains: Computer Science, Natural
Language Processing, and Material Chemistry. Evaluation results show that the
agentic approach consistently outperformed standalone LLMs in terms of idea
quality, relevance, and novelty. These findings suggest that combining LLMs
with agentic workflows can significantly enhance the innovation pipeline by
unlocking the untapped potential of business idea generation from patent data.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [24] [MobileRAG: A Fast, Memory-Efficient, and Energy-Efficient Method for On-Device RAG](https://arxiv.org/abs/2507.01079)
*Taehwan Park,Geonho Lee,Min-Soo Kim*

Main category: cs.DB

TL;DR: MobileRAG is proposed to enable RAG on mobile devices by combining EcoVector and SCR, outperforming conventional methods in resource efficiency and maintaining accuracy.


<details>
  <summary>Details</summary>
Motivation: Applying RAG on mobile devices is underexplored due to limited resources, and existing solutions are impractical for on-device scenarios.

Method: Combining a mobile-friendly vector search algorithm, EcoVector, with a lightweight Selective Content Reduction (SCR) method.

Result: EcoVector reduces memory and CPU usage, while SCR filters irrelevant text to diminish LM input size without degrading accuracy.

Conclusion: MobileRAG significantly outperforms conventional methods in latency, memory, and power while maintaining accuracy and enabling offline operation.

Abstract: Retrieval-Augmented Generation (RAG) has proven effective on server
infrastructures, but its application on mobile devices is still underexplored
due to limited memory and power resources. Existing vector search and RAG
solutions largely assume abundant computation resources, making them
impractical for on-device scenarios. In this paper, we propose MobileRAG, a
fully on-device pipeline that overcomes these limitations by combining a
mobile-friendly vector search algorithm, \textit{EcoVector}, with a lightweight
\textit{Selective Content Reduction} (SCR) method. By partitioning and
partially loading index data, EcoVector drastically reduces both memory
footprint and CPU usage, while the SCR method filters out irrelevant text to
diminish Language Model (LM) input size without degrading accuracy. Extensive
experiments demonstrated that MobileRAG significantly outperforms conventional
vector search and RAG methods in terms of latency, memory usage, and power
consumption, while maintaining accuracy and enabling offline operation to
safeguard privacy in resource-constrained environments.

</details>


### [25] [Handling out-of-order input arrival in CEP engines on the edge combining optimistic, pessimistic and lazy evaluation](https://arxiv.org/abs/2507.01461)
*Styliani Kyrama,Anastasios Gounaris*

Main category: cs.DB

TL;DR: LimeCEP is a hybrid CEP approach that combines lazy evaluation, buffering, and speculative processing to efficiently handle data inconsistencies while supporting multi-pattern detection under relaxed semantics.


<details>
  <summary>Details</summary>
Motivation: handling out-of-order, late, and duplicate events is critical for real-time analytics, especially on resource-constrained devices that process heterogeneous data from multiple sources

Method: a hybrid CEP approach that combines lazy evaluation, buffering, and speculative processing

Result: LimeCEP integrates Kafka for efficient message ordering, retention, and duplicate elimination, and offers configurable strategies to trade off between accuracy, latency, and resource consumption

Conclusion: LimeCEP achieves up to six orders of magnitude lower latency, with up to 10 times lower memory usage and 6 times lower CPU utilization, while maintaining near-perfect precision and recall under high-disorder input streams, making it well-suited for non-cloud deployments.

Abstract: In Complex Event Processing, handling out-of-order, late, and duplicate
events is critical for real-time analytics, especially on resource-constrained
devices that process heterogeneous data from multiple sources. We present
LimeCEP, a hybrid CEP approach that combines lazy evaluation, buffering, and
speculative processing to efficiently handle data inconsistencies while
supporting multi-pattern detection under relaxed semantics. LimeCEP integrates
Kafka for efficient message ordering, retention, and duplicate elimination, and
offers configurable strategies to trade off between accuracy, latency, and
resource consumption. Compared to state-of-the-art systems like SASE and
FlinkCEP, LimeCEP achieves up to six orders of magnitude lower latency, with up
to 10 times lower memory usage and 6 times lower CPU utilization, while
maintaining near-perfect precision and recall under high-disorder input
streams, making it well-suited for non-cloud deployments.

</details>


### [26] [Data Agent: A Holistic Architecture for Orchestrating Data+AI Ecosystems](https://arxiv.org/abs/2507.01599)
*Zhaoyan Sun,Jiayi Wang,Xinyang Zhao,Jiachi Wang,Guoliang Li*

Main category: cs.DB

TL;DR: This paper introduces the concept of a Data Agent, a novel architecture leveraging LLMs to orchestrate Data+AI ecosystems by integrating knowledge comprehension, reasoning, and planning capabilities, and showcases examples of its applications.


<details>
  <summary>Details</summary>
Motivation: Existing Data+AI systems have limited capabilities in semantic understanding, reasoning, and planning.

Method: incorporate LLM techniques to revolutionize data systems for orchestrating Data+AI applications effectively

Result: We present examples of data agent systems, including a data science agent, data analytics agents, and a database administrator (DBA) agent.

Conclusion: We propose the concept of a 'Data Agent' - a comprehensive architecture designed to orchestrate Data+AI ecosystems, which focuses on tackling data-related tasks by integrating knowledge comprehension, reasoning, and planning capabilities.

Abstract: Traditional Data+AI systems utilize data-driven techniques to optimize
performance, but they rely heavily on human experts to orchestrate system
pipelines, enabling them to adapt to changes in data, queries, tasks, and
environments. For instance, while there are numerous data science tools
available, developing a pipeline planning system to coordinate these tools
remains challenging. This difficulty arises because existing Data+AI systems
have limited capabilities in semantic understanding, reasoning, and planning.
Fortunately, we have witnessed the success of large language models (LLMs) in
enhancing semantic understanding, reasoning, and planning abilities. It is
crucial to incorporate LLM techniques to revolutionize data systems for
orchestrating Data+AI applications effectively.
  To achieve this, we propose the concept of a 'Data Agent' - a comprehensive
architecture designed to orchestrate Data+AI ecosystems, which focuses on
tackling data-related tasks by integrating knowledge comprehension, reasoning,
and planning capabilities. We delve into the challenges involved in designing
data agents, such as understanding data/queries/environments/tools,
orchestrating pipelines/workflows, optimizing and executing pipelines, and
fostering pipeline self-reflection. Furthermore, we present examples of data
agent systems, including a data science agent, data analytics agents (such as
unstructured data analytics agent, semantic structured data analytics agent,
data lake analytics agent, and multi-modal data analytics agent), and a
database administrator (DBA) agent. We also outline several open challenges
associated with designing data agent systems.

</details>


### [27] [PathDB: A system for evaluating regular path queries](https://arxiv.org/abs/2507.01755)
*Roberto García,Renzo Angles,Vicente Rojas,Sebastián Ferrada*

Main category: cs.DB

TL;DR: PathDB is a Java-based graph database optimized for in-memory path queries using RPQ and a modular design, outperforming DFS and BFS in benchmarks.


<details>
  <summary>Details</summary>
Motivation: The paper introduces PathDB, a Java-based graph database designed for in-memory data loading and querying, which motivates the need for a system optimized for path-based queries.

Method: PathDB utilizes Regular Path Queries (RPQ) and a closed path algebra, processing paths through a parser, logical plan, and physical plan.

Result: Benchmark experiments illustrate PathDB's performance compared to DFS and BFS.

Conclusion: PathDB demonstrates efficient execution times and flexibility in handling dynamic and complex path queries compared to baseline methods.

Abstract: PathDB is a Java-based graph database designed for in-memory data loading and
querying. By utilizing Regular Path Queries (RPQ) and a closed path algebra,
PathDB processes paths through its three main components: the parser, the
logical plan, and the physical plan. This modular design allows for targeted
optimizations and modifications without impacting overall functionality.
Benchmark experiments illustrate PathDB's execution times and flexibility in
handling dynamic and complex path queries, compared to baseline methods like
Depth-First Search (DFS) and Breadth-First Search (BFS) guided by an automaton,
highlighting its optimizations that contribute to its performance.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [28] [Can Argus Judge Them All? Comparing VLMs Across Domains](https://arxiv.org/abs/2507.01042)
*Harsh Joshi,Gautam Siddharth Kashyap,Rafiq Ali,Ebad Shabbir,Niharika Jain,Sarthak Jain,Jiechao Gao,Usman Naseem*

Main category: cs.IR

TL;DR: VLMs benchmarked for task consistency, revealing generalization vs. specialization trade-offs; CLIP generalizes best, BLIP excels on curated data, LXMERT leads in reasoning.


<details>
  <summary>Details</summary>
Motivation: VLMs are advancing multimodal AI, yet their performance consistency across tasks is underexamined.

Method: Benchmarked CLIP, BLIP, and LXMERT across diverse datasets spanning retrieval, captioning, and reasoning, including task accuracy, generation quality, efficiency, and a novel Cross-Dataset Consistency (CDC) metric.

Result: CLIP shows strongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT leads in structured reasoning.

Conclusion: VLMs exhibit trade-offs between generalization and specialization.

Abstract: Vision-Language Models (VLMs) are advancing multimodal AI, yet their
performance consistency across tasks is underexamined. We benchmark CLIP, BLIP,
and LXMERT across diverse datasets spanning retrieval, captioning, and
reasoning. Our evaluation includes task accuracy, generation quality,
efficiency, and a novel Cross-Dataset Consistency (CDC) metric. CLIP shows
strongest generalization (CDC: 0.92), BLIP excels on curated data, and LXMERT
leads in structured reasoning. These results expose trade-offs between
generalization and specialization, informing industrial deployment of VLMs and
guiding development toward robust, task-flexible architectures.

</details>


### [29] [Conversational LLMs Simplify Secure Clinical Data Access, Understanding, and Analysis](https://arxiv.org/abs/2507.01053)
*Rafi Al Attrach,Pedro Moreira,Rajna Fani,Renato Umeton,Leo Anthony Celi*

Main category: cs.IR

TL;DR: M3 lowers the technical barrier to understanding and querying MIMIC-IV data by allowing researchers to converse with the database in plain English.


<details>
  <summary>Details</summary>
Motivation: The complexity of large clinical datasets like MIMIC-IV, particularly the need for sophisticated querying skills and understanding of clinical settings, presents a significant barrier to their effective use.

Method: M3 uses a language model to translate natural language questions into SQL, executes the query against the MIMIC-IV dataset, and returns structured results alongside the underlying query.

Result: Demonstrations show that minutes of dialogue with M3 yield nuanced cohort analyses that once demanded hours of handcrafted SQL.

Conclusion: M3 simplifies access to clinical critical-care data, inviting broader research community participation and accelerating the translation of raw records into actionable insight.

Abstract: As ever-larger clinical datasets become available, they have the potential to
unlock unprecedented opportunities for medical research. Foremost among them is
Medical Information Mart for Intensive Care (MIMIC-IV), the world's largest
open-source EHR database. However, the inherent complexity of these datasets,
particularly the need for sophisticated querying skills and the need to
understand the underlying clinical settings, often presents a significant
barrier to their effective use. M3 lowers the technical barrier to
understanding and querying MIMIC-IV data. With a single command it retrieves
MIMIC-IV from PhysioNet, launches a local SQLite instance (or hooks into the
hosted BigQuery), and-via the Model Context Protocol (MCP)-lets researchers
converse with the database in plain English. Ask a clinical question in natural
language; M3 uses a language model to translate it into SQL, executes the query
against the MIMIC-IV dataset, and returns structured results alongside the
underlying query for verifiability and reproducibility. Demonstrations show
that minutes of dialogue with M3 yield the kind of nuanced cohort analyses that
once demanded hours of handcrafted SQL and relied on understanding the
complexities of clinical workflows. By simplifying access, M3 invites the
broader research community to mine clinical critical-care data and accelerates
the translation of raw records into actionable insight.

</details>


### [30] [Cohort Retrieval using Dense Passage Retrieval](https://arxiv.org/abs/2507.01049)
*Pranav Jadhav*

Main category: cs.IR

TL;DR: Applies Dense Passage Retrieval (DPR) for patient cohort retrieval in the echocardiography domain and shows superior performance.


<details>
  <summary>Details</summary>
Motivation: Patient cohort retrieval is a pivotal task in medical research and clinical practice, enabling the identification of specific patient groups from extensive electronic health records (EHRs).

Method: Applying Dense Passage Retrieval (DPR) to transform an echocardiographic EHR dataset of unstructured nature into a Query-Passage dataset.

Result: A custom-trained DPR embedding model demonstrates superior performance compared to traditional and off-the-shelf SOTA methods.

Conclusion: This paper is the first to apply DPR for patient cohort retrieval in the echocardiography domain, establishing a framework that can be adapted to other medical domains.

Abstract: Patient cohort retrieval is a pivotal task in medical research and clinical
practice, enabling the identification of specific patient groups from extensive
electronic health records (EHRs). In this work, we address the challenge of
cohort retrieval in the echocardiography domain by applying Dense Passage
Retrieval (DPR), a prominent methodology in semantic search. We propose a
systematic approach to transform an echocardiographic EHR dataset of
unstructured nature into a Query-Passage dataset, framing the problem as a
Cohort Retrieval task. Additionally, we design and implement evaluation metrics
inspired by real-world clinical scenarios to rigorously test the models across
diverse retrieval tasks. Furthermore, we present a custom-trained DPR embedding
model that demonstrates superior performance compared to traditional and
off-the-shelf SOTA methods.To our knowledge, this is the first work to apply
DPR for patient cohort retrieval in the echocardiography domain, establishing a
framework that can be adapted to other medical domains.

</details>


### [31] [Enhanced Influence-aware Group Recommendation for Online Media Propagation](https://arxiv.org/abs/2507.01616)
*Chengkun He,Xiangmin Zhou,Chen Wang,Longbing Cao,Jie Shao,Xiaodong Li,Guang Xu,Carrie Jinqiu Hu,Zahir Tari*

Main category: cs.IR

TL;DR: 提出EIGR框架，通过GES策略、DYIC模型和UG-Index来解决影响感知群体推荐中的挑战，并在实际数据集中表现出色。


<details>
  <summary>Details</summary>
Motivation: 社交媒体流上的群体推荐因其在电子商务、娱乐和在线新闻广播等领域的广泛应用而备受关注。由于社交图的大规模和不断增长、用户组内影响传播的动态性以及实时群体项目匹配的高计算开销，影响感知群体推荐仍然具有挑战性。

Method: GES策略最小化多个时间社交图中的冗余，DYIC模型预测社交项目和用户组的影响传播，UG-Index高效组织用户组并实现实时推荐生成。

Result: EIGR框架在实际数据集上优于最先进的基线。

Conclusion: EIGR框架在有效性和效率方面始终优于最先进的基线。

Abstract: Group recommendation over social media streams has attracted significant
attention due to its wide applications in domains such as e-commerce,
entertainment, and online news broadcasting. By leveraging social connections
and group behaviours, group recommendation (GR) aims to provide more accurate
and engaging content to a set of users rather than individuals. Recently,
influence-aware GR has emerged as a promising direction, as it considers the
impact of social influence on group decision-making. In earlier work, we
proposed Influence-aware Group Recommendation (IGR) to solve this task.
However, this task remains challenging due to three key factors: the large and
ever-growing scale of social graphs, the inherently dynamic nature of influence
propagation within user groups, and the high computational overhead of
real-time group-item matching.
  To tackle these issues, we propose an Enhanced Influence-aware Group
Recommendation (EIGR) framework. First, we introduce a Graph Extraction-based
Sampling (GES) strategy to minimise redundancy across multiple temporal social
graphs and effectively capture the evolving dynamics of both groups and items.
Second, we design a novel DYnamic Independent Cascade (DYIC) model to predict
how influence propagates over time across social items and user groups.
Finally, we develop a two-level hash-based User Group Index (UG-Index) to
efficiently organise user groups and enable real-time recommendation
generation. Extensive experiments on real-world datasets demonstrate that our
proposed framework, EIGR, consistently outperforms state-of-the-art baselines
in both effectiveness and efficiency.

</details>


### [32] [A Data Science Approach to Calcutta High Court Judgments: An Efficient LLM and RAG-powered Framework for Summarization and Similar Cases Retrieval](https://arxiv.org/abs/2507.01058)
*Puspendu Banerjee,Aritra Mazumdar,Wazib Ansar,Saptarsi Goswami,Amlan Chakrabarti*

Main category: cs.IR

TL;DR: 利用 LLM 和 RAG 技术改进加尔各答高等法院判决分析的效率。


<details>
  <summary>Details</summary>
Motivation: 作为民主三大支柱之一的司法机构，正在处理越来越多的法律问题，需要谨慎利用司法资源。

Method: 利用数据科学方法，特别是大型语言模型 (LLM) 和检索增强生成 (RAG) 技术。

Result: 通过使用案例标题摘要微调 Pegasus 模型，我们在法律案例的摘要方面取得了显着改进。我们的两步总结技术保留了关键的法律背景，从而可以生成用于 RAG 的综合向量数据库。RAG 驱动的框架可以有效地检索与用户查询类似的案例，从而提供全面的概述和总结。

Conclusion: 该技术不仅提高了法律研究效率，而且有助于法律专业人士和学生轻松获取和掌握关键法律信息，从而有益于整个法律领域。

Abstract: The judiciary, as one of democracy's three pillars, is dealing with a rising
amount of legal issues, needing careful use of judicial resources. This
research presents a complex framework that leverages Data Science
methodologies, notably Large Language Models (LLM) and Retrieval-Augmented
Generation (RAG) techniques, to improve the efficiency of analyzing Calcutta
High Court verdicts. Our framework focuses on two key aspects: first, the
creation of a robust summarization mechanism that distills complex legal texts
into concise and coherent summaries; and second, the development of an
intelligent system for retrieving similar cases, which will assist legal
professionals in research and decision making. By fine-tuning the Pegasus model
using case head note summaries, we achieve significant improvements in the
summarization of legal cases. Our two-step summarizing technique preserves
crucial legal contexts, allowing for the production of a comprehensive vector
database for RAG. The RAG-powered framework efficiently retrieves similar cases
in response to user queries, offering thorough overviews and summaries. This
technique not only improves legal research efficiency, but it also helps legal
professionals and students easily acquire and grasp key legal information,
benefiting the overall legal scenario.

</details>


### [33] [Optimizing Conversational Product Recommendation via Reinforcement Learning](https://arxiv.org/abs/2507.01060)
*Kang Liu*

Main category: cs.IR

TL;DR: 本文提出了一种基于强化学习的对话策略优化方法，旨在提高产品推荐过程中的用户参与度和转化率。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的组织采用智能代理来支持销售和服务运营，对话的有效性不仅取决于推荐什么，还取决于推荐的方式和时间。

Method: 使用强化学习方法学习最优对话策略。

Result: 代理能够改进对话策略，提高用户参与度和产品接受度。

Conclusion: 这篇论文提出了一个基于强化学习的方法，用于优化跨行业产品推荐的对话策略，通过挖掘用户行为模式和转化结果，使agent能够改进对话策略，提高用户参与度和产品接受度。

Abstract: We propose a reinforcement learning-based approach to optimize conversational
strategies for product recommendation across diverse industries. As
organizations increasingly adopt intelligent agents to support sales and
service operations, the effectiveness of a conversation hinges not only on what
is recommended but how and when recommendations are delivered. We explore a
methodology where agentic systems learn optimal dialogue policies through
feedback-driven reinforcement learning. By mining aggregate behavioral patterns
and conversion outcomes, our approach enables agents to refine talk tracks that
drive higher engagement and product uptake, while adhering to contextual and
regulatory constraints. We outline the conceptual framework, highlight key
innovations, and discuss the implications for scalable, personalized
recommendation in enterprise environments.

</details>


### [34] [FAIR-MATCH: A Multi-Objective Framework for Bias Mitigation in Reciprocal Dating Recommendations](https://arxiv.org/abs/2507.01063)
*Madhav Kotecha*

Main category: cs.IR

TL;DR: 本研究分析了约会应用程序推荐系统，强调了关键问题，并提出了研究支持的解决方案，以解决算法偏差并提高性能。


<details>
  <summary>Details</summary>
Motivation: 当前约会应用中的推荐系统存在显著的算法缺陷，包括但不限于受欢迎程度偏差、过滤气泡效应和不充分的互惠建模，这些缺陷限制了有效性并引入了有害的偏差。

Method: 通过分析相互推荐框架、公平性评估指标和行业实施，

Result: 目前的系统性能适中，协同过滤达到 25.1%，而互惠方法达到 28.7%。

Conclusion: 提出了一个数学框架，通过增强的相似性度量、多目标优化和公平感知算法来解决这些限制，这些算法在保持竞争精度的同时，改进了人口统计学表示，以减少算法偏差。

Abstract: Online dating platforms have fundamentally transformed the formation of
romantic relationships, with millions of users worldwide relying on algorithmic
matching systems to find compatible partners. However, current recommendation
systems in dating applications suffer from significant algorithmic
deficiencies, including but not limited to popularity bias, filter bubble
effects, and inadequate reciprocity modeling that limit effectiveness and
introduce harmful biases. This research integrates foundational work with
recent empirical findings to deliver a detailed analysis of dating app
recommendation systems, highlighting key issues and suggesting research-backed
solutions. Through analysis of reciprocal recommendation frameworks, fairness
evaluation metrics, and industry implementations, we demonstrate that current
systems achieve modest performance with collaborative filtering reaching 25.1\%
while reciprocal methods achieve 28.7\%. Our proposed mathematical framework
addresses these limitations through enhanced similarity measures,
multi-objective optimization, and fairness-aware algorithms that maintain
competitive accuracy while improving demographic representation to reduce
algorithmic bias.

</details>


### [35] [Embedding-based Retrieval in Multimodal Content Moderation](https://arxiv.org/abs/2507.01066)
*Hanzhong Liang,Jinghao Shi,Xiang Shen,Zixuan Wang,Vera Wen,Ardalan Mehrani,Zhiqian Chen,Yifan Wu,Zhixin Zhang*

Main category: cs.IR

TL;DR: 提出了一种基于嵌入的检索 (EBR) 方法，以补充传统的分类方法，用于短视频平台上的内容审核，从而提高效率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 传统的分类方法在需要快速和经济高效的响应的场景中表现不佳，例如趋势适应和紧急升级。

Method: 利用监督对比学习 (SCL) 框架训练了一套基础嵌入模型，包括单模态和多模态架构，并设计和实施了基于嵌入的检索系统，该系统集成了嵌入生成和视频检索，以实现高效和有效的趋势处理。

Result: 离线实验表明，EBR 将 ROC-AUC 从 0.85 提高到 0.99，PR-AUC 从 0.35 提高到 0.95。在线实验表明，EBR 将操作率提高了 10.32%，并将运营成本降低了 80% 以上。

Conclusion: EBR通过提高效率、降低成本并增强可解释性和灵活性，优于基于分类的解决方案。

Abstract: Video understanding plays a fundamental role for content moderation on short
video platforms, enabling the detection of inappropriate content. While
classification remains the dominant approach for content moderation, it often
struggles in scenarios requiring rapid and cost-efficient responses, such as
trend adaptation and urgent escalations. To address this issue, we introduce an
Embedding-Based Retrieval (EBR) method designed to complement traditional
classification approaches. We first leverage a Supervised Contrastive Learning
(SCL) framework to train a suite of foundation embedding models, including both
single-modal and multi-modal architectures. Our models demonstrate superior
performance over established contrastive learning methods such as CLIP and
MoCo. Building on these embedding models, we design and implement the
embedding-based retrieval system that integrates embedding generation and video
retrieval to enable efficient and effective trend handling. Comprehensive
offline experiments on 25 diverse emerging trends show that EBR improves
ROC-AUC from 0.85 to 0.99 and PR-AUC from 0.35 to 0.95. Further online
experiments reveal that EBR increases action rates by 10.32% and reduces
operational costs by over 80%, while also enhancing interpretability and
flexibility compared to classification-based solutions.

</details>


### [36] [Towards a Signal Detection Based Measure for Assessing Information Quality of Explainable Recommender Systems](https://arxiv.org/abs/2507.01168)
*Yeonbin Son,Matthew L. Bolton*

Main category: cs.IR

TL;DR: This paper proposes an objective metric, Veracity, to evaluate the quality of explanations in recommender systems, which is decomposed into Fidelity and Attunement. The metric's effectiveness is validated through experiments.


<details>
  <summary>Details</summary>
Motivation: Existing evaluations of recommender systems primarily focus on recommendation performance, with limited assessment of explanation quality, often relying on subjective user opinions. This paper aims to fill this gap by developing an objective metric to evaluate the information quality of explanations.

Method: The paper decomposes Veracity into Fidelity and Attunement, uses signal detection theory to determine decision outcomes for each dimension, and combines them to calculate a sensitivity, which serves as the final Veracity value.

Result: The results of the four cases provided meaningful insights into the effectiveness of the proposed Veracity metric in capturing differences in information quality.

Conclusion: The paper introduces an objective metric, Veracity, to evaluate the information quality of explanations in recommender systems. The effectiveness of the metric is validated through four cases.

Abstract: There is growing interest in explainable recommender systems that provide
recommendations along with explanations for the reasoning behind them. When
evaluating recommender systems, most studies focus on overall recommendation
performance. Only a few assess the quality of the explanations. Explanation
quality is often evaluated through user studies that subjectively gather users'
opinions on representative explanatory factors that shape end-users'
perspective towards the results, not about the explanation contents itself. We
aim to fill this gap by developing an objective metric to evaluate Veracity:
the information quality of explanations. Specifically, we decompose Veracity
into two dimensions: Fidelity and Attunement. Fidelity refers to whether the
explanation includes accurate information about the recommended item.
Attunement evaluates whether the explanation reflects the target user's
preferences. By applying signal detection theory, we first determine decision
outcomes for each dimension and then combine them to calculate a sensitivity,
which serves as the final Veracity value. To assess the effectiveness of the
proposed metric, we set up four cases with varying levels of information
quality to validate whether our metric can accurately capture differences in
quality. The results provided meaningful insights into the effectiveness of our
proposed metric.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [37] [Few-Shot Inspired Generative Zero-Shot Learning](https://arxiv.org/abs/2507.01026)
*Md Shakil Ahamed Shohag,Q. M. Jonathan Wu,Farhad Pourpanah*

Main category: cs.LG

TL;DR: FSIGenZ: a few-shot-inspired generative ZSL framework that reduces reliance on large-scale feature synthesis.


<details>
  <summary>Details</summary>
Motivation: conventional ZSL methods treat them as uniformly present. To address this, we introduce Model-Specific Attribute Scoring (MSAS), which dynamically re-scores class attributes based on model-specific optimization to approximate instance-level variability without access to unseen data.

Method: introduce Model-Specific Attribute Scoring (MSAS), estimate group-level prototypes as clusters of instances based on MSAS-adjusted attribute scores, introduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training a semantic-aware contrastive classifier (SCC) using these prototypes

Result: Experiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves competitive performance using far fewer synthetic features.

Conclusion: FSIGenZ achieves competitive performance using far fewer synthetic features.

Abstract: Generative zero-shot learning (ZSL) methods typically synthesize visual
features for unseen classes using predefined semantic attributes, followed by
training a fully supervised classification model. While effective, these
methods require substantial computational resources and extensive synthetic
data, thereby relaxing the original ZSL assumptions. In this paper, we propose
FSIGenZ, a few-shot-inspired generative ZSL framework that reduces reliance on
large-scale feature synthesis. Our key insight is that class-level attributes
exhibit instance-level variability, i.e., some attributes may be absent or
partially visible, yet conventional ZSL methods treat them as uniformly
present. To address this, we introduce Model-Specific Attribute Scoring (MSAS),
which dynamically re-scores class attributes based on model-specific
optimization to approximate instance-level variability without access to unseen
data. We further estimate group-level prototypes as clusters of instances based
on MSAS-adjusted attribute scores, which serve as representative synthetic
features for each unseen class. To mitigate the resulting data imbalance, we
introduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training
a semantic-aware contrastive classifier (SCC) using these prototypes.
Experiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves
competitive performance using far fewer synthetic features.

</details>


### [38] [DBellQuant: Breaking the Bell with Double-Bell Transformation for LLMs Post Training Binarization](https://arxiv.org/abs/2507.01027)
*Zijian Ye,Wei Huang,Yifei Yu,Tianhe Ren,Zhongrui Wang,Xiaojuan Qi*

Main category: cs.LG

TL;DR: DBellQuant 是一种创新的训练后量化 (PTQ) 框架，通过使用 Learnable Transformation for Dual-Bell (LTDB) 算法，实现了近 1 位权重压缩和 6 位激活量化，且性能下降最小。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 表现出卓越的性能，但面临着巨大的计算和内存挑战，这限制了它们的实际部署。量化已成为一种有前途的解决方案；然而，其有效性通常受到权重分布（不利于量化）和激活异常值引起的量化误差的限制。

Method: DBellQuant 使用可学习变换进行双峰 (LTDB) 算法，该算法将单峰权重分布转换为双峰形式以减少二值化误差，并将逆变换应用于平滑激活。

Result: DBellQuant 实现了近 1 位权重压缩和 6 位激活量化，且性能下降最小。例如，在 Wikitext2 数据集上，DBellQuant 在 LLaMA2-13B 上实现了 14.39 的困惑度，具有 6 位激活量化，明显优于 BiLLM 的 21.35，而没有激活量化，突显了其在压缩 LLM 以用于实际应用中的潜力。

Conclusion: DBellQuant 通过在积极的权重和激活量化下保持卓越的模型性能，创造了新的技术水平。

Abstract: Large language models (LLMs) demonstrate remarkable performance but face
substantial computational and memory challenges that limit their practical
deployment. Quantization has emerged as a promising solution; however, its
effectiveness is often limited by quantization errors arising from weight
distributions that are not quantization-friendly and the presence of activation
outliers. To address these challenges, we introduce DBellQuant, an innovative
post-training quantization (PTQ) framework that achieves nearly 1-bit weight
compression and 6-bit activation quantization with minimal performance
degradation. DBellQuant uses Learnable Transformation for Dual-Bell (LTDB)
algorithm, which transforms single-bell weight distributions into dual-bell
forms to reduce binarization errors and applies inverse transformations to
smooth activations. DBellQuant sets a new state-of-the-art by preserving
superior model performance under aggressive weight and activation quantization.
For example, on the Wikitext2 dataset, DBellQuant achieves a perplexity of
14.39 on LLaMA2-13B with 6-bit activation quantization, significantly
outperforming BiLLM's 21.35 without activation quantization, underscoring its
potential in compressing LLMs for real-world applications.

</details>


### [39] [Dual Perspectives on Non-Contrastive Self-Supervised Learning](https://arxiv.org/abs/2507.01028)
*Jean Ponce,Martial Hebert,Basile Terver*

Main category: cs.LG

TL;DR: 该论文研究了非对比自监督学习中的停止梯度和指数移动平均程序，表明它们可以避免表示崩溃，并且相关的动态系统是稳定的。


<details>
  <summary>Details</summary>
Motivation: 非对比自监督学习的目标是训练一个编码器和一个预测器，该预测器可以最小化从第一个视图的嵌入预测的代码与第二个视图的嵌入之间的平均差异。在这种情况下，停止梯度和指数移动平均迭代程序通常用于避免表示崩溃，并在下游监督应用中具有出色的性能。

Method: 该论文从优化和动力系统的双重理论角度研究了这些程序。

Result: 该论文表明，通常情况下，虽然它们没有优化原始目标，或者就此而言，没有优化任何其他平滑函数，但它们确实避免了崩溃。然后，我们使用动态系统视角表明，在没有停止梯度或指数移动平均的情况下，最小化原始目标函数总是会导致崩溃。相反，我们最终表明，与这两个程序相关的动态系统的极限点通常是渐近稳定的平衡，没有退化为平凡解的风险。

Conclusion: 该论文表明，停止梯度和指数移动平均迭代程序可以避免表示崩溃，并且与这些程序相关的动态系统的极限点通常是渐近稳定的平衡，没有退化为平凡解的风险。

Abstract: The objective of non-contrastive approaches to self-supervised learning is to
train on pairs of different views of the data an encoder and a predictor that
minimize the mean discrepancy between the code predicted from the embedding of
the first view and the embedding of the second one. In this setting, the stop
gradient and exponential moving average iterative procedures are commonly used
to avoid representation collapse, with excellent performance in downstream
supervised applications. This presentation investigates these procedures from
the dual theoretical viewpoints of optimization and dynamical systems. We first
show that, in general, although they do not optimize the original objective, or
for that matter, any other smooth function, they do avoid collapse. Following
Tian et al. [2021], but without any of the extra assumptions used in their
proofs, we then show using a dynamical system perspective that, in the linear
case, minimizing the original objective function without the use of a stop
gradient or exponential moving average always leads to collapse. Conversely, we
finally show that the limit points of the dynamical systems associated with
these two procedures are, in general, asymptotically stable equilibria, with no
risk of degenerating to trivial solutions.

</details>


### [40] [PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning](https://arxiv.org/abs/2507.01029)
*Junjie Zhou,Yingli Zuo,Shichang Feng,Peng Wan,Qi Zhu,Daoqiang Zhang,Wei Shao*

Main category: cs.LG

TL;DR: PathCoT 是一种新的零样本 CoT 提示方法，它通过整合病理学专家知识和自我评估来提高 MLLM 在病理视觉理解和推理方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型 (MLLM) 在应用于病理视觉推理任务时仍然面临重大挑战：(1) LLM 常常表现不佳，因为它们缺乏特定领域的信息，这可能导致模型产生幻觉。(2) CoT 中额外的推理步骤可能会引入错误，导致答案发散。

Method: PathCoT，一种新颖的零样本CoT提示方法，它将病理学专家知识整合到 MLLM 的推理过程中，并结合自我评估来减轻答案的发散。

Result: PathMMU 数据集上的实验结果证明了该方法在病理视觉理解和推理方面的有效性。

Conclusion: PathCoT在病理视觉理解和推理方面表现出色。

Abstract: With the development of generative artificial intelligence and instruction
tuning techniques, multimodal large language models (MLLMs) have made
impressive progress on general reasoning tasks. Benefiting from the
chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning
problem step-by-step. However, existing MLLMs still face significant challenges
when applied to pathology visual reasoning tasks: (1) LLMs often underperforms
because they lack domain-specific information, which can lead to model
hallucinations. (2) The additional reasoning steps in CoT may introduce errors,
leading to the divergence of answers. To address these limitations, we propose
PathCoT, a novel zero-shot CoT prompting method which integrates the pathology
expert-knowledge into the reasoning process of MLLMs and incorporates
self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides
the MLLM with prior knowledge to perform as pathology experts, and provides
comprehensive analysis of the image with their domain-specific knowledge. By
incorporating the experts' knowledge, PathCoT can obtain the answers with CoT
reasoning. Furthermore, PathCoT incorporates a self-evaluation step that
assesses both the results generated directly by MLLMs and those derived through
CoT, finally determining the reliable answer. The experimental results on the
PathMMU dataset demonstrate the effectiveness of our method on pathology visual
understanding and reasoning.

</details>


### [41] [Optimizing Flamelet Generated Manifold Models: A Machine Learning Performance Study](https://arxiv.org/abs/2507.01030)
*Reza Lotfi Navaei,Mohammad Safarzadeh,Seyed Mohammad Jafar Sobhani*

Main category: cs.LG

TL;DR: 本研究利用机器学习算法开发Laminar FGM库，用于甲烷燃料燃烧模拟，MLP方法表现最佳，准确率达99.81%。


<details>
  <summary>Details</summary>
Motivation: 火焰小面生成流形(FGM)因其精确性和物理表示而受到认可。FGM的实际应用需要大量的内存资源。FGM库是专门为特定燃料开发的，随后利用机器学习技术用于所有数值问题。本研究旨在开发Laminar FGM库，利用机器学习算法在甲烷燃料的燃烧模拟中的应用。

Method: 采用四种机器学习算法（多层感知器、随机森林、线性回归、支持向量机）来重建Flamelet libraries。

Result: 确定了七个库适合构建用于训练机器学习模型数据库，误差率为2.30%。评估了每种方法的默认架构以确定最佳方法，从而选择MLP方法作为主要选择。最佳模型实现了99.81%的准确率。

Conclusion: 通过超参数调整增强了MLP方法，最佳模型包含四个隐藏层，分别有10、15、20和25个神经元，实现了99.81%的准确率。

Abstract: In chemistry tabulations and Flamelet combustion models, the Flamelet
Generated Manifold (FGM) is recognized for its precision and physical
representation. The practical implementation of FGM requires a significant
allocation of memory resources. FGM libraries are developed specifically for a
specific fuel and subsequently utilized for all numerical problems using
machine learning techniques. This research aims to develop libraries of Laminar
FGM utilizing machine learning algorithms for application in combustion
simulations of methane fuel. This study employs four Machine Learning
algorithms to regenerate Flamelet libraries, based on an understanding of data
sources, techniques, and data-driven concepts. 1. Multi-Layer Perceptron; 2.
Random Forest; 3. Linear Regression; 4. Support Vector Machine. Seven libraries
were identified as appropriate for constructing a database for training machine
learning models, giving an error rate of 2.30%. The default architectures of
each method were evaluated to determine the optimal approach, leading to the
selection of the MLP method as the primary choice. The method was enhanced
through hyperparameter tuning to improve accuracy. The quantity of hidden
layers and neurons significantly influences method performance. The optimal
model, comprising four hidden layers with 10, 15, 20, and 25 neurons
respectively, achieved an accuracy of 99.81%.

</details>


### [42] [PyTorch-based Geometric Learning with Non-CUDA Processing Units: Experiences from Intel Gaudi-v2 HPUs](https://arxiv.org/abs/2507.01031)
*Fanchen Bu,Kijung Shin*

Main category: cs.LG

TL;DR: This paper presents experiences porting PyTorch-based geometric learning frameworks to Gaudi-v2 HPUs, introduces core utilities, and provides tutorials and examples to lower the barrier for researchers to experiment with geometric-learning algorithms and models on non-CUDA hardware.


<details>
  <summary>Details</summary>
Motivation: Emerging accelerators such as Intel's Gaudi Habana Processing Units (HPUs) offer competitive performance and energy efficiency, but the usage of such non-CUDA processing units requires significant engineering effort and novel software adaptations.

Method: porting PyTorch-based geometric learning frameworks to Gaudi-v2 HPUs and introducing a collection of core utilities that restore essential operations (e.g., scatter, sparse indexing, k-nearest neighbors) on Gaudi-v2 HPUs

Result: We consolidate sixteen guided tutorials and eleven real-world examples with diagnostic analyses of encountered failures and detailed workarounds. We collect all our experiences into a publicly accessible GitHub repository.

Conclusion: This work lowers the barrier for researchers to experiment with geometric-learning algorithms and models on non-CUDA hardware, providing a foundation for further optimization and cross-platform portability.

Abstract: Geometric learning has emerged as a powerful paradigm for modeling
non-Euclidean data, especially graph-structured ones, with applications
spanning social networks, molecular structures, knowledge graphs, and
recommender systems. While Nvidia's CUDA-enabled graphics processing units
(GPUs) largely dominate the hardware landscape, emerging accelerators such as
Intel's Gaudi Habana Processing Units (HPUs) offer competitive performance and
energy efficiency. However, the usage of such non-CUDA processing units
requires significant engineering effort and novel software adaptations. In this
work, we present our experiences porting PyTorch-based geometric learning
frameworks to Gaudi-v2 HPUs. We introduce a collection of core utilities that
restore essential operations (e.g., scatter, sparse indexing, k-nearest
neighbors) on Gaudi-v2 HPUs, and we consolidate sixteen guided tutorials and
eleven real-world examples with diagnostic analyses of encountered failures and
detailed workarounds. We collect all our experiences into a publicly accessible
GitHub repository. Our contributions lower the barrier for researchers to
experiment with geometric-learning algorithms and models on non-CUDA hardware,
providing a foundation for further optimization and cross-platform portability.

</details>


### [43] [An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks](https://arxiv.org/abs/2507.01032)
*Nan Mu,Hongbo Yang,Chen Zhao*

Main category: cs.LG

TL;DR: Developed a method to reduce multi-omics testing costs while maintaining accuracy by using an uncertainty-aware dynamic decision framework. It reduces redundant testing by using a single omics modality in some cases.


<details>
  <summary>Details</summary>
Motivation: High cost of multi-omics profiling imposes a significant economic burden, with over reliance on full omics data potentially leading to unnecessary resource consumption.

Method: An uncertainty-aware, multi-view dynamic decision framework for omics data classification. At the single-omics level, refine the activation functions of neural networks to generate Dirichlet distribution parameters, utilizing subjective logic to quantify both the belief masses and uncertainty mass of classification results. At the multi omics level, employ a fusion strategy based on Dempster-Shafer theory to integrate heterogeneous modalities. Apply a dynamic decision mechanism that omics data are incrementally introduced for each patient until a threshold is met.

Result: Achieved accurate classification using a single omics modality in over 50% of cases in three datasets, effectively reducing redundant testing. Maintains diagnostic performance comparable to full-omics models and preserves essential biological insights.

Conclusion: The method maintains diagnostic performance comparable to full-omics models and preserves essential biological insights. In three datasets, over 50% of cases achieved accurate classification using a single omics modality, effectively reducing redundant testing.

Abstract: Background and Objective: High-throughput multi-omics technologies have
proven invaluable for elucidating disease mechanisms and enabling early
diagnosis. However, the high cost of multi-omics profiling imposes a
significant economic burden, with over reliance on full omics data potentially
leading to unnecessary resource consumption. To address these issues, we
propose an uncertainty-aware, multi-view dynamic decision framework for omics
data classification that aims to achieve high diagnostic accuracy while
minimizing testing costs. Methodology: At the single-omics level, we refine the
activation functions of neural networks to generate Dirichlet distribution
parameters, utilizing subjective logic to quantify both the belief masses and
uncertainty mass of classification results. Belief mass reflects the support of
a specific omics modality for a disease class, while the uncertainty parameter
captures limitations in data quality and model discriminability, providing a
more trustworthy basis for decision-making. At the multi omics level, we employ
a fusion strategy based on Dempster-Shafer theory to integrate heterogeneous
modalities, leveraging their complementarity to boost diagnostic accuracy and
robustness. A dynamic decision mechanism is then applied that omics data are
incrementally introduced for each patient until either all data sources are
utilized or the model confidence exceeds a predefined threshold, potentially
before all data sources are utilized. Results and Conclusion: We evaluate our
approach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN.
In three datasets, over 50% of cases achieved accurate classification using a
single omics modality, effectively reducing redundant testing. Meanwhile, our
method maintains diagnostic performance comparable to full-omics models and
preserves essential biological insights.

</details>
