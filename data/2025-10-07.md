<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.CV](#cs.CV) [Total: 42]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.DB](#cs.DB) [Total: 3]
- [cs.IR](#cs.IR) [Total: 11]
- [cs.LG](#cs.LG) [Total: 42]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Decomposing Attention To Find Context-Sensitive Neurons](https://arxiv.org/abs/2510.03315)
*Alex Gibson*

Main category: cs.CL

TL;DR: 该论文研究了transformer语言模型中的注意力头，特别是那些注意力模式分散且注意力分数与内容依赖性弱的头。


<details>
  <summary>Details</summary>
Motivation: 研究这些注意力头的动机在于理解它们在语言模型中的作用，并探索它们是否具有稳定的特性。

Method: 该论文通过采样softmax分母，并结合GPT2-Small第一层中多个稳定头的输出，用周围文本的线性摘要来近似它们的组合输出。

Result: 该研究仅通过权重和一个校准文本，就能发现数百个对周围文本的高级上下文属性做出反应的第一层神经元，包括那些在校准文本上未激活的神经元。

Conclusion: 该研究表明，可以通过分析注意力头的softmax分母来理解它们在语言模型中的作用，并揭示模型中对上下文信息敏感的神经元。

Abstract: We study transformer language models, analyzing attention heads whose
attention patterns are spread out, and whose attention scores depend weakly on
content. We argue that the softmax denominators of these heads are stable when
the underlying token distribution is fixed. By sampling softmax denominators
from a "calibration text", we can combine together the outputs of multiple such
stable heads in the first layer of GPT2-Small, approximating their combined
output by a linear summary of the surrounding text. This approximation enables
a procedure where from the weights alone - and a single calibration text - we
can uncover hundreds of first layer neurons that respond to high-level
contextual properties of the surrounding text, including neurons that didn't
activate on the calibration text.

</details>


### [2] [Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision](https://arxiv.org/abs/2510.03323)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为 Graph-$S^3$ 的 agentic 文本图推理框架，用于解决基于 LLM 的文本图问答系统中图检索的挑战。该框架使用合成的逐步监督训练一个基于 LLM 的检索器。


<details>
  <summary>Details</summary>
Motivation: 现有的检索器性能较差，因为它们要么依赖于浅层嵌入相似性，要么采用需要过度数据标记和训练成本的交互式检索策略。

Method: 该方法包括一个数据合成管道，用于提取黄金子图以生成奖励，以及一个两阶段训练方案，用于学习基于合成奖励的交互式图探索策略。

Result: 在三个常见数据集上与七个强大的基线进行比较的大量实验表明，该方法在准确率方面平均提高了 8.1%，在 F1 分数方面平均提高了 9.7%。

Conclusion: 该方法在更复杂的多跳推理任务中具有更高的优势。

Abstract: A significant portion of real-world data is inherently represented as textual
graphs, and integrating these graphs into large language models (LLMs) is
promising to enable complex graph-based question answering. However, a key
challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,
how to retrieve relevant content from large graphs that is sufficiently
informative while remaining compact for the LLM context. Existing retrievers
suffer from poor performance since they either rely on shallow embedding
similarity or employ interactive retrieving policies that demand excessive data
labeling and training cost. To address these issues, we present Graph-$S^3$, an
agentic textual graph reasoning framework that employs an LLM-based retriever
trained with synthetic stepwise supervision. Instead of rewarding the agent
based on the final answers, which may lead to sparse and unstable training
signals, we propose to closely evaluate each step of the retriever based on
offline-extracted golden subgraphs. Our main techniques include a data
synthesis pipeline to extract the golden subgraphs for reward generation and a
two-stage training scheme to learn the interactive graph exploration policy
based on the synthesized rewards. Based on extensive experiments on three
common datasets in comparison with seven strong baselines, our approach
achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score.
The advantage is even higher in more complicated multi-hop reasoning tasks. Our
code will be open-sourced.

</details>


### [3] [Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks](https://arxiv.org/abs/2510.03384)
*Arjun Arunasalam,Madison Pickering,Z. Berkay Celik,Blase Ur*

Main category: cs.CL

TL;DR: 大型语言模型在完成日常任务时所展示的价值观与人类和其它LLM不一致。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在完成主观日常任务时所体现的隐含价值观，以及它们与人类的比较。

Method: 审计六个流行的LLM完成30个日常任务，并将LLM与来自美国的100名人类众包工作者进行比较。

Result: LLM在隐含价值观方面通常与人类和其他LLM不一致。

Conclusion: LLM在日常任务中体现的价值观存在差异，与人类价值观不一致。

Abstract: Large language models (LLMs) can underpin AI assistants that help users with
everyday tasks, such as by making recommendations or performing basic
computation. Despite AI assistants' promise, little is known about the implicit
values these assistants display while completing subjective everyday tasks.
Humans may consider values like environmentalism, charity, and diversity. To
what extent do LLMs exhibit these values in completing everyday tasks? How do
they compare with humans? We answer these questions by auditing how six popular
LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human
crowdworkers from the US. We find LLMs often do not align with humans, nor with
other LLMs, in the implicit values exhibited.

</details>


### [4] [Morpheme Induction for Emergent Language](https://arxiv.org/abs/2510.03439)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: CSAR 是一种从平行语料库中诱导语素的贪婪算法。


<details>
  <summary>Details</summary>
Motivation: 为了从emergent language语料库中诱导语素

Method: 该算法通过 (1) 根据形式和意义之间的互信息对语素进行加权，(2) 选择权重最高的配对，(3) 从语料库中删除它，以及 (4) 重复该过程来诱导更多语素。

Result: CSAR 在程序生成的数据集上进行了验证，并与相关任务的基线进行了比较。 此外，CSAR 在人类语言数据上的性能也得到了验证，表明该算法在相邻领域做出了合理的预测。 最后，我们分析了一些emergent languages，量化了诸如同义词和多义词程度的语言特征。

Conclusion: CSAR 算法在emergent languages中能够有效诱导语素，并在程序生成数据集和人类语言数据上表现出良好的性能。

Abstract: We introduce CSAR, an algorithm for inducing morphemes from emergent language
corpora of parallel utterances and meanings. It is a greedy algorithm that (1)
weights morphemes based on mutual information between forms and meanings, (2)
selects the highest-weighted pair, (3) removes it from the corpus, and (4)
repeats the process to induce further morphemes (i.e., Count, Select, Ablate,
Repeat). The effectiveness of CSAR is first validated on procedurally generated
datasets and compared against baselines for related tasks. Second, we validate
CSAR's performance on human language data to show that the algorithm makes
reasonable predictions in adjacent domains. Finally, we analyze a handful of
emergent languages, quantifying linguistic characteristics like degree of
synonymy and polysemy.

</details>


### [5] [Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video](https://arxiv.org/abs/2510.03458)
*Mengyao Xu,Wenfei Zhou,Yauhen Babakhin,Gabriel Moreira,Ronay Ak,Radek Osmulski,Bo Liu,Even Oldridge,Benedikt Schifferer*

Main category: cs.CL

TL;DR: Omni-Embed-Nemotron: A unified multimodal retrieval embedding model for handling complex real-world information needs, extending retrieval beyond text to include images, audio, and video.


<details>
  <summary>Details</summary>
Motivation: Existing text-based retrievers in RAG systems struggle with the visually and semantically rich content in real-world documents like PDFs, slides, or videos.

Method: Extends retrieval beyond text and images to support audio and video modalities, enabling cross-modal and joint-modal retrieval using a single model. The architecture, training setup, and evaluation results of Omni-Embed-Nemotron are described.

Result: Demonstrates effectiveness in text, image, and video retrieval.

Conclusion: Omni-Embed-Nemotron is effective in handling complex real-world information needs by supporting multiple modalities.

Abstract: We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding
model developed to handle the increasing complexity of real-world information
needs. While Retrieval-Augmented Generation (RAG) has significantly advanced
language models by incorporating external knowledge, existing text-based
retrievers rely on clean, structured input and struggle with the visually and
semantically rich content found in real-world documents such as PDFs, slides,
or videos. Recent work such as ColPali has shown that preserving document
layout using image-based representations can improve retrieval quality.
Building on this, and inspired by the capabilities of recent multimodal models
such as Qwen2.5-Omni, we extend retrieval beyond text and images to also
support audio and video modalities. Omni-Embed-Nemotron enables both
cross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)
retrieval using a single model. We describe the architecture, training setup,
and evaluation results of Omni-Embed-Nemotron, and demonstrate its
effectiveness in text, image, and video retrieval.

</details>


### [6] [Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment](https://arxiv.org/abs/2510.04919)
*Davood Rafiei,Morgan Lindsay Heisler,Weiwei Zhang,Mohammadreza Pourreza,Yong Zhang*

Main category: cs.CL

TL;DR: 论文研究了SFT训练数据与目标查询的结构特征匹配程度如何影响模型性能。


<details>
  <summary>Details</summary>
Motivation: 领域内SFT训练数据的可变性会阻碍模型在跨领域推广的能力。

Method: 通过比较训练集、目标数据和SFT之前模型预测的结构化SQL特征的分布，来评估对齐情况。

Result: 结构对齐是微调成功的重要预测指标。当对齐程度高时，SFT可以显著提高准确性和SQL生成质量；当对齐程度低时，改进效果不明显或没有改进。

Conclusion: 研究结果表明，在NL2SQL任务中，为了进行有效的微调和泛化，需要进行有针对性的数据选择。

Abstract: Supervised Fine-Tuning (SFT) is an effective method for adapting Large
Language Models (LLMs) on downstream tasks. However, variability in training
data can hinder a model's ability to generalize across domains. This paper
studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or
text to SQL), examining how well SFT training data matches the structural
characteristics of target queries and how this alignment impacts model
performance. We hypothesize that alignment can be accurately estimated by
comparing the distributions of structural SQL features across the training set,
target data, and the model's predictions prior to SFT. Through comprehensive
experiments on three large cross-domain NL2SQL benchmarks and multiple model
families, we show that structural alignment is a strong predictor of
fine-tuning success. When alignment is high, SFT yields substantial gains in
accuracy and SQL generation quality; when alignment is low, improvements are
marginal or absent. These findings highlight the importance of alignment-aware
data selection for effective fine-tuning and generalization in NL2SQL tasks.

</details>


### [7] [Searching for the Most Human-like Emergent Language](https://arxiv.org/abs/2510.03467)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: 本文设计了一个基于信号博弈的涌现通信环境，以生成在与人类语言相似性方面最先进的涌现语言。


<details>
  <summary>Details</summary>
Motivation: 使用XferBench作为目标函数，通过超参数优化来完成。

Method: XferBench通过测量涌现语言对人类语言的深度迁移学习的适用性，来量化涌现语言与人类语言的统计相似性。

Result: 我们证明了熵对涌现语言的迁移学习性能的预测能力，并证实了先前关于涌现通信系统的熵最小化性质的结果。

Conclusion: 最后，我们报告了关于哪些超参数产生更真实的涌现语言的概括，也就是说，哪些超参数能更好地迁移到人类语言。

Abstract: In this paper, we design a signalling game-based emergent communication
environment to generate state-of-the-art emergent languages in terms of
similarity to human language. This is done with hyperparameter optimization,
using XferBench as the objective function. XferBench quantifies the statistical
similarity of emergent language to human language by measuring its suitability
for deep transfer learning to human language. Additionally, we demonstrate the
predictive power of entropy on the transfer learning performance of emergent
language as well as corroborate previous results on the entropy-minimization
properties of emergent communication systems. Finally, we report
generalizations regarding what hyperparameters produce more realistic emergent
languages, that is, ones which transfer better to human language.

</details>


### [8] [SEER: The Span-based Emotion Evidence Retrieval Benchmark](https://arxiv.org/abs/2510.03490)
*Aneesha Sampath,Oya Aran,Emily Mower Provost*

Main category: cs.CL

TL;DR: SEER introduces a benchmark for LLMs to identify specific text spans expressing emotion, moving beyond sentence-level classification.


<details>
  <summary>Details</summary>
Motivation: Existing emotion recognition tasks lack the granularity to pinpoint specific phrases conveying emotion, which is crucial for applications like empathetic dialogue.

Method: The SEER benchmark includes two tasks: identifying emotion evidence within a single sentence and across a 5-sentence passage. It features new annotations on 1200 real-world sentences and evaluates 14 open-source LLMs.

Result: LLMs perform reasonably well on single-sentence inputs but degrade on longer passages. Error analysis reveals overreliance on keywords and false positives.

Conclusion: The study highlights the challenges LLMs face in accurately identifying emotion evidence in text, particularly in longer contexts, suggesting areas for improvement.

Abstract: We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to
test Large Language Models' (LLMs) ability to identify the specific spans of
text that express emotion. Unlike traditional emotion recognition tasks that
assign a single label to an entire sentence, SEER targets the underexplored
task of emotion evidence detection: pinpointing which exact phrases convey
emotion. This span-level approach is crucial for applications like empathetic
dialogue and clinical support, which need to know how emotion is expressed, not
just what the emotion is. SEER includes two tasks: identifying emotion evidence
within a single sentence, and identifying evidence across a short passage of
five consecutive sentences. It contains new annotations for both emotion and
emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs
and find that, while some models approach average human performance on
single-sentence inputs, their accuracy degrades in longer passages. Our error
analysis reveals key failure modes, including overreliance on emotion keywords
and false positives in neutral text.

</details>


### [9] [ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection](https://arxiv.org/abs/2510.03502)
*Ali Khairallah,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 提出了首个大规模阿拉伯语数据集ALHD，用于区分人类和LLM生成的文本。


<details>
  <summary>Details</summary>
Motivation: 为了解决阿拉伯语LLM生成文本检测中的泛化性问题，并应对虚假信息、学术不端和网络威胁的风险。

Method: 构建了一个包含新闻、社交媒体和评论三种类型，覆盖MSA和方言阿拉伯语，超过40万平衡样本的数据集。使用了传统分类器、BERT模型和LLM进行基准测试。

Result: 微调的BERT模型表现最佳，但在跨类型泛化时面临挑战，尤其是在新闻文章中。

Conclusion: ALHD为阿拉伯语LLM检测研究奠定了基础，并指出了未来研究方向，特别是在提高跨类型泛化能力方面。

Abstract: We introduce ALHD, the first large-scale comprehensive Arabic dataset
explicitly designed to distinguish between human- and LLM-generated texts. ALHD
spans three genres (news, social media, reviews), covering both MSA and
dialectal Arabic, and contains over 400K balanced samples generated by three
leading LLMs and originated from multiple human sources, which enables studying
generalizability in Arabic LLM-genearted text detection. We provide rigorous
preprocessing, rich annotations, and standardized balanced splits to support
reproducibility. In addition, we present, analyze and discuss benchmark
experiments using our new dataset, in turn identifying gaps and proposing
future research directions. Benchmarking across traditional classifiers,
BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that
fine-tuned BERT models achieve competitive performance, outperforming LLM-based
models. Results are however not always consistent, as we observe challenges
when generalizing across genres; indeed, models struggle to generalize when
they need to deal with unseen patterns in cross-genre settings, and these
challenges are particularly prominent when dealing with news articles, where
LLM-generated texts resemble human texts in style, which opens up avenues for
future research. ALHD establishes a foundation for research related to Arabic
LLM-detection and mitigating risks of misinformation, academic dishonesty, and
cyber threats.

</details>


### [10] [TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning](https://arxiv.org/abs/2510.03519)
*Fangxu Yu,Hongyu Zhao,Tianyi Zhou*

Main category: cs.CL

TL;DR: TS-Reasoner aligns time series foundation models (TSFMs) with large language models (LLMs) for improved time series reasoning.


<details>
  <summary>Details</summary>
Motivation: Existing TSFMs lack reasoning capabilities, while LLMs struggle with numerical time series data. Integrating them is challenging due to difficulties in aligning the two modalities.

Method: A two-stage training recipe is proposed that applies instruction finetuning after the alignment pretraining. The method leverages a pretrained TSFM and freezes it during training.

Result: TS-Reasoner outperforms existing LLMs, VLMs, and Time Series LLMs with remarkable data efficiency.

Conclusion: TS-Reasoner effectively aligns TSFMs and LLMs for enhanced time series understanding and reasoning.

Abstract: Time series reasoning is crucial to decision-making in diverse domains,
including finance, energy usage, traffic, weather, and scientific discovery.
While existing time series foundation models (TSFMs) can capture low-level
dynamic patterns and provide accurate forecasting, further analysis usually
requires additional background knowledge and sophisticated reasoning, which are
lacking in most TSFMs but can be achieved through large language models (LLMs).
On the other hand, without expensive post-training, LLMs often struggle with
the numerical understanding of time series data. Although it is intuitive to
integrate the two types of models, developing effective training recipes that
align the two modalities for reasoning tasks is still an open challenge. To
this end, we propose TS-Reasoner that aligns the latent representations of
TSFMs with the textual inputs of LLMs for downstream understanding/reasoning
tasks. Specifically, we propose a simple yet effective method to curate
diverse, synthetic pairs of time series and textual captions for alignment
training. We then develop a two-stage training recipe that applies instruction
finetuning after the alignment pretraining. Unlike existing works that train an
LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it
during training. Extensive experiments on several benchmarks demonstrate that
TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision
Language Models (VLMs), and Time Series LLMs, but also achieves this with
remarkable data efficiency, e.g., using less than half the training data.

</details>


### [11] [LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction](https://arxiv.org/abs/2510.03577)
*Ikram Belmadani,Parisa Nazari Hashemi,Thomas Sebbag,Benoit Favre,Guillaume Fortier,Solen Quiniou,Emmanuel Morin,Richard Dufour*

Main category: cs.CL

TL;DR: 本文介绍了参与EvalLLM 2025挑战赛，使用少量样本在法语生物医学命名实体识别（NER）和健康事件抽取任务中的工作。


<details>
  <summary>Details</summary>
Motivation: 在资源极低的情况下，最大化性能。

Method: 结合大型语言模型（LLMs）、标注指南、合成数据和后处理，提出了三种NER方法：(1) 使用GPT-4.1进行上下文学习（ICL），自动选择10个示例并将标注指南摘要纳入提示；(2) 通用NER系统GLiNER，在合成语料库上进行微调，然后通过LLM进行后处理验证；(3) 开放LLM LLaMA-3.1-8B-Instruct，在相同的合成语料库上进行微调。事件提取使用相同的ICL策略与GPT-4.1，在提示中重复使用指南摘要。

Result: GPT-4.1在NER中以61.53%的macro-F1和事件提取中以15.02%的macro-F1领先。

Conclusion: 精心设计的提示对于在极低资源场景中最大化性能至关重要。

Abstract: This work presents our participation in the EvalLLM 2025 challenge on
biomedical Named Entity Recognition (NER) and health event extraction in French
(few-shot setting). For NER, we propose three approaches combining large
language models (LLMs), annotation guidelines, synthetic data, and
post-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating
automatic selection of 10 examples and a summary of the annotation guidelines
into the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic
corpus and then verified by an LLM in post-processing, and (3) the open LLM
LLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event
extraction uses the same ICL strategy with GPT-4.1, reusing the guideline
summary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for
NER and 15.02% for event extraction, highlighting the importance of
well-crafted prompting to maximize performance in very low-resource scenarios.

</details>


### [12] [Identifying Financial Risk Information Using RAG with a Contrastive Insight](https://arxiv.org/abs/2510.03521)
*Ali Elahi*

Main category: cs.CL

TL;DR: RAG 在专业领域的推理任务中表现不佳，因为它无法检索可比较的案例或相关问题。本文提出了一种基于 RAG 的对等感知比较推理层，以解决此限制。


<details>
  <summary>Details</summary>
Motivation: RAG 在专业推理任务中的输出通常是通用的，反映的是广泛的事实，而不是特定于上下文的见解。例如，在金融领域，它会导致对大多数公司都适用的通用风险。

Method: 在 RAG 的基础上，提出了一个对等感知比较推理层。

Result: 对比实验表明，我们的对比方法在文本生成指标（如 ROUGE 和 BERTScore）方面优于基线 RAG，与人工生成的股票研究和风险相比。

Conclusion: 本文提出了一种新的方法，通过在 RAG 的基础上增加一个对等感知比较推理层，提高了 RAG 在专业领域的推理能力。

Abstract: In specialized domains, humans often compare new problems against similar
examples, highlight nuances, and draw conclusions instead of analyzing
information in isolation. When applying reasoning in specialized contexts with
LLMs on top of a RAG, the pipeline can capture contextually relevant
information, but it is not designed to retrieve comparable cases or related
problems.
  While RAG is effective at extracting factual information, its outputs in
specialized reasoning tasks often remain generic, reflecting broad facts rather
than context-specific insights. In finance, it results in generic risks that
are true for the majority of companies. To address this limitation, we propose
a peer-aware comparative inference layer on top of RAG.
  Our contrastive approach outperforms baseline RAG in text generation metrics
such as ROUGE and BERTScore in comparison with human-generated equity research
and risk.

</details>


### [13] [Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs](https://arxiv.org/abs/2510.03527)
*Sayan Ghosh,Shahzaib Saqib Warraich,Dhruv Tarsadiya,Gregory Yauney,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 本文介绍了一种名为 Consensus Graphs (ConGrs) 的新方法，用于整合语言模型多次采样生成结果中的信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效综合不同长文本回复中的丰富认知信号。

Method: 使用生物信息学的轻量级词汇序列对齐算法构建 ConGrs，并辅以辅助语言模型判断。设计了任务相关的解码方法，从 ConGr 数据结构中合成单个最终回复。

Result: 在两个传记生成任务中，ConGrs 的事实准确率比平均回复提高了 31%，对语言模型判断的依赖减少了 80% 以上。在三个基于拒绝的任务中，拒绝率提高了 56%。在 MATH 和 AIME 推理任务中，准确率比自我验证和多数投票基线提高了 6 个百分点。

Conclusion: ConGrs 提供了一种灵活的方法，可以捕获语言模型回复中的变化，并利用回复变化提供的认知信号来合成更有效的回复。

Abstract: Language models can be sampled multiple times to access the distribution
underlying their responses, but existing methods cannot efficiently synthesize
rich epistemic signals across different long-form responses. We introduce
Consensus Graphs (ConGrs), a flexible DAG-based data structure that represents
shared information, as well as semantic variation in a set of sampled LM
responses to the same prompt. We construct ConGrs using a light-weight lexical
sequence alignment algorithm from bioinformatics, supplemented by the targeted
usage of a secondary LM judge. Further, we design task-dependent decoding
methods to synthesize a single, final response from our ConGr data structure.
Our experiments show that synthesizing responses from ConGrs improves factual
precision on two biography generation tasks by up to 31% over an average
response and reduces reliance on LM judges by more than 80% compared to other
methods. We also use ConGrs for three refusal-based tasks requiring abstention
on unanswerable queries and find that abstention rate is increased by up to
56%. We apply our approach to the MATH and AIME reasoning tasks and find an
improvement over self-verification and majority vote baselines by up to 6
points of accuracy. We show that ConGrs provide a flexible method for capturing
variation in LM responses and using the epistemic signals provided by response
variation to synthesize more effective responses.

</details>


### [14] [Epistemic Diversity and Knowledge Collapse in Large Language Models](https://arxiv.org/abs/2510.04226)
*Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)倾向于生成在词汇、语义和风格上同质的文本，导致知识坍塌的风险。本文提出了一种新的方法来测量认知多样性，并对LLM知识坍塌进行广泛的实证研究。


<details>
  <summary>Details</summary>
Motivation: 现有的同质化研究主要集中在封闭式多项选择或模糊语义特征上，并且没有考察跨时间和文化背景的趋势。因此，本文旨在克服这些局限性。

Method: 本文提出了一种新的方法来测量认知多样性，即LLM输出中真实世界声明的变化。

Result: 研究结果表明，虽然较新的模型倾向于生成更多样化的声明，但几乎所有模型的认知多样性都低于基本的网络搜索。模型大小对认知多样性有负面影响，而检索增强生成(RAG)有正面影响，但RAG的改进因文化背景而异。与传统的知识来源(维基百科)相比，特定国家的声明更多地反映英语，而不是当地语言，突出了认知表征的差距。

Conclusion: 本文的研究结果表明，大型语言模型存在知识坍塌的风险，并且在认知多样性方面存在差距。

Abstract: Large language models (LLMs) tend to generate lexically, semantically, and
stylistically homogenous texts. This poses a risk of knowledge collapse, where
homogenous LLMs mediate a shrinking in the range of accessible information over
time. Existing works on homogenization are limited by a focus on closed-ended
multiple-choice setups or fuzzy semantic features, and do not look at trends
across time and cultural contexts. To overcome this, we present a new
methodology to measure epistemic diversity, i.e., variation in real-world
claims in LLM outputs, which we use to perform a broad empirical study of LLM
knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200
prompt variations sourced from real user chats. For the topics in our study, we
show that while newer models tend to generate more diverse claims, nearly all
models are less epistemically diverse than a basic web search. We find that
model size has a negative impact on epistemic diversity, while
retrieval-augmented generation (RAG) has a positive impact, though the
improvement from RAG varies by the cultural context. Finally, compared to a
traditional knowledge source (Wikipedia), we find that country-specific claims
reflect the English language more than the local one, highlighting a gap in
epistemic representation

</details>


### [15] [Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance](https://arxiv.org/abs/2510.03528)
*Ahmed Alajrami,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: Instruction-tuning with perturbed instructions can improve LLMs' robustness to noisy instructions.


<details>
  <summary>Details</summary>
Motivation: LLMs are sensitive to minor variations in instruction phrasing.

Method: Instruction-tuning with perturbations (removing stop words, shuffling words) and evaluating on original/perturbed benchmarks (MMLU, BBH, GSM8K).

Result: Instruction-tuning on perturbed instructions can improve downstream performance in some cases.

Conclusion: Including perturbed instructions in instruction-tuning can make LLMs more resilient to noisy user inputs.

Abstract: Instruction-tuning plays a vital role in enhancing the task-solving abilities
of large language models (LLMs), improving their usability in generating
helpful responses on various tasks. However, previous work has demonstrated
that they are sensitive to minor variations in instruction phrasing. In this
paper, we explore whether introducing perturbations in instruction-tuning data
can enhance LLMs' resistance against noisy instructions. We focus on how
instruction-tuning with perturbations, such as removing stop words or shuffling
words, affects LLMs' performance on the original and perturbed versions of
widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics
and potential shifts in model behavior. Surprisingly, our results suggest that
instruction-tuning on perturbed instructions can, in some cases, improve
downstream performance. These findings highlight the importance of including
perturbed instructions in instruction-tuning, which can make LLMs more
resilient to noisy user inputs.

</details>


### [16] [GRACE: Generative Representation Learning via Contrastive Policy Optimization](https://arxiv.org/abs/2510.04506)
*Jiashuo Sun,Shixuan Liu,Zhaochen Su,Xianrui Zhong,Pengcheng Jiang,Bowen Jin,Peiran Li,Weijia Shi,Jiawei Han*

Main category: cs.CL

TL;DR: GRACE框架通过将对比信号视为奖励来指导生成策略，从而训练大型语言模型（LLM）作为文本编码器，进而产生更强的嵌入和透明的理由。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于对比损失，将模型视为黑盒函数，忽略了其生成和推理能力。

Method: GRACE框架将LLM视为一个策略，生成可解释的理由，并通过策略梯度优化训练模型，使用多组件奖励函数来最大化查询正对之间的相似性，并最小化与负对的相似性。

Result: 在MTEB基准测试中，GRACE在多个类别上取得了广泛的收益：在四个主干网络上平均，监督设置比基本模型提高了11.5%，无监督变体提高了6.9%，同时保留了一般能力。

Conclusion: 这项工作将对比目标视为理由的奖励，统一了表示学习与生成，从而产生更强的嵌入和透明的理由。

Abstract: Prevailing methods for training Large Language Models (LLMs) as text encoders
rely on contrastive losses that treat the model as a black box function,
discarding its generative and reasoning capabilities in favor of static
embeddings. We introduce GRACE (Generative Representation Learning via
Contrastive Policy Optimization), a novel framework that reimagines contrastive
signals not as losses to be minimized, but as rewards that guide a generative
policy. In GRACE, the LLM acts as a policy that produces explicit,
human-interpretable rationales--structured natural language explanations of its
semantic understanding. These rationales are then encoded into high-quality
embeddings via mean pooling. Using policy gradient optimization, we train the
model with a multi-component reward function that maximizes similarity between
query positive pairs and minimizes similarity with negatives. This transforms
the LLM from an opaque encoder into an interpretable agent whose reasoning
process is transparent and inspectable. On MTEB benchmark, GRACE yields broad
cross category gains: averaged over four backbones, the supervised setting
improves overall score by 11.5% over base models, and the unsupervised variant
adds 6.9%, while preserving general capabilities. This work treats contrastive
objectives as rewards over rationales, unifying representation learning with
generation to produce stronger embeddings and transparent rationales. The
model, data and code are available at https://github.com/GasolSun36/GRACE.

</details>


### [17] [TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering](https://arxiv.org/abs/2510.03536)
*Zhaohan Meng,Zaiqiao Meng,Siwei Liu,Iadh Ounis*

Main category: cs.CL

TL;DR: 本研究提出了一种名为TriMediQ的三元组结构方法，旨在提高大型语言模型(llm)在交互式医疗问答中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在静态和单轮医疗问答基准测试中表现出色，但与实际临床咨询所需的迭代信息收集过程不符。当被迫推理对话日志时，大型语言模型的可靠性会显著下降。

Method: TriMediQ将患者的回答总结成三元组，并将它们集成到知识图(KG)中，从而实现多跳推理。它包含一个冻结的三元组生成器，用于提取临床相关三元组，以及一个可训练的投影模块，用于捕获来自KG的关系信息。

Result: 在两个交互式问答基准测试中，TriMediQ的准确率比iMedQA数据集上的五个基线提高了10.4%。

Conclusion: 将患者的回答转换为基于三元组的结构化图，可以实现更准确的临床推理，为部署基于llm的医疗助手提供解决方案。

Abstract: Large Language Models (LLMs) perform strongly in static and single-turn
medical Question Answer (QA) benchmarks, yet such settings diverge from the
iterative information gathering process required in practical clinical
consultations. The MEDIQ framework addresses this mismatch by recasting the
diagnosis as an interactive dialogue between a patient and an expert system,
but the reliability of LLMs drops dramatically when forced to reason with
dialogue logs, where clinical facts appear in sentences without clear links. To
bridge this gap, we introduce TriMediQ, a triplet-structured approach that
summarises patient responses into triplets and integrates them into a Knowledge
Graph (KG), enabling multi-hop reasoning. We introduce a frozen triplet
generator that extracts clinically relevant triplets, using prompts designed to
ensure factual consistency. In parallel, a trainable projection module,
comprising a graph encoder and a projector, captures relational information
from the KG to enhance expert reasoning. TriMediQ operates in two steps: (i)
the projection module fine-tuning with all LLM weights frozen; and (ii) using
the fine-tuned module to guide multi-hop reasoning during inference. We
evaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up
to 10.4\% improvement in accuracy over five baselines on the iMedQA dataset.
These results demonstrate that converting patient responses into structured
triplet-based graphs enables more accurate clinical reasoning in multi-turn
settings, providing a solution for the deployment of LLM-based medical
assistants.

</details>


### [18] [Fine-grained auxiliary learning for real-world product recommendation](https://arxiv.org/abs/2510.04551)
*Mario Almagro,Diego Ortego,David Jimenez*

Main category: cs.CL

TL;DR: 提出了一种辅助学习策略ALC，通过学习细粒度嵌入来提高覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现实系统中产品推荐模型的覆盖率不足，大量推荐需要人工干预。

Method: 引入两个训练目标，利用batch中最难的负样本，在正样本和负样本之间建立区分性训练信号。

Result: 在两个产品推荐数据集上验证了ALC，结合最近的阈值一致性margin loss，展示了最先进的覆盖率。

Conclusion: ALC 是一种有效的提高产品推荐模型覆盖率的方法。

Abstract: Product recommendation is the task of recovering the closest items to a given
query within a large product corpora. Generally, one can determine if
top-ranked products are related to the query by applying a similarity
threshold; exceeding it deems the product relevant, otherwise manual revision
is required. Despite being a well-known problem, the integration of these
models in real-world systems is often overlooked. In particular, production
systems have strong coverage requirements, i.e., a high proportion of
recommendations must be automated. In this paper we propose ALC , an Auxiliary
Learning strategy that boosts Coverage through learning fine-grained
embeddings. Concretely, we introduce two training objectives that leverage the
hardest negatives in the batch to build discriminative training signals between
positives and negatives. We validate ALC using three extreme multi-label
classification approaches in two product recommendation datasets;
LF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating
state-of-the-art coverage rates when combined with a recent
threshold-consistent margin loss.

</details>


### [19] [What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification](https://arxiv.org/abs/2510.03541)
*Andrew Halterman,Katherine A. Keith*

Main category: cs.CL

TL;DR: 这篇论文关注的是大型语言模型（LLM）在计算社会科学（CSS）中用于文本分类时，提示前后被忽视的步骤：概念化和下游统计推断。作者认为LLM可能会导致分析师跳过概念化步骤，从而产生概念化误差，进而影响下游估计。


<details>
  <summary>Details</summary>
Motivation: 强调在使用LLM进行文本分类时，概念化的重要性，并指出当前研究对这一环节的忽视。

Method: 通过模拟实验来验证概念化偏差的影响。

Result: 研究表明，仅靠提高LLM的准确性或事后偏差校正方法无法纠正概念化引入的偏差。

Conclusion: 提醒CSS分析师概念化仍然是首要关注的问题，并提供了关于如何获得低成本、无偏、低方差的下游估计的具体建议。

Abstract: Generative large language models (LLMs) are now used extensively for text
classification in computational social science (CSS). In this work, focus on
the steps before and after LLM prompting -- conceptualization of concepts to be
classified and using LLM predictions in downstream statistical inference --
which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can
tempt analysts to skip the conceptualization step, creating conceptualization
errors that bias downstream estimates. Using simulations, we show that this
conceptualization-induced bias cannot be corrected for solely by increasing LLM
accuracy or post-hoc bias correction methods. We conclude by reminding CSS
analysts that conceptualization is still a first-order concern in the LLM-era
and provide concrete advice on how to pursue low-cost, unbiased, low-variance
downstream estimates.

</details>


### [20] [Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry](https://arxiv.org/abs/2510.04631)
*Anastasia Zhukova,Jonas Lührs,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 本研究探索了如何将 SciNCL 应用于流程工业领域，利用文本日志中蕴含的关键信息，这些信息通常以稀疏知识图谱的形式存在。


<details>
  <summary>Details</summary>
Motivation: 利用知识图谱 (KGs) 增强预训练语言模型，从而学习领域特定的术语或文档之间的关系。

Method: 应用 SciNCL，一种图感知的邻域对比学习方法。

Result: 在专有的流程工业文本嵌入基准 (PITEB) 上，使用从 GE 导出的 triplets 进行微调的语言模型优于最先进的 mE5-large 文本编码器 9.8-14.3% (5.4-8.0p)，并且模型尺寸小 3-5 倍。

Conclusion: SciNCL 可以有效地应用于流程工业领域，提高文本嵌入的性能，同时减小模型尺寸。

Abstract: Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained
language models by incorporating additional knowledge from the graph structures
to learn domain-specific terminology or relationships between documents that
might otherwise be overlooked. This paper explores how SciNCL, a graph-aware
neighborhood contrastive learning methodology originally designed for
scientific publications, can be applied to the process industry domain, where
text logs contain crucial information about daily operations and are often
structured as sparse KGs. Our experiments demonstrate that language models
fine-tuned with triplets derived from GE outperform a state-of-the-art
mE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process
industry text embedding benchmark (PITEB) while being 3-5 times smaller in
size.

</details>


### [21] [CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making](https://arxiv.org/abs/2510.03553)
*Hasibur Rahman,Hanan Salam*

Main category: cs.CL

TL;DR: 论文提出了一个名为CCD-Bench的新基准，用于评估大型语言模型（LLM）在跨文化价值冲突下的决策能力。结果表明，LLM在决策时倾向于某些文化价值观，而忽视其他文化价值观，并且缺乏对权力协商、基于权利的推理或性别意识分析的考虑。


<details>
  <summary>Details</summary>
Motivation: 现有的基准主要针对文化知识、价值预测或单轴偏差诊断，而忽略了LLM在多种文化价值观直接冲突时的判断能力。

Method: 构建了一个包含2,182个开放式困境的基准CCD-Bench，这些困境涵盖七个领域，并配有对应于十个GLOBE文化集群的匿名回应选项。使用分层拉丁方来减轻排序效应。评估了17个非推理LLM。

Result: 模型 disproportionately 喜欢 Nordic Europe 和 Germanic Europe，而对 Eastern Europe 和 the Middle East and North Africa 的选择不足。尽管 87.9% 的理由参考了多个 GLOBE 维度，但这种多元主义是肤浅的：模型重新组合了 Future Orientation 和 Performance Orientation，并且很少以 Assertiveness 或 Gender Egalitarianism 为基础。

Conclusion: 当前的对齐流程促进了一种共识导向的世界观，不能很好地服务于需要权力协商、基于权利的推理或性别意识分析的场景。需要实质性地参与不同的世界观的对齐策略。

Abstract: Although large language models (LLMs) are increasingly implicated in
interpersonal and societal decision-making, their ability to navigate explicit
conflicts between legitimately different cultural value systems remains largely
unexamined. Existing benchmarks predominantly target cultural knowledge
(CulturalBench), value prediction (WorldValuesBench), or single-axis bias
diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple
culturally grounded values directly clash. We address this gap with CCD-Bench,
a benchmark that assesses LLM decision-making under cross-cultural value
conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains,
each paired with ten anonymized response options corresponding to the ten GLOBE
cultural clusters. These dilemmas are presented using a stratified Latin square
to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models
disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe
(12.4 percent), while options for Eastern Europe and the Middle East and North
Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of
rationales reference multiple GLOBE dimensions, this pluralism is superficial:
models recombine Future Orientation and Performance Orientation, and rarely
ground choices in Assertiveness or Gender Egalitarianism (both under 3
percent). Ordering effects are negligible (Cramer's V less than 0.10), and
symmetrized KL divergence shows clustering by developer lineage rather than
geography. These patterns suggest that current alignment pipelines promote a
consensus-oriented worldview that underserves scenarios demanding power
negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts
evaluation beyond isolated bias detection toward pluralistic decision making
and highlights the need for alignment strategies that substantively engage
diverse worldviews.

</details>


### [22] [Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models](https://arxiv.org/abs/2510.03561)
*Adam Filipek*

Main category: cs.CL

TL;DR: 提出了 Reactive Transformer (RxT)，一种用于对话 AI 的新型架构，通过维护固定大小的短期记忆 (STM) 系统，以事件驱动的方式处理对话，降低了计算复杂度并实现了低延迟。


<details>
  <summary>Details</summary>
Motivation: Transformer 在会话 AI 中的应用受到其无状态特性和计算复杂度的限制，导致长对话中成本高昂和延迟。

Method: RxT 将每个会话轮次作为离散事件实时处理，利用生成器-解码器生成响应，并通过记忆编码器和记忆注意力网络异步更新 STM。

Result: 在合成数据上进行的概念验证实验表明，与相当大小的基线无状态模型相比，RxT 具有卓越的性能和恒定时间的推理延迟。

Conclusion: RxT 通过将响应生成与记忆更新分离，实现了低延迟、真正实时、有状态且经济可行的长对话。

Abstract: The Transformer architecture has become the de facto standard for Large
Language Models (LLMs), demonstrating remarkable capabilities in language
understanding and generation. However, its application in conversational AI is
fundamentally constrained by its stateless nature and the quadratic
computational complexity ($O(L^2)$) with respect to sequence length $L$.
Current models emulate memory by reprocessing an ever-expanding conversation
history with each turn, leading to prohibitive costs and latency in long
dialogues. This paper introduces the Reactive Transformer (RxT), a novel
architecture designed to overcome these limitations by shifting from a
data-driven to an event-driven paradigm. RxT processes each conversational turn
as a discrete event in real-time, maintaining context in an integrated,
fixed-size Short-Term Memory (STM) system. The architecture features a distinct
operational cycle where a generator-decoder produces a response based on the
current query and the previous memory state, after which a memory-encoder and a
dedicated Memory Attention network asynchronously update the STM with a
representation of the complete interaction. This design fundamentally alters
the scaling dynamics, reducing the total user-facing cost of a conversation
from quadratic ($O(N^2 \cdot T)$) to linear ($O(N \cdot T)$) with respect to
the number of interactions $N$. By decoupling response generation from memory
updates, RxT achieves low latency, enabling truly real-time, stateful, and
economically viable long-form conversations. We validated our architecture with
a series of proof-of-concept experiments on synthetic data, demonstrating
superior performance and constant-time inference latency compared to a baseline
stateless model of comparable size.

</details>


### [23] [Decoupling Task-Solving and Output Formatting in LLM Generation](https://arxiv.org/abs/2510.03595)
*Haikang Deng,Po-Nien Kung,Nanyun Peng*

Main category: cs.CL

TL;DR: Deco-G是一个解码框架，它将格式遵从性与任务解决分离，以提高大型语言模型在复杂任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在遵循包含任务描述的指令以解决复杂问题时越来越熟练，但是，随着prompt变得越来越复杂，模型通常难以遵循所有指令。当指令性prompt将推理指令与规定解决方案必须如何呈现的严格格式要求交织在一起时，这种困难尤其常见。

Method: Deco-G使用单独的易处理概率模型（TPM）处理格式遵从性，同时仅使用任务指令prompt LLM。在每个解码步骤中，Deco-G将来自LLM的下一个token概率与TPM计算的格式遵从性可能性相结合，以形成输出概率。为了使这种方法既实用又可扩展，我们引入了三个关键创新：instruction-aware distillation，灵活的trie构建算法和用于计算效率的HMM状态修剪。

Result: Deco-G在具有各种格式要求的各种任务中均有效，包括数学推理，LLM-as-a-judge和事件参数提取。总体而言，我们的方法比常规prompt实践产生了1.0％至6.0％的相对收益，并保证了格式遵从性。

Conclusion: Deco-G通过将格式遵从性与任务解决分离，提高了大型语言模型在复杂任务中的性能。

Abstract: Large language models (LLMs) are increasingly adept at following instructions
containing task descriptions to solve complex problems, such as mathematical
reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow
more complex, models often struggle to adhere to all instructions. This
difficulty is especially common when instructive prompts intertwine reasoning
directives -- specifying what the model should solve -- with rigid formatting
requirements that dictate how the solution must be presented. The entanglement
creates competing goals for the model, suggesting that more explicit separation
of these two aspects could lead to improved performance. To this front, we
introduce Deco-G, a decoding framework that explicitly decouples format
adherence from task solving. Deco-G handles format compliance with a separate
tractable probabilistic model (TPM), while prompts LLMs with only task
instructions. At each decoding step, Deco-G combines next token probabilities
from the LLM with the TPM calculated format compliance likelihood to form the
output probability. To make this approach both practical and scalable for
modern instruction-tuned LLMs, we introduce three key innovations:
instruction-aware distillation, a flexible trie-building algorithm, and HMM
state pruning for computational efficiency. We demonstrate the effectiveness of
Deco-G across a wide range of tasks with diverse format requirements, including
mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall,
our approach yields 1.0% to 6.0% relative gain over regular prompting practice
with guaranteed format compliance.

</details>


### [24] [Can an LLM Induce a Graph? Investigating Memory Drift and Context Length](https://arxiv.org/abs/2510.03611)
*Raquib Bin Yousuf,Aadyant Khatri,Shengzhe Xu,Mandar Sharma,Naren Ramakrishnan*

Main category: cs.CL

TL;DR: 评估大型语言模型在信息密集场景下的推理能力，发现现有模型的记忆漂移和上下文遗忘问题比现有基准测试显示的更早。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准不能准确反映大型语言模型在信息密集场景下的性能，尤其是在需要从文本中推导结构化关系知识的复杂推理任务中。

Method: 使用需要模型从潜在嘈杂的自然语言内容中归纳结构化关系知识（例如图）的复杂推理任务来评估模型。

Result: 大型语言模型在关系推理任务中，比现有基准测试显示的更早出现记忆漂移和上下文遗忘。

Conclusion: 现有模型从非结构化输入中提取结构化知识的能力有限，需要进行架构调整以改进远程推理。

Abstract: Recently proposed evaluation benchmarks aim to characterize the effective
context length and the forgetting tendencies of large language models (LLMs).
However, these benchmarks often rely on simplistic 'needle in a haystack'
retrieval or continuation tasks that may not accurately reflect the performance
of these models in information-dense scenarios. Thus, rather than simple next
token prediction, we argue for evaluating these models on more complex
reasoning tasks that requires them to induce structured relational knowledge
from the text - such as graphs from potentially noisy natural language content.
While the input text can be viewed as generated in terms of a graph, its
structure is not made explicit and connections must be induced from distributed
textual cues, separated by long contexts and interspersed with irrelevant
information. Our findings reveal that LLMs begin to exhibit memory drift and
contextual forgetting at much shorter effective lengths when tasked with this
form of relational reasoning, compared to what existing benchmarks suggest.
With these findings, we offer recommendations for the optimal use of popular
LLMs for complex reasoning tasks. We further show that even models specialized
for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in
these settings. These results point to significant limitations in the models'
ability to abstract structured knowledge from unstructured input and highlight
the need for architectural adaptations to improve long-range reasoning.

</details>


### [25] [Towards Unsupervised Speech Recognition at the Syllable-Level](https://arxiv.org/abs/2510.03639)
*Liming Wang,Junrui Ni,Kai-Wei Chang,Saurabhchand Bhati,David Harwath,Mark Hasegawa-Johnson,James R. Glass*

Main category: cs.CL

TL;DR: 本文提出了一种基于掩码语言模型的音节级无监督语音识别框架，该框架无需字形-音素转换器，且避免了基于GAN的方法的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于音素的方法通常依赖于昂贵的资源，例如字形-音素转换器（G2P），并且由于训练不稳定，难以推广到具有模糊音素边界的语言。本文旨在解决这两个挑战。

Method: 本文提出了一种基于掩码语言模型的音节级UASR框架。

Result: 在LibriSpeech上，该方法实现了高达40%的字符错误率（CER）的相对降低，并且有效地推广到普通话。

Conclusion: 该方法在LibriSpeech和普通话上的结果表明了其有效性。

Abstract: Training speech recognizers with unpaired speech and text -- known as
unsupervised speech recognition (UASR) -- is a crucial step toward extending
ASR to low-resource languages in the long-tail distribution and enabling
multimodal learning from non-parallel data. However, existing approaches based
on phones often rely on costly resources such as grapheme-to-phoneme converters
(G2Ps) and struggle to generalize to languages with ambiguous phoneme
boundaries due to training instability. In this paper, we address both
challenges by introducing a syllable-level UASR framework based on masked
language modeling, which avoids the need for G2P and the instability of
GAN-based methods. Our approach achieves up to a 40\% relative reduction in
character error rate (CER) on LibriSpeech and generalizes effectively to
Mandarin, a language that has remained particularly difficult for prior
methods. Code will be released upon acceptance.

</details>


### [26] [UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG](https://arxiv.org/abs/2510.03663)
*Xiangyu Peng,Cab Qin,Zeyuan Chen,Ran Xu,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 提出UniDoc-Bench，一个大规模、真实的MM-RAG基准，包含70k真实PDF页面，1600个多模态QA对，涵盖事实检索、比较、总结和逻辑推理查询。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态检索增强生成(MM-RAG)评估是分散的，集中在孤立的文本或图像上，或简化的多模态设置，未能捕捉到以文档为中心的多模态用例。

Method: 构建UniDoc-Bench基准，从真实PDF页面中提取并链接文本、表格和图形中的证据，然后生成多模态QA对。采用统一协议，标准化候选池、提示和评估指标，支持四种范式的比较：文本、图像、多模态文本图像融合和多模态联合检索。

Result: 多模态文本图像融合RAG系统始终优于单模态和联合多模态嵌入检索，表明单独的文本或图像都不足，并且当前的多模态嵌入仍然不足。

Conclusion: 分析揭示了视觉上下文何时以及如何补充文本证据，揭示了系统性的失败模式，并为开发更强大的MM-RAG管道提供了可操作的指导。

Abstract: Multimodal retrieval-augmented generation (MM-RAG) is a key approach for
applying large language models (LLMs) and agents to real-world knowledge bases,
yet current evaluations are fragmented, focusing on either text or images in
isolation or on simplified multimodal setups that fail to capture
document-centric multimodal use cases. In this paper, we introduce
UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from
70k real-world PDF pages across eight domains. Our pipeline extracts and links
evidence from text, tables, and figures, then generates 1,600 multimodal QA
pairs spanning factual retrieval, comparison, summarization, and logical
reasoning queries. To ensure reliability, 20% of QA pairs are validated by
multiple annotators and expert adjudication. UniDoc-Bench supports
apples-to-apples comparison across four paradigms: (1) text-only, (2)
image-only, (3) multimodal text-image fusion, and (4) multimodal joint
retrieval -- under a unified protocol with standardized candidate pools,
prompts, and evaluation metrics. Our experiments show that multimodal
text-image fusion RAG systems consistently outperform both unimodal and jointly
multimodal embedding-based retrieval, indicating that neither text nor images
alone are sufficient and that current multimodal embeddings remain inadequate.
Beyond benchmarking, our analysis reveals when and how visual context
complements textual evidence, uncovers systematic failure modes, and offers
actionable guidance for developing more robust MM-RAG pipelines.

</details>


### [27] [Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text](https://arxiv.org/abs/2510.03683)
*Nisar Hussain,Amna Qasim,Gull Mehak,Muhammad Zain,Momina Hafeez,Grigori Sidorov*

Main category: cs.CL

TL;DR: 本文提出了一种基于QLoRA的微调框架，用于提高Roman Urdu-English文本中冒犯性语言的检测。


<details>
  <summary>Details</summary>
Motivation: 在混合编码的语言（如Roman Urdu）中使用贬义词，由于语法不明确、拼写不一致和缺乏标记数据，给自然语言处理系统带来了挑战。

Method: 该研究使用谷歌翻译将Roman Urdu-English混合编码数据集翻译成英语，并使用QLoRA微调了多个transformers和大语言模型，包括Meta LLaMA 3 8B、Mistral 7B v0.1、LLaMA 2 7B、ModernBERT和RoBERTa。

Result: Meta LLaMA 3 8B获得了最高的F1分数91.45，其次是Mistral 7B，为89.66，超过了传统的transformer基线。

Conclusion: 结果表明，QLoRA在微调高性能模型以用于混合编码冒犯性语言检测等低资源环境中的有效性，并证实了LLM在此任务中的潜力。这项工作推进了一种可扩展的Roman Urdu审核方法，并为未来基于LLM的多语言冒犯性检测系统铺平了道路。

Abstract: The use of derogatory terms in languages that employ code mixing, such as
Roman Urdu, presents challenges for Natural Language Processing systems due to
unstated grammar, inconsistent spelling, and a scarcity of labeled data. In
this work, we propose a QLoRA based fine tuning framework to improve offensive
language detection in Roman Urdu-English text. We translated the Roman
Urdu-English code mixed dataset into English using Google Translate to leverage
English LLMs, while acknowledging that this translation reduces direct
engagement with code mixing features. Our focus is on classification
performance using English translated low resource inputs. We fine tuned several
transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B
v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient
adaptation. Models were trained and evaluated on a manually annotated Roman
Urdu dataset for offensive vs non offensive content. Of all tested models, the
highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral
7B at 89.66, surpassing traditional transformer baselines. These results
demonstrate the efficacy of QLoRA in fine tuning high performing models for low
resource environments such as code mixed offensive language detection, and
confirm the potential of LLMs for this task. This work advances a scalable
approach to Roman Urdu moderation and paves the way for future multilingual
offensive detection systems based on LLMs.

</details>


### [28] [MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction](https://arxiv.org/abs/2510.03687)
*Yue Huang,Yanyuan Chen,Dexuan Xu,Weihua Yue,Huamin Zhang,Meikang Qiu,Yu Huang*

Main category: cs.CL

TL;DR: MedReflect框架通过模拟医生般的反思性思维模式，激发大型语言模型（LLM）在医疗问题解决中的潜力，无需外部检索或大量标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部知识或推理数据集，存在检索开销高、标注成本高等问题，且性能受限。

Method: MedReflect生成单次反思链，包括初始假设生成、自我提问、自我回答和决策优化。

Result: 仅用2000个随机抽样的训练样本进行轻微微调，即可在多个医疗基准测试中实现显著的绝对精度提升，同时降低标注需求。

Conclusion: LLM可以通过自我反思和自我改进来解决特定的医疗问题，减少对外部监督和大量特定任务微调数据的依赖。

Abstract: Medical problem solving demands expert knowledge and intricate reasoning.
Recent studies of large language models (LLMs) attempt to ease this complexity
by introducing external knowledge verification through retrieval-augmented
generation or by training on reasoning datasets. However, these approaches
suffer from drawbacks such as retrieval overhead and high annotation costs, and
they heavily rely on substituted external assistants to reach limited
performance in medical field. In this paper, we introduce MedReflect, a
generalizable framework designed to inspire LLMs with a physician-like
reflective thinking mode. MedReflect generates a single-pass reflection chain
that includes initial hypothesis generation, self-questioning, self-answering
and decision refinement. This self-verified and self-reflective nature releases
large language model's latent capability in medical problem-solving without
external retrieval or heavy annotation. We demonstrate that MedReflect enables
cost-efficient medical dataset construction: with merely 2,000 randomly sampled
training examples and a light fine-tuning, this approach achieves notable
absolute accuracy improvements across a series of medical benchmarks while
cutting annotation requirements. Our results provide evidence that LLMs can
learn to solve specialized medical problems via self-reflection and
self-improve, reducing reliance on external supervision and extensive
task-specific fine-tuning data.

</details>


### [29] [TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation](https://arxiv.org/abs/2510.03748)
*Ramtin Kakavand,Ebrahim Ansari*

Main category: cs.CL

TL;DR: TreePrompt是一种新颖的示例选择方法，它学习 LLM 偏好，以在树结构框架中识别高质量、上下文相关的示例。


<details>
  <summary>Details</summary>
Motivation: 现有示例选择方法只关注查询到示例的相似性，而没有考虑示例的质量。

Method: 提出 TreePrompt，一种新颖的示例选择方法，它学习 LLM 偏好，以在树结构框架中识别高质量、上下文相关的示例。将 TreePrompt 与 K-最近邻 (K-NN) 和自适应少样本提示 (AFSP) 相结合。

Result: 在两个语言对（英语-波斯语 (MIZAN) 和英语-德语 (WMT19)）上的评估表明，将 TreePrompt 与 AFSP 或随机选择相结合可以提高翻译性能。

Conclusion: 将 TreePrompt 与 AFSP 或随机选择相结合可以提高翻译性能。

Abstract: Large Language Models (LLMs) have consistently demonstrated strong
performance in machine translation, especially when guided by high-quality
prompts. Few-shot prompting is an effective technique to improve translation
quality; however, most existing example selection methods focus solely on
query-to-example similarity and do not account for the quality of the examples.
In this work, we propose TreePrompt, a novel example selection approach that
learns LLM preferences to identify high-quality, contextually relevant examples
within a tree-structured framework. To further explore the balance between
similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN)
and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs -
English-Persian (MIZAN) and English-German (WMT19) - show that integrating
TreePrompt with AFSP or Random selection leads to improved translation
performance.

</details>


### [30] [Cross-Lingual Multi-Granularity Framework for Interpretable Parkinson's Disease Diagnosis from Speech](https://arxiv.org/abs/2510.03758)
*Ilias Tougui,Mehdi Zakroum,Mounir Ghogho*

Main category: cs.CL

TL;DR: 本文提出了一种细粒度的多语言帕金森病(PD)检测方法，该方法通过自动流程从记录中提取时间对齐的音素、音节和单词。


<details>
  <summary>Details</summary>
Motivation: 目前基于语音的检测系统分析整个话语，可能忽略了特定语音元素的诊断价值。

Method: 使用意大利语、西班牙语和英语数据集，我们实现了一个具有多头注意力的双向LSTM，以比较不同粒度级别的诊断性能。

Result: 音素级别的分析取得了优异的性能，AUROC为93.78% +- 2.34%，准确率为92.17% +- 2.43%。

Conclusion: 结果表明，对于跨语言PD检测，增强了诊断能力。重要的是，注意力分析表明，信息量最大的语音特征与已建立的临床协议中使用的特征相一致：音素水平上的持续元音（/a/、/e/、/o/、/i/），音节水平上的快速重复音节（/ta/、/pa/、/la/、/ka/）和单词水平上的/pataka/序列。

Abstract: Parkinson's Disease (PD) affects over 10 million people worldwide, with
speech impairments in up to 89% of patients. Current speech-based detection
systems analyze entire utterances, potentially overlooking the diagnostic value
of specific phonetic elements. We developed a granularity-aware approach for
multilingual PD detection using an automated pipeline that extracts
time-aligned phonemes, syllables, and words from recordings. Using Italian,
Spanish, and English datasets, we implemented a bidirectional LSTM with
multi-head attention to compare diagnostic performance across the different
granularity levels. Phoneme-level analysis achieved superior performance with
AUROC of 93.78% +- 2.34% and accuracy of 92.17% +- 2.43%. This demonstrates
enhanced diagnostic capability for cross-linguistic PD detection. Importantly,
attention analysis revealed that the most informative speech features align
with those used in established clinical protocols: sustained vowels (/a/, /e/,
/o/, /i/) at phoneme level, diadochokinetic syllables (/ta/, /pa/, /la/, /ka/)
at syllable level, and /pataka/ sequences at word level. Source code will be
available at https://github.com/jetliqs/clearpd.

</details>


### [31] [Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs](https://arxiv.org/abs/2510.03762)
*Deshan Sumanathilaka,Nicholas Micallef,Julian Hough*

Main category: cs.CL

TL;DR: 本研究探讨了少样本提示策略如何影响词义消歧 (WSD) 任务，特别关注了不平衡样本分布引入的偏差。使用 GLOSSGPT 提示方法在五种语言上测试其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究少样本提示技术在自然语言处理中的实际应用和有效性，以及不平衡样本分布可能引入的偏差。

Method: 使用 GLOSSGPT 提示方法，在英语、德语、西班牙语、法语和意大利语这五种语言上进行测试，评估 GPT-4o 和 LLaMA-3.1-70B 模型的性能。

Result: 不平衡的少样本示例会导致多语言中不正确的语义预测，但英语中未出现此问题。

Conclusion: 多语言 WSD 对少样本设置中的样本分布敏感，强调需要平衡和有代表性的提示策略。

Abstract: Recent advances in Large Language Models (LLMs) have significantly reshaped
the landscape of Natural Language Processing (NLP). Among the various prompting
techniques, few-shot prompting has gained considerable attention for its
practicality and effectiveness. This study investigates how few-shot prompting
strategies impact the Word Sense Disambiguation (WSD) task, particularly
focusing on the biases introduced by imbalanced sample distributions. We use
the GLOSSGPT prompting method, an advanced approach for English WSD, to test
its effectiveness across five languages: English, German, Spanish, French, and
Italian. Our results show that imbalanced few-shot examples can cause incorrect
sense predictions in multilingual languages, but this issue does not appear in
English. To assess model behavior, we evaluate both the GPT-4o and
LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual
WSD to sample distribution in few-shot settings, emphasizing the need for
balanced and representative prompting strategies.

</details>


### [32] [Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development](https://arxiv.org/abs/2510.03781)
*Majid Asgari-Bidhendi,Muhammad Amin Ghaseminia,Alireza Shahbazi,Sayyed Ali Hossayni,Najmeh Torabian,Behrouz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: 本文介绍了一个名为 Rezwan 的大型 AI 辅助圣训语料库的开发，该语料库包含超过 120 万条叙述，这些叙述通过完全自动化的流程提取和结构化。


<details>
  <summary>Details</summary>
Motivation: 构建在 Maktabat Ahl al-Bayt 等数字存储库的基础上，利用大型语言模型 (LLM) 进行分割、链文本分离、验证和多层丰富。

Method: 每个叙述都通过机器翻译成十二种语言、智能变音、抽象概括、主题标记和跨文本语义分析得到增强。

Result: 对 1,213 个随机抽样的叙述进行了严格的评估，由六位领域专家进行评估。结果表明，在链文本分离 (9.33/10) 和概括 (9.33/10) 等结构化任务中，准确率接近人类水平，同时突出了变音和语义相似性检测方面持续存在的挑战。

Conclusion: 这项工作引入了一种新的宗教文本处理范例，展示了 AI 如何增强人类的专业知识，从而实现大规模、多语言和语义丰富的伊斯兰遗产访问。

Abstract: This paper presents the development of Rezwan, a large-scale AI-assisted
Hadith corpus comprising over 1.2M narrations, extracted and structured through
a fully automated pipeline. Building on digital repositories such as Maktabat
Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for
segmentation, chain--text separation, validation, and multi-layer enrichment.
Each narration is enhanced with machine translation into twelve languages,
intelligent diacritization, abstractive summarization, thematic tagging, and
cross-text semantic analysis. This multi-step process transforms raw text into
a richly annotated research-ready infrastructure for digital humanities and
Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled
narrations, assessed by six domain experts. Results show near-human accuracy in
structured tasks such as chain--text separation (9.33/10) and summarization
(9.33/10), while highlighting ongoing challenges in diacritization and semantic
similarity detection. Comparative analysis against the manually curated Noor
Corpus demonstrates the superiority of Najm in both scale and quality, with a
mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis
confirms the economic feasibility of the AI approach: tasks requiring over
229,000 hours of expert labor were completed within months at a fraction of the
cost. The work introduces a new paradigm in religious text processing by
showing how AI can augment human expertise, enabling large-scale, multilingual,
and semantically enriched access to Islamic heritage.

</details>


### [33] [Mechanistic Interpretability of Socio-Political Frames in Language Models](https://arxiv.org/abs/2510.03799)
*Hadi Asghari,Sami Nenno*

Main category: cs.CL

TL;DR: 大型语言模型可以生成和识别认知框架，尤其是在社会政治语境下。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型生成文本和识别文本框架的能力

Method: 通过prompt让LLM生成特定框架的文本，并进行zero-shot框架识别。受启发于机械可解释性研究，研究者探索了模型隐藏层中strict father和nurturing parent框架的位置，并识别出与其存在密切相关的奇异维度。

Result: LLM能够流利地生成能够唤起特定框架的文本，并且可以在zero-shot场景中识别这些框架。

Conclusion: 该研究有助于理解LLM如何捕捉和表达有意义的人类概念。

Abstract: This paper explores the ability of large language models to generate and
recognize deep cognitive frames, particularly in socio-political contexts. We
demonstrate that LLMs are highly fluent in generating texts that evoke specific
frames and can recognize these frames in zero-shot settings. Inspired by
mechanistic interpretability research, we investigate the location of the
`strict father' and `nurturing parent' frames within the model's hidden
representation, identifying singular dimensions that correlate strongly with
their presence. Our findings contribute to understanding how LLMs capture and
express meaningful human concepts.

</details>


### [34] [Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models](https://arxiv.org/abs/2510.03805)
*Canhui Wu,Qiong Cao,Chang Li,Zhenfang Wang,Chao Xue,Yuwei Fan,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 这篇论文提出了一种名为 Step Pruner (SP) 的强化学习框架，旨在解决大型推理模型 (LRM) 中过度冗余的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习方法通常通过惩罚生成的 token 来促进简洁性，但这存在两个问题：token 数量少并不总是意味着推理步骤少，并且模型可能会通过丢弃推理步骤来最小化 token 使用量，从而产生 hacking 行为。

Method: 该论文提出了 Step Pruner (SP)，它通过支持紧凑的推理步骤来引导 LRM 进行更有效的推理。SP 的 step-aware 奖励函数优先考虑正确性，同时对冗余步骤进行惩罚，并对不正确的响应不予奖励，以防止错误的推理得到强化。此外，该论文还提出了一种动态停止机制：当任何输出步骤的长度超过上限时，停止更新，以防止因合并步骤而导致的 hacking 行为。

Result: 在四个推理基准上的大量实验表明，SP 在显着减少响应长度的同时，实现了最先进的准确性。例如，在 AIME24 上，SP 将 token 使用量减少了 69.7%。

Conclusion: SP 框架能够有效地减少大型推理模型的冗余，同时保持甚至提高准确性。

Abstract: Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks
but often suffer from excessive verbosity, known as "overthinking." Existing
solutions via reinforcement learning (RL) typically penalize generated tokens
to promote conciseness. However, these methods encounter two challenges:
responses with fewer tokens do not always correspond to fewer reasoning steps,
and models may develop hacking behavior in later stages of training by
discarding reasoning steps to minimize token usage. In this work, we introduce
\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more
efficient reasoning by favoring compact reasoning steps. Our step-aware reward
function prioritizes correctness while imposing penalties for redundant steps,
and withholds rewards for incorrect responses to prevent the reinforcement of
erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when
the length of any output step exceeds the upper limit, we halt updates to
prevent hacking behavior caused by merging steps. Extensive experiments across
four reasoning benchmarks demonstrate that SP achieves state-of-the-art
accuracy while significantly reducing response length. For instance, on AIME24,
SP reduces token usage by \textbf{69.7\%}.

</details>


### [35] [Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches](https://arxiv.org/abs/2510.03808)
*Mehedi Hasan Emon*

Main category: cs.CL

TL;DR: 本研究探讨了使用INCEpTION工具注释语篇中的修辞关系，并将人工注释与基于大型语言模型的自动方法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索使用大型语言模型自动分类语篇修辞关系，以提高效率并推动语篇分析和自然语言处理的交叉发展。

Method: 该研究使用INCEpTION工具进行语篇修辞关系的人工标注，并采用BERT、DistilBERT和Logistic Regression模型对板球新闻中的修辞关系（如阐述、对比、背景和因果关系）进行分类。

Result: 结果表明，DistilBERT模型取得了最高的准确率。

Conclusion: DistilBERT在语篇关系预测方面具有潜力，本研究对语篇分析和基于Transformer的自然语言处理的交叉领域做出了贡献。

Abstract: This research explores the annotation of rhetorical relations in discourse
using the INCEpTION tool and compares manual annotation with automatic
approaches based on large language models. The study focuses on sports reports
(specifically cricket news) and evaluates the performance of BERT, DistilBERT,
and Logistic Regression models in classifying rhetorical relations such as
elaboration, contrast, background, and cause-effect. The results show that
DistilBERT achieved the highest accuracy, highlighting its potential for
efficient discourse relation prediction. This work contributes to the growing
intersection of discourse parsing and transformer-based NLP. (This paper was
conducted as part of an academic requirement under the supervision of Prof. Dr.
Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords:
Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing,
NLP.

</details>


### [36] [Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles](https://arxiv.org/abs/2510.03898)
*Nusrat Jahan Lia,Shubhashis Roy Dipta,Abdullah Khan Zehady,Naymul Islam,Madhusodan Chakraborty,Abdullah Al Wasif*

Main category: cs.CL

TL;DR: 本文构建了首个孟加拉语政治立场检测基准数据集，用于评估大型语言模型（LLM）在检测孟加拉语新闻中的政治偏见的能力。


<details>
  <summary>Details</summary>
Motivation: 检测媒体偏见至关重要，特别是在南亚地区。然而，针对孟加拉语政治偏见研究的带注释数据集和计算研究仍然稀缺。孟加拉语新闻中的政治立场检测需要理解语言线索、文化背景、微妙偏见、修辞策略、语码转换、隐含情感和社会政治背景。

Method: 构建了一个包含200篇具有政治意义且备受争议的孟加拉语新闻文章的数据集，并标注为倾向政府、批评政府和中立立场。对28个专有和开源LLM进行了综合评估。

Result: 在检测批评政府的内容方面表现出色（F1高达0.83），但在中立文章方面存在很大困难（F1低至0.00）。模型还倾向于过度预测倾向政府的立场，经常错误地解释模糊的叙述。

Conclusion: 该数据集及其相关诊断为推进孟加拉媒体研究中的立场检测奠定了基础，并为提高LLM在低资源语言中的性能提供了见解。

Abstract: Detecting media bias is crucial, specifically in the South Asian region.
Despite this, annotated datasets and computational studies for Bangla political
bias research remain scarce. Crucially because, political stance detection in
Bangla news requires understanding of linguistic cues, cultural context, subtle
biases, rhetorical strategies, code-switching, implicit sentiment, and
socio-political background. To address this, we introduce the first benchmark
dataset of 200 politically significant and highly debated Bangla news articles,
labeled for government-leaning, government-critique, and neutral stances,
alongside diagnostic analyses for evaluating large language models (LLMs). Our
comprehensive evaluation of 28 proprietary and open-source LLMs shows strong
performance in detecting government-critique content (F1 up to 0.83) but
substantial difficulty with neutral articles (F1 as low as 0.00). Models also
tend to over-predict government-leaning stances, often misinterpreting
ambiguous narratives. This dataset and its associated diagnostics provide a
foundation for advancing stance detection in Bangla media research and offer
insights for improving LLM performance in low-resource languages.

</details>


### [37] [PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian](https://arxiv.org/abs/2510.03913)
*Mohammad Amin Abbasi,Hassan Naderi*

Main category: cs.CL

TL;DR: 本文介绍了PsychoLexTherapy，一个使用小型语言模型（SLM）模拟波斯语心理治疗推理的框架，专为在资源不足的语言中开发具有文化基础的、治疗上连贯的对话系统而设计，并优化了设备端部署，保障隐私。


<details>
  <summary>Details</summary>
Motivation: 在资源不足的语言中，开发具有文化基础且治疗上连贯的对话系统是一个挑战。PsychoLexTherapy旨在解决这个问题，特别关注波斯语心理治疗的模拟。

Method: 该研究分三个阶段进行：(i) 使用PsychoLexEval评估SLM的心理学知识；(ii) 设计并实施面向推理的PsychoLexTherapy框架；(iii) 构建两个评估数据集（PsychoLexQuery和PsychoLexDialogue）以进行基准测试。采用了简单提示、多智能体辩论和结构化治疗推理路径等多种实验方法。

Result: 实验结果表明，谨慎的模型选择可以平衡准确性、效率和隐私。PsychoLexTherapy在PsychoLexQuery上优于所有基线，并在多轮测试中表现出更高的共情、连贯性、文化适应性和个性化。

Conclusion: PsychoLexTherapy为波斯语心理治疗模拟奠定了实用、保护隐私和文化对齐的基础，贡献了新的数据集、可重复的评估流程以及关于治疗推理结构化记忆的实证见解。

Abstract: This study presents PsychoLexTherapy, a framework for simulating
psychotherapeutic reasoning in Persian using small language models (SLMs). The
framework tackles the challenge of developing culturally grounded,
therapeutically coherent dialogue systems with structured memory for multi-turn
interactions in underrepresented languages. To ensure privacy and feasibility,
PsychoLexTherapy is optimized for on-device deployment, enabling use without
external servers. Development followed a three-stage process: (i) assessing
SLMs psychological knowledge with PsychoLexEval; (ii) designing and
implementing the reasoning-oriented PsychoLexTherapy framework; and (iii)
constructing two evaluation datasets-PsychoLexQuery (real Persian user
questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark
against multiple baselines. Experiments compared simple prompting, multi-agent
debate, and structured therapeutic reasoning paths. Results showed that
deliberate model selection balanced accuracy, efficiency, and privacy. On
PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic
LLM-as-a-judge evaluation and was ranked highest by human evaluators in a
single-turn preference study. In multi-turn tests with PsychoLexDialogue, the
long-term memory module proved essential: while naive history concatenation
caused incoherence and information loss, the full framework achieved the
highest ratings in empathy, coherence, cultural fit, and personalization.
Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and
culturally aligned foundation for Persian psychotherapy simulation,
contributing novel datasets, a reproducible evaluation pipeline, and empirical
insights into structured memory for therapeutic reasoning.

</details>


### [38] [Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs](https://arxiv.org/abs/2510.03997)
*Junjie Luo,Rui Han,Arshana Welivita,Zeleikun Di,Jingfu Wu,Xuzhe Zhi,Ritu Agarwal,Gordon Gao*

Main category: cs.CL

TL;DR: 本研究使用大型语言模型分析了410万患者对22.7万美国医生的评价，以推断医生的人格特质和患者的主观判断。


<details>
  <summary>Details</summary>
Motivation: 了解患者如何看待医生对于改善信任、沟通和满意度至关重要。

Method: 该研究构建了一个基于LLM的流程，用于推断医生的Big Five人格特质和五个以患者为导向的主观判断。通过多模型比较和人工专家评估验证了该方法。

Result: 研究发现男性医生在所有特质上都获得更高的评价，尤其在临床能力方面；儿科和精神科医生在共情相关特质上表现突出；所有特质都正向预测患者的总体满意度。聚类分析识别出四种不同的医生类型。

Conclusion: 从患者叙述中自动提取特质可以为大规模理解医患关系提供可解释的、经过验证的指标，对医疗保健中的质量评估、偏见检测和劳动力发展具有重要意义。

Abstract: Understanding how patients perceive their physicians is essential to
improving trust, communication, and satisfaction. We present a large language
model (LLM)-based pipeline that infers Big Five personality traits and five
patient-oriented subjective judgments. The analysis encompasses 4.1 million
patient reviews of 226,999 U.S. physicians from an initial pool of one million.
We validate the method through multi-model comparison and human expert
benchmarking, achieving strong agreement between human and LLM assessments
(correlation coefficients 0.72-0.89) and external validity through correlations
with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis
reveals systematic patterns: male physicians receive higher ratings across all
traits, with largest disparities in clinical competence perceptions;
empathy-related traits predominate in pediatrics and psychiatry; and all traits
positively predict overall satisfaction. Cluster analysis identifies four
distinct physician archetypes, from "Well-Rounded Excellent" (33.8%, uniformly
high traits) to "Underperforming" (22.6%, consistently low). These findings
demonstrate that automated trait extraction from patient narratives can provide
interpretable, validated metrics for understanding physician-patient
relationships at scale, with implications for quality measurement, bias
detection, and workforce development in healthcare.

</details>


### [39] [Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions](https://arxiv.org/abs/2510.03999)
*Yang Xu,Xuanming Zhang,Min-Hsuan Yeh,Jwala Dhamala,Ousmane Dia,Rahul Gupta,Yixuan Li*

Main category: cs.CL

TL;DR: 大型语言模型(llm)中的欺骗是一个普遍的特征。本文介绍了一种模拟框架，用于探测和评估llm在扩展的相互依赖的任务序列和动态的上下文压力下的欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 现有的研究大多局限于单轮提示，无法捕捉到欺骗策略展开的长程交互。

Method: 该框架实例化了一个多代理系统：一个执行者代理负责完成任务，一个监督者代理负责评估进度、提供反馈并维持不断发展的信任状态。然后，一个独立的欺骗审计员审查完整的轨迹，以确定欺骗发生的时间和方式。

Result: 欺骗是依赖于模型的，随着事件压力的增加而增加，并且持续侵蚀监督者的信任。定性分析进一步揭示了隐藏、含糊和伪造的不同策略。

Conclusion: 欺骗是长程交互中出现的一种风险，并为在现实世界中评估未来的llm奠定了基础。

Abstract: Deception is a pervasive feature of human communication and an emerging
concern in large language models (LLMs). While recent studies document
instances of LLM deception under pressure, most evaluations remain confined to
single-turn prompts and fail to capture the long-horizon interactions in which
deceptive strategies typically unfold. We introduce the first simulation
framework for probing and evaluating deception in LLMs under extended sequences
of interdependent tasks and dynamic contextual pressures. Our framework
instantiates a multi-agent system: a performer agent tasked with completing
tasks and a supervisor agent that evaluates progress, provides feedback, and
maintains evolving states of trust. An independent deception auditor then
reviews full trajectories to identify when and how deception occurs. We conduct
extensive experiments across 11 frontier models, spanning both closed- and
open-source systems, and find that deception is model-dependent, increases with
event pressure, and consistently erodes supervisor trust. Qualitative analyses
further reveal distinct strategies of concealment, equivocation, and
falsification. Our findings establish deception as an emergent risk in
long-horizon interactions and provide a foundation for evaluating future LLMs
in real-world, trust-sensitive contexts.

</details>


### [40] [Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation](https://arxiv.org/abs/2510.04001)
*Xuankang Zhang,Jiangming Liu*

Main category: cs.CL

TL;DR: 本文提出了一种新的实体知识增强方法，用于识别社交媒体和生物医学文本中的COVID-19相关命名实体。


<details>
  <summary>Details</summary>
Motivation: 由于社交媒体上的COVID-19文本非正式，注释稀少且不足以训练鲁棒的识别模型，并且COVID-19中的命名实体识别需要广泛的领域特定知识，因此对该主题的命名实体识别工作有限。

Method: 我们提出了一种用于COVID-19的新型实体知识增强方法，该方法也可应用于非正式和正式文本格式的一般生物医学命名实体识别。

Result: 在COVID-19推文数据集和PubMed数据集上进行的实验表明，我们提出的实体知识增强提高了完全监督和少样本设置下的NER性能。

Conclusion: 本文提出了一种有效的实体知识增强方法，可用于识别社交媒体和生物医学文本中的COVID-19相关命名实体，并在实验中验证了其有效性。

Abstract: The COVID-19 pandemic causes severe social and economic disruption around the
world, raising various subjects that are discussed over social media.
Identifying pandemic-related named entities as expressed on social media is
fundamental and important to understand the discussions about the pandemic.
However, there is limited work on named entity recognition on this topic due to
the following challenges: 1) COVID-19 texts in social media are informal and
their annotations are rare and insufficient to train a robust recognition
model, and 2) named entity recognition in COVID-19 requires extensive
domain-specific knowledge. To address these issues, we propose a novel entity
knowledge augmentation approach for COVID-19, which can also be applied in
general biomedical named entity recognition in both informal text format and
formal text format. Experiments carried out on the COVID-19 tweets dataset and
PubMed dataset show that our proposed entity knowledge augmentation improves
NER performance in both fully-supervised and few-shot settings. Our source code
is publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master

</details>


### [41] [AgriGPT-VL: Agricultural Vision-Language Understanding Suite](https://arxiv.org/abs/2510.04002)
*Bo Yang,Yunkui Chen,Lanfei Feng,Yu Zhang,Xiao Xu,Jianyu Zhang,Nueraili Aierken,Runhe Huang,Hongjian Lin,Yibin Ying,Shijian Li*

Main category: cs.CL

TL;DR: 论文提出了 AgriGPT-VL 套件，一个用于农业的统一多模态框架，包括数据集、模型和评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在农业应用中受到领域模型、语料库和评估的限制。

Method: 1. 构建了最大的农业视觉语言语料库 Agri-3M-VL。2. 开发了农业专用视觉语言模型 AgriGPT-VL，通过文本基础、多模态对齐和 GRPO 改进进行训练。3. 构建了 AgriBench-VL-4K 评估套件。

Result: AgriGPT-VL 在 AgriBench-VL-4K 上优于通用 VLM，并在文本任务上保持竞争力。消融实验证实了对齐和 GRPO 改进的收益。

Conclusion: 论文开源所有资源，以支持可重复的研究和在低资源农业环境中的部署。

Abstract: Despite rapid advances in multimodal large language models, agricultural
applications remain constrained by the scarcity of domain-tailored models,
curated vision-language corpora, and rigorous evaluation. To address these
challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for
agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL,
the largest vision-language corpus for agriculture to our knowledge, curated by
a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M
image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO
reinforcement learning samples. Second, we develop AgriGPT-VL, an
agriculture-specialized vision-language model trained via a progressive
curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO
refinement. This method achieves strong multimodal reasoning while preserving
text-only capability. Third, we establish AgriBench-VL-4K, a compact yet
challenging evaluation suite with open-ended and image-grounded questions,
paired with multi-metric evaluation and an LLM-as-a-judge framework.
Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on
AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge
evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K
with no noticeable degradation of language ability. Ablation studies further
confirm consistent gains from our alignment and GRPO refinement stages. We will
open source all of the resources to support reproducible research and
deployment in low-resource agricultural settings.

</details>


### [42] [LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization](https://arxiv.org/abs/2510.04013)
*Jiarui Liu,Jivitesh Jain,Mona Diab,Nishant Subramani*

Main category: cs.CL

TL;DR: 这篇论文研究了大型语言模型(LLM)的可靠性问题，特别是模型生成不正确信息的问题。通过研究模型内部的激活状态，来预测模型输出的正确性，并评估外部上下文的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然功能强大，但其可靠性是一个主要问题，因为模型经常会自信地生成不正确的信息。利用上下文信息可以帮助引导生成，但是确定查询何时能从检索到的上下文中获益以及评估上下文的有效性仍然具有挑战性。

Method: 本文运用可解释性方法，确定是否仅从模型的激活状态就能预测模型输出的正确性。同时，探索模型内部是否包含关于外部上下文有效性的信号。考虑正确、不正确和不相关的上下文，并引入指标来区分它们。

Result: 在六个不同模型上的实验表明，一个在第一个输出token的中间层激活状态上训练的简单分类器，可以大约75%的准确率预测输出的正确性，从而实现早期审计。基于模型内部的指标在区分正确和不正确的上下文方面显著优于prompting baselines，防止受污染的上下文引入的不准确性。

Conclusion: 这些发现提供了一个视角，可以更好地理解LLM的底层决策过程。

Abstract: Although large language models (LLMs) have tremendous utility,
trustworthiness is still a chief concern: models often generate incorrect
information with high confidence. While contextual information can help guide
generation, identifying when a query would benefit from retrieved context and
assessing the effectiveness of that context remains challenging. In this work,
we operationalize interpretability methods to ascertain whether we can predict
the correctness of model outputs from the model's activations alone. We also
explore whether model internals contain signals about the efficacy of external
context. We consider correct, incorrect, and irrelevant context and introduce
metrics to distinguish amongst them. Experiments on six different models reveal
that a simple classifier trained on intermediate layer activations of the first
output token can predict output correctness with about 75% accuracy, enabling
early auditing. Our model-internals-based metric significantly outperforms
prompting baselines at distinguishing between correct and incorrect context,
guarding against inaccuracies introduced by polluted context. These findings
offer a lens to better understand the underlying decision-making processes of
LLMs. Our code is publicly available at
https://github.com/jiarui-liu/LLM-Microscope

</details>


### [43] [Thai Semantic End-of-Turn Detection for Real-Time Voice Agents](https://arxiv.org/abs/2510.04016)
*Thanapol Popit,Natthapath Rungseesiripak,Monthol Charattrakool,Saksorn Ruangtanusak*

Main category: cs.CL

TL;DR: 本文研究了泰语语音交互中，如何低延迟、高可靠地检测用户何时结束发言。


<details>
  <summary>Details</summary>
Motivation: 传统的静音检测方法延迟高且在特定语言环境下失效。因此，本文旨在研究泰语环境下基于文本的EOT检测方法。

Method: 本文对比了小型LLM的零样本/少样本提示和轻量级Transformer的监督微调方法。利用YODAS语料库和泰语特定语言特征，将EOT问题转化为token边界上的二元决策。

Result: 本文报告了准确率和延迟之间的权衡关系，并提供了一个可公开使用的实现方案。

Conclusion: 本文为泰语EOT检测建立了一个基线，并证明小型微调模型可以实现近乎实时的EOT决策，适用于本地设备上的智能体。

Abstract: Fluid voice-to-voice interaction requires reliable and low-latency detection
of when a user has finished speaking. Traditional audio-silence end-pointers
add hundreds of milliseconds of delay and fail under hesitations or
language-specific phenomena. We present, to our knowledge, the first systematic
study of Thai text-only end-of-turn (EOT) detection for real-time agents. We
compare zero-shot and few-shot prompting of compact LLMs to supervised
fine-tuning of lightweight transformers. Using transcribed subtitles from the
YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final
particles), we formulate EOT as a binary decision over token boundaries. We
report a clear accuracy-latency tradeoff and provide a public-ready
implementation plan. This work establishes a Thai baseline and demonstrates
that small, fine-tuned models can deliver near-instant EOT decisions suitable
for on-device agents.

</details>


### [44] [Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?](https://arxiv.org/abs/2510.04031)
*Nelvin Tan,James Asikin Cheung,Yu-Ching Shih,Dong Yang,Amol Salunkhe*

Main category: cs.CL

TL;DR: 大型语言模型在文本分类任务中表现出色，但其决策过程需要解释。本文研究了在LLM推理中加入反事实分析如何影响LLM识别关键贡献词语的能力。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在文本分类任务中的决策过程，特别是在LLM为黑盒且调用成本高昂的实际约束下。

Method: 提出一种名为决策变化率的框架，用于量化分类中关键单词的重要性。通过将反事实分析融入LLM推理，观察其对识别关键单词的影响。

Result: 实验结果表明，使用反事实分析是有帮助的。

Conclusion: 反事实分析可以帮助LLM识别对其分类决策贡献最大的词语。

Abstract: Large language models (LLMs) are becoming useful in many domains due to their
impressive abilities that arise from large training datasets and large model
sizes. More recently, they have been shown to be very effective in textual
classification tasks, motivating the need to explain the LLMs' decisions.
Motivated by practical constrains where LLMs are black-boxed and LLM calls are
expensive, we study how incorporating counterfactuals into LLM reasoning can
affect the LLM's ability to identify the top words that have contributed to its
classification decision. To this end, we introduce a framework called the
decision changing rate that helps us quantify the importance of the top words
in classification. Our experimental results show that using counterfactuals can
be helpful.

</details>


### [45] [Small Language Models for Emergency Departments Decision Support: A Benchmark Study](https://arxiv.org/abs/2510.04032)
*Zirui Wang,Jiajun Wu,Braden Teitge,Jessalyn Holodinsky,Steve Drew*

Main category: cs.CL

TL;DR: 本文旨在评估适用于急诊科 (ED) 决策支持的小型语言模型 (SLM)，因为它们具有推理能力和高效性能，同时考虑到实际部署中的硬件限制、运营成本和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 在快节奏和高风险的急诊科环境中，小型语言模型 (SLM) 具有巨大的潜力，因为它们能够提供及时和准确的信息，从而改善临床决策和工作流程效率。

Method: 本文构建了一个综合的基准，用于评估适合急诊科决策支持的 SLM，并重点关注在通用领域和医学语料库上训练的 SLM。基准数据集包括 MedMCQA、MedQA-4Options 和 PubMedQA，以及模拟急诊科医生日常任务的医学摘要数据集。

Result: 实验结果表明，通用领域的 SLM 在这些不同的急诊科基准测试中，出人意料地优于经过医学微调的 SLM。

Conclusion: 对于急诊科而言，可能不需要对模型进行专门的医学微调。

Abstract: Large language models (LLMs) have become increasingly popular in medical
domains to assist physicians with a variety of clinical and operational tasks.
Given the fast-paced and high-stakes environment of emergency departments
(EDs), small language models (SLMs), characterized by a reduction in parameter
count compared to LLMs, offer significant potential due to their inherent
reasoning capability and efficient performance. This enables SLMs to support
physicians by providing timely and accurate information synthesis, thereby
improving clinical decision-making and workflow efficiency. In this paper, we
present a comprehensive benchmark designed to identify SLMs suited for ED
decision support, taking into account both specialized medical expertise and
broad general problem-solving capabilities. In our evaluations, we focus on
SLMs that have been trained on a mixture of general-domain and medical corpora.
A key motivation for emphasizing SLMs is the practical hardware limitations,
operational cost constraints, and privacy concerns in the typical real-world
deployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and
PubMedQA, with the medical abstracts dataset emulating tasks aligned with real
ED physicians' daily tasks. Experimental results reveal that general-domain
SLMs surprisingly outperform their medically fine-tuned counterparts across
these diverse benchmarks for ED. This indicates that for ED, specialized
medical fine-tuning of the model may not be required.

</details>


### [46] [Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment](https://arxiv.org/abs/2510.04045)
*Yunfan Zhang,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: 探讨了大型语言模型在理解细微人类观点方面的局限性，并研究了思维链（CoT）推理技术在构建可控多元化模型中的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常被训练成反映一套相对统一的价值观，限制了它们在需要理解细微人类观点任务中的适用性。最近的研究强调了使LLM能够支持可操纵的多元化的重要性——即采纳特定观点并使生成的输出与之对齐的能力。

Method: 研究了CoT提示、在人工编写的CoT上进行微调、在合成解释上进行微调以及基于可验证奖励的强化学习（RLVR）等方法。

Result: 在所研究的方法中，RLVR始终优于其他方法，并表现出强大的训练样本效率。

Conclusion: 分析了生成的CoT traces在忠实性和安全性方面的情况，表明RLVR方法具有优越性。

Abstract: Large Language Models (LLMs) are typically trained to reflect a relatively
uniform set of values, which limits their applicability to tasks that require
understanding of nuanced human perspectives. Recent research has underscored
the importance of enabling LLMs to support steerable pluralism -- the capacity
to adopt a specific perspective and align generated outputs with it. In this
work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be
applied to building steerable pluralistic models. We explore several methods,
including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on
synthetic explanations, and Reinforcement Learning with Verifiable Rewards
(RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA
datasets. Among the methods studied, RLVR consistently outperforms others and
demonstrates strong training sample efficiency. We further analyze the
generated CoT traces with respect to faithfulness and safety.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [47] [SoC-DT: Standard-of-Care Aligned Digital Twins for Patient-Specific Tumor Dynamics](https://arxiv.org/abs/2510.03287)
*Moinak Bhattacharya,Gagandeep Singh,Prateek Prasanna*

Main category: cs.CV

TL;DR: 本文介绍了一种名为Standard-of-Care Digital Twin (SoC-DT) 的可微框架，用于预测标准治疗(SoC)下的肿瘤轨迹。


<details>
  <summary>Details</summary>
Motivation: 在肿瘤学中，准确预测标准治疗(SoC)下的肿瘤轨迹仍然是一个尚未满足的重要需求。传统的反应扩散模型无法捕捉异质治疗范式下的肿瘤动态。

Method: 该框架统一了反应扩散肿瘤生长模型、离散SoC干预（手术、化疗、放疗）以及基因组和人口统计学个性化，以预测治疗后成像上的肿瘤结构。此外，还提出了一种隐式-显式指数时间差分求解器IMEX-SoC，以确保SoC治疗情况下的稳定性、积极性和可扩展性。

Result: 在合成数据和真实世界神经胶质瘤数据上的评估表明，SoC-DT在预测肿瘤动态方面始终优于经典的PDE基线和纯粹的数据驱动神经模型。

Conclusion: SoC-DT通过将机制可解释性与现代可微求解器相结合，为肿瘤学中患者特异性数字孪生建立了原则性基础，从而能够实现生物学上一致的肿瘤动力学估计。

Abstract: Accurate prediction of tumor trajectories under standard-of-care (SoC)
therapies remains a major unmet need in oncology. This capability is essential
for optimizing treatment planning and anticipating disease progression.
Conventional reaction-diffusion models are limited in scope, as they fail to
capture tumor dynamics under heterogeneous therapeutic paradigms. There is
hence a critical need for computational frameworks that can realistically
simulate SoC interventions while accounting for inter-patient variability in
genomics, demographics, and treatment regimens. We introduce Standard-of-Care
Digital Twin (SoC-DT), a differentiable framework that unifies
reaction-diffusion tumor growth models, discrete SoC interventions (surgery,
chemotherapy, radiotherapy) along with genomic and demographic personalization
to predict post-treatment tumor structure on imaging. An implicit-explicit
exponential time-differencing solver, IMEX-SoC, is also proposed, which ensures
stability, positivity, and scalability in SoC treatment situations. Evaluated
on both synthetic data and real world glioma data, SoC-DT consistently
outperforms classical PDE baselines and purely data-driven neural models in
predicting tumor dynamics. By bridging mechanistic interpretability with modern
differentiable solvers, SoC-DT establishes a principled foundation for
patient-specific digital twins in oncology, enabling biologically consistent
tumor dynamics estimation. Code will be made available upon acceptance.

</details>


### [48] [Visualizing Celebrity Dynamics in Video Content: A Proposed Approach Using Face Recognition Timestamp Data](https://arxiv.org/abs/2510.03292)
*Doğanay Demir,İlknur Durgar Elkahlout*

Main category: cs.CV

TL;DR: 本文提出了一个混合框架，结合了分布式多GPU推理系统和交互式可视化平台，用于分析视频片段中的名人动态。


<details>
  <summary>Details</summary>
Motivation: 在视频内容占主导地位的时代，理解其结构和动态变得越来越重要。

Method: 该推理框架通过利用优化的ONNX模型、异构批处理推理和高吞吐量并行性来高效处理大量视频数据，确保可扩展地生成带时间戳的外观记录。然后，这些记录被转换成一个全面的可视化套件，包括外观频率图、持续时间分析、饼图、共同外观矩阵、网络图、堆积面积图、季节性比较和热图。

Result: 这些可视化提供了对视频内容的多维洞察，揭示了名人在剧集和季度中的突出程度、屏幕时间分布、时间动态、共同出现关系和强度模式。

Conclusion: 通过将分布式识别与结构化的、视觉驱动的分析联系起来，这项工作为娱乐分析、内容创作策略和观众参与度研究提供了新的可能性。

Abstract: In an era dominated by video content, understanding its structure and
dynamics has become increasingly important. This paper presents a hybrid
framework that combines a distributed multi-GPU inference system with an
interactive visualization platform for analyzing celebrity dynamics in video
episodes. The inference framework efficiently processes large volumes of video
data by leveraging optimized ONNX models, heterogeneous batch inference, and
high-throughput parallelism, ensuring scalable generation of timestamped
appearance records. These records are then transformed into a comprehensive
suite of visualizations, including appearance frequency charts, duration
analyses, pie charts, co-appearance matrices, network graphs, stacked area
charts, seasonal comparisons, and heatmaps. Together, these visualizations
provide multi-dimensional insights into video content, revealing patterns in
celebrity prominence, screen-time distribution, temporal dynamics,
co-appearance relationships, and intensity across episodes and seasons. The
interactive nature of the system allows users to dynamically explore data,
identify key moments, and uncover evolving relationships between individuals.
By bridging distributed recognition with structured, visually-driven analytics,
this work enables new possibilities for entertainment analytics, content
creation strategies, and audience engagement studies.

</details>


### [49] [Domain-Robust Marine Plastic Detection Using Vision Models](https://arxiv.org/abs/2510.03294)
*Saanvi Kataria*

Main category: cs.CV

TL;DR: 该研究评估了水下塑料垃圾检测的跨域鲁棒性模型。


<details>
  <summary>Details</summary>
Motivation: 水下塑料污染是一个紧迫的环境威胁，需要可靠的自动化水下垃圾检测技术。但视觉系统在一个数据集上训练后，在新图像上的性能会因域偏移而下降。

Method: 在标记的水下数据集上训练卷积神经网络（CNN）和视觉Transformer，并在一个平衡的跨域测试集上评估它们。同时评估了两个零样本模型：CLIP ViT-L14 和 Google 的 Gemini 2.0 Flash。

Result: MobileNetV2 提供了最强的跨域性能（F1 0.97），超过了更大的模型。所有微调的模型都实现了高精度（约 99%），但在召回率上有所不同。零样本 CLIP 具有相对较高的召回率（约 80%），但容易出现假阳性（精度约 56%），而 Gemini 则表现出相反的特征（精度约 99%，召回率约 81%）。

Conclusion: 紧凑型 CNN 配合监督训练可以有效地推广用于跨域水下检测，而大型预训练的视觉-语言模型则提供互补优势。

Abstract: Marine plastic pollution is a pressing environmental threat, making reliable
automation for underwater debris detection essential. However, vision systems
trained on one dataset often degrade on new imagery due to domain shift. This
study benchmarks models for cross-domain robustness, training convolutional
neural networks - CNNs (MobileNetV2, ResNet-18, EfficientNet-B0) and vision
transformers (DeiT-Tiny, ViT-B16) on a labeled underwater dataset and then
evaluates them on a balanced cross-domain test set built from plastic-positive
images drawn from a different source and negatives from the training domain.
Two zero-shot models were assessed, CLIP ViT-L14 and Google's Gemini 2.0 Flash,
that leverage pretraining to classify images without fine-tuning. Results show
the lightweight MobileNetV2 delivers the strongest cross-domain performance (F1
0.97), surpassing larger models. All fine-tuned models achieved high Precision
(around 99%), but differ in Recall, indicating varying sensitivity to plastic
instances. Zero-shot CLIP is comparatively sensitive (Recall around 80%) yet
prone to false positives (Precision around 56%), whereas Gemini exhibits the
inverse profile (Precision around 99%, Recall around 81%). Error analysis
highlights recurring confusions with coral textures, suspended particulates,
and specular glare. Overall, compact CNNs with supervised training can
generalize effectively for cross-domain underwater detection, while large
pretrained vision-language models provide complementary strengths.

</details>


### [50] [Multimodal Arabic Captioning with Interpretable Visual Concept Integration](https://arxiv.org/abs/2510.03295)
*Passant Elchafei,Amany Fashwan*

Main category: cs.CV

TL;DR: VLCAP是一个阿拉伯图像字幕框架，它结合了基于CLIP的视觉标签检索和多模态文本生成。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在解决生成具有文化连贯性和上下文准确性的阿拉伯语图像字幕的问题。

Method: 该方法包括：1) 使用三种多语言编码器（mCLIP、AraCLIP 和 Jina V4）提取可解释的阿拉伯语视觉概念；2) 构建混合词汇表，并用从 Visual Genome 数据集翻译的通用领域标签进行丰富；3) 将检索到的标签转换为流畅的阿拉伯语提示，并与原始图像一起传递给视觉-语言模型；4) 使用 Qwen-VL 和 Gemini Pro Vision 进行字幕生成。

Result: mCLIP + Gemini Pro Vision 实现了最佳 BLEU-1 (5.34%) 和余弦相似度 (60.01%)，而 AraCLIP + Qwen-VL 获得了最高的 LLM-judge 评分 (36.33%)。

Conclusion: VLCAP 框架能够生成具有文化连贯性和上下文准确性的阿拉伯语字幕。

Abstract: We present VLCAP, an Arabic image captioning framework that integrates
CLIP-based visual label retrieval with multimodal text generation. Rather than
relying solely on end-to-end captioning, VLCAP grounds generation in
interpretable Arabic visual concepts extracted with three multilingual
encoders, mCLIP, AraCLIP, and Jina V4, each evaluated separately for label
retrieval. A hybrid vocabulary is built from training captions and enriched
with about 21K general domain labels translated from the Visual Genome dataset,
covering objects, attributes, and scenes. The top-k retrieved labels are
transformed into fluent Arabic prompts and passed along with the original image
to vision-language models. In the second stage, we tested Qwen-VL and Gemini
Pro Vision for caption generation, resulting in six encoder-decoder
configurations. The results show that mCLIP + Gemini Pro Vision achieved the
best BLEU-1 (5.34%) and cosine similarity (60.01%), while AraCLIP + Qwen-VL
obtained the highest LLM-judge score (36.33%). This interpretable pipeline
enables culturally coherent and contextually accurate Arabic captions.

</details>


### [51] [Convolutional Neural Nets vs Vision Transformers: A SpaceNet Case Study with Balanced vs Imbalanced Regimes](https://arxiv.org/abs/2510.03297)
*Akshar Gothi*

Main category: cs.CV

TL;DR: 本文对比了卷积神经网络 (EfficientNet-B0) 和 Vision Transformer (ViT-Base) 在 SpaceNet 数据集上的性能，使用了不平衡和平衡两种标签分布。


<details>
  <summary>Details</summary>
Motivation: 研究不同标签分布下，卷积神经网络和 Vision Transformer 的性能差异。

Method: 在相同的预处理、数据增强和训练预算下，比较 EfficientNet-B0 和 ViT-Base 在 SpaceNet 数据集上的性能。

Result: 在不平衡数据集上，EfficientNet-B0 在测试准确率、macro-F1 和延迟方面表现更好；在平衡数据集上，两者性能接近，但 CNN 仍然保持效率优势。

Conclusion: 平衡数据集可以缩小架构差距，但 CNN 在效率方面仍然具有优势。

Abstract: We present a controlled comparison of a convolutional neural network
(EfficientNet-B0) and a Vision Transformer (ViT-Base) on SpaceNet under two
label-distribution regimes: a naturally imbalanced five-class split and a
balanced-resampled split with 700 images per class (70:20:10 train/val/test).
With matched preprocessing (224x224, ImageNet normalization), lightweight
augmentations, and a 40-epoch budget on a single NVIDIA P100, we report
accuracy, macro-F1, balanced accuracy, per-class recall, and deployment metrics
(model size and latency). On the imbalanced split, EfficientNet-B0 reaches 93%
test accuracy with strong macro-F1 and lower latency; ViT-Base is competitive
at 93% with a larger parameter count and runtime. On the balanced split, both
models are strong; EfficientNet-B0 reaches 99% while ViT-Base remains
competitive, indicating that balancing narrows architecture gaps while CNNs
retain an efficiency edge. We release manifests, logs, and per-image
predictions to support reproducibility.

</details>


### [52] [A Comprehensive Review on Artificial Intelligence Empowered Solutions for Enhancing Pedestrian and Cyclist Safety](https://arxiv.org/abs/2510.03314)
*Shucheng Zhang,Yan Shi,Bingzhang Wang,Yuang Zhang,Muhammad Monjurul Karim,Kehua Chen,Chenxi Liu,Mehrdad Nasri,Yinhai Wang*

Main category: cs.CV

TL;DR: 本文综述了基于视觉的AI在弱势道路使用者（VRU）安全方面的应用，重点关注过去五年的进展和新兴研究趋势。


<details>
  <summary>Details</summary>
Motivation: 传统的基于基础设施的措施在动态城市环境中通常不足以保护弱势道路使用者（VRU），因此需要利用人工智能（AI）的新机会来实现主动和情境感知的VRU保护。

Method: 本文系统地考察了四个核心任务：检测和分类、跟踪和重识别、轨迹预测以及意图识别和预测。

Result: 本文重点介绍了数据、模型和部署角度的四个主要开放挑战。

Conclusion: 本文旨在为开发下一代传感系统以提高VRU安全性提供基础参考。

Abstract: Ensuring the safety of vulnerable road users (VRUs), such as pedestrians and
cyclists, remains a critical global challenge, as conventional
infrastructure-based measures often prove inadequate in dynamic urban
environments. Recent advances in artificial intelligence (AI), particularly in
visual perception and reasoning, open new opportunities for proactive and
context-aware VRU protection. However, existing surveys on AI applications for
VRUs predominantly focus on detection, offering limited coverage of other
vision-based tasks that are essential for comprehensive VRU understanding and
protection. This paper presents a state-of-the-art review of recent progress in
camera-based AI sensing systems for VRU safety, with an emphasis on
developments from the past five years and emerging research trends. We
systematically examine four core tasks, namely detection and classification,
tracking and reidentification, trajectory prediction, and intent recognition
and prediction, which together form the backbone of AI-empowered proactive
solutions for VRU protection in intelligent transportation systems. To guide
future research, we highlight four major open challenges from the perspectives
of data, model, and deployment. By linking advances in visual AI with practical
considerations for real-world implementation, this survey aims to provide a
foundational reference for the development of next-generation sensing systems
to enhance VRU safety.

</details>


### [53] [The View From Space: Navigating Instrumentation Differences with EOFMs](https://arxiv.org/abs/2510.03316)
*Ryan P. Demilt,Nicholas LaHaye,Karis Tenneson*

Main category: cs.CV

TL;DR: 地球观测基础模型（EOFMs）已成为处理遥感和其他地球观测数据的重要工具。本文研究了不同传感器架构对EOFMs内部表征的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的EOFMs大多只在单一数据模态上训练，并且通过匹配不同模态的波段来进行应用或基准测试。目前尚不清楚不同的传感器架构对EOFMs的内部表征有什么影响。

Method: 通过实验分析不同传感器架构对EOFMs表征空间的影响。

Result: EOFMs的表征空间对传感器架构非常敏感。

Conclusion: 理解这种差异对于认识当前EOFMs设计的缺陷以及指导模型开发者、用户和遥感科学界 आगे发展至关重要。

Abstract: Earth Observation Foundation Models (EOFMs) have exploded in prevalence as
tools for processing the massive volumes of remotely sensed and other earth
observation data, and for delivering impact on the many essential earth
monitoring tasks. An emerging trend posits using the outputs of pre-trained
models as 'embeddings' which summarize high dimensional data to be used for
generic tasks such as similarity search and content-specific queries. However,
most EOFM models are trained only on single modalities of data and then applied
or benchmarked by matching bands across different modalities. It is not clear
from existing work what impact diverse sensor architectures have on the
internal representations of the present suite of EOFMs. We show in this work
that the representation space of EOFMs is highly sensitive to sensor
architecture and that understanding this difference gives a vital perspective
on the pitfalls of current EOFM design and signals for how to move forward as
model developers, users, and a community guided by robust remote-sensing
science.

</details>


### [54] [Photorealistic Inpainting for Perturbation-based Explanations in Ecological Monitoring](https://arxiv.org/abs/2510.03317)
*Günel Aghakishiyeva,Jiayi Zhou,Saagar Arya,James David Poling,Holly R. Houliston,Jamie N. Womble,David W. Johnston,Brinnae Bent*

Main category: cs.CV

TL;DR: 本文提出了一种基于图像修复的、基于扰动的解释技术，该技术能够生成逼真的、掩码定位的编辑，以保留场景上下文，并揭示驱动物种识别和特征归因等任务预测的细粒度形态线索。


<details>
  <summary>Details</summary>
Motivation: 生态监测越来越多地通过视觉模型实现自动化，但模糊的预测限制了信任和现场应用。

Method: 该方法使用图像修复引导的、基于扰动的解释技术，并使用 Segment-Anything-Model 改进的掩码来支持两种干预：（i）对象移除/替换，以及（ii）背景替换。

Result: 通过重新评估扰动图像（翻转率、置信度下降）和专家审查生态合理性和可解释性来评估解释。结果解释可以定位诊断结构，避免传统扰动常见的删除伪影，并产生与领域相关的见解，从而支持专家验证和更值得信赖的 AI 在生态学中的部署。

Conclusion: 该研究提出了一种新的解释技术，可以提高生态学中人工智能部署的可信度。

Abstract: Ecological monitoring is increasingly automated by vision models, yet opaque
predictions limit trust and field adoption. We present an inpainting-guided,
perturbation-based explanation technique that produces photorealistic,
mask-localized edits that preserve scene context. Unlike masking or blurring,
these edits stay in-distribution and reveal which fine-grained morphological
cues drive predictions in tasks such as species recognition and trait
attribution. We demonstrate the approach on a YOLOv9 detector fine-tuned for
harbor seal detection in Glacier Bay drone imagery, using
Segment-Anything-Model-refined masks to support two interventions: (i) object
removal/replacement (e.g., replacing seals with plausible ice/water or boats)
and (ii) background replacement with original animals composited onto new
scenes. Explanations are assessed by re-scoring perturbed images (flip rate,
confidence drop) and by expert review for ecological plausibility and
interpretability. The resulting explanations localize diagnostic structures,
avoid deletion artifacts common to traditional perturbations, and yield
domain-relevant insights that support expert validation and more trustworthy
deployment of AI in ecology.

</details>


### [55] [Advances in Medical Image Segmentation: A Comprehensive Survey with a Focus on Lumbar Spine Applications](https://arxiv.org/abs/2510.03318)
*Ahmed Kabil,Ghada Khoriba,Mina Yousef,Essam A. Rashed*

Main category: cs.CV

TL;DR: 本研究全面回顾了医学图像分割（MIS）的方法，包括传统图像处理和现代深度学习技术。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在精确诊断、治疗计划和监测中起着关键作用。

Method: 调查涵盖了阈值分割、边缘检测、区域分割、聚类算法、模型方法以及深度学习架构（如CNN、FCN、U-Net及其变体）。

Result: 重点介绍了新兴趋势，包括混合架构、跨模态学习、联邦和分布式学习框架以及主动学习策略。

Conclusion: 尽管该领域取得了显著进展，但仍然存在关键挑战，包括数据集偏差、领域适应、深度学习模型的可解释性以及集成到实际临床工作流程中。

Abstract: Medical Image Segmentation (MIS) stands as a cornerstone in medical image
analysis, playing a pivotal role in precise diagnostics, treatment planning,
and monitoring of various medical conditions. This paper presents a
comprehensive and systematic survey of MIS methodologies, bridging the gap
between traditional image processing techniques and modern deep learning
approaches. The survey encompasses thresholding, edge detection, region-based
segmentation, clustering algorithms, and model-based techniques while also
delving into state-of-the-art deep learning architectures such as Convolutional
Neural Networks (CNNs), Fully Convolutional Networks (FCNs), and the widely
adopted U-Net and its variants. Moreover, integrating attention mechanisms,
semi-supervised learning, generative adversarial networks (GANs), and
Transformer-based models is thoroughly explored. In addition to covering
established methods, this survey highlights emerging trends, including hybrid
architectures, cross-modality learning, federated and distributed learning
frameworks, and active learning strategies, which aim to address challenges
such as limited labeled datasets, computational complexity, and model
generalizability across diverse imaging modalities. Furthermore, a specialized
case study on lumbar spine segmentation is presented, offering insights into
the challenges and advancements in this relatively underexplored anatomical
region. Despite significant progress in the field, critical challenges persist,
including dataset bias, domain adaptation, interpretability of deep learning
models, and integration into real-world clinical workflows.

</details>


### [56] [DECOR: Deep Embedding Clustering with Orientation Robustness](https://arxiv.org/abs/2510.03328)
*Fiona Victoria Stanley Jothiraj,Arunaggiri Pandian Karunanidhi,Seth A. Eichmeyer*

Main category: cs.CV

TL;DR: 提出了一种名为DECOR的深度聚类框架，用于在晶圆制造中对晶圆缺陷进行分组，即使在数据复杂、未标记和不平衡的情况下也能保持可靠性。


<details>
  <summary>Details</summary>
Motivation: 在半导体制造中，晶圆缺陷的早期检测对于优化产品产量至关重要。然而，来自晶圆质量测试的原始晶圆数据通常是复杂的、未标记的、不平衡的，并且可能在单个晶圆上包含多个缺陷，这使得设计在这种不完善的数据条件下保持可靠性的聚类方法至关重要。

Method: DECOR是一种具有方向鲁棒性的深度聚类框架，它可以将晶圆图中的复杂缺陷模式分组为一致的聚类。DECOR 显式地考虑了晶圆图中的方向变化，确保空间上相似的缺陷无论其旋转或对齐方式如何，都能被一致地聚类。

Result: 在开源的 MixedWM38 数据集上评估了该方法，证明了其在没有手动调整的情况下发现聚类的能力。实验表明，该方法优于现有的聚类基线方法。

Conclusion: DECOR为自动化视觉检测系统提供了一种可靠且可扩展的解决方案。

Abstract: In semiconductor manufacturing, early detection of wafer defects is critical
for product yield optimization. However, raw wafer data from wafer quality
tests are often complex, unlabeled, imbalanced and can contain multiple defects
on a single wafer, making it crucial to design clustering methods that remain
reliable under such imperfect data conditions. We introduce DECOR, a deep
clustering with orientation robustness framework that groups complex defect
patterns from wafer maps into consistent clusters. We evaluate our method on
the open source MixedWM38 dataset, demonstrating its ability to discover
clusters without manual tuning. DECOR explicitly accounts for orientation
variations in wafer maps, ensuring that spatially similar defects are
consistently clustered regardless of its rotation or alignment. Experiments
indicate that our method outperforms existing clustering baseline methods, thus
providing a reliable and scalable solution in automated visual inspection
systems.

</details>


### [57] [Automating construction safety inspections using a multi-modal vision-language RAG framework](https://arxiv.org/abs/2510.04145)
*Chenxin Wang,Elyas Asadi Shamsabadi,Zhaohui Chen,Luming Shen,Alireza Ahmadian Fard Fini,Daniel Dias-da-Costa*

Main category: cs.CV

TL;DR: 本文介绍了一种名为 SiteShield 的多模态 LVLM-RAG 框架，用于自动化建筑安全检查报告。


<details>
  <summary>Details</summary>
Motivation: 现有方法效率低下，大型视觉语言模型 (LVLM) 的应用受到限制，缺乏实时适应性。

Method: 使用多模态 LVLM-RAG 框架 SiteShield，集成视觉和音频输入。

Result: SiteShield 的 F1 值为 0.82，hamming 损失为 0.04，精确率为 0.76，召回率为 0.96，优于没有 RAG 的单模态 LLM。

Conclusion: SiteShield 提供了一种新的途径来提高安全报告生成的信息检索和效率。

Abstract: Conventional construction safety inspection methods are often inefficient as
they require navigating through large volume of information. Recent advances in
large vision-language models (LVLMs) provide opportunities to automate safety
inspections through enhanced visual and linguistic understanding. However,
existing applications face limitations including irrelevant or unspecific
responses, restricted modal inputs and hallucinations. Utilisation of Large
Language Models (LLMs) for this purpose is constrained by availability of
training data and frequently lack real-time adaptability. This study introduces
SiteShield, a multi-modal LVLM-based Retrieval-Augmented Generation (RAG)
framework for automating construction safety inspection reports by integrating
visual and audio inputs. Using real-world data, SiteShield outperformed
unimodal LLMs without RAG with an F1 score of 0.82, hamming loss of 0.04,
precision of 0.76, and recall of 0.96. The findings indicate that SiteShield
offers a novel pathway to enhance information retrieval and efficiency in
generating safety reports.

</details>


### [58] [Error correction in multiclass image classification of facial emotion on unbalanced samples](https://arxiv.org/abs/2510.03337)
*Andrey A. Lebedev,Victor B. Kazantsev,Sergey V. Stasenko*

Main category: cs.CV

TL;DR: 本文研究了不平衡样本上人脸图像多类分类中的误差校正问题。


<details>
  <summary>Details</summary>
Motivation: 研究基于包含不同年龄段的人的七种不同情绪状态标记的图像的数据框架的分析，特别关注类不平衡问题，其中一些情绪明显优于其他情绪。

Method: 为了解决分类问题，使用了基于LSTM的神经网络模型，该模型具有注意力机制，专注于人脸的关键区域，这些区域对于情绪识别具有信息性。作为实验的一部分，该模型在六个类的子集的所有可能配置上进行训练，随后对在训练阶段排除的第七类进行误差校正。

Result: 结果表明，所有类都可以进行校正，尽管成功程度不同：一些类可以更好地恢复，而另一些类则较差。此外，在测试样本中，当校正某些类时，记录到小类的关键质量指标有所提高，这表明所提出的方法在解决与搜索罕见事件相关的应用问题（例如，在反欺诈系统中）中具有前景。

Conclusion: 因此，所提出的方法可以有效地应用于面部表情分析系统以及需要在倾斜类分布下进行稳定分类的任务中。

Abstract: This paper considers the problem of error correction in multi-class
classification of face images on unbalanced samples. The study is based on the
analysis of a data frame containing images labeled by seven different emotional
states of people of different ages. Particular attention is paid to the problem
of class imbalance, in which some emotions significantly prevail over others.
To solve the classification problem, a neural network model based on LSTM with
an attention mechanism focusing on key areas of the face that are informative
for emotion recognition is used. As part of the experiments, the model is
trained on all possible configurations of subsets of six classes with
subsequent error correction for the seventh class, excluded at the training
stage. The results show that correction is possible for all classes, although
the degree of success varies: some classes are better restored, others are
worse. In addition, on the test sample, when correcting some classes, an
increase in key quality metrics for small classes was recorded, which indicates
the promise of the proposed approach in solving applied problems related to the
search for rare events, for example, in anti-fraud systems. Thus, the proposed
method can be effectively applied in facial expression analysis systems and in
tasks requiring stable classification under skewed class distribution.

</details>


### [59] [OpusAnimation: Code-Based Dynamic Chart Generation](https://arxiv.org/abs/2510.03341)
*Bozheng Li,Miao Yang,Zhenhan Chen,Jiawang Cao,Mushui Liu,Yi Lu,Yongliang Wu,Bin Zhang,Yangguang Ji,Licheng Tang,Jay Wu,Wenbo Zhu*

Main category: cs.CV

TL;DR: 本文介绍了首个评估多模态大型语言模型（MLLM）在动态图表生成任务能力的基准DCG-Bench，并构建了高质量数据集DCG-8K。提出了一个两阶段训练方案，使用联合代码-视觉奖励进行群体相对策略优化，构建了一个专家MLLM Qwen2.5-VL-DCG-3B。实验结果表明，现有MLLM在视觉到图表任务中存在不足，而本文模型优于最佳开源MLLM，并与参数量更大的闭源模型性能相当。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型在静态图表的生成和理解方面取得了显著进展，但它们在处理动态图表的生成和理解方面的潜力尚未得到充分探索。

Method: 1. 构建了首个评估MLLM在动态图表生成任务能力的基准DCG-Bench。
2. 构建了一个高质量的动态图表生成数据集DCG-8K，包含指令-代码-视频三元组和代码及视频评估的QA对。
3. 提出了一个两阶段训练方案，使用联合代码-视觉奖励进行群体相对策略优化，构建专家MLLM Qwen2.5-VL-DCG-3B。

Result: 本文模型在三个任务上平均性能提升了8.31%，并且仅使用30亿参数就达到了与专有模型相当的性能。

Conclusion: 本文证明了所提出的训练方案的有效性，并揭示了现有MLLM在视觉到图表任务中的不足。

Abstract: Dynamic Chart Generation (DCG) involves producing code-rendered animated
visualizations as charts. While recent advances in multi-modal large language
models (MLLMs) have significantly improved their capability on static chart
generation and comprehension, MLLMs' potential for handling dynamic chart
generation and understanding remains underexplored. To bridge this research
gap, we introduce DCG-Bench (Dynamic Chart Generation Benchmark), the first
benchmark evaluating MLLM's capability on dynamic chart generation tasks from
three dimensions: Simple Text-to-Chart, Detailed Text-to-Chart, and
Video-to-Chart tasks. We construct DCG-8K, a high-quality DCG dataset with
annotations covering instruction-code-video triplets and QA pairs for both code
and video evaluation. Based on DCG-8K, we explored a two-stage training recipe,
proposing Joint-Code-Visual Reward for group relative policy optimization to
construct expert MLLM Qwen2.5-VL-DCG-3B for the DCG task. Our benchmarking
result reveals shortcomings of existing MLLMs in the visual-to-chart task, and
our model beats the best open-sourced MLLM with an average 8.31% performance
gain across three tasks, and shows on par performance against proprietary
models with only 3B parameters, proving the effectiveness of our training
recipe. Our code and dataset will be publicly available.

</details>


### [60] [Visual Odometry with Transformers](https://arxiv.org/abs/2510.03348)
*Vlardimir Yugay,Duy-Kien Nguyen,Theo Gevers,Cees G. M. Snoek,Martin R. Oswald*

Main category: cs.CV

TL;DR: 提出了一种名为VoT的端到端单目视觉里程计方法，该方法使用Transformer直接预测相机运动，无需手工组件或3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖相机标定和超参数调整，难以泛化到真实场景，且难以处理长视频和提供精确的逐帧估计。

Method: 使用Visual odometry Transformer (VoT) 处理单目帧序列，通过时空注意力提取特征并建模全局关系，直接预测相机运动。

Result: VoT在更大规模数据集上表现良好，受益于更强大的预训练骨干网络，可泛化到不同的相机运动和标定设置，优于传统方法且速度快3倍以上。

Conclusion: 证明了单目视觉里程计可以通过端到端的方式有效解决，无需手工组件。

Abstract: Modern monocular visual odometry methods typically combine pre-trained deep
learning components with optimization modules, resulting in complex pipelines
that rely heavily on camera calibration and hyperparameter tuning, and often
struggle in unseen real-world scenarios. Recent large-scale 3D models trained
on massive amounts of multi-modal data have partially alleviated these
challenges, providing generalizable dense reconstruction and camera pose
estimation. Still, they remain limited in handling long videos and providing
accurate per-frame estimates, which are required for visual odometry. In this
work, we demonstrate that monocular visual odometry can be addressed
effectively in an end-to-end manner, thereby eliminating the need for
handcrafted components such as bundle adjustment, feature matching, camera
calibration, or dense 3D reconstruction. We introduce VoT, short for Visual
odometry Transformer, which processes sequences of monocular frames by
extracting features and modeling global relationships through temporal and
spatial attention. Unlike prior methods, VoT directly predicts camera motion
without estimating dense geometry and relies solely on camera poses for
supervision. The framework is modular and flexible, allowing seamless
integration of various pre-trained encoders as feature extractors. Experimental
results demonstrate that VoT scales effectively with larger datasets, benefits
substantially from stronger pre-trained backbones, generalizes across diverse
camera motions and calibration settings, and outperforms traditional methods
while running more than 3 times faster. The code will be released.

</details>


### [61] [Inference-Time Search using Side Information for Diffusion-based Image Reconstruction](https://arxiv.org/abs/2510.03352)
*Mahdi Farahbakhsh,Vishnu Teja Kunde,Dileep Kalathil,Krishna Narayanan,Jean-Francois Chamberland*

Main category: cs.CV

TL;DR: 提出了一种新的推理时搜索算法，该算法利用辅助信息来指导采样过程，以平衡探索和利用，从而实现更准确和可靠的重建。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常忽略了可能显著提高重建质量的辅助信息，尤其是在严重不适定的设置中。

Method: 提出一种新的推理时搜索算法，该算法使用辅助信息来指导采样过程。

Result: 在大量逆问题（如盒状修复、超分辨率和各种去模糊任务，包括运动、高斯、非线性去模糊和盲去模糊）的实验中，该方法持续提高了基于扩散的图像重建算法的定性和定量性能。

Conclusion: 该方法优于其他基线，包括基于奖励梯度的引导算法。

Abstract: Diffusion models have emerged as powerful priors for solving inverse
problems. However, existing approaches typically overlook side information that
could significantly improve reconstruction quality, especially in severely
ill-posed settings. In this work, we propose a novel inference-time search
algorithm that guides the sampling process using the side information in a
manner that balances exploration and exploitation. This enables more accurate
and reliable reconstructions, providing an alternative to the gradient-based
guidance that is prone to reward-hacking artifacts. Our approach can be
seamlessly integrated into a wide range of existing diffusion-based image
reconstruction pipelines. Through extensive experiments on a number of inverse
problems, such as box inpainting, super-resolution, and various deblurring
tasks including motion, Gaussian, nonlinear, and blind deblurring, we show that
our approach consistently improves the qualitative and quantitative performance
of diffusion-based image reconstruction algorithms. We also show the superior
performance of our approach with respect to other baselines, including reward
gradient-based guidance algorithms. The code is available at
\href{https://github.com/mhdfb/sideinfo-search-reconstruction}{this
repository}.

</details>


### [62] [Sonar Image Datasets: A Comprehensive Survey of Resources, Challenges, and Applications](https://arxiv.org/abs/2510.03353)
*Larissa S. Gomes,Gustavo P. Almeida,Bryan U. Moreira,Marco Quiroz,Breno Xavier,Lucas Soares,Stephanie L. Brião,Felipe G. Oliveira,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: 本文全面回顾了声呐图像数据集的现状，旨在为水声数据分析领域的研究人员提供指导。


<details>
  <summary>Details</summary>
Motivation: 水下探索、自主导航和生态系统监测依赖于声呐图像，但缺乏公开的、良好注释的数据集阻碍了机器学习模型的发展。

Method: 本文对各种声呐模式（包括侧扫声呐、前视声呐、合成孔径声呐、多波束回声探测器和双频识别声呐）的公开数据集进行了映射，并对分类、检测、分割和 3D 重建等应用进行了分析。

Result: 本文重点介绍了最新的进展，并整合了新发布的数据集。研究结果被综合成一个主表和一个时间轴，清晰地比较了数据集的特征、大小和注释细节。

Conclusion: 本文旨在通过提供声呐图像数据集的全面和简洁的回顾，为水声数据分析领域的研究人员提供指导。

Abstract: Sonar images are relevant for advancing underwater exploration, autonomous
navigation, and ecosystem monitoring. However, the progress depends on data
availability. The scarcity of publicly available, well-annotated sonar image
datasets creates a significant bottleneck for the development of robust machine
learning models. This paper presents a comprehensive and concise review of the
current landscape of sonar image datasets, seeking not only to catalog existing
resources but also to contextualize them, identify gaps, and provide a clear
roadmap, serving as a base guide for researchers of any kind who wish to start
or advance in the field of underwater acoustic data analysis. We mapped
publicly accessible datasets across various sonar modalities, including Side
Scan Sonar (SSS), Forward-Looking Sonar (FLS), Synthetic Aperture Sonar (SAS),
Multibeam Echo Sounder (MBES), and Dual-Frequency Identification Sonar
(DIDSON). An analysis was conducted on applications such as classification,
detection, segmentation, and 3D reconstruction. This work focuses on
state-of-the-art advancements, incorporating newly released datasets. The
findings are synthesized into a master table and a chronological timeline,
offering a clear and accessible comparison of characteristics, sizes, and
annotation details datasets.

</details>


### [63] [Learned Display Radiance Fields with Lensless Cameras](https://arxiv.org/abs/2510.03356)
*Ziyang Chen,Yuta Itoh,Kaan Akşit*

Main category: cs.CV

TL;DR: 本文提出了一种新的显示器校准方法，该方法使用无透镜相机和基于隐式神经表示的算法，可以在不需要专业设备和暗室的情况下，从不同视角捕捉显示器特性。


<details>
  <summary>Details</summary>
Motivation: 传统显示器校准需要专业设备和暗室，这使得大多数用户难以进行。本文旨在解决这个问题。

Method: 本文共同设计了一个无透镜相机和一个基于隐式神经表示的算法，用于从不同视角捕捉显示器特性。该管线能够有效地重建从显示器发出的、视角锥为46.6{\deg} X 37.6{\deg}的光场。

Result: 该管线能够有效地重建从显示器发出的、视角锥为46.6{\deg} X 37.6{\deg}的光场。

Conclusion: 本文提出的管线为轻松的显示器校准和表征奠定了初步基础。

Abstract: Calibrating displays is a basic and regular task that content creators must
perform to maintain optimal visual experience, yet it remains a troublesome
issue. Measuring display characteristics from different viewpoints often
requires specialized equipment and a dark room, making it inaccessible to most
users. To avoid specialized hardware requirements in display calibrations, our
work co-designs a lensless camera and an Implicit Neural Representation based
algorithm for capturing display characteristics from various viewpoints. More
specifically, our pipeline enables efficient reconstruction of light fields
emitted from a display from a viewing cone of 46.6{\deg} X 37.6{\deg}. Our
emerging pipeline paves the initial steps towards effortless display
calibration and characterization.

</details>


### [64] [Provenance Networks: End-to-End Exemplar-Based Explainability](https://arxiv.org/abs/2510.03361)
*Ali Kayyam,Anusha Madan Gopal,M. Anthony Lewis*

Main category: cs.CV

TL;DR: 提出了一种新的神经模型，称为来源网络，旨在提供端到端、由训练数据驱动的可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统方法缺乏模型透明度，来源网络通过将每个预测直接与其支持的训练示例联系起来，嵌入可解释性到架构中，从而解决模型不透明、幻觉和数据贡献者信用分配等问题。

Method: 该模型类似于学习的KNN，其中每个输出都由特征空间中相关性加权的具体的例子来证明。

Result: 来源网络可以系统地研究记忆和泛化之间的权衡，验证给定的输入是否包含在训练集中，帮助检测错误标记或异常数据点，增强对输入扰动的弹性，并支持识别有助于生成新数据点的类似输入。

Conclusion: 来源网络提供了一种与现有可解释性技术互补的方法，通过提高神经模型的透明度、鲁棒性和可信度来解决现代深度学习中的关键挑战。

Abstract: We introduce provenance networks, a novel class of neural models designed to
provide end-to-end, training-data-driven explainability. Unlike conventional
post-hoc methods, provenance networks learn to link each prediction directly to
its supporting training examples as part of the model's normal operation,
embedding interpretability into the architecture itself. Conceptually, the
model operates similarly to a learned KNN, where each output is justified by
concrete exemplars weighted by relevance in the feature space. This approach
facilitates systematic investigations of the trade-off between memorization and
generalization, enables verification of whether a given input was included in
the training set, aids in the detection of mislabeled or anomalous data points,
enhances resilience to input perturbations, and supports the identification of
similar inputs contributing to the generation of a new data point. By jointly
optimizing the primary task and the explainability objective, provenance
networks offer insights into model behavior that traditional deep networks
cannot provide. While the model introduces additional computational cost and
currently scales to moderately sized datasets, it provides a complementary
approach to existing explainability techniques. In particular, it addresses
critical challenges in modern deep learning, including model opaqueness,
hallucination, and the assignment of credit to data contributors, thereby
improving transparency, robustness, and trustworthiness in neural models.

</details>


### [65] [Unified Unsupervised Anomaly Detection via Matching Cost Filtering](https://arxiv.org/abs/2510.03363)
*Zhe Zhang,Mingxiu Cai,Gaochang Wu,Jing Zhang,Lingqiao Liu,Dacheng Tao,Tianyou Chai,Xiatian Zhu*

Main category: cs.CV

TL;DR: 提出了一种名为统一成本过滤（UCF）的通用后处理框架，用于细化任何UAD模型的异常成本量，从而减轻匹配噪声并突出细微异常。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督异常检测方法忽略了匹配噪声，并且单模和多模方法之间缺乏统一的理解和知识转移。

Method: 通过匹配测试样本和来自相同或不同模态的正常样本来构建成本量，然后使用一个可学习的过滤模块，该模块具有来自测试样本的多层注意力引导，以减轻匹配噪声。

Result: 在22个不同的基准测试中进行的综合实验表明，UCF在增强各种UAD方法方面的有效性，在单模（RGB）和多模（RGB-3D，RGB-Text）UAD场景中均始终获得新的最先进的结果。

Conclusion: UCF是一种有效的通用框架，可以提高各种无监督异常检测方法的性能，并在单模和多模场景中都取得了最先进的结果。

Abstract: Unsupervised anomaly detection (UAD) aims to identify image- and pixel-level
anomalies using only normal training data, with wide applications such as
industrial inspection and medical analysis, where anomalies are scarce due to
privacy concerns and cold-start constraints. Existing methods, whether
reconstruction-based (restoring normal counterparts) or embedding-based
(pretrained representations), fundamentally conduct image- or feature-level
matching to generate anomaly maps. Nonetheless, matching noise has been largely
overlooked, limiting their detection ability. Beyond earlier focus on unimodal
RGB-based UAD, recent advances expand to multimodal scenarios, e.g., RGB--3D
and RGB--Text, enabled by point cloud sensing and vision--language models.
Despite shared challenges, these lines remain largely isolated, hindering a
comprehensive understanding and knowledge transfer. In this paper, we advocate
unified UAD for both unimodal and multimodal settings in the matching
perspective. Under this insight, we present Unified Cost Filtering (UCF), a
generic post-hoc refinement framework for refining anomaly cost volume of any
UAD model. The cost volume is constructed by matching a test sample against
normal samples from the same or different modalities, followed by a learnable
filtering module with multi-layer attention guidance from the test sample,
mitigating matching noise and highlighting subtle anomalies. Comprehensive
experiments on 22 diverse benchmarks demonstrate the efficacy of UCF in
enhancing a variety of UAD methods, consistently achieving new state-of-the-art
results in both unimodal (RGB) and multimodal (RGB--3D, RGB--Text) UAD
scenarios. Code and models will be released at
https://github.com/ZHE-SAPI/CostFilter-AD.

</details>


### [66] [Visual Language Model as a Judge for Object Detection in Industrial Diagrams](https://arxiv.org/abs/2510.03376)
*Sanjukta Ghosh*

Main category: cs.CV

TL;DR: 本文提出了一种利用视觉语言模型（VLM）评估对象检测结果并指导改进的框架，以解决工业图中对象检测质量自动评估的问题。


<details>
  <summary>Details</summary>
Motivation: 将工业图转换为数字形式对于构建数字孪生和实现智能工业自动化至关重要，而对象检测是数字化过程中的一个核心挑战。目前缺乏自动评估对象检测结果质量的方法。

Method: 采用视觉语言模型（VLM）来评估对象检测结果，识别缺失或不一致的检测。

Result: 该方法能够自动评估质量并提高复杂工业图的整体检测性能。

Conclusion: 该框架通过利用VLM的多模态能力，实现了对象检测结果的自动质量评估和改进。

Abstract: Industrial diagrams such as piping and instrumentation diagrams (P&IDs) are
essential for the design, operation, and maintenance of industrial plants.
Converting these diagrams into digital form is an important step toward
building digital twins and enabling intelligent industrial automation. A
central challenge in this digitalization process is accurate object detection.
Although recent advances have significantly improved object detection
algorithms, there remains a lack of methods to automatically evaluate the
quality of their outputs. This paper addresses this gap by introducing a
framework that employs Visual Language Models (VLMs) to assess object detection
results and guide their refinement. The approach exploits the multimodal
capabilities of VLMs to identify missing or inconsistent detections, thereby
enabling automated quality assessment and improving overall detection
performance on complex industrial diagrams.

</details>


### [67] [Spatial-ViLT: Enhancing Visual Spatial Reasoning through Multi-Task Learning](https://arxiv.org/abs/2510.03441)
*Chashi Mahiul Islam,Oteo Mamo,Samuel Jacob Chacko,Xiuwen Liu,Weikuan Yu*

Main category: cs.CV

TL;DR: SpatialViLT: A VLM enhanced with spatial features (depth, coordinates, edges) for improved 3D scene spatial reasoning.


<details>
  <summary>Details</summary>
Motivation: VLMs struggle with spatial reasoning in 3D scenes and complex object arrangements.

Method: Introduces SpatialViLT, a VLM integrating spatial features via multi-task learning, with SpatialViLT and MaskedSpatialViLT variants, and a SpatialEnsemble combining both.

Result: Achieves state-of-the-art accuracy on the Visual Spatial Reasoning (VSR) dataset, excelling in directional, topological, and proximity relations.

Conclusion: Significantly enhances the spatial intelligence of AI systems, crucial for advanced multimodal understanding and real-world applications.

Abstract: Vision-language models (VLMs) have advanced multimodal reasoning but still
face challenges in spatial reasoning for 3D scenes and complex object
configurations. To address this, we introduce SpatialViLT, an enhanced VLM that
integrates spatial features like depth maps, 3D coordinates, and edge maps
through a multi-task learning framework. This approach enriches multimodal
embeddings with spatial understanding. We propose two variants: SpatialViLT and
MaskedSpatialViLT, focusing on full and masked object regions, respectively.
Additionally, SpatialEnsemble combines both approaches, achieving
state-of-the-art accuracy. Our models excel in spatial reasoning categories
such as directional, topological, and proximity relations, as demonstrated on
the challenging Visual Spatial Reasoning (VSR) dataset. This work represents a
significant step in enhancing the spatial intelligence of AI systems, crucial
for advanced multimodal understanding and real-world applications.

</details>


### [68] [Denoising of Two-Phase Optically Sectioned Structured Illumination Reconstructions Using Encoder-Decoder Networks](https://arxiv.org/abs/2510.03452)
*Allison Davis,Yezhi Shen,Xiaoyu Ji,Fengqing Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种基于深度学习的两相光学切片结构光照（OS-SI）伪影消除方法，通过合成训练数据，解决了缺乏干净的ground-truth数据的问题。


<details>
  <summary>Details</summary>
Motivation: 传统去噪方法难以抑制两相OS-SI中因缩短采集时间而引入的残余伪影。监督训练受限于缺乏干净的光学切片ground-truth数据。

Method: 使用编码器-解码器网络，包括非对称去噪自编码器（DAE）和U-Net，在通过将真实伪影场应用于合成图像而形成的合成训练对上进行训练。

Result: 两种网络都提高了图像清晰度，并且每种网络在不同类型的伪影方面表现出色。

Conclusion: 合成训练能够对OS-SI图像进行监督去噪，并突出了编码器-解码器网络在简化重建工作流程方面的潜力。

Abstract: Structured illumination (SI) enhances image resolution and contrast by
projecting patterned light onto a sample. In two-phase optical-sectioning SI
(OS-SI), reduced acquisition time introduces residual artifacts that
conventional denoising struggles to suppress. Deep learning offers an
alternative to traditional methods; however, supervised training is limited by
the lack of clean, optically sectioned ground-truth data. We investigate
encoder-decoder networks for artifact reduction in two-phase OS-SI, using
synthetic training pairs formed by applying real artifact fields to synthetic
images. An asymmetrical denoising autoencoder (DAE) and a U-Net are trained on
the synthetic data, then evaluated on real OS-SI images. Both networks improve
image clarity, with each excelling against different artifact types. These
results demonstrate that synthetic training enables supervised denoising of
OS-SI images and highlight the potential of encoder-decoder networks to
streamline reconstruction workflows.

</details>


### [69] [PEaRL: Pathway-Enhanced Representation Learning for Gene and Pathway Expression Prediction from Histology](https://arxiv.org/abs/2510.03455)
*Sejuti Majumder,Saarthak Kapse,Moinak Bhattacharya,Xuan Xu,Alisa Yurovsky,Prateek Prasanna*

Main category: cs.CV

TL;DR: PEaRL: A multimodal framework integrating histopathology with spatial transcriptomics using pathway activation scores for improved interpretability and performance in cancer ST datasets.


<details>
  <summary>Details</summary>
Motivation: Existing multimodal approaches rely on a small set of highly variable genes, limiting predictive scope and overlooking coordinated biological programs.

Method: PEaRL represents transcriptomics through pathway activation scores computed with ssGSEA, encoding pathway signals with a transformer, and aligning them with histology features via contrastive learning.

Result: PEaRL outperforms SOTA methods across three cancer ST datasets, yielding higher accuracy for gene- and pathway-level expression prediction.

Conclusion: Grounding transcriptomic representation in pathways produces more biologically faithful and interpretable multimodal models, advancing computational pathology beyond gene-level embeddings.

Abstract: Integrating histopathology with spatial transcriptomics (ST) provides a
powerful opportunity to link tissue morphology with molecular function. Yet
most existing multimodal approaches rely on a small set of highly variable
genes, which limits predictive scope and overlooks the coordinated biological
programs that shape tissue phenotypes. We present PEaRL (Pathway Enhanced
Representation Learning), a multimodal framework that represents
transcriptomics through pathway activation scores computed with ssGSEA. By
encoding biologically coherent pathway signals with a transformer and aligning
them with histology features via contrastive learning, PEaRL reduces
dimensionality, improves interpretability, and strengthens cross-modal
correspondence. Across three cancer ST datasets (breast, skin, and lymph node),
PEaRL consistently outperforms SOTA methods, yielding higher accuracy for both
gene- and pathway-level expression prediction (up to 58.9 percent and 20.4
percent increase in Pearson correlation coefficient compared to SOTA). These
results demonstrate that grounding transcriptomic representation in pathways
produces more biologically faithful and interpretable multimodal models,
advancing computational pathology beyond gene-level embeddings.

</details>


### [70] [DuPLUS: Dual-Prompt Vision-Language Framework for Universal Medical Image Segmentation and Prognosis](https://arxiv.org/abs/2510.03483)
*Numan Saeed,Tausifa Jan Saleem,Fadillah Maani,Muhammad Ridzuan,Hu Wang,Mohammad Yaqub*

Main category: cs.CV

TL;DR: DuPLUS是一个用于多模态医学图像分析的深度学习框架，它通过分层语义提示实现对分析任务的细粒度控制，并在分割和预后预测方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像深度学习模型缺乏通用性和预后能力，而“通用”方法又过于简单，缺乏医学语义理解。

Method: DuPLUS引入了一种新颖的视觉-语言框架，该框架利用分层语义提示和独特的双提示机制，实现文本控制的架构。

Result: DuPLUS在三种成像方式、十个不同的解剖医学数据集上进行了泛化，涵盖了30多个器官和肿瘤类型，并在10个数据集中有8个优于最先进的任务特定和通用模型。在头颈癌数据集上，DuPLUS实现了0.69的一致性指数（CI）。

Conclusion: DuPLUS是一种多功能且临床相关的医学图像分析解决方案，它可以通过高效的参数微调快速适应来自不同中心的新任务和模式。

Abstract: Deep learning for medical imaging is hampered by task-specific models that
lack generalizability and prognostic capabilities, while existing 'universal'
approaches suffer from simplistic conditioning and poor medical semantic
understanding. To address these limitations, we introduce DuPLUS, a deep
learning framework for efficient multi-modal medical image analysis. DuPLUS
introduces a novel vision-language framework that leverages hierarchical
semantic prompts for fine-grained control over the analysis task, a capability
absent in prior universal models. To enable extensibility to other medical
tasks, it includes a hierarchical, text-controlled architecture driven by a
unique dual-prompt mechanism. For segmentation, DuPLUS is able to generalize
across three imaging modalities, ten different anatomically various medical
datasets, encompassing more than 30 organs and tumor types. It outperforms the
state-of-the-art task specific and universal models on 8 out of 10 datasets. We
demonstrate extensibility of its text-controlled architecture by seamless
integration of electronic health record (EHR) data for prognosis prediction,
and on a head and neck cancer dataset, DuPLUS achieved a Concordance Index (CI)
of 0.69. Parameter-efficient fine-tuning enables rapid adaptation to new tasks
and modalities from varying centers, establishing DuPLUS as a versatile and
clinically relevant solution for medical image analysis. The code for this work
is made available at: https://anonymous.4open.science/r/DuPLUS-6C52

</details>


### [71] [Real-Time Threaded Houbara Detection and Segmentation for Wildlife Conservation using Mobile Platforms](https://arxiv.org/abs/2510.03501)
*Lyes Saad Saoud,Loic Lesobre,Enrico Sorato,Irfan Hussain*

Main category: cs.CV

TL;DR: 提出了一种移动优化的双阶段深度学习框架，用于在自然环境中实时进行动物检测和分割，通过并行化YOLOv10检测和MobileSAM分割来提高实时性能。


<details>
  <summary>Details</summary>
Motivation: 在自然环境中实时进行动物检测和分割对于野生动物保护至关重要，但由于计算资源有限和许多物种的隐蔽性外观，这些任务仍然具有挑战性。

Method: 集成了一个线程检测模型（TDM）以并行化YOLOv10-based检测和MobileSAM-based分割。通过线程减少延迟来改进实时性能。YOLOv10处理检测，而MobileSAM执行轻量级分割，两者同时执行以实现高效的资源利用。

Result: 在隐蔽的Houbara Bustard上，该模型实现了mAP50为0.9627，mAP75为0.7731，mAP95为0.7178，MobileSAM mIoU为0.7421。YOLOv10以每帧43.7毫秒的速度运行，确认了实时就绪。

Conclusion: 该研究引入了一个包含40,000张带注释图像的精选Houbara数据集，以支持跨不同条件下的模型训练和评估。代码和数据集已在GitHub上公开提供。

Abstract: Real-time animal detection and segmentation in natural environments are vital
for wildlife conservation, enabling non-invasive monitoring through remote
camera streams. However, these tasks remain challenging due to limited
computational resources and the cryptic appearance of many species. We propose
a mobile-optimized two-stage deep learning framework that integrates a
Threading Detection Model (TDM) to parallelize YOLOv10-based detection and
MobileSAM-based segmentation. Unlike prior YOLO+SAM pipelines, our approach
improves real-time performance by reducing latency through threading. YOLOv10
handles detection while MobileSAM performs lightweight segmentation, both
executed concurrently for efficient resource use. On the cryptic Houbara
Bustard, a conservation-priority species, our model achieves mAP50 of 0.9627,
mAP75 of 0.7731, mAP95 of 0.7178, and a MobileSAM mIoU of 0.7421. YOLOv10
operates at 43.7 ms per frame, confirming real-time readiness. We introduce a
curated Houbara dataset of 40,000 annotated images to support model training
and evaluation across diverse conditions. The code and dataset used in this
study are publicly available on GitHub at
https://github.com/LyesSaadSaoud/mobile-houbara-detseg. For interactive demos
and additional resources, visit
https://lyessaadsaoud.github.io/LyesSaadSaoud-Threaded-YOLO-SAM-Houbara.

</details>


### [72] [Platonic Transformers: A Solid Choice For Equivariance](https://arxiv.org/abs/2510.03511)
*Mohammad Mohaiminul Islam,Rishabh Anand,David R. Wessels,Friso de Kruiff,Thijs P. Kuipers,Rex Ying,Clara I. Sánchez,Sharvaree Vadgama,Georg Bökman,Erik J. Bekkers*

Main category: cs.CV

TL;DR: Platonic Transformer通过定义Platonic solid对称群的参考系来关注，从而实现连续转换和平面对称的等变性，同时保持标准Transformer的架构和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的等变方法通常会牺牲效率和灵活性，而Platonic Transformer旨在解决这个问题。

Method: Platonic Transformer通过定义Platonic solid对称群的参考系来关注，从而诱导出一个原则性的权重共享方案。

Result: 在计算机视觉、3D点云和分子性质预测等多个基准测试中，Platonic Transformer通过利用这些几何约束以零额外成本实现了具有竞争力的性能。

Conclusion: Platonic Transformer在不增加额外成本的情况下，实现了几何约束下的竞争性能。

Abstract: While widespread, Transformers lack inductive biases for geometric symmetries
common in science and computer vision. Existing equivariant methods often
sacrifice the efficiency and flexibility that make Transformers so effective
through complex, computationally intensive designs. We introduce the Platonic
Transformer to resolve this trade-off. By defining attention relative to
reference frames from the Platonic solid symmetry groups, our method induces a
principled weight-sharing scheme. This enables combined equivariance to
continuous translations and Platonic symmetries, while preserving the exact
architecture and computational cost of a standard Transformer. Furthermore, we
show that this attention is formally equivalent to a dynamic group convolution,
which reveals that the model learns adaptive geometric filters and enables a
highly scalable, linear-time convolutional variant. Across diverse benchmarks
in computer vision (CIFAR-10), 3D point clouds (ScanObjectNN), and molecular
property prediction (QM9, OMol25), the Platonic Transformer achieves
competitive performance by leveraging these geometric constraints at no
additional cost.

</details>


### [73] [Domain Generalization for Semantic Segmentation: A Survey](https://arxiv.org/abs/2510.03540)
*Manuel Schwonberg,Hanno Gottschalk*

Main category: cs.CV

TL;DR: 本研究概述了领域泛化语义分割，重点介绍了基于基础模型的领域泛化方法，并比较了各种方法的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在未知领域的泛化是一个重大挑战。领域泛化（DG）旨在跨多个不同的未见目标领域进行泛化。领域泛化与语义分割任务特别相关，语义分割任务用于生物医学或自动驾驶等多个领域。

Method: 对现有方法进行聚类和回顾，并确定了向基于基础模型的领域泛化的范式转变。

Result: 对所有方法进行了广泛的性能比较，突出了基础模型对领域泛化的重大影响。

Conclusion: 本研究旨在推进领域泛化研究，并激发科学家探索新的研究方向。

Abstract: The generalization of deep neural networks to unknown domains is a major
challenge despite their tremendous progress in recent years. For this reason,
the dynamic area of domain generalization (DG) has emerged. In contrast to
unsupervised domain adaptation, there is no access to or knowledge about the
target domains, and DG methods aim to generalize across multiple different
unseen target domains. Domain generalization is particularly relevant for the
task semantic segmentation which is used in several areas such as biomedicine
or automated driving. This survey provides a comprehensive overview of the
rapidly evolving topic of domain generalized semantic segmentation. We cluster
and review existing approaches and identify the paradigm shift towards
foundation-model-based domain generalization. Finally, we provide an extensive
performance comparison of all approaches, which highlights the significant
influence of foundation models on domain generalization. This survey seeks to
advance domain generalization research and inspire scientists to explore new
research directions.

</details>


### [74] [From Scope to Script: An Automated Report Generation Model for Gastrointestinal Endoscopy](https://arxiv.org/abs/2510.03543)
*Evandros Kaklamanos,Kristjana Kristinsdottir,Jonathan Huang,Dustin Carlson,Rajesh Keswani,John Pandolfino,Mozziyar Etemadi*

Main category: cs.CV

TL;DR: 本文提出了一种自动报告生成模型，旨在减轻胃肠科医生在内窥镜检查中的文档负担，提高临床工作效率并减少医生职业倦怠。


<details>
  <summary>Details</summary>
Motivation: 内窥镜检查的文档负担给胃肠科医生带来了巨大的压力，导致临床工作流程效率低下和医生职业倦怠。

Method: 该模型利用基于 Transformer 的视觉编码器和文本解码器，采用两阶段训练框架。第一阶段，在图像/文本标题对上预训练两个组件以捕获广义视觉语言特征，然后在图像/报告对上进行微调以生成临床上有意义的发现。

Result: 该方法简化了文档流程，并有望减少医生工作量和改善患者护理。

Conclusion: 提出的自动报告生成模型可以有效减轻医生的文档负担，提高工作效率，并最终改善患者护理。

Abstract: Endoscopic procedures such as esophagogastroduodenoscopy (EGD) and
colonoscopy play a critical role in diagnosing and managing gastrointestinal
(GI) disorders. However, the documentation burden associated with these
procedures place significant strain on gastroenterologists, contributing to
inefficiencies in clinical workflows and physician burnout. To address this
challenge, we propose a novel automated report generation model that leverages
a transformer-based vision encoder and text decoder within a two-stage training
framework. In the first stage, both components are pre-trained on image/text
caption pairs to capture generalized vision-language features, followed by
fine-tuning on images/report pairs to generate clinically meaningful findings.
Our approach not only streamlines the documentation process but also holds
promise for reducing physician workload and improving patient care.

</details>


### [75] [SketchPlan: Diffusion Based Drone Planning From Human Sketches](https://arxiv.org/abs/2510.03545)
*Sixten Norelius,Aaron O. Feldman,Mac Schwager*

Main category: cs.CV

TL;DR: SketchPlan is a diffusion-based planner that uses 2D hand-drawn sketches over depth images to generate 3D flight paths for drone navigation.


<details>
  <summary>Details</summary>
Motivation: The paper aims to enable intuitive drone navigation using hand-drawn sketches.

Method: The method involves a SketchAdapter that maps sketches to 2D paths, and DiffPath, a diffusion model that infers 3D trajectories from 2D projections and depth images. The model is trained on a synthetic dataset with both auto-labeled and human-labeled data.

Result: SketchPlan achieves zero-shot sim-to-real transfer and generates accurate flight paths. It achieved 100% success in low/medium clutter and 40% in unseen high-clutter environments in real-world drone tests.

Conclusion: The paper concludes that SketchPlan effectively interprets human intent and infers 3D paths, with a modular design and training on mixed data significantly boosting its capabilities.

Abstract: We propose SketchPlan, a diffusion-based planner that interprets 2D
hand-drawn sketches over depth images to generate 3D flight paths for drone
navigation. SketchPlan comprises two components: a SketchAdapter that learns to
map the human sketches to projected 2D paths, and DiffPath, a diffusion model
that infers 3D trajectories from 2D projections and a first person view depth
image. Our model achieves zero-shot sim-to-real transfer, generating accurate
and safe flight paths in previously unseen real-world environments. To train
the model, we build a synthetic dataset of 32k flight paths using a diverse set
of photorealistic 3D Gaussian Splatting scenes. We automatically label the data
by computing 2D projections of the 3D flight paths onto the camera plane, and
use this to train the DiffPath diffusion model. However, since real human 2D
sketches differ significantly from ideal 2D projections, we additionally label
872 of the 3D flight paths with real human sketches and use this to train the
SketchAdapter to infer the 2D projection from the human sketch. We demonstrate
SketchPlan's effectiveness in both simulated and real-world experiments, and
show through ablations that training on a mix of human labeled and auto-labeled
data together with a modular design significantly boosts its capabilities to
correctly interpret human intent and infer 3D paths. In real-world drone tests,
SketchPlan achieved 100\% success in low/medium clutter and 40\% in unseen
high-clutter environments, outperforming key ablations by 20-60\% in task
completion.

</details>


### [76] [Unmasking Puppeteers: Leveraging Biometric Leakage to Disarm Impersonation in AI-based Videoconferencing](https://arxiv.org/abs/2510.03548)
*Danial Samadi Vahdati,Tai Duc Nguyen,Ekta Prashnani,Koki Nagano,David Luebke,Orazio Gallo,Matthew Stamm*

Main category: cs.CV

TL;DR: 提出了一种新的生物特征泄露防御方法，用于检测基于AI的说话头视频会议系统中的身份盗用攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的AI说话头视频会议系统存在被攻击者利用进行实时身份盗用的安全问题，且现有深度伪造检测器失效。

Method: 利用姿态-表情潜在空间包含驱动身份的生物特征信息这一关键观察，提出一种姿态条件、大间隔对比编码器，用于隔离传输的潜在空间中的持久身份线索，同时消除瞬态姿态和表情。

Result: 实验表明，该方法优于现有的傀儡防御方法，能够实时运行，并对分布外场景表现出强大的泛化能力。

Conclusion: 该方法能够有效检测说话头视频会议系统中的身份盗用攻击，且具有实时性和泛化性。

Abstract: AI-based talking-head videoconferencing systems reduce bandwidth by sending a
compact pose-expression latent and re-synthesizing RGB at the receiver, but
this latent can be puppeteered, letting an attacker hijack a victim's likeness
in real time. Because every frame is synthetic, deepfake and synthetic video
detectors fail outright. To address this security problem, we exploit a key
observation: the pose-expression latent inherently contains biometric
information of the driving identity. Therefore, we introduce the first
biometric leakage defense without ever looking at the reconstructed RGB video:
a pose-conditioned, large-margin contrastive encoder that isolates persistent
identity cues inside the transmitted latent while cancelling transient pose and
expression. A simple cosine test on this disentangled embedding flags illicit
identity swaps as the video is rendered. Our experiments on multiple
talking-head generation models show that our method consistently outperforms
existing puppeteering defenses, operates in real-time, and shows strong
generalization to out-of-distribution scenarios.

</details>


### [77] [Streaming Drag-Oriented Interactive Video Manipulation: Drag Anything, Anytime!](https://arxiv.org/abs/2510.03550)
*Junbao Zhou,Yuan Zhou,Kesen Zhao,Qingshan Xu,Beier Zhu,Richang Hong,Hanwang Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的视频编辑任务REVEL，允许用户通过精细的交互式拖动随时修改生成的视频。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归视频扩散模型难以实现流式、细粒度的输出控制，导致生成结果与用户期望不符。

Method: 提出了一种名为DragStream的无训练方法，包含自适应分布自校正策略和空间频率选择性优化机制。

Result: 大量实验证明了DragStream的有效性。

Conclusion: DragStream可以无缝集成到现有的自回归视频扩散模型中。

Abstract: Achieving streaming, fine-grained control over the outputs of autoregressive
video diffusion models remains challenging, making it difficult to ensure that
they consistently align with user expectations. To bridge this gap, we propose
\textbf{stReaming drag-oriEnted interactiVe vidEo manipuLation (REVEL)}, a new
task that enables users to modify generated videos \emph{anytime} on
\emph{anything} via fine-grained, interactive drag. Beyond DragVideo and
SG-I2V, REVEL unifies drag-style video manipulation as editing and animating
video frames with both supporting user-specified translation, deformation, and
rotation effects, making drag operations versatile. In resolving REVEL, we
observe: \emph{i}) drag-induced perturbations accumulate in latent space,
causing severe latent distribution drift that halts the drag process;
\emph{ii}) streaming drag is easily disturbed by context frames, thereby
yielding visually unnatural outcomes. We thus propose a training-free approach,
\textbf{DragStream}, comprising: \emph{i}) an adaptive distribution
self-rectification strategy that leverages neighboring frames' statistics to
effectively constrain the drift of latent embeddings; \emph{ii}) a
spatial-frequency selective optimization mechanism, allowing the model to fully
exploit contextual information while mitigating its interference via
selectively propagating visual cues along generation. Our method can be
seamlessly integrated into existing autoregressive video diffusion models, and
extensive experiments firmly demonstrate the effectiveness of our DragStream.

</details>


### [78] [GAS-MIL: Group-Aggregative Selection Multi-Instance Learning for Ensemble of Foundation Models in Digital Pathology Image Analysis](https://arxiv.org/abs/2510.03555)
*Peiran Quan,Zifan Gu,Zhuo Zhao,Qin Zhou,Donghan M. Yang,Ruichen Rong,Yang Xie,Guanghua Xiao*

Main category: cs.CV

TL;DR: 提出了GAS-MIL，一个灵活的集成框架，可以无缝集成来自多个FMs的特征，无需手动特征选择或进行特定于任务的微调。


<details>
  <summary>Details</summary>
Motivation: 调整和基准测试用于特定诊断任务的单个FMs通常耗时且资源密集，尤其是在考虑到它们的规模和多样性的情况下。

Method: GAS-MIL，一个灵活的集成框架，可以无缝集成来自多个FMs的特征，保留它们的互补优势，而无需手动特征选择或进行特定于任务的微调。

Result: 在三个癌症数据集（前列腺癌（PANDA）、卵巢癌（UBC-OCEAN）和乳腺癌（TCGA-BrCa））的分类任务中，相对于单个FMs和已建立的MIL方法，GAS-MIL始终实现卓越或相当的性能，证明了其稳健性和泛化性。

Conclusion: 通过实现异构FMs的有效集成，GAS-MIL简化了病理学模型部署，并为未来的多模态和精确肿瘤学应用提供了可扩展的基础。

Abstract: Foundation models (FMs) have transformed computational pathology by providing
powerful, general-purpose feature extractors. However, adapting and
benchmarking individual FMs for specific diagnostic tasks is often
time-consuming and resource-intensive, especially given their scale and
diversity. To address this challenge, we introduce Group-Aggregative Selection
Multi-Instance Learning (GAS-MIL), a flexible ensemble framework that
seamlessly integrates features from multiple FMs, preserving their
complementary strengths without requiring manual feature selection or extensive
task-specific fine-tuning. Across classification tasks in three cancer
datasets-prostate (PANDA), ovarian (UBC-OCEAN), and breast (TCGA-BrCa)-GAS-MIL
consistently achieves superior or on-par performance relative to individual FMs
and established MIL methods, demonstrating its robustness and generalizability.
By enabling efficient integration of heterogeneous FMs, GAS-MIL streamlines
model deployment for pathology and provides a scalable foundation for future
multimodal and precision oncology applications.

</details>


### [79] [Real-Time Assessment of Bystander Situation Awareness in Drone-Assisted First Aid](https://arxiv.org/abs/2510.03558)
*Shen Chang,Renran Tian,Nicole Adams,Nan Kong*

Main category: cs.CV

TL;DR: 本文介绍了一种利用无人机快速运送纳洛酮的方案，以应对阿片类药物过量紧急情况，并在急救服务到达之前，为未经医疗培训的旁观者提供救生干预。


<details>
  <summary>Details</summary>
Motivation: 研究旁观者情境意识（SA）在人机协作（HAT）中的关键作用，并解决实时SA评估中的研究空白。

Method: 引入无人机辅助纳洛酮递送模拟数据集（DANDSD），并提出一种基于视频的实时SA评估框架，该框架利用图嵌入和Transformer模型来评估旁观者的SA。

Result: 该方法在SA预测方面表现出高性能，并在时间分割精度方面优于FINCH基线9%（MoF）和5%（IoU）。

Conclusion: 这项工作支持开发能够有效指导旁观者的自适应无人机系统，最终改善紧急响应结果并挽救生命。

Abstract: Rapid naloxone delivery via drones offers a promising solution for responding
to opioid overdose emergencies (OOEs), by extending lifesaving interventions to
medically untrained bystanders before emergency medical services (EMS) arrive.
Recognizing the critical role of bystander situational awareness (SA) in
human-autonomy teaming (HAT), we address a key research gap in real-time SA
assessment by introducing the Drone-Assisted Naloxone Delivery Simulation
Dataset (DANDSD). This pioneering dataset captures HAT during simulated OOEs,
where college students without medical training act as bystanders tasked with
administering intranasal naloxone to a mock overdose victim. Leveraging this
dataset, we propose a video-based real-time SA assessment framework that
utilizes graph embeddings and transformer models to assess bystander SA in real
time. Our approach integrates visual perception and comprehension cues--such as
geometric, kinematic, and interaction graph features--and achieves
high-performance SA prediction. It also demonstrates strong temporal
segmentation accuracy, outperforming the FINCH baseline by 9% in Mean over
Frames (MoF) and 5% in Intersection over Union (IoU). This work supports the
development of adaptive drone systems capable of guiding bystanders
effectively, ultimately improving emergency response outcomes and saving lives.

</details>


### [80] [Evaluating OCR performance on food packaging labels in South Africa](https://arxiv.org/abs/2510.03570)
*Mayimunah Nagayi,Alice Khan,Tamryn Frank,Rina Swart,Clement Nyirenda*

Main category: cs.CV

TL;DR: 该研究评估了四种开源OCR系统（Tesseract、EasyOCR、PaddleOCR和TrOCR）在真实食品包装图像上的性能，旨在评估它们提取成分列表和营养成分表的能力。


<details>
  <summary>Details</summary>
Motivation: 食品包装的准确OCR对于合规性和营养监测非常重要，但由于多语言文本、密集的布局、各种字体、眩光和弯曲的表面而具有挑战性。

Method: 使用包含231种产品（1,628张图像）的数据集处理所有四个模型，以评估速度和覆盖率。创建了113张图像（60种产品）的ground truth子集，用于准确性评估。指标包括字符错误率（CER）、词错误率（WER）、BLEU、ROUGE-L、F1、覆盖率和执行时间。

Result: 在ground truth子集上，Tesseract实现了最低的CER（0.912）和最高的BLEU（0.245）。EasyOCR在准确性和多语言支持之间取得了良好的平衡。PaddleOCR实现了接近完全的覆盖率，但由于GPU不兼容，只能在CPU上运行，因此速度较慢，而TrOCR产生了最差的结果，尽管有GPU加速。

Conclusion: 这些结果提供了一个特定于包装的基准，建立了一个基线，并强调了布局感知方法和文本定位的方向。

Abstract: This study evaluates four open-source Optical Character Recognition (OCR)
systems which are Tesseract, EasyOCR, PaddleOCR, and TrOCR on real world food
packaging images. The aim is to assess their ability to extract ingredient
lists and nutrition facts panels. Accurate OCR for packaging is important for
compliance and nutrition monitoring but is challenging due to multilingual
text, dense layouts, varied fonts, glare, and curved surfaces. A dataset of 231
products (1,628 images) was processed by all four models to assess speed and
coverage, and a ground truth subset of 113 images (60 products) was created for
accuracy evaluation. Metrics include Character Error Rate (CER), Word Error
Rate (WER), BLEU, ROUGE-L, F1, coverage, and execution time. On the ground
truth subset, Tesseract achieved the lowest CER (0.912) and the highest BLEU
(0.245). EasyOCR provided a good balance between accuracy and multilingual
support. PaddleOCR achieved near complete coverage but was slower because it
ran on CPU only due to GPU incompatibility, and TrOCR produced the weakest
results despite GPU acceleration. These results provide a packaging-specific
benchmark, establish a baseline, and highlight directions for layout-aware
methods and text localization.

</details>


### [81] [FrameOracle: Learning What to See and How Much to See in Videos](https://arxiv.org/abs/2510.03584)
*Chaoyu Li,Tianzhi Li,Fei Tao,Zhenyu Zhao,Ziqian Wu,Maozheng Zhao,Juntong Song,Cheng Niu,Pooyan Fazli*

Main category: cs.CV

TL;DR: 提出 FrameOracle，一个轻量级的即插即用模块，用于预测哪些帧与给定查询最相关以及需要多少帧。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解的视觉语言模型 (VLM) 性能受到它们可以处理的输入帧数量的限制。现有的帧采样策略通常无法适应信息密度或任务复杂度的变化，从而导致效率低下和信息丢失。

Method: FrameOracle 使用四阶段课程进行训练，前三个阶段依赖于弱代理信号，例如跨模态相似性。在最后阶段，它利用来自 FrameOracle-41K 的更强的监督，这是一个新的数据集，提供关键帧注释，指定回答每个问题所需的最小帧集。

Result: 在五个 VLM 和六个基准测试中进行的大量实验表明，FrameOracle 将 16 帧输入减少到平均 10.4 帧，而精度没有任何损失。当从 64 帧候选开始时，它将输入减少到平均 13.9 帧，同时将精度提高了 1.4%，从而实现了可扩展视频理解的最先进的效率-精度权衡。

Conclusion: FrameOracle 实现了可扩展视频理解的最先进的效率-精度权衡。

Abstract: Vision-language models (VLMs) have advanced video understanding, but their
performance is limited by the number of input frames they can process. Existing
frame sampling strategies, such as uniform or fixed-budget selection, often
fail to adapt to variations in information density or task complexity,
resulting in inefficiency and information loss. To address this, we present
FrameOracle, a lightweight and plug-and-play module that predicts both (1)
which frames are most relevant to a given query and (2) how many frames are
needed. FrameOracle is trained using a four-stage curriculum, with the first
three stages relying on weak proxy signals such as cross-modal similarity. In
the final stage, it leverages stronger supervision from a new dataset we
introduce, FrameOracle-41K, the first large-scale VideoQA collection to provide
keyframe annotations specifying the minimal set of frames required to answer
each question. Extensive experiments across five VLMs and six benchmarks
demonstrate that FrameOracle reduces 16-frame inputs to an average of 10.4
frames without any loss in accuracy. When starting from 64-frame candidates, it
reduces the input to an average of 13.9 frames while improving accuracy by
1.4%, achieving state-of-the-art efficiency-accuracy trade-offs for scalable
video understanding.

</details>


### [82] [A Hybrid Co-Finetuning Approach for Visual Bug Detection in Video Games](https://arxiv.org/abs/2510.03591)
*Faliu Yi,Sherif Abdelfattah,Wei Huang,Adrian Brown*

Main category: cs.CV

TL;DR: 提出了一种混合协同微调 (CFT) 方法，用于检测视频游戏中的视觉错误，该方法集成了标记和未标记的数据，以减少对大量标记数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 人工识别视频游戏中的视觉错误成本高昂，且需要专业的领域知识。监督的视觉错误检测模型依赖于大量标记数据集，但此类错误的发生频率较低，这带来了巨大的挑战。

Method: 该方法利用来自目标游戏和各种协同域游戏的标记样本，并结合未标记数据来增强特征表示学习。

Result: 该框架展示了增强的可扩展性和适应性，有助于在各种游戏标题中进行有效的视觉错误检测。实验结果表明，该方法对游戏视觉错误检测具有鲁棒性，与传统基线相比，在多个游戏环境中表现出优越的性能。即使仅使用目标游戏中 50% 的标记数据进行训练，CFT 也能保持具有竞争力的性能。

Conclusion: 该混合协同微调 (CFT) 方法能够有效利用标记和未标记数据，从而大大减少对特定目标游戏标记示例的依赖，并且在游戏视觉错误检测中表现出强大的性能。

Abstract: Manual identification of visual bugs in video games is a resource-intensive
and costly process, often demanding specialized domain knowledge. While
supervised visual bug detection models offer a promising solution, their
reliance on extensive labeled datasets presents a significant challenge due to
the infrequent occurrence of such bugs. To overcome this limitation, we propose
a hybrid Co-FineTuning (CFT) method that effectively integrates both labeled
and unlabeled data. Our approach leverages labeled samples from the target game
and diverse co-domain games, additionally incorporating unlabeled data to
enhance feature representation learning. This strategy maximizes the utility of
all available data, substantially reducing the dependency on labeled examples
from the specific target game. The developed framework demonstrates enhanced
scalability and adaptability, facilitating efficient visual bug detection
across various game titles. Our experimental results show the robustness of the
proposed method for game visual bug detection, exhibiting superior performance
compared to conventional baselines across multiple gaming environments.
Furthermore, CFT maintains competitive performance even when trained with only
50% of the labeled data from the target game.

</details>


### [83] [Exploring the Hierarchical Reasoning Model for Small Natural-Image Classification Without Augmentation](https://arxiv.org/abs/2510.03598)
*Alexander V. Mantzaris*

Main category: cs.CV

TL;DR: 本文研究了分层推理模型（HRM）作为图像分类器的实用性，发现其在MNIST上表现良好，但在CIFAR-10和CIFAR-100等小型自然图像数据集上泛化能力较差。


<details>
  <summary>Details</summary>
Motivation: 研究HRM在图像分类任务中的有效性，特别是在没有数据增强的情况下。

Method: 在MNIST、CIFAR-10和CIFAR-100数据集上评估HRM的性能，并与简单的卷积神经网络进行比较。

Result: HRM在MNIST上表现良好，但在CIFAR-10和CIFAR-100上表现不佳，表明其泛化能力不足。

Conclusion: 在没有数据增强的情况下，HRM在小型图像分类任务中不如简单的卷积架构，但未来的改进可能会提高其性能。

Abstract: This paper asks whether the Hierarchical Reasoning Model (HRM) with the two
Transformer-style modules $(f_L,f_H)$, one step (DEQ-style) training, deep
supervision, Rotary Position Embeddings, and RMSNorm can serve as a practical
image classifier. It is evaluated on MNIST, CIFAR-10, and CIFAR-100 under a
deliberately raw regime: no data augmentation, identical optimizer family with
one-epoch warmup then cosine-floor decay, and label smoothing. HRM optimizes
stably and performs well on MNIST ($\approx 98\%$ test accuracy), but on small
natural images it overfits and generalizes poorly: on CIFAR-10, HRM reaches
65.0\% after 25 epochs, whereas a two-stage Conv--BN--ReLU baseline attains
77.2\% while training $\sim 30\times$ faster per epoch; on CIFAR-100, HRM
achieves only 29.7\% test accuracy despite 91.5\% train accuracy, while the
same CNN reaches 45.3\% test with 50.5\% train accuracy. Loss traces and error
analyses indicate healthy optimization but insufficient image-specific
inductive bias for HRM in this regime. It is concluded that, for
small-resolution image classification without augmentation, HRM is not
competitive with even simple convolutional architectures as the HRM currently
exist but this does not exclude possibilities that modifications to the model
may allow it to improve greatly.

</details>


### [84] [Unsupervised Transformer Pre-Training for Images: Self-Distillation, Mean Teachers, and Random Crops](https://arxiv.org/abs/2510.03606)
*Mattia Scardecchia*

Main category: cs.CV

TL;DR: DINOv2 achieves state-of-the-art performance in self-supervised learning, surpassing weakly supervised methods.


<details>
  <summary>Details</summary>
Motivation: Examine the core ideas behind DINOv2's approach, multi-crop view augmentation and self-distillation with a mean teacher, and trace their development in previous work.

Method: Compare the performance of DINO and DINOv2 with other SSL and WSL methods across various downstream tasks.

Result: Highlight some remarkable emergent properties of their learned features with transformer backbones.

Conclusion: Briefly discuss DINOv2's limitations, its impact, and future research directions.

Abstract: Recent advances in self-supervised learning (SSL) have made it possible to
learn general-purpose visual features that capture both the high-level
semantics and the fine-grained spatial structure of images. Most notably, the
recent DINOv2 has established a new state of the art by surpassing weakly
supervised methods (WSL) like OpenCLIP on most benchmarks. In this survey, we
examine the core ideas behind its approach, multi-crop view augmentation and
self-distillation with a mean teacher, and trace their development in previous
work. We then compare the performance of DINO and DINOv2 with other SSL and WSL
methods across various downstream tasks, and highlight some remarkable emergent
properties of their learned features with transformer backbones. We conclude by
briefly discussing DINOv2's limitations, its impact, and future research
directions.

</details>


### [85] [Diffusion-Classifier Synergy: Reward-Aligned Learning via Mutual Boosting Loop for FSCIL](https://arxiv.org/abs/2510.03608)
*Ruitao Wu,Yifan Zhao,Guangyao Chen,Jia Li*

Main category: cs.CV

TL;DR: 提出了一个新框架，通过扩散模型和FSCIL分类器之间的相互提升循环来解决Few-Shot Class-Incremental Learning (FSCIL) 问题。


<details>
  <summary>Details</summary>
Motivation: 现有的FSCIL方法由于依赖有限的数据集，泛化能力较差。直接应用扩散模型可能导致语义错位或无效指导。

Method: 引入了Diffusion-Classifier Synergy (DCS)，一个新框架，它在扩散模型和FSCIL分类器之间建立了一个相互促进的循环。DCS利用奖励对齐的学习策略，其中从分类器的状态导出的动态、多方面的奖励函数指导扩散模型。

Result: 在FSCIL基准测试中，DCS 显著提高了知识保留和新类学习，实现了最先进的性能。

Conclusion: 通过生成的图像优化分类器，改进的分类器状态产生更好的奖励信号，这种协同进化过程，经验证可以实现FSCIL的最先进的性能。

Abstract: Few-Shot Class-Incremental Learning (FSCIL) challenges models to sequentially
learn new classes from minimal examples without forgetting prior knowledge, a
task complicated by the stability-plasticity dilemma and data scarcity. Current
FSCIL methods often struggle with generalization due to their reliance on
limited datasets. While diffusion models offer a path for data augmentation,
their direct application can lead to semantic misalignment or ineffective
guidance. This paper introduces Diffusion-Classifier Synergy (DCS), a novel
framework that establishes a mutual boosting loop between diffusion model and
FSCIL classifier. DCS utilizes a reward-aligned learning strategy, where a
dynamic, multi-faceted reward function derived from the classifier's state
directs the diffusion model. This reward system operates at two levels: the
feature level ensures semantic coherence and diversity using prototype-anchored
maximum mean discrepancy and dimension-wise variance matching, while the logits
level promotes exploratory image generation and enhances inter-class
discriminability through confidence recalibration and cross-session
confusion-aware mechanisms. This co-evolutionary process, where generated
images refine the classifier and an improved classifier state yields better
reward signals, demonstrably achieves state-of-the-art performance on FSCIL
benchmarks, significantly enhancing both knowledge retention and new class
learning.

</details>


### [86] [MonitorVLM:A Vision Language Framework for Safety Violation Detection in Mining Operations](https://arxiv.org/abs/2510.03666)
*Jiang Wu,Sichao Wu,Yinsong Ma,Guangyuan Yu,Haoyuan Xu,Lifang Zheng,Jingliang Duan*

Main category: cs.CV

TL;DR: 论文提出了一种名为MonitorVLM的视觉-语言框架，用于从监控视频中检测安全违规行为，特别是在矿业等高风险领域。


<details>
  <summary>Details</summary>
Motivation: 传统的人工检查劳动强度大，容易出错，并且不足以应对大规模动态环境，因此迫切需要智能和自动化的安全监控。

Method: 该方法引入了三个关键创新：一个领域特定的违规数据集，一个动态选择最相关条款的子句过滤器（CF）模块，以及一个增强工人区域以改进细粒度动作识别的行为放大器（BM）模块。

Result: 实验结果表明，MonitorVLM显著优于基线视觉-语言模型，在精确率、召回率和F1得分方面均有提高。

Conclusion: 该研究强调了多模态大型模型在加强矿业及其他行业的职业安全监控方面的潜力。

Abstract: Industrial accidents, particularly in high-risk domains such as surface and
underground mining, are frequently caused by unsafe worker behaviors.
Traditional manual inspection remains labor-intensive, error-prone, and
insufficient for large-scale, dynamic environments, highlighting the urgent
need for intelligent and automated safety monitoring. In this paper, we present
MonitorVLM, a novel vision--language framework designed to detect safety
violations directly from surveillance video streams. MonitorVLM introduces
three key innovations: (1) a domain-specific violation dataset comprising 9,000
vision--question--answer (VQA) samples across 40 high-frequency mining
regulations, enriched with augmentation and auxiliary detection cues; (2) a
clause filter (CF) module that dynamically selects the Top-$K$ most relevant
clauses, reducing inference latency by 13.56\% while maintaining accuracy; and
(3) a behavior magnifier (BM) module that enhances worker regions to improve
fine-grained action recognition, yielding additional gains of 3.45% in
precision and 8.62% in recall. Experimental results demonstrate that MonitorVLM
significantly outperforms baseline vision--language models, achieving
improvements of 22.01% in precision, 34.22\% in recall, and 28.37% in F1 score
over the 72B unfine-tuned baseline. A lightweight web-based interface further
integrates MonitorVLM into practical workflows, enabling automatic violation
reporting with video timestamping. This study highlights the potential of
multimodal large models to enhance occupational safety monitoring in mining and
beyond.

</details>


### [87] [A Novel Cloud-Based Diffusion-Guided Hybrid Model for High-Accuracy Accident Detection in Intelligent Transportation Systems](https://arxiv.org/abs/2510.03675)
*Siva Sai,Saksham Gupta,Vinay Chamola,Rajkumar Buyya*

Main category: cs.CV

TL;DR: 本文提出了一种新的混合模型，将引导分类与扩散技术相结合，用于智能交通系统中的事故检测。


<details>
  <summary>Details</summary>
Motivation: 传统分类方法在理解复杂数据分布方面存在不足，而扩散模型具有有效理解复杂数据分布的内在能力。

Method: 该模型利用微调的ExceptionNet架构输出作为输入，并处理图像张量作为条件，创建了一个鲁棒的分类框架。该模型由多个条件模块组成，旨在利用时间嵌入和图像协变量嵌入来调节输入的线性投影，从而使网络能够在整个扩散过程中动态地调整其行为。

Result: 所提出的扩散模型在基于图像的事故检测中表现最佳，准确率达到97.32%。

Conclusion: 该研究表明，扩散模型在智能交通系统中的事故检测方面具有显著的改进。

Abstract: The integration of Diffusion Models into Intelligent Transportation Systems
(ITS) is a substantial improvement in the detection of accidents. We present a
novel hybrid model integrating guidance classification with diffusion
techniques. By leveraging fine-tuned ExceptionNet architecture outputs as input
for our proposed diffusion model and processing image tensors as our
conditioning, our approach creates a robust classification framework. Our model
consists of multiple conditional modules, which aim to modulate the linear
projection of inputs using time embeddings and image covariate embeddings,
allowing the network to adapt its behavior dynamically throughout the diffusion
process. To address the computationally intensive nature of diffusion models,
our implementation is cloud-based, enabling scalable and efficient processing.
Our strategy overcomes the shortcomings of conventional classification
approaches by leveraging diffusion models inherent capacity to effectively
understand complicated data distributions. We investigate important diffusion
characteristics, such as timestep schedulers, timestep encoding techniques,
timestep count, and architectural design changes, using a thorough ablation
study, and have conducted a comprehensive evaluation of the proposed model
against the baseline models on a publicly available dataset. The proposed
diffusion model performs best in image-based accident detection with an
accuracy of 97.32%.

</details>


### [88] [SAMSOD: Rethinking SAM Optimization for RGB-T Salient Object Detection](https://arxiv.org/abs/2510.03689)
*Zhengyi Liu,Xinrui Wang,Xianyong Fang,Zhengzheng Tu,Linbo Wang*

Main category: cs.CV

TL;DR: 提出了一种名为SAMSOD的模型，用于RGB-T显著目标检测，通过利用单模态监督、梯度解冲突和解耦适配器来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T显著目标检测方法忽略了两种模态的不平衡收敛以及高低激活之间的显著梯度差异，导致性能提升空间受限。

Method: 该模型利用单模态监督来增强非主导模态的学习，采用梯度解冲突来减少冲突梯度对模型收敛的影响，并利用两个解耦适配器分别屏蔽高低激活神经元，通过增强背景学习来强调前景对象。

Result: 在RGB-T SOD基准数据集和泛化性实验中，证明了所提出方法的有效性。

Conclusion: 该方法在RGB-T显著目标检测任务中表现出色，并在其他相关任务中具有良好的泛化能力。

Abstract: RGB-T salient object detection (SOD) aims to segment attractive objects by
combining RGB and thermal infrared images. To enhance performance, the Segment
Anything Model has been fine-tuned for this task. However, the imbalance
convergence of two modalities and significant gradient difference between high-
and low- activations are ignored, thereby leaving room for further performance
enhancement. In this paper, we propose a model called \textit{SAMSOD}, which
utilizes unimodal supervision to enhance the learning of non-dominant modality
and employs gradient deconfliction to reduce the impact of conflicting
gradients on model convergence. The method also leverages two decoupled
adapters to separately mask high- and low-activation neurons, emphasizing
foreground objects by enhancing background learning. Fundamental experiments on
RGB-T SOD benchmark datasets and generalizability experiments on scribble
supervised RGB-T SOD, fully supervised RGB-D SOD datasets and full-supervised
RGB-D rail surface defect detection all demonstrate the effectiveness of our
proposed method.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [WAREX: Web Agent Reliability Evaluation on Existing Benchmarks](https://arxiv.org/abs/2510.03285)
*Su Kara,Fazle Faisal,Suman Nath*

Main category: cs.AI

TL;DR: 本文介绍了一个名为WAREX的工具，用于评估Web代理在真实网络环境中的可靠性，发现现有代理在不稳定和存在安全风险的真实网站环境中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有Web代理基准测试未考虑真实网络环境的不稳定性及安全风险，无法准确评估代理的可靠性。

Method: 通过在WebArena、WebVoyager和REAL三个基准测试中引入WAREX来评估代理的性能。

Result: 引入WAREX后，任务成功率显著下降，表明现有代理的鲁棒性有限。

Conclusion: 现有Web代理在真实网络环境中表现不佳，需要进一步提高其鲁棒性。

Abstract: Recent advances in browser-based LLM agents have shown promise for automating
tasks ranging from simple form filling to hotel booking or online shopping.
Current benchmarks measure agent performance in controlled environments, such
as containers or stable networks, where websites behave deterministically.
However, in the real world, users access websites over networks and HTTPS
connections that introduce instability from multiple sources: client-side,
server-side issues or broader system failures. Moreover, live websites are
prone to web attacks such Cross-Site Scripting, as well as general site
modifications which can cause unexpected or malicious pop-ups or improper
functionality. To address this gap, we present WAREX: Web Agent Reliability
Evaluation on Existing Benchmarks. We measure the impact of WAREX across three
popular benchmarks: WebArena, WebVoyager, and REAL. Our experiments show that
introducing WAREX leads to significant drops in task success rates,
highlighting the limited robustness of state-of-the-art agents.

</details>


### [90] [Refined Iterated Pareto Greedy for Energy-aware Hybrid Flowshop Scheduling with Blocking Constraints](https://arxiv.org/abs/2510.03377)
*Ahmed Missaoui,Cemalettin Ozturk,Barry O'Sullivan*

Main category: cs.AI

TL;DR: 研究混合流水车间调度问题，目标是最小化完工时间和总能耗。


<details>
  <summary>Details</summary>
Motivation: 不可再生能源的稀缺、地缘政治问题、价格上涨和气候变化迫使全球经济开发更节能的解决方案。制造业是能源消耗大户，面临降低能耗的挑战。节能调度是一种有吸引力的方法，因为它可以快速部署并立即产生影响。

Method: 将问题建模为多目标混合整数规划 (MIP) 模型，并提出了一种增强的 epsilon 约束方法来寻找帕累托最优解。此外，还开发了一种有效的多目标元启发式算法，即改进的迭代帕累托贪婪 (RIPG)，以在合理的时间内解决大型实例。

Result: 使用小型、中型和大型实例对我们提出的方法进行基准测试，以评估它们的效率。采用了两种众所周知的算法来比较我们的新方法。计算结果表明了我们方法的有效性。

Conclusion: 所提出的方法在解决混合流水车间调度问题上是有效的，可以最小化完工时间和总能耗。

Abstract: The scarcity of non-renewable energy sources, geopolitical problems in its
supply, increasing prices, and the impact of climate change, force the global
economy to develop more energy-efficient solutions for their operations. The
Manufacturing sector is not excluded from this challenge as one of the largest
consumers of energy. Energy-efficient scheduling is a method that attracts
manufacturing companies to reduce their consumption as it can be quickly
deployed and can show impact immediately. In this study, the hybrid flow shop
scheduling problem with blocking constraint (BHFS) is investigated in which we
seek to minimize the latest completion time (i.e. makespan) and overall energy
consumption, a typical manufacturing setting across many industries from
automotive to pharmaceutical. Energy consumption and the latest completion time
of customer orders are usually conflicting objectives. Therefore, we first
formulate the problem as a novel multi-objective mixed integer programming
(MIP) model and propose an augmented epsilon-constraint method for finding the
Pareto-optimal solutions. Also, an effective multi-objective metaheuristic
algorithm. Refined Iterated Pareto Greedy (RIPG), is developed to solve large
instances in reasonable time. Our proposed methods are benchmarked using small,
medium, and large-size instances to evaluate their efficiency. Two well-known
algorithms are adopted for comparing our novel approaches. The computational
results show the effectiveness of our method.

</details>


### [91] [Know Thyself? On the Incapability and Implications of AI Self-Recognition](https://arxiv.org/abs/2510.03399)
*Xiaoyan Bai,Aryan Shrivastava,Ari Holtzman,Chenhao Tan*

Main category: cs.AI

TL;DR: 该论文介绍了一个评估大型语言模型（LLM）自我识别能力的框架，发现现有模型在该方面表现不佳，并存在对GPT和Claude模型的偏见。


<details>
  <summary>Details</summary>
Motivation: 当前对模型是否具备自我识别能力存在争议，因此需要一个系统性的评估框架。

Method: 通过二元自我识别和精确模型预测两个任务，评估10个大型语言模型识别自身生成文本的能力。

Result: 研究发现，大多数模型无法有效识别自身生成的文本，且存在对GPT和Claude模型的强烈偏见。模型对自身和其他模型的存在有一定了解，但其推理显示出层级偏见。

Conclusion: 研究结果对人工智能安全具有重要意义，未来应致力于发展适当的人工智能自我意识。

Abstract: Self-recognition is a crucial metacognitive capability for AI systems,
relevant not only for psychological analysis but also for safety, particularly
in evaluative scenarios. Motivated by contradictory interpretations of whether
models possess self-recognition (Panickssery et al., 2024; Davidson et al.,
2024), we introduce a systematic evaluation framework that can be easily
applied and updated. Specifically, we measure how well 10 contemporary larger
language models (LLMs) can identify their own generated text versus text from
other models through two tasks: binary self-recognition and exact model
prediction. Different from prior claims, our results reveal a consistent
failure in self-recognition. Only 4 out of 10 models predict themselves as
generators, and the performance is rarely above random chance. Additionally,
models exhibit a strong bias toward predicting GPT and Claude families. We also
provide the first evaluation of model awareness of their own and others'
existence, as well as the reasoning behind their choices in self-recognition.
We find that the model demonstrates some knowledge of its own existence and
other models, but their reasoning reveals a hierarchical bias. They appear to
assume that GPT, Claude, and occasionally Gemini are the top-tier models, often
associating high-quality text with them. We conclude by discussing the
implications of our findings on AI safety and future directions to develop
appropriate AI self-awareness.

</details>


### [92] [ContraGen: A Multi-Agent Generation Framework for Enterprise Contradictions Detection](https://arxiv.org/abs/2510.03418)
*Ananya Mantravadi,Shivali Dalmia,Abhishek Mukherji,Nand Dave,Anudha Mittal*

Main category: cs.AI

TL;DR: 这篇论文提出了一个名为ContraGen的框架，用于评估企业环境中检索增强生成（RAG）系统中的矛盾检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有的矛盾检测基准测试主要集中在句子层面，无法捕捉企业文档的复杂性，而企业环境中合规性、治理和责任至关重要，检索到的证据中的矛盾会导致不一致或不可信的输出。

Method: 该框架通过生成包含嵌入矛盾的合成企业风格文档，实现对文档内和跨文档一致性的系统评估。结合自动矛盾挖掘和人工验证，确保高准确性。

Result: 论文生成了逼真的企业文档，对业务流程中常见的矛盾类型进行了分类，实现了对自我矛盾和成对矛盾的受控创建，开发了一个矛盾感知的检索评估管道，并嵌入了人工监督。

Conclusion: 这项工作为企业信息检索应用中更值得信赖和负责任的RAG系统奠定了基础，在这些应用中，检测和解决矛盾对于降低风险和确保合规性至关重要。

Abstract: Retrieval-Augmented Generation (RAG) integrates LLMs with external sources,
offering advanced capabilities for information access and decision-making.
However, contradictions in retrieved evidence can result in inconsistent or
untrustworthy outputs, which is especially problematic in enterprise settings
where compliance, governance, and accountability are critical. Existing
benchmarks for contradiction detection are limited to sentence-level analysis
and do not capture the complexity of enterprise documents such as contracts,
financial filings, compliance reports, or policy manuals. To address this
limitation, we propose ContraGen, a contradiction-aware benchmark framework
tailored to enterprise domain. The framework generates synthetic
enterprise-style documents with embedded contradictions, enabling systematic
evaluation of both intra-document and cross-document consistency. Automated
contradiction mining is combined with human-in-the-loop validation to ensure
high accuracy. Our contributions include generating realistic enterprise
documents, modeling a taxonomy of contradiction types common in business
processes, enabling controlled creation of self- and pairwise contradictions,
developing a contradiction-aware retrieval evaluation pipeline and embedding
human oversight to reflect domain-specific judgment complexity. This work
establishes a foundation for more trustworthy and accountable RAG systems in
enterprise information-seeking applications, where detecting and resolving
contradictions is essential for reducing risk and ensuring compliance.

</details>


### [93] [A Qualitative Comparative Evaluation of Cognitive and Generative Theories](https://arxiv.org/abs/2510.03453)
*Paul S. Rosenbloom*

Main category: cs.AI

TL;DR: 对基于认知架构和生成神经架构的理论进行评估非常困难


<details>
  <summary>Details</summary>
Motivation: 对基于认知架构的理论进行评估是一项具有挑战性的活动。由于重叠的原因，评估对于基于生成神经架构的理论也具有挑战性。

Method: 通过利用对理论评估的广泛视角，对面向全脑的认知和生成架构以及基于这些架构的完整系统进行广泛的比较。

Result: 论文对认知架构和生成架构进行了比较

Conclusion: 论文对全脑认知和生成架构进行了比较

Abstract: Evaluation is a critical activity associated with any theory. Yet this has
proven to be an exceptionally challenging activity for theories based on
cognitive architectures. For an overlapping set of reasons, evaluation can also
be challenging for theories based on generative neural architectures. This dual
challenge is approached here by leveraging a broad perspective on theory
evaluation to yield a wide-ranging, albeit qualitative, comparison of
whole-mind-oriented cognitive and generative architectures and the full systems
that are based on these architectures.

</details>


### [94] [Bridging LLM Planning Agents and Formal Methods: A Case Study in Plan Verification](https://arxiv.org/abs/2510.03469)
*Keshav Ramani,Vali Tawosi,Salwa Alamir,Daniel Borrajo*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的框架，用于评估自然语言计划与其预期行为之间的一致性


<details>
  <summary>Details</summary>
Motivation: 通过将自然语言计划转换为克里普克结构和线性时序逻辑（LTL）并执行模型检查

Method: 使用大型语言模型（LLM）

Result: GPT-5 实现了出色的分类性能（F1 分数为 96.3%），并且几乎总是产生句法上完美的正式表示，可以作为保证

Conclusion: 语义上完美的正式模型的合成仍有待探索

Abstract: We introduce a novel framework for evaluating the alignment between natural
language plans and their expected behavior by converting them into Kripke
structures and Linear Temporal Logic (LTL) using Large Language Models (LLMs)
and performing model checking. We systematically evaluate this framework on a
simplified version of the PlanBench plan verification dataset and report on
metrics like Accuracy, Precision, Recall and F1 scores. Our experiments
demonstrate that GPT-5 achieves excellent classification performance (F1 score
of 96.3%) while almost always producing syntactically perfect formal
representations that can act as guarantees. However, the synthesis of
semantically perfect formal models remains an area for future exploration.

</details>


### [95] [Towards Policy-Compliant Agents: Learning Efficient Guardrails For Policy Violation Detection](https://arxiv.org/abs/2510.03485)
*Xiaofei Wen,Wenjie Jacky Mo,Yanan Xie,Peng Qi,Muhao Chen*

Main category: cs.AI

TL;DR: 本文介绍了PolicyGuardBench，一个用于检测agent轨迹中策略违规的基准，以及PolicyGuard-4B，一个轻量级的guardrail模型。


<details>
  <summary>Details</summary>
Motivation: 现有工作较少关注web agent在生成长程轨迹时是否符合外部或人为设定的策略，以及策略违规是否在不同环境（如领域和子领域）中持续存在。

Method: 本文构建了包含约6万个示例的PolicyGuardBench基准，通过生成各种策略并在子领域内和跨子领域配对，标注违规行为。此外，还提出了基于前缀的违规检测任务。利用该数据集训练了PolicyGuard-4B模型。

Result: PolicyGuard-4B模型在所有任务中都表现出强大的检测精度，同时保持了推理效率，并在跨领域和未见环境中表现出良好的泛化能力。

Conclusion: PolicyGuardBench和PolicyGuard-4B共同构建了一个全面的框架，用于研究web agent轨迹中的策略合规性，并表明在小规模下实现准确且可泛化的guardrail是可行的。

Abstract: Autonomous web agents need to operate under externally imposed or
human-specified policies while generating long-horizon trajectories. However,
little work has examined whether these trajectories comply with such policies,
or whether policy violations persist across different contexts such as domains
(e.g., shopping or coding websites) and subdomains (e.g., product search and
order management in shopping). To address this gap, we introduce
PolicyGuardBench, a benchmark of about 60k examples for detecting policy
violations in agent trajectories. From diverse agent runs, we generate a broad
set of policies and create both within subdomain and cross subdomain pairings
with violation labels. In addition to full-trajectory evaluation,
PolicyGuardBench also includes a prefix-based violation detection task where
models must anticipate policy violations from truncated trajectory prefixes
rather than complete sequences. Using this dataset, we train PolicyGuard-4B, a
lightweight guardrail model that delivers strong detection accuracy across all
tasks while keeping inference efficient. Notably, PolicyGuard-4B generalizes
across domains and preserves high accuracy on unseen settings. Together,
PolicyGuardBench and PolicyGuard-4B provide the first comprehensive framework
for studying policy compliance in web agent trajectories, and show that
accurate and generalizable guardrails are feasible at small scales.

</details>


### [96] [OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit Flows](https://arxiv.org/abs/2510.03506)
*John Nguyen,Marton Havasi,Tariq Berrada,Luke Zettlemoyer,Ricky T. Q. Chen*

Main category: cs.AI

TL;DR: OneFlow is a non-autoregressive multimodal model for concurrent text-image generation.


<details>
  <summary>Details</summary>
Motivation: Existing autoregressive models have rigid causal ordering between text and image generation.

Method: OneFlow combines insertion-based Edit Flow for text with Flow Matching for image latents, enabling hierarchical sampling.

Result: OneFlow outperforms autoregressive baselines on generation and understanding tasks with fewer training FLOPs.

Conclusion: OneFlow surpasses autoregressive and diffusion-based approaches, unlocking new capabilities for concurrent generation, iterative refinement, and reasoning-like generation.

Abstract: We present OneFlow, the first non-autoregressive multimodal model that
enables variable-length and concurrent mixed-modal generation. Unlike
autoregressive models that enforce rigid causal ordering between text and image
generation, OneFlow combines an insertion-based Edit Flow for discrete text
tokens with Flow Matching for image latents. OneFlow enables concurrent
text-image synthesis with hierarchical sampling that prioritizes content over
grammar. Through controlled experiments across model sizes from 1B to 8B, we
demonstrate that OneFlow outperforms autoregressive baselines on both
generation and understanding tasks while using up to 50% fewer training FLOPs.
OneFlow surpasses both autoregressive and diffusion-based approaches while
unlocking new capabilities for concurrent generation, iterative refinement, and
natural reasoning-like generation.

</details>


### [97] [CAG: Chunked Augmented Generation for Google Chrome's Built-in Gemini Nano](https://arxiv.org/abs/2412.18708)
*Vivek Vellaiyappan Surulimuthu,Aditya Karnam Gururaj Rao*

Main category: cs.AI

TL;DR: 提出了分块增强生成（CAG）架构，以克服Chrome内置Gemini Nano模型的上下文窗口限制。


<details>
  <summary>Details</summary>
Motivation: Chrome内置Gemini Nano模型的上下文窗口有限，处理大型输入时面临挑战。

Method: 通过智能输入分块和处理策略，实现高效处理大型内容。

Result: 该实现证明了在Chrome中直接处理大型文档和数据集的有效性。

Conclusion: CAG使得复杂的AI功能可以通过浏览器访问，而无需外部API依赖。

Abstract: We present Chunked Augmented Generation (CAG), an architecture specifically
designed to overcome the context window limitations of Google Chrome's built-in
Gemini Nano model. While Chrome's integration of Gemini Nano represents a
significant advancement in bringing AI capabilities directly to the browser,
its restricted context window poses challenges for processing large inputs. CAG
addresses this limitation through intelligent input chunking and processing
strategies, enabling efficient handling of extensive content while maintaining
the model's performance within browser constraints. Our implementation
demonstrates particular efficacy in processing large documents and datasets
directly within Chrome, making sophisticated AI capabilities accessible through
the browser without external API dependencies. Get started now at
https://github.com/vivekVells/cag-js.

</details>


### [98] [Understanding the Role of Training Data in Test-Time Scaling](https://arxiv.org/abs/2510.03605)
*Adel Javanmard,Baharan Mirzasoleiman,Vahab Mirrokni*

Main category: cs.AI

TL;DR: 测试时扩展通过分配额外的计算来生成更长的思维链 (CoT)，从而提高大型语言模型 (LLM) 的推理能力。这使得模型能够通过将问题分解为额外的步骤、回溯和纠正错误来处理更复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 本文研究了在线性回归的上下文权重预测任务上训练的 transformer 的测试时扩展的性能。我们的分析为几个有趣的观察结果提供了理论解释。

Method: 通过在上下文权重预测任务上训练的 transformer 进行实验和理论分析。

Result: 在任何固定的测试误差下，增加测试时计算允许我们减少训练提示中的上下文示例（上下文长度）的数量。如果解决下游任务所需的技能没有充分存在于训练数据中，增加测试时计算可能会损害性能。对任务难度进行表征，通过其特征协方差矩阵的最小特征值，表明在多样化、相关且困难的任务集上进行训练会导致测试时扩展的最佳性能。

Conclusion: 在多样化、相关且困难的任务集上进行训练会导致测试时扩展的最佳性能。

Abstract: Test-time scaling improves the reasoning capabilities of large language
models (LLMs) by allocating extra compute to generate longer Chains-of-Thoughts
(CoTs). This enables models to tackle more complex problem by breaking them
down into additional steps, backtracking, and correcting mistakes. Despite its
strong performance--demonstrated by OpenAI's o1 and DeepSeek R1, the conditions
in the training data under which long CoTs emerge, and when such long CoTs
improve the performance, remain unclear. In this paper, we study the
performance of test-time scaling for transformers trained on an in-context
weight prediction task for linear regression. Our analysis provides a
theoretical explanation for several intriguing observations: First, at any
fixed test error, increasing test-time compute allows us to reduce the number
of in-context examples (context length) in training prompts. Second, if the
skills required to solve a downstream task are not sufficiently present in the
training data, increasing test-time compute can harm performance. Finally, we
characterize task hardness via the smallest eigenvalue of its feature
covariance matrix and show that training on a diverse, relevant, and hard set
of tasks results in best performance for test-time scaling. We confirm our
findings with experiments on large, nonlinear transformer architectures.

</details>


### [99] [Cross-Modal Content Optimization for Steering Web Agent Preferences](https://arxiv.org/abs/2510.03612)
*Tanqiu Jiang,Min Bai,Nikolaos Pappas,Yanjun Qi,Sandesh Swamy*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的跨模态偏好引导（CPS）方法，通过联合优化视觉和文本通道中的细微修改，以在现实的黑盒攻击场景下更有效地操纵基于视觉语言模型（VLM）的Web代理的选择结果。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM代理在内容推荐或产品排名等选择任务中容易受到攻击，攻击者可以通过对抗性弹出窗口、图像扰动或内容调整来操纵偏好。然而，现有研究通常假设强大的白盒访问权限或不切实际的设置。

Method: 论文提出了CPS方法，该方法联合优化项目的视觉和自然语言描述中的不易察觉的修改，利用CLIP可迁移的图像扰动和RLHF诱导的语言偏差来引导代理决策。该方法在黑盒威胁设置下运行，攻击者只能编辑自己的列表的图像和文本元数据，而无法了解代理的模型内部结构。

Result: 在电影选择和电子商务任务中，CPS在GPT-4.1、Qwen-2.5VL和Pixtral-Large等VLM代理上的评估结果表明，CPS比其他基线方法更有效，同时保持较低的检测率。

Conclusion: 研究结果表明，随着代理系统在社会中扮演越来越重要的角色，迫切需要强大的防御措施。

Abstract: Vision-language model (VLM)-based web agents increasingly power high-stakes
selection tasks like content recommendation or product ranking by combining
multimodal perception with preference reasoning. Recent studies reveal that
these agents are vulnerable against attackers who can bias selection outcomes
through preference manipulations using adversarial pop-ups, image
perturbations, or content tweaks. Existing work, however, either assumes strong
white-box access, with limited single-modal perturbations, or uses impractical
settings. In this paper, we demonstrate, for the first time, that joint
exploitation of visual and textual channels yields significantly more powerful
preference manipulations under realistic attacker capabilities. We introduce
Cross-Modal Preference Steering (CPS) that jointly optimizes imperceptible
modifications to an item's visual and natural language descriptions, exploiting
CLIP-transferable image perturbations and RLHF-induced linguistic biases to
steer agent decisions. In contrast to prior studies that assume gradient
access, or control over webpages, or agent memory, we adopt a realistic
black-box threat setup: a non-privileged adversary can edit only their own
listing's images and textual metadata, with no insight into the agent's model
internals. We evaluate CPS on agents powered by state-of-the-art proprietary
and open source VLMs including GPT-4.1, Qwen-2.5VL and Pixtral-Large on both
movie selection and e-commerce tasks. Our results show that CPS is
significantly more effective than leading baseline methods. For instance, our
results show that CPS consistently outperforms baselines across all models
while maintaining 70% lower detection rates, demonstrating both effectiveness
and stealth. These findings highlight an urgent need for robust defenses as
agentic systems play an increasingly consequential role in society.

</details>


### [100] [MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual Information](https://arxiv.org/abs/2510.03632)
*Jiaxi Li,Yucheng Shi,Jin Lu,Ninghao Liu*

Main category: cs.AI

TL;DR: 本文提出了一种名为互信息树搜索 (MITS) 的新框架，该框架利用信息论原理指导 LLM 的推理，在保持计算效率的同时，实现了卓越的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有树搜索方法难以对中间推理步骤的质量进行即时和可靠的定量评估，并且广泛的路径探索在计算上是昂贵的。

Method: MITS 引入了一个基于逐点互信息 (PMI) 的有效评分函数，该函数能够逐步评估推理路径并通过 beam search 扩展搜索树，而无需昂贵的look-ahead模拟。该框架辅以基于熵的动态抽样策略，该策略自适应地将计算资源分配给探索最有益的不确定推理步骤。对于最终预测，MITS 采用加权投票方案，将 PMI 分数与预测共识相结合。

Result: 在各种推理基准上的综合实验表明，MITS 始终优于基线方法。

Conclusion: MITS 建立了一个有原则且高效的 LLM 推理框架

Abstract: Tree search has become as a representative framework for test-time reasoning
with large language models (LLMs), exemplified by methods such as
Tree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning
paths. However, it remains difficult to provide instant and reliable
quantitative assessments of intermediate reasoning step quality, and extensive
path exploration is computationally costly. To address this, we propose Mutual
Information Tree Search (MITS), a novel framework that guides reasoning with
information-theoretic principles. MITS introduces an effective scoring function
based on pointwise mutual information (PMI), which enables step-wise evaluation
of reasoning paths and search tree expansion via beam search without expensive
look-ahead simulations, achieving superior reasoning performances while
maintaining computational efficiency. The framework is complemented by an
entropy-based dynamic sampling strategy that adaptively allocates computational
resources to uncertain reasoning steps where exploration is most beneficial.
For final prediction, MITS employs a weighted voting scheme that combines PMI
scores with prediction consensus. Through comprehensive experiments on diverse
reasoning benchmarks, MITS consistently surpasses baseline methods,
establishing a principled and efficient framework for LLM reasoning.

</details>


### [101] [Rainbow Padding: Mitigating Early Termination in Instruction-Tuned Diffusion LLMs](https://arxiv.org/abs/2510.03680)
*Bumjun Kim,Dongjae Jeon,Dueun Kim,Wonje Jeung,Albert No*

Main category: cs.AI

TL;DR: instruction-tuned dLLMs have a vulnerability that responses become shorter as sequence length increases. The reason is that the dual role of <eos> as both termination and padding. To address this, Rainbow Padding is introduced.


<details>
  <summary>Details</summary>
Motivation: instruction-tuned dLLMs exhibit a critical vulnerability we term 	texttt{<eos>} overflow: as allocated sequence length increases, responses paradoxically become shorter, collapsing into early termination or degenerating into streams of 	texttt{<eos>} tokens.Although noticed in practice, this issue has not been systematically analyzed.

Method: introduce Rainbow Padding, a simple remedy that replaces repeated 	texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens, distributing probability mass and breaking 	texttt{<eos>} dominance.

Result: Rainbow Padding substantially improves length robustness and output quality, with as few as seven padding tokens sufficient to prevent early termination.

Conclusion: LoRA fine-tuning for a single epoch on minimal data yields significant improvements, making this solution highly practical.

Abstract: Diffusion large language models (dLLMs) have emerged as a promising
alternative to autoregressive models, offering flexible generation orders and
strong performance on complex reasoning tasks. However, instruction-tuned dLLMs
exhibit a critical vulnerability we term \texttt{<eos>} overflow: as allocated
sequence length increases, responses paradoxically become shorter, collapsing
into early termination or degenerating into streams of \texttt{<eos>} tokens.
Although noticed in practice, this issue has not been systematically analyzed.
We trace its root cause to the dual role of \texttt{<eos>} as both termination
and padding, which concentrates probability mass on \texttt{<eos>} at later
positions and propagates backward to trigger early termination. To address
this, we introduce Rainbow Padding, a simple remedy that replaces repeated
\texttt{<eos>} placeholders with a repeating cycle of distinct padding tokens,
distributing probability mass and breaking \texttt{<eos>} dominance.
Experiments show that Rainbow Padding substantially improves length robustness
and output quality, with as few as seven padding tokens sufficient to prevent
early termination. Moreover, the method integrates efficiently into existing
instruction-tuned models: LoRA fine-tuning for a single epoch on minimal data
yields significant improvements, making this solution highly practical. The
code is publicly available at https://github.com/quasar529/rainbow-padding.

</details>


### [102] [Mind the Goal: Data-Efficient Goal-Oriented Evaluation of Conversational Agents and Chatbots using Teacher Models](https://arxiv.org/abs/2510.03696)
*Deepak Babu Piskala,Sharlene Chen,Udita Patel,Parul Kalra,Rafael Castrillo*

Main category: cs.AI

TL;DR: 提出了一个用于评估多轮聊天机器人交互的综合框架，该框架侧重于用户目标的实现情况，而不仅仅是单轮对话的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法主要在turn的层面评估交互，没有解决用户目标是否实现的问题。本文旨在解决多轮对话中以目标为导向的评估问题。

Method: 提出了Goal Success Rate (GSR)来衡量目标完成的百分比，并提出了Root Cause of Failure (RCOF) 分类法来识别多智能体聊天机器人失败的原因。该方法通过用户目标对对话进行分割，并使用所有相关的turns来评估成功与否。此外，还提出了一个基于模型的评估系统，该系统结合了teacher LLM，领域专家定义目标，并设定质量标准来指导LLM。LLM使用“思考token”来产生可解释的基本原理。

Result: 在企业环境中，将该框架应用于评估AIDA，一个从零开始构建的多智能体对话式代理系统，并在其成立后的六个月内观察到GSR从63％提高到79％。

Conclusion: 该框架是通用的，通过基于多智能体聊天机器人中故障点的分析，提供可操作的见解，诊断整体成功率，识别关键故障模式，并为系统改进提供信息。

Abstract: Evaluating the quality of multi-turn chatbot interactions remains
challenging, as most existing methods assess interactions at the turn level
without addressing whether a user's overarching goal was fulfilled. A ``goal''
here refers to an information need or task, such as asking for policy
information or applying for leave. We propose a comprehensive framework for
goal-oriented evaluation of multi-agent systems (MAS), introducing the
\textbf{Goal Success Rate (GSR)} to measure the percentage of fulfilled goals,
and a \textbf{Root Cause of Failure (RCOF)} taxonomy to identify reasons for
failure in multi-agent chatbots. Our method segments conversations by user
goals and evaluates success using all relevant turns. We present a model-based
evaluation system combining teacher LLMs, where domain experts define goals,
set quality standards serving as a guidance for the LLMs. The LLMs use
``thinking tokens'' to produce interpretable rationales, enabling
\textit{explainable}, \textit{data-efficient} evaluations. In an enterprise
setting, we apply our framework to evaluate AIDA, a zero-to-one employee
conversational agent system built as a ground-up multi-agent conversational
agent, and observe GSR improvement from 63\% to 79\% over six months since its
inception. Our framework is generic and offers actionable insights through a
detailed defect taxonomy based on analysis of failure points in multi-agent
chatbots, diagnosing overall success, identifying key failure modes, and
informing system improvements.

</details>


### [103] [H-DDx: A Hierarchical Evaluation Framework for Differential Diagnosis](https://arxiv.org/abs/2510.03700)
*Seungseop Lim,Gibaeg Kim,Hyunkyung Lee,Wooseok Han,Jean Seo,Jaehyo Yoo,Eunho Yang*

Main category: cs.AI

TL;DR: 本文介绍了一种新的评估框架H-DDx，用于评估大型语言模型在鉴别诊断中的性能，该框架通过层级指标更好地反映临床相关性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法主要依赖于 Top-k 准确率等扁平指标，无法区分临床相关的近似错误和诊断上的显著错误。

Method: 该框架利用检索和重排序流程将自由文本诊断映射到 ICD-10 代码，并应用层级指标来评估预测结果与真实诊断的接近程度。

Result: 实验结果表明，传统的扁平指标低估了模型的性能，而领域专业化的开源模型表现出优势。该框架还可以揭示层级错误模式。

Conclusion: H-DDx 框架能够更准确地评估大型语言模型在鉴别诊断中的性能，并提供更好的可解释性。

Abstract: An accurate differential diagnosis (DDx) is essential for patient care,
shaping therapeutic decisions and influencing outcomes. Recently, Large
Language Models (LLMs) have emerged as promising tools to support this process
by generating a DDx list from patient narratives. However, existing evaluations
of LLMs in this domain primarily rely on flat metrics, such as Top-k accuracy,
which fail to distinguish between clinically relevant near-misses and
diagnostically distant errors. To mitigate this limitation, we introduce H-DDx,
a hierarchical evaluation framework that better reflects clinical relevance.
H-DDx leverages a retrieval and reranking pipeline to map free-text diagnoses
to ICD-10 codes and applies a hierarchical metric that credits predictions
closely related to the ground-truth diagnosis. In benchmarking 22 leading
models, we show that conventional flat metrics underestimate performance by
overlooking clinically meaningful outputs, with our results highlighting the
strengths of domain-specialized open-source models. Furthermore, our framework
enhances interpretability by revealing hierarchical error patterns,
demonstrating that LLMs often correctly identify the broader clinical context
even when the precise diagnosis is missed.

</details>


### [104] [Bridging the Gap Between Multimodal Foundation Models and World Models](https://arxiv.org/abs/2510.03727)
*Xuehai He*

Main category: cs.AI

TL;DR: 本文旨在弥合多模态基础模型 (MFM) 和世界模型之间的差距。


<details>
  <summary>Details</summary>
Motivation: 目前的多模态基础模型 (MFM) 在执行反事实推理、模拟动态、理解时空信息、控制生成的视觉结果以及执行多方面推理等基本能力方面存在不足，无法作为有效的世界模型。

Method: 通过判别任务提高 MFM 的推理能力，并为 MFM 配备结构化推理技能，例如因果推理、反事实思维和时空推理。探索多模态基础模型在图像和视频模态中的生成能力，引入用于结构化和可控生成的新框架。结合场景图、多模态条件和多模态对齐策略来指导生成过程，确保与高级语义和细粒度的用户意图保持一致。将这些技术进一步扩展到可控 4D 生成，从而实现随时间和空间进行交互、编辑和变形的对象合成。

Result: 新的框架可以提升多模态基础模型在推理和生成方面的能力。

Conclusion: 本文 исследует了弥合多模态基础模型 (MFM) 和世界模型之间的差距的方法，并提出了新的框架。

Abstract: Humans understand the world through the integration of multiple sensory
modalities, enabling them to perceive, reason about, and imagine dynamic
physical processes. Inspired by this capability, multimodal foundation models
(MFMs) have emerged as powerful tools for multimodal understanding and
generation. However, today's MFMs fall short of serving as effective world
models. They lack the essential ability such as perform counterfactual
reasoning, simulate dynamics, understand the spatiotemporal information,
control generated visual outcomes, and perform multifaceted reasoning. We
investigates what it takes to bridge the gap between multimodal foundation
models and world models. We begin by improving the reasoning capabilities of
MFMs through discriminative tasks and equipping MFMs with structured reasoning
skills, such as causal inference, counterfactual thinking, and spatiotemporal
reasoning, enabling them to go beyond surface correlations and understand
deeper relationships within visual and textual data. Next, we explore
generative capabilities of multimodal foundation models across both image and
video modalities, introducing new frameworks for structured and controllable
generation. Our approaches incorporate scene graphs, multimodal conditioning,
and multimodal alignment strategies to guide the generation process, ensuring
consistency with high-level semantics and fine-grained user intent. We further
extend these techniques to controllable 4D generation, enabling interactive,
editable, and morphable object synthesis over time and space.

</details>


### [105] [OptAgent: Optimizing Query Rewriting for E-commerce via Multi-Agent Simulation](https://arxiv.org/abs/2510.03771)
*Divij Handa,David Blincoe,Orson Adams,Yinlin Fu*

Main category: cs.AI

TL;DR: 提出了一种名为OptAgent的新框架，该框架结合了多智能体模拟和遗传算法，用于验证和优化QR的查询。


<details>
  <summary>Details</summary>
Motivation: 可靠的评估对于部署有能力且符合用户需求的基于llm的系统是必要的。电子商务查询重写(QR)就是一个这样的问题，确定重写的查询是否正确地捕获了用户的意图非常困难。

Method: 该方法使用多个基于llm的代理(每个代理都充当模拟购物客户)作为动态奖励信号。这些agent派生分数的平均值作为进化算法的有效适应度函数，该算法迭代地优化用户的初始查询。

Result: 在五个不同类别的1000个真实电子商务查询的数据集上评估OptAgent，并且我们观察到比原始用户查询平均提高了21.98%，比best-of-n LLM重写基线平均提高了3.36%。

Conclusion: OptAgent框架有效地利用多智能体模拟和遗传算法来验证和优化电子商务查询重写任务，并在实际数据集上取得了显著的改进。

Abstract: Deploying capable and user-aligned LLM-based systems necessitates reliable
evaluation. While LLMs excel in verifiable tasks like coding and mathematics,
where gold-standard solutions are available, adoption remains challenging for
subjective tasks that lack a single correct answer. E-commerce Query Rewriting
(QR) is one such problem where determining whether a rewritten query properly
captures the user intent is extremely difficult to figure out algorithmically.
In this work, we introduce OptAgent, a novel framework that combines
multi-agent simulations with genetic algorithms to verify and optimize queries
for QR. Instead of relying on a static reward model or a single LLM judge, our
approach uses multiple LLM-based agents, each acting as a simulated shopping
customer, as a dynamic reward signal. The average of these agent-derived scores
serves as an effective fitness function for an evolutionary algorithm that
iteratively refines the user's initial query. We evaluate OptAgent on a dataset
of 1000 real-world e-commerce queries in five different categories, and we
observe an average improvement of 21.98% over the original user query and 3.36%
over a Best-of-N LLM rewriting baseline.

</details>


### [106] [GuidedSampling: Steering LLMs Towards Diverse Candidate Solutions at Inference-Time](https://arxiv.org/abs/2510.03777)
*Divij Handa,Mihir Parmar,Aswin RRV,Md Nayem Uddin,Hamid Palangi,Chitta Baral*

Main category: cs.AI

TL;DR: GuidedSampling improves model performance by decoupling exploration and generation phases, increasing diversity in solution candidates.


<details>
  <summary>Details</summary>
Motivation: Repeated Sampling struggles to generate diverse solution candidates, relying on the same underlying approach.

Method: The GuidedSampling algorithm decouples exploration and generation phases. Exploration identifies multiple concepts, while generation applies a concept to provide solutions.

Result: GuidedSampling improves pass@50 by ~21.6% compared to RS. Models trained on GuidedSampling trajectories improve pass@5 by ~9.7% and increase the average number of concepts per instance (1.67 -> 3.03).

Conclusion: GuidedSampling yields a more diverse set of candidates than traditional RS.

Abstract: Repeated Sampling (RS) is a simple inference-time algorithm that has been
shown to improve model performance on complex tasks. Although it is an
effective way of scaling inference time, it often struggles to generate diverse
solution candidates, frequently relying on the same underlying approach to
solve the problem and thus producing redundant samples. To address this
limitation, we propose a new inference algorithm, GuidedSampling, which
decouples the exploration and generation phases during inference, increasing
diversity of generated candidate solutions. The exploration phase identifies
multiple concepts that can be utilized to solve the problem, while the
generation phase applies a specific concept to provide final solution
candidates. We first define the theoretical bounds of GuidedSampling and then
empirically demonstrate that it improves the performance of base model at
pass@50 by on an average ~21.6% across various benchmarks compared to RS.
Furthermore, models trained on trajectories of GuidedSampling exhibit
substantial performance improvements at pass@5 by on an average ~9.7%, compared
to models trained on traditional RS. Additionally, models trained with
GuidedSampling increases the average number of concepts per instance (1.67 ->
3.03), yielding a diverse set of candidates than traditional RS.

</details>


### [107] [The Hidden Game Problem](https://arxiv.org/abs/2510.03845)
*Gon Buzaglo,Noah Golowich,Elad Hazan*

Main category: cs.AI

TL;DR: 本文研究具有大型策略空间的一类博弈，其动机源于AI对齐和语言博弈中的挑战。


<details>
  <summary>Details</summary>
Motivation: 引入了隐藏博弈问题，其中对于每个玩家，策略的未知子集始终产生比其余策略更高的回报。

Method: 通过开发后悔最小化技术的组合来肯定地回答这个问题，该组合实现了最佳的外部和交换后悔界限。

Result: 我们的方法确保在隐藏子博弈中快速收敛到相关均衡，利用隐藏博弈结构来提高计算效率。

Conclusion: 设计有效的后悔最小化算法来发现和利用这些隐藏结构，从而在这些子博弈中达到均衡，同时保持一般理性。

Abstract: This paper investigates a class of games with large strategy spaces,
motivated by challenges in AI alignment and language games. We introduce the
hidden game problem, where for each player, an unknown subset of strategies
consistently yields higher rewards compared to the rest. The central question
is whether efficient regret minimization algorithms can be designed to discover
and exploit such hidden structures, leading to equilibrium in these subgames
while maintaining rationality in general. We answer this question affirmatively
by developing a composition of regret minimization techniques that achieve
optimal external and swap regret bounds. Our approach ensures rapid convergence
to correlated equilibria in hidden subgames, leveraging the hidden game
structure for improved computational efficiency.

</details>


### [108] [Small Language Models for Agentic Systems: A Survey of Architectures, Capabilities, and Deployment Trade offs](https://arxiv.org/abs/2510.03847)
*Raghav Sharma,Manan Mehta*

Main category: cs.AI

TL;DR: 小型语言模型（SLM）在需要模式和 API 约束的代理任务中通常优于大型语言模型（LLM）。


<details>
  <summary>Details</summary>
Motivation: 探索小型语言模型在代理任务中的有效性，尤其是在工具使用、函数调用和检索增强生成（RAG）方面。

Method: 综合分析了各种开源和商业 SLM 的最新证据，并将其与现代评估方法和serving stacks相结合。提出了SLM-default，LLM-fallback系统，并提出了反映实际生产目标的工程指标。

Result: 小型语言模型通过引导解码、严格的 JSON 模式输出和验证器优先的工具执行，在工具使用、函数调用和 RAG 方面可以匹配甚至超过大型语言模型，同时降低了 10-100 倍的 token 成本，并显著改善了延迟和能耗。

Conclusion: 本文为构建快速、低成本且可靠的代理提供了一个实用的蓝图，该代理默认使用 SLM，同时保留了通过有针对性的 LLM 辅助实现的 headroom。

Abstract: Small language models (SLMs; 1-12B params, sometimes up to 20B) are
sufficient and often superior for agentic workloads where the objective is
schema- and API-constrained accuracy rather than open-ended generation. We
synthesize recent evidence across open and proprietary SLMs (Phi-4-Mini,
Qwen-2.5-7B, Gemma-2-9B, Llama-3.2-1B/3B, Ministral-3B/8B, Apple on-device 3B,
DeepSeek-R1-Distill) and connect it to modern evaluations (BFCL v3/v4,
StableToolBench) and serving stacks (vLLM, SGLang, TensorRT-LLM) paired with
guided decoding libraries (XGrammar, Outlines). We formalize SLM-default,
LLM-fallback systems with uncertainty-aware routing and verifier cascades, and
propose engineering metrics that reflect real production goals: cost per
successful task (CPS), schema validity rate, executable call rate, p50/p95
latency, and energy per request. Guided decoding, strict JSON Schema outputs,
and validator-first tool execution close much of the capability gap with larger
models and often let SLMs match or surpass LLMs on tool use, function calling,
and RAG at 10x-100x lower token cost with materially better latency and energy.
We provide design patterns for agent stacks that prioritize SLMs: schema-first
prompting, type-safe function registries, confidence scoring with verifier
rollups, and lightweight adaptation via LoRA/QLoRA. We also delineate limits
where fallback remains valuable (open-domain reasoning and some long-horizon
planning). The result is a practical blueprint for building fast, inexpensive,
and reliable agents that default to SLMs while preserving headroom with
targeted LLM assistance.
  Keywords: small language models, agents, function calling, structured
outputs, JSON Schema, guided decoding, LoRA/QLoRA, routing, energy efficiency,
edge inference

</details>


### [109] [Algorithm Generation via Creative Ideation](https://arxiv.org/abs/2510.03851)
*Ruiying Ma,Chieh-Jan Mike Liang,Yanjie Gao,Francis Y. Yan*

Main category: cs.AI

TL;DR: 大型语言模型(LLM)在算法生成方面存在局限性，倾向于已知的通用设计。


<details>
  <summary>Details</summary>
Motivation: 系统算法设计具有挑战性，解空间的不连续性导致工程师依赖通用启发式方法，牺牲了性能。研究LLM是否能驱动算法生成。

Method: 提出了MetaMuse框架，基于三个自反思原则：(1)在可测量的性能空间中量化解决方案的多样性和有效性，(2)通过外部刺激引导构思，(3)使用航路点推理构建可执行的解决方案。

Result: MetaMuse在缓存替换（减少高达35.76%的缓存未命中）和在线装箱（减少高达30.93%的箱子使用）两个关键问题上生成了高性能的解决方案。

Conclusion: MetaMuse能够为全局云提供商的两个关键问题生成高性能的解决方案。

Abstract: Designing system algorithms remains challenging, where the discontinuous
nature of the solution space often forces system engineers to rely on generic
heuristics at the expense of performance. We study whether LLMs can practically
drive algorithm generation, and find that they are biased towards well-known
generic designs, rather than making the creative leaps needed to navigate the
discontinuous solution space. To address this limitation, we introduce
MetaMuse, a framework for creative ideation built on three self-reflection
principles: (1) quantifying solution diversity and usefulness in measurable
performance space, rather than abstract idea space, (2) steering ideation
through external stimuli, rather than internal randomness, and (3) constructing
executable solutions using waypoint reasoning, rather than free-form
chain-of-thought. Extensive evaluation shows that MetaMuse can generate
high-performing solutions for two critical problems at a global cloud provider:
cache replacement (reducing cache misses by up to 35.76%) and online bin
packing (reducing bin usage by up to 30.93%).

</details>


### [110] [Adaptive and Explainable AI Agents for Anomaly Detection in Critical IoT Infrastructure using LLM-Enhanced Contextual Reasoning](https://arxiv.org/abs/2510.03859)
*Raghav Sharma,Manan Mehta*

Main category: cs.AI

TL;DR: 提出了一种使用LLM和XAI代理来改进物联网环境中异常检测的方法。


<details>
  <summary>Details</summary>
Motivation: 传统的异常检测方法在高维、动态和数据不完整的环境中存在局限性。

Method: 利用LLM支持的上下文推理方法，结合XAI代理，通过注意力机制和记忆缓冲区发现数据流中的隐藏模式和不一致性。

Result: 提出的新方法在准确性和可解释性方面优于现有模型。

Conclusion: 该方法适用于未来物联网中的异常检测任务。

Abstract: Ensuring that critical IoT systems function safely and smoothly depends a lot
on finding anomalies quickly. As more complex systems, like smart healthcare,
energy grids and industrial automation, appear, it is easier to see the
shortcomings of older methods of detection. Monitoring failures usually happen
in dynamic, high dimensional situations, especially when data is incomplete,
messy or always evolving. Such limits point out the requirement for adaptive,
intelligent systems that always improve and think. LLMs are now capable of
significantly changing how context is understood and semantic inference is done
across all types of data. This proposal suggests using an LLM supported
contextual reasoning method along with XAI agents to improve how anomalies are
found in significant IoT environments. To discover hidden patterns and notice
inconsistencies in data streams, it uses attention methods, avoids dealing with
details from every time step and uses memory buffers with meaning. Because no
code AI stresses transparency and interpretability, people can check and accept
the AI's decisions, helping ensure AI follows company policies. The two
architectures are put together in a test that compares the results of the
traditional model with those of the suggested LLM enhanced model. Important
measures to check are the accuracy of detection, how much inaccurate
information is included in the results, how clearly the findings can be read
and how fast the system responds under different test situations. The
metaheuristic is tested in simulations of real world smart grid and healthcare
contexts to check its adaptability and reliability. From the study, we see that
the new approach performs much better than most existing models in both
accuracy and interpretation, so it could be a good fit for future anomaly
detection tasks in IoT

</details>


### [111] [Spatial CAPTCHA: Generatively Benchmarking Spatial Reasoning for Human-Machine Differentiation](https://arxiv.org/abs/2510.03863)
*Arina Kharlamova,Bowei He,Chen Ma,Xue Liu*

Main category: cs.AI

TL;DR: 提出了Spatial CAPTCHA，一种利用人类和多模态大型语言模型在空间推理上的根本差异的新型人机验证框架。


<details>
  <summary>Details</summary>
Motivation: 传统验证码的有效性因多模态大型语言模型的最新进展而降低。

Method: 生成需要几何推理、透视、遮挡处理和心理旋转的动态问题。采用具有基于约束的难度控制、自动正确性验证和人工参与验证的程序生成流程。

Result: 在Spatial-CAPTCHA-Bench基准测试中，人类的表现大大优于10个最先进的多模态大型语言模型，最佳模型的Pass@1准确率仅为31.0%。与Google reCAPTCHA的比较证实了其作为安全机制和AI空间推理诊断工具的有效性。

Conclusion: Spatial CAPTCHA是一种有效的人机验证框架，可以弥补现有验证码的不足。

Abstract: Online services rely on CAPTCHAs as a first line of defense against automated
abuse, yet recent advances in multi-modal large language models (MLLMs) have
eroded the effectiveness of conventional designs that focus on text recognition
or 2D image understanding. To address this challenge, we present Spatial
CAPTCHA, a novel human-verification framework that leverages fundamental
differences in spatial reasoning between humans and MLLMs. Unlike existing
CAPTCHAs which rely on low-level perception tasks that are vulnerable to modern
AI, Spatial CAPTCHA generates dynamic questions requiring geometric reasoning,
perspective-taking, occlusion handling, and mental rotation. These skills are
intuitive for humans but difficult for state-of-the-art (SOTA) AI systems. The
system employs a procedural generation pipeline with constraint-based
difficulty control, automated correctness verification, and human-in-the-loop
validation to ensure scalability, robustness, and adaptability. Evaluation on a
corresponding benchmark, Spatial-CAPTCHA-Bench, demonstrates that humans vastly
outperform 10 state-of-the-art MLLMs, with the best model achieving only 31.0%
Pass@1 accuracy. Furthermore, we compare Spatial CAPTCHA with Google reCAPTCHA,
which confirms its effectiveness as both a security mechanism and a diagnostic
tool for spatial reasoning in AI.

</details>


### [112] [Rare Text Semantics Were Always There in Your Diffusion Transformer](https://arxiv.org/abs/2510.03886)
*Seil Kang,Woojung Han,Dayun Ju,Seong Jae Hwang*

Main category: cs.AI

TL;DR: MM-DiTs在处理罕见prompt时会遇到困难，因为这些概念在预训练期间留下的印记较弱。


<details>
  <summary>Details</summary>
Motivation: 用户不断尝试用想象力丰富的prompt来挑战text-to-vision生成模型，但模型在生成这些prompt时表现不佳。

Method: 通过在联合注意力模块之前，通过方差放大来扩大文本token嵌入周围的表征盆地，从而使MM-DiT内部的罕见语义显现出来。

Result: 该方法在text-to-vision任务中表现出有效性，包括text-to-image、text-to-video和文本驱动的图像编辑。

Conclusion: 该研究邀请生成模型揭示用户意图中的语义，这些语义曾经隐藏但现在可以被发现。

Abstract: Starting from flow- and diffusion-based transformers, Multi-modal Diffusion
Transformers (MM-DiTs) have reshaped text-to-vision generation, gaining acclaim
for exceptional visual fidelity. As these models advance, users continually
push the boundary with imaginative or rare prompts, which advanced models still
falter in generating, since their concepts are often too scarce to leave a
strong imprint during pre-training. In this paper, we propose a simple yet
effective intervention that surfaces rare semantics inside MM-DiTs without
additional training steps, data, denoising-time optimization, or reliance on
external modules (e.g., large language models). In particular, the
joint-attention mechanism intrinsic to MM-DiT sequentially updates text
embeddings alongside image embeddings throughout transformer blocks. We find
that by mathematically expanding representational basins around text token
embeddings via variance scale-up before the joint-attention blocks, rare
semantics clearly emerge in MM-DiT's outputs. Furthermore, our results
generalize effectively across text-to-vision tasks, including text-to-image,
text-to-video, and text-driven image editing. Our work invites generative
models to reveal the semantics that users intend, once hidden yet ready to
surface.

</details>


### [113] [Kantian-Utilitarian XAI: Meta-Explained](https://arxiv.org/abs/2510.03892)
*Zahra Atf,Peter R. Lewis*

Main category: cs.AI

TL;DR: 提出了一个咖啡领域的、具有伦理意识的、游戏化的可解释人工智能系统，用于消费者决策。


<details>
  <summary>Details</summary>
Motivation: 帮助消费者在购买咖啡时做出更符合伦理的选择。

Method: 该系统包含两个符号引擎（康德模块和功利模块）提供实时理由，以及一个元解释器来突出康德主义与功利主义的（不）对齐。

Result: 发布了一个结构化配置、一个用于可审计性的策略跟踪和一个交互式用户界面。

Conclusion: 该系统能够在福利损失较小的情况下，切换到在道义上更清洁的、接近平价的选项。

Abstract: We present a gamified explainable AI (XAI) system for ethically aware
consumer decision-making in the coffee domain. Each session comprises six
rounds with three options per round. Two symbolic engines provide real-time
reasons: a Kantian module flags rule violations (e.g., child labor,
deforestation risk without shade certification, opaque supply chains, unsafe
decaf), and a utilitarian module scores options via multi-criteria aggregation
over normalized attributes (price, carbon, water, transparency, farmer income
share, taste/freshness, packaging, convenience). A meta-explainer with a regret
bound (0.2) highlights Kantian--utilitarian (mis)alignment and switches to a
deontically clean, near-parity option when welfare loss is small. We release a
structured configuration (attribute schema, certification map, weights, rule
set), a policy trace for auditability, and an interactive UI.

</details>


### [114] [Quantifying Risks in Multi-turn Conversation with Large Language Models](https://arxiv.org/abs/2510.03969)
*Chengxiao Wang,Isha Chaudhary,Qian Hu,Weitong Ruan,Rahul Gupta,Gagandeep Singh*

Main category: cs.AI

TL;DR: 提出了一种新的认证框架，用于评估大型语言模型在多轮对话中产生灾难性风险的可能性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法无法完全揭示大型语言模型的漏洞，因为它们依赖于固定的攻击提示序列，缺乏统计保证，并且无法扩展到多轮对话的巨大空间。

Method: 将多轮对话建模为查询序列上的概率分布，用马尔可夫过程表示，并使用置信区间量化灾难性风险。

Result: 在最差的模型中，认证的下限高达 70%，表明迫切需要改进前沿 LLM 中的安全训练策略。

Conclusion: 该研究揭示了前沿模型中潜在的灾难性风险，并强调了改进 LLM 安全性的必要性。

Abstract: Large Language Models (LLMs) can produce catastrophic responses in
conversational settings that pose serious risks to public safety and security.
Existing evaluations often fail to fully reveal these vulnerabilities because
they rely on fixed attack prompt sequences, lack statistical guarantees, and do
not scale to the vast space of multi-turn conversations. In this work, we
propose QRLLM, a novel, principled Certification framework for Catastrophic
risks in multi-turn Conversation for LLMs that bounds the probability of an LLM
generating catastrophic responses under multi-turn conversation distributions
with statistical guarantees. We model multi-turn conversations as probability
distributions over query sequences, represented by a Markov process on a query
graph whose edges encode semantic similarity to capture realistic
conversational flow, and quantify catastrophic risks using confidence
intervals. We define several inexpensive and practical distributions: random
node, graph path, adaptive with rejection. Our results demonstrate that these
distributions can reveal substantial catastrophic risks in frontier models,
with certified lower bounds as high as 70\% for the worst model, highlighting
the urgent need for improved safety training strategies in frontier LLMs.

</details>


### [115] [What Shapes a Creative Machine Mind? Comprehensively Benchmarking Creativity in Foundation Models](https://arxiv.org/abs/2510.04009)
*Zicong He,Boxuan Zhang,Weihao Liu,Ruixiang Tang,Lu Cheng*

Main category: cs.AI

TL;DR: 提出了一个名为C^2-Eval的整体基准，用于评估FMs中的创造力。


<details>
  <summary>Details</summary>
Motivation: 现有的创造力评估框架仍然是分散的，依赖于未牢固地建立在已建立的理论基础上的临时指标。

Method: 区分收敛创造力（例如，代码生成）和发散创造力（例如，讲故事）这两种互补的创造力形式。它使用源自社会科学理论的细粒度标准评估这两个维度，侧重于有用性、原创性和惊奇性（U-O-S）。

Result: 通过对领先的专有和开源模型进行的大量实验，分析了它们在创造能力方面的权衡。

Conclusion: C^2-Eval是检查创造性AI不断发展的有效途径。

Abstract: The meteoric rise of foundation models (FMs) has expanded their capabilities
far beyond conventional tasks. Creativity, long regarded as a hallmark of human
intelligence and a driver of innovation, is now increasingly recognized as a
critical dimension of machine intelligence in the era of generative FMs,
complementing traditional measures of accuracy. However, existing evaluation
frameworks for creativity remain fragmented, relying on ad hoc metrics not
firmly grounded in established theories. To address this gap, we introduce
C^2-Eval, a holistic benchmark for unified assessment of creativity in FMs.
C^2-Eval distinguishes between two complementary forms of creativity:
convergent creativity, where tasks admit constrained solutions (e.g., code
generation), and divergent creativity, where tasks are open-ended (e.g.,
storytelling). It evaluates both dimensions using fine-grained criteria derived
from social-science theory, focusing on Usefulness, Originality, and Surprise
(U-O-S). Through extensive experiments on leading proprietary and open-source
models, we analyze trade-offs in their creative capabilities. Our results
highlight both the strengths and challenges of current FMs in pursuing a
creative machine mind, showing that C^2-Eval is an effective lens for examining
the evolving landscape of creative AI.

</details>


### [116] [Zephyrus: An Agentic Framework for Weather Science](https://arxiv.org/abs/2510.04017)
*Sumanth Varambally,Marshall Fisher,Jas Thakker,Yiwei Chen,Zhirui Xia,Yasaman Jafari,Ruijia Niu,Manas Jain,Veeramakali Vignesh Manivannan,Zachary Novack,Luyu Han,Srikar Eranky,Salva Rühling Cachay,Taylor Berg-Kirkpatrick,Duncan Watson-Parris,Yi-An Ma,Rose Yu*

Main category: cs.AI

TL;DR: 构建了一个用于天气科学的agentic框架，利用LLM和Python代码环境来分析天气数据。


<details>
  <summary>Details</summary>
Motivation: 现有的天气预报模型缺乏语言推理能力，而大型语言模型无法处理高维气象数据集。

Method: 构建一个名为Zephyrus的基于LLM的天气agent，通过与天气数据交互、观察结果和对话反馈来迭代分析。

Result: Zephyrus agent在天气相关任务上的表现优于纯文本基线，正确率提高了35%。

Conclusion: Zephyrus在更困难的任务上表现与纯文本基线相似，表明benchmark具有挑战性，并为未来的工作提供了方向。

Abstract: Foundation models for weather science are pre-trained on vast amounts of
structured numerical data and outperform traditional weather forecasting
systems. However, these models lack language-based reasoning capabilities,
limiting their utility in interactive scientific workflows. Large language
models (LLMs) excel at understanding and generating text but cannot reason
about high-dimensional meteorological datasets. We bridge this gap by building
a novel agentic framework for weather science. Our framework includes a Python
code-based environment for agents (ZephyrusWorld) to interact with weather
data, featuring tools like an interface to WeatherBench 2 dataset, geoquerying
for geographical masks from natural language, weather forecasting, and climate
simulation capabilities. We design Zephyrus, a multi-turn LLM-based weather
agent that iteratively analyzes weather datasets, observes results, and refines
its approach through conversational feedback loops. We accompany the agent with
a new benchmark, ZephyrusBench, with a scalable data generation pipeline that
constructs diverse question-answer pairs across weather-related tasks, from
basic lookups to advanced forecasting, extreme event detection, and
counterfactual reasoning. Experiments on this benchmark demonstrate the strong
performance of Zephyrus agents over text-only baselines, outperforming them by
up to 35 percentage points in correctness. However, on harder tasks, Zephyrus
performs similarly to text-only baselines, highlighting the challenging nature
of our benchmark and suggesting promising directions for future work.

</details>


### [117] [LLM-Based Data Science Agents: A Survey of Capabilities, Challenges, and Future Directions](https://arxiv.org/abs/2510.04023)
*Mizanur Rahman,Amran Bhuiyan,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Ridwan Mahbub,Ahmed Masry,Shafiq Joty,Enamul Hoque*

Main category: cs.AI

TL;DR: 本调查全面分析了数据科学代理，根据端到端数据科学流程的六个阶段对 45 个系统进行了系统分析和映射。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型 (LLM) 的最新进展催生了一类新的 AI 代理，这些代理通过整合跨文本、代码、表格和视觉的规划、工具使用和多模式推理，从而自动执行数据科学工作流程的多个阶段。

Method: 本文提出了数据科学代理的第一个全面的、与生命周期对齐的分类法，并沿着五个横向设计维度对每个代理进行注释：推理和规划风格、模态集成、工具编排深度、学习和对齐方法以及信任、安全和治理机制。

Result: 大多数系统强调探索性分析、可视化和建模，而忽略了业务理解、部署和监控；多模态推理和工具编排仍然是未解决的挑战；超过 90% 的系统缺乏明确的信任和安全机制。

Conclusion: 总结了对齐稳定性、可解释性、治理和稳健的评估框架方面的未解决的挑战，并提出了未来的研究方向，以指导开发稳健、值得信赖、低延迟、透明且广泛可访问的数据科学代理。

Abstract: Recent advances in large language models (LLMs) have enabled a new class of
AI agents that automate multiple stages of the data science workflow by
integrating planning, tool use, and multimodal reasoning across text, code,
tables, and visuals. This survey presents the first comprehensive,
lifecycle-aligned taxonomy of data science agents, systematically analyzing and
mapping forty-five systems onto the six stages of the end-to-end data science
process: business understanding and data acquisition, exploratory analysis and
visualization, feature engineering, model building and selection,
interpretation and explanation, and deployment and monitoring. In addition to
lifecycle coverage, we annotate each agent along five cross-cutting design
dimensions: reasoning and planning style, modality integration, tool
orchestration depth, learning and alignment methods, and trust, safety, and
governance mechanisms. Beyond classification, we provide a critical synthesis
of agent capabilities, highlight strengths and limitations at each stage, and
review emerging benchmarks and evaluation practices. Our analysis identifies
three key trends: most systems emphasize exploratory analysis, visualization,
and modeling while neglecting business understanding, deployment, and
monitoring; multimodal reasoning and tool orchestration remain unresolved
challenges; and over 90% lack explicit trust and safety mechanisms. We conclude
by outlining open challenges in alignment stability, explainability,
governance, and robust evaluation frameworks, and propose future research
directions to guide the development of robust, trustworthy, low-latency,
transparent, and broadly accessible data science agents.

</details>


### [118] [A global log for medical AI](https://arxiv.org/abs/2510.04033)
*Ayush Noori,Adam Rodman,Alan Karthikesalingam,Bilal A. Mateen,Christopher A. Longhurst,Daniel Yang,Dave deBronkart,Gauden Galea,Harold F. Wolf III,Jacob Waxman,Joshua C. Mandel,Juliana Rotich,Kenneth D. Mandl,Maryam Mustafa,Melissa Miles,Nigam H. Shah,Peter Lee,Robert Korom,Scott Mahoney,Seth Hain,Tien Yin Wong,Trevor Mundel,Vivek Natarajan,Noa Dagan,David A. Clifton,Ran D. Balicer,Isaac S. Kohane,Marinka Zitnik*

Main category: cs.AI

TL;DR: 介绍MedLog，一种用于临床AI事件级别日志记录的协议，类似于syslog。


<details>
  <summary>Details</summary>
Motivation: 医疗保健领域缺乏记录AI模型使用情况的标准方法，阻碍了性能评估、问题检测和偏差纠正。

Method: 提出MedLog协议，每次AI模型被调用时创建一个包含九个核心字段的记录。

Result: MedLog支持风险采样、生命周期感知保留策略和写后缓存，以鼓励早期采用并最小化数据占用。

Conclusion: MedLog的实现能够持续监测、审计和迭代改进医疗AI，为新型数字流行病学奠定基础。

Abstract: Modern computer systems often rely on syslog, a simple, universal protocol
that records every critical event across heterogeneous infrastructure. However,
healthcare's rapidly growing clinical AI stack has no equivalent. As hospitals
rush to pilot large language models and other AI-based clinical decision
support tools, we still lack a standard way to record how, when, by whom, and
for whom these AI models are used. Without that transparency and visibility, it
is challenging to measure real-world performance and outcomes, detect adverse
events, or correct bias or dataset drift. In the spirit of syslog, we introduce
MedLog, a protocol for event-level logging of clinical AI. Any time an AI model
is invoked to interact with a human, interface with another algorithm, or act
independently, a MedLog record is created. This record consists of nine core
fields: header, model, user, target, inputs, artifacts, outputs, outcomes, and
feedback, providing a structured and consistent record of model activity. To
encourage early adoption, especially in low-resource settings, and minimize the
data footprint, MedLog supports risk-based sampling, lifecycle-aware retention
policies, and write-behind caching; detailed traces for complex, agentic, or
multi-stage workflows can also be captured under MedLog. MedLog can catalyze
the development of new databases and software to store and analyze MedLog
records. Realizing this vision would enable continuous surveillance, auditing,
and iterative improvement of medical AI, laying the foundation for a new form
of digital epidemiology.

</details>


### [119] [FaithCoT-Bench: Benchmarking Instance-Level Faithfulness of Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.04040)
*Xu Shen,Song Wang,Zhen Tan,Laura Yao,Xinyu Zhao,Kaidi Xu,Xin Wang,Tianlong Chen*

Main category: cs.AI

TL;DR: 论文提出了FaithCoT-Bench，一个用于检测CoT推理不忠实性的基准。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明，大型语言模型的CoT推理过程可能不忠实，但在实际应用中难以判断特定轨迹是否忠实于模型内部推理。

Method: 构建了一个统一的基准FaithCoT-Bench，并将不忠实性检测定义为一个判别决策问题。创建了一个专家标注的数据集FINE-CoT，包含1000多个轨迹，包括300多个不忠实的实例，并提供细粒度的原因和步骤级别的证据。

Result: 对11种代表性的检测方法进行了系统评估，揭示了现有方法的优缺点，并表明在知识密集型领域和更先进的模型中，检测的挑战更大。

Conclusion: FaithCoT-Bench是首个全面的实例级别CoT忠实性基准，为未来在LLM中实现更可解释和可信的推理奠定了坚实的基础。

Abstract: Large language models (LLMs) increasingly rely on Chain-of-Thought (CoT)
prompting to improve problem-solving and provide seemingly transparent
explanations. However, growing evidence shows that CoT often fail to faithfully
represent the underlying reasoning process, raising concerns about their
reliability in high-risk applications. Although prior studies have focused on
mechanism-level analyses showing that CoTs can be unfaithful, they leave open
the practical challenge of deciding whether a specific trajectory is faithful
to the internal reasoning of the model. To address this gap, we introduce
FaithCoT-Bench, a unified benchmark for instance-level CoT unfaithfulness
detection. Our framework establishes a rigorous task formulation that
formulates unfaithfulness detection as a discriminative decision problem, and
provides FINE-CoT (Faithfulness instance evaluation for Chain-of-Thought), an
expert-annotated collection of over 1,000 trajectories generated by four
representative LLMs across four domains, including more than 300 unfaithful
instances with fine-grained causes and step-level evidence. We further conduct
a systematic evaluation of eleven representative detection methods spanning
counterfactual, logit-based, and LLM-as-judge paradigms, deriving empirical
insights that clarify the strengths and weaknesses of existing approaches and
reveal the increased challenges of detection in knowledge-intensive domains and
with more advanced models. To the best of our knowledge, FaithCoT-Bench
establishes the first comprehensive benchmark for instance-level CoT
faithfulness, setting a solid basis for future research toward more
interpretable and trustworthy reasoning in LLMs.

</details>


### [120] [Increasing LLM response trustworthiness using voting ensembles](https://arxiv.org/abs/2510.04048)
*Aparna Nair-Kanneganti,Trevor J. Chan,Shir Goldfinger,Emily Mackay,Brian Anthony,Alison Pouch*

Main category: cs.AI

TL;DR: LLMs lack uncertainty quantification, making them untrustworthy. This paper introduces a voting ensemble method with a variable threshold to improve answer trustworthiness by allowing abstention.


<details>
  <summary>Details</summary>
Motivation: LLMs' inability to quantify uncertainty limits their use in high-stakes applications.

Method: The paper proposes a voting ensemble approach with a variable threshold, allowing the ensemble to abstain when confidence is low.

Result: The method significantly increases answer trustworthiness with modest reductions in response yield and accuracy in arithmetic problem solving and clinical-note question-answering.

Conclusion: Voting ensembles are useful in applications requiring high certainty, such as healthcare and data annotation, even if not every question is answered.

Abstract: Despite huge advances, LLMs still lack convenient and reliable methods to
quantify the uncertainty in their responses, making them difficult to trust in
high-stakes applications. One of the simplest approaches to eliciting more
accurate answers is to select the mode of many responses, a technique known as
ensembling. In this work, we expand on typical ensembling approaches by looking
at ensembles with a variable voting threshold. We introduce a theoretical
framework for question answering and show that, by permitting ensembles to
"abstain" from providing an answer when the dominant response falls short of
the threshold, it is possible to dramatically increase the trustworthiness of
the remaining answers. From this framework, we derive theoretical results as
well as report experimental results on two problem domains: arithmetic problem
solving and clinical-note question-answering. In both domains, we observe that
large gains in answer trustworthiness can be achieved using highly restrictive
voting ensembles, while incurring relatively modest reductions in response
yield and accuracy. Due to this quality, voting ensembles may be particularly
useful in applications - such as healthcare and data annotation - that require
a high degree of certainty but which may not require that every question
receive an automated answer.

</details>


### [121] [Toward a unified framework for data-efficient evaluation of large language models](https://arxiv.org/abs/2510.04051)
*Lele Liao,Qile Zhang,Ruofan Wu,Guanhua Fang*

Main category: cs.AI

TL;DR: 提出了一种新的LLM评估框架LEGO-IRT，旨在提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于IRT的方法存在局限性，例如通常仅限于二元正确性指标，无法处理生成任务中使用的连续分数，并且忽略了不同指标或基准之间的相关性等结构性知识。

Method: LEGO-IRT原生支持二元和连续评估指标，并引入分解架构来显式建模和利用结构性知识，将模型能力估计分解为一般组件和特定于结构的组件。

Result: LEGO-IRT仅使用总评估项目的3％即可实现稳定的能力估计，且结合结构知识可将估计误差降低多达10％。

Conclusion: LEGO-IRT框架估计的潜在能力可能更符合人类偏好。

Abstract: Evaluating large language models (LLMs) on comprehensive benchmarks is a
cornerstone of their development, yet it's often computationally and
financially prohibitive. While Item Response Theory (IRT) offers a promising
path toward data-efficient evaluation by disentangling model capability from
item difficulty, existing IRT-based methods are hampered by significant
limitations. They are typically restricted to binary correctness metrics,
failing to natively handle the continuous scores used in generative tasks, and
they operate on single benchmarks, ignoring valuable structural knowledge like
correlations across different metrics or benchmarks. To overcome these
challenges, we introduce LEGO-IRT, a unified and flexible framework for
data-efficient LLM evaluation. LEGO-IRT's novel design natively supports both
binary and continuous evaluation metrics. Moreover, it introduces a factorized
architecture to explicitly model and leverage structural knowledge, decomposing
model ability estimates into a general component and structure-specific (e.g.,
per-metric or per-benchmark) components. Through extensive experiments
involving $70$ LLMs across $5$ benchmarks, we show that LEGO-IRT achieves
stable capability estimates using just $3\%$ of the total evaluation items. We
demonstrate that incorporating structural knowledge reduces estimation error by
up to $10\%$ and reveal that the latent abilities estimated by our framework
may align more closely with human preferences.

</details>


### [122] [Decoding Emotion in the Deep: A Systematic Study of How LLMs Represent, Retain, and Express Emotion](https://arxiv.org/abs/2510.04064)
*Jingxiang Zhang,Lujia Zhong*

Main category: cs.AI

TL;DR: 该研究探索了大型语言模型(llm)中潜在的情感表征，发现llm发展出定义明确的情感内部结构，这种结构随着模型规模的扩大而变得更加清晰，并且明显优于zero-shot提示。


<details>
  <summary>Details</summary>
Motivation: 研究动机是虽然llm可以模拟情商，但它们内部的情感机制仍未被探索。本文旨在研究情感在llm的神经结构中是如何、在何处以及持续多久被编码的。

Method: 该研究构建了一个包含约40万条言语的大规模reddit语料库，这些言语通过分类、重写和合成生成等多阶段过程在七种基本情感之间进行平衡。然后，使用这个数据集，采用轻量级的“探针”从各种qwen3和llama模型的隐藏层中读取信息，而不改变它们的参数。

Result: 研究结果表明，llm发展出定义明确的情感内部结构，这种结构随着模型规模的扩大而变得更加清晰，并且明显优于zero-shot提示。情感信号不是最后一层现象，而是早期出现并在网络中间达到峰值。内部状态既具有可塑性（可以受到简单系统提示的影响），又具有持久性，因为初始情感基调在随后的数百个token中仍然可以检测到。

Conclusion: 该研究贡献了一个数据集、一个开源探测工具包以及llm中情感景象的详细地图，为开发更透明和一致的ai系统提供了关键见解。

Abstract: Large Language Models (LLMs) are increasingly expected to navigate the
nuances of human emotion. While research confirms that LLMs can simulate
emotional intelligence, their internal emotional mechanisms remain largely
unexplored. This paper investigates the latent emotional representations within
modern LLMs by asking: how, where, and for how long is emotion encoded in their
neural architecture? To address this, we introduce a novel, large-scale Reddit
corpus of approximately 400,000 utterances, balanced across seven basic
emotions through a multi-stage process of classification, rewriting, and
synthetic generation. Using this dataset, we employ lightweight "probes" to
read out information from the hidden layers of various Qwen3 and LLaMA models
without altering their parameters. Our findings reveal that LLMs develop a
surprisingly well-defined internal geometry of emotion, which sharpens with
model scale and significantly outperforms zero-shot prompting. We demonstrate
that this emotional signal is not a final-layer phenomenon but emerges early
and peaks mid-network. Furthermore, the internal states are both malleable
(they can be influenced by simple system prompts) and persistent, as the
initial emotional tone remains detectable for hundreds of subsequent tokens. We
contribute our dataset, an open-source probing toolkit, and a detailed map of
the emotional landscape within LLMs, offering crucial insights for developing
more transparent and aligned AI systems. The code and dataset are open-sourced.

</details>


### [123] [Moral Anchor System: A Predictive Framework for AI Value Alignment and Drift Prevention](https://arxiv.org/abs/2510.04073)
*Santhosh Kumar Ravindran*

Main category: cs.AI

TL;DR: 本文提出了一种名为道德锚定系统（MAS）的新框架，用于检测、预测和缓解人工智能（AI）代理中的价值漂移。


<details>
  <summary>Details</summary>
Motivation: 人工智能（AI）作为超级助手的兴起提高了生产力和决策能力，但也引发了关于价值对齐的关键问题，即确保AI行为与人类道德和意图保持一致。一个关键风险是价值漂移，即AI系统由于不断变化的环境、学习动态或意外的优化而偏离对齐的价值观，可能导致效率低下或违反道德规范。

Method: MAS结合了用于监控价值状态的实时贝叶斯推理、用于预测漂移的LSTM网络以及用于自适应干预的以人为中心的治理层。

Result: 实验结果表明，在模拟中，集成概率漂移检测、预测分析和自适应治理可以将价值漂移事件减少80%或更多，同时保持高检测精度（85%）和低误报率（适应后为0.08）。

Conclusion: MAS的原创性在于其预测性和适应性，与静态对齐方法形成对比。

Abstract: The rise of artificial intelligence (AI) as super-capable assistants has
transformed productivity and decision-making across domains. Yet, this
integration raises critical concerns about value alignment - ensuring AI
behaviors remain consistent with human ethics and intentions. A key risk is
value drift, where AI systems deviate from aligned values due to evolving
contexts, learning dynamics, or unintended optimizations, potentially leading
to inefficiencies or ethical breaches. We propose the Moral Anchor System
(MAS), a novel framework to detect, predict, and mitigate value drift in AI
agents. MAS combines real-time Bayesian inference for monitoring value states,
LSTM networks for forecasting drift, and a human-centric governance layer for
adaptive interventions. It emphasizes low-latency responses (<20 ms) to prevent
breaches, while reducing false positives and alert fatigue via supervised
fine-tuning with human feedback. Our hypothesis: integrating probabilistic
drift detection, predictive analytics, and adaptive governance can reduce value
drift incidents by 80 percent or more in simulations, maintaining high
detection accuracy (85 percent) and low false positive rates (0.08
post-adaptation). Rigorous experiments with goal-misaligned agents validate
MAS's scalability and responsiveness. MAS's originality lies in its predictive
and adaptive nature, contrasting static alignment methods. Contributions
include: (1) MAS architecture for AI integration; (2) empirical results
prioritizing speed and usability; (3) cross-domain applicability insights; and
(4) open-source code for replication.

</details>


### [124] [SPOGW: a Score-based Preference Optimization method via Group-Wise comparison for workflows](https://arxiv.org/abs/2510.04089)
*Yitong Cui,Liu Liu,Baosheng Yu,Jiayan Qiu,Xikai Zhang,Likang Xiao,Yixing Liu,Quan Chen*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于分数的偏好方法SPOGW，用于自动生成和优化agentic工作流。


<details>
  <summary>Details</summary>
Motivation: 目前agentic工作流的设计需要大量的人工干预，并且现有方法存在表示能力有限、适应性不足、可扩展性弱以及成对比较范式等问题。

Method: SPOGW通过组间比较直接在基数奖励信号上操作，并在连续空间中实现更高效和稳定的优化。SPOGW结合了迭代离线GRPO (ioGRPO)和优势掩蔽KL散度 (mKL)，通过更加强调策略响应的有利区域来调节训练更新。

Result: 在涵盖数学推理、编码和问题回答的五个基准数据集上，SPOGW与当前最先进的方法的性能相匹配或超过了它们。

Conclusion: SPOGW为自动生成和优化agentic工作流提供了一种可行且前瞻性的方法。

Abstract: Large language models (LLMs) have exhibited significant capabilities in
addressing challenging problems throughout various fields, often through the
use of agentic workflows that adhere to structured instructions and multi-step
procedures. However, designing such workflows demands substantial manual
effort, posing challenges to scalability and generalizability. Recent studies
have aimed to minimize the human intervention needed for their construction,
leading to advances in automated techniques for optimizing agentic workflows.
However, current approaches are often constrained by their limited
representational capacity, insufficient adaptability, weak scalability, and
pairwise comparison paradigm -- issues that stem primarily from a dependence on
discrete optimization techniques. To overcome these limitations, we introduce a
new score-based preference approach, refereed as SPOGW, which operates directly
on cardinal reward signals through group-wise comparison and enables more
efficient and stable optimization in a continuous space. SPOGW incorporates
Iterative offline GRPO (ioGRPO) with advantage-masked KL divergence (mKL),
which regulates training update by placing greater emphasis on the advantageous
regions of the policy response. In five benchmark datasets covering
mathematical reasoning, coding, and question answering, SPOGW matches or
exceeds the performance of current state-of-the-art approaches, presenting a
viable and forward-looking methodology for automated generation and
optimization of agentic workflows.

</details>


### [125] [Harnessing LLM for Noise-Robust Cognitive Diagnosis in Web-Based Intelligent Education Systems](https://arxiv.org/abs/2510.04093)
*Guixian Zhang,Guan Yuan,Ziqi Xu,Yanmei Zhang,Zhenyun Deng,Debo Cheng*

Main category: cs.AI

TL;DR: 提出了一种基于扩散的LLM框架DLLM，用于噪声鲁棒的认知诊断。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在认知诊断中难以处理结构化数据，且易受噪声干扰，Web环境下的数据不平衡和噪声问题更加严重。

Method: 构建基于响应正确性的独立子图，应用关系增强对齐模块缓解数据不平衡，融合子图表示并与LLM语义增强表示对齐。在对齐前，使用两阶段去噪扩散模块消除噪声。

Result: 在三个公开数据集上的实验结果表明，DLLM在不同噪声水平下均能实现最佳预测性能。

Conclusion: DLLM实现了噪声鲁棒性，并有效利用了LLM的语义知识。

Abstract: Cognitive diagnostics in the Web-based Intelligent Education System (WIES)
aims to assess students' mastery of knowledge concepts from heterogeneous,
noisy interactions. Recent work has tried to utilize Large Language Models
(LLMs) for cognitive diagnosis, yet LLMs struggle with structured data and are
prone to noise-induced misjudgments. Specially, WIES's open environment
continuously attracts new students and produces vast amounts of response logs,
exacerbating the data imbalance and noise issues inherent in traditional
educational systems. To address these challenges, we propose DLLM, a
Diffusion-based LLM framework for noise-robust cognitive diagnosis. DLLM first
constructs independent subgraphs based on response correctness, then applies
relation augmentation alignment module to mitigate data imbalance. The two
subgraph representations are then fused and aligned with LLM-derived,
semantically augmented representations. Importantly, before each alignment
step, DLLM employs a two-stage denoising diffusion module to eliminate
intrinsic noise while assisting structural representation alignment.
Specifically, unconditional denoising diffusion first removes erroneous
information, followed by conditional denoising diffusion based on graph-guided
to eliminate misleading information. Finally, the noise-robust representation
that integrates semantic knowledge and structural information is fed into
existing cognitive diagnosis models for prediction. Experimental results on
three publicly available web-based educational platform datasets demonstrate
that our DLLM achieves optimal predictive performance across varying noise
levels, which demonstrates that DLLM achieves noise robustness while
effectively leveraging semantic knowledge from LLM.

</details>


### [126] [WebRenderBench: Enhancing Web Interface Generation through Layout-Style Consistency and Reinforcement Learning](https://arxiv.org/abs/2510.04097)
*Peichao Lai,Jinhui Zhuang,Kexuan Zhang,Ningchang Xiong,Shengjie Wang,Yanwei Xu,Chong Chen,Yilei Wang,Bin Cui*

Main category: cs.AI

TL;DR: 本研究提出了一个名为WebRenderBench的大规模网页UI到代码转换的基准，并提出了一种新的评估指标来衡量布局和样式的一致性。此外，还介绍了一个名为ALISA的智能体，它将这个指标整合到强化学习中，以提高在爬取的非对称网页上的训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有的WebUI到代码的基准在数据多样性和评估可靠性方面仍然有限。

Method: 1. 提出了WebRenderBench基准，包含22.5k个来自真实门户网站的网页。2. 提出了一种新的评估指标，用于测量最终渲染页面的布局和样式一致性。3. 引入了ALISA，它将评估指标整合到强化学习中。

Result: ALISA显著提高了生成性能，在多个指标上实现了最先进的结果。

Conclusion: 该研究提出的WebRenderBench基准和ALISA智能体能够有效提升WebUI到代码的转换效果，并在非对称网页上实现更好的训练。

Abstract: Automating the conversion of UI images into web code is a critical task for
front-end development and rapid prototyping. Advances in multimodal large
language models (MLLMs) have made WebUI-to-Code increasingly feasible, yet
existing benchmarks remain limited in data diversity and evaluation
reliability. To address these issues, we present WebRenderBench, a large-scale
benchmark of 22.5k webpages collected from real-world portal sites, offering
greater diversity, complexity, and realism than prior benchmarks. We further
propose a novel evaluation metric that measures layout and style consistency
from the final rendered pages. Unlike vision-based methods that rely on costly
LLM reasoning or structure-based comparisons vulnerable to noise and asymmetry,
our approach enables more efficient, objective, and reliable UI quality
assessment. Finally, we introduce the Automated Layout and Style Inspection
Agent (ALISA), which integrates this metric into reinforcement learning as a
reward signal to enhance training on crawled asymmetric webpages. Experiments
show that ALISA significantly boosts generation performance, achieving
state-of-the-art results across multiple metrics.

</details>


### [127] [Searching Meta Reasoning Skeleton to Guide LLM Reasoning](https://arxiv.org/abs/2510.04116)
*Ziying Zhang,Yaqing Wang,Quanming Yao*

Main category: cs.AI

TL;DR: 本文提出了一种名为AutoMR的框架，该框架通过有向无环图(DAG)表示元推理骨架，并自动搜索查询感知的元推理骨架，以提高大型语言模型(LLM)的推理性能。


<details>
  <summary>Details</summary>
Motivation: 先前研究使用手动设计的结构实现元推理骨架，限制了适应特定查询需求和捕获推理步骤之间复杂逻辑依赖关系的能力。

Method: 该方法使用有向无环图(DAG)表示元推理骨架，并设计了一种动态骨架抽样算法，该算法可以在推理时随着推理上下文扩展元推理骨架，从而实现高效的查询感知骨架搜索。

Result: 在广泛的基准数据集上的实验结果表明，AutoMR在推理性能方面优于以往的研究。

Conclusion: AutoMR框架能够有效地搜索查询感知的元推理骨架，从而提高大型语言模型的推理性能。

Abstract: Meta reasoning behaviors work as a skeleton to guide large language model
(LLM) reasoning, thus help to improve reasoning performance. However, prior
researches implement meta reasoning skeleton with manually designed structure,
limiting ability to adapt to query-specific requirement and capture intricate
logical dependency among reasoning steps. To deal with the challenges, we
represent meta reasoning skeleton with directed acyclic graph (DAG) to unify
skeletons proposed in prior works and model intricate logical dependency. Then
we propose AutoMR, a framework that searches for query-aware meta reasoning
skeleton automatically inspired by automated machine learning (AutoML).
Specifically, we construct search space based on DAG representation of skeleton
and then formulate the search problem. We design a dynamic skeleton sampling
algorithm by expanding meta reasoning skeleton along with reasoning context at
inference time. This algorithm can derive any meta reasoning skeleton in search
space efficiently and adapt skeleton to evolving base reasoning context, thus
enable efficient query-aware skeleton search. We conduct experiments on
extensive benchmark datasets. Experimental results show that AutoMR achieves
better reasoning performance than previous works broadly.

</details>


### [128] [Internal states before wait modulate reasoning patterns](https://arxiv.org/abs/2510.04128)
*Dmitrii Troitskii,Koyena Pal,Chris Wendler,Callum Stuart McDougall,Neel Nanda*

Main category: cs.AI

TL;DR: 本文研究了推理模型中wait token之前的模型潜在信息是否包含调节后续推理过程的相关信息。


<details>
  <summary>Details</summary>
Motivation: 先前的研究表明，推理模型中的wait token是推理能力和自我纠正能力的重要标志，但对其具体原因知之甚少，限制了我们对有效推理模型的理解。

Method: 通过训练DeepSeek-R1-Distill-Llama-8B及其基础版本的多个层的交叉编码器，并引入交叉编码器设置中的潜在属性技术，来定位促进/抑制wait token概率的相关特征。

Result: 找到了与推理过程相关的少量特征，这些特征会引起不同类型的推理模式，例如从头开始、回忆先验知识、表达不确定性和仔细检查。

Conclusion: 证明了识别出的许多特征确实与推理过程相关，并引起不同类型的推理模式。

Abstract: Prior work has shown that a significant driver of performance in reasoning
models is their ability to reason and self-correct. A distinctive marker in
these reasoning traces is the token wait, which often signals reasoning
behavior such as backtracking. Despite being such a complex behavior, little is
understood of exactly why models do or do not decide to reason in this
particular manner, which limits our understanding of what makes a reasoning
model so effective. In this work, we address the question whether model's
latents preceding wait tokens contain relevant information for modulating the
subsequent reasoning process. We train crosscoders at multiple layers of
DeepSeek-R1-Distill-Llama-8B and its base version, and introduce a latent
attribution technique in the crosscoder setting. We locate a small set of
features relevant for promoting/suppressing wait tokens' probabilities.
Finally, through a targeted series of experiments analyzing max activating
examples and causal interventions, we show that many of our identified features
indeed are relevant for the reasoning process and give rise to different types
of reasoning patterns such as restarting from the beginning, recalling prior
knowledge, expressing uncertainty, and double-checking.

</details>


### [129] [Selective Expert Guidance for Effective and Diverse Exploration in Reinforcement Learning of LLMs](https://arxiv.org/abs/2510.04140)
*Zishang Jiang,Jinyi Han,Tingyun Li,Xinyi Wang,Sihang Jiang,Jiaqing Liang,Zhaoqian Dai,Shuguang Ma,Fei Yu,Yanghua Xiao*

Main category: cs.AI

TL;DR: 提出MENTOR，一种混合策略专家导航框架，用于在RLVR中进行有效和多样化的探索。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖于基础模型的能力，且通过模仿专家轨迹来提高效果，忽略了多样性。

Method: 仅在关键决策点提供专家指导，以进行token级别的推理优化。

Result: MENTOR使模型能够捕捉专家策略的本质，从而执行高质量的探索并实现卓越的整体性能。

Conclusion: MENTOR通过在关键决策点提供专家指导，实现了RLVR中有效和多样化的探索。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has become a widely
adopted technique for enhancing the reasoning ability of Large Language Models
(LLMs). However, the effectiveness of RLVR strongly depends on the capability
of base models. This issue arises because it requires the model to have
sufficient capability to perform high-quality exploration, which involves both
effectiveness and diversity. Unfortunately, existing methods address this issue
by imitating expert trajectories, which improve effectiveness but neglect
diversity. To address this, we argue that the expert only needs to provide
guidance only at critical decision points rather than the entire reasoning
path. Based on this insight, we propose MENTOR: Mixed-policy Expert Navigation
for Token-level Optimization of Reasoning, a framework that provides expert
guidance only at critical decision points to perform effective and diverse
exploration in RLVR. Extensive experiments show that MENTOR enables models
capture the essence of expert strategies rather than surface imitation, thereby
performing high-quality exploration and achieving superior overall performance.
Our code is available online.

</details>


### [130] [The Artificial Intelligence Cognitive Examination: A Survey on the Evolution of Multimodal Evaluation from Recognition to Reasoning](https://arxiv.org/abs/2510.04141)
*Mayank Ravishankara,Varindra V. Persad Maharaj*

Main category: cs.AI

TL;DR: 多模态人工智能评估已经从简单的识别任务发展到复杂的推理基准。


<details>
  <summary>Details</summary>
Motivation: 旧的基准已经饱和，高性能通常掩盖了根本的弱点。我们需要重新定义创建真正智能系统的目标。

Method: 本文回顾了多模态人工智能评估的演变，将其视为越来越复杂的“认知检查”的演变。

Result: 多模态人工智能评估已经从ImageNet时代的“知识测试”发展到GQA和VCR等“应用逻辑和理解”测试，再到MMBench、SEED-Bench和MMMU等“专家级整合”基准。

Conclusion: 人工智能评估不仅仅是数据集的历史，而是一个持续的、对抗性的过程，旨在设计更好的检查，从而重新定义我们创建真正智能系统的目标。

Abstract: This survey paper chronicles the evolution of evaluation in multimodal
artificial intelligence (AI), framing it as a progression of increasingly
sophisticated "cognitive examinations." We argue that the field is undergoing a
paradigm shift, moving from simple recognition tasks that test "what" a model
sees, to complex reasoning benchmarks that probe "why" and "how" it
understands. This evolution is driven by the saturation of older benchmarks,
where high performance often masks fundamental weaknesses. We chart the journey
from the foundational "knowledge tests" of the ImageNet era to the "applied
logic and comprehension" exams such as GQA and Visual Commonsense Reasoning
(VCR), which were designed specifically to diagnose systemic flaws such as
shortcut learning and failures in compositional generalization. We then survey
the current frontier of "expert-level integration" benchmarks (e.g., MMBench,
SEED-Bench, MMMU) designed for today's powerful multimodal large language
models (MLLMs), which increasingly evaluate the reasoning process itself.
Finally, we explore the uncharted territories of evaluating abstract, creative,
and social intelligence. We conclude that the narrative of AI evaluation is not
merely a history of datasets, but a continuous, adversarial process of
designing better examinations that, in turn, redefine our goals for creating
truly intelligent systems.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [131] [Is it Bigger than a Breadbox: Efficient Cardinality Estimation for Real World Workloads](https://arxiv.org/abs/2510.03386)
*Zixuan Yi,Sami Abu-el-Haija,Yawen Wang,Teja Vemparala,Yannis Chronis,Yu Gan,Michael Burrows,Carsten Binnig,Bryan Perozzi,Ryan Marcus,Fatma Ozcan*

Main category: cs.DB

TL;DR: 这篇论文提出了一种新的基于学习的基数估计方法，该方法通过在线学习许多简单的回归器，每个回归器都针对一个特定的子查询模式进行优化，从而在准确性和效率之间取得了平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的数据库引擎依赖于成本模型来生成高效的查询执行计划，但这些成本模型中的基数估计通常使用启发式方法，并且误差会随着查询复杂性的增加而显著增长。基于学习的估计器虽然可以提高准确性，但会增加操作复杂性。

Method: 该方法通过在线学习许多简单的回归器，每个回归器都针对一个特定的子查询模式进行优化。与模式相对应的回归器可以使用子查询图结构的哈希值进行随机访问。

Result: 该方法在误差指标上与最先进的基于学习的方法具有竞争力，并且在PostgreSQL中实现了显著的准确性和运行时改进。

Conclusion: 该方法与传统的基数估计方法相比，具有更高的准确性和更低的运行时开销，与其他学习的基数估计器相比，大大降低了运营成本，从而在Pareto前沿提供了最实用和高效的解决方案。

Abstract: DB engines produce efficient query execution plans by relying on cost models.
Practical implementations estimate cardinality of queries using heuristics,
with magic numbers tuned to improve average performance on benchmarks.
Empirically, estimation error significantly grows with query complexity.
Alternatively, learning-based estimators offer improved accuracy, but add
operational complexity preventing their adoption in-practice. Recognizing that
query workloads contain highly repetitive subquery patterns, we learn many
simple regressors online, each localized to a pattern. The regressor
corresponding to a pattern can be randomly-accessed using hash of graph
structure of the subquery. Our method has negligible overhead and competes with
SoTA learning-based approaches on error metrics. Further, amending PostgreSQL
with our method achieves notable accuracy and runtime improvements over
traditional methods and drastically reduces operational costs compared to other
learned cardinality estimators, thereby offering the most practical and
efficient solution on the Pareto frontier. Concretely, simulating JOB-lite
workload on IMDb speeds-up execution by 7.5 minutes (>30%) while incurring only
37 seconds overhead for online learning.

</details>


### [132] [Dual Pruning and Sorting-Free Overestimation for Average-Utility Sequential Pattern Mining](https://arxiv.org/abs/2510.04014)
*Kai Cao,Yucong Duan,Wensheng Gan*

Main category: cs.DB

TL;DR: 本文提出了一种名为 HAUSP-PG 的新算法，用于高效挖掘高平均效用序列模式。


<details>
  <summary>Details</summary>
Motivation: 现有的高实用性序列模式挖掘算法在高价值长序列的挖掘中效率较低，且高平均效用序列模式挖掘比高实用性序列模式挖掘更公平、更有价值。

Method: 该算法采用两种互补策略独立处理模式前缀和剩余序列，实现双重剪枝效果，并提出了一种无需项目排序的平均效用上界计算方法。

Result: 实验结果表明，该算法在真实和合成数据集上均能取得令人满意的性能。

Conclusion: 提出的 HAUSP-PG 算法能够有效提升高平均效用序列模式的挖掘效率，特别是在处理长序列时。

Abstract: In a quantitative sequential database, numerous efficient algorithms have
been developed for high-utility sequential pattern mining (HUSPM). HUSPM
establishes a relationship between frequency and significance in the real world
and reflects more crucial information than frequent pattern mining. However,
high average-utility sequential pattern mining (HAUSPM) is deemed fairer and
more valuable than HUSPM. It provides a reasonable measure for longer patterns
by considering their length. In contrast to scenarios in retail business
analysis, some pattern mining applications, such as cybersecurity or artificial
intelligence (AI), often involve much longer sequences. Consequently, pruning
strategies can exert a more pronounced impact on efficiency. This paper
proposes a novel algorithm named HAUSP-PG, which adopts two complementary
strategies to independently process pattern prefixes and remaining sequences,
thereby achieving a dual pruning effect. Additionally, the proposed method
calculates average utility upper bounds without requiring item sorting,
significantly reducing computational time and memory consumption compared to
alternative approaches. Through experiments conducted on both real-life and
synthetic datasets, we demonstrate that the proposed algorithm could achieve
satisfactory performance.

</details>


### [133] [Ambidextrous Degree Sequence Bounds for Pessimistic Cardinality Estimation](https://arxiv.org/abs/2510.04249)
*Yu-Ting Lin,Hsin-Po Wang*

Main category: cs.DB

TL;DR: 这篇论文提出了一种新的基数估计方法，该方法在连接查询中更准确地估计连接大小的上限。


<details>
  <summary>Details</summary>
Motivation: 在大型数据库系统中，悲观基数估计是评估连接查询基数的关键任务。现有的方法存在高估的问题。

Method: 该论文引入了“灵巧”边界的概念，通过计算底层图中的“爪对”来改进基数估计。

Result: 新提出的“灵巧”边界在理论上不比旧边界差，并且在实验上更紧密。例如，在计算com-Youtube数据集中的朋友三元组时，最佳灵巧边界为5.1 * 10^8，而实际基数为1.8 * 10^7。

Conclusion: 该论文提出的新方法能够更有效地进行基数估计，减少了高估的程度。

Abstract: In a large database system, upper-bounding the cardinality of a join query is
a crucial task called $\textit{pessimistic cardinality estimation}$. Recently,
Abo Khamis, Nakos, Olteanu, and Suciu unified related works into the following
dexterous framework. Step 1: Let $(X_1, \dotsc, X_n)$ be a random row of the
join, equating $H(X_1, \dotsc, X_n)$ to the log of the join cardinality. Step
2: Upper-bound $H(X_1, \dotsc, X_n)$ using Shannon-type inequalities such as
$H(X, Y, Z) \le H(X) + H(Y|X) + H(Z|Y)$. Step 3: Upper-bound $H(X_i) + p H(X_j
| X_i)$ using the $p$-norm of the degree sequence of the underlying graph of a
relation.
  While old bound in step 3 count "claws $\in$" in the underlying graph, we
proposed $\textit{ambidextrous}$ bounds that count "claw pairs
${\ni}\!{-}\!{\in}$". The new bounds are provably not looser and empirically
tighter: they overestimate by $x^{3/4}$ times when the old bounds overestimate
by $x$ times. An example is counting friend triples in the
$\texttt{com-Youtube}$ dataset, the best dexterous bound is $1.2 \cdot 10^9$,
the best ambidextrous bound is $5.1 \cdot 10^8$, and the actual cardinality is
$1.8 \cdot 10^7$.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [134] [Evaluating High-Resolution Piano Sustain Pedal Depth Estimation with Musically Informed Metrics](https://arxiv.org/abs/2510.03750)
*Hanwen Zhang,Kun Fang,Ziyu Wang,Ichiro Fujinaga*

Main category: cs.IR

TL;DR: 提出了一种评估钢琴踏板深度估计任务的新框架，该框架不仅使用传统的帧级别指标，还结合了动作级别和手势级别的分析，以捕捉音乐上重要的特征。


<details>
  <summary>Details</summary>
Motivation: 传统的帧级别指标在评估钢琴踏板深度估计任务时不够完善，忽略了音乐上重要的特征，如方向变化边界和踏板曲线轮廓。

Method: 该框架通过测量压/保持/释放状态的片段的方向和时间来评估动作级别，并通过评估每个压-放周期的轮廓相似性来评估手势级别。将该框架应用于比较纯音频基线与两个变体：一个结合了来自MIDI的符号信息，另一个在二元值设置中训练，所有这些都在统一的架构中。

Result: 结果表明，尽管帧级别增益不大，但知情的MIDI模型在动作和手势级别上明显优于其他模型。表明该框架捕获了传统指标无法辨别的音乐相关改进。

Conclusion: 该框架提供了一种更实用、更有效的评估踏板深度估计模型的方法。

Abstract: Evaluation for continuous piano pedal depth estimation tasks remains
incomplete when relying only on conventional frame-level metrics, which
overlook musically important features such as direction-change boundaries and
pedal curve contours. To provide more interpretable and musically meaningful
insights, we propose an evaluation framework that augments standard frame-level
metrics with an action-level assessment measuring direction and timing using
segments of press/hold/release states and a gesture-level analysis that
evaluates contour similarity of each press-release cycle. We apply this
framework to compare an audio-only baseline with two variants: one
incorporating symbolic information from MIDI, and another trained in a
binary-valued setting, all within a unified architecture. Results show that the
MIDI-informed model significantly outperforms the others at action and gesture
levels, despite modest frame-level gains. These findings demonstrate that our
framework captures musically relevant improvements indiscernible by traditional
metrics, offering a more practical and effective approach to evaluating pedal
depth estimation models.

</details>


### [135] [Investigating LLM Variability in Personalized Conversational Information Retrieval](https://arxiv.org/abs/2510.03795)
*Simon Lupart,Daniël van Dijk,Eric Langezaal,Ian van Dort,Mohammad Aliannejadi*

Main category: cs.IR

TL;DR: 该研究重现并扩展了Mo等人在个性化对话信息检索（CIR）方面的工作，发现人工选择的个人文本知识库（PTKB）始终提高检索性能，而基于LLM的选择方法则不然。该研究强调了多轮评估和方差报告的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化CIR研究依赖于GPT-3.5 Turbo模型的单次运行实验，结果可能存在变异性和可重复性问题。该研究旨在通过更广泛的模型和数据集评估来解决这些问题。

Method: 该研究重现了Mo等人的方法，并将其应用于新的TREC iKAT 2024数据集，评估了包括Llama、Qwen和GPT-4o-mini在内的多种模型。同时，比较了不同数据集上的方差，并分析了不同指标的变异性。

Result: 研究结果表明，人工选择的PTKB始终提高检索性能，而基于LLM的选择方法则不然。此外，iKAT数据集上的变异性高于CAsT数据集，且面向召回率的指标比面向精确率的指标表现出更低的方差。

Conclusion: 该研究强调了在评估基于LLM的CIR系统时，需要进行多轮评估和方差报告，并建议在更广泛的模型、数据集和指标上进行评估，以实现更稳健和通用的个性化CIR实践。

Abstract: Personalized Conversational Information Retrieval (CIR) has seen rapid
progress in recent years, driven by the development of Large Language Models
(LLMs). Personalized CIR aims to enhance document retrieval by leveraging
user-specific information, such as preferences, knowledge, or constraints, to
tailor responses to individual needs. A key resource for this task is the TREC
iKAT 2023 dataset, designed to evaluate personalization in CIR pipelines.
Building on this resource, Mo et al. explored several strategies for
incorporating Personal Textual Knowledge Bases (PTKB) into LLM-based query
reformulation. Their findings suggested that personalization from PTKBs could
be detrimental and that human annotations were often noisy. However, these
conclusions were based on single-run experiments using the GPT-3.5 Turbo model,
raising concerns about output variability and repeatability. In this
reproducibility study, we rigorously reproduce and extend their work, focusing
on LLM output variability and model generalization. We apply the original
methods to the new TREC iKAT 2024 dataset and evaluate a diverse range of
models, including Llama (1B-70B), Qwen-7B, GPT-4o-mini. Our results show that
human-selected PTKBs consistently enhance retrieval performance, while
LLM-based selection methods do not reliably outperform manual choices. We
further compare variance across datasets and observe higher variability on iKAT
than on CAsT, highlighting the challenges of evaluating personalized CIR.
Notably, recall-oriented metrics exhibit lower variance than precision-oriented
ones, a critical insight for first-stage retrievers. Finally, we underscore the
need for multi-run evaluations and variance reporting when assessing LLM-based
CIR systems. By broadening evaluation across models, datasets, and metrics, our
study contributes to more robust and generalizable practices for personalized
CIR.

</details>


### [136] [Beyond Static Evaluation: Rethinking the Assessment of Personalized Agent Adaptability in Information Retrieval](https://arxiv.org/abs/2510.03984)
*Kirandeep Kaur,Preetam Prabhu Srikar Dammu,Hideo Joho,Chirag Shah*

Main category: cs.IR

TL;DR: 本文提出了一种评估自适应个性化AI agent的新视角，从静态性能转向交互感知的演进评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法无法反映用户需求随时间演变，阻碍了评估agents在动态交互中适应个体用户能力。

Method: 提出一个包含三个核心组件的评估框架：基于用户画像的、具有时间演变偏好模型的用户模拟；受访谈启发的、结构化的诱导协议，用于提取上下文偏好；以及能够衡量agent行为在会话和任务中改进程度的、适应感知的评估机制。

Result: 通过在PersonalWAB数据集上进行电商搜索的案例研究，展示了所提出的框架。

Conclusion: 本文为理解和评估个性化提供了一个概念基础，将其视为一个持续的、以用户为中心的努力。

Abstract: Personalized AI agents are becoming central to modern information retrieval,
yet most evaluation methodologies remain static, relying on fixed benchmarks
and one-off metrics that fail to reflect how users' needs evolve over time.
These limitations hinder our ability to assess whether agents can meaningfully
adapt to individuals across dynamic, longitudinal interactions. In this
perspective paper, we propose a conceptual lens for rethinking evaluation in
adaptive personalization, shifting the focus from static performance snapshots
to interaction-aware, evolving assessments. We organize this lens around three
core components: (1) persona-based user simulation with temporally evolving
preference models; (2) structured elicitation protocols inspired by reference
interviews to extract preferences in context; and (3) adaptation-aware
evaluation mechanisms that measure how agent behavior improves across sessions
and tasks. While recent works have embraced LLM-driven user simulation, we
situate this practice within a broader paradigm for evaluating agents over
time. To illustrate our ideas, we conduct a case study in e-commerce search
using the PersonalWAB dataset. Beyond presenting a framework, our work lays a
conceptual foundation for understanding and evaluating personalization as a
continuous, user-centric endeavor.

</details>


### [137] [Visual Lifelog Retrieval through Captioning-Enhanced Interpretation](https://arxiv.org/abs/2510.04010)
*Yu-Fei Shih,An-Zi Yen,Hen-Hsen Huang,Hsin-Hsi Chen*

Main category: cs.IR

TL;DR: 提出了一种名为CIVIL的视觉生活日志检索系统，该系统通过为视觉生活日志生成标题并使用文本嵌入模型将标题和用户查询投影到共享向量空间中来实现。


<details>
  <summary>Details</summary>
Motivation: 为了解决人们难以记住过去经历的具体细节，需要重新审视这些记忆的问题，因此生活日志检索成为一项关键应用。

Method: 该系统首先为视觉生活日志生成标题，然后利用文本嵌入模型将标题和用户查询投影到共享向量空间中。此外，还提出了三种不同的方法：单标题法、集体标题法和合并标题法，每种方法都旨在解释生活记录者的生活经历。

Result: 实验结果表明，该方法有效地描述了第一人称视觉图像，从而提高了生活日志检索的结果。

Conclusion: 该方法能够有效地描述第一人称视觉图像，增强生活日志检索的效果。此外，还构建了一个文本数据集，可以将视觉生活日志转换为标题，从而重建个人生活体验。

Abstract: People often struggle to remember specific details of past experiences, which
can lead to the need to revisit these memories. Consequently, lifelog retrieval
has emerged as a crucial application. Various studies have explored methods to
facilitate rapid access to personal lifelogs for memory recall assistance. In
this paper, we propose a Captioning-Integrated Visual Lifelog (CIVIL) Retrieval
System for extracting specific images from a user's visual lifelog based on
textual queries. Unlike traditional embedding-based methods, our system first
generates captions for visual lifelogs and then utilizes a text embedding model
to project both the captions and user queries into a shared vector space.
Visual lifelogs, captured through wearable cameras, provide a first-person
viewpoint, necessitating the interpretation of the activities of the individual
behind the camera rather than merely describing the scene. To address this, we
introduce three distinct approaches: the single caption method, the collective
caption method, and the merged caption method, each designed to interpret the
life experiences of lifeloggers. Experimental results show that our method
effectively describes first-person visual images, enhancing the outcomes of
lifelog retrieval. Furthermore, we construct a textual dataset that converts
visual lifelogs into captions, thereby reconstructing personal life
experiences.

</details>


### [138] [The LCLStream Ecosystem for Multi-Institutional Dataset Exploration](https://arxiv.org/abs/2510.04012)
*David Rogers,Valerio Mariani,Cong Wang,Ryan Coffee,Wilko Kroeger,Murali Shankar,Hans Thorsten Schwander,Tom Beck,Frédéric Poitevin,Jana Thayer*

Main category: cs.IR

TL;DR: LCLStreamer是一个新的端到端实验数据流框架，旨在支持新型应用，如AI训练和高通量X射线分析。


<details>
  <summary>Details</summary>
Motivation: 为X射线科学数据分析社区提供高速数据流源，满足日益增长的需求。

Method: 结合云微服务与传统HPC批处理执行模型，实现安全性和灵活性。

Result: LCLStreamer框架已为未来实验原型设计并实施了几个关键的新范例。

Conclusion: LCLStreamer通过其灵活的API驱动数据请求服务，为DOE集成研究基础设施做出了独特的贡献。

Abstract: We describe a new end-to-end experimental data streaming framework designed
from the ground up to support new types of applications -- AI training,
extremely high-rate X-ray time-of-flight analysis, crystal structure
determination with distributed processing, and custom data science applications
and visualizers yet to be created. Throughout, we use design choices merging
cloud microservices with traditional HPC batch execution models for security
and flexibility. This project makes a unique contribution to the DOE Integrated
Research Infrastructure (IRI) landscape. By creating a flexible, API-driven
data request service, we address a significant need for high-speed data
streaming sources for the X-ray science data analysis community. With the
combination of data request API, mutual authentication web security framework,
job queue system, high-rate data buffer, and complementary nature to facility
infrastructure, the LCLStreamer framework has prototyped and implemented
several new paradigms critical for future generation experiments.

</details>


### [139] [RLRF: Competitive Search Agent Design via Reinforcement Learning from Ranker Feedback](https://arxiv.org/abs/2510.04096)
*Tommy Mordo,Sagie Dekel,Omer Madmon,Moshe Tennenholtz,Oren Kurland*

Main category: cs.IR

TL;DR: 提出了一种新的框架，即基于排序器反馈的强化学习（RLRF），用于训练LLM以改进竞争性搜索中的文档排序。


<details>
  <summary>Details</summary>
Motivation: 文档发布者越来越多地利用LLM来生成和修改竞争性内容，以提高其在查询中的排名。

Method: 使用从排名竞争中获得的偏好数据集来训练LLM。

Result: 该方法始终且大幅优于以前提出的基于LLM的竞争性文档修改方法，并且对未训练过的排序函数有效，能够适应战略对手。

Conclusion: 强化学习在竞争性搜索中具有巨大的潜力。

Abstract: Competitive search is a setting where document publishers modify them to
improve their ranking in response to a query. Recently, publishers have
increasingly leveraged LLMs to generate and modify competitive content. We
introduce Reinforcement Learning from Ranker Feedback (RLRF), a framework that
trains LLMs using preference datasets derived from ranking competitions. The
goal of a publisher (LLM-based) agent is to optimize content for improved
ranking while accounting for the strategies of competing agents. We generate
the datasets using approaches that do not rely on human-authored data. We show
that our proposed agents consistently and substantially outperform previously
suggested approaches for LLM-based competitive document modification. We
further show that our agents are effective with ranking functions they were not
trained for (i.e., out of distribution) and they adapt to strategic opponents.
These findings provide support to the significant potential of using
reinforcement learning in competitive search.

</details>


### [140] [Learning-Based Hashing for ANN Search: Foundations and Early Advances](https://arxiv.org/abs/2510.04127)
*Sean Moran*

Main category: cs.IR

TL;DR: 本文回顾了早期基于学习的哈希方法，重点介绍了塑造该领域的核心思想。


<details>
  <summary>Details</summary>
Motivation: 近似最近邻 (ANN) 搜索是信息检索中的一个基本问题，是计算机视觉、自然语言处理和跨模态搜索中大规模应用的基础。基于哈希的方法通过将高维数据映射到紧凑的二进制代码中来提供有效的解决方案，从而可以在 Hamming 空间中实现快速相似性计算。

Method: 本文回顾了有监督、无监督和半监督方法，重点介绍了如何设计投影函数以生成有意义的嵌入，以及量化策略如何将这些嵌入转换为二进制代码。本文还研究了多位和多阈值模型的扩展，以及跨模态检索的早期进展。

Result: 本文对早期基于学习的哈希方法进行了基础性调查，重点介绍了塑造该领域的核心思想。

Conclusion: 本文的重点是介绍基于学习的哈希的的概念基础，而不是提供最新方法的详尽描述。通过将这些早期模型置于其历史背景中，旨在使读者对继续为该领域当前研究提供信息的原理、权衡和未决挑战有一个结构化的理解。

Abstract: Approximate Nearest Neighbour (ANN) search is a fundamental problem in
information retrieval, underpinning large-scale applications in computer
vision, natural language processing, and cross-modal search. Hashing-based
methods provide an efficient solution by mapping high-dimensional data into
compact binary codes that enable fast similarity computations in Hamming space.
Over the past two decades, a substantial body of work has explored learning to
hash, where projection and quantisation functions are optimised from data
rather than chosen at random.
  This article offers a foundational survey of early learning-based hashing
methods, with an emphasis on the core ideas that shaped the field. We review
supervised, unsupervised, and semi-supervised approaches, highlighting how
projection functions are designed to generate meaningful embeddings and how
quantisation strategies convert these embeddings into binary codes. We also
examine extensions to multi-bit and multi-threshold models, as well as early
advances in cross-modal retrieval.
  Rather than providing an exhaustive account of the most recent methods, our
goal is to introduce the conceptual foundations of learning-based hashing for
ANN search. By situating these early models in their historical context, we aim
to equip readers with a structured understanding of the principles, trade-offs,
and open challenges that continue to inform current research in this area.

</details>


### [141] [Empowering Denoising Sequential Recommendation with Large Language Model Embeddings](https://arxiv.org/abs/2510.04239)
*Tongzhou Wu,Yuhao Wang,Maolin Wang,Chi Zhang,Xiangyu Zhao*

Main category: cs.IR

TL;DR: 该论文提出了一种新的去噪序列推荐框架（IADSR），以解决传统序列推荐模型受噪声影响的问题。


<details>
  <summary>Details</summary>
Motivation: 传统序列推荐模型容易受到偶然交互等噪声的影响，导致性能下降。现有去噪方法过度依赖协同信息，尤其对于冷启动物品。

Method: IADSR框架包含两个阶段：首先，从传统序列推荐模型和LLM中获取物品的协同和语义嵌入；然后，对齐协同和语义嵌入，并基于协同和语义模态中捕获的长期和短期兴趣来识别交互序列中的噪声。

Result: 在四个公共数据集上的大量实验验证了所提出框架的有效性及其与不同序列推荐系统的兼容性。

Conclusion: 该论文提出的IADSR框架能够有效降低序列推荐模型中的噪声影响，提高推荐性能，并具有良好的通用性。

Abstract: Sequential recommendation aims to capture user preferences by modeling
sequential patterns in user-item interactions. However, these models are often
influenced by noise such as accidental interactions, leading to suboptimal
performance. Therefore, to reduce the effect of noise, some works propose
explicitly identifying and removing noisy items. However, we find that simply
relying on collaborative information may result in an over-denoising problem,
especially for cold items. To overcome these limitations, we propose a novel
framework: Interest Alignment for Denoising Sequential Recommendation (IADSR)
which integrates both collaborative and semantic information. Specifically,
IADSR is comprised of two stages: in the first stage, we obtain the
collaborative and semantic embeddings of each item from a traditional
sequential recommendation model and an LLM, respectively. In the second stage,
we align the collaborative and semantic embeddings and then identify noise in
the interaction sequence based on long-term and short-term interests captured
in the collaborative and semantic modalities. Our extensive experiments on four
public datasets validate the effectiveness of the proposed framework and its
compatibility with different sequential recommendation systems.

</details>


### [142] [Causality-aware Graph Aggregation Weight Estimator for Popularity Debiasing in Top-K Recommendation](https://arxiv.org/abs/2510.04502)
*Yue Que,Yingyi Zhang,Xiangyu Zhao,Chen Ma*

Main category: cs.IR

TL;DR: 提出了一种新的方法来减轻基于图的推荐系统中由于信息传播过程中的回声效应而产生的人气偏差，该方法通过对图聚合过程进行合理建模来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的去偏方法在充分缓解人气偏差方面仍然不足，因为它们没有提供对图聚合合理性的见解，因此缺乏最优性保证，并且它们未能很好地平衡训练和去偏过程，从而削弱了有效性。

Method: 我们揭示了图聚合是因果推理中后门调整的一种特殊形式，其中聚合权重对应于历史交互可能性分布。基于此，我们设计了一种编码器-解码器架构，即用于去偏的因果感知图聚合权重估计器 (CAGED)，通过优化交互可能性的证据下界来近似无偏聚合权重。为了增强早期训练阶段的去偏效果，我们进一步设计了一种动量更新策略，以逐步优化聚合权重矩阵。

Result: 在三个数据集上的大量实验表明，CAGED 优于现有的基于图的去偏方法。

Conclusion: 通过对图聚合过程的合理建模，CAGED有效地减轻了人气偏差，并在推荐性能上取得了显著提升。

Abstract: Graph-based recommender systems leverage neighborhood aggregation to generate
node representations, which is highly sensitive to popularity bias, resulting
in an echo effect during information propagation. Existing graph-based
debiasing solutions refine the aggregation process with attempts such as edge
reconstruction or weight adjustment. However, these methods remain inadequate
in fully alleviating popularity bias. Specifically, this is because 1) they
provide no insights into graph aggregation rationality, thus lacking an
optimality guarantee; 2) they fail to well balance the training and debiasing
process, which undermines the effectiveness. In this paper, we propose a novel
approach to mitigate popularity bias through rational modeling of the graph
aggregation process. We reveal that graph aggregation is a special form of
backdoor adjustment in causal inference, where the aggregation weight
corresponds to the historical interaction likelihood distribution. Based on
this insight, we devise an encoder-decoder architecture, namely Causality-aware
Graph Aggregation Weight Estimator for Debiasing (CAGED), to approximate the
unbiased aggregation weight by optimizing the evidence lower bound of the
interaction likelihood. In order to enhance the debiasing effectiveness during
early training stages, we further design a momentum update strategy that
incrementally refines the aggregation weight matrix. Extensive experiments on
three datasets demonstrate that CAGED outperforms existing graph-based
debiasing methods. Our implementation is available at
https://github.com/QueYork/CAGED.

</details>


### [143] [MARCO: A Cooperative Knowledge Transfer Framework for Personalized Cross-domain Recommendations](https://arxiv.org/abs/2510.04508)
*Lili Xie,Yi Zhang,Ruihong Qiu,Jiajun Liu,Sen Wang*

Main category: cs.IR

TL;DR: 提出了一种基于多智能体强化学习的跨域推荐框架(MARCO)，以解决数据稀疏性和冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的跨域推荐方法依赖于单智能体框架，导致由于不一致的领域贡献和固有的分布差异而产生的负迁移问题。

Method: 提出了一个基于多智能体强化学习的跨域推荐框架MARCO，其中每个智能体负责评估来自单个源领域的贡献，从而有效地管理信用分配并减轻负迁移。此外，引入了基于熵的动作多样性惩罚，通过鼓励不同的智能体的联合行动来增强策略表达能力并稳定训练。

Result: 在四个基准数据集上的大量实验表明，MARCO的性能优于最先进的方法，突出了其鲁棒性和强大的泛化能力。

Conclusion: MARCO框架有效地解决了跨域推荐中的数据稀疏性和冷启动问题，并通过多智能体强化学习实现了更好的性能和泛化能力。

Abstract: Recommender systems frequently encounter data sparsity issues, particularly
when addressing cold-start scenarios involving new users or items. Multi-source
cross-domain recommendation (CDR) addresses these challenges by transferring
valuable knowledge from multiple source domains to enhance recommendations in a
target domain. However, existing reinforcement learning (RL)-based CDR methods
typically rely on a single-agent framework, leading to negative transfer issues
caused by inconsistent domain contributions and inherent distributional
discrepancies among source domains. To overcome these limitations, MARCO, a
Multi-Agent Reinforcement Learning-based Cross-Domain recommendation framework,
is proposed. It leverages cooperative multi-agent reinforcement learning, where
each agent is dedicated to estimating the contribution from an individual
source domain, effectively managing credit assignment and mitigating negative
transfer. In addition, an entropy-based action diversity penalty is introduced
to enhance policy expressiveness and stabilize training by encouraging diverse
agents' joint actions. Extensive experiments across four benchmark datasets
demonstrate MARCO's superior performance over state-of-the-art methods,
highlighting its robustness and strong generalization capabilities. The code is
at https://github.com/xiewilliams/MARCO.

</details>


### [144] [Topic-Specific Classifiers are Better Relevance Judges than Prompted LLMs](https://arxiv.org/abs/2510.04633)
*Lukas Gienapp,Martin Potthast,Harrisen Scells,Eugene Yang*

Main category: cs.IR

TL;DR: 提出了一种新的处理未标注文档问题的方法，该方法通过训练特定主题的相关性分类器来对齐评估者的相关性概念。


<details>
  <summary>Details</summary>
Motivation: 未标注文档问题是信息检索中测试集可重用性的主要障碍。以往使用大型语言模型作为相关性判断器的方法存在循环论证的问题。

Method: 通过在单个评估者对单个主题池的判断上，使用独立的LoRA权重调整来微调monoT5，从而训练特定主题的相关性分类器。

Result: 该分类器获得的相关性判断与ground truth系统排序的Spearmans' ρ相关性>0.95。与将未判断的文档视为不相关相比，每个主题仅需128个初始人工判断即可提高模型的可比性，同时比现有的LLM-as-a-judge方法更可靠。

Conclusion: 主题特定的相关性分类器是解决未标注文档问题的一种轻量级且直接的方法，同时保持人工判断作为检索评估的黄金标准。代码、模型和数据已公开发布。

Abstract: The unjudged document problem, where pooled test collections have incomplete
relevance judgments for evaluating new retrieval systems, is a key obstacle to
the reusability of test collections in information retrieval. While the de
facto standard to deal with the problem is to treat unjudged documents as
non-relevant, many alternatives have been proposed, including the use of large
language models (LLMs) as a relevance judge (LLM-as-a-judge). However, this has
been criticized as circular, since the same LLM can be used as a judge and as a
ranker at the same time. We propose to train topic-specific relevance
classifiers instead: By finetuning monoT5 with independent LoRA weight
adaptation on the judgments of a single assessor for a single topic's pool, we
align it to that assessor's notion of relevance for the topic. The system
rankings obtained through our classifier's relevance judgments achieve a
Spearmans' $\rho$ correlation of $>0.95$ with ground truth system rankings. As
little as 128 initial human judgments per topic suffice to improve the
comparability of models, compared to treating unjudged documents as
non-relevant, while achieving more reliability than existing LLM-as-a-judge
approaches. Topic-specific relevance classifiers thus are a lightweight and
straightforward way to tackle the unjudged document problem, while maintaining
human judgments as the gold standard for retrieval evaluation. Code, models,
and data are made openly available.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [145] [PARS: Low-Latency LLM Serving via Pairwise Learning-to-Rank](https://arxiv.org/abs/2510.03243)
*Yiheng Tao,Yihe Zhang,Matthew T. Dearing,Xin Wang,Yuping Fan,Zhiling Lan*

Main category: cs.LG

TL;DR: 提出了一种名为PARS的prompt感知LLM任务调度器，通过近似最短作业优先（SJF）调度来提高服务效率。


<details>
  <summary>Details</summary>
Motivation: 传统的先来先服务（FCFS）调度策略容易受到队头阻塞（HOL）的影响，长任务会延迟排在后面的短任务。

Method: PARS通过pairwise ranking与margin ranking loss相结合，预测基于响应长度的任务排序。

Result: PARS显著提高了性能，包括推理工作负载，并且具有良好的泛化能力。

Conclusion: PARS能够有效预测基于响应长度的任务排序，减少延迟且开销最小。

Abstract: Efficient scheduling of LLM inference tasks is essential for achieving low
latency and high throughput, particularly with the growing use of
reasoning-capable LLMs. Traditional strategies like First-Come-First-Serve
(FCFS) often suffer from Head-of-Line (HOL) blocking, where long-running tasks
delay shorter ones queued behind them. In this paper, we introduce PARS, a
prompt-aware LLM task scheduler that improves serving efficiency by
approximating shortest-job-first (SJF) scheduling through pairwise ranking with
margin ranking loss. PARS focuses on impactful scheduling decisions and is
seamlessly integrated into the state-of-the-art LLM serving system vLLM. It
effectively predicts response-length-based task ordering, reducing latency with
minimal overhead. Extensive experiments across multiple LLMs and real-world
inference datasets show that PARS significantly improves performance, including
for reasoning workloads. Furthermore, our cross-model evaluations demonstrate
that the design generalizes well, enabling effective scheduling even when
predictors are trained on different LLMs.

</details>


### [146] [VIFO: Visual Feature Empowered Multivariate Time Series Forecasting with Cross-Modal Fusion](https://arxiv.org/abs/2510.03244)
*Yanlong Wang,Hang Yu,Jian Xu,Fei Ma,Hongkang Zhang,Tongtong Feng,Zijian Zhang,Shao-Lun Huang,Danny Dongning Sun,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: VIFO: a cross-modal forecasting model that renders multivariate time series into image, enabling pre-trained LVM to extract complex cross-channel patterns.


<details>
  <summary>Details</summary>
Motivation: Existing models ignore crucial cross-channel dependencies and have not fully exploited the power of large vision models (LVMs) to interpret spatiotemporal data.

Method: The paper proposes VIFO, which renders time series into images, uses a pre-trained LVM to extract visual features, and fuses these with time series representations.

Result: VIFO achieves competitive performance on multiple benchmarks by freezing the LVM and training only 7.45% of its parameters.

Conclusion: VIFO offers an efficient and effective solution for capturing cross-variable relationships.

Abstract: Large time series foundation models often adopt channel-independent
architectures to handle varying data dimensions, but this design ignores
crucial cross-channel dependencies. Concurrently, existing multimodal
approaches have not fully exploited the power of large vision models (LVMs) to
interpret spatiotemporal data. Additionally, there remains significant
unexplored potential in leveraging the advantages of information extraction
from different modalities to enhance time series forecasting performance. To
address these gaps, we propose the VIFO, a cross-modal forecasting model. VIFO
uniquely renders multivariate time series into image, enabling pre-trained LVM
to extract complex cross-channel patterns that are invisible to
channel-independent models. These visual features are then aligned and fused
with representations from the time series modality. By freezing the LVM and
training only 7.45% of its parameters, VIFO achieves competitive performance on
multiple benchmarks, offering an efficient and effective solution for capturing
cross-variable relationships in

</details>


### [147] [Frequency-Aware Model Parameter Explorer: A new attribution method for improving explainability](https://arxiv.org/abs/2510.03245)
*Ali Yavari,Alireza Mohamadi,Elham Beydaghi,Rainer A. Leitgeb*

Main category: cs.LG

TL;DR: 这篇论文提出了一种新的可迁移对抗攻击方法，并基于此提出了一种新的归因方法，以提高DNN的可解释性。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的噪声和故意的扰动下，确保深度神经网络(DNNs)的可靠性仍然是一个重大的挑战，现有的归因方法效果欠佳，需要进一步改进。

Method: 提出一种新的可迁移对抗攻击，实现通过高频和低频分量进行频率感知探索。基于此，提出一种新的归因方法，名为频率感知模型参数探索器(FAMPE)。

Result: FAMPE的插入分数平均提高了13.02%，优于现有方法。

Conclusion: 通过详细的消融研究， исследуется高频和低频分量在可解释性中的作用。

Abstract: Ensuring the reliability of deep neural networks (DNNs) in the presence of
real world noise and intentional perturbations remains a significant challenge.
To address this, attribution methods have been proposed, though their efficacy
remains suboptimal and necessitates further refinement. In this paper, we
propose a novel category of transferable adversarial attacks, called
transferable frequency-aware attacks, enabling frequency-aware exploration via
both high-and low-frequency components. Based on this type of attacks, we also
propose a novel attribution method, named Frequency-Aware Model Parameter
Explorer (FAMPE), which improves the explainability for DNNs. Relative to the
current state-of-the-art method AttEXplore, our FAMPE attains an average gain
of 13.02% in Insertion Score, thereby outperforming existing approaches.
Through detailed ablation studies, we also investigate the role of both high-
and low-frequency components in explainability.

</details>


### [148] [MetaMP: Seamless Metadata Enrichment and AI Application Framework for Enhanced Membrane Protein Visualization and Analysis](https://arxiv.org/abs/2510.04776)
*Ebenezer Awotoro,Chisom Ezekannagha,Florian Schwarz,Johannes Tauscher,Dominik Heider,Katharina Ladewig,Christel Le Bon,Karine Moncoq,Bruno Miroux,Georges Hattab*

Main category: cs.LG

TL;DR: MetaMP: A web application unifying membrane-protein databases with machine learning for improved data quality, streamlined exploration, and AI-driven analysis.


<details>
  <summary>Details</summary>
Motivation: The increasing number and complexity of membrane protein structures, coupled with data inconsistencies and computational challenges, necessitate improved database integration.

Method: A framework (MetaMP) unifies membrane-protein databases within a web application and uses machine learning for classification. It enriches metadata and offers interactive views.

Result: MetaMP resolved 77% of data discrepancies, accurately predicted the class of new membrane proteins 98% of the time, and demonstrated advantages across different tasks without compromising speed or accuracy.

Conclusion: MetaMP harmonizes current knowledge and empowers AI-driven exploration of membrane-protein architecture, providing a much-needed resource for the field.

Abstract: Structural biology has made significant progress in determining membrane
proteins, leading to a remarkable increase in the number of available
structures in dedicated databases. The inherent complexity of membrane protein
structures, coupled with challenges such as missing data, inconsistencies, and
computational barriers from disparate sources, underscores the need for
improved database integration. To address this gap, we present MetaMP, a
framework that unifies membrane-protein databases within a web application and
uses machine learning for classification. MetaMP improves data quality by
enriching metadata, offering a user-friendly interface, and providing eight
interactive views for streamlined exploration. MetaMP was effective across
tasks of varying difficulty, demonstrating advantages across different levels
without compromising speed or accuracy, according to user evaluations.
Moreover, MetaMP supports essential functions such as structure classification
and outlier detection.
  We present three practical applications of Artificial Intelligence (AI) in
membrane protein research: predicting transmembrane segments, reconciling
legacy databases, and classifying structures with explainable AI support. In a
validation focused on statistics, MetaMP resolved 77% of data discrepancies and
accurately predicted the class of newly identified membrane proteins 98% of the
time and overtook expert curation. Altogether, MetaMP is a much-needed resource
that harmonizes current knowledge and empowers AI-driven exploration of
membrane-protein architecture.

</details>


### [149] [StructPrune: Structured Global Pruning asymptotics with $\mathcal{O}(\sqrt{N})$ GPU Memory](https://arxiv.org/abs/2510.03246)
*Xinyuan Song,Guangji Bai,Liang Zhao*

Main category: cs.LG

TL;DR: 本文提出了一种名为 STRUPRUNE 的新的结构化剪枝框架，该框架结合了局部剪枝的内存效率和结构化方法的硬件兼容性，从而能够在十亿参数规模上进行实际部署。


<details>
  <summary>Details</summary>
Motivation: 全局剪枝虽然性能强大，但需要大量内存，这对于十亿参数模型来说是不可行的。局部剪枝虽然降低了 GPU 内存使用量，但忽略了层间依赖关系，在高稀疏度情况下通常会导致次优性能。结构化剪枝虽然更具硬件效率，但通常依赖于全局剪枝，因为结构化模式在局部优化下更容易出现严重的性能下降。

Method: 本文提出了一种分而治之的策略，将全局剪枝问题分解为跨不同模块的协调子问题，每个子问题都适合在有限的 GPU 内存中。在此基础上，设计了一个基于 ADMM 的框架 STRUPRUNE，该框架将结构化稀疏性集成到剪枝过程中。

Result: 实验表明，STRUPRUNE 在降低内存成本的同时，与全局结构化剪枝的困惑度相匹配，从而能够在十亿参数规模上进行实际部署。

Conclusion: STRUPRUNE 框架能够在降低内存成本的同时，保持与全局结构化剪枝相当的性能，为十亿参数规模模型的实际部署提供了可能性。

Abstract: Pruning is critical for scaling large language models (LLMs). Global pruning
achieves strong performance but requires $\mathcal{O}(N)$ memory, which is
infeasible for billion-parameter models. Local pruning reduces GPU memory usage
to that of a single layer by pruning layers independently, but it neglects
inter-layer dependencies and often leads to suboptimal performance in
high-sparsity regimes. Unlike unstructured pruning, structured pruning produces
regular sparsity patterns that align well with GPU kernels and library
optimizations, making it more hardware-efficient. However, structured pruning
typically relies on global pruning, since structured patterns are more prone to
severe performance degradation under local optimization. To jointly achieve
structured pruning and the memory efficiency of local pruning, we propose a
divide-and-conquer strategy that decomposes the global pruning problem into
coordinated subproblems across different modules, each of which fits within
limited GPU memory. Building on this idea, we design \textbf{STRUPRUNE}, an
ADMM-based framework that integrates structured sparsity into the pruning
process, combining the memory efficiency of local pruning with the hardware
compatibility of structured methods. We derive a closed-form analytical
solution for structured pruning masks that provides an explicit rule for
layer-wise sparsity allocation, and further develop an energy-based asymptotic
framework yielding a softmax-form allocation scheme that simplifies
optimization while adapting to heterogeneous layer importance. Experiments
demonstrate that STRUPRUNE matches the perplexity of global structured pruning
while reducing memory cost from $\mathcal{O}(N)$ to $\mathcal{O}(\sqrt{N})$,
enabling practical deployment at the billion-parameter scale.

</details>


### [150] [Towards Multimodal Active Learning: Efficient Learning with Limited Paired Data](https://arxiv.org/abs/2510.03247)
*Jiancheng Zhang,Yinglun Zhu*

Main category: cs.LG

TL;DR: 提出了一种新的多模态主动学习框架，用于解决非对齐数据的标注难题，通过主动学习跨模态对齐而非预对齐对的标签来降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有的主动学习算法主要集中在单模态数据上，忽略了多模态学习中的大量标注负担。现代多模态流程（如CLIP和SigLIP）中，单模态特征易于获取，但高质量的对齐成本很高。

Method: 开发了一种新算法，该算法结合了不确定性和多样性原则，实现了线性时间获取，并无缝应用于基于池和基于流的设置。

Result: 在基准数据集上的大量实验表明，该方法在保持性能的同时，始终降低多模态标注成本；例如，在ColorSwap数据集上，它可以在不损失准确性的前提下，将标注需求降低多达40%。

Conclusion: 该方法有效地降低了多模态数据的标注成本，并在实际应用中具有潜力。

Abstract: Active learning (AL) is a principled strategy to reduce annotation cost in
data-hungry deep learning. However, existing AL algorithms focus almost
exclusively on unimodal data, overlooking the substantial annotation burden in
multimodal learning. We introduce the first framework for multimodal active
learning with unaligned data, where the learner must actively acquire
cross-modal alignments rather than labels on pre-aligned pairs. This setting
captures the practical bottleneck in modern multimodal pipelines such as CLIP
and SigLIP, where unimodal features are easy to obtain but high-quality
alignment is costly. We develop a new algorithm that combines uncertainty and
diversity principles in a modality-aware design, achieves linear-time
acquisition, and applies seamlessly to both pool-based and streaming-based
settings. Extensive experiments on benchmark datasets demonstrate that our
approach consistently reduces multimodal annotation cost while preserving
performance; for instance, on the ColorSwap dataset it cuts annotation
requirements by up to $40\%$ without loss in accuracy.

</details>


### [151] [Real-Time Brain Biomechanics Prediction with Neural Operators: Toward Clinically Deployable Traumatic Brain Injury Models](https://arxiv.org/abs/2510.03248)
*Anusha Agarwal,Dibakar Roy Sarkar,Somdatta Goswami*

Main category: cs.LG

TL;DR: 本研究探索了使用神经算子（NO）架构来快速预测患者特定脑位移场，以实现临床和转化环境中的实时TBI建模。


<details>
  <summary>Details</summary>
Motivation: 有限元（FE）模型能够高精度预测大脑形变，但计算成本高昂，限制了其在快速决策中的临床应用。

Method: 将TBI建模问题转化为算子学习问题，将受试者特定的解剖MRI、磁共振弹性成像（MRE）刚度图和人口统计学特征映射到全场3D脑位移预测。使用了四种架构：傅里叶神经算子（FNO）、分解FNO（F-FNO）、多重网格FNO（MG-FNO）和深度算子网络（DeepONet）。

Result: MG-FNO实现了最高的精度（MSE = 0.0023，94.3％的空间保真度），F-FNO比标准FNO快2倍，DeepONet提供了最快的推理速度（14.5次迭代/秒），比MG-FNO快7倍。

Conclusion: 神经算子为预测大脑形变提供了一种高效、分辨率不变的方法，为实时、患者特定的TBI风险评估、临床分诊支持和防护设备优化打开了大门。

Abstract: Traumatic brain injury (TBI) remains a major public health concern, with over
69 million cases annually worldwide. Finite element (FE) models offer
high-fidelity predictions of brain deformation but are computationally
expensive, requiring hours per simulation and limiting their clinical utility
for rapid decision-making. This study benchmarks state-of-the-art neural
operator (NO) architectures for rapid, patient-specific prediction of brain
displacement fields, aiming to enable real-time TBI modeling in clinical and
translational settings. We formulated TBI modeling as an operator learning
problem, mapping subject-specific anatomical MRI, magnetic resonance
elastography (MRE) stiffness maps, and demographic features to full-field 3D
brain displacement predictions. Four architectures - Fourier Neural Operator
(FNO), Factorized FNO (F-FNO), Multi-Grid FNO (MG-FNO), and Deep Operator
Network (DeepONet) were trained and evaluated on 249 MRE datasets across
physiologically relevant frequencies (20 - 90 Hz). MG-FNO achieved the highest
accuracy (MSE = 0.0023, 94.3\% spatial fidelity) and preserved fine-scale
features, while F-FNO converged 2$\times$ faster than standard FNO. DeepONet
offered the fastest inference (14.5 iterations/s) with a 7$\times$
computational speed-up over MG-FNO, suggesting utility for embedded or edge
computing applications. All NOs reduced computation time from hours to
milliseconds without sacrificing anatomical realism. NOs provide an efficient,
resolution-invariant approach for predicting brain deformation, opening the
door to real-time, patient-specific TBI risk assessment, clinical triage
support, and optimization of protective equipment. These results highlight the
potential for NO-based digital twins of the human brain, enabling scalable,
on-demand biomechanical modeling in both clinical and population health
contexts.

</details>


### [152] [Light Differentiable Logic Gate Networks](https://arxiv.org/abs/2510.03250)
*Lukas Rüttgers,Till Aczel,Andreas Plesner,Roger Wattenhofer*

Main category: cs.LG

TL;DR: DLGNs are efficient but hard to scale. The paper identifies the parametrization of logic gate neurons as the root cause.


<details>
  <summary>Details</summary>
Motivation: Vanishing gradients, discretization errors, and high training cost impede the scaling of DLGNs; increasing depth harms accuracy.

Method: The paper proposes a reparametrization that also shrinks the parameter size logarithmically in the number of inputs per gate.

Result: For binary inputs, the reparametrization reduces model size by 4x, speeds up the backward pass by up to 1.86x, and converges in 8.5x fewer training steps. Accuracy on CIFAR-100 remains stable or superior.

Conclusion: The proposed reparametrization overcomes issues with the original parametrization, improving efficiency and scalability.

Abstract: Differentiable logic gate networks (DLGNs) exhibit extraordinary efficiency
at inference while sustaining competitive accuracy. But vanishing gradients,
discretization errors, and high training cost impede scaling these networks.
Even with dedicated parameter initialization schemes from subsequent works,
increasing depth still harms accuracy. We show that the root cause of these
issues lies in the underlying parametrization of logic gate neurons themselves.
To overcome this issue, we propose a reparametrization that also shrinks the
parameter size logarithmically in the number of inputs per gate. For binary
inputs, this already reduces the model size by 4x, speeds up the backward pass
by up to 1.86x, and converges in 8.5x fewer training steps. On top of that, we
show that the accuracy on CIFAR-100 remains stable and sometimes superior to
the original parametrization.

</details>


### [153] [Numerion: A Multi-Hypercomplex Model for Time Series Forecasting](https://arxiv.org/abs/2510.03251)
*Hanzhong Cao,Wenbo Yan,Ying Tan*

Main category: cs.LG

TL;DR: 该论文提出了一种名为Numerion的时间序列预测模型，该模型基于多重超复数空间，通过将时间序列映射到不同维度的超复数空间中，实现对时间序列的分解和独立建模，并通过动态融合机制自适应地融合不同空间中表现出的潜在模式。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列预测方法通常依赖于复杂的模型结构和先验知识进行序列分解，但计算复杂且假设的鲁棒性有限。

Method: 该论文提出了Numerion模型，它基于多重超复数空间，将线性层和激活函数推广到任意2的幂维的超复数空间，并引入了一种新的实-超复数-实域多层感知器（RHR-MLP）架构。Numerion利用多个RHR-MLP将时间序列映射到不同维度的超复数空间，从而自然地分解和独立建模序列。

Result: 实验结果表明，该模型在多个公共数据集上取得了最先进的结果。

Conclusion: 多维RHR-MLP能够自然地分解时间序列，并且更高维的超复数空间倾向于捕获更低频率的特征。

Abstract: Many methods aim to enhance time series forecasting by decomposing the series
through intricate model structures and prior knowledge, yet they are inevitably
limited by computational complexity and the robustness of the assumptions. Our
research uncovers that in the complex domain and higher-order hypercomplex
spaces, the characteristic frequencies of time series naturally decrease.
Leveraging this insight, we propose Numerion, a time series forecasting model
based on multiple hypercomplex spaces. Specifically, grounded in theoretical
support, we generalize linear layers and activation functions to hypercomplex
spaces of arbitrary power-of-two dimensions and introduce a novel
Real-Hypercomplex-Real Domain Multi-Layer Perceptron (RHR-MLP) architecture.
Numerion utilizes multiple RHR-MLPs to map time series into hypercomplex spaces
of varying dimensions, naturally decomposing and independently modeling the
series, and adaptively fuses the latent patterns exhibited in different spaces
through a dynamic fusion mechanism. Experiments validate the model`s
performance, achieving state-of-the-art results on multiple public datasets.
Visualizations and quantitative analyses comprehensively demonstrate the
ability of multi-dimensional RHR-MLPs to naturally decompose time series and
reveal the tendency of higher dimensional hypercomplex spaces to capture lower
frequency features.

</details>


### [154] [Universal Multi-Domain Translation via Diffusion Routers](https://arxiv.org/abs/2510.03252)
*Duc Kieu,Kien Do,Tuan Hoang,Thao Minh Le,Tung Kieu,Dang Nguyen,Thin Nguyen*

Main category: cs.LG

TL;DR: 本文提出了一种通用多域翻译（UMDT）方法，旨在仅使用K-1个配对数据集在任意K个域之间进行翻译。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么需要完全对齐的元组，要么只能处理训练中看到的域对，限制了它们的实用性并排除许多跨域映射。

Method: 我们提出了Diffusion Router（DR），这是一个统一的基于扩散的框架，它使用单个噪声预测器对所有中心$
leftrightarrow$非中心翻译进行建模，该噪声预测器以源域和目标域标签为条件。DR通过路由中心域来实现间接非中心翻译。我们进一步引入了一种新的可扩展学习策略，该策略具有变分边界目标和有效的Tweedie细化程序，以支持直接非中心映射。

Result: 在三个大规模UMDT基准上的评估表明，DR在间接和直接翻译方面都取得了最先进的结果，同时降低了采样成本并解锁了诸如草图$
leftrightarrow$分割之类的新颖任务。

Conclusion: 这些结果表明，DR是用于跨多个域进行通用翻译的可扩展且通用的框架。

Abstract: Multi-domain translation (MDT) aims to learn translations between multiple
domains, yet existing approaches either require fully aligned tuples or can
only handle domain pairs seen in training, limiting their practicality and
excluding many cross-domain mappings. We introduce universal MDT (UMDT), a
generalization of MDT that seeks to translate between any pair of $K$ domains
using only $K-1$ paired datasets with a central domain. To tackle this problem,
we propose Diffusion Router (DR), a unified diffusion-based framework that
models all central$\leftrightarrow$non-central translations with a single noise
predictor conditioned on the source and target domain labels. DR enables
indirect non-central translations by routing through the central domain. We
further introduce a novel scalable learning strategy with a variational-bound
objective and an efficient Tweedie refinement procedure to support direct
non-central mappings. Through evaluation on three large-scale UMDT benchmarks,
DR achieves state-of-the-art results for both indirect and direct translations,
while lowering sampling cost and unlocking novel tasks such as
sketch$\leftrightarrow$segmentation. These results establish DR as a scalable
and versatile framework for universal translation across multiple domains.

</details>


### [155] [Solving the Granularity Mismatch: Hierarchical Preference Learning for Long-Horizon LLM Agents](https://arxiv.org/abs/2510.03253)
*Heyang Gao,Zexu Sun,Erxue Min,Hengyi Cai,Shuaiqiang Wang,Dawei Yin,Xu Chen*

Main category: cs.LG

TL;DR: 提出了一个分层偏好学习（HPL）框架，用于优化LLM智能体，利用多粒度偏好信号。


<details>
  <summary>Details</summary>
Motivation: 现有的基于偏好的离线方法，如直接偏好优化（DPO），在对齐LLM智能体以解决复杂问题时，面临着粒度不匹配的问题：轨迹级别DPO过于粗糙，步骤级别DPO过于短视。

Method: HPL结合了轨迹和步骤级别的DPO，并通过双层课程引导组级别偏好优化。该方法将专家轨迹分解为语义连贯的动作组，并生成对比性的次优组，以实现细粒度的子任务级别偏好学习。此外，HPL引入了一个课程调度器，根据组长度和样本难度组织学习过程。

Result: 在三个具有挑战性的智能体基准测试中，HPL优于现有的最先进方法。

Conclusion: 分层DPO损失有效地整合了跨多个粒度的偏好信号，而双层课程对于使智能体能够解决从简单行为到复杂多步骤序列的各种任务至关重要。

Abstract: Large Language Models (LLMs) as autonomous agents are increasingly tasked
with solving complex, long-horizon problems. Aligning these agents via
preference-based offline methods like Direct Preference Optimization (DPO) is a
promising direction, yet it faces a critical granularity mismatch.
Trajectory-level DPO provides a signal that is too coarse for precise credit
assignment, while step-level DPO is often too myopic to capture the value of
multi-step behaviors. To resolve this challenge, we introduce Hierarchical
Preference Learning (HPL), a hierarchical framework that optimizes LLM agents
by leveraging preference signals at multiple, synergistic granularities. While
HPL incorporates trajectory- and step-level DPO for global and local policy
stability, its core innovation lies in group-level preference optimization
guided by a dual-layer curriculum. Our approach first decomposes expert
trajectories into semantically coherent action groups and then generates
contrasting suboptimal groups to enable preference learning at a fine-grained,
sub-task level. Then, instead of treating all preference pairs equally, HPL
introduces a curriculum scheduler that organizes the learning process from
simple to complex. This curriculum is structured along two axes: the group
length, representing sub-task complexity, and the sample difficulty, defined by
the reward gap between preferred and dispreferred action groups. Experiments on
three challenging agent benchmarks show that HPL outperforms existing
state-of-the-art methods. Our analyses demonstrate that the hierarchical DPO
loss effectively integrates preference signals across multiple granularities,
while the dual-layer curriculum is crucial for enabling the agent to solve a
wide range of tasks, from simple behaviors to complex multi-step sequences.

</details>


### [156] [Adversarial training with restricted data manipulation](https://arxiv.org/abs/2510.03254)
*David Benfield,Stefano Coniglio,Phan Tu Vuong,Alain Zemkoho*

Main category: cs.LG

TL;DR: 提出了一种约束悲观双层优化模型，以提高对抗机器学习中分类器的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的悲观双层方法由于无限制的对抗，可能导致模型过于悲观和不切实际，从而降低在真实世界数据上的分类器性能。

Method: 构建了一个约束悲观双层优化模型，限制了对抗者的行为。

Result: 实验表明，该模型平均表现优于现有方法。

Conclusion: 通过限制对抗者的行为，可以获得更符合实际情况的解，从而提高分类器的性能。

Abstract: Adversarial machine learning concerns situations in which learners face
attacks from active adversaries. Such scenarios arise in applications such as
spam email filtering, malware detection and fake image generation, where
security methods must be actively updated to keep up with the everimproving
generation of malicious data. Pessimistic Bilevel optimisation has been shown
to be an effective method of training resilient classifiers against such
adversaries. By modelling these scenarios as a game between the learner and the
adversary, we anticipate how the adversary will modify their data and then
train a resilient classifier accordingly. However, since existing pessimistic
bilevel approaches feature an unrestricted adversary, the model is vulnerable
to becoming overly pessimistic and unrealistic. When finding the optimal
solution that defeats the classifier, it is possible that the adversary's data
becomes nonsensical and loses its intended nature. Such an adversary will not
properly reflect reality, and consequently, will lead to poor classifier
performance when implemented on real-world data. By constructing a constrained
pessimistic bilevel optimisation model, we restrict the adversary's movements
and identify a solution that better reflects reality. We demonstrate through
experiments that this model performs, on average, better than the existing
approach.

</details>


### [157] [SciTS: Scientific Time Series Understanding and Generation with LLMs](https://arxiv.org/abs/2510.03255)
*Wen Wu,Ziyang Zhang,Liwei Liu,Xuenan Xu,Junlin Liu,Ke Fan,Qitan Lv,Jimin Zhuang,Chen Zhang,Zheqi Yuan,Siyuan Hou,Tianyi Lin,Kai Chen,Bowen Zhou,Chao Zhang*

Main category: cs.LG

TL;DR: 论文介绍了一个新的科学时间序列基准测试 SciTS 和一个名为 TimeOmni 的框架，以提升大型语言模型 (LLM) 在理解和生成时间序列数据方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态 LLM 在处理科学时间序列数据时存在不足，并且现有的统一时间序列模型在非周期性、异构科学信号上的有效性不明确。

Method: 论文构建了一个包含 12 个科学领域和 43 个任务的 SciTS 基准测试，并提出了 TimeOmni 框架，该框架使 LLM 能够理解和生成时间序列，同时与通用 LLM 训练保持兼容。

Result: 实验结果表明，通用 LLM 比专门的时间序列模型表现出更强的泛化能力，而将时间序列表示为文本或图像会限制其性能。

Conclusion: 这项工作填补了科学时间序列专用基准测试和建模框架的空白，为 LLM 理解和生成复杂的时间科学数据铺平了道路。

Abstract: The scientific reasoning ability of large language models (LLMs) has recently
attracted significant attention. Time series, as a fundamental modality in
scientific data, presents unique challenges that are often overlooked in
current multimodal LLMs, which either encode numerical sequences as text or
convert them into images. Such approaches may be insufficient for comprehensive
scientific time series understanding and generation. Existing unified time
series models typically specialise in either forecasting or analysis, and their
effectiveness on non-periodic, heterogeneous scientific signals remains
unclear. To address these gaps, we introduce SciTS, a benchmark spanning 12
scientific domains and 43 tasks, with over 50k+ instances, both univariate and
multivariate signals ranging from $10^0$ to $10^7$ in length and up to 10~MHz
in frequency. We benchmark 17 models, including text-only LLMs, multimodal
LLMs, and unified time series models, and find that general-purpose LLMs
exhibit stronger generalisability than specialised time series models, while
representing time series as text or images limits their performance due to
excessively long sequences and loss of numerical precision, respectively. We
then introduce TimeOmni, a framework that equips LLMs with the ability to
understand and generate time series while remaining compatible with
general-purpose LLM training. This work fills a gap in both dedicated
benchmarks and modelling frameworks for scientific time series, paving the way
for LLMs to understand and generate complex temporal scientific data.

</details>


### [158] [Triple-BERT: Do We Really Need MARL for Order Dispatch on Ride-Sharing Platforms?](https://arxiv.org/abs/2510.03257)
*Zijian Zhao,Sen Li*

Main category: cs.LG

TL;DR: 这篇论文提出了一种名为Triple-BERT的集中式单智能体强化学习（MARL）方法，用于解决网约车平台上大规模订单调度的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL方法无法捕捉全局信息，合作性差，CTDE方法存在维度灾难。为了解决这些问题，提出了Triple-BERT。

Method: 该方法基于TD3变体，通过动作分解策略处理巨大的动作空间，并引入了基于BERT的新型网络来处理广泛的观察空间。

Result: 在曼哈顿的真实网约车数据集上验证了该方法，Triple-BERT比当前最先进的方法提高了约11.95%，服务订单增加了4.26%，接客时间减少了22.25%。

Conclusion: Triple-BERT在大规模订单调度方面表现出色，优于现有方法。

Abstract: On-demand ride-sharing platforms, such as Uber and Lyft, face the intricate
real-time challenge of bundling and matching passengers-each with distinct
origins and destinations-to available vehicles, all while navigating
significant system uncertainties. Due to the extensive observation space
arising from the large number of drivers and orders, order dispatching, though
fundamentally a centralized task, is often addressed using Multi-Agent
Reinforcement Learning (MARL). However, independent MARL methods fail to
capture global information and exhibit poor cooperation among workers, while
Centralized Training Decentralized Execution (CTDE) MARL methods suffer from
the curse of dimensionality. To overcome these challenges, we propose
Triple-BERT, a centralized Single Agent Reinforcement Learning (MARL) method
designed specifically for large-scale order dispatching on ride-sharing
platforms. Built on a variant TD3, our approach addresses the vast action space
through an action decomposition strategy that breaks down the joint action
probability into individual driver action probabilities. To handle the
extensive observation space, we introduce a novel BERT-based network, where
parameter reuse mitigates parameter growth as the number of drivers and orders
increases, and the attention mechanism effectively captures the complex
relationships among the large pool of driver and orders. We validate our method
using a real-world ride-hailing dataset from Manhattan. Triple-BERT achieves
approximately an 11.95% improvement over current state-of-the-art methods, with
a 4.26% increase in served orders and a 22.25% reduction in pickup times. Our
code, trained model parameters, and processed data are publicly available at
the repository https://github.com/RS2002/Triple-BERT .

</details>


### [159] [POEM: Explore Unexplored Reliable Samples to Enhance Test-Time Adaptation](https://arxiv.org/abs/2510.03258)
*Chang'an Yi,Xiaohui Deng,Shuaicheng Niu,Yan Zhou*

Main category: cs.LG

TL;DR: 本文提出了一种名为POEM的通用测试时自适应(TTA)方法，旨在通过探索先前未被利用的可靠样本来提升TTA性能，并引入额外的Adapt Branch网络以平衡领域无关表示的提取和目标数据上的高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的TTA方法依赖于熵作为置信度指标来优化模型，但对预定义的熵阈值敏感，导致一些潜在可靠的目标样本被忽略和未充分利用。

Method: 提出POEM方法，通过探索先前未被利用的可靠样本来提升TTA性能，并引入额外的Adapt Branch网络来平衡领域无关表示的提取和目标数据上的高性能。

Result: 在多个架构上的综合实验表明，POEM在具有挑战性的场景和真实世界的领域转移中始终优于现有的TTA方法，同时保持了计算效率。

Conclusion: POEM方法是有效的，并且其核心思想可以作为一种增强策略来提高现有TTA方法的性能。

Abstract: Test-time adaptation (TTA) aims to transfer knowledge from a source model to
unknown test data with potential distribution shifts in an online manner. Many
existing TTA methods rely on entropy as a confidence metric to optimize the
model. However, these approaches are sensitive to the predefined entropy
threshold, influencing which samples are chosen for model adaptation.
Consequently, potentially reliable target samples are often overlooked and
underutilized. For instance, a sample's entropy might slightly exceed the
threshold initially, but fall below it after the model is updated. Such samples
can provide stable supervised information and offer a normal range of gradients
to guide model adaptation. In this paper, we propose a general approach,
\underline{POEM}, to promote TTA via ex\underline{\textbf{p}}loring the
previously unexpl\underline{\textbf{o}}red reliabl\underline{\textbf{e}}
sa\underline{\textbf{m}}ples. Additionally, we introduce an extra Adapt Branch
network to strike a balance between extracting domain-agnostic representations
and achieving high performance on target data. Comprehensive experiments across
multiple architectures demonstrate that POEM consistently outperforms existing
TTA methods in both challenging scenarios and real-world domain shifts, while
remaining computationally efficient. The effectiveness of POEM is evaluated
through extensive analyses and thorough ablation studies. Moreover, the core
idea behind POEM can be employed as an augmentation strategy to boost the
performance of existing TTA approaches. The source code is publicly available
at \emph{https://github.com/ycarobot/POEM}

</details>


### [160] [Meta-Awareness Enhances Reasoning Models: Self-Alignment Reinforcement Learning](https://arxiv.org/abs/2510.03259)
*Yoonjeon Kim,Doohyuk Jang,Eunho Yang*

Main category: cs.LG

TL;DR: 大型推理模型缺乏元认知能力，通过自我对齐提升元认知能力可以显著提高性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型缺乏元认知能力，即无法了解自身的思考方式，导致真实情况与预测的元信息不一致。

Method: 设计了一个通过自我对齐提升元认知能力 (MASA) 的训练流程，利用自生成信号训练元认知能力，无需外部训练资源。通过过滤零方差提示和提前停止不太可能得到正确答案的展开来提高训练效率。

Result: 在领域内任务中提高了准确性和训练效率，在领域外基准测试中表现出强大的泛化能力。在 AIME25 上提高了 19.3% 的准确率，在六个数学基准测试中平均提高了 6.2%。在 GPQA-Diamond 上提高了 3.87%，在跨越逻辑、科学和编码领域的 13 个基准测试中总体准确率提高了 2.08%。

Conclusion: 通过元认知指导进行训练可以增强领域外泛化能力。

Abstract: Recent studies on reasoning models explore the meta-awareness of language
models, the ability to know how to think by itself. We argue that large
reasoning models lack this meta-awareness property by proving severe
misalignment between true rollouts and predicted meta information. We posit
that aligning meta-prediction with true rollouts will lead to significant
performance gains. To verify this hypothesis, we design a training pipeline
that boosts Meta-Awareness via Self-Alignment (MASA), and prove that enhanced
meta-awareness directly translates to improved accuracy. Unlike existing
meta-cognitive reasoning models, our method does not require external training
sources but leverages self-generated signals to train meta-awareness. Moreover,
our method enables efficient training by i) filtering out zero-variance prompts
that are either trivial or unsolvable and ii) cutting off lengthy rollouts when
they are unlikely to lead to correct answers. The results are inspiring: our
strategy yields significant improvements in both accuracy and training
efficiency on in-domain tasks and shows strong generalization to out-of-domain
benchmarks. More specifically, our method can speed up GRPO training by over
1.28x to reach the same performance, and achieve a 19.3% gain in accuracy on
AIME25, and a 6.2 % average gain over six mathematics benchmarks. Training with
meta-cognitive guidance enhances out-of-domain generalization, giving a 3.87 %
boost on GPQA-Diamond and a 2.08 % overall accuracy gain across 13 benchmarks
spanning logical, scientific, and coding domains.

</details>


### [161] [Semantic-Inductive Attribute Selection for Zero-Shot Learning](https://arxiv.org/abs/2510.03260)
*Juan Jose Herrera-Aranda,Guillermo Gomez-Trenado,Francisco Herrera,Isaac Triguero*

Main category: cs.LG

TL;DR: 本文提出了一种划分方案，可以在归纳设置中模拟未见条件，从而评估属性相关性，而无需访问未见类的语义信息。


<details>
  <summary>Details</summary>
Motivation: 语义空间在连接可见类和未见类方面起着关键作用，但它们通常包含noisy、冗余或不相关的属性，从而降低了性能。

Method: 本文研究了两种互补的特征选择策略，并评估了它们的泛化能力：RFS和GA。

Result: 在五个基准数据集上的实验表明，这两种方法都能通过减少冗余来持续提高未见类的准确性。

Conclusion: 这些结果证实了语义空间本质上是冗余的，并强调了所提出的划分方案是归纳条件下改进语义空间的有效工具。

Abstract: Zero-Shot Learning is an important paradigm within General-Purpose Artificial
Intelligence Systems, particularly in those that operate in open-world
scenarios where systems must adapt to new tasks dynamically. Semantic spaces
play a pivotal role as they bridge seen and unseen classes, but whether
human-annotated or generated by a machine learning model, they often contain
noisy, redundant, or irrelevant attributes that hinder performance. To address
this, we introduce a partitioning scheme that simulates unseen conditions in an
inductive setting (which is the most challenging), allowing attribute relevance
to be assessed without access to semantic information from unseen classes.
Within this framework, we study two complementary feature-selection strategies
and assess their generalisation. The first adapts embedded feature selection to
the particular demands of ZSL, turning model-driven rankings into meaningful
semantic pruning; the second leverages evolutionary computation to directly
explore the space of attribute subsets more broadly. Experiments on five
benchmark datasets (AWA2, CUB, SUN, aPY, FLO) show that both methods
consistently improve accuracy on unseen classes by reducing redundancy, but in
complementary ways: RFS is efficient and competitive though dependent on
critical hyperparameters, whereas GA is more costly yet explores the search
space more broadly and avoids such dependence. These results confirm that
semantic spaces are inherently redundant and highlight the proposed
partitioning scheme as an effective tool to refine them under inductive
conditions.

</details>


### [162] [Data-Driven Temperature Modelling of Machine Tools by Neural Networks: A Benchmark](https://arxiv.org/abs/2510.03261)
*C. Coelho,M. Hohmann,D. Fernández,L. Penter,S. Ihlenfeldt,O. Niggemann*

Main category: cs.LG

TL;DR: 提出了一种新的范例，其中神经网络经过训练可以预测机床内的高保真温度和热通量场，从而能够使用可互换的下游组件计算和校正各种误差类型。


<details>
  <summary>Details</summary>
Motivation: 传统的热误差校正/补偿方法依赖于测量的温度-变形场或传递函数。大多数现有的数据驱动补偿策略采用神经网络 (NN) 来直接预测热误差或特定补偿值。虽然有效，但这些方法与特定的误差类型、空间位置或机器配置紧密相关，限制了它们的通用性和适应性。

Method: 神经网络是使用有限元方法在变化的初始条件下获得的数据进行训练的，并结合了基于相关的选择策略，该策略可识别信息量最大的测量点，从而最大限度地减少推理期间的硬件需求。我们进一步对最先进的时间序列 NN 架构（即循环 NN、门控循环单元、长短期记忆 (LSTM)、双向 LSTM、Transformer 和时间卷积网络）进行基准测试，通过训练专门的模型（针对特定初始条件定制）和通用模型（能够外推到看不见的场景）。

Result: 结果表明，温度和热通量场的预测准确且成本低廉，为在机床环境中实现灵活且通用的热误差校正奠定了基础。

Conclusion: 该研究为机床环境中的热误差校正提供了一种新的、通用的方法。

Abstract: Thermal errors in machine tools significantly impact machining precision and
productivity. Traditional thermal error correction/compensation methods rely on
measured temperature-deformation fields or on transfer functions. Most existing
data-driven compensation strategies employ neural networks (NNs) to directly
predict thermal errors or specific compensation values. While effective, these
approaches are tightly bound to particular error types, spatial locations, or
machine configurations, limiting their generality and adaptability. In this
work, we introduce a novel paradigm in which NNs are trained to predict
high-fidelity temperature and heat flux fields within the machine tool. The
proposed framework enables subsequent computation and correction of a wide
range of error types using modular, swappable downstream components. The NN is
trained using data obtained with the finite element method under varying
initial conditions and incorporates a correlation-based selection strategy that
identifies the most informative measurement points, minimising hardware
requirements during inference. We further benchmark state-of-the-art
time-series NN architectures, namely Recurrent NN, Gated Recurrent Unit,
Long-Short Term Memory (LSTM), Bidirectional LSTM, Transformer, and Temporal
Convolutional Network, by training both specialised models, tailored for
specific initial conditions, and general models, capable of extrapolating to
unseen scenarios. The results show accurate and low-cost prediction of
temperature and heat flux fields, laying the basis for enabling flexible and
generalisable thermal error correction in machine tool environments.

</details>


### [163] [Rethinking Inter-LoRA Orthogonality in Adapter Merging: Insights from Orthogonal Monte Carlo Dropout](https://arxiv.org/abs/2510.03262)
*Andi Zhang,Xuan Ding,Haofan Wang,Steven McDonagh,Samuel Kaski*

Main category: cs.LG

TL;DR: 提出了正交蒙特卡洛 Dropout，一种在组合稀疏语义向量时强制执行严格正交性的机制，且没有额外的时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 当合并多个 LoRA 时，它们的语义向量可能会相互干扰。该方法旨在解决这个问题。

Method: 该方法保证合并的 LoRA 保持正交，从而避免直接干扰。

Result: 正交性并不一定导致语义解耦或组合性。

Conclusion: LoRA 间的正交性可能不足以实现真正的语义组合性，促使人们重新审视其在适配器合并中的作用。

Abstract: We propose Orthogonal Monte Carlo Dropout, a mechanism that enforces strict
orthogonality when combining sparse semantic vectors without extra time
complexity. LoRA, a popular fine-tuning method for large models, typically
trains a module to represent a specific concept such as an object or a style.
When multiple LoRAs are merged, for example to generate an object in a
particular style, their semantic vectors may interfere with each other. Our
method guarantees, at the theoretical and runtime levels, that merged LoRAs
remain orthogonal and thus free from direct interference. However, empirical
analysis reveals that such orthogonality does not lead to the semantic
disentanglement or compositionality highlighted in prior work on compositional
adaptation. This finding suggests that inter-LoRA orthogonality alone may be
insufficient for achieving true semantic compositionality, prompting a
re-examination of its role in adapter merging.

</details>


### [164] [Memory Self-Regeneration: Uncovering Hidden Knowledge in Unlearned Models](https://arxiv.org/abs/2510.03263)
*Agnieszka Polowczyk,Alicja Polowczyk,Joanna Waczyńska,Piotr Borycki,Przemysław Spurek*

Main category: cs.LG

TL;DR: 现代文本到图像模型可以生成逼真的视觉效果，但也可能被滥用以生成有害内容。因此，机器学习领域开始研究如何有选择地从模型的训练数据中删除特定知识，而不会导致其整体性能下降。然而，事实证明，真正忘记一个给定的概念是一项极其困难的任务。使用对抗性提示的模型显示出生成所谓未学习概念的能力，这些概念可能不仅有害，而且是非法的。本文介绍了关于模型忘记和回忆知识的能力的考虑，介绍了记忆自我再生任务。此外，我们提出了MemoRa策略，我们认为这是一种支持有效恢复先前丢失知识的再生方法。此外，我们提出知识检索中的鲁棒性是开发更鲁棒和有效的非学习技术的关键但尚未充分探索的评估措施。最后，我们证明了遗忘以两种不同的方式发生：短期遗忘，概念可以快速回忆；长期遗忘，恢复更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 由于现代文本到图像模型可能被滥用以生成有害内容，因此需要研究如何有选择地从模型的训练数据中删除特定知识。

Method: 提出了MemoRa策略，这是一种支持有效恢复先前丢失知识的再生方法, 介绍了记忆自我再生任务。

Result: 证明了遗忘以两种不同的方式发生：短期遗忘和长期遗忘。

Conclusion: 知识检索中的鲁棒性是开发更鲁棒和有效的非学习技术的关键但尚未充分探索的评估措施。模型忘记和回忆知识的能力需要被考虑。

Abstract: The impressive capability of modern text-to-image models to generate
realistic visuals has come with a serious drawback: they can be misused to
create harmful, deceptive or unlawful content. This has accelerated the push
for machine unlearning. This new field seeks to selectively remove specific
knowledge from a model's training data without causing a drop in its overall
performance. However, it turns out that actually forgetting a given concept is
an extremely difficult task. Models exposed to attacks using adversarial
prompts show the ability to generate so-called unlearned concepts, which can be
not only harmful but also illegal. In this paper, we present considerations
regarding the ability of models to forget and recall knowledge, introducing the
Memory Self-Regeneration task. Furthermore, we present MemoRa strategy, which
we consider to be a regenerative approach supporting the effective recovery of
previously lost knowledge. Moreover, we propose that robustness in knowledge
retrieval is a crucial yet underexplored evaluation measure for developing more
robust and effective unlearning techniques. Finally, we demonstrate that
forgetting occurs in two distinct ways: short-term, where concepts can be
quickly recalled, and long-term, where recovery is more challenging.

</details>


### [165] [Front-Loading Reasoning: The Synergy between Pretraining and Post-Training Data](https://arxiv.org/abs/2510.03264)
*Syeda Nahida Akter,Shrimai Prabhumoye,Eric Nyberg,Mostofa Patwary,Mohammad Shoeybi,Yejin Choi,Bryan Catanzaro*

Main category: cs.LG

TL;DR: 本研究探讨了在LLM训练的不同阶段引入推理数据的影响，发现前期预训练阶段的推理数据至关重要。


<details>
  <summary>Details</summary>
Motivation: 当前提升LLM推理能力的方法主要依赖于在高质量、推理密集型数据上进行后训练，而预训练阶段推理数据的作用尚不明确。

Method: 通过系统研究不同规模、多样性和质量的推理数据在LLM训练不同阶段的影响。

Result: 发现在预训练阶段引入推理数据至关重要（平均提升19%），且预训练阶段受益于推理模式的广泛多样性（平均提升11%），而后训练阶段对数据质量更敏感（平均提升15%）。

Conclusion: 研究结果表明，语言建模和推理的传统分离具有挑战性，并为在整个训练过程中战略性地分配数据以构建更强大的模型提供了原则性指导。

Abstract: The prevailing paradigm for enhancing the reasoning abilities of LLMs
revolves around post-training on high-quality, reasoning-intensive data. While
emerging literature suggests that reasoning data is increasingly incorporated
also during the mid-training stage-a practice that is relatively more
proprietary and less openly characterized-the role of such data in pretraining
remains unclear. In particular, due to the opaqueness of pretraining corpora in
most frontier models, the effect of reasoning data introduced at different
phases of pre- and/or post-training is relatively less reported in the
scientific literature. This raises several important questions: Is adding
reasoning data earlier during pretraining any better than introducing it during
post-training? Could earlier inclusion risk overfitting and harm
generalization, or instead establish durable foundations that later fine-tuning
cannot recover? We conduct the first systematic study of how reasoning
data-varying in scale, diversity, and quality-affects LLM performance when
introduced at different stages of training. We find that front-loading
reasoning data into pretraining is critical (19% avg gain), establishing
foundational capabilities that cannot be fully replicated by later-stage SFT,
even with more data. We uncover an asymmetric principle for optimal data
allocation: pretraining benefits most from broad diversity in reasoning
patterns (11% avg gain), while SFT is more sensitive to data quality (15% avg
gain). We show that high-quality pretraining data has latent effects, activated
only after SFT, and that naively scaling SFT data can be detrimental, washing
away the benefits of early reasoning injection. Our results challenge the
conventional separation of language modeling and reasoning, providing a
principled guide for strategically allocating data across the entire training
pipeline to build more capable models.

</details>


### [166] [MindCraft: How Concept Trees Take Shape In Deep Models](https://arxiv.org/abs/2510.03265)
*Bowei Tian,Yexiao He,Wanghao Ye,Ziyao Wang,Meng Liu,Ang Li*

Main category: cs.LG

TL;DR: 这篇论文介绍了一个名为 MindCraft 的框架，它基于概念树，旨在分析大型基础模型内部如何构建和稳定概念。


<details>
  <summary>Details</summary>
Motivation: 探究大型基础模型如何在其内部构建和稳定概念。

Method: 通过在每一层应用谱分解，并将主方向连接成概念路径，概念树重构了概念的层次结构。

Result: 概念树能够恢复语义层次结构，解耦潜在概念，并广泛应用于多个领域。

Conclusion: 概念树建立了一个广泛适用且强大的框架，能够深入分析深度模型中的概念表示，标志着可解释人工智能基础方面的重要一步。

Abstract: Large-scale foundation models demonstrate strong performance across language,
vision, and reasoning tasks. However, how they internally structure and
stabilize concepts remains elusive. Inspired by causal inference, we introduce
the MindCraft framework built upon Concept Trees. By applying spectral
decomposition at each layer and linking principal directions into branching
Concept Paths, Concept Trees reconstruct the hierarchical emergence of
concepts, revealing exactly when they diverge from shared representations into
linearly separable subspaces. Empirical evaluations across diverse scenarios
across disciplines, including medical diagnosis, physics reasoning, and
political decision-making, show that Concept Trees recover semantic
hierarchies, disentangle latent concepts, and can be widely applied across
multiple domains. The Concept Tree establishes a widely applicable and powerful
framework that enables in-depth analysis of conceptual representations in deep
models, marking a significant step forward in the foundation of interpretable
AI.

</details>


### [167] [Variational Autoencoders-based Detection of Extremes in Plant Productivity in an Earth System Model](https://arxiv.org/abs/2510.03266)
*Bharat Sharma,Jitendra Kumar*

Main category: cs.LG

TL;DR: 本研究利用变分自编码器（VAE）识别美国大陆四个AR6区域的GPP极端事件，并与奇异谱分析（SSA）方法进行比较，发现VAE在计算效率和捕捉非线性时间依赖性方面具有优势。


<details>
  <summary>Details</summary>
Motivation: 气候异常对陆地碳循环动态产生显著影响，需要可靠的方法来检测和分析植物生产力中的异常行为。

Method: 采用变分自编码器（VAE）识别GPP中的极端事件。VAE架构采用三个密集层和一个潜在空间，输入序列长度为12个月，基于重建误差识别异常。

Result: VAE和SSA方法在极端事件频率的空间模式上表现出很强的一致性，同时VAE产生了更高的阈值。两种方法都表明，到2050-80年，负碳循环极端事件的幅度和频率都在增加，特别是在北美西部和中部。

Conclusion: VAE方法显示出与已建立的SSA技术相当的性能，同时提供计算优势和增强的捕捉碳循环变异中非线性时间依赖性的能力。与SSA不同，VAE方法不需要定义数据中信号的周期性；它可以从数据中发现它们。

Abstract: Climate anomalies significantly impact terrestrial carbon cycle dynamics,
necessitating robust methods for detecting and analyzing anomalous behavior in
plant productivity. This study presents a novel application of variational
autoencoders (VAE) for identifying extreme events in gross primary productivity
(GPP) from Community Earth System Model version 2 simulations across four AR6
regions in the Continental United States. We compare VAE-based anomaly
detection with traditional singular spectral analysis (SSA) methods across
three time periods: 1850-80, 1950-80, and 2050-80 under the SSP585 scenario.
The VAE architecture employs three dense layers and a latent space with an
input sequence length of 12 months, trained on a normalized GPP time series to
reconstruct the GPP and identifying anomalies based on reconstruction errors.
Extreme events are defined using 5th percentile thresholds applied to both VAE
and SSA anomalies. Results demonstrate strong regional agreement between VAE
and SSA methods in spatial patterns of extreme event frequencies, despite VAE
producing higher threshold values (179-756 GgC for VAE vs. 100-784 GgC for SSA
across regions and periods). Both methods reveal increasing magnitudes and
frequencies of negative carbon cycle extremes toward 2050-80, particularly in
Western and Central North America. The VAE approach shows comparable
performance to established SSA techniques, while offering computational
advantages and enhanced capability for capturing non-linear temporal
dependencies in carbon cycle variability. Unlike SSA, the VAE method does not
require one to define the periodicity of the signals in the data; it discovers
them from the data.

</details>


### [168] [PT$^2$-LLM: Post-Training Ternarization for Large Language Models](https://arxiv.org/abs/2510.03267)
*Xianglong Yan,Chengzhu Bao,Zhiteng Li,Tianao Zhang,Kaicheng Yang,Haotong Qin,Ruobing Xie,Xingwu Sun,Yulun Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为PT^2-LLM的后训练三元化框架，用于压缩大型语言模型（LLMs）。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然功能强大，但其庞大的内存和计算需求限制了部署。三元化作为一种有前途的压缩技术，受到了广泛关注，但其在后训练量化（PTQ）设置中的潜力仍有待探索。

Method: 该框架的核心是一个非对称三元量化器，配备了一个两阶段优化流程：迭代三元拟合（ITF）和激活感知网格对齐（AGA）。此外，还提出了一种基于结构相似性的重排序（SSR）策略，以简化量化并减轻异常值的影响。

Result: 实验表明，PT^2-LLM 提供了与最先进的（SOTA）2-bit PTQ 方法相比具有竞争力的性能，同时降低了内存成本，并加速了预填充和解码，实现了端到端的加速。

Conclusion: PT^2-LLM 是一种有效的 LLM 压缩方法，在性能、内存和速度方面都具有优势。

Abstract: Large Language Models (LLMs) have shown impressive capabilities across
diverse tasks, but their large memory and compute demands hinder deployment.
Ternarization has gained attention as a promising compression technique,
delivering substantial size reduction and high computational efficiency.
However, its potential in the post-training quantization (PTQ) setting remains
underexplored, due to the challenge of training-free parameter optimization and
the quantization difficulty posed by outliers and dispersed weights. To address
these issues, we propose PT$^2$-LLM, a post-training ternarization framework
tailored for LLMs. At its core is an Asymmetric Ternary Quantizer equipped with
a two-stage refinement pipeline: (1) Iterative Ternary Fitting (ITF), which
alternates between optimal ternary grid construction and flexible rounding to
minimize quantization error, and (2) Activation-aware Grid Alignment (AGA),
which further refines the ternary grid to better match full-precision outputs.
In addition, we propose a plug-and-play Structural Similarity-based Reordering
(SSR) strategy that leverages inter-column structural similarity to ease
quantization and mitigate outlier effects, further enhancing overall
performance. Extensive experiments demonstrate that PT$^2$-LLM delivers
competitive performance against state-of-the-art (SOTA) 2-bit PTQ methods with
lower memory cost, while also accelerating both prefill and decoding to achieve
end-to-end speedup. The code and models will be available at
https://github.com/XIANGLONGYAN/PT2-LLM.

</details>


### [169] [Decrypt Modality Gap in Multimodal Contrastive Learning: From Convergent Representation to Pair Alignment](https://arxiv.org/abs/2510.03268)
*Lingjie Yi,Raphael Douady,Chao Chen*

Main category: cs.LG

TL;DR: 本文研究了多模态对比学习（MCL）中的模态差距问题，并从理论上分析了其成因和对下游任务的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态对比学习方法存在模态差距现象，且模态差距对下游任务的影响尚不明确。本文旨在探究模态差距的成因以及它如何影响下游任务。

Method: 本文构建了一个理论框架，用于分析MCL的收敛最优表示和模态对齐，并探讨不同约束条件下的模态差距。

Result: 研究表明，在无约束或锥约束下，模态差距收敛到零；在子空间约束下，模态差距收敛到两个超平面之间的最小角度。维度坍塌是模态差距的根本原因。此外，在子空间约束下，配对样本无法完美对齐。模态差距通过影响样本对之间的对齐来影响下游性能。

Conclusion: 本文从理论上揭示了多模态对比学习中模态差距的成因和影响，并提出了通过超平面旋转和共享空间投影来实现模态完美对齐的方法。

Abstract: Multimodal contrastive learning (MCL) aims to embed data from different
modalities in a shared embedding space. However, empirical evidence shows that
representations from different modalities occupy completely separate regions of
embedding space, a phenomenon referred to as the modality gap. Moreover,
experimental findings on how the size of the modality gap influences downstream
performance are inconsistent. These observations raise two key questions: (1)
What causes the modality gap? (2) How does it affect downstream tasks? To
address these questions, this paper introduces the first theoretical framework
for analyzing the convergent optimal representations of MCL and the modality
alignment when training is optimized. Specifically, we prove that without any
constraint or under the cone constraint, the modality gap converges to zero.
Under the subspace constraint (i.e., representations of two modalities fall
into two distinct hyperplanes due to dimension collapse), the modality gap
converges to the smallest angle between the two hyperplanes. This result
identifies \emph{dimension collapse} as the fundamental origin of the modality
gap. Furthermore, our theorems demonstrate that paired samples cannot be
perfectly aligned under the subspace constraint. The modality gap influences
downstream performance by affecting the alignment between sample pairs. We
prove that, in this case, perfect alignment between two modalities can still be
achieved via two ways: hyperplane rotation and shared space projection.

</details>


### [170] [General Exploratory Bonus for Optimistic Exploration in RLHF](https://arxiv.org/abs/2510.03269)
*Wendi Li,Changdae Oh,Yixuan Li*

Main category: cs.LG

TL;DR: 现有的探索性奖励方法通常无法实现乐观主义，因为它们会无意中将探索偏向参考模型的高概率区域，从而加强保守行为而不是促进不确定区域的发现。我们引入了通用探索性奖励（GEB），它通过参考相关的奖励调节来抵消由散度引起的偏差，并在多个散度设置和大型语言模型骨干上优于基线。


<details>
  <summary>Details</summary>
Motivation: 在人反馈的强化学习中，乐观探索对于提高样本效率至关重要。

Method: 我们提供了一个理论分析，表明当前在KL或α-散度正则化下的公式，会无意中将探索偏向参考模型的高概率区域，从而加强保守行为而不是促进不确定区域的发现。为了解决这个缺陷，我们引入了通用探索性奖励（GEB），这是一个新的理论框架，可以证明满足乐观主义原则。GEB通过参考相关的奖励调节来抵消由散度引起的偏差，并将先前的启发式奖励统一为特殊情况，同时自然地扩展到整个α-散度族。

Result: GEB在多个散度设置和大型语言模型骨干上的对齐任务中始终优于基线。

Conclusion: 这些结果表明，GEB为RLHF中的乐观探索提供了一个原则性和实用的解决方案。

Abstract: Optimistic exploration is central to improving sample efficiency in
reinforcement learning with human feedback, yet existing exploratory bonus
methods to incentivize exploration often fail to realize optimism. We provide a
theoretical analysis showing that current formulations, under KL or
$\alpha$-divergence regularization, unintentionally bias exploration toward
high-probability regions of the reference model, thereby reinforcing
conservative behavior instead of promoting discovery of uncertain regions. To
address this pitfall, we introduce the General Exploratory Bonus (GEB), a novel
theoretical framework that provably satisfies the optimism principle. GEB
counteracts divergence-induced bias via reference-dependent reward regulation
and unifies prior heuristic bonuses as special cases, while extending naturally
across the full $\alpha$-divergence family. Empirically, GEB consistently
outperforms baselines on alignment tasks across multiple divergence settings
and large language model backbones. These results demonstrate that GEB offers
both a principled and practical solution for optimistic exploration in RLHF.

</details>


### [171] [CoDA: Coding LM via Diffusion Adaptation](https://arxiv.org/abs/2510.03270)
*Haolin Chen,Shiyu Wang,Can Qin,Bo Pang,Zuxin Liu,Jielin Qiu,Jianguo Zhang,Yingbo Zhou,Zeyuan Chen,Ran Xu,Shelby Heinecke,Silvio Savarese,Caiming Xiong,Huan Wang,Weiran Yao*

Main category: cs.LG

TL;DR: CoDA is a 1.7B-parameter diffusion coder.


<details>
  <summary>Details</summary>
Motivation: Diffusion language models have bidirectional context and infilling capabilities but are heavyweight.

Method: Large-scale diffusion pre-training with code-centric mid-training and instruction tuning, enabling confidence-guided sampling.

Result: CoDA-1.7B-Instruct matches or surpasses diffusion models up to 7B parameters on Humaneval, MBPP, and EvalPlus.

Conclusion: The release includes model checkpoints, evaluation harnesses, and TPU training pipelines to accelerate research on lightweight diffusion-based coding assistants.

Abstract: Diffusion language models promise bidirectional context and infilling
capabilities that autoregressive coders lack, yet practical systems remain
heavyweight. We introduce CoDA, a 1.7B-parameter diffusion coder trained on TPU
with a fully open-source training pipeline. CoDA pairs large-scale diffusion
pre-training with code-centric mid-training and instruction tuning, enabling
confidence-guided sampling that keeps inference latency competitive. On
Humaneval, MBPP, and EvalPlus, CoDA-1.7B-Instruct matches or surpasses
diffusion models up to 7B parameters. Our release includes model checkpoints,
evaluation harnesses, and TPU training pipelines to accelerate research on
lightweight diffusion-based coding assistants.

</details>


### [172] [Decision Potential Surface: A Theoretical and Practical Approximation of LLM's Decision Boundary](https://arxiv.org/abs/2510.03271)
*Zi Liang,Zhiyao Wu,Haoyang Shang,Yulin Jin,Qingqing Ye,Huadi Zheng,Peizhao Hu,Haibo Hu*

Main category: cs.LG

TL;DR: 提出了一种新的LLM决策边界分析方法，通过少量序列采样近似LLM的决策边界。


<details>
  <summary>Details</summary>
Motivation: 分析大型语言模型（LLM）的决策边界对于揭示模型的核心属性和解释行为至关重要，但由于LLM词汇量巨大和自回归的特性，构建LLM的决策边界在计算上是不可行的。

Method: 提出了决策势表面（DPS）的概念，它定义在区分每个输入的不同的抽样序列的置信度上，自然地捕捉了决策边界的潜力。提出了一种近似决策边界构建算法，即K-DPS。

Result: 从理论上推导了K-DPS与理想DPS之间的绝对误差、期望误差和误差集中度的上界，证明了这些误差可以通过采样时间进行权衡。通过各种LLM和语料库的广泛实验验证了我们的结果。

Conclusion: 所提出的K-DPS算法能够以可忽略的误差近似LLM的决策边界。

Abstract: Decision boundary, the subspace of inputs where a machine learning model
assigns equal classification probabilities to two classes, is pivotal in
revealing core model properties and interpreting behaviors. While analyzing the
decision boundary of large language models (LLMs) has raised increasing
attention recently, constructing it for mainstream LLMs remains computationally
infeasible due to the enormous vocabulary-sequence sizes and the
auto-regressive nature of LLMs. To address this issue, in this paper we propose
Decision Potential Surface (DPS), a new notion for analyzing LLM decision
boundary. DPS is defined on the confidences in distinguishing different
sampling sequences for each input, which naturally captures the potential of
decision boundary. We prove that the zero-height isohypse in DPS is equivalent
to the decision boundary of an LLM, with enclosed regions representing decision
regions. By leveraging DPS, for the first time in the literature, we propose an
approximate decision boundary construction algorithm, namely $K$-DPS, which
only requires K-finite times of sequence sampling to approximate an LLM's
decision boundary with negligible error. We theoretically derive the upper
bounds for the absolute error, expected error, and the error concentration
between K-DPS and the ideal DPS, demonstrating that such errors can be
trade-off with sampling times. Our results are empirically validated by
extensive experiments across various LLMs and corpora.

</details>


### [173] [PDE-Transformer: A Continuous Dynamical Systems Approach to Sequence Modeling](https://arxiv.org/abs/2510.03272)
*Yukun Zhang,Xueqing Zhou*

Main category: cs.LG

TL;DR: Transformer的内部机制仍然难以捉摸，本文提出了一个新的分析框架，将Transformer的离散分层结构重新概念化为由主偏微分方程（PDE）控制的连续时空动力系统。


<details>
  <summary>Details</summary>
Motivation: 对Transformer的内部机制缺乏理论理解。

Method: 将Transformer的核心架构组件映射到不同的数学算子，并将Transformer的离散分层结构重新概念化为由主偏微分方程（PDE）控制的连续时空动力系统，通过比较一个标准的Transformer和一个缺乏显式稳定器的PDE模拟器，

Result: 如果没有残差连接，系统会遭受灾难性的表征漂移，而如果没有层归一化，会导致不稳定、爆炸性的训练动态。

Conclusion: 残差连接和层归一化是驯服Transformer这种强大但不稳定的连续系统所需的基本数学稳定器。

Abstract: The Transformer architecture has revolutionized artificial intelligence, yet
a principled theoretical understanding of its internal mechanisms remains
elusive. This paper introduces a novel analytical framework that
reconceptualizes the Transformer's discrete, layered structure as a continuous
spatiotemporal dynamical system governed by a master Partial Differential
Equation (PDE). Within this paradigm, we map core architectural components to
distinct mathematical operators: self-attention as a non-local interaction, the
feed-forward network as a local reaction, and, critically, residual connections
and layer normalization as indispensable stabilization mechanisms. We do not
propose a new model, but rather employ the PDE system as a theoretical probe to
analyze the mathematical necessity of these components. By comparing a standard
Transformer with a PDE simulator that lacks explicit stabilizers, our
experiments provide compelling empirical evidence for our central thesis. We
demonstrate that without residual connections, the system suffers from
catastrophic representational drift, while the absence of layer normalization
leads to unstable, explosive training dynamics. Our findings reveal that these
seemingly heuristic "tricks" are, in fact, fundamental mathematical stabilizers
required to tame an otherwise powerful but inherently unstable continuous
system. This work offers a first-principles explanation for the Transformer's
design and establishes a new paradigm for analyzing deep neural networks
through the lens of continuous dynamics.

</details>


### [174] [Learning without Global Backpropagation via Synergistic Information Distillation](https://arxiv.org/abs/2510.03273)
*Chenhao Ye,Ming Tang*

Main category: cs.LG

TL;DR: 提出了一种名为协同信息蒸馏（SID）的新训练框架，旨在解决反向传播（BP）的可扩展性瓶颈问题，如更新锁定和高内存消耗。


<details>
  <summary>Details</summary>
Motivation: 反向传播（BP）存在两个关键的可扩展性瓶颈：更新锁定和高内存消耗。

Method: 将深度学习重新定义为局部协同细化问题的级联。在SID中，一个深度网络被构建为模块的流水线，每个模块都有一个局部目标，以改进关于ground-truth目标的概率信念。该目标平衡了对目标的保真度和与其前一个模块的信念的一致性。

Result: SID在分类精度上与BP相匹配或超过BP，表现出卓越的可扩展性和对标签噪声的显著鲁棒性。

Conclusion: SID是一种通用的BP替代方案，它保证了网络深度带来的单调性能提升，并且在经验上表现出优越的可扩展性和对标签噪声的鲁棒性。

Abstract: Backpropagation (BP), while foundational to deep learning, imposes two
critical scalability bottlenecks: update locking, where network modules remain
idle until the entire backward pass completes, and high memory consumption due
to storing activations for gradient computation. To address these limitations,
we introduce Synergistic Information Distillation (SID), a novel training
framework that reframes deep learning as a cascade of local cooperative
refinement problems. In SID, a deep network is structured as a pipeline of
modules, each imposed with a local objective to refine a probabilistic belief
about the ground-truth target. This objective balances fidelity to the target
with consistency to the belief from its preceding module. By decoupling the
backward dependencies between modules, SID enables parallel training and hence
eliminates update locking and drastically reduces memory requirements.
Meanwhile, this design preserves the standard feed-forward inference pass,
making SID a versatile drop-in replacement for BP. We provide a theoretical
foundation, proving that SID guarantees monotonic performance improvement with
network depth. Empirically, SID consistently matches or surpasses the
classification accuracy of BP, exhibiting superior scalability and pronounced
robustness to label noise.Code is available at:
https://github.com/ychAlbert/sid-bp

</details>


### [175] [Quant-dLLM: Post-Training Extreme Low-Bit Quantization for Diffusion Large Language Models](https://arxiv.org/abs/2510.03274)
*Tianao Zhang,Zhiteng Li,Xianglong Yan,Haotong Qin,Yong Guo,Yulun Zhang*

Main category: cs.LG

TL;DR: Quant-dLLM: A novel quantization framework for diffusion large language models (dLLMs) that achieves better performance than directly applying post-training quantization (PTQ) methods.


<details>
  <summary>Details</summary>
Motivation: Weight compression is needed for deploying large dLLMs, but directly applying PTQ at 2-bit leads to poor performance.

Method: Proposes Masked Calibration Simulation (MCS) to align calibration with timestep-dependent masking and a Data-aware Any-order Quantizer (DAQ) to learn ultra-low-bit weight representations. Also introduces Adaptive Blockwise Mixed Precision (ABMP) for precision allocation.

Result: Quant-dLLM achieves higher accuracy than state-of-the-art AR-transfer PTQ methods on dLLMs at 2-bit precision.

Conclusion: Quant-dLLM is an effective ultra-low-bit PTQ framework tailored for dLLMs.

Abstract: Diffusion large language models (dLLMs), which offer bidirectional context
and flexible masked-denoising generation, are emerging as a compelling
alternative to autoregressive (AR) LLMs. However, like AR LLMs, their model
sizes continue to grow, motivating weight compression for deployment. Although
post-training quantization (PTQ) is effective for AR LLMs, directly
transferring it to dLLMs at 2-bit leads to unsatisfactory performance. To
tackle these challenges, we propose Quant-dLLM, an ultra-low-bit PTQ framework
tailored to dLLMs. Since masked-denoising activations in dLLMs differ from the
fully visible signals assumed by standard PTQ methods, we introduce Masked
Calibration Simulation (MCS) to align calibration with the timestep-dependent
masking, which yields more reliable calibrations. Moreover, we propose a
Data-aware Any-order Quantizer (DAQ) that learns ultra-low-bit weight
representations via an optimization algorithm. It performs iterative
approximation guided by our simulated calibration data. In addition, under a
strict 2-bit budget, we introduce Adaptive Blockwise Mixed Precision (ABMP), a
sensitivity-based precision allocation scheme that adaptively assigns bit width
across channel groups. When restricted to 2-bit precision, Quant-dLLM
consistently achieves higher accuracy than state-of-the-art (SOTA) AR-transfer
PTQ methods on dLLMs. The code and models will be available at:
https://github.com/ZTA2785/Quant-dLLM.

</details>


### [176] [SDQ-LLM: Sigma-Delta Quantization for 1-bit LLMs of any size](https://arxiv.org/abs/2510.03275)
*Junhao Xia,Ming Zhao,Limin Xiao,Xiujun Zhang*

Main category: cs.LG

TL;DR: SDQ-LLM: A novel framework for extremely low-bit quantization of LLMs, preserving linguistic reasoning capabilities.


<details>
  <summary>Details</summary>
Motivation: To address the computational and memory challenges faced by large language models (LLMs), making extremely low-bit quantization crucial for their efficient deployment.

Method: Introduces Sigma-Delta Quantization (SDQ-LLM) with continuous adjustability of the Over-Sampling Ratio (OSR), Hadamard-based weight smoothing, and a fine-grained, layer- and linear-wise OSR allocation strategy (MultiOSR).

Result: SDQ-LLM achieves efficient and high-precision performance on OPT and LLaMA model families, even under highly aggressive low-OSR settings.

Conclusion: SDQ-LLM enables extremely low-bit quantization of LLMs while preserving their linguistic reasoning capabilities, offering an optimal trade-off between model size and accuracy.

Abstract: Large language models (LLMs) face significant computational and memory
challenges, making extremely low-bit quantization crucial for their efficient
deployment. In this work, we introduce SDQ-LLM: Sigma-Delta Quantization for
1-bit LLMs of any size, a novel framework that enables extremely low-bit
quantization of LLMs while preserving their linguistic reasoning capabilities.
A distinctive feature of SDQ-LLM is the continuous adjustability of the
Over-Sampling Ratio (OSR), enabling dynamic adaptation to memory or VRAM
constraints by selecting fractional OSR (e.g. 2.5 times) for an optimal
trade-off between model size and accuracy. SDQ-LLM uses upsampling combined
with Sigma-Delta Quantizer to binarize or ternarize LLMs weights, encoding
high-precision parameters into 1-bit or 1.58-bit representations, replacing the
multiplication operations within linear layers with addition. This approach
significantly enhances inference efficiency under extremely low-bit
quantization. To further reduce the loss of quantization precision, we
incorporate Hadamard-based weight smoothing prior to quantization, improving
the stability and robustness of the weight representations. Furthermore, to
fully leverage the continuity of the OSR and reduce precision loss, recognizing
the correlation between quantization sensitivity and weight variance, we
propose a fine-grained, layer- and linear-wise OSR allocation strategy,
MultiOSR. This strategy distributes OSR both across layers and within each
layer, based on weight variance and parameter scale. Finally, extensive
experiments on OPT and LLaMA model families demonstrate that SDQ-LLM achieves a
more efficient and high-precision performance even under highly aggressive
low-OSR settings. Our code is available at
https://github.com/Dreamlittlecat/LLM-Quant-Factory.

</details>


### [177] [QuadEnhancer: Leveraging Quadratic Transformations to Enhance Deep Neural Networks](https://arxiv.org/abs/2510.03276)
*Qian Chen,Linxin Yang,Akang Wang,Xiaodong Luo,Yin Zhang*

Main category: cs.LG

TL;DR: 这篇论文提出了一种轻量级的二次增强器，旨在通过引入二次变换来增加神经网络的非线性，从而提高现有架构的性能。


<details>
  <summary>Details</summary>
Motivation: 为了增强现有神经网络架构的性能，论文探索了引入二次变换以增加非线性。

Method: 提出了一个轻量级的二次增强器，它利用低秩性、权重共享和稀疏化技术来降低参数复杂度和计算复杂度。该方法在每一层引入特征之间的二次交互，同时只增加少量的模型参数和前向计算。

Result: 在图像分类、文本分类和微调大型语言模型三个任务中，所提出的方法都表现出明显且显著的性能提升。

Conclusion: 论文提出的方法在所有任务中都证明了其有效性，能够带来清晰且显著的性能提升。

Abstract: The combination of linear transformations and non-linear activation functions
forms the foundation of most modern deep neural networks, enabling them to
approximate highly complex functions. This paper explores the introduction of
quadratic transformations to further increase nonlinearity in neural networks,
with the aim of enhancing the performance of existing architectures. To reduce
parameter complexity and computational complexity, we propose a lightweight
quadratic enhancer that uses low-rankness, weight sharing, and sparsification
techniques. For a fixed architecture, the proposed approach introduces
quadratic interactions between features at every layer, while only adding
negligible amounts of additional model parameters and forward computations. We
conduct a set of proof-of-concept experiments for the proposed method across
three tasks: image classification, text classification, and fine-tuning
large-language models. In all tasks, the proposed approach demonstrates clear
and substantial performance gains.

</details>


### [178] [Quantifying constraint hierarchies in Bayesian PINNs via per-constraint Hessian decomposition](https://arxiv.org/abs/2510.03278)
*Filip Landgren*

Main category: cs.LG

TL;DR: 贝叶斯物理信息神经网络(B-PINNs)结合数据和控制方程来解决不确定性下的微分方程。然而，由于物理约束对网络的影响尚不清楚，解释B-PINNs中的不确定性和过度自信需要谨慎。


<details>
  <summary>Details</summary>
Motivation: 需要进一步阐明个体物理约束如何塑造这些网络。

Method: 引入了一种可扩展的、无矩阵的拉普拉斯框架，该框架将后验 Hessian 分解为来自每个约束的贡献，并提供指标来量化它们对损失情况的相对影响。

Result: 该方法跟踪约束如何塑造网络的几何形状，并直接通过 Hessian 展示了改变单个损失权重如何在其他约束中重新分配曲率和有效优势。

Conclusion: 该研究提供了一种量化物理约束对贝叶斯物理信息神经网络影响的方法。

Abstract: Bayesian physics-informed neural networks (B-PINNs) merge data with governing
equations to solve differential equations under uncertainty. However,
interpreting uncertainty and overconfidence in B-PINNs requires care due to the
poorly understood effects the physical constraints have on the network;
overconfidence could reflect warranted precision, enforced by the constraints,
rather than miscalibration. Motivated by the need to further clarify how
individual physical constraints shape these networks, we introduce a scalable,
matrix-free Laplace framework that decomposes the posterior Hessian into
contributions from each constraint and provides metrics to quantify their
relative influence on the loss landscape. Applied to the Van der Pol equation,
our method tracks how constraints sculpt the network's geometry and shows,
directly through the Hessian, how changing a single loss weight non-trivially
redistributes curvature and effective dominance across the others.

</details>


### [179] [MemMamba: Rethinking Memory Patterns in State Space Model](https://arxiv.org/abs/2510.03279)
*Youjin Wang,Yangjingyi Chen,Jiahao Yan,Jiaxuan Lu,Xiao Sun*

Main category: cs.LG

TL;DR: 本文介绍了一种名为MemMamba的新型架构，旨在解决Mamba模型中存在的长程记忆衰减问题，同时保持线性复杂性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在效率和内存之间存在固有的权衡。循环神经网络难以扩展，而Transformers受限于二次复杂度。Mamba虽然高效，但其长程记忆呈指数衰减。

Method: 通过数学推导和信息论分析，揭示了Mamba的记忆衰减机制。引入了水平-垂直记忆保真度指标来量化关键信息损失。提出了MemMamba，它集成了状态总结机制以及跨层和跨token的注意力。

Result: MemMamba在长序列基准测试（如PG19和Passkey Retrieval）上优于现有的Mamba变体和Transformers，并在推理效率上提高了48%。

Conclusion: MemMamba在复杂性-记忆权衡方面取得了突破，为超长序列建模提供了一种新范例。

Abstract: With the explosive growth of data, long-sequence modeling has become
increasingly important in tasks such as natural language processing and
bioinformatics. However, existing methods face inherent trade-offs between
efficiency and memory. Recurrent neural networks suffer from gradient vanishing
and explosion, making them hard to scale. Transformers can model global
dependencies but are constrained by quadratic complexity. Recently, selective
state-space models such as Mamba have demonstrated high efficiency with O(n)
time and O(1) recurrent inference, yet their long-range memory decays
exponentially. In this work, we conduct mathematical derivations and
information-theoretic analysis to systematically uncover the memory decay
mechanism of Mamba, answering a fundamental question: what is the nature of
Mamba's long-range memory and how does it retain information? To quantify key
information loss, we further introduce horizontal-vertical memory fidelity
metrics that capture degradation both within and across layers. Inspired by how
humans distill and retain salient information when reading long documents, we
propose MemMamba, a novel architectural framework that integrates state
summarization mechanism together with cross-layer and cross-token attention,
which alleviates long-range forgetting while preserving linear complexity.
MemMamba achieves significant improvements over existing Mamba variants and
Transformers on long-sequence benchmarks such as PG19 and Passkey Retrieval,
while delivering a 48% speedup in inference efficiency. Both theoretical
analysis and empirical results demonstrate that MemMamba achieves a
breakthrough in the complexity-memory trade-off, offering a new paradigm for
ultra-long sequence modeling.

</details>


### [180] [Training Optimal Large Diffusion Language Models](https://arxiv.org/abs/2510.03280)
*Jinjie Ni,Qian Liu,Chao Du,Longxu Dou,Hang Yan,Zili Wang,Tianyu Pang,Michael Qizhe Shieh*

Main category: cs.LG

TL;DR: 介绍了扩散语言模型（DLM）的首个系统性扩展法则 Quokka，涵盖计算和数据受限的情况，并研究了关键的建模和优化设计。


<details>
  <summary>Details</summary>
Motivation: 旨在为 DLM 训练提供短期实践指导，并为整个人工智能社区带来长期启发。

Method: 提出了一个系统性的扩展法则，同时研究了关键的建模和优化设计。

Result: Quokka 是 Chinchilla 的好朋友，并提供了更广泛的范围。

Conclusion: 希望研究结果能为 DLM 训练带来短期实践指导，并为整个人工智能社区带来长期启发。

Abstract: We introduce Quokka, the first systematic scaling law for diffusion language
models (DLMs), encompassing both compute-constrained and data-constrained
regimes, and studying the key modeling and optimization designs. Quokka is a
good friend of Chinchilla and provides wider scopes. We hope the results would
bring short-term practical guidance in DLMs training and long-term inspirations
for the whole AI community.

</details>


### [181] [Discovering Transformer Circuits via a Hybrid Attribution and Pruning Framework](https://arxiv.org/abs/2510.03282)
*Hao Gu,Vibhas Nair,Amrithaa Ashok Kumar,Jayvart Sharma,Ryan Lagasse*

Main category: cs.LG

TL;DR: 提出了一种混合归因和剪枝 (HAP) 框架，用于识别稀疏子网络或电路，以完成特定任务。


<details>
  <summary>Details</summary>
Motivation: 现有的电路发现算法面临着一个基本的权衡：归因修补速度快，但对完整模型不忠实，而边缘剪枝是忠实的，但计算成本高昂。

Method: 该研究提出了一种混合归因和剪枝 (HAP) 框架，该框架使用归因修补来识别高潜力子图，然后应用边缘剪枝从中提取忠实的电路。

Result: HAP 比基线算法快 46%，且不牺牲电路的真实性。此外，我们提出了一个关于间接对象识别任务的案例研究，表明我们的方法保留了合作电路组件（例如 S 抑制头），而归因修补方法在高稀疏度下会修剪这些组件。

Conclusion: HAP 是一种有效的方法，可以提高机械可解释性研究的可扩展性，以适应更大的模型。

Abstract: Interpreting language models often involves circuit analysis, which aims to
identify sparse subnetworks, or circuits, that accomplish specific tasks.
Existing circuit discovery algorithms face a fundamental trade-off: attribution
patching is fast but unfaithful to the full model, while edge pruning is
faithful but computationally expensive. This research proposes a hybrid
attribution and pruning (HAP) framework that uses attribution patching to
identify a high-potential subgraph, then applies edge pruning to extract a
faithful circuit from it. We show that HAP is 46\% faster than baseline
algorithms without sacrificing circuit faithfulness. Furthermore, we present a
case study on the Indirect Object Identification task, showing that our method
preserves cooperative circuit components (e.g. S-inhibition heads) that
attribution patching methods prune at high sparsity. Our results show that HAP
could be an effective approach for improving the scalability of mechanistic
interpretability research to larger models. Our code is available at
https://anonymous.4open.science/r/HAP-circuit-discovery.

</details>


### [182] [MACE: A Hybrid LLM Serving System with Colocated SLO-aware Continuous Retraining Alignment](https://arxiv.org/abs/2510.03283)
*Yufei Li,Yu Fu,Yue Dong,Cong Liu*

Main category: cs.LG

TL;DR: 提出了一种名为MACE的混合LLM系统，该系统在边缘服务器上共置并发推理和微调，并通过智能内存管理来最大限度地提高任务性能并保证推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 边缘服务器上部署的LLM需要频繁的重新训练，但在GPU资源受限的情况下，推理延迟和模型精度之间存在根本矛盾。现有的重新训练策略要么延迟模型更新，要么过度分配资源给重新训练，要么忽略迭代级别的重新训练粒度。

Method: MACE利用迭代级调度对于适应模型漂移至关重要的洞察力，并相应地分配GPU周期以平衡吞吐量、延迟和更新鲜度。

Result: MACE在资源受限的情况下，匹配或超过了连续重新训练，同时将推理延迟降低了高达63%，并保持了吞吐量。MACE改善了预填充、解码和微调阶段的延迟分解，并在NVIDIA AGX Orin中维持了85%以上的GPU利用率。

Conclusion: 迭代级混合调度是在边缘平台部署具有持续学习能力的LLM的一个有希望的方向。

Abstract: Large language models (LLMs) deployed on edge servers are increasingly used
in latency-sensitive applications such as personalized assistants,
recommendation, and content moderation. However, the non-stationary nature of
user data necessitates frequent retraining, which introduces a fundamental
tension between inference latency and model accuracy under constrained GPU
resources. Existing retraining strategies either delay model updates,
over-commit resources to retraining, or overlook iteration-level retraining
granularity. In this paper, we identify that iteration-level scheduling is
crucial for adapting retraining frequency to model drift without violating
service-level objectives (SLOs). We propose MACE, a hybrid LLM system that
colocates concurrent inference (prefill, decode) and fine-tuning, with
intelligent memory management to maximize task performance while promising
inference throughput. MACE leverages the insight that not all model updates
equally affect output alignment and allocates GPU cycles accordingly to balance
throughput, latency, and update freshness. Our trace-driven evaluation shows
that MACE matches or exceeds continuous retraining while reducing inference
latency by up to 63% and maintaining throughput under resource constraints.
Compared to periodic retraining, MACE improves latency breakdown across
prefill, decode, and finetune stages, and sustains GPU utilization above 85% in
NVIDIA AGX Orin. These results demonstrate that iteration-level hybrid
scheduling is a promising direction for deploying LLMs with continual learning
capabilities on edge platforms.

</details>


### [183] [Edge-FIT: Federated Instruction Tuning of Quantized LLMs for Privacy-Preserving Smart Home Environments](https://arxiv.org/abs/2510.03284)
*Vinay Venkatesh,Vamsidhar R Kamanuru,Lav Kumar,Nikita Kothari*

Main category: cs.LG

TL;DR: 提出了Edge-FIT，一个用于LLM的联邦指令调整框架。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习方法在面对LLM的大量参数时会失败。

Method: Edge-FIT结合了联邦学习和4位量化低秩适配(QLORA)。

Result: Edge-FIT调整的Llama 2(7B)达到了0.89的F1分数。使用3.8B Phi-3-mini模型验证了Edge-FIT作为家庭计算网关上分散式LLM部署的可扩展框架。

Conclusion: Edge-FIT是一个用于分散式LLM部署的可扩展框架。

Abstract: This paper proposes Edge-FIT (Federated Instruction Tuning on the Edge), a
scalable framework for Federated Instruction Tuning (FIT) of Large Language
Models (LLMs). Traditional Federated Learning (TFL) methods, like FedAvg, fail
when confronted with the massive parameter size of LLMs [3], [6]. Our Edge-FIT
framework combines federated learning with 4-bit Quantized Low-Rank Adaptation
(QLORA), mitigating the core issues of communication and computational
overhead. We demonstrate this by filtering the general-purpose Databricks Dolly
15k dataset for the IoT domain. Experimental results show the Edge-FIT tuned
Llama 2(7B) achieves an F1-Score of 0.89. We also demonstrate a viable
trade-off using the 3.8B Phi-3-mini model, validating Edge-FIT as a scalable
framework for decentralized LLM deployment on home compute gateways.

</details>


### [184] [LogAction: Consistent Cross-system Anomaly Detection through Logs via Active Domain](https://arxiv.org/abs/2510.03288)
*Chiming Duan,Minghua He,Pei Xiao,Tong Jia,Xin Zhang,Zhewei Zhong,Xiang Luo,Yan Niu,Lingzhe Zhang,Yifan Wu,Siyu Yu,Weijie Hong,Ying Li,Gang Huang*

Main category: cs.LG

TL;DR: LogAction: A log-based anomaly detection model using active domain adaptation to address labeling challenges and distribution gaps.


<details>
  <summary>Details</summary>
Motivation: Existing anomaly detection methods rely heavily on labeled data, which is challenging to obtain. Transfer learning and active learning approaches are hindered by distribution gaps and cold-start problems.

Method: LogAction integrates transfer learning and active learning. It uses labeled data from a mature system and employs free energy-based and uncertainty-based sampling for manual labeling of logs at distribution boundaries.

Result: LogAction achieves an average 93.01% F1 score with only 2% of manual labels, outperforming state-of-the-art methods by 26.28% on six datasets.

Conclusion: LogAction effectively addresses the challenges of log-based anomaly detection by combining transfer learning and active learning to minimize labeling effort and bridge data distribution gaps.

Abstract: Log-based anomaly detection is a essential task for ensuring the reliability
and performance of software systems. However, the performance of existing
anomaly detection methods heavily relies on labeling, while labeling a large
volume of logs is highly challenging. To address this issue, many approaches
based on transfer learning and active learning have been proposed.
Nevertheless, their effectiveness is hindered by issues such as the gap between
source and target system data distributions and cold-start problems. In this
paper, we propose LogAction, a novel log-based anomaly detection model based on
active domain adaptation. LogAction integrates transfer learning and active
learning techniques. On one hand, it uses labeled data from a mature system to
train a base model, mitigating the cold-start issue in active learning. On the
other hand, LogAction utilize free energy-based sampling and uncertainty-based
sampling to select logs located at the distribution boundaries for manual
labeling, thus addresses the data distribution gap in transfer learning with
minimal human labeling efforts. Experimental results on six different
combinations of datasets demonstrate that LogAction achieves an average 93.01%
F1 score with only 2% of manual labels, outperforming some state-of-the-art
methods by 26.28%. Website: https://logaction.github.io

</details>


### [185] [Why mask diffusion does not work](https://arxiv.org/abs/2510.03289)
*Haocheng Sun,Cynthia Xin Wen,Edward Hong Wang*

Main category: cs.LG

TL;DR: 本文探讨了掩码扩散语言模型，并指出了其在并行生成和双向注意力方面的固有困难。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型在并行生成和双向注意力方面优于自回归模型，从而实现更可控的生成过程。探讨了当前开源的掩码扩散语言模型。

Method: 分析了掩码扩散在实现并行生成和双向注意力时面临的困难，并提出了有效的训练和推理策略。

Result: 论证了掩码扩散在并行生成和双向注意力方面存在固有困难。

Conclusion: 为掩码扩散提出了有效的训练和推理策略。

Abstract: The main advantages of diffusion language models over autoregressive (AR)
models lie in their ability to support parallel generation and bidirectional
attention, enabling a more controllable generation process. In recent years,
open-source mask diffusion language models have emerged, most of which are
based on a variant known as absorbing diffusion. However, this paper
demonstrates why mask diffusion faces inherent difficulties in achieving
parallel generation and bidirectional attention. We also propose the most
effective training and inference strategies for mask diffusion.

</details>


### [186] [Single-Core Superscalar Optimization of Clifford Neural Layers](https://arxiv.org/abs/2510.03290)
*X. Angelo Huang,Ruben Ciranni,Giovanni Spadaccini,Carla J. López Zurita*

Main category: cs.LG

TL;DR: 这篇论文提出了一系列优化方法，以加速Clifford卷积层的推理过程，同时保持正确性。


<details>
  <summary>Details</summary>
Motivation: 在物理科学领域，人们对开发具有等变性质的网络越来越感兴趣，Clifford神经层作为一种方法，可以在给定特定群作用的情况下，提供E(n)和O(n)等变性。

Method: 该论文分析了Clifford卷积层内部计算的理论基础，以消除冗余的矩阵分配和计算，然后系统地应用已建立的优化技术来进一步提高性能。

Result: 相对于基线实现，最终平均加速了21.35倍。在六种情况下，运行时间与原始PyTorch实现相当甚至更快。在其余情况下，实现了与原始库相同数量级的性能。

Conclusion: 通过对Clifford代数的理论基础进行分析，并应用优化技术，可以显著提高Clifford卷积层的推理速度，且性能与原始PyTorch实现相当甚至更好。

Abstract: Within the growing interest in the physical sciences in developing networks
with equivariance properties, Clifford neural layers shine as one approach that
delivers $E(n)$ and $O(n)$ equivariances given specific group actions. In this
paper, we analyze the inner structure of the computation within Clifford
convolutional layers and propose and implement several optimizations to speed
up the inference process while maintaining correctness. In particular, we begin
by analyzing the theoretical foundations of Clifford algebras to eliminate
redundant matrix allocations and computations, then systematically apply
established optimization techniques to enhance performance further. We report a
final average speedup of 21.35x over the baseline implementation of eleven
functions and runtimes comparable to and faster than the original PyTorch
implementation in six cases. In the remaining cases, we achieve performance in
the same order of magnitude as the original library.

</details>
